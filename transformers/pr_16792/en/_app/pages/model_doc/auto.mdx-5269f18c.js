import{S as lLt,i as iLt,s as dLt,e as a,k as l,w as f,t as o,M as cLt,c as n,d as t,m as i,a as s,x as m,h as r,b as d,F as e,g as b,y as g,q as h,o as p,B as _,v as fLt}from"../../chunks/vendor-6b77c823.js";import{T as ujr}from"../../chunks/Tip-39098574.js";import{D as w}from"../../chunks/Docstring-1088f2fb.js";import{C as A}from"../../chunks/CodeBlock-3a8b25a8.js";import{I as z}from"../../chunks/IconCopyLink-7a11ce68.js";function mLt(zf){let oe,co,ge,Ae,io,ue,we,Xo,Qi,Qf,fa,Wi,Hi,Z5,Wf,Re,fo,Ui,On,e3,Vn,Xn,o3,Ji,zn,r3,Yi,Hf,Da;return{c(){oe=a("p"),co=o("If your "),ge=a("code"),Ae=o("NewModelConfig"),io=o(" is a subclass of "),ue=a("code"),we=o("PretrainedConfig"),Xo=o(`, make sure its
`),Qi=a("code"),Qf=o("model_type"),fa=o(" attribute is set to the same key you use when registering the config (here "),Wi=a("code"),Hi=o('"new-model"'),Z5=o(")."),Wf=l(),Re=a("p"),fo=o("Likewise, if your "),Ui=a("code"),On=o("NewModel"),e3=o(" is a subclass of "),Vn=a("a"),Xn=o("PreTrainedModel"),o3=o(`, make sure its
`),Ji=a("code"),zn=o("config_class"),r3=o(` attribute is set to the same class you use when registering the model (here
`),Yi=a("code"),Hf=o("NewModelConfig"),Da=o(")."),this.h()},l(mo){oe=n(mo,"P",{});var ve=s(oe);co=r(ve,"If your "),ge=n(ve,"CODE",{});var ex=s(ge);Ae=r(ex,"NewModelConfig"),ex.forEach(t),io=r(ve," is a subclass of "),ue=n(ve,"CODE",{});var Ki=s(ue);we=r(Ki,"PretrainedConfig"),Ki.forEach(t),Xo=r(ve,`, make sure its
`),Qi=n(ve,"CODE",{});var ox=s(Qi);Qf=r(ox,"model_type"),ox.forEach(t),fa=r(ve," attribute is set to the same key you use when registering the config (here "),Wi=n(ve,"CODE",{});var rx=s(Wi);Hi=r(rx,'"new-model"'),rx.forEach(t),Z5=r(ve,")."),ve.forEach(t),Wf=i(mo),Re=n(mo,"P",{});var zo=s(Re);fo=r(zo,"Likewise, if your "),Ui=n(zo,"CODE",{});var Ga=s(Ui);On=r(Ga,"NewModel"),Ga.forEach(t),e3=r(zo," is a subclass of "),Vn=n(zo,"A",{href:!0});var tx=s(Vn);Xn=r(tx,"PreTrainedModel"),tx.forEach(t),o3=r(zo,`, make sure its
`),Ji=n(zo,"CODE",{});var Uf=s(Ji);zn=r(Uf,"config_class"),Uf.forEach(t),r3=r(zo,` attribute is set to the same class you use when registering the model (here
`),Yi=n(zo,"CODE",{});var ax=s(Yi);Hf=r(ax,"NewModelConfig"),ax.forEach(t),Da=r(zo,")."),zo.forEach(t),this.h()},h(){d(Vn,"href","/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel")},m(mo,ve){b(mo,oe,ve),e(oe,co),e(oe,ge),e(ge,Ae),e(oe,io),e(oe,ue),e(ue,we),e(oe,Xo),e(oe,Qi),e(Qi,Qf),e(oe,fa),e(oe,Wi),e(Wi,Hi),e(oe,Z5),b(mo,Wf,ve),b(mo,Re,ve),e(Re,fo),e(Re,Ui),e(Ui,On),e(Re,e3),e(Re,Vn),e(Vn,Xn),e(Re,o3),e(Re,Ji),e(Ji,zn),e(Re,r3),e(Re,Yi),e(Yi,Hf),e(Re,Da)},d(mo){mo&&t(oe),mo&&t(Wf),mo&&t(Re)}}}function gLt(zf){let oe,co,ge,Ae,io;return{c(){oe=a("p"),co=o("Passing "),ge=a("code"),Ae=o("use_auth_token=True"),io=o(" is required when you want to use a private model.")},l(ue){oe=n(ue,"P",{});var we=s(oe);co=r(we,"Passing "),ge=n(we,"CODE",{});var Xo=s(ge);Ae=r(Xo,"use_auth_token=True"),Xo.forEach(t),io=r(we," is required when you want to use a private model."),we.forEach(t)},m(ue,we){b(ue,oe,we),e(oe,co),e(oe,ge),e(ge,Ae),e(oe,io)},d(ue){ue&&t(oe)}}}function hLt(zf){let oe,co,ge,Ae,io;return{c(){oe=a("p"),co=o("Passing "),ge=a("code"),Ae=o("use_auth_token=True"),io=o(" is required when you want to use a private model.")},l(ue){oe=n(ue,"P",{});var we=s(oe);co=r(we,"Passing "),ge=n(we,"CODE",{});var Xo=s(ge);Ae=r(Xo,"use_auth_token=True"),Xo.forEach(t),io=r(we," is required when you want to use a private model."),we.forEach(t)},m(ue,we){b(ue,oe,we),e(oe,co),e(oe,ge),e(ge,Ae),e(oe,io)},d(ue){ue&&t(oe)}}}function pLt(zf){let oe,co,ge,Ae,io,ue,we,Xo,Qi,Qf,fa,Wi,Hi,Z5,Wf,Re,fo,Ui,On,e3,Vn,Xn,o3,Ji,zn,r3,Yi,Hf,Da,mo,ve,ex,Ki,ox,rx,zo,Ga,tx,Uf,ax,zNe,RPe,Zi,Jf,EK,t3,QNe,CK,WNe,BPe,Qn,HNe,wK,UNe,JNe,AK,YNe,KNe,PPe,a3,$Pe,nx,ZNe,IPe,Yf,qPe,ed,Kf,yK,n3,eje,LK,oje,NPe,Qo,s3,rje,l3,tje,sx,aje,nje,sje,i3,lje,xK,ije,dje,cje,go,d3,fje,kK,mje,gje,od,hje,SK,pje,_je,RK,uje,bje,vje,v,Zf,BK,Fje,Tje,lx,Mje,Eje,Cje,em,PK,wje,Aje,ix,yje,Lje,xje,om,$K,kje,Sje,dx,Rje,Bje,Pje,rm,IK,$je,Ije,cx,qje,Nje,jje,tm,qK,Dje,Gje,fx,Oje,Vje,Xje,am,NK,zje,Qje,mx,Wje,Hje,Uje,nm,jK,Jje,Yje,gx,Kje,Zje,eDe,sm,DK,oDe,rDe,hx,tDe,aDe,nDe,lm,GK,sDe,lDe,px,iDe,dDe,cDe,im,OK,fDe,mDe,_x,gDe,hDe,pDe,dm,VK,_De,uDe,ux,bDe,vDe,FDe,cm,XK,TDe,MDe,bx,EDe,CDe,wDe,fm,zK,ADe,yDe,vx,LDe,xDe,kDe,mm,QK,SDe,RDe,Fx,BDe,PDe,$De,gm,WK,IDe,qDe,Tx,NDe,jDe,DDe,hm,HK,GDe,ODe,Mx,VDe,XDe,zDe,pm,UK,QDe,WDe,Ex,HDe,UDe,JDe,_m,JK,YDe,KDe,Cx,ZDe,eGe,oGe,um,YK,rGe,tGe,wx,aGe,nGe,sGe,bm,KK,lGe,iGe,Ax,dGe,cGe,fGe,vm,ZK,mGe,gGe,yx,hGe,pGe,_Ge,Fm,eZ,uGe,bGe,Lx,vGe,FGe,TGe,Tm,oZ,MGe,EGe,xx,CGe,wGe,AGe,Mm,rZ,yGe,LGe,kx,xGe,kGe,SGe,Em,tZ,RGe,BGe,Sx,PGe,$Ge,IGe,Cm,aZ,qGe,NGe,Rx,jGe,DGe,GGe,wm,nZ,OGe,VGe,Bx,XGe,zGe,QGe,Am,sZ,WGe,HGe,Px,UGe,JGe,YGe,ym,lZ,KGe,ZGe,$x,eOe,oOe,rOe,Lm,iZ,tOe,aOe,Ix,nOe,sOe,lOe,xm,dZ,iOe,dOe,qx,cOe,fOe,mOe,km,cZ,gOe,hOe,Nx,pOe,_Oe,uOe,Sm,fZ,bOe,vOe,jx,FOe,TOe,MOe,Rm,mZ,EOe,COe,Dx,wOe,AOe,yOe,Bm,gZ,LOe,xOe,Gx,kOe,SOe,ROe,Pm,hZ,BOe,POe,Ox,$Oe,IOe,qOe,$m,pZ,NOe,jOe,Vx,DOe,GOe,OOe,Im,_Z,VOe,XOe,Xx,zOe,QOe,WOe,qm,uZ,HOe,UOe,zx,JOe,YOe,KOe,Nm,bZ,ZOe,eVe,Qx,oVe,rVe,tVe,jm,vZ,aVe,nVe,Wx,sVe,lVe,iVe,Dm,FZ,dVe,cVe,Hx,fVe,mVe,gVe,Gm,TZ,hVe,pVe,Ux,_Ve,uVe,bVe,Om,MZ,vVe,FVe,Jx,TVe,MVe,EVe,Vm,EZ,CVe,wVe,Yx,AVe,yVe,LVe,Xm,CZ,xVe,kVe,Kx,SVe,RVe,BVe,zm,wZ,PVe,$Ve,Zx,IVe,qVe,NVe,Qm,AZ,jVe,DVe,ek,GVe,OVe,VVe,Wm,yZ,XVe,zVe,ok,QVe,WVe,HVe,Hm,LZ,UVe,JVe,rk,YVe,KVe,ZVe,Um,xZ,eXe,oXe,tk,rXe,tXe,aXe,Jm,kZ,nXe,sXe,ak,lXe,iXe,dXe,Ym,SZ,cXe,fXe,nk,mXe,gXe,hXe,Km,RZ,pXe,_Xe,sk,uXe,bXe,vXe,Zm,BZ,FXe,TXe,lk,MXe,EXe,CXe,eg,PZ,wXe,AXe,ik,yXe,LXe,xXe,og,$Z,kXe,SXe,dk,RXe,BXe,PXe,rg,IZ,$Xe,IXe,ck,qXe,NXe,jXe,tg,qZ,DXe,GXe,fk,OXe,VXe,XXe,ag,NZ,zXe,QXe,mk,WXe,HXe,UXe,ng,jZ,JXe,YXe,gk,KXe,ZXe,eze,sg,DZ,oze,rze,hk,tze,aze,nze,lg,GZ,sze,lze,pk,ize,dze,cze,ig,OZ,fze,mze,_k,gze,hze,pze,dg,VZ,_ze,uze,uk,bze,vze,Fze,cg,XZ,Tze,Mze,bk,Eze,Cze,wze,fg,zZ,Aze,yze,vk,Lze,xze,kze,mg,QZ,Sze,Rze,Fk,Bze,Pze,$ze,gg,WZ,Ize,qze,Tk,Nze,jze,Dze,hg,HZ,Gze,Oze,Mk,Vze,Xze,zze,pg,UZ,Qze,Wze,Ek,Hze,Uze,Jze,_g,JZ,Yze,Kze,Ck,Zze,eQe,oQe,ug,YZ,rQe,tQe,wk,aQe,nQe,sQe,bg,KZ,lQe,iQe,Ak,dQe,cQe,fQe,vg,ZZ,mQe,gQe,yk,hQe,pQe,_Qe,Fg,eee,uQe,bQe,Lk,vQe,FQe,TQe,Tg,oee,MQe,EQe,xk,CQe,wQe,AQe,Mg,ree,yQe,LQe,kk,xQe,kQe,SQe,Eg,tee,RQe,BQe,Sk,PQe,$Qe,IQe,Cg,aee,qQe,NQe,Rk,jQe,DQe,GQe,wg,nee,OQe,VQe,Bk,XQe,zQe,QQe,Ag,see,WQe,HQe,Pk,UQe,JQe,YQe,yg,lee,KQe,ZQe,$k,eWe,oWe,rWe,Lg,iee,tWe,aWe,Ik,nWe,sWe,lWe,xg,dee,iWe,dWe,qk,cWe,fWe,mWe,kg,cee,gWe,hWe,Nk,pWe,_We,uWe,Sg,fee,bWe,vWe,jk,FWe,TWe,MWe,Rg,mee,EWe,CWe,Dk,wWe,AWe,yWe,Bg,gee,LWe,xWe,Gk,kWe,SWe,RWe,Pg,hee,BWe,PWe,Ok,$We,IWe,qWe,$g,pee,NWe,jWe,Vk,DWe,GWe,OWe,Ig,_ee,VWe,XWe,Xk,zWe,QWe,WWe,qg,uee,HWe,UWe,zk,JWe,YWe,KWe,Ng,bee,ZWe,eHe,Qk,oHe,rHe,tHe,jg,vee,aHe,nHe,Wk,sHe,lHe,iHe,Dg,Fee,dHe,cHe,Hk,fHe,mHe,gHe,Gg,Tee,hHe,pHe,Uk,_He,uHe,bHe,Og,Mee,vHe,FHe,Jk,THe,MHe,EHe,Vg,Eee,CHe,wHe,Yk,AHe,yHe,LHe,Xg,Cee,xHe,kHe,Kk,SHe,RHe,BHe,zg,wee,PHe,$He,Zk,IHe,qHe,NHe,Qg,Aee,jHe,DHe,eS,GHe,OHe,VHe,Wg,yee,XHe,zHe,oS,QHe,WHe,HHe,Lee,UHe,JHe,c3,YHe,Hg,f3,KHe,xee,ZHe,jPe,rd,Ug,kee,m3,eUe,See,oUe,DPe,Wo,g3,rUe,h3,tUe,rS,aUe,nUe,sUe,p3,lUe,Ree,iUe,dUe,cUe,ho,_3,fUe,Bee,mUe,gUe,Oa,hUe,Pee,pUe,_Ue,$ee,uUe,bUe,Iee,vUe,FUe,TUe,E,Wn,qee,MUe,EUe,tS,CUe,wUe,aS,AUe,yUe,LUe,Hn,Nee,xUe,kUe,nS,SUe,RUe,sS,BUe,PUe,$Ue,Un,jee,IUe,qUe,lS,NUe,jUe,iS,DUe,GUe,OUe,Jg,Dee,VUe,XUe,dS,zUe,QUe,WUe,Jn,Gee,HUe,UUe,cS,JUe,YUe,fS,KUe,ZUe,eJe,Yg,Oee,oJe,rJe,mS,tJe,aJe,nJe,Kg,Vee,sJe,lJe,gS,iJe,dJe,cJe,Zg,Xee,fJe,mJe,hS,gJe,hJe,pJe,Yn,zee,_Je,uJe,pS,bJe,vJe,_S,FJe,TJe,MJe,Kn,Qee,EJe,CJe,uS,wJe,AJe,bS,yJe,LJe,xJe,Zn,Wee,kJe,SJe,vS,RJe,BJe,FS,PJe,$Je,IJe,eh,Hee,qJe,NJe,TS,jJe,DJe,GJe,oh,Uee,OJe,VJe,MS,XJe,zJe,QJe,es,Jee,WJe,HJe,ES,UJe,JJe,CS,YJe,KJe,ZJe,rh,Yee,eYe,oYe,wS,rYe,tYe,aYe,os,Kee,nYe,sYe,AS,lYe,iYe,yS,dYe,cYe,fYe,rs,Zee,mYe,gYe,LS,hYe,pYe,xS,_Ye,uYe,bYe,ts,eoe,vYe,FYe,kS,TYe,MYe,ooe,EYe,CYe,wYe,th,roe,AYe,yYe,SS,LYe,xYe,kYe,as,toe,SYe,RYe,RS,BYe,PYe,BS,$Ye,IYe,qYe,ns,aoe,NYe,jYe,PS,DYe,GYe,$S,OYe,VYe,XYe,ss,noe,zYe,QYe,IS,WYe,HYe,qS,UYe,JYe,YYe,ls,soe,KYe,ZYe,NS,eKe,oKe,jS,rKe,tKe,aKe,is,loe,nKe,sKe,DS,lKe,iKe,GS,dKe,cKe,fKe,ds,ioe,mKe,gKe,OS,hKe,pKe,VS,_Ke,uKe,bKe,ah,doe,vKe,FKe,XS,TKe,MKe,EKe,cs,coe,CKe,wKe,zS,AKe,yKe,QS,LKe,xKe,kKe,nh,foe,SKe,RKe,WS,BKe,PKe,$Ke,fs,moe,IKe,qKe,HS,NKe,jKe,US,DKe,GKe,OKe,ms,goe,VKe,XKe,JS,zKe,QKe,YS,WKe,HKe,UKe,gs,hoe,JKe,YKe,KS,KKe,ZKe,ZS,eZe,oZe,rZe,hs,poe,tZe,aZe,eR,nZe,sZe,oR,lZe,iZe,dZe,ps,_oe,cZe,fZe,rR,mZe,gZe,tR,hZe,pZe,_Ze,sh,uoe,uZe,bZe,aR,vZe,FZe,TZe,_s,boe,MZe,EZe,nR,CZe,wZe,sR,AZe,yZe,LZe,us,voe,xZe,kZe,lR,SZe,RZe,iR,BZe,PZe,$Ze,bs,Foe,IZe,qZe,dR,NZe,jZe,cR,DZe,GZe,OZe,vs,Toe,VZe,XZe,fR,zZe,QZe,mR,WZe,HZe,UZe,Fs,Moe,JZe,YZe,gR,KZe,ZZe,hR,eeo,oeo,reo,Ts,Eoe,teo,aeo,pR,neo,seo,_R,leo,ieo,deo,Ms,Coe,ceo,feo,uR,meo,geo,bR,heo,peo,_eo,lh,woe,ueo,beo,vR,veo,Feo,Teo,Es,Aoe,Meo,Eeo,FR,Ceo,weo,TR,Aeo,yeo,Leo,ih,yoe,xeo,keo,MR,Seo,Reo,Beo,dh,Loe,Peo,$eo,ER,Ieo,qeo,Neo,Cs,xoe,jeo,Deo,CR,Geo,Oeo,wR,Veo,Xeo,zeo,ws,koe,Qeo,Weo,AR,Heo,Ueo,yR,Jeo,Yeo,Keo,As,Soe,Zeo,eoo,LR,ooo,roo,xR,too,aoo,noo,ch,Roe,soo,loo,kR,ioo,doo,coo,ys,Boe,foo,moo,SR,goo,hoo,RR,poo,_oo,uoo,Ls,Poe,boo,voo,BR,Foo,Too,PR,Moo,Eoo,Coo,xs,$oe,woo,Aoo,$R,yoo,Loo,IR,xoo,koo,Soo,ks,Ioe,Roo,Boo,qR,Poo,$oo,NR,Ioo,qoo,Noo,Ss,qoe,joo,Doo,jR,Goo,Ooo,DR,Voo,Xoo,zoo,Rs,Noe,Qoo,Woo,GR,Hoo,Uoo,OR,Joo,Yoo,Koo,fh,joe,Zoo,ero,VR,oro,rro,tro,mh,Doe,aro,nro,XR,sro,lro,iro,gh,Goe,dro,cro,zR,fro,mro,gro,hh,Ooe,hro,pro,QR,_ro,uro,bro,Bs,Voe,vro,Fro,WR,Tro,Mro,HR,Ero,Cro,wro,ph,Xoe,Aro,yro,UR,Lro,xro,kro,Ps,zoe,Sro,Rro,JR,Bro,Pro,YR,$ro,Iro,qro,$s,Qoe,Nro,jro,KR,Dro,Gro,ZR,Oro,Vro,Xro,Is,Woe,zro,Qro,eB,Wro,Hro,oB,Uro,Jro,Yro,qs,Hoe,Kro,Zro,rB,eto,oto,tB,rto,tto,ato,Ns,Uoe,nto,sto,aB,lto,ito,nB,dto,cto,fto,js,Joe,mto,gto,sB,hto,pto,lB,_to,uto,bto,_h,Yoe,vto,Fto,iB,Tto,Mto,Eto,uh,Koe,Cto,wto,dB,Ato,yto,Lto,Ds,Zoe,xto,kto,cB,Sto,Rto,fB,Bto,Pto,$to,Gs,ere,Ito,qto,mB,Nto,jto,gB,Dto,Gto,Oto,Os,ore,Vto,Xto,hB,zto,Qto,pB,Wto,Hto,Uto,bh,rre,Jto,Yto,_B,Kto,Zto,eao,vh,tre,oao,rao,uB,tao,aao,nao,Fh,are,sao,lao,bB,iao,dao,cao,Vs,nre,fao,mao,vB,gao,hao,FB,pao,_ao,uao,Th,sre,bao,vao,TB,Fao,Tao,Mao,Mh,lre,Eao,Cao,MB,wao,Aao,yao,Xs,ire,Lao,xao,EB,kao,Sao,CB,Rao,Bao,Pao,Eh,dre,$ao,Iao,wB,qao,Nao,jao,Ch,cre,Dao,Gao,AB,Oao,Vao,Xao,zs,fre,zao,Qao,yB,Wao,Hao,LB,Uao,Jao,Yao,Qs,mre,Kao,Zao,xB,eno,ono,kB,rno,tno,ano,Ws,gre,nno,sno,SB,lno,ino,RB,dno,cno,fno,Hs,hre,mno,gno,BB,hno,pno,PB,_no,uno,bno,pre,vno,Fno,u3,Tno,wh,b3,Mno,_re,Eno,GPe,td,Ah,ure,v3,Cno,bre,wno,OPe,Ho,F3,Ano,T3,yno,$B,Lno,xno,kno,M3,Sno,vre,Rno,Bno,Pno,qe,E3,$no,Fre,Ino,qno,Va,Nno,Tre,jno,Dno,Mre,Gno,Ono,Ere,Vno,Xno,zno,H,yh,Cre,Qno,Wno,IB,Hno,Uno,Jno,Lh,wre,Yno,Kno,qB,Zno,eso,oso,xh,Are,rso,tso,NB,aso,nso,sso,kh,yre,lso,iso,jB,dso,cso,fso,Sh,Lre,mso,gso,DB,hso,pso,_so,Rh,xre,uso,bso,GB,vso,Fso,Tso,Bh,kre,Mso,Eso,OB,Cso,wso,Aso,Ph,Sre,yso,Lso,VB,xso,kso,Sso,$h,Rre,Rso,Bso,XB,Pso,$so,Iso,Ih,Bre,qso,Nso,zB,jso,Dso,Gso,qh,Pre,Oso,Vso,QB,Xso,zso,Qso,Nh,$re,Wso,Hso,WB,Uso,Jso,Yso,jh,Ire,Kso,Zso,HB,elo,olo,rlo,Dh,qre,tlo,alo,UB,nlo,slo,llo,Gh,Nre,ilo,dlo,JB,clo,flo,mlo,Oh,jre,glo,hlo,YB,plo,_lo,ulo,Vh,Dre,blo,vlo,KB,Flo,Tlo,Mlo,Xh,Gre,Elo,Clo,ZB,wlo,Alo,ylo,zh,Ore,Llo,xlo,eP,klo,Slo,Rlo,Qh,Vre,Blo,Plo,oP,$lo,Ilo,qlo,Wh,Xre,Nlo,jlo,rP,Dlo,Glo,Olo,Hh,zre,Vlo,Xlo,tP,zlo,Qlo,Wlo,Uh,Qre,Hlo,Ulo,aP,Jlo,Ylo,Klo,Jh,Zlo,Wre,eio,oio,C3,rio,Yh,w3,tio,Hre,aio,VPe,ad,Kh,Ure,A3,nio,Jre,sio,XPe,Uo,y3,lio,L3,iio,nP,dio,cio,fio,x3,mio,Yre,gio,hio,pio,Ne,k3,_io,Kre,uio,bio,nd,vio,Zre,Fio,Tio,ete,Mio,Eio,Cio,de,Zh,ote,wio,Aio,sP,yio,Lio,xio,ep,rte,kio,Sio,lP,Rio,Bio,Pio,op,tte,$io,Iio,iP,qio,Nio,jio,rp,ate,Dio,Gio,dP,Oio,Vio,Xio,tp,nte,zio,Qio,cP,Wio,Hio,Uio,ap,ste,Jio,Yio,fP,Kio,Zio,edo,np,lte,odo,rdo,mP,tdo,ado,ndo,sp,ite,sdo,ldo,gP,ido,ddo,cdo,lp,dte,fdo,mdo,hP,gdo,hdo,pdo,ip,cte,_do,udo,pP,bdo,vdo,Fdo,dp,fte,Tdo,Mdo,_P,Edo,Cdo,wdo,cp,mte,Ado,ydo,uP,Ldo,xdo,kdo,fp,gte,Sdo,Rdo,bP,Bdo,Pdo,$do,mp,hte,Ido,qdo,vP,Ndo,jdo,Ddo,gp,Gdo,pte,Odo,Vdo,S3,Xdo,hp,R3,zdo,_te,Qdo,zPe,sd,pp,ute,B3,Wdo,bte,Hdo,QPe,Jo,P3,Udo,ld,Jdo,FP,Ydo,Kdo,TP,Zdo,eco,oco,$3,rco,vte,tco,aco,nco,Xr,I3,sco,Fte,lco,ico,id,dco,Tte,cco,fco,MP,mco,gco,hco,Mte,pco,_co,q3,uco,je,N3,bco,Ete,vco,Fco,Xa,Tco,Cte,Mco,Eco,wte,Cco,wco,Ate,Aco,yco,Lco,T,_p,yte,xco,kco,EP,Sco,Rco,Bco,up,Lte,Pco,$co,CP,Ico,qco,Nco,bp,xte,jco,Dco,wP,Gco,Oco,Vco,vp,kte,Xco,zco,AP,Qco,Wco,Hco,Fp,Ste,Uco,Jco,yP,Yco,Kco,Zco,Tp,Rte,efo,ofo,LP,rfo,tfo,afo,Mp,Bte,nfo,sfo,xP,lfo,ifo,dfo,Ep,Pte,cfo,ffo,kP,mfo,gfo,hfo,Cp,$te,pfo,_fo,SP,ufo,bfo,vfo,wp,Ite,Ffo,Tfo,RP,Mfo,Efo,Cfo,Ap,qte,wfo,Afo,BP,yfo,Lfo,xfo,yp,Nte,kfo,Sfo,PP,Rfo,Bfo,Pfo,Lp,jte,$fo,Ifo,$P,qfo,Nfo,jfo,xp,Dte,Dfo,Gfo,IP,Ofo,Vfo,Xfo,kp,Gte,zfo,Qfo,qP,Wfo,Hfo,Ufo,Sp,Ote,Jfo,Yfo,NP,Kfo,Zfo,emo,Rp,Vte,omo,rmo,jP,tmo,amo,nmo,Bp,Xte,smo,lmo,DP,imo,dmo,cmo,Pp,zte,fmo,mmo,GP,gmo,hmo,pmo,$p,Qte,_mo,umo,OP,bmo,vmo,Fmo,Ip,Wte,Tmo,Mmo,VP,Emo,Cmo,wmo,qp,Hte,Amo,ymo,XP,Lmo,xmo,kmo,Np,Ute,Smo,Rmo,zP,Bmo,Pmo,$mo,jp,Jte,Imo,qmo,QP,Nmo,jmo,Dmo,Dp,Yte,Gmo,Omo,WP,Vmo,Xmo,zmo,Gp,Kte,Qmo,Wmo,HP,Hmo,Umo,Jmo,Op,Zte,Ymo,Kmo,UP,Zmo,ego,ogo,Vp,eae,rgo,tgo,JP,ago,ngo,sgo,Xp,oae,lgo,igo,YP,dgo,cgo,fgo,zp,rae,mgo,ggo,KP,hgo,pgo,_go,Us,tae,ugo,bgo,ZP,vgo,Fgo,e$,Tgo,Mgo,Ego,Qp,aae,Cgo,wgo,o$,Ago,ygo,Lgo,Wp,nae,xgo,kgo,r$,Sgo,Rgo,Bgo,Hp,sae,Pgo,$go,t$,Igo,qgo,Ngo,Up,lae,jgo,Dgo,a$,Ggo,Ogo,Vgo,Jp,iae,Xgo,zgo,n$,Qgo,Wgo,Hgo,Yp,dae,Ugo,Jgo,s$,Ygo,Kgo,Zgo,Kp,cae,eho,oho,l$,rho,tho,aho,Zp,fae,nho,sho,i$,lho,iho,dho,e_,mae,cho,fho,d$,mho,gho,hho,o_,gae,pho,_ho,c$,uho,bho,vho,r_,hae,Fho,Tho,f$,Mho,Eho,Cho,t_,pae,who,Aho,m$,yho,Lho,xho,a_,_ae,kho,Sho,g$,Rho,Bho,Pho,n_,uae,$ho,Iho,h$,qho,Nho,jho,s_,bae,Dho,Gho,p$,Oho,Vho,Xho,l_,vae,zho,Qho,_$,Who,Hho,Uho,i_,Fae,Jho,Yho,u$,Kho,Zho,epo,d_,Tae,opo,rpo,b$,tpo,apo,npo,c_,Mae,spo,lpo,v$,ipo,dpo,cpo,f_,Eae,fpo,mpo,F$,gpo,hpo,ppo,m_,Cae,_po,upo,T$,bpo,vpo,Fpo,g_,wae,Tpo,Mpo,M$,Epo,Cpo,wpo,h_,Aae,Apo,ypo,E$,Lpo,xpo,kpo,p_,yae,Spo,Rpo,C$,Bpo,Ppo,$po,__,Lae,Ipo,qpo,w$,Npo,jpo,Dpo,u_,xae,Gpo,Opo,A$,Vpo,Xpo,zpo,b_,kae,Qpo,Wpo,y$,Hpo,Upo,Jpo,v_,Sae,Ypo,Kpo,L$,Zpo,e_o,o_o,F_,Rae,r_o,t_o,x$,a_o,n_o,s_o,T_,Bae,l_o,i_o,k$,d_o,c_o,f_o,M_,Pae,m_o,g_o,S$,h_o,p_o,__o,E_,$ae,u_o,b_o,R$,v_o,F_o,T_o,C_,Iae,M_o,E_o,B$,C_o,w_o,A_o,w_,qae,y_o,L_o,P$,x_o,k_o,S_o,A_,Nae,R_o,B_o,$$,P_o,$_o,I_o,y_,jae,q_o,N_o,I$,j_o,D_o,G_o,L_,Dae,O_o,V_o,q$,X_o,z_o,Q_o,x_,Gae,W_o,H_o,N$,U_o,J_o,Y_o,k_,Oae,K_o,Z_o,j$,euo,ouo,ruo,S_,Vae,tuo,auo,D$,nuo,suo,luo,R_,Xae,iuo,duo,G$,cuo,fuo,muo,B_,zae,guo,huo,O$,puo,_uo,uuo,P_,Qae,buo,vuo,V$,Fuo,Tuo,Muo,$_,Wae,Euo,Cuo,X$,wuo,Auo,yuo,I_,Hae,Luo,xuo,z$,kuo,Suo,Ruo,q_,Uae,Buo,Puo,Q$,$uo,Iuo,quo,N_,Jae,Nuo,juo,W$,Duo,Guo,Ouo,j_,Yae,Vuo,Xuo,H$,zuo,Quo,Wuo,D_,Kae,Huo,Uuo,U$,Juo,Yuo,Kuo,G_,Zae,Zuo,e2o,J$,o2o,r2o,t2o,O_,ene,a2o,n2o,Y$,s2o,l2o,i2o,V_,one,d2o,c2o,K$,f2o,m2o,g2o,X_,rne,h2o,p2o,Z$,_2o,u2o,b2o,z_,tne,v2o,F2o,eI,T2o,M2o,E2o,Q_,ane,C2o,w2o,oI,A2o,y2o,L2o,W_,nne,x2o,k2o,rI,S2o,R2o,B2o,H_,sne,P2o,$2o,tI,I2o,q2o,N2o,U_,lne,j2o,D2o,aI,G2o,O2o,V2o,J_,ine,X2o,z2o,nI,Q2o,W2o,H2o,Y_,dne,U2o,J2o,sI,Y2o,K2o,Z2o,K_,cne,e1o,o1o,lI,r1o,t1o,a1o,Z_,fne,n1o,s1o,iI,l1o,i1o,d1o,eu,mne,c1o,f1o,dI,m1o,g1o,h1o,ou,gne,p1o,_1o,cI,u1o,b1o,v1o,ru,F1o,hne,T1o,M1o,pne,E1o,C1o,_ne,w1o,A1o,j3,WPe,dd,tu,une,D3,y1o,bne,L1o,HPe,Yo,G3,x1o,cd,k1o,fI,S1o,R1o,mI,B1o,P1o,$1o,O3,I1o,vne,q1o,N1o,j1o,zr,V3,D1o,Fne,G1o,O1o,fd,V1o,Tne,X1o,z1o,gI,Q1o,W1o,H1o,Mne,U1o,J1o,X3,Y1o,De,z3,K1o,Ene,Z1o,ebo,za,obo,Cne,rbo,tbo,wne,abo,nbo,Ane,sbo,lbo,ibo,S,au,yne,dbo,cbo,hI,fbo,mbo,gbo,nu,Lne,hbo,pbo,pI,_bo,ubo,bbo,su,xne,vbo,Fbo,_I,Tbo,Mbo,Ebo,lu,kne,Cbo,wbo,uI,Abo,ybo,Lbo,iu,Sne,xbo,kbo,bI,Sbo,Rbo,Bbo,du,Rne,Pbo,$bo,vI,Ibo,qbo,Nbo,cu,Bne,jbo,Dbo,FI,Gbo,Obo,Vbo,fu,Pne,Xbo,zbo,TI,Qbo,Wbo,Hbo,mu,$ne,Ubo,Jbo,MI,Ybo,Kbo,Zbo,gu,Ine,e6o,o6o,EI,r6o,t6o,a6o,hu,qne,n6o,s6o,CI,l6o,i6o,d6o,pu,Nne,c6o,f6o,wI,m6o,g6o,h6o,_u,jne,p6o,_6o,AI,u6o,b6o,v6o,uu,Dne,F6o,T6o,yI,M6o,E6o,C6o,bu,Gne,w6o,A6o,LI,y6o,L6o,x6o,vu,One,k6o,S6o,xI,R6o,B6o,P6o,Fu,Vne,$6o,I6o,kI,q6o,N6o,j6o,Tu,Xne,D6o,G6o,SI,O6o,V6o,X6o,Mu,zne,z6o,Q6o,RI,W6o,H6o,U6o,Eu,Qne,J6o,Y6o,BI,K6o,Z6o,evo,Cu,Wne,ovo,rvo,PI,tvo,avo,nvo,wu,Hne,svo,lvo,$I,ivo,dvo,cvo,Au,Une,fvo,mvo,II,gvo,hvo,pvo,yu,Jne,_vo,uvo,qI,bvo,vvo,Fvo,Lu,Yne,Tvo,Mvo,NI,Evo,Cvo,wvo,xu,Kne,Avo,yvo,jI,Lvo,xvo,kvo,ku,Zne,Svo,Rvo,DI,Bvo,Pvo,$vo,Su,ese,Ivo,qvo,GI,Nvo,jvo,Dvo,Ru,ose,Gvo,Ovo,OI,Vvo,Xvo,zvo,Bu,rse,Qvo,Wvo,VI,Hvo,Uvo,Jvo,Pu,tse,Yvo,Kvo,XI,Zvo,eFo,oFo,$u,ase,rFo,tFo,zI,aFo,nFo,sFo,Iu,nse,lFo,iFo,QI,dFo,cFo,fFo,qu,sse,mFo,gFo,WI,hFo,pFo,_Fo,Nu,lse,uFo,bFo,HI,vFo,FFo,TFo,ju,ise,MFo,EFo,UI,CFo,wFo,AFo,Du,dse,yFo,LFo,JI,xFo,kFo,SFo,Gu,cse,RFo,BFo,YI,PFo,$Fo,IFo,Ou,fse,qFo,NFo,KI,jFo,DFo,GFo,Vu,mse,OFo,VFo,ZI,XFo,zFo,QFo,Xu,WFo,gse,HFo,UFo,hse,JFo,YFo,pse,KFo,ZFo,Q3,UPe,md,zu,_se,W3,eTo,use,oTo,JPe,Ko,H3,rTo,gd,tTo,eq,aTo,nTo,oq,sTo,lTo,iTo,U3,dTo,bse,cTo,fTo,mTo,Qr,J3,gTo,vse,hTo,pTo,hd,_To,Fse,uTo,bTo,rq,vTo,FTo,TTo,Tse,MTo,ETo,Y3,CTo,Ge,K3,wTo,Mse,ATo,yTo,Qa,LTo,Ese,xTo,kTo,Cse,STo,RTo,wse,BTo,PTo,$To,$,Qu,Ase,ITo,qTo,tq,NTo,jTo,DTo,Wu,yse,GTo,OTo,aq,VTo,XTo,zTo,Hu,Lse,QTo,WTo,nq,HTo,UTo,JTo,Uu,xse,YTo,KTo,sq,ZTo,e7o,o7o,Ju,kse,r7o,t7o,lq,a7o,n7o,s7o,Yu,Sse,l7o,i7o,iq,d7o,c7o,f7o,Ku,Rse,m7o,g7o,dq,h7o,p7o,_7o,Zu,Bse,u7o,b7o,cq,v7o,F7o,T7o,e2,Pse,M7o,E7o,fq,C7o,w7o,A7o,o2,$se,y7o,L7o,mq,x7o,k7o,S7o,r2,Ise,R7o,B7o,gq,P7o,$7o,I7o,t2,qse,q7o,N7o,hq,j7o,D7o,G7o,a2,Nse,O7o,V7o,pq,X7o,z7o,Q7o,n2,jse,W7o,H7o,_q,U7o,J7o,Y7o,s2,Dse,K7o,Z7o,uq,e9o,o9o,r9o,l2,Gse,t9o,a9o,bq,n9o,s9o,l9o,i2,Ose,i9o,d9o,vq,c9o,f9o,m9o,d2,Vse,g9o,h9o,Fq,p9o,_9o,u9o,c2,Xse,b9o,v9o,Tq,F9o,T9o,M9o,f2,zse,E9o,C9o,Mq,w9o,A9o,y9o,m2,Qse,L9o,x9o,Eq,k9o,S9o,R9o,g2,Wse,B9o,P9o,Cq,$9o,I9o,q9o,h2,Hse,N9o,j9o,wq,D9o,G9o,O9o,p2,Use,V9o,X9o,Aq,z9o,Q9o,W9o,_2,Jse,H9o,U9o,yq,J9o,Y9o,K9o,u2,Yse,Z9o,eMo,Lq,oMo,rMo,tMo,b2,Kse,aMo,nMo,xq,sMo,lMo,iMo,v2,Zse,dMo,cMo,kq,fMo,mMo,gMo,F2,ele,hMo,pMo,Sq,_Mo,uMo,bMo,T2,ole,vMo,FMo,Rq,TMo,MMo,EMo,M2,rle,CMo,wMo,Bq,AMo,yMo,LMo,E2,tle,xMo,kMo,Pq,SMo,RMo,BMo,C2,ale,PMo,$Mo,$q,IMo,qMo,NMo,w2,nle,jMo,DMo,Iq,GMo,OMo,VMo,A2,sle,XMo,zMo,qq,QMo,WMo,HMo,y2,UMo,lle,JMo,YMo,ile,KMo,ZMo,dle,e4o,o4o,Z3,YPe,pd,L2,cle,eC,r4o,fle,t4o,KPe,Zo,oC,a4o,_d,n4o,Nq,s4o,l4o,jq,i4o,d4o,c4o,rC,f4o,mle,m4o,g4o,h4o,Wr,tC,p4o,gle,_4o,u4o,ud,b4o,hle,v4o,F4o,Dq,T4o,M4o,E4o,ple,C4o,w4o,aC,A4o,Oe,nC,y4o,_le,L4o,x4o,Wa,k4o,ule,S4o,R4o,ble,B4o,P4o,vle,$4o,I4o,q4o,I,x2,Fle,N4o,j4o,Gq,D4o,G4o,O4o,k2,Tle,V4o,X4o,Oq,z4o,Q4o,W4o,S2,Mle,H4o,U4o,Vq,J4o,Y4o,K4o,R2,Ele,Z4o,eEo,Xq,oEo,rEo,tEo,B2,Cle,aEo,nEo,zq,sEo,lEo,iEo,P2,wle,dEo,cEo,Qq,fEo,mEo,gEo,$2,Ale,hEo,pEo,Wq,_Eo,uEo,bEo,I2,yle,vEo,FEo,Hq,TEo,MEo,EEo,q2,Lle,CEo,wEo,Uq,AEo,yEo,LEo,N2,xle,xEo,kEo,Jq,SEo,REo,BEo,j2,kle,PEo,$Eo,Yq,IEo,qEo,NEo,D2,Sle,jEo,DEo,Kq,GEo,OEo,VEo,G2,Rle,XEo,zEo,Zq,QEo,WEo,HEo,O2,Ble,UEo,JEo,eN,YEo,KEo,ZEo,V2,Ple,e5o,o5o,oN,r5o,t5o,a5o,X2,$le,n5o,s5o,rN,l5o,i5o,d5o,z2,Ile,c5o,f5o,tN,m5o,g5o,h5o,Q2,qle,p5o,_5o,aN,u5o,b5o,v5o,W2,Nle,F5o,T5o,nN,M5o,E5o,C5o,H2,jle,w5o,A5o,sN,y5o,L5o,x5o,U2,Dle,k5o,S5o,lN,R5o,B5o,P5o,J2,Gle,$5o,I5o,iN,q5o,N5o,j5o,Y2,Ole,D5o,G5o,dN,O5o,V5o,X5o,K2,Vle,z5o,Q5o,cN,W5o,H5o,U5o,Z2,Xle,J5o,Y5o,fN,K5o,Z5o,e3o,e1,zle,o3o,r3o,mN,t3o,a3o,n3o,o1,Qle,s3o,l3o,gN,i3o,d3o,c3o,r1,Wle,f3o,m3o,hN,g3o,h3o,p3o,t1,Hle,_3o,u3o,pN,b3o,v3o,F3o,a1,Ule,T3o,M3o,_N,E3o,C3o,w3o,n1,Jle,A3o,y3o,Yle,L3o,x3o,k3o,s1,Kle,S3o,R3o,uN,B3o,P3o,$3o,l1,Zle,I3o,q3o,bN,N3o,j3o,D3o,i1,eie,G3o,O3o,vN,V3o,X3o,z3o,d1,oie,Q3o,W3o,FN,H3o,U3o,J3o,c1,Y3o,rie,K3o,Z3o,tie,eCo,oCo,aie,rCo,tCo,sC,ZPe,bd,f1,nie,lC,aCo,sie,nCo,e$e,er,iC,sCo,vd,lCo,TN,iCo,dCo,MN,cCo,fCo,mCo,dC,gCo,lie,hCo,pCo,_Co,Hr,cC,uCo,iie,bCo,vCo,Fd,FCo,die,TCo,MCo,EN,ECo,CCo,wCo,cie,ACo,yCo,fC,LCo,Ve,mC,xCo,fie,kCo,SCo,Ha,RCo,mie,BCo,PCo,gie,$Co,ICo,hie,qCo,NCo,jCo,ne,m1,pie,DCo,GCo,CN,OCo,VCo,XCo,g1,_ie,zCo,QCo,wN,WCo,HCo,UCo,h1,uie,JCo,YCo,AN,KCo,ZCo,ewo,p1,bie,owo,rwo,yN,two,awo,nwo,_1,vie,swo,lwo,LN,iwo,dwo,cwo,u1,Fie,fwo,mwo,xN,gwo,hwo,pwo,b1,Tie,_wo,uwo,kN,bwo,vwo,Fwo,v1,Mie,Two,Mwo,SN,Ewo,Cwo,wwo,F1,Eie,Awo,ywo,RN,Lwo,xwo,kwo,T1,Cie,Swo,Rwo,BN,Bwo,Pwo,$wo,M1,wie,Iwo,qwo,PN,Nwo,jwo,Dwo,E1,Aie,Gwo,Owo,$N,Vwo,Xwo,zwo,C1,yie,Qwo,Wwo,IN,Hwo,Uwo,Jwo,w1,Lie,Ywo,Kwo,qN,Zwo,e0o,o0o,A1,xie,r0o,t0o,NN,a0o,n0o,s0o,y1,kie,l0o,i0o,jN,d0o,c0o,f0o,L1,Sie,m0o,g0o,DN,h0o,p0o,_0o,x1,Rie,u0o,b0o,GN,v0o,F0o,T0o,k1,M0o,Bie,E0o,C0o,Pie,w0o,A0o,$ie,y0o,L0o,gC,o$e,Td,S1,Iie,hC,x0o,qie,k0o,r$e,or,pC,S0o,Md,R0o,ON,B0o,P0o,VN,$0o,I0o,q0o,_C,N0o,Nie,j0o,D0o,G0o,Ur,uC,O0o,jie,V0o,X0o,Ed,z0o,Die,Q0o,W0o,XN,H0o,U0o,J0o,Gie,Y0o,K0o,bC,Z0o,Xe,vC,eAo,Oie,oAo,rAo,Ua,tAo,Vie,aAo,nAo,Xie,sAo,lAo,zie,iAo,dAo,cAo,y,R1,Qie,fAo,mAo,zN,gAo,hAo,pAo,B1,Wie,_Ao,uAo,QN,bAo,vAo,FAo,P1,Hie,TAo,MAo,WN,EAo,CAo,wAo,$1,Uie,AAo,yAo,HN,LAo,xAo,kAo,I1,Jie,SAo,RAo,UN,BAo,PAo,$Ao,q1,Yie,IAo,qAo,JN,NAo,jAo,DAo,N1,Kie,GAo,OAo,YN,VAo,XAo,zAo,j1,Zie,QAo,WAo,KN,HAo,UAo,JAo,D1,ede,YAo,KAo,ZN,ZAo,eyo,oyo,G1,ode,ryo,tyo,ej,ayo,nyo,syo,O1,rde,lyo,iyo,oj,dyo,cyo,fyo,V1,tde,myo,gyo,rj,hyo,pyo,_yo,X1,ade,uyo,byo,tj,vyo,Fyo,Tyo,z1,nde,Myo,Eyo,aj,Cyo,wyo,Ayo,Q1,sde,yyo,Lyo,nj,xyo,kyo,Syo,W1,lde,Ryo,Byo,sj,Pyo,$yo,Iyo,H1,ide,qyo,Nyo,lj,jyo,Dyo,Gyo,U1,dde,Oyo,Vyo,ij,Xyo,zyo,Qyo,J1,cde,Wyo,Hyo,dj,Uyo,Jyo,Yyo,Y1,fde,Kyo,Zyo,cj,eLo,oLo,rLo,K1,mde,tLo,aLo,fj,nLo,sLo,lLo,Z1,gde,iLo,dLo,mj,cLo,fLo,mLo,eb,hde,gLo,hLo,gj,pLo,_Lo,uLo,ob,pde,bLo,vLo,hj,FLo,TLo,MLo,rb,_de,ELo,CLo,pj,wLo,ALo,yLo,tb,ude,LLo,xLo,_j,kLo,SLo,RLo,ab,bde,BLo,PLo,uj,$Lo,ILo,qLo,nb,vde,NLo,jLo,bj,DLo,GLo,OLo,sb,Fde,VLo,XLo,vj,zLo,QLo,WLo,lb,Tde,HLo,ULo,Fj,JLo,YLo,KLo,ib,Mde,ZLo,e8o,Tj,o8o,r8o,t8o,db,Ede,a8o,n8o,Mj,s8o,l8o,i8o,cb,Cde,d8o,c8o,Ej,f8o,m8o,g8o,fb,wde,h8o,p8o,Cj,_8o,u8o,b8o,mb,Ade,v8o,F8o,wj,T8o,M8o,E8o,gb,yde,C8o,w8o,Aj,A8o,y8o,L8o,hb,Lde,x8o,k8o,yj,S8o,R8o,B8o,pb,xde,P8o,$8o,Lj,I8o,q8o,N8o,_b,kde,j8o,D8o,xj,G8o,O8o,V8o,ub,Sde,X8o,z8o,kj,Q8o,W8o,H8o,bb,Rde,U8o,J8o,Sj,Y8o,K8o,Z8o,vb,Bde,exo,oxo,Rj,rxo,txo,axo,Fb,Pde,nxo,sxo,Bj,lxo,ixo,dxo,Tb,$de,cxo,fxo,Pj,mxo,gxo,hxo,Mb,Ide,pxo,_xo,$j,uxo,bxo,vxo,Eb,qde,Fxo,Txo,Ij,Mxo,Exo,Cxo,Cb,Nde,wxo,Axo,qj,yxo,Lxo,xxo,wb,kxo,jde,Sxo,Rxo,Dde,Bxo,Pxo,Gde,$xo,Ixo,FC,t$e,Cd,Ab,Ode,TC,qxo,Vde,Nxo,a$e,rr,MC,jxo,wd,Dxo,Nj,Gxo,Oxo,jj,Vxo,Xxo,zxo,EC,Qxo,Xde,Wxo,Hxo,Uxo,Jr,CC,Jxo,zde,Yxo,Kxo,Ad,Zxo,Qde,eko,oko,Dj,rko,tko,ako,Wde,nko,sko,wC,lko,ze,AC,iko,Hde,dko,cko,Ja,fko,Ude,mko,gko,Jde,hko,pko,Yde,_ko,uko,bko,G,yb,Kde,vko,Fko,Gj,Tko,Mko,Eko,Lb,Zde,Cko,wko,Oj,Ako,yko,Lko,xb,ece,xko,kko,Vj,Sko,Rko,Bko,kb,oce,Pko,$ko,Xj,Iko,qko,Nko,Sb,rce,jko,Dko,zj,Gko,Oko,Vko,Rb,tce,Xko,zko,Qj,Qko,Wko,Hko,Bb,ace,Uko,Jko,Wj,Yko,Kko,Zko,Pb,nce,eSo,oSo,Hj,rSo,tSo,aSo,$b,sce,nSo,sSo,Uj,lSo,iSo,dSo,Ib,lce,cSo,fSo,Jj,mSo,gSo,hSo,qb,ice,pSo,_So,Yj,uSo,bSo,vSo,Nb,dce,FSo,TSo,Kj,MSo,ESo,CSo,jb,cce,wSo,ASo,Zj,ySo,LSo,xSo,Db,fce,kSo,SSo,eD,RSo,BSo,PSo,Gb,mce,$So,ISo,oD,qSo,NSo,jSo,Ob,gce,DSo,GSo,rD,OSo,VSo,XSo,Vb,hce,zSo,QSo,tD,WSo,HSo,USo,Xb,pce,JSo,YSo,aD,KSo,ZSo,eRo,zb,_ce,oRo,rRo,nD,tRo,aRo,nRo,Qb,uce,sRo,lRo,sD,iRo,dRo,cRo,Wb,bce,fRo,mRo,lD,gRo,hRo,pRo,Hb,vce,_Ro,uRo,iD,bRo,vRo,FRo,Ub,Fce,TRo,MRo,dD,ERo,CRo,wRo,Jb,Tce,ARo,yRo,cD,LRo,xRo,kRo,Yb,Mce,SRo,RRo,fD,BRo,PRo,$Ro,Kb,Ece,IRo,qRo,mD,NRo,jRo,DRo,Zb,Cce,GRo,ORo,gD,VRo,XRo,zRo,e6,wce,QRo,WRo,hD,HRo,URo,JRo,o6,YRo,Ace,KRo,ZRo,yce,eBo,oBo,Lce,rBo,tBo,yC,n$e,yd,r6,xce,LC,aBo,kce,nBo,s$e,tr,xC,sBo,Ld,lBo,pD,iBo,dBo,_D,cBo,fBo,mBo,kC,gBo,Sce,hBo,pBo,_Bo,Yr,SC,uBo,Rce,bBo,vBo,xd,FBo,Bce,TBo,MBo,uD,EBo,CBo,wBo,Pce,ABo,yBo,RC,LBo,Qe,BC,xBo,$ce,kBo,SBo,Ya,RBo,Ice,BBo,PBo,qce,$Bo,IBo,Nce,qBo,NBo,jBo,da,t6,jce,DBo,GBo,bD,OBo,VBo,XBo,a6,Dce,zBo,QBo,vD,WBo,HBo,UBo,n6,Gce,JBo,YBo,FD,KBo,ZBo,ePo,s6,Oce,oPo,rPo,TD,tPo,aPo,nPo,l6,Vce,sPo,lPo,MD,iPo,dPo,cPo,i6,fPo,Xce,mPo,gPo,zce,hPo,pPo,Qce,_Po,uPo,PC,l$e,kd,d6,Wce,$C,bPo,Hce,vPo,i$e,ar,IC,FPo,Sd,TPo,ED,MPo,EPo,CD,CPo,wPo,APo,qC,yPo,Uce,LPo,xPo,kPo,Kr,NC,SPo,Jce,RPo,BPo,Rd,PPo,Yce,$Po,IPo,wD,qPo,NPo,jPo,Kce,DPo,GPo,jC,OPo,We,DC,VPo,Zce,XPo,zPo,Ka,QPo,efe,WPo,HPo,ofe,UPo,JPo,rfe,YPo,KPo,ZPo,j,c6,tfe,e$o,o$o,AD,r$o,t$o,a$o,f6,afe,n$o,s$o,yD,l$o,i$o,d$o,m6,nfe,c$o,f$o,LD,m$o,g$o,h$o,g6,sfe,p$o,_$o,xD,u$o,b$o,v$o,h6,lfe,F$o,T$o,kD,M$o,E$o,C$o,p6,ife,w$o,A$o,SD,y$o,L$o,x$o,_6,dfe,k$o,S$o,RD,R$o,B$o,P$o,u6,cfe,$$o,I$o,BD,q$o,N$o,j$o,b6,ffe,D$o,G$o,PD,O$o,V$o,X$o,v6,mfe,z$o,Q$o,$D,W$o,H$o,U$o,F6,gfe,J$o,Y$o,ID,K$o,Z$o,eIo,T6,hfe,oIo,rIo,qD,tIo,aIo,nIo,M6,pfe,sIo,lIo,ND,iIo,dIo,cIo,E6,_fe,fIo,mIo,jD,gIo,hIo,pIo,C6,ufe,_Io,uIo,DD,bIo,vIo,FIo,w6,bfe,TIo,MIo,GD,EIo,CIo,wIo,A6,vfe,AIo,yIo,OD,LIo,xIo,kIo,y6,Ffe,SIo,RIo,VD,BIo,PIo,$Io,L6,Tfe,IIo,qIo,XD,NIo,jIo,DIo,x6,Mfe,GIo,OIo,zD,VIo,XIo,zIo,k6,Efe,QIo,WIo,QD,HIo,UIo,JIo,S6,Cfe,YIo,KIo,WD,ZIo,eqo,oqo,R6,wfe,rqo,tqo,HD,aqo,nqo,sqo,B6,Afe,lqo,iqo,UD,dqo,cqo,fqo,P6,yfe,mqo,gqo,JD,hqo,pqo,_qo,$6,Lfe,uqo,bqo,YD,vqo,Fqo,Tqo,I6,xfe,Mqo,Eqo,KD,Cqo,wqo,Aqo,q6,kfe,yqo,Lqo,ZD,xqo,kqo,Sqo,N6,Sfe,Rqo,Bqo,eG,Pqo,$qo,Iqo,j6,Rfe,qqo,Nqo,oG,jqo,Dqo,Gqo,D6,Bfe,Oqo,Vqo,rG,Xqo,zqo,Qqo,G6,Pfe,Wqo,Hqo,tG,Uqo,Jqo,Yqo,O6,$fe,Kqo,Zqo,aG,eNo,oNo,rNo,V6,tNo,Ife,aNo,nNo,qfe,sNo,lNo,Nfe,iNo,dNo,GC,d$e,Bd,X6,jfe,OC,cNo,Dfe,fNo,c$e,nr,VC,mNo,Pd,gNo,nG,hNo,pNo,sG,_No,uNo,bNo,XC,vNo,Gfe,FNo,TNo,MNo,Zr,zC,ENo,Ofe,CNo,wNo,$d,ANo,Vfe,yNo,LNo,lG,xNo,kNo,SNo,Xfe,RNo,BNo,QC,PNo,He,WC,$No,zfe,INo,qNo,Za,NNo,Qfe,jNo,DNo,Wfe,GNo,ONo,Hfe,VNo,XNo,zNo,R,z6,Ufe,QNo,WNo,iG,HNo,UNo,JNo,Q6,Jfe,YNo,KNo,dG,ZNo,ejo,ojo,W6,Yfe,rjo,tjo,cG,ajo,njo,sjo,H6,Kfe,ljo,ijo,fG,djo,cjo,fjo,U6,Zfe,mjo,gjo,mG,hjo,pjo,_jo,J6,eme,ujo,bjo,gG,vjo,Fjo,Tjo,Y6,ome,Mjo,Ejo,hG,Cjo,wjo,Ajo,K6,rme,yjo,Ljo,pG,xjo,kjo,Sjo,Z6,tme,Rjo,Bjo,_G,Pjo,$jo,Ijo,ev,ame,qjo,Njo,uG,jjo,Djo,Gjo,ov,nme,Ojo,Vjo,bG,Xjo,zjo,Qjo,rv,sme,Wjo,Hjo,vG,Ujo,Jjo,Yjo,tv,lme,Kjo,Zjo,FG,eDo,oDo,rDo,av,ime,tDo,aDo,TG,nDo,sDo,lDo,nv,dme,iDo,dDo,MG,cDo,fDo,mDo,sv,cme,gDo,hDo,EG,pDo,_Do,uDo,lv,fme,bDo,vDo,CG,FDo,TDo,MDo,iv,mme,EDo,CDo,wG,wDo,ADo,yDo,dv,gme,LDo,xDo,AG,kDo,SDo,RDo,cv,hme,BDo,PDo,yG,$Do,IDo,qDo,fv,pme,NDo,jDo,LG,DDo,GDo,ODo,mv,_me,VDo,XDo,xG,zDo,QDo,WDo,gv,ume,HDo,UDo,kG,JDo,YDo,KDo,hv,bme,ZDo,eGo,SG,oGo,rGo,tGo,pv,vme,aGo,nGo,RG,sGo,lGo,iGo,_v,Fme,dGo,cGo,BG,fGo,mGo,gGo,uv,Tme,hGo,pGo,PG,_Go,uGo,bGo,bv,Mme,vGo,FGo,$G,TGo,MGo,EGo,vv,Eme,CGo,wGo,IG,AGo,yGo,LGo,Fv,Cme,xGo,kGo,qG,SGo,RGo,BGo,Tv,wme,PGo,$Go,NG,IGo,qGo,NGo,Mv,Ame,jGo,DGo,jG,GGo,OGo,VGo,Ev,yme,XGo,zGo,DG,QGo,WGo,HGo,Cv,Lme,UGo,JGo,GG,YGo,KGo,ZGo,wv,xme,eOo,oOo,OG,rOo,tOo,aOo,Av,kme,nOo,sOo,VG,lOo,iOo,dOo,yv,Sme,cOo,fOo,XG,mOo,gOo,hOo,Lv,Rme,pOo,_Oo,zG,uOo,bOo,vOo,xv,Bme,FOo,TOo,QG,MOo,EOo,COo,kv,wOo,Pme,AOo,yOo,$me,LOo,xOo,Ime,kOo,SOo,HC,f$e,Id,Sv,qme,UC,ROo,Nme,BOo,m$e,sr,JC,POo,qd,$Oo,WG,IOo,qOo,HG,NOo,jOo,DOo,YC,GOo,jme,OOo,VOo,XOo,et,KC,zOo,Dme,QOo,WOo,Nd,HOo,Gme,UOo,JOo,UG,YOo,KOo,ZOo,Ome,eVo,oVo,ZC,rVo,Ue,ew,tVo,Vme,aVo,nVo,en,sVo,Xme,lVo,iVo,zme,dVo,cVo,Qme,fVo,mVo,gVo,Wme,Rv,Hme,hVo,pVo,JG,_Vo,uVo,bVo,Bv,vVo,Ume,FVo,TVo,Jme,MVo,EVo,Yme,CVo,wVo,ow,g$e,jd,Pv,Kme,rw,AVo,Zme,yVo,h$e,lr,tw,LVo,Dd,xVo,YG,kVo,SVo,KG,RVo,BVo,PVo,aw,$Vo,ege,IVo,qVo,NVo,ot,nw,jVo,oge,DVo,GVo,Gd,OVo,rge,VVo,XVo,ZG,zVo,QVo,WVo,tge,HVo,UVo,sw,JVo,Je,lw,YVo,age,KVo,ZVo,on,eXo,nge,oXo,rXo,sge,tXo,aXo,lge,nXo,sXo,lXo,ce,$v,ige,iXo,dXo,eO,cXo,fXo,mXo,Iv,dge,gXo,hXo,oO,pXo,_Xo,uXo,qv,cge,bXo,vXo,rO,FXo,TXo,MXo,Js,fge,EXo,CXo,tO,wXo,AXo,aO,yXo,LXo,xXo,Nv,mge,kXo,SXo,nO,RXo,BXo,PXo,ma,gge,$Xo,IXo,sO,qXo,NXo,lO,jXo,DXo,iO,GXo,OXo,VXo,jv,hge,XXo,zXo,dO,QXo,WXo,HXo,Dv,pge,UXo,JXo,cO,YXo,KXo,ZXo,Gv,_ge,ezo,ozo,fO,rzo,tzo,azo,Ov,uge,nzo,szo,mO,lzo,izo,dzo,Vv,bge,czo,fzo,gO,mzo,gzo,hzo,Xv,vge,pzo,_zo,hO,uzo,bzo,vzo,zv,Fge,Fzo,Tzo,pO,Mzo,Ezo,Czo,Qv,wzo,Tge,Azo,yzo,Mge,Lzo,xzo,Ege,kzo,Szo,iw,p$e,Od,Wv,Cge,dw,Rzo,wge,Bzo,_$e,ir,cw,Pzo,Vd,$zo,_O,Izo,qzo,uO,Nzo,jzo,Dzo,fw,Gzo,Age,Ozo,Vzo,Xzo,rt,mw,zzo,yge,Qzo,Wzo,Xd,Hzo,Lge,Uzo,Jzo,bO,Yzo,Kzo,Zzo,xge,eQo,oQo,gw,rQo,Ye,hw,tQo,kge,aQo,nQo,rn,sQo,Sge,lQo,iQo,Rge,dQo,cQo,Bge,fQo,mQo,gQo,Pge,Hv,$ge,hQo,pQo,vO,_Qo,uQo,bQo,Uv,vQo,Ige,FQo,TQo,qge,MQo,EQo,Nge,CQo,wQo,pw,u$e,zd,Jv,jge,_w,AQo,Dge,yQo,b$e,dr,uw,LQo,Qd,xQo,FO,kQo,SQo,TO,RQo,BQo,PQo,bw,$Qo,Gge,IQo,qQo,NQo,tt,vw,jQo,Oge,DQo,GQo,Wd,OQo,Vge,VQo,XQo,MO,zQo,QQo,WQo,Xge,HQo,UQo,Fw,JQo,Ke,Tw,YQo,zge,KQo,ZQo,tn,eWo,Qge,oWo,rWo,Wge,tWo,aWo,Hge,nWo,sWo,lWo,Be,Yv,Uge,iWo,dWo,EO,cWo,fWo,mWo,Kv,Jge,gWo,hWo,CO,pWo,_Wo,uWo,Zv,Yge,bWo,vWo,wO,FWo,TWo,MWo,eF,Kge,EWo,CWo,AO,wWo,AWo,yWo,oF,Zge,LWo,xWo,yO,kWo,SWo,RWo,rF,ehe,BWo,PWo,LO,$Wo,IWo,qWo,tF,ohe,NWo,jWo,xO,DWo,GWo,OWo,aF,rhe,VWo,XWo,kO,zWo,QWo,WWo,nF,HWo,the,UWo,JWo,ahe,YWo,KWo,nhe,ZWo,eHo,Mw,v$e,Hd,sF,she,Ew,oHo,lhe,rHo,F$e,cr,Cw,tHo,Ud,aHo,SO,nHo,sHo,RO,lHo,iHo,dHo,ww,cHo,ihe,fHo,mHo,gHo,at,Aw,hHo,dhe,pHo,_Ho,Jd,uHo,che,bHo,vHo,BO,FHo,THo,MHo,fhe,EHo,CHo,yw,wHo,Ze,Lw,AHo,mhe,yHo,LHo,an,xHo,ghe,kHo,SHo,hhe,RHo,BHo,phe,PHo,$Ho,IHo,nn,lF,_he,qHo,NHo,PO,jHo,DHo,GHo,iF,uhe,OHo,VHo,$O,XHo,zHo,QHo,dF,bhe,WHo,HHo,IO,UHo,JHo,YHo,cF,vhe,KHo,ZHo,qO,eUo,oUo,rUo,fF,tUo,Fhe,aUo,nUo,The,sUo,lUo,Mhe,iUo,dUo,xw,T$e,Yd,mF,Ehe,kw,cUo,Che,fUo,M$e,fr,Sw,mUo,Kd,gUo,NO,hUo,pUo,jO,_Uo,uUo,bUo,Rw,vUo,whe,FUo,TUo,MUo,nt,Bw,EUo,Ahe,CUo,wUo,Zd,AUo,yhe,yUo,LUo,DO,xUo,kUo,SUo,Lhe,RUo,BUo,Pw,PUo,eo,$w,$Uo,xhe,IUo,qUo,sn,NUo,khe,jUo,DUo,She,GUo,OUo,Rhe,VUo,XUo,zUo,Pe,gF,Bhe,QUo,WUo,GO,HUo,UUo,JUo,hF,Phe,YUo,KUo,OO,ZUo,eJo,oJo,pF,$he,rJo,tJo,VO,aJo,nJo,sJo,_F,Ihe,lJo,iJo,XO,dJo,cJo,fJo,uF,qhe,mJo,gJo,zO,hJo,pJo,_Jo,bF,Nhe,uJo,bJo,QO,vJo,FJo,TJo,vF,jhe,MJo,EJo,WO,CJo,wJo,AJo,FF,Dhe,yJo,LJo,HO,xJo,kJo,SJo,TF,RJo,Ghe,BJo,PJo,Ohe,$Jo,IJo,Vhe,qJo,NJo,Iw,E$e,ec,MF,Xhe,qw,jJo,zhe,DJo,C$e,mr,Nw,GJo,oc,OJo,UO,VJo,XJo,JO,zJo,QJo,WJo,jw,HJo,Qhe,UJo,JJo,YJo,st,Dw,KJo,Whe,ZJo,eYo,rc,oYo,Hhe,rYo,tYo,YO,aYo,nYo,sYo,Uhe,lYo,iYo,Gw,dYo,oo,Ow,cYo,Jhe,fYo,mYo,ln,gYo,Yhe,hYo,pYo,Khe,_Yo,uYo,Zhe,bYo,vYo,FYo,Vw,EF,epe,TYo,MYo,KO,EYo,CYo,wYo,CF,ope,AYo,yYo,ZO,LYo,xYo,kYo,wF,SYo,rpe,RYo,BYo,tpe,PYo,$Yo,ape,IYo,qYo,Xw,w$e,tc,AF,npe,zw,NYo,spe,jYo,A$e,gr,Qw,DYo,ac,GYo,eV,OYo,VYo,oV,XYo,zYo,QYo,Ww,WYo,lpe,HYo,UYo,JYo,lt,Hw,YYo,ipe,KYo,ZYo,nc,eKo,dpe,oKo,rKo,rV,tKo,aKo,nKo,cpe,sKo,lKo,Uw,iKo,ro,Jw,dKo,fpe,cKo,fKo,dn,mKo,mpe,gKo,hKo,gpe,pKo,_Ko,hpe,uKo,bKo,vKo,cn,yF,ppe,FKo,TKo,tV,MKo,EKo,CKo,LF,_pe,wKo,AKo,aV,yKo,LKo,xKo,xF,upe,kKo,SKo,nV,RKo,BKo,PKo,kF,bpe,$Ko,IKo,sV,qKo,NKo,jKo,SF,DKo,vpe,GKo,OKo,Fpe,VKo,XKo,Tpe,zKo,QKo,Yw,y$e,sc,RF,Mpe,Kw,WKo,Epe,HKo,L$e,hr,Zw,UKo,lc,JKo,lV,YKo,KKo,iV,ZKo,eZo,oZo,e0,rZo,Cpe,tZo,aZo,nZo,it,o0,sZo,wpe,lZo,iZo,ic,dZo,Ape,cZo,fZo,dV,mZo,gZo,hZo,ype,pZo,_Zo,r0,uZo,to,t0,bZo,Lpe,vZo,FZo,fn,TZo,xpe,MZo,EZo,kpe,CZo,wZo,Spe,AZo,yZo,LZo,dc,BF,Rpe,xZo,kZo,cV,SZo,RZo,BZo,PF,Bpe,PZo,$Zo,fV,IZo,qZo,NZo,$F,Ppe,jZo,DZo,mV,GZo,OZo,VZo,IF,XZo,$pe,zZo,QZo,Ipe,WZo,HZo,qpe,UZo,JZo,a0,x$e,cc,qF,Npe,n0,YZo,jpe,KZo,k$e,pr,s0,ZZo,fc,eer,gV,oer,rer,hV,ter,aer,ner,l0,ser,Dpe,ler,ier,der,dt,i0,cer,Gpe,fer,mer,mc,ger,Ope,her,per,pV,_er,uer,ber,Vpe,ver,Fer,d0,Ter,ao,c0,Mer,Xpe,Eer,Cer,mn,wer,zpe,Aer,yer,Qpe,Ler,xer,Wpe,ker,Ser,Rer,Hpe,NF,Upe,Ber,Per,_V,$er,Ier,qer,jF,Ner,Jpe,jer,Der,Ype,Ger,Oer,Kpe,Ver,Xer,f0,S$e,gc,DF,Zpe,m0,zer,e_e,Qer,R$e,_r,g0,Wer,hc,Her,uV,Uer,Jer,bV,Yer,Ker,Zer,h0,eor,o_e,oor,ror,tor,ct,p0,aor,r_e,nor,sor,pc,lor,t_e,ior,dor,vV,cor,mor,gor,a_e,hor,por,_0,_or,no,u0,uor,n_e,bor,vor,gn,For,s_e,Tor,Mor,l_e,Eor,Cor,i_e,wor,Aor,yor,d_e,GF,c_e,Lor,xor,FV,kor,Sor,Ror,OF,Bor,f_e,Por,$or,m_e,Ior,qor,g_e,Nor,jor,b0,B$e,_c,VF,h_e,v0,Dor,p_e,Gor,P$e,ur,F0,Oor,uc,Vor,TV,Xor,zor,MV,Qor,Wor,Hor,T0,Uor,__e,Jor,Yor,Kor,ft,M0,Zor,u_e,err,orr,bc,rrr,b_e,trr,arr,EV,nrr,srr,lrr,v_e,irr,drr,E0,crr,so,C0,frr,F_e,mrr,grr,hn,hrr,T_e,prr,_rr,M_e,urr,brr,E_e,vrr,Frr,Trr,pn,XF,C_e,Mrr,Err,CV,Crr,wrr,Arr,zF,w_e,yrr,Lrr,wV,xrr,krr,Srr,QF,A_e,Rrr,Brr,AV,Prr,$rr,Irr,WF,y_e,qrr,Nrr,yV,jrr,Drr,Grr,HF,Orr,L_e,Vrr,Xrr,x_e,zrr,Qrr,k_e,Wrr,Hrr,w0,$$e,vc,UF,S_e,A0,Urr,R_e,Jrr,I$e,br,y0,Yrr,Fc,Krr,LV,Zrr,etr,xV,otr,rtr,ttr,L0,atr,B_e,ntr,str,ltr,mt,x0,itr,P_e,dtr,ctr,Tc,ftr,$_e,mtr,gtr,kV,htr,ptr,_tr,I_e,utr,btr,k0,vtr,lo,S0,Ftr,q_e,Ttr,Mtr,_n,Etr,N_e,Ctr,wtr,j_e,Atr,ytr,D_e,Ltr,xtr,ktr,G_e,JF,O_e,Str,Rtr,SV,Btr,Ptr,$tr,YF,Itr,V_e,qtr,Ntr,X_e,jtr,Dtr,z_e,Gtr,Otr,R0,q$e,Mc,KF,Q_e,B0,Vtr,W_e,Xtr,N$e,vr,P0,ztr,Ec,Qtr,RV,Wtr,Htr,BV,Utr,Jtr,Ytr,$0,Ktr,H_e,Ztr,ear,oar,gt,I0,rar,U_e,tar,aar,Cc,nar,J_e,sar,lar,PV,iar,dar,car,Y_e,far,mar,q0,gar,po,N0,har,K_e,par,_ar,un,uar,Z_e,bar,Far,eue,Tar,Mar,oue,Ear,Car,war,x,ZF,rue,Aar,yar,$V,Lar,xar,kar,eT,tue,Sar,Rar,IV,Bar,Par,$ar,oT,aue,Iar,qar,qV,Nar,jar,Dar,rT,nue,Gar,Oar,NV,Var,Xar,zar,tT,sue,Qar,War,jV,Har,Uar,Jar,aT,lue,Yar,Kar,DV,Zar,enr,onr,nT,iue,rnr,tnr,GV,anr,nnr,snr,sT,due,lnr,inr,OV,dnr,cnr,fnr,lT,cue,mnr,gnr,VV,hnr,pnr,_nr,iT,fue,unr,bnr,XV,vnr,Fnr,Tnr,dT,mue,Mnr,Enr,zV,Cnr,wnr,Anr,cT,gue,ynr,Lnr,QV,xnr,knr,Snr,fT,hue,Rnr,Bnr,WV,Pnr,$nr,Inr,mT,pue,qnr,Nnr,HV,jnr,Dnr,Gnr,gT,_ue,Onr,Vnr,UV,Xnr,znr,Qnr,hT,uue,Wnr,Hnr,JV,Unr,Jnr,Ynr,Ys,bue,Knr,Znr,YV,esr,osr,KV,rsr,tsr,asr,pT,vue,nsr,ssr,ZV,lsr,isr,dsr,_T,Fue,csr,fsr,eX,msr,gsr,hsr,uT,Tue,psr,_sr,oX,usr,bsr,vsr,bT,Mue,Fsr,Tsr,rX,Msr,Esr,Csr,vT,Eue,wsr,Asr,tX,ysr,Lsr,xsr,FT,Cue,ksr,Ssr,aX,Rsr,Bsr,Psr,TT,wue,$sr,Isr,nX,qsr,Nsr,jsr,MT,Aue,Dsr,Gsr,sX,Osr,Vsr,Xsr,ET,yue,zsr,Qsr,lX,Wsr,Hsr,Usr,CT,Lue,Jsr,Ysr,iX,Ksr,Zsr,elr,wT,xue,olr,rlr,dX,tlr,alr,nlr,AT,kue,slr,llr,cX,ilr,dlr,clr,yT,Sue,flr,mlr,fX,glr,hlr,plr,LT,Rue,_lr,ulr,mX,blr,vlr,Flr,xT,Bue,Tlr,Mlr,gX,Elr,Clr,wlr,kT,Pue,Alr,ylr,hX,Llr,xlr,klr,ST,$ue,Slr,Rlr,pX,Blr,Plr,$lr,RT,Iue,Ilr,qlr,_X,Nlr,jlr,Dlr,BT,que,Glr,Olr,uX,Vlr,Xlr,zlr,PT,Nue,Qlr,Wlr,bX,Hlr,Ulr,Jlr,$T,jue,Ylr,Klr,vX,Zlr,eir,oir,IT,Due,rir,tir,FX,air,nir,sir,qT,Gue,lir,iir,TX,dir,cir,fir,NT,Oue,mir,gir,MX,hir,pir,_ir,jT,Vue,uir,bir,EX,vir,Fir,Tir,DT,Xue,Mir,Eir,CX,Cir,wir,Air,GT,zue,yir,Lir,wX,xir,kir,Sir,Que,Rir,Bir,j0,j$e,wc,OT,Wue,D0,Pir,Hue,$ir,D$e,Fr,G0,Iir,Ac,qir,AX,Nir,jir,yX,Dir,Gir,Oir,O0,Vir,Uue,Xir,zir,Qir,ht,V0,Wir,Jue,Hir,Uir,yc,Jir,Yue,Yir,Kir,LX,Zir,edr,odr,Kue,rdr,tdr,X0,adr,_o,z0,ndr,Zue,sdr,ldr,bn,idr,e2e,ddr,cdr,o2e,fdr,mdr,r2e,gdr,hdr,pdr,U,VT,t2e,_dr,udr,xX,bdr,vdr,Fdr,XT,a2e,Tdr,Mdr,kX,Edr,Cdr,wdr,zT,n2e,Adr,ydr,SX,Ldr,xdr,kdr,QT,s2e,Sdr,Rdr,RX,Bdr,Pdr,$dr,WT,l2e,Idr,qdr,BX,Ndr,jdr,Ddr,HT,i2e,Gdr,Odr,PX,Vdr,Xdr,zdr,UT,d2e,Qdr,Wdr,$X,Hdr,Udr,Jdr,JT,c2e,Ydr,Kdr,IX,Zdr,ecr,ocr,YT,f2e,rcr,tcr,qX,acr,ncr,scr,KT,m2e,lcr,icr,NX,dcr,ccr,fcr,ZT,g2e,mcr,gcr,jX,hcr,pcr,_cr,e7,h2e,ucr,bcr,DX,vcr,Fcr,Tcr,o7,p2e,Mcr,Ecr,GX,Ccr,wcr,Acr,r7,_2e,ycr,Lcr,OX,xcr,kcr,Scr,t7,u2e,Rcr,Bcr,VX,Pcr,$cr,Icr,a7,b2e,qcr,Ncr,XX,jcr,Dcr,Gcr,n7,v2e,Ocr,Vcr,zX,Xcr,zcr,Qcr,s7,F2e,Wcr,Hcr,QX,Ucr,Jcr,Ycr,l7,T2e,Kcr,Zcr,WX,efr,ofr,rfr,i7,M2e,tfr,afr,HX,nfr,sfr,lfr,d7,E2e,ifr,dfr,UX,cfr,ffr,mfr,c7,C2e,gfr,hfr,JX,pfr,_fr,ufr,f7,w2e,bfr,vfr,YX,Ffr,Tfr,Mfr,A2e,Efr,Cfr,Q0,G$e,Lc,m7,y2e,W0,wfr,L2e,Afr,O$e,Tr,H0,yfr,xc,Lfr,KX,xfr,kfr,ZX,Sfr,Rfr,Bfr,U0,Pfr,x2e,$fr,Ifr,qfr,pt,J0,Nfr,k2e,jfr,Dfr,kc,Gfr,S2e,Ofr,Vfr,ez,Xfr,zfr,Qfr,R2e,Wfr,Hfr,Y0,Ufr,uo,K0,Jfr,B2e,Yfr,Kfr,vn,Zfr,P2e,emr,omr,$2e,rmr,tmr,I2e,amr,nmr,smr,he,g7,q2e,lmr,imr,oz,dmr,cmr,fmr,h7,N2e,mmr,gmr,rz,hmr,pmr,_mr,p7,j2e,umr,bmr,tz,vmr,Fmr,Tmr,_7,D2e,Mmr,Emr,az,Cmr,wmr,Amr,u7,G2e,ymr,Lmr,nz,xmr,kmr,Smr,b7,O2e,Rmr,Bmr,sz,Pmr,$mr,Imr,v7,V2e,qmr,Nmr,lz,jmr,Dmr,Gmr,F7,X2e,Omr,Vmr,iz,Xmr,zmr,Qmr,T7,z2e,Wmr,Hmr,dz,Umr,Jmr,Ymr,M7,Q2e,Kmr,Zmr,cz,egr,ogr,rgr,E7,W2e,tgr,agr,fz,ngr,sgr,lgr,C7,H2e,igr,dgr,mz,cgr,fgr,mgr,U2e,ggr,hgr,Z0,V$e,Sc,w7,J2e,eA,pgr,Y2e,_gr,X$e,Mr,oA,ugr,Rc,bgr,gz,vgr,Fgr,hz,Tgr,Mgr,Egr,rA,Cgr,K2e,wgr,Agr,ygr,_t,tA,Lgr,Z2e,xgr,kgr,Bc,Sgr,e1e,Rgr,Bgr,pz,Pgr,$gr,Igr,o1e,qgr,Ngr,aA,jgr,bo,nA,Dgr,r1e,Ggr,Ogr,Fn,Vgr,t1e,Xgr,zgr,a1e,Qgr,Wgr,n1e,Hgr,Ugr,Jgr,sA,A7,s1e,Ygr,Kgr,_z,Zgr,ehr,ohr,y7,l1e,rhr,thr,uz,ahr,nhr,shr,i1e,lhr,ihr,lA,z$e,Pc,L7,d1e,iA,dhr,c1e,chr,Q$e,Er,dA,fhr,$c,mhr,bz,ghr,hhr,vz,phr,_hr,uhr,cA,bhr,f1e,vhr,Fhr,Thr,ut,fA,Mhr,m1e,Ehr,Chr,Ic,whr,g1e,Ahr,yhr,Fz,Lhr,xhr,khr,h1e,Shr,Rhr,mA,Bhr,vo,gA,Phr,p1e,$hr,Ihr,Tn,qhr,_1e,Nhr,jhr,u1e,Dhr,Ghr,b1e,Ohr,Vhr,Xhr,K,x7,v1e,zhr,Qhr,Tz,Whr,Hhr,Uhr,k7,F1e,Jhr,Yhr,Mz,Khr,Zhr,epr,S7,T1e,opr,rpr,Ez,tpr,apr,npr,R7,M1e,spr,lpr,Cz,ipr,dpr,cpr,B7,E1e,fpr,mpr,wz,gpr,hpr,ppr,P7,C1e,_pr,upr,Az,bpr,vpr,Fpr,$7,w1e,Tpr,Mpr,yz,Epr,Cpr,wpr,I7,A1e,Apr,ypr,Lz,Lpr,xpr,kpr,q7,y1e,Spr,Rpr,xz,Bpr,Ppr,$pr,N7,L1e,Ipr,qpr,kz,Npr,jpr,Dpr,j7,x1e,Gpr,Opr,Sz,Vpr,Xpr,zpr,D7,k1e,Qpr,Wpr,Rz,Hpr,Upr,Jpr,G7,S1e,Ypr,Kpr,Bz,Zpr,e_r,o_r,O7,R1e,r_r,t_r,Pz,a_r,n_r,s_r,V7,B1e,l_r,i_r,$z,d_r,c_r,f_r,X7,P1e,m_r,g_r,Iz,h_r,p_r,__r,z7,$1e,u_r,b_r,qz,v_r,F_r,T_r,Q7,I1e,M_r,E_r,Nz,C_r,w_r,A_r,W7,q1e,y_r,L_r,jz,x_r,k_r,S_r,H7,N1e,R_r,B_r,Dz,P_r,$_r,I_r,j1e,q_r,N_r,hA,W$e,qc,U7,D1e,pA,j_r,G1e,D_r,H$e,Cr,_A,G_r,Nc,O_r,Gz,V_r,X_r,Oz,z_r,Q_r,W_r,uA,H_r,O1e,U_r,J_r,Y_r,bt,bA,K_r,V1e,Z_r,eur,jc,our,X1e,rur,tur,Vz,aur,nur,sur,z1e,lur,iur,vA,dur,Fo,FA,cur,Q1e,fur,mur,Mn,gur,W1e,hur,pur,H1e,_ur,uur,U1e,bur,vur,Fur,Fe,J7,J1e,Tur,Mur,Xz,Eur,Cur,wur,Y7,Y1e,Aur,yur,zz,Lur,xur,kur,K7,K1e,Sur,Rur,Qz,Bur,Pur,$ur,Z7,Z1e,Iur,qur,Wz,Nur,jur,Dur,e9,ebe,Gur,Our,Hz,Vur,Xur,zur,o9,obe,Qur,Wur,Uz,Hur,Uur,Jur,r9,rbe,Yur,Kur,Jz,Zur,e2r,o2r,t9,tbe,r2r,t2r,Yz,a2r,n2r,s2r,a9,abe,l2r,i2r,Kz,d2r,c2r,f2r,n9,nbe,m2r,g2r,Zz,h2r,p2r,_2r,sbe,u2r,b2r,TA,U$e,Dc,s9,lbe,MA,v2r,ibe,F2r,J$e,wr,EA,T2r,Gc,M2r,eQ,E2r,C2r,oQ,w2r,A2r,y2r,CA,L2r,dbe,x2r,k2r,S2r,vt,wA,R2r,cbe,B2r,P2r,Oc,$2r,fbe,I2r,q2r,rQ,N2r,j2r,D2r,mbe,G2r,O2r,AA,V2r,To,yA,X2r,gbe,z2r,Q2r,En,W2r,hbe,H2r,U2r,pbe,J2r,Y2r,_be,K2r,Z2r,e1r,V,l9,ube,o1r,r1r,tQ,t1r,a1r,n1r,i9,bbe,s1r,l1r,aQ,i1r,d1r,c1r,d9,vbe,f1r,m1r,nQ,g1r,h1r,p1r,c9,Fbe,_1r,u1r,sQ,b1r,v1r,F1r,f9,Tbe,T1r,M1r,lQ,E1r,C1r,w1r,m9,Mbe,A1r,y1r,iQ,L1r,x1r,k1r,g9,Ebe,S1r,R1r,dQ,B1r,P1r,$1r,h9,Cbe,I1r,q1r,cQ,N1r,j1r,D1r,p9,wbe,G1r,O1r,fQ,V1r,X1r,z1r,_9,Abe,Q1r,W1r,mQ,H1r,U1r,J1r,u9,ybe,Y1r,K1r,gQ,Z1r,ebr,obr,b9,Lbe,rbr,tbr,hQ,abr,nbr,sbr,v9,xbe,lbr,ibr,pQ,dbr,cbr,fbr,F9,kbe,mbr,gbr,_Q,hbr,pbr,_br,T9,Sbe,ubr,bbr,uQ,vbr,Fbr,Tbr,M9,Rbe,Mbr,Ebr,bQ,Cbr,wbr,Abr,E9,Bbe,ybr,Lbr,vQ,xbr,kbr,Sbr,C9,Pbe,Rbr,Bbr,FQ,Pbr,$br,Ibr,w9,$be,qbr,Nbr,TQ,jbr,Dbr,Gbr,A9,Ibe,Obr,Vbr,MQ,Xbr,zbr,Qbr,y9,qbe,Wbr,Hbr,EQ,Ubr,Jbr,Ybr,L9,Nbe,Kbr,Zbr,CQ,e6r,o6r,r6r,x9,jbe,t6r,a6r,wQ,n6r,s6r,l6r,k9,Dbe,i6r,d6r,AQ,c6r,f6r,m6r,S9,Gbe,g6r,h6r,yQ,p6r,_6r,u6r,R9,Obe,b6r,v6r,LQ,F6r,T6r,M6r,Vbe,E6r,C6r,LA,Y$e,Vc,B9,Xbe,xA,w6r,zbe,A6r,K$e,Ar,kA,y6r,Xc,L6r,xQ,x6r,k6r,kQ,S6r,R6r,B6r,SA,P6r,Qbe,$6r,I6r,q6r,Ft,RA,N6r,Wbe,j6r,D6r,zc,G6r,Hbe,O6r,V6r,SQ,X6r,z6r,Q6r,Ube,W6r,H6r,BA,U6r,Mo,PA,J6r,Jbe,Y6r,K6r,Cn,Z6r,Ybe,evr,ovr,Kbe,rvr,tvr,Zbe,avr,nvr,svr,se,P9,e6e,lvr,ivr,RQ,dvr,cvr,fvr,$9,o6e,mvr,gvr,BQ,hvr,pvr,_vr,I9,r6e,uvr,bvr,PQ,vvr,Fvr,Tvr,q9,t6e,Mvr,Evr,$Q,Cvr,wvr,Avr,N9,a6e,yvr,Lvr,IQ,xvr,kvr,Svr,j9,n6e,Rvr,Bvr,qQ,Pvr,$vr,Ivr,D9,s6e,qvr,Nvr,NQ,jvr,Dvr,Gvr,G9,l6e,Ovr,Vvr,jQ,Xvr,zvr,Qvr,O9,i6e,Wvr,Hvr,DQ,Uvr,Jvr,Yvr,V9,d6e,Kvr,Zvr,GQ,eFr,oFr,rFr,X9,c6e,tFr,aFr,OQ,nFr,sFr,lFr,z9,f6e,iFr,dFr,VQ,cFr,fFr,mFr,Q9,m6e,gFr,hFr,XQ,pFr,_Fr,uFr,W9,g6e,bFr,vFr,zQ,FFr,TFr,MFr,H9,h6e,EFr,CFr,QQ,wFr,AFr,yFr,U9,p6e,LFr,xFr,WQ,kFr,SFr,RFr,J9,_6e,BFr,PFr,HQ,$Fr,IFr,qFr,u6e,NFr,jFr,$A,Z$e,Qc,Y9,b6e,IA,DFr,v6e,GFr,eIe,yr,qA,OFr,Wc,VFr,UQ,XFr,zFr,JQ,QFr,WFr,HFr,NA,UFr,F6e,JFr,YFr,KFr,Tt,jA,ZFr,T6e,eTr,oTr,Hc,rTr,M6e,tTr,aTr,YQ,nTr,sTr,lTr,E6e,iTr,dTr,DA,cTr,Eo,GA,fTr,C6e,mTr,gTr,wn,hTr,w6e,pTr,_Tr,A6e,uTr,bTr,y6e,vTr,FTr,TTr,L6e,K9,x6e,MTr,ETr,KQ,CTr,wTr,ATr,k6e,yTr,LTr,OA,oIe,Uc,Z9,S6e,VA,xTr,R6e,kTr,rIe,Lr,XA,STr,Jc,RTr,ZQ,BTr,PTr,eW,$Tr,ITr,qTr,zA,NTr,B6e,jTr,DTr,GTr,Mt,QA,OTr,P6e,VTr,XTr,Yc,zTr,$6e,QTr,WTr,oW,HTr,UTr,JTr,I6e,YTr,KTr,WA,ZTr,Co,HA,e7r,q6e,o7r,r7r,An,t7r,N6e,a7r,n7r,j6e,s7r,l7r,D6e,i7r,d7r,c7r,Z,eM,G6e,f7r,m7r,rW,g7r,h7r,p7r,oM,O6e,_7r,u7r,tW,b7r,v7r,F7r,rM,V6e,T7r,M7r,aW,E7r,C7r,w7r,tM,X6e,A7r,y7r,nW,L7r,x7r,k7r,aM,z6e,S7r,R7r,sW,B7r,P7r,$7r,nM,Q6e,I7r,q7r,lW,N7r,j7r,D7r,sM,W6e,G7r,O7r,iW,V7r,X7r,z7r,lM,H6e,Q7r,W7r,dW,H7r,U7r,J7r,iM,U6e,Y7r,K7r,cW,Z7r,e9r,o9r,dM,J6e,r9r,t9r,fW,a9r,n9r,s9r,cM,Y6e,l9r,i9r,mW,d9r,c9r,f9r,fM,K6e,m9r,g9r,gW,h9r,p9r,_9r,mM,Z6e,u9r,b9r,hW,v9r,F9r,T9r,gM,eve,M9r,E9r,pW,C9r,w9r,A9r,hM,ove,y9r,L9r,_W,x9r,k9r,S9r,pM,rve,R9r,B9r,uW,P9r,$9r,I9r,_M,tve,q9r,N9r,bW,j9r,D9r,G9r,uM,ave,O9r,V9r,vW,X9r,z9r,Q9r,bM,nve,W9r,H9r,FW,U9r,J9r,Y9r,vM,sve,K9r,Z9r,TW,eMr,oMr,rMr,lve,tMr,aMr,UA,tIe,Kc,FM,ive,JA,nMr,dve,sMr,aIe,xr,YA,lMr,Zc,iMr,MW,dMr,cMr,EW,fMr,mMr,gMr,KA,hMr,cve,pMr,_Mr,uMr,Et,ZA,bMr,fve,vMr,FMr,ef,TMr,mve,MMr,EMr,CW,CMr,wMr,AMr,gve,yMr,LMr,ey,xMr,wo,oy,kMr,hve,SMr,RMr,yn,BMr,pve,PMr,$Mr,_ve,IMr,qMr,uve,NMr,jMr,DMr,ee,TM,bve,GMr,OMr,wW,VMr,XMr,zMr,MM,vve,QMr,WMr,AW,HMr,UMr,JMr,EM,Fve,YMr,KMr,yW,ZMr,e4r,o4r,CM,Tve,r4r,t4r,LW,a4r,n4r,s4r,wM,Mve,l4r,i4r,xW,d4r,c4r,f4r,AM,Eve,m4r,g4r,kW,h4r,p4r,_4r,yM,Cve,u4r,b4r,SW,v4r,F4r,T4r,LM,wve,M4r,E4r,RW,C4r,w4r,A4r,xM,Ave,y4r,L4r,BW,x4r,k4r,S4r,kM,yve,R4r,B4r,PW,P4r,$4r,I4r,SM,Lve,q4r,N4r,$W,j4r,D4r,G4r,RM,xve,O4r,V4r,IW,X4r,z4r,Q4r,BM,kve,W4r,H4r,qW,U4r,J4r,Y4r,PM,Sve,K4r,Z4r,NW,eEr,oEr,rEr,$M,Rve,tEr,aEr,jW,nEr,sEr,lEr,IM,Bve,iEr,dEr,DW,cEr,fEr,mEr,qM,Pve,gEr,hEr,GW,pEr,_Er,uEr,NM,$ve,bEr,vEr,OW,FEr,TEr,MEr,jM,Ive,EEr,CEr,VW,wEr,AEr,yEr,DM,qve,LEr,xEr,XW,kEr,SEr,REr,Nve,BEr,PEr,ry,nIe,of,GM,jve,ty,$Er,Dve,IEr,sIe,kr,ay,qEr,rf,NEr,zW,jEr,DEr,QW,GEr,OEr,VEr,ny,XEr,Gve,zEr,QEr,WEr,Ct,sy,HEr,Ove,UEr,JEr,tf,YEr,Vve,KEr,ZEr,WW,e5r,o5r,r5r,Xve,t5r,a5r,ly,n5r,Ao,iy,s5r,zve,l5r,i5r,Ln,d5r,Qve,c5r,f5r,Wve,m5r,g5r,Hve,h5r,p5r,_5r,Uve,OM,Jve,u5r,b5r,HW,v5r,F5r,T5r,Yve,M5r,E5r,dy,lIe,af,VM,Kve,cy,C5r,Zve,w5r,iIe,Sr,fy,A5r,nf,y5r,UW,L5r,x5r,JW,k5r,S5r,R5r,my,B5r,eFe,P5r,$5r,I5r,wt,gy,q5r,oFe,N5r,j5r,sf,D5r,rFe,G5r,O5r,YW,V5r,X5r,z5r,tFe,Q5r,W5r,hy,H5r,yo,py,U5r,aFe,J5r,Y5r,xn,K5r,nFe,Z5r,e3r,sFe,o3r,r3r,lFe,t3r,a3r,n3r,iFe,XM,dFe,s3r,l3r,KW,i3r,d3r,c3r,cFe,f3r,m3r,_y,dIe,lf,zM,fFe,uy,g3r,mFe,h3r,cIe,Rr,by,p3r,df,_3r,ZW,u3r,b3r,eH,v3r,F3r,T3r,vy,M3r,gFe,E3r,C3r,w3r,At,Fy,A3r,hFe,y3r,L3r,cf,x3r,pFe,k3r,S3r,oH,R3r,B3r,P3r,_Fe,$3r,I3r,Ty,q3r,Lo,My,N3r,uFe,j3r,D3r,kn,G3r,bFe,O3r,V3r,vFe,X3r,z3r,FFe,Q3r,W3r,H3r,X,QM,TFe,U3r,J3r,rH,Y3r,K3r,Z3r,WM,MFe,eCr,oCr,tH,rCr,tCr,aCr,HM,EFe,nCr,sCr,aH,lCr,iCr,dCr,UM,CFe,cCr,fCr,nH,mCr,gCr,hCr,JM,wFe,pCr,_Cr,sH,uCr,bCr,vCr,YM,AFe,FCr,TCr,lH,MCr,ECr,CCr,KM,yFe,wCr,ACr,iH,yCr,LCr,xCr,ZM,LFe,kCr,SCr,dH,RCr,BCr,PCr,e4,xFe,$Cr,ICr,cH,qCr,NCr,jCr,o4,kFe,DCr,GCr,fH,OCr,VCr,XCr,r4,SFe,zCr,QCr,mH,WCr,HCr,UCr,t4,RFe,JCr,YCr,gH,KCr,ZCr,ewr,a4,BFe,owr,rwr,hH,twr,awr,nwr,n4,PFe,swr,lwr,pH,iwr,dwr,cwr,s4,$Fe,fwr,mwr,_H,gwr,hwr,pwr,l4,IFe,_wr,uwr,uH,bwr,vwr,Fwr,i4,qFe,Twr,Mwr,bH,Ewr,Cwr,wwr,d4,NFe,Awr,ywr,vH,Lwr,xwr,kwr,c4,jFe,Swr,Rwr,FH,Bwr,Pwr,$wr,f4,DFe,Iwr,qwr,TH,Nwr,jwr,Dwr,m4,GFe,Gwr,Owr,MH,Vwr,Xwr,zwr,g4,OFe,Qwr,Wwr,EH,Hwr,Uwr,Jwr,h4,VFe,Ywr,Kwr,CH,Zwr,e0r,o0r,p4,XFe,r0r,t0r,wH,a0r,n0r,s0r,_4,zFe,l0r,i0r,AH,d0r,c0r,f0r,u4,QFe,m0r,g0r,yH,h0r,p0r,_0r,WFe,u0r,b0r,Ey,fIe,ff,b4,HFe,Cy,v0r,UFe,F0r,mIe,Br,wy,T0r,mf,M0r,LH,E0r,C0r,xH,w0r,A0r,y0r,Ay,L0r,JFe,x0r,k0r,S0r,yt,yy,R0r,YFe,B0r,P0r,gf,$0r,KFe,I0r,q0r,kH,N0r,j0r,D0r,ZFe,G0r,O0r,Ly,V0r,xo,xy,X0r,eTe,z0r,Q0r,Sn,W0r,oTe,H0r,U0r,rTe,J0r,Y0r,tTe,K0r,Z0r,eAr,ca,v4,aTe,oAr,rAr,SH,tAr,aAr,nAr,F4,nTe,sAr,lAr,RH,iAr,dAr,cAr,T4,sTe,fAr,mAr,BH,gAr,hAr,pAr,M4,lTe,_Ar,uAr,PH,bAr,vAr,FAr,E4,iTe,TAr,MAr,$H,EAr,CAr,wAr,dTe,AAr,yAr,ky,gIe,hf,C4,cTe,Sy,LAr,fTe,xAr,hIe,Pr,Ry,kAr,pf,SAr,IH,RAr,BAr,qH,PAr,$Ar,IAr,By,qAr,mTe,NAr,jAr,DAr,Lt,Py,GAr,gTe,OAr,VAr,_f,XAr,hTe,zAr,QAr,NH,WAr,HAr,UAr,pTe,JAr,YAr,$y,KAr,ko,Iy,ZAr,_Te,eyr,oyr,Rn,ryr,uTe,tyr,ayr,bTe,nyr,syr,vTe,lyr,iyr,dyr,fe,w4,FTe,cyr,fyr,jH,myr,gyr,hyr,A4,TTe,pyr,_yr,DH,uyr,byr,vyr,y4,MTe,Fyr,Tyr,GH,Myr,Eyr,Cyr,L4,ETe,wyr,Ayr,OH,yyr,Lyr,xyr,x4,CTe,kyr,Syr,VH,Ryr,Byr,Pyr,k4,wTe,$yr,Iyr,XH,qyr,Nyr,jyr,S4,ATe,Dyr,Gyr,zH,Oyr,Vyr,Xyr,R4,yTe,zyr,Qyr,QH,Wyr,Hyr,Uyr,B4,LTe,Jyr,Yyr,WH,Kyr,Zyr,eLr,P4,xTe,oLr,rLr,HH,tLr,aLr,nLr,$4,kTe,sLr,lLr,UH,iLr,dLr,cLr,I4,STe,fLr,mLr,JH,gLr,hLr,pLr,q4,RTe,_Lr,uLr,YH,bLr,vLr,FLr,BTe,TLr,MLr,qy,pIe,uf,N4,PTe,Ny,ELr,$Te,CLr,_Ie,$r,jy,wLr,bf,ALr,KH,yLr,LLr,ZH,xLr,kLr,SLr,Dy,RLr,ITe,BLr,PLr,$Lr,xt,Gy,ILr,qTe,qLr,NLr,vf,jLr,NTe,DLr,GLr,eU,OLr,VLr,XLr,jTe,zLr,QLr,Oy,WLr,So,Vy,HLr,DTe,ULr,JLr,Bn,YLr,GTe,KLr,ZLr,OTe,e8r,o8r,VTe,r8r,t8r,a8r,Te,j4,XTe,n8r,s8r,oU,l8r,i8r,d8r,D4,zTe,c8r,f8r,rU,m8r,g8r,h8r,G4,QTe,p8r,_8r,tU,u8r,b8r,v8r,O4,WTe,F8r,T8r,aU,M8r,E8r,C8r,V4,HTe,w8r,A8r,nU,y8r,L8r,x8r,X4,UTe,k8r,S8r,sU,R8r,B8r,P8r,z4,JTe,$8r,I8r,lU,q8r,N8r,j8r,Q4,YTe,D8r,G8r,iU,O8r,V8r,X8r,W4,KTe,z8r,Q8r,dU,W8r,H8r,U8r,H4,ZTe,J8r,Y8r,cU,K8r,Z8r,exr,e7e,oxr,rxr,Xy,uIe,Ff,U4,o7e,zy,txr,r7e,axr,bIe,Ir,Qy,nxr,Tf,sxr,fU,lxr,ixr,mU,dxr,cxr,fxr,Wy,mxr,t7e,gxr,hxr,pxr,kt,Hy,_xr,a7e,uxr,bxr,Mf,vxr,n7e,Fxr,Txr,gU,Mxr,Exr,Cxr,s7e,wxr,Axr,Uy,yxr,Ro,Jy,Lxr,l7e,xxr,kxr,Pn,Sxr,i7e,Rxr,Bxr,d7e,Pxr,$xr,c7e,Ixr,qxr,Nxr,Me,J4,f7e,jxr,Dxr,hU,Gxr,Oxr,Vxr,Y4,m7e,Xxr,zxr,pU,Qxr,Wxr,Hxr,K4,g7e,Uxr,Jxr,_U,Yxr,Kxr,Zxr,Z4,h7e,ekr,okr,uU,rkr,tkr,akr,eE,p7e,nkr,skr,bU,lkr,ikr,dkr,oE,_7e,ckr,fkr,vU,mkr,gkr,hkr,rE,u7e,pkr,_kr,FU,ukr,bkr,vkr,tE,b7e,Fkr,Tkr,TU,Mkr,Ekr,Ckr,aE,v7e,wkr,Akr,MU,ykr,Lkr,xkr,nE,F7e,kkr,Skr,EU,Rkr,Bkr,Pkr,T7e,$kr,Ikr,Yy,vIe,Ef,sE,M7e,Ky,qkr,E7e,Nkr,FIe,qr,Zy,jkr,Cf,Dkr,CU,Gkr,Okr,wU,Vkr,Xkr,zkr,eL,Qkr,C7e,Wkr,Hkr,Ukr,St,oL,Jkr,w7e,Ykr,Kkr,wf,Zkr,A7e,eSr,oSr,AU,rSr,tSr,aSr,y7e,nSr,sSr,rL,lSr,Bo,tL,iSr,L7e,dSr,cSr,$n,fSr,x7e,mSr,gSr,k7e,hSr,pSr,S7e,_Sr,uSr,bSr,Ee,lE,R7e,vSr,FSr,yU,TSr,MSr,ESr,iE,B7e,CSr,wSr,LU,ASr,ySr,LSr,dE,P7e,xSr,kSr,xU,SSr,RSr,BSr,cE,$7e,PSr,$Sr,kU,ISr,qSr,NSr,fE,I7e,jSr,DSr,SU,GSr,OSr,VSr,mE,q7e,XSr,zSr,RU,QSr,WSr,HSr,gE,N7e,USr,JSr,BU,YSr,KSr,ZSr,hE,j7e,eRr,oRr,PU,rRr,tRr,aRr,pE,D7e,nRr,sRr,$U,lRr,iRr,dRr,_E,G7e,cRr,fRr,IU,mRr,gRr,hRr,O7e,pRr,_Rr,aL,TIe,Af,uE,V7e,nL,uRr,X7e,bRr,MIe,Nr,sL,vRr,yf,FRr,qU,TRr,MRr,NU,ERr,CRr,wRr,lL,ARr,z7e,yRr,LRr,xRr,Rt,iL,kRr,Q7e,SRr,RRr,Lf,BRr,W7e,PRr,$Rr,jU,IRr,qRr,NRr,H7e,jRr,DRr,dL,GRr,Po,cL,ORr,U7e,VRr,XRr,In,zRr,J7e,QRr,WRr,Y7e,HRr,URr,K7e,JRr,YRr,KRr,Ce,bE,Z7e,ZRr,eBr,DU,oBr,rBr,tBr,vE,e9e,aBr,nBr,GU,sBr,lBr,iBr,FE,o9e,dBr,cBr,OU,fBr,mBr,gBr,TE,r9e,hBr,pBr,VU,_Br,uBr,bBr,ME,t9e,vBr,FBr,XU,TBr,MBr,EBr,EE,a9e,CBr,wBr,zU,ABr,yBr,LBr,CE,n9e,xBr,kBr,QU,SBr,RBr,BBr,wE,s9e,PBr,$Br,WU,IBr,qBr,NBr,AE,l9e,jBr,DBr,HU,GBr,OBr,VBr,yE,i9e,XBr,zBr,UU,QBr,WBr,HBr,d9e,UBr,JBr,fL,EIe,xf,LE,c9e,mL,YBr,f9e,KBr,CIe,jr,gL,ZBr,kf,ePr,JU,oPr,rPr,YU,tPr,aPr,nPr,hL,sPr,m9e,lPr,iPr,dPr,Bt,pL,cPr,g9e,fPr,mPr,Sf,gPr,h9e,hPr,pPr,KU,_Pr,uPr,bPr,p9e,vPr,FPr,_L,TPr,$o,uL,MPr,_9e,EPr,CPr,qn,wPr,u9e,APr,yPr,b9e,LPr,xPr,v9e,kPr,SPr,RPr,$e,xE,F9e,BPr,PPr,ZU,$Pr,IPr,qPr,kE,T9e,NPr,jPr,eJ,DPr,GPr,OPr,SE,M9e,VPr,XPr,oJ,zPr,QPr,WPr,RE,E9e,HPr,UPr,rJ,JPr,YPr,KPr,BE,C9e,ZPr,e$r,tJ,o$r,r$r,t$r,PE,w9e,a$r,n$r,aJ,s$r,l$r,i$r,$E,A9e,d$r,c$r,nJ,f$r,m$r,g$r,IE,y9e,h$r,p$r,sJ,_$r,u$r,b$r,L9e,v$r,F$r,bL,wIe,Rf,qE,x9e,vL,T$r,k9e,M$r,AIe,Dr,FL,E$r,Bf,C$r,lJ,w$r,A$r,iJ,y$r,L$r,x$r,TL,k$r,S9e,S$r,R$r,B$r,Pt,ML,P$r,R9e,$$r,I$r,Pf,q$r,B9e,N$r,j$r,dJ,D$r,G$r,O$r,P9e,V$r,X$r,EL,z$r,Io,CL,Q$r,$9e,W$r,H$r,Nn,U$r,I9e,J$r,Y$r,q9e,K$r,Z$r,N9e,eIr,oIr,rIr,Ie,NE,j9e,tIr,aIr,cJ,nIr,sIr,lIr,jE,D9e,iIr,dIr,fJ,cIr,fIr,mIr,DE,G9e,gIr,hIr,mJ,pIr,_Ir,uIr,GE,O9e,bIr,vIr,gJ,FIr,TIr,MIr,OE,V9e,EIr,CIr,hJ,wIr,AIr,yIr,VE,X9e,LIr,xIr,pJ,kIr,SIr,RIr,XE,z9e,BIr,PIr,_J,$Ir,IIr,qIr,zE,Q9e,NIr,jIr,uJ,DIr,GIr,OIr,W9e,VIr,XIr,wL,yIe,$f,QE,H9e,AL,zIr,U9e,QIr,LIe,Gr,yL,WIr,If,HIr,bJ,UIr,JIr,vJ,YIr,KIr,ZIr,LL,eqr,J9e,oqr,rqr,tqr,$t,xL,aqr,Y9e,nqr,sqr,qf,lqr,K9e,iqr,dqr,FJ,cqr,fqr,mqr,Z9e,gqr,hqr,kL,pqr,qo,SL,_qr,eMe,uqr,bqr,jn,vqr,oMe,Fqr,Tqr,rMe,Mqr,Eqr,tMe,Cqr,wqr,Aqr,aMe,WE,nMe,yqr,Lqr,TJ,xqr,kqr,Sqr,sMe,Rqr,Bqr,RL,xIe,Nf,HE,lMe,BL,Pqr,iMe,$qr,kIe,Or,PL,Iqr,jf,qqr,MJ,Nqr,jqr,EJ,Dqr,Gqr,Oqr,$L,Vqr,dMe,Xqr,zqr,Qqr,It,IL,Wqr,cMe,Hqr,Uqr,Df,Jqr,fMe,Yqr,Kqr,CJ,Zqr,eNr,oNr,mMe,rNr,tNr,qL,aNr,No,NL,nNr,gMe,sNr,lNr,Dn,iNr,hMe,dNr,cNr,pMe,fNr,mNr,_Me,gNr,hNr,pNr,jL,UE,uMe,_Nr,uNr,wJ,bNr,vNr,FNr,JE,bMe,TNr,MNr,AJ,ENr,CNr,wNr,vMe,ANr,yNr,DL,SIe,Gf,YE,FMe,GL,LNr,TMe,xNr,RIe,Vr,OL,kNr,Of,SNr,yJ,RNr,BNr,LJ,PNr,$Nr,INr,VL,qNr,MMe,NNr,jNr,DNr,qt,XL,GNr,EMe,ONr,VNr,Vf,XNr,CMe,zNr,QNr,xJ,WNr,HNr,UNr,wMe,JNr,YNr,zL,KNr,jo,QL,ZNr,AMe,ejr,ojr,Gn,rjr,yMe,tjr,ajr,LMe,njr,sjr,xMe,ljr,ijr,djr,kMe,KE,SMe,cjr,fjr,kJ,mjr,gjr,hjr,RMe,pjr,_jr,WL,BIe;return ue=new z({}),Da=new A({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),t3=new z({}),a3=new A({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Yf=new ujr({props:{warning:!0,$$slots:{default:[mLt]},$$scope:{ctx:zf}}}),n3=new z({}),s3=new w({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/configuration_auto.py#L563"}}),d3=new w({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/configuration_auto.py#L586"}}),c3=new A({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),f3=new w({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/configuration_auto.py#L708"}}),m3=new z({}),g3=new w({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/tokenization_auto.py#L384"}}),_3=new w({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_16792/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/tokenization_auto.py#L398"}}),u3=new A({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)`}}),b3=new w({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/tokenization_auto.py#L594"}}),v3=new z({}),F3=new w({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/feature_extraction_auto.py#L176"}}),E3=new w({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_16792/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/feature_extraction_auto.py#L190"}}),Jh=new ujr({props:{$$slots:{default:[gLt]},$$scope:{ctx:zf}}}),C3=new A({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),w3=new w({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/feature_extraction_auto.py#L317"}}),A3=new z({}),y3=new w({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/processing_auto.py#L76"}}),k3=new w({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/processing_auto.py#L90"}}),gp=new ujr({props:{$$slots:{default:[hLt]},$$scope:{ctx:zf}}}),S3=new A({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),R3=new w({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/processing_auto.py#L243"}}),B3=new z({}),P3=new w({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L718"}}),I3=new w({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),q3=new A({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),N3=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),j3=new A({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),D3=new z({}),G3=new w({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L725"}}),V3=new w({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),X3=new A({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),z3=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Q3=new A({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),W3=new z({}),H3=new w({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L740"}}),J3=new w({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),Y3=new A({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),K3=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Z3=new A({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),eC=new z({}),oC=new w({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L747"}}),tC=new w({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),aC=new A({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),nC=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),sC=new A({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),lC=new z({}),iC=new w({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L754"}}),cC=new w({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),fC=new A({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),mC=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),gC=new A({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),hC=new z({}),pC=new w({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L763"}}),uC=new w({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),bC=new A({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),vC=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),FC=new A({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),TC=new z({}),MC=new w({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L797"}}),CC=new w({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),wC=new A({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),AC=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),yC=new A({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),LC=new z({}),xC=new w({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L804"}}),SC=new w({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),RC=new A({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),BC=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),PC=new A({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),$C=new z({}),IC=new w({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L790"}}),NC=new w({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),jC=new A({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),DC=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),GC=new A({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),OC=new z({}),VC=new w({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L772"}}),zC=new w({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),QC=new A({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),WC=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),HC=new A({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),UC=new z({}),JC=new w({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L779"}}),KC=new w({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),ZC=new A({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),ew=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),ow=new A({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),rw=new z({}),tw=new w({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L813"}}),nw=new w({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),sw=new A({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),lw=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),iw=new A({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),dw=new z({}),cw=new w({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L852"}}),mw=new w({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),gw=new A({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),hw=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),pw=new A({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),_w=new z({}),uw=new w({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L859"}}),vw=new w({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),Fw=new A({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),Tw=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Mw=new A({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Ew=new z({}),Cw=new w({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L882"}}),Aw=new w({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),yw=new A({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),Lw=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),xw=new A({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),kw=new z({}),Sw=new w({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L866"}}),Bw=new w({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),Pw=new A({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),$w=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Iw=new A({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),qw=new z({}),Nw=new w({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L873"}}),Dw=new w({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),Gw=new A({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),Ow=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Xw=new A({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),zw=new z({}),Qw=new w({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L891"}}),Hw=new w({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),Uw=new A({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),Jw=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Yw=new A({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Kw=new z({}),Zw=new w({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L898"}}),o0=new w({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),r0=new A({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),t0=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),a0=new A({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),n0=new z({}),s0=new w({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L845"}}),i0=new w({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),d0=new A({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),c0=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),f0=new A({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),m0=new z({}),g0=new w({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L820"}}),p0=new w({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),_0=new A({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),u0=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),b0=new A({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),v0=new z({}),F0=new w({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L827"}}),M0=new w({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),E0=new A({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),C0=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),w0=new A({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),A0=new z({}),y0=new w({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_auto.py#L836"}}),x0=new w({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),k0=new A({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),S0=new w({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),R0=new A({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),B0=new z({}),P0=new w({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L381"}}),I0=new w({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),q0=new A({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),N0=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),j0=new A({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),D0=new z({}),G0=new w({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L388"}}),V0=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),X0=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),z0=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Q0=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),W0=new z({}),H0=new w({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L403"}}),J0=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),Y0=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),K0=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Z0=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),eA=new z({}),oA=new w({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L410"}}),tA=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),aA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),nA=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),lA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),iA=new z({}),dA=new w({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L424"}}),fA=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),mA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),gA=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),hA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),pA=new z({}),_A=new w({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L431"}}),bA=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),vA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),FA=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),TA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),MA=new z({}),EA=new w({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L440"}}),wA=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),AA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),yA=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),LA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),xA=new z({}),kA=new w({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L476"}}),RA=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),BA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),PA=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),$A=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),IA=new z({}),qA=new w({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L456"}}),jA=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),DA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),GA=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),OA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),VA=new z({}),XA=new w({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L467"}}),QA=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),WA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),HA=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),UA=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),JA=new z({}),YA=new w({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L449"}}),ZA=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),ey=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),oy=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),ry=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),ty=new z({}),ay=new w({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L417"}}),sy=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),ly=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),iy=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),dy=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),cy=new z({}),fy=new w({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_tf_auto.py#L492"}}),gy=new w({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),hy=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),py=new w({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),_y=new A({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),uy=new z({}),by=new w({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L240"}}),Fy=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),Ty=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),My=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Ey=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Cy=new z({}),wy=new w({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L254"}}),yy=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),Ly=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),xy=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),ky=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Sy=new z({}),Ry=new w({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L247"}}),Py=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),$y=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),Iy=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),qy=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Ny=new z({}),jy=new w({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L261"}}),Gy=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),Oy=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),Vy=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Xy=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),zy=new z({}),Qy=new w({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L268"}}),Hy=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),Uy=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),Jy=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),Yy=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Ky=new z({}),Zy=new w({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L277"}}),oL=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),rL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),tL=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),aL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),nL=new z({}),sL=new w({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L286"}}),iL=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),dL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),cL=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),fL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),mL=new z({}),gL=new w({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L293"}}),pL=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),_L=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),uL=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),bL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),vL=new z({}),FL=new w({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L302"}}),ML=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),EL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),CL=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),wL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),AL=new z({}),yL=new w({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L309"}}),xL=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),kL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),SL=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),RL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),BL=new z({}),PL=new w({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L318"}}),IL=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),qL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),NL=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),DL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),GL=new z({}),OL=new w({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/modeling_flax_auto.py#L327"}}),XL=new w({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16792/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16792/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L389"}}),zL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),QL=new w({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16792/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16792/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/pr_16792/src/transformers/models/auto/auto_factory.py#L417"}}),WL=new A({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){oe=a("meta"),co=l(),ge=a("h1"),Ae=a("a"),io=a("span"),f(ue.$$.fragment),we=l(),Xo=a("span"),Qi=o("Auto Classes"),Qf=l(),fa=a("p"),Wi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Hi=a("code"),Z5=o("from_pretrained()"),Wf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Re=l(),fo=a("p"),Ui=o("Instantiating one of "),On=a("a"),e3=o("AutoConfig"),Vn=o(", "),Xn=a("a"),o3=o("AutoModel"),Ji=o(`, and
`),zn=a("a"),r3=o("AutoTokenizer"),Yi=o(" will directly create a class of the relevant architecture. For instance"),Hf=l(),f(Da.$$.fragment),mo=l(),ve=a("p"),ex=o("will create a model that is an instance of "),Ki=a("a"),ox=o("BertModel"),rx=o("."),zo=l(),Ga=a("p"),tx=o("There is one class of "),Uf=a("code"),ax=o("AutoModel"),zNe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),RPe=l(),Zi=a("h2"),Jf=a("a"),EK=a("span"),f(t3.$$.fragment),QNe=l(),CK=a("span"),WNe=o("Extending the Auto Classes"),BPe=l(),Qn=a("p"),HNe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),wK=a("code"),UNe=o("NewModel"),JNe=o(", make sure you have a "),AK=a("code"),YNe=o("NewModelConfig"),KNe=o(` then you can add those to the auto
classes like this:`),PPe=l(),f(a3.$$.fragment),$Pe=l(),nx=a("p"),ZNe=o("You will then be able to use the auto classes like you would usually do!"),IPe=l(),f(Yf.$$.fragment),qPe=l(),ed=a("h2"),Kf=a("a"),yK=a("span"),f(n3.$$.fragment),eje=l(),LK=a("span"),oje=o("AutoConfig"),NPe=l(),Qo=a("div"),f(s3.$$.fragment),rje=l(),l3=a("p"),tje=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),sx=a("a"),aje=o("from_pretrained()"),nje=o(" class method."),sje=l(),i3=a("p"),lje=o("This class cannot be instantiated directly using "),xK=a("code"),ije=o("__init__()"),dje=o(" (throws an error)."),cje=l(),go=a("div"),f(d3.$$.fragment),fje=l(),kK=a("p"),mje=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),gje=l(),od=a("p"),hje=o("The configuration class to instantiate is selected based on the "),SK=a("code"),pje=o("model_type"),_je=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),RK=a("code"),uje=o("pretrained_model_name_or_path"),bje=o(":"),vje=l(),v=a("ul"),Zf=a("li"),BK=a("strong"),Fje=o("albert"),Tje=o(" \u2014 "),lx=a("a"),Mje=o("AlbertConfig"),Eje=o(" (ALBERT model)"),Cje=l(),em=a("li"),PK=a("strong"),wje=o("bart"),Aje=o(" \u2014 "),ix=a("a"),yje=o("BartConfig"),Lje=o(" (BART model)"),xje=l(),om=a("li"),$K=a("strong"),kje=o("beit"),Sje=o(" \u2014 "),dx=a("a"),Rje=o("BeitConfig"),Bje=o(" (BEiT model)"),Pje=l(),rm=a("li"),IK=a("strong"),$je=o("bert"),Ije=o(" \u2014 "),cx=a("a"),qje=o("BertConfig"),Nje=o(" (BERT model)"),jje=l(),tm=a("li"),qK=a("strong"),Dje=o("bert-generation"),Gje=o(" \u2014 "),fx=a("a"),Oje=o("BertGenerationConfig"),Vje=o(" (Bert Generation model)"),Xje=l(),am=a("li"),NK=a("strong"),zje=o("big_bird"),Qje=o(" \u2014 "),mx=a("a"),Wje=o("BigBirdConfig"),Hje=o(" (BigBird model)"),Uje=l(),nm=a("li"),jK=a("strong"),Jje=o("bigbird_pegasus"),Yje=o(" \u2014 "),gx=a("a"),Kje=o("BigBirdPegasusConfig"),Zje=o(" (BigBirdPegasus model)"),eDe=l(),sm=a("li"),DK=a("strong"),oDe=o("blenderbot"),rDe=o(" \u2014 "),hx=a("a"),tDe=o("BlenderbotConfig"),aDe=o(" (Blenderbot model)"),nDe=l(),lm=a("li"),GK=a("strong"),sDe=o("blenderbot-small"),lDe=o(" \u2014 "),px=a("a"),iDe=o("BlenderbotSmallConfig"),dDe=o(" (BlenderbotSmall model)"),cDe=l(),im=a("li"),OK=a("strong"),fDe=o("camembert"),mDe=o(" \u2014 "),_x=a("a"),gDe=o("CamembertConfig"),hDe=o(" (CamemBERT model)"),pDe=l(),dm=a("li"),VK=a("strong"),_De=o("canine"),uDe=o(" \u2014 "),ux=a("a"),bDe=o("CanineConfig"),vDe=o(" (Canine model)"),FDe=l(),cm=a("li"),XK=a("strong"),TDe=o("clip"),MDe=o(" \u2014 "),bx=a("a"),EDe=o("CLIPConfig"),CDe=o(" (CLIP model)"),wDe=l(),fm=a("li"),zK=a("strong"),ADe=o("convbert"),yDe=o(" \u2014 "),vx=a("a"),LDe=o("ConvBertConfig"),xDe=o(" (ConvBERT model)"),kDe=l(),mm=a("li"),QK=a("strong"),SDe=o("convnext"),RDe=o(" \u2014 "),Fx=a("a"),BDe=o("ConvNextConfig"),PDe=o(" (ConvNext model)"),$De=l(),gm=a("li"),WK=a("strong"),IDe=o("ctrl"),qDe=o(" \u2014 "),Tx=a("a"),NDe=o("CTRLConfig"),jDe=o(" (CTRL model)"),DDe=l(),hm=a("li"),HK=a("strong"),GDe=o("data2vec-audio"),ODe=o(" \u2014 "),Mx=a("a"),VDe=o("Data2VecAudioConfig"),XDe=o(" (Data2VecAudio model)"),zDe=l(),pm=a("li"),UK=a("strong"),QDe=o("data2vec-text"),WDe=o(" \u2014 "),Ex=a("a"),HDe=o("Data2VecTextConfig"),UDe=o(" (Data2VecText model)"),JDe=l(),_m=a("li"),JK=a("strong"),YDe=o("data2vec-vision"),KDe=o(" \u2014 "),Cx=a("a"),ZDe=o("Data2VecVisionConfig"),eGe=o(" (Data2VecVision model)"),oGe=l(),um=a("li"),YK=a("strong"),rGe=o("deberta"),tGe=o(" \u2014 "),wx=a("a"),aGe=o("DebertaConfig"),nGe=o(" (DeBERTa model)"),sGe=l(),bm=a("li"),KK=a("strong"),lGe=o("deberta-v2"),iGe=o(" \u2014 "),Ax=a("a"),dGe=o("DebertaV2Config"),cGe=o(" (DeBERTa-v2 model)"),fGe=l(),vm=a("li"),ZK=a("strong"),mGe=o("decision_transformer"),gGe=o(" \u2014 "),yx=a("a"),hGe=o("DecisionTransformerConfig"),pGe=o(" (Decision Transformer model)"),_Ge=l(),Fm=a("li"),eZ=a("strong"),uGe=o("deit"),bGe=o(" \u2014 "),Lx=a("a"),vGe=o("DeiTConfig"),FGe=o(" (DeiT model)"),TGe=l(),Tm=a("li"),oZ=a("strong"),MGe=o("detr"),EGe=o(" \u2014 "),xx=a("a"),CGe=o("DetrConfig"),wGe=o(" (DETR model)"),AGe=l(),Mm=a("li"),rZ=a("strong"),yGe=o("distilbert"),LGe=o(" \u2014 "),kx=a("a"),xGe=o("DistilBertConfig"),kGe=o(" (DistilBERT model)"),SGe=l(),Em=a("li"),tZ=a("strong"),RGe=o("dpr"),BGe=o(" \u2014 "),Sx=a("a"),PGe=o("DPRConfig"),$Ge=o(" (DPR model)"),IGe=l(),Cm=a("li"),aZ=a("strong"),qGe=o("dpt"),NGe=o(" \u2014 "),Rx=a("a"),jGe=o("DPTConfig"),DGe=o(" (DPT model)"),GGe=l(),wm=a("li"),nZ=a("strong"),OGe=o("electra"),VGe=o(" \u2014 "),Bx=a("a"),XGe=o("ElectraConfig"),zGe=o(" (ELECTRA model)"),QGe=l(),Am=a("li"),sZ=a("strong"),WGe=o("encoder-decoder"),HGe=o(" \u2014 "),Px=a("a"),UGe=o("EncoderDecoderConfig"),JGe=o(" (Encoder decoder model)"),YGe=l(),ym=a("li"),lZ=a("strong"),KGe=o("flaubert"),ZGe=o(" \u2014 "),$x=a("a"),eOe=o("FlaubertConfig"),oOe=o(" (FlauBERT model)"),rOe=l(),Lm=a("li"),iZ=a("strong"),tOe=o("fnet"),aOe=o(" \u2014 "),Ix=a("a"),nOe=o("FNetConfig"),sOe=o(" (FNet model)"),lOe=l(),xm=a("li"),dZ=a("strong"),iOe=o("fsmt"),dOe=o(" \u2014 "),qx=a("a"),cOe=o("FSMTConfig"),fOe=o(" (FairSeq Machine-Translation model)"),mOe=l(),km=a("li"),cZ=a("strong"),gOe=o("funnel"),hOe=o(" \u2014 "),Nx=a("a"),pOe=o("FunnelConfig"),_Oe=o(" (Funnel Transformer model)"),uOe=l(),Sm=a("li"),fZ=a("strong"),bOe=o("glpn"),vOe=o(" \u2014 "),jx=a("a"),FOe=o("GLPNConfig"),TOe=o(" (GLPN model)"),MOe=l(),Rm=a("li"),mZ=a("strong"),EOe=o("gpt2"),COe=o(" \u2014 "),Dx=a("a"),wOe=o("GPT2Config"),AOe=o(" (OpenAI GPT-2 model)"),yOe=l(),Bm=a("li"),gZ=a("strong"),LOe=o("gpt_neo"),xOe=o(" \u2014 "),Gx=a("a"),kOe=o("GPTNeoConfig"),SOe=o(" (GPT Neo model)"),ROe=l(),Pm=a("li"),hZ=a("strong"),BOe=o("gptj"),POe=o(" \u2014 "),Ox=a("a"),$Oe=o("GPTJConfig"),IOe=o(" (GPT-J model)"),qOe=l(),$m=a("li"),pZ=a("strong"),NOe=o("hubert"),jOe=o(" \u2014 "),Vx=a("a"),DOe=o("HubertConfig"),GOe=o(" (Hubert model)"),OOe=l(),Im=a("li"),_Z=a("strong"),VOe=o("ibert"),XOe=o(" \u2014 "),Xx=a("a"),zOe=o("IBertConfig"),QOe=o(" (I-BERT model)"),WOe=l(),qm=a("li"),uZ=a("strong"),HOe=o("imagegpt"),UOe=o(" \u2014 "),zx=a("a"),JOe=o("ImageGPTConfig"),YOe=o(" (ImageGPT model)"),KOe=l(),Nm=a("li"),bZ=a("strong"),ZOe=o("layoutlm"),eVe=o(" \u2014 "),Qx=a("a"),oVe=o("LayoutLMConfig"),rVe=o(" (LayoutLM model)"),tVe=l(),jm=a("li"),vZ=a("strong"),aVe=o("layoutlmv2"),nVe=o(" \u2014 "),Wx=a("a"),sVe=o("LayoutLMv2Config"),lVe=o(" (LayoutLMv2 model)"),iVe=l(),Dm=a("li"),FZ=a("strong"),dVe=o("led"),cVe=o(" \u2014 "),Hx=a("a"),fVe=o("LEDConfig"),mVe=o(" (LED model)"),gVe=l(),Gm=a("li"),TZ=a("strong"),hVe=o("longformer"),pVe=o(" \u2014 "),Ux=a("a"),_Ve=o("LongformerConfig"),uVe=o(" (Longformer model)"),bVe=l(),Om=a("li"),MZ=a("strong"),vVe=o("longt5"),FVe=o(" \u2014 "),Jx=a("a"),TVe=o("LongT5Config"),MVe=o(" (LongT5 model)"),EVe=l(),Vm=a("li"),EZ=a("strong"),CVe=o("luke"),wVe=o(" \u2014 "),Yx=a("a"),AVe=o("LukeConfig"),yVe=o(" (LUKE model)"),LVe=l(),Xm=a("li"),CZ=a("strong"),xVe=o("lxmert"),kVe=o(" \u2014 "),Kx=a("a"),SVe=o("LxmertConfig"),RVe=o(" (LXMERT model)"),BVe=l(),zm=a("li"),wZ=a("strong"),PVe=o("m2m_100"),$Ve=o(" \u2014 "),Zx=a("a"),IVe=o("M2M100Config"),qVe=o(" (M2M100 model)"),NVe=l(),Qm=a("li"),AZ=a("strong"),jVe=o("marian"),DVe=o(" \u2014 "),ek=a("a"),GVe=o("MarianConfig"),OVe=o(" (Marian model)"),VVe=l(),Wm=a("li"),yZ=a("strong"),XVe=o("maskformer"),zVe=o(" \u2014 "),ok=a("a"),QVe=o("MaskFormerConfig"),WVe=o(" (MaskFormer model)"),HVe=l(),Hm=a("li"),LZ=a("strong"),UVe=o("mbart"),JVe=o(" \u2014 "),rk=a("a"),YVe=o("MBartConfig"),KVe=o(" (mBART model)"),ZVe=l(),Um=a("li"),xZ=a("strong"),eXe=o("megatron-bert"),oXe=o(" \u2014 "),tk=a("a"),rXe=o("MegatronBertConfig"),tXe=o(" (MegatronBert model)"),aXe=l(),Jm=a("li"),kZ=a("strong"),nXe=o("mobilebert"),sXe=o(" \u2014 "),ak=a("a"),lXe=o("MobileBertConfig"),iXe=o(" (MobileBERT model)"),dXe=l(),Ym=a("li"),SZ=a("strong"),cXe=o("mpnet"),fXe=o(" \u2014 "),nk=a("a"),mXe=o("MPNetConfig"),gXe=o(" (MPNet model)"),hXe=l(),Km=a("li"),RZ=a("strong"),pXe=o("mt5"),_Xe=o(" \u2014 "),sk=a("a"),uXe=o("MT5Config"),bXe=o(" (mT5 model)"),vXe=l(),Zm=a("li"),BZ=a("strong"),FXe=o("nystromformer"),TXe=o(" \u2014 "),lk=a("a"),MXe=o("NystromformerConfig"),EXe=o(" (Nystromformer model)"),CXe=l(),eg=a("li"),PZ=a("strong"),wXe=o("openai-gpt"),AXe=o(" \u2014 "),ik=a("a"),yXe=o("OpenAIGPTConfig"),LXe=o(" (OpenAI GPT model)"),xXe=l(),og=a("li"),$Z=a("strong"),kXe=o("pegasus"),SXe=o(" \u2014 "),dk=a("a"),RXe=o("PegasusConfig"),BXe=o(" (Pegasus model)"),PXe=l(),rg=a("li"),IZ=a("strong"),$Xe=o("perceiver"),IXe=o(" \u2014 "),ck=a("a"),qXe=o("PerceiverConfig"),NXe=o(" (Perceiver model)"),jXe=l(),tg=a("li"),qZ=a("strong"),DXe=o("plbart"),GXe=o(" \u2014 "),fk=a("a"),OXe=o("PLBartConfig"),VXe=o(" (PLBart model)"),XXe=l(),ag=a("li"),NZ=a("strong"),zXe=o("poolformer"),QXe=o(" \u2014 "),mk=a("a"),WXe=o("PoolFormerConfig"),HXe=o(" (PoolFormer model)"),UXe=l(),ng=a("li"),jZ=a("strong"),JXe=o("prophetnet"),YXe=o(" \u2014 "),gk=a("a"),KXe=o("ProphetNetConfig"),ZXe=o(" (ProphetNet model)"),eze=l(),sg=a("li"),DZ=a("strong"),oze=o("qdqbert"),rze=o(" \u2014 "),hk=a("a"),tze=o("QDQBertConfig"),aze=o(" (QDQBert model)"),nze=l(),lg=a("li"),GZ=a("strong"),sze=o("rag"),lze=o(" \u2014 "),pk=a("a"),ize=o("RagConfig"),dze=o(" (RAG model)"),cze=l(),ig=a("li"),OZ=a("strong"),fze=o("realm"),mze=o(" \u2014 "),_k=a("a"),gze=o("RealmConfig"),hze=o(" (Realm model)"),pze=l(),dg=a("li"),VZ=a("strong"),_ze=o("reformer"),uze=o(" \u2014 "),uk=a("a"),bze=o("ReformerConfig"),vze=o(" (Reformer model)"),Fze=l(),cg=a("li"),XZ=a("strong"),Tze=o("regnet"),Mze=o(" \u2014 "),bk=a("a"),Eze=o("RegNetConfig"),Cze=o(" (RegNet model)"),wze=l(),fg=a("li"),zZ=a("strong"),Aze=o("rembert"),yze=o(" \u2014 "),vk=a("a"),Lze=o("RemBertConfig"),xze=o(" (RemBERT model)"),kze=l(),mg=a("li"),QZ=a("strong"),Sze=o("resnet"),Rze=o(" \u2014 "),Fk=a("a"),Bze=o("ResNetConfig"),Pze=o(" (ResNet model)"),$ze=l(),gg=a("li"),WZ=a("strong"),Ize=o("retribert"),qze=o(" \u2014 "),Tk=a("a"),Nze=o("RetriBertConfig"),jze=o(" (RetriBERT model)"),Dze=l(),hg=a("li"),HZ=a("strong"),Gze=o("roberta"),Oze=o(" \u2014 "),Mk=a("a"),Vze=o("RobertaConfig"),Xze=o(" (RoBERTa model)"),zze=l(),pg=a("li"),UZ=a("strong"),Qze=o("roformer"),Wze=o(" \u2014 "),Ek=a("a"),Hze=o("RoFormerConfig"),Uze=o(" (RoFormer model)"),Jze=l(),_g=a("li"),JZ=a("strong"),Yze=o("segformer"),Kze=o(" \u2014 "),Ck=a("a"),Zze=o("SegformerConfig"),eQe=o(" (SegFormer model)"),oQe=l(),ug=a("li"),YZ=a("strong"),rQe=o("sew"),tQe=o(" \u2014 "),wk=a("a"),aQe=o("SEWConfig"),nQe=o(" (SEW model)"),sQe=l(),bg=a("li"),KZ=a("strong"),lQe=o("sew-d"),iQe=o(" \u2014 "),Ak=a("a"),dQe=o("SEWDConfig"),cQe=o(" (SEW-D model)"),fQe=l(),vg=a("li"),ZZ=a("strong"),mQe=o("speech-encoder-decoder"),gQe=o(" \u2014 "),yk=a("a"),hQe=o("SpeechEncoderDecoderConfig"),pQe=o(" (Speech Encoder decoder model)"),_Qe=l(),Fg=a("li"),eee=a("strong"),uQe=o("speech_to_text"),bQe=o(" \u2014 "),Lk=a("a"),vQe=o("Speech2TextConfig"),FQe=o(" (Speech2Text model)"),TQe=l(),Tg=a("li"),oee=a("strong"),MQe=o("speech_to_text_2"),EQe=o(" \u2014 "),xk=a("a"),CQe=o("Speech2Text2Config"),wQe=o(" (Speech2Text2 model)"),AQe=l(),Mg=a("li"),ree=a("strong"),yQe=o("splinter"),LQe=o(" \u2014 "),kk=a("a"),xQe=o("SplinterConfig"),kQe=o(" (Splinter model)"),SQe=l(),Eg=a("li"),tee=a("strong"),RQe=o("squeezebert"),BQe=o(" \u2014 "),Sk=a("a"),PQe=o("SqueezeBertConfig"),$Qe=o(" (SqueezeBERT model)"),IQe=l(),Cg=a("li"),aee=a("strong"),qQe=o("swin"),NQe=o(" \u2014 "),Rk=a("a"),jQe=o("SwinConfig"),DQe=o(" (Swin model)"),GQe=l(),wg=a("li"),nee=a("strong"),OQe=o("t5"),VQe=o(" \u2014 "),Bk=a("a"),XQe=o("T5Config"),zQe=o(" (T5 model)"),QQe=l(),Ag=a("li"),see=a("strong"),WQe=o("tapas"),HQe=o(" \u2014 "),Pk=a("a"),UQe=o("TapasConfig"),JQe=o(" (TAPAS model)"),YQe=l(),yg=a("li"),lee=a("strong"),KQe=o("tapex"),ZQe=o(" \u2014 "),$k=a("a"),eWe=o("BartConfig"),oWe=o(" (TAPEX model)"),rWe=l(),Lg=a("li"),iee=a("strong"),tWe=o("transfo-xl"),aWe=o(" \u2014 "),Ik=a("a"),nWe=o("TransfoXLConfig"),sWe=o(" (Transformer-XL model)"),lWe=l(),xg=a("li"),dee=a("strong"),iWe=o("trocr"),dWe=o(" \u2014 "),qk=a("a"),cWe=o("TrOCRConfig"),fWe=o(" (TrOCR model)"),mWe=l(),kg=a("li"),cee=a("strong"),gWe=o("unispeech"),hWe=o(" \u2014 "),Nk=a("a"),pWe=o("UniSpeechConfig"),_We=o(" (UniSpeech model)"),uWe=l(),Sg=a("li"),fee=a("strong"),bWe=o("unispeech-sat"),vWe=o(" \u2014 "),jk=a("a"),FWe=o("UniSpeechSatConfig"),TWe=o(" (UniSpeechSat model)"),MWe=l(),Rg=a("li"),mee=a("strong"),EWe=o("van"),CWe=o(" \u2014 "),Dk=a("a"),wWe=o("VanConfig"),AWe=o(" (VAN model)"),yWe=l(),Bg=a("li"),gee=a("strong"),LWe=o("vilt"),xWe=o(" \u2014 "),Gk=a("a"),kWe=o("ViltConfig"),SWe=o(" (ViLT model)"),RWe=l(),Pg=a("li"),hee=a("strong"),BWe=o("vision-encoder-decoder"),PWe=o(" \u2014 "),Ok=a("a"),$We=o("VisionEncoderDecoderConfig"),IWe=o(" (Vision Encoder decoder model)"),qWe=l(),$g=a("li"),pee=a("strong"),NWe=o("vision-text-dual-encoder"),jWe=o(" \u2014 "),Vk=a("a"),DWe=o("VisionTextDualEncoderConfig"),GWe=o(" (VisionTextDualEncoder model)"),OWe=l(),Ig=a("li"),_ee=a("strong"),VWe=o("visual_bert"),XWe=o(" \u2014 "),Xk=a("a"),zWe=o("VisualBertConfig"),QWe=o(" (VisualBert model)"),WWe=l(),qg=a("li"),uee=a("strong"),HWe=o("vit"),UWe=o(" \u2014 "),zk=a("a"),JWe=o("ViTConfig"),YWe=o(" (ViT model)"),KWe=l(),Ng=a("li"),bee=a("strong"),ZWe=o("vit_mae"),eHe=o(" \u2014 "),Qk=a("a"),oHe=o("ViTMAEConfig"),rHe=o(" (ViTMAE model)"),tHe=l(),jg=a("li"),vee=a("strong"),aHe=o("wav2vec2"),nHe=o(" \u2014 "),Wk=a("a"),sHe=o("Wav2Vec2Config"),lHe=o(" (Wav2Vec2 model)"),iHe=l(),Dg=a("li"),Fee=a("strong"),dHe=o("wavlm"),cHe=o(" \u2014 "),Hk=a("a"),fHe=o("WavLMConfig"),mHe=o(" (WavLM model)"),gHe=l(),Gg=a("li"),Tee=a("strong"),hHe=o("xglm"),pHe=o(" \u2014 "),Uk=a("a"),_He=o("XGLMConfig"),uHe=o(" (XGLM model)"),bHe=l(),Og=a("li"),Mee=a("strong"),vHe=o("xlm"),FHe=o(" \u2014 "),Jk=a("a"),THe=o("XLMConfig"),MHe=o(" (XLM model)"),EHe=l(),Vg=a("li"),Eee=a("strong"),CHe=o("xlm-prophetnet"),wHe=o(" \u2014 "),Yk=a("a"),AHe=o("XLMProphetNetConfig"),yHe=o(" (XLMProphetNet model)"),LHe=l(),Xg=a("li"),Cee=a("strong"),xHe=o("xlm-roberta"),kHe=o(" \u2014 "),Kk=a("a"),SHe=o("XLMRobertaConfig"),RHe=o(" (XLM-RoBERTa model)"),BHe=l(),zg=a("li"),wee=a("strong"),PHe=o("xlm-roberta-xl"),$He=o(" \u2014 "),Zk=a("a"),IHe=o("XLMRobertaXLConfig"),qHe=o(" (XLM-RoBERTa-XL model)"),NHe=l(),Qg=a("li"),Aee=a("strong"),jHe=o("xlnet"),DHe=o(" \u2014 "),eS=a("a"),GHe=o("XLNetConfig"),OHe=o(" (XLNet model)"),VHe=l(),Wg=a("li"),yee=a("strong"),XHe=o("yoso"),zHe=o(" \u2014 "),oS=a("a"),QHe=o("YosoConfig"),WHe=o(" (YOSO model)"),HHe=l(),Lee=a("p"),UHe=o("Examples:"),JHe=l(),f(c3.$$.fragment),YHe=l(),Hg=a("div"),f(f3.$$.fragment),KHe=l(),xee=a("p"),ZHe=o("Register a new configuration for this class."),jPe=l(),rd=a("h2"),Ug=a("a"),kee=a("span"),f(m3.$$.fragment),eUe=l(),See=a("span"),oUe=o("AutoTokenizer"),DPe=l(),Wo=a("div"),f(g3.$$.fragment),rUe=l(),h3=a("p"),tUe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),rS=a("a"),aUe=o("AutoTokenizer.from_pretrained()"),nUe=o(" class method."),sUe=l(),p3=a("p"),lUe=o("This class cannot be instantiated directly using "),Ree=a("code"),iUe=o("__init__()"),dUe=o(" (throws an error)."),cUe=l(),ho=a("div"),f(_3.$$.fragment),fUe=l(),Bee=a("p"),mUe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),gUe=l(),Oa=a("p"),hUe=o("The tokenizer class to instantiate is selected based on the "),Pee=a("code"),pUe=o("model_type"),_Ue=o(` property of the config object (either
passed as an argument or loaded from `),$ee=a("code"),uUe=o("pretrained_model_name_or_path"),bUe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Iee=a("code"),vUe=o("pretrained_model_name_or_path"),FUe=o(":"),TUe=l(),E=a("ul"),Wn=a("li"),qee=a("strong"),MUe=o("albert"),EUe=o(" \u2014 "),tS=a("a"),CUe=o("AlbertTokenizer"),wUe=o(" or "),aS=a("a"),AUe=o("AlbertTokenizerFast"),yUe=o(" (ALBERT model)"),LUe=l(),Hn=a("li"),Nee=a("strong"),xUe=o("bart"),kUe=o(" \u2014 "),nS=a("a"),SUe=o("BartTokenizer"),RUe=o(" or "),sS=a("a"),BUe=o("BartTokenizerFast"),PUe=o(" (BART model)"),$Ue=l(),Un=a("li"),jee=a("strong"),IUe=o("barthez"),qUe=o(" \u2014 "),lS=a("a"),NUe=o("BarthezTokenizer"),jUe=o(" or "),iS=a("a"),DUe=o("BarthezTokenizerFast"),GUe=o(" (BARThez model)"),OUe=l(),Jg=a("li"),Dee=a("strong"),VUe=o("bartpho"),XUe=o(" \u2014 "),dS=a("a"),zUe=o("BartphoTokenizer"),QUe=o(" (BARTpho model)"),WUe=l(),Jn=a("li"),Gee=a("strong"),HUe=o("bert"),UUe=o(" \u2014 "),cS=a("a"),JUe=o("BertTokenizer"),YUe=o(" or "),fS=a("a"),KUe=o("BertTokenizerFast"),ZUe=o(" (BERT model)"),eJe=l(),Yg=a("li"),Oee=a("strong"),oJe=o("bert-generation"),rJe=o(" \u2014 "),mS=a("a"),tJe=o("BertGenerationTokenizer"),aJe=o(" (Bert Generation model)"),nJe=l(),Kg=a("li"),Vee=a("strong"),sJe=o("bert-japanese"),lJe=o(" \u2014 "),gS=a("a"),iJe=o("BertJapaneseTokenizer"),dJe=o(" (BertJapanese model)"),cJe=l(),Zg=a("li"),Xee=a("strong"),fJe=o("bertweet"),mJe=o(" \u2014 "),hS=a("a"),gJe=o("BertweetTokenizer"),hJe=o(" (Bertweet model)"),pJe=l(),Yn=a("li"),zee=a("strong"),_Je=o("big_bird"),uJe=o(" \u2014 "),pS=a("a"),bJe=o("BigBirdTokenizer"),vJe=o(" or "),_S=a("a"),FJe=o("BigBirdTokenizerFast"),TJe=o(" (BigBird model)"),MJe=l(),Kn=a("li"),Qee=a("strong"),EJe=o("bigbird_pegasus"),CJe=o(" \u2014 "),uS=a("a"),wJe=o("PegasusTokenizer"),AJe=o(" or "),bS=a("a"),yJe=o("PegasusTokenizerFast"),LJe=o(" (BigBirdPegasus model)"),xJe=l(),Zn=a("li"),Wee=a("strong"),kJe=o("blenderbot"),SJe=o(" \u2014 "),vS=a("a"),RJe=o("BlenderbotTokenizer"),BJe=o(" or "),FS=a("a"),PJe=o("BlenderbotTokenizerFast"),$Je=o(" (Blenderbot model)"),IJe=l(),eh=a("li"),Hee=a("strong"),qJe=o("blenderbot-small"),NJe=o(" \u2014 "),TS=a("a"),jJe=o("BlenderbotSmallTokenizer"),DJe=o(" (BlenderbotSmall model)"),GJe=l(),oh=a("li"),Uee=a("strong"),OJe=o("byt5"),VJe=o(" \u2014 "),MS=a("a"),XJe=o("ByT5Tokenizer"),zJe=o(" (ByT5 model)"),QJe=l(),es=a("li"),Jee=a("strong"),WJe=o("camembert"),HJe=o(" \u2014 "),ES=a("a"),UJe=o("CamembertTokenizer"),JJe=o(" or "),CS=a("a"),YJe=o("CamembertTokenizerFast"),KJe=o(" (CamemBERT model)"),ZJe=l(),rh=a("li"),Yee=a("strong"),eYe=o("canine"),oYe=o(" \u2014 "),wS=a("a"),rYe=o("CanineTokenizer"),tYe=o(" (Canine model)"),aYe=l(),os=a("li"),Kee=a("strong"),nYe=o("clip"),sYe=o(" \u2014 "),AS=a("a"),lYe=o("CLIPTokenizer"),iYe=o(" or "),yS=a("a"),dYe=o("CLIPTokenizerFast"),cYe=o(" (CLIP model)"),fYe=l(),rs=a("li"),Zee=a("strong"),mYe=o("convbert"),gYe=o(" \u2014 "),LS=a("a"),hYe=o("ConvBertTokenizer"),pYe=o(" or "),xS=a("a"),_Ye=o("ConvBertTokenizerFast"),uYe=o(" (ConvBERT model)"),bYe=l(),ts=a("li"),eoe=a("strong"),vYe=o("cpm"),FYe=o(" \u2014 "),kS=a("a"),TYe=o("CpmTokenizer"),MYe=o(" or "),ooe=a("code"),EYe=o("CpmTokenizerFast"),CYe=o(" (CPM model)"),wYe=l(),th=a("li"),roe=a("strong"),AYe=o("ctrl"),yYe=o(" \u2014 "),SS=a("a"),LYe=o("CTRLTokenizer"),xYe=o(" (CTRL model)"),kYe=l(),as=a("li"),toe=a("strong"),SYe=o("data2vec-text"),RYe=o(" \u2014 "),RS=a("a"),BYe=o("RobertaTokenizer"),PYe=o(" or "),BS=a("a"),$Ye=o("RobertaTokenizerFast"),IYe=o(" (Data2VecText model)"),qYe=l(),ns=a("li"),aoe=a("strong"),NYe=o("deberta"),jYe=o(" \u2014 "),PS=a("a"),DYe=o("DebertaTokenizer"),GYe=o(" or "),$S=a("a"),OYe=o("DebertaTokenizerFast"),VYe=o(" (DeBERTa model)"),XYe=l(),ss=a("li"),noe=a("strong"),zYe=o("deberta-v2"),QYe=o(" \u2014 "),IS=a("a"),WYe=o("DebertaV2Tokenizer"),HYe=o(" or "),qS=a("a"),UYe=o("DebertaV2TokenizerFast"),JYe=o(" (DeBERTa-v2 model)"),YYe=l(),ls=a("li"),soe=a("strong"),KYe=o("distilbert"),ZYe=o(" \u2014 "),NS=a("a"),eKe=o("DistilBertTokenizer"),oKe=o(" or "),jS=a("a"),rKe=o("DistilBertTokenizerFast"),tKe=o(" (DistilBERT model)"),aKe=l(),is=a("li"),loe=a("strong"),nKe=o("dpr"),sKe=o(" \u2014 "),DS=a("a"),lKe=o("DPRQuestionEncoderTokenizer"),iKe=o(" or "),GS=a("a"),dKe=o("DPRQuestionEncoderTokenizerFast"),cKe=o(" (DPR model)"),fKe=l(),ds=a("li"),ioe=a("strong"),mKe=o("electra"),gKe=o(" \u2014 "),OS=a("a"),hKe=o("ElectraTokenizer"),pKe=o(" or "),VS=a("a"),_Ke=o("ElectraTokenizerFast"),uKe=o(" (ELECTRA model)"),bKe=l(),ah=a("li"),doe=a("strong"),vKe=o("flaubert"),FKe=o(" \u2014 "),XS=a("a"),TKe=o("FlaubertTokenizer"),MKe=o(" (FlauBERT model)"),EKe=l(),cs=a("li"),coe=a("strong"),CKe=o("fnet"),wKe=o(" \u2014 "),zS=a("a"),AKe=o("FNetTokenizer"),yKe=o(" or "),QS=a("a"),LKe=o("FNetTokenizerFast"),xKe=o(" (FNet model)"),kKe=l(),nh=a("li"),foe=a("strong"),SKe=o("fsmt"),RKe=o(" \u2014 "),WS=a("a"),BKe=o("FSMTTokenizer"),PKe=o(" (FairSeq Machine-Translation model)"),$Ke=l(),fs=a("li"),moe=a("strong"),IKe=o("funnel"),qKe=o(" \u2014 "),HS=a("a"),NKe=o("FunnelTokenizer"),jKe=o(" or "),US=a("a"),DKe=o("FunnelTokenizerFast"),GKe=o(" (Funnel Transformer model)"),OKe=l(),ms=a("li"),goe=a("strong"),VKe=o("gpt2"),XKe=o(" \u2014 "),JS=a("a"),zKe=o("GPT2Tokenizer"),QKe=o(" or "),YS=a("a"),WKe=o("GPT2TokenizerFast"),HKe=o(" (OpenAI GPT-2 model)"),UKe=l(),gs=a("li"),hoe=a("strong"),JKe=o("gpt_neo"),YKe=o(" \u2014 "),KS=a("a"),KKe=o("GPT2Tokenizer"),ZKe=o(" or "),ZS=a("a"),eZe=o("GPT2TokenizerFast"),oZe=o(" (GPT Neo model)"),rZe=l(),hs=a("li"),poe=a("strong"),tZe=o("gptj"),aZe=o(" \u2014 "),eR=a("a"),nZe=o("GPT2Tokenizer"),sZe=o(" or "),oR=a("a"),lZe=o("GPT2TokenizerFast"),iZe=o(" (GPT-J model)"),dZe=l(),ps=a("li"),_oe=a("strong"),cZe=o("herbert"),fZe=o(" \u2014 "),rR=a("a"),mZe=o("HerbertTokenizer"),gZe=o(" or "),tR=a("a"),hZe=o("HerbertTokenizerFast"),pZe=o(" (HerBERT model)"),_Ze=l(),sh=a("li"),uoe=a("strong"),uZe=o("hubert"),bZe=o(" \u2014 "),aR=a("a"),vZe=o("Wav2Vec2CTCTokenizer"),FZe=o(" (Hubert model)"),TZe=l(),_s=a("li"),boe=a("strong"),MZe=o("ibert"),EZe=o(" \u2014 "),nR=a("a"),CZe=o("RobertaTokenizer"),wZe=o(" or "),sR=a("a"),AZe=o("RobertaTokenizerFast"),yZe=o(" (I-BERT model)"),LZe=l(),us=a("li"),voe=a("strong"),xZe=o("layoutlm"),kZe=o(" \u2014 "),lR=a("a"),SZe=o("LayoutLMTokenizer"),RZe=o(" or "),iR=a("a"),BZe=o("LayoutLMTokenizerFast"),PZe=o(" (LayoutLM model)"),$Ze=l(),bs=a("li"),Foe=a("strong"),IZe=o("layoutlmv2"),qZe=o(" \u2014 "),dR=a("a"),NZe=o("LayoutLMv2Tokenizer"),jZe=o(" or "),cR=a("a"),DZe=o("LayoutLMv2TokenizerFast"),GZe=o(" (LayoutLMv2 model)"),OZe=l(),vs=a("li"),Toe=a("strong"),VZe=o("layoutxlm"),XZe=o(" \u2014 "),fR=a("a"),zZe=o("LayoutXLMTokenizer"),QZe=o(" or "),mR=a("a"),WZe=o("LayoutXLMTokenizerFast"),HZe=o(" (LayoutXLM model)"),UZe=l(),Fs=a("li"),Moe=a("strong"),JZe=o("led"),YZe=o(" \u2014 "),gR=a("a"),KZe=o("LEDTokenizer"),ZZe=o(" or "),hR=a("a"),eeo=o("LEDTokenizerFast"),oeo=o(" (LED model)"),reo=l(),Ts=a("li"),Eoe=a("strong"),teo=o("longformer"),aeo=o(" \u2014 "),pR=a("a"),neo=o("LongformerTokenizer"),seo=o(" or "),_R=a("a"),leo=o("LongformerTokenizerFast"),ieo=o(" (Longformer model)"),deo=l(),Ms=a("li"),Coe=a("strong"),ceo=o("longt5"),feo=o(" \u2014 "),uR=a("a"),meo=o("T5Tokenizer"),geo=o(" or "),bR=a("a"),heo=o("T5TokenizerFast"),peo=o(" (LongT5 model)"),_eo=l(),lh=a("li"),woe=a("strong"),ueo=o("luke"),beo=o(" \u2014 "),vR=a("a"),veo=o("LukeTokenizer"),Feo=o(" (LUKE model)"),Teo=l(),Es=a("li"),Aoe=a("strong"),Meo=o("lxmert"),Eeo=o(" \u2014 "),FR=a("a"),Ceo=o("LxmertTokenizer"),weo=o(" or "),TR=a("a"),Aeo=o("LxmertTokenizerFast"),yeo=o(" (LXMERT model)"),Leo=l(),ih=a("li"),yoe=a("strong"),xeo=o("m2m_100"),keo=o(" \u2014 "),MR=a("a"),Seo=o("M2M100Tokenizer"),Reo=o(" (M2M100 model)"),Beo=l(),dh=a("li"),Loe=a("strong"),Peo=o("marian"),$eo=o(" \u2014 "),ER=a("a"),Ieo=o("MarianTokenizer"),qeo=o(" (Marian model)"),Neo=l(),Cs=a("li"),xoe=a("strong"),jeo=o("mbart"),Deo=o(" \u2014 "),CR=a("a"),Geo=o("MBartTokenizer"),Oeo=o(" or "),wR=a("a"),Veo=o("MBartTokenizerFast"),Xeo=o(" (mBART model)"),zeo=l(),ws=a("li"),koe=a("strong"),Qeo=o("mbart50"),Weo=o(" \u2014 "),AR=a("a"),Heo=o("MBart50Tokenizer"),Ueo=o(" or "),yR=a("a"),Jeo=o("MBart50TokenizerFast"),Yeo=o(" (mBART-50 model)"),Keo=l(),As=a("li"),Soe=a("strong"),Zeo=o("megatron-bert"),eoo=o(" \u2014 "),LR=a("a"),ooo=o("BertTokenizer"),roo=o(" or "),xR=a("a"),too=o("BertTokenizerFast"),aoo=o(" (MegatronBert model)"),noo=l(),ch=a("li"),Roe=a("strong"),soo=o("mluke"),loo=o(" \u2014 "),kR=a("a"),ioo=o("MLukeTokenizer"),doo=o(" (mLUKE model)"),coo=l(),ys=a("li"),Boe=a("strong"),foo=o("mobilebert"),moo=o(" \u2014 "),SR=a("a"),goo=o("MobileBertTokenizer"),hoo=o(" or "),RR=a("a"),poo=o("MobileBertTokenizerFast"),_oo=o(" (MobileBERT model)"),uoo=l(),Ls=a("li"),Poe=a("strong"),boo=o("mpnet"),voo=o(" \u2014 "),BR=a("a"),Foo=o("MPNetTokenizer"),Too=o(" or "),PR=a("a"),Moo=o("MPNetTokenizerFast"),Eoo=o(" (MPNet model)"),Coo=l(),xs=a("li"),$oe=a("strong"),woo=o("mt5"),Aoo=o(" \u2014 "),$R=a("a"),yoo=o("MT5Tokenizer"),Loo=o(" or "),IR=a("a"),xoo=o("MT5TokenizerFast"),koo=o(" (mT5 model)"),Soo=l(),ks=a("li"),Ioe=a("strong"),Roo=o("nystromformer"),Boo=o(" \u2014 "),qR=a("a"),Poo=o("AlbertTokenizer"),$oo=o(" or "),NR=a("a"),Ioo=o("AlbertTokenizerFast"),qoo=o(" (Nystromformer model)"),Noo=l(),Ss=a("li"),qoe=a("strong"),joo=o("openai-gpt"),Doo=o(" \u2014 "),jR=a("a"),Goo=o("OpenAIGPTTokenizer"),Ooo=o(" or "),DR=a("a"),Voo=o("OpenAIGPTTokenizerFast"),Xoo=o(" (OpenAI GPT model)"),zoo=l(),Rs=a("li"),Noe=a("strong"),Qoo=o("pegasus"),Woo=o(" \u2014 "),GR=a("a"),Hoo=o("PegasusTokenizer"),Uoo=o(" or "),OR=a("a"),Joo=o("PegasusTokenizerFast"),Yoo=o(" (Pegasus model)"),Koo=l(),fh=a("li"),joe=a("strong"),Zoo=o("perceiver"),ero=o(" \u2014 "),VR=a("a"),oro=o("PerceiverTokenizer"),rro=o(" (Perceiver model)"),tro=l(),mh=a("li"),Doe=a("strong"),aro=o("phobert"),nro=o(" \u2014 "),XR=a("a"),sro=o("PhobertTokenizer"),lro=o(" (PhoBERT model)"),iro=l(),gh=a("li"),Goe=a("strong"),dro=o("plbart"),cro=o(" \u2014 "),zR=a("a"),fro=o("PLBartTokenizer"),mro=o(" (PLBart model)"),gro=l(),hh=a("li"),Ooe=a("strong"),hro=o("prophetnet"),pro=o(" \u2014 "),QR=a("a"),_ro=o("ProphetNetTokenizer"),uro=o(" (ProphetNet model)"),bro=l(),Bs=a("li"),Voe=a("strong"),vro=o("qdqbert"),Fro=o(" \u2014 "),WR=a("a"),Tro=o("BertTokenizer"),Mro=o(" or "),HR=a("a"),Ero=o("BertTokenizerFast"),Cro=o(" (QDQBert model)"),wro=l(),ph=a("li"),Xoe=a("strong"),Aro=o("rag"),yro=o(" \u2014 "),UR=a("a"),Lro=o("RagTokenizer"),xro=o(" (RAG model)"),kro=l(),Ps=a("li"),zoe=a("strong"),Sro=o("realm"),Rro=o(" \u2014 "),JR=a("a"),Bro=o("RealmTokenizer"),Pro=o(" or "),YR=a("a"),$ro=o("RealmTokenizerFast"),Iro=o(" (Realm model)"),qro=l(),$s=a("li"),Qoe=a("strong"),Nro=o("reformer"),jro=o(" \u2014 "),KR=a("a"),Dro=o("ReformerTokenizer"),Gro=o(" or "),ZR=a("a"),Oro=o("ReformerTokenizerFast"),Vro=o(" (Reformer model)"),Xro=l(),Is=a("li"),Woe=a("strong"),zro=o("rembert"),Qro=o(" \u2014 "),eB=a("a"),Wro=o("RemBertTokenizer"),Hro=o(" or "),oB=a("a"),Uro=o("RemBertTokenizerFast"),Jro=o(" (RemBERT model)"),Yro=l(),qs=a("li"),Hoe=a("strong"),Kro=o("retribert"),Zro=o(" \u2014 "),rB=a("a"),eto=o("RetriBertTokenizer"),oto=o(" or "),tB=a("a"),rto=o("RetriBertTokenizerFast"),tto=o(" (RetriBERT model)"),ato=l(),Ns=a("li"),Uoe=a("strong"),nto=o("roberta"),sto=o(" \u2014 "),aB=a("a"),lto=o("RobertaTokenizer"),ito=o(" or "),nB=a("a"),dto=o("RobertaTokenizerFast"),cto=o(" (RoBERTa model)"),fto=l(),js=a("li"),Joe=a("strong"),mto=o("roformer"),gto=o(" \u2014 "),sB=a("a"),hto=o("RoFormerTokenizer"),pto=o(" or "),lB=a("a"),_to=o("RoFormerTokenizerFast"),uto=o(" (RoFormer model)"),bto=l(),_h=a("li"),Yoe=a("strong"),vto=o("speech_to_text"),Fto=o(" \u2014 "),iB=a("a"),Tto=o("Speech2TextTokenizer"),Mto=o(" (Speech2Text model)"),Eto=l(),uh=a("li"),Koe=a("strong"),Cto=o("speech_to_text_2"),wto=o(" \u2014 "),dB=a("a"),Ato=o("Speech2Text2Tokenizer"),yto=o(" (Speech2Text2 model)"),Lto=l(),Ds=a("li"),Zoe=a("strong"),xto=o("splinter"),kto=o(" \u2014 "),cB=a("a"),Sto=o("SplinterTokenizer"),Rto=o(" or "),fB=a("a"),Bto=o("SplinterTokenizerFast"),Pto=o(" (Splinter model)"),$to=l(),Gs=a("li"),ere=a("strong"),Ito=o("squeezebert"),qto=o(" \u2014 "),mB=a("a"),Nto=o("SqueezeBertTokenizer"),jto=o(" or "),gB=a("a"),Dto=o("SqueezeBertTokenizerFast"),Gto=o(" (SqueezeBERT model)"),Oto=l(),Os=a("li"),ore=a("strong"),Vto=o("t5"),Xto=o(" \u2014 "),hB=a("a"),zto=o("T5Tokenizer"),Qto=o(" or "),pB=a("a"),Wto=o("T5TokenizerFast"),Hto=o(" (T5 model)"),Uto=l(),bh=a("li"),rre=a("strong"),Jto=o("tapas"),Yto=o(" \u2014 "),_B=a("a"),Kto=o("TapasTokenizer"),Zto=o(" (TAPAS model)"),eao=l(),vh=a("li"),tre=a("strong"),oao=o("tapex"),rao=o(" \u2014 "),uB=a("a"),tao=o("TapexTokenizer"),aao=o(" (TAPEX model)"),nao=l(),Fh=a("li"),are=a("strong"),sao=o("transfo-xl"),lao=o(" \u2014 "),bB=a("a"),iao=o("TransfoXLTokenizer"),dao=o(" (Transformer-XL model)"),cao=l(),Vs=a("li"),nre=a("strong"),fao=o("visual_bert"),mao=o(" \u2014 "),vB=a("a"),gao=o("BertTokenizer"),hao=o(" or "),FB=a("a"),pao=o("BertTokenizerFast"),_ao=o(" (VisualBert model)"),uao=l(),Th=a("li"),sre=a("strong"),bao=o("wav2vec2"),vao=o(" \u2014 "),TB=a("a"),Fao=o("Wav2Vec2CTCTokenizer"),Tao=o(" (Wav2Vec2 model)"),Mao=l(),Mh=a("li"),lre=a("strong"),Eao=o("wav2vec2_phoneme"),Cao=o(" \u2014 "),MB=a("a"),wao=o("Wav2Vec2PhonemeCTCTokenizer"),Aao=o(" (Wav2Vec2Phoneme model)"),yao=l(),Xs=a("li"),ire=a("strong"),Lao=o("xglm"),xao=o(" \u2014 "),EB=a("a"),kao=o("XGLMTokenizer"),Sao=o(" or "),CB=a("a"),Rao=o("XGLMTokenizerFast"),Bao=o(" (XGLM model)"),Pao=l(),Eh=a("li"),dre=a("strong"),$ao=o("xlm"),Iao=o(" \u2014 "),wB=a("a"),qao=o("XLMTokenizer"),Nao=o(" (XLM model)"),jao=l(),Ch=a("li"),cre=a("strong"),Dao=o("xlm-prophetnet"),Gao=o(" \u2014 "),AB=a("a"),Oao=o("XLMProphetNetTokenizer"),Vao=o(" (XLMProphetNet model)"),Xao=l(),zs=a("li"),fre=a("strong"),zao=o("xlm-roberta"),Qao=o(" \u2014 "),yB=a("a"),Wao=o("XLMRobertaTokenizer"),Hao=o(" or "),LB=a("a"),Uao=o("XLMRobertaTokenizerFast"),Jao=o(" (XLM-RoBERTa model)"),Yao=l(),Qs=a("li"),mre=a("strong"),Kao=o("xlm-roberta-xl"),Zao=o(" \u2014 "),xB=a("a"),eno=o("RobertaTokenizer"),ono=o(" or "),kB=a("a"),rno=o("RobertaTokenizerFast"),tno=o(" (XLM-RoBERTa-XL model)"),ano=l(),Ws=a("li"),gre=a("strong"),nno=o("xlnet"),sno=o(" \u2014 "),SB=a("a"),lno=o("XLNetTokenizer"),ino=o(" or "),RB=a("a"),dno=o("XLNetTokenizerFast"),cno=o(" (XLNet model)"),fno=l(),Hs=a("li"),hre=a("strong"),mno=o("yoso"),gno=o(" \u2014 "),BB=a("a"),hno=o("AlbertTokenizer"),pno=o(" or "),PB=a("a"),_no=o("AlbertTokenizerFast"),uno=o(" (YOSO model)"),bno=l(),pre=a("p"),vno=o("Examples:"),Fno=l(),f(u3.$$.fragment),Tno=l(),wh=a("div"),f(b3.$$.fragment),Mno=l(),_re=a("p"),Eno=o("Register a new tokenizer in this mapping."),GPe=l(),td=a("h2"),Ah=a("a"),ure=a("span"),f(v3.$$.fragment),Cno=l(),bre=a("span"),wno=o("AutoFeatureExtractor"),OPe=l(),Ho=a("div"),f(F3.$$.fragment),Ano=l(),T3=a("p"),yno=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),$B=a("a"),Lno=o("AutoFeatureExtractor.from_pretrained()"),xno=o(" class method."),kno=l(),M3=a("p"),Sno=o("This class cannot be instantiated directly using "),vre=a("code"),Rno=o("__init__()"),Bno=o(" (throws an error)."),Pno=l(),qe=a("div"),f(E3.$$.fragment),$no=l(),Fre=a("p"),Ino=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),qno=l(),Va=a("p"),Nno=o("The feature extractor class to instantiate is selected based on the "),Tre=a("code"),jno=o("model_type"),Dno=o(` property of the config object
(either passed as an argument or loaded from `),Mre=a("code"),Gno=o("pretrained_model_name_or_path"),Ono=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ere=a("code"),Vno=o("pretrained_model_name_or_path"),Xno=o(":"),zno=l(),H=a("ul"),yh=a("li"),Cre=a("strong"),Qno=o("beit"),Wno=o(" \u2014 "),IB=a("a"),Hno=o("BeitFeatureExtractor"),Uno=o(" (BEiT model)"),Jno=l(),Lh=a("li"),wre=a("strong"),Yno=o("clip"),Kno=o(" \u2014 "),qB=a("a"),Zno=o("CLIPFeatureExtractor"),eso=o(" (CLIP model)"),oso=l(),xh=a("li"),Are=a("strong"),rso=o("convnext"),tso=o(" \u2014 "),NB=a("a"),aso=o("ConvNextFeatureExtractor"),nso=o(" (ConvNext model)"),sso=l(),kh=a("li"),yre=a("strong"),lso=o("data2vec-audio"),iso=o(" \u2014 "),jB=a("a"),dso=o("Wav2Vec2FeatureExtractor"),cso=o(" (Data2VecAudio model)"),fso=l(),Sh=a("li"),Lre=a("strong"),mso=o("data2vec-vision"),gso=o(" \u2014 "),DB=a("a"),hso=o("BeitFeatureExtractor"),pso=o(" (Data2VecVision model)"),_so=l(),Rh=a("li"),xre=a("strong"),uso=o("deit"),bso=o(" \u2014 "),GB=a("a"),vso=o("DeiTFeatureExtractor"),Fso=o(" (DeiT model)"),Tso=l(),Bh=a("li"),kre=a("strong"),Mso=o("detr"),Eso=o(" \u2014 "),OB=a("a"),Cso=o("DetrFeatureExtractor"),wso=o(" (DETR model)"),Aso=l(),Ph=a("li"),Sre=a("strong"),yso=o("dpt"),Lso=o(" \u2014 "),VB=a("a"),xso=o("DPTFeatureExtractor"),kso=o(" (DPT model)"),Sso=l(),$h=a("li"),Rre=a("strong"),Rso=o("glpn"),Bso=o(" \u2014 "),XB=a("a"),Pso=o("GLPNFeatureExtractor"),$so=o(" (GLPN model)"),Iso=l(),Ih=a("li"),Bre=a("strong"),qso=o("hubert"),Nso=o(" \u2014 "),zB=a("a"),jso=o("Wav2Vec2FeatureExtractor"),Dso=o(" (Hubert model)"),Gso=l(),qh=a("li"),Pre=a("strong"),Oso=o("layoutlmv2"),Vso=o(" \u2014 "),QB=a("a"),Xso=o("LayoutLMv2FeatureExtractor"),zso=o(" (LayoutLMv2 model)"),Qso=l(),Nh=a("li"),$re=a("strong"),Wso=o("maskformer"),Hso=o(" \u2014 "),WB=a("a"),Uso=o("MaskFormerFeatureExtractor"),Jso=o(" (MaskFormer model)"),Yso=l(),jh=a("li"),Ire=a("strong"),Kso=o("perceiver"),Zso=o(" \u2014 "),HB=a("a"),elo=o("PerceiverFeatureExtractor"),olo=o(" (Perceiver model)"),rlo=l(),Dh=a("li"),qre=a("strong"),tlo=o("poolformer"),alo=o(" \u2014 "),UB=a("a"),nlo=o("PoolFormerFeatureExtractor"),slo=o(" (PoolFormer model)"),llo=l(),Gh=a("li"),Nre=a("strong"),ilo=o("regnet"),dlo=o(" \u2014 "),JB=a("a"),clo=o("ConvNextFeatureExtractor"),flo=o(" (RegNet model)"),mlo=l(),Oh=a("li"),jre=a("strong"),glo=o("resnet"),hlo=o(" \u2014 "),YB=a("a"),plo=o("ConvNextFeatureExtractor"),_lo=o(" (ResNet model)"),ulo=l(),Vh=a("li"),Dre=a("strong"),blo=o("segformer"),vlo=o(" \u2014 "),KB=a("a"),Flo=o("SegformerFeatureExtractor"),Tlo=o(" (SegFormer model)"),Mlo=l(),Xh=a("li"),Gre=a("strong"),Elo=o("speech_to_text"),Clo=o(" \u2014 "),ZB=a("a"),wlo=o("Speech2TextFeatureExtractor"),Alo=o(" (Speech2Text model)"),ylo=l(),zh=a("li"),Ore=a("strong"),Llo=o("swin"),xlo=o(" \u2014 "),eP=a("a"),klo=o("ViTFeatureExtractor"),Slo=o(" (Swin model)"),Rlo=l(),Qh=a("li"),Vre=a("strong"),Blo=o("van"),Plo=o(" \u2014 "),oP=a("a"),$lo=o("ConvNextFeatureExtractor"),Ilo=o(" (VAN model)"),qlo=l(),Wh=a("li"),Xre=a("strong"),Nlo=o("vit"),jlo=o(" \u2014 "),rP=a("a"),Dlo=o("ViTFeatureExtractor"),Glo=o(" (ViT model)"),Olo=l(),Hh=a("li"),zre=a("strong"),Vlo=o("vit_mae"),Xlo=o(" \u2014 "),tP=a("a"),zlo=o("ViTFeatureExtractor"),Qlo=o(" (ViTMAE model)"),Wlo=l(),Uh=a("li"),Qre=a("strong"),Hlo=o("wav2vec2"),Ulo=o(" \u2014 "),aP=a("a"),Jlo=o("Wav2Vec2FeatureExtractor"),Ylo=o(" (Wav2Vec2 model)"),Klo=l(),f(Jh.$$.fragment),Zlo=l(),Wre=a("p"),eio=o("Examples:"),oio=l(),f(C3.$$.fragment),rio=l(),Yh=a("div"),f(w3.$$.fragment),tio=l(),Hre=a("p"),aio=o("Register a new feature extractor for this class."),VPe=l(),ad=a("h2"),Kh=a("a"),Ure=a("span"),f(A3.$$.fragment),nio=l(),Jre=a("span"),sio=o("AutoProcessor"),XPe=l(),Uo=a("div"),f(y3.$$.fragment),lio=l(),L3=a("p"),iio=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),nP=a("a"),dio=o("AutoProcessor.from_pretrained()"),cio=o(" class method."),fio=l(),x3=a("p"),mio=o("This class cannot be instantiated directly using "),Yre=a("code"),gio=o("__init__()"),hio=o(" (throws an error)."),pio=l(),Ne=a("div"),f(k3.$$.fragment),_io=l(),Kre=a("p"),uio=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),bio=l(),nd=a("p"),vio=o("The processor class to instantiate is selected based on the "),Zre=a("code"),Fio=o("model_type"),Tio=o(` property of the config object (either
passed as an argument or loaded from `),ete=a("code"),Mio=o("pretrained_model_name_or_path"),Eio=o(" if possible):"),Cio=l(),de=a("ul"),Zh=a("li"),ote=a("strong"),wio=o("clip"),Aio=o(" \u2014 "),sP=a("a"),yio=o("CLIPProcessor"),Lio=o(" (CLIP model)"),xio=l(),ep=a("li"),rte=a("strong"),kio=o("layoutlmv2"),Sio=o(" \u2014 "),lP=a("a"),Rio=o("LayoutLMv2Processor"),Bio=o(" (LayoutLMv2 model)"),Pio=l(),op=a("li"),tte=a("strong"),$io=o("layoutxlm"),Iio=o(" \u2014 "),iP=a("a"),qio=o("LayoutXLMProcessor"),Nio=o(" (LayoutXLM model)"),jio=l(),rp=a("li"),ate=a("strong"),Dio=o("sew"),Gio=o(" \u2014 "),dP=a("a"),Oio=o("Wav2Vec2Processor"),Vio=o(" (SEW model)"),Xio=l(),tp=a("li"),nte=a("strong"),zio=o("sew-d"),Qio=o(" \u2014 "),cP=a("a"),Wio=o("Wav2Vec2Processor"),Hio=o(" (SEW-D model)"),Uio=l(),ap=a("li"),ste=a("strong"),Jio=o("speech_to_text"),Yio=o(" \u2014 "),fP=a("a"),Kio=o("Speech2TextProcessor"),Zio=o(" (Speech2Text model)"),edo=l(),np=a("li"),lte=a("strong"),odo=o("speech_to_text_2"),rdo=o(" \u2014 "),mP=a("a"),tdo=o("Speech2Text2Processor"),ado=o(" (Speech2Text2 model)"),ndo=l(),sp=a("li"),ite=a("strong"),sdo=o("trocr"),ldo=o(" \u2014 "),gP=a("a"),ido=o("TrOCRProcessor"),ddo=o(" (TrOCR model)"),cdo=l(),lp=a("li"),dte=a("strong"),fdo=o("unispeech"),mdo=o(" \u2014 "),hP=a("a"),gdo=o("Wav2Vec2Processor"),hdo=o(" (UniSpeech model)"),pdo=l(),ip=a("li"),cte=a("strong"),_do=o("unispeech-sat"),udo=o(" \u2014 "),pP=a("a"),bdo=o("Wav2Vec2Processor"),vdo=o(" (UniSpeechSat model)"),Fdo=l(),dp=a("li"),fte=a("strong"),Tdo=o("vilt"),Mdo=o(" \u2014 "),_P=a("a"),Edo=o("ViltProcessor"),Cdo=o(" (ViLT model)"),wdo=l(),cp=a("li"),mte=a("strong"),Ado=o("vision-text-dual-encoder"),ydo=o(" \u2014 "),uP=a("a"),Ldo=o("VisionTextDualEncoderProcessor"),xdo=o(" (VisionTextDualEncoder model)"),kdo=l(),fp=a("li"),gte=a("strong"),Sdo=o("wav2vec2"),Rdo=o(" \u2014 "),bP=a("a"),Bdo=o("Wav2Vec2Processor"),Pdo=o(" (Wav2Vec2 model)"),$do=l(),mp=a("li"),hte=a("strong"),Ido=o("wavlm"),qdo=o(" \u2014 "),vP=a("a"),Ndo=o("Wav2Vec2Processor"),jdo=o(" (WavLM model)"),Ddo=l(),f(gp.$$.fragment),Gdo=l(),pte=a("p"),Odo=o("Examples:"),Vdo=l(),f(S3.$$.fragment),Xdo=l(),hp=a("div"),f(R3.$$.fragment),zdo=l(),_te=a("p"),Qdo=o("Register a new processor for this class."),zPe=l(),sd=a("h2"),pp=a("a"),ute=a("span"),f(B3.$$.fragment),Wdo=l(),bte=a("span"),Hdo=o("AutoModel"),QPe=l(),Jo=a("div"),f(P3.$$.fragment),Udo=l(),ld=a("p"),Jdo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),FP=a("a"),Ydo=o("from_pretrained()"),Kdo=o(" class method or the "),TP=a("a"),Zdo=o("from_config()"),eco=o(` class
method.`),oco=l(),$3=a("p"),rco=o("This class cannot be instantiated directly using "),vte=a("code"),tco=o("__init__()"),aco=o(" (throws an error)."),nco=l(),Xr=a("div"),f(I3.$$.fragment),sco=l(),Fte=a("p"),lco=o("Instantiates one of the base model classes of the library from a configuration."),ico=l(),id=a("p"),dco=o(`Note:
Loading a model from its configuration file does `),Tte=a("strong"),cco=o("not"),fco=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MP=a("a"),mco=o("from_pretrained()"),gco=o(" to load the model weights."),hco=l(),Mte=a("p"),pco=o("Examples:"),_co=l(),f(q3.$$.fragment),uco=l(),je=a("div"),f(N3.$$.fragment),bco=l(),Ete=a("p"),vco=o("Instantiate one of the base model classes of the library from a pretrained model."),Fco=l(),Xa=a("p"),Tco=o("The model class to instantiate is selected based on the "),Cte=a("code"),Mco=o("model_type"),Eco=o(` property of the config object (either
passed as an argument or loaded from `),wte=a("code"),Cco=o("pretrained_model_name_or_path"),wco=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ate=a("code"),Aco=o("pretrained_model_name_or_path"),yco=o(":"),Lco=l(),T=a("ul"),_p=a("li"),yte=a("strong"),xco=o("albert"),kco=o(" \u2014 "),EP=a("a"),Sco=o("AlbertModel"),Rco=o(" (ALBERT model)"),Bco=l(),up=a("li"),Lte=a("strong"),Pco=o("bart"),$co=o(" \u2014 "),CP=a("a"),Ico=o("BartModel"),qco=o(" (BART model)"),Nco=l(),bp=a("li"),xte=a("strong"),jco=o("beit"),Dco=o(" \u2014 "),wP=a("a"),Gco=o("BeitModel"),Oco=o(" (BEiT model)"),Vco=l(),vp=a("li"),kte=a("strong"),Xco=o("bert"),zco=o(" \u2014 "),AP=a("a"),Qco=o("BertModel"),Wco=o(" (BERT model)"),Hco=l(),Fp=a("li"),Ste=a("strong"),Uco=o("bert-generation"),Jco=o(" \u2014 "),yP=a("a"),Yco=o("BertGenerationEncoder"),Kco=o(" (Bert Generation model)"),Zco=l(),Tp=a("li"),Rte=a("strong"),efo=o("big_bird"),ofo=o(" \u2014 "),LP=a("a"),rfo=o("BigBirdModel"),tfo=o(" (BigBird model)"),afo=l(),Mp=a("li"),Bte=a("strong"),nfo=o("bigbird_pegasus"),sfo=o(" \u2014 "),xP=a("a"),lfo=o("BigBirdPegasusModel"),ifo=o(" (BigBirdPegasus model)"),dfo=l(),Ep=a("li"),Pte=a("strong"),cfo=o("blenderbot"),ffo=o(" \u2014 "),kP=a("a"),mfo=o("BlenderbotModel"),gfo=o(" (Blenderbot model)"),hfo=l(),Cp=a("li"),$te=a("strong"),pfo=o("blenderbot-small"),_fo=o(" \u2014 "),SP=a("a"),ufo=o("BlenderbotSmallModel"),bfo=o(" (BlenderbotSmall model)"),vfo=l(),wp=a("li"),Ite=a("strong"),Ffo=o("camembert"),Tfo=o(" \u2014 "),RP=a("a"),Mfo=o("CamembertModel"),Efo=o(" (CamemBERT model)"),Cfo=l(),Ap=a("li"),qte=a("strong"),wfo=o("canine"),Afo=o(" \u2014 "),BP=a("a"),yfo=o("CanineModel"),Lfo=o(" (Canine model)"),xfo=l(),yp=a("li"),Nte=a("strong"),kfo=o("clip"),Sfo=o(" \u2014 "),PP=a("a"),Rfo=o("CLIPModel"),Bfo=o(" (CLIP model)"),Pfo=l(),Lp=a("li"),jte=a("strong"),$fo=o("convbert"),Ifo=o(" \u2014 "),$P=a("a"),qfo=o("ConvBertModel"),Nfo=o(" (ConvBERT model)"),jfo=l(),xp=a("li"),Dte=a("strong"),Dfo=o("convnext"),Gfo=o(" \u2014 "),IP=a("a"),Ofo=o("ConvNextModel"),Vfo=o(" (ConvNext model)"),Xfo=l(),kp=a("li"),Gte=a("strong"),zfo=o("ctrl"),Qfo=o(" \u2014 "),qP=a("a"),Wfo=o("CTRLModel"),Hfo=o(" (CTRL model)"),Ufo=l(),Sp=a("li"),Ote=a("strong"),Jfo=o("data2vec-audio"),Yfo=o(" \u2014 "),NP=a("a"),Kfo=o("Data2VecAudioModel"),Zfo=o(" (Data2VecAudio model)"),emo=l(),Rp=a("li"),Vte=a("strong"),omo=o("data2vec-text"),rmo=o(" \u2014 "),jP=a("a"),tmo=o("Data2VecTextModel"),amo=o(" (Data2VecText model)"),nmo=l(),Bp=a("li"),Xte=a("strong"),smo=o("data2vec-vision"),lmo=o(" \u2014 "),DP=a("a"),imo=o("Data2VecVisionModel"),dmo=o(" (Data2VecVision model)"),cmo=l(),Pp=a("li"),zte=a("strong"),fmo=o("deberta"),mmo=o(" \u2014 "),GP=a("a"),gmo=o("DebertaModel"),hmo=o(" (DeBERTa model)"),pmo=l(),$p=a("li"),Qte=a("strong"),_mo=o("deberta-v2"),umo=o(" \u2014 "),OP=a("a"),bmo=o("DebertaV2Model"),vmo=o(" (DeBERTa-v2 model)"),Fmo=l(),Ip=a("li"),Wte=a("strong"),Tmo=o("decision_transformer"),Mmo=o(" \u2014 "),VP=a("a"),Emo=o("DecisionTransformerModel"),Cmo=o(" (Decision Transformer model)"),wmo=l(),qp=a("li"),Hte=a("strong"),Amo=o("deit"),ymo=o(" \u2014 "),XP=a("a"),Lmo=o("DeiTModel"),xmo=o(" (DeiT model)"),kmo=l(),Np=a("li"),Ute=a("strong"),Smo=o("detr"),Rmo=o(" \u2014 "),zP=a("a"),Bmo=o("DetrModel"),Pmo=o(" (DETR model)"),$mo=l(),jp=a("li"),Jte=a("strong"),Imo=o("distilbert"),qmo=o(" \u2014 "),QP=a("a"),Nmo=o("DistilBertModel"),jmo=o(" (DistilBERT model)"),Dmo=l(),Dp=a("li"),Yte=a("strong"),Gmo=o("dpr"),Omo=o(" \u2014 "),WP=a("a"),Vmo=o("DPRQuestionEncoder"),Xmo=o(" (DPR model)"),zmo=l(),Gp=a("li"),Kte=a("strong"),Qmo=o("dpt"),Wmo=o(" \u2014 "),HP=a("a"),Hmo=o("DPTModel"),Umo=o(" (DPT model)"),Jmo=l(),Op=a("li"),Zte=a("strong"),Ymo=o("electra"),Kmo=o(" \u2014 "),UP=a("a"),Zmo=o("ElectraModel"),ego=o(" (ELECTRA model)"),ogo=l(),Vp=a("li"),eae=a("strong"),rgo=o("flaubert"),tgo=o(" \u2014 "),JP=a("a"),ago=o("FlaubertModel"),ngo=o(" (FlauBERT model)"),sgo=l(),Xp=a("li"),oae=a("strong"),lgo=o("fnet"),igo=o(" \u2014 "),YP=a("a"),dgo=o("FNetModel"),cgo=o(" (FNet model)"),fgo=l(),zp=a("li"),rae=a("strong"),mgo=o("fsmt"),ggo=o(" \u2014 "),KP=a("a"),hgo=o("FSMTModel"),pgo=o(" (FairSeq Machine-Translation model)"),_go=l(),Us=a("li"),tae=a("strong"),ugo=o("funnel"),bgo=o(" \u2014 "),ZP=a("a"),vgo=o("FunnelModel"),Fgo=o(" or "),e$=a("a"),Tgo=o("FunnelBaseModel"),Mgo=o(" (Funnel Transformer model)"),Ego=l(),Qp=a("li"),aae=a("strong"),Cgo=o("glpn"),wgo=o(" \u2014 "),o$=a("a"),Ago=o("GLPNModel"),ygo=o(" (GLPN model)"),Lgo=l(),Wp=a("li"),nae=a("strong"),xgo=o("gpt2"),kgo=o(" \u2014 "),r$=a("a"),Sgo=o("GPT2Model"),Rgo=o(" (OpenAI GPT-2 model)"),Bgo=l(),Hp=a("li"),sae=a("strong"),Pgo=o("gpt_neo"),$go=o(" \u2014 "),t$=a("a"),Igo=o("GPTNeoModel"),qgo=o(" (GPT Neo model)"),Ngo=l(),Up=a("li"),lae=a("strong"),jgo=o("gptj"),Dgo=o(" \u2014 "),a$=a("a"),Ggo=o("GPTJModel"),Ogo=o(" (GPT-J model)"),Vgo=l(),Jp=a("li"),iae=a("strong"),Xgo=o("hubert"),zgo=o(" \u2014 "),n$=a("a"),Qgo=o("HubertModel"),Wgo=o(" (Hubert model)"),Hgo=l(),Yp=a("li"),dae=a("strong"),Ugo=o("ibert"),Jgo=o(" \u2014 "),s$=a("a"),Ygo=o("IBertModel"),Kgo=o(" (I-BERT model)"),Zgo=l(),Kp=a("li"),cae=a("strong"),eho=o("imagegpt"),oho=o(" \u2014 "),l$=a("a"),rho=o("ImageGPTModel"),tho=o(" (ImageGPT model)"),aho=l(),Zp=a("li"),fae=a("strong"),nho=o("layoutlm"),sho=o(" \u2014 "),i$=a("a"),lho=o("LayoutLMModel"),iho=o(" (LayoutLM model)"),dho=l(),e_=a("li"),mae=a("strong"),cho=o("layoutlmv2"),fho=o(" \u2014 "),d$=a("a"),mho=o("LayoutLMv2Model"),gho=o(" (LayoutLMv2 model)"),hho=l(),o_=a("li"),gae=a("strong"),pho=o("led"),_ho=o(" \u2014 "),c$=a("a"),uho=o("LEDModel"),bho=o(" (LED model)"),vho=l(),r_=a("li"),hae=a("strong"),Fho=o("longformer"),Tho=o(" \u2014 "),f$=a("a"),Mho=o("LongformerModel"),Eho=o(" (Longformer model)"),Cho=l(),t_=a("li"),pae=a("strong"),who=o("longt5"),Aho=o(" \u2014 "),m$=a("a"),yho=o("LongT5Model"),Lho=o(" (LongT5 model)"),xho=l(),a_=a("li"),_ae=a("strong"),kho=o("luke"),Sho=o(" \u2014 "),g$=a("a"),Rho=o("LukeModel"),Bho=o(" (LUKE model)"),Pho=l(),n_=a("li"),uae=a("strong"),$ho=o("lxmert"),Iho=o(" \u2014 "),h$=a("a"),qho=o("LxmertModel"),Nho=o(" (LXMERT model)"),jho=l(),s_=a("li"),bae=a("strong"),Dho=o("m2m_100"),Gho=o(" \u2014 "),p$=a("a"),Oho=o("M2M100Model"),Vho=o(" (M2M100 model)"),Xho=l(),l_=a("li"),vae=a("strong"),zho=o("marian"),Qho=o(" \u2014 "),_$=a("a"),Who=o("MarianModel"),Hho=o(" (Marian model)"),Uho=l(),i_=a("li"),Fae=a("strong"),Jho=o("maskformer"),Yho=o(" \u2014 "),u$=a("a"),Kho=o("MaskFormerModel"),Zho=o(" (MaskFormer model)"),epo=l(),d_=a("li"),Tae=a("strong"),opo=o("mbart"),rpo=o(" \u2014 "),b$=a("a"),tpo=o("MBartModel"),apo=o(" (mBART model)"),npo=l(),c_=a("li"),Mae=a("strong"),spo=o("megatron-bert"),lpo=o(" \u2014 "),v$=a("a"),ipo=o("MegatronBertModel"),dpo=o(" (MegatronBert model)"),cpo=l(),f_=a("li"),Eae=a("strong"),fpo=o("mobilebert"),mpo=o(" \u2014 "),F$=a("a"),gpo=o("MobileBertModel"),hpo=o(" (MobileBERT model)"),ppo=l(),m_=a("li"),Cae=a("strong"),_po=o("mpnet"),upo=o(" \u2014 "),T$=a("a"),bpo=o("MPNetModel"),vpo=o(" (MPNet model)"),Fpo=l(),g_=a("li"),wae=a("strong"),Tpo=o("mt5"),Mpo=o(" \u2014 "),M$=a("a"),Epo=o("MT5Model"),Cpo=o(" (mT5 model)"),wpo=l(),h_=a("li"),Aae=a("strong"),Apo=o("nystromformer"),ypo=o(" \u2014 "),E$=a("a"),Lpo=o("NystromformerModel"),xpo=o(" (Nystromformer model)"),kpo=l(),p_=a("li"),yae=a("strong"),Spo=o("openai-gpt"),Rpo=o(" \u2014 "),C$=a("a"),Bpo=o("OpenAIGPTModel"),Ppo=o(" (OpenAI GPT model)"),$po=l(),__=a("li"),Lae=a("strong"),Ipo=o("pegasus"),qpo=o(" \u2014 "),w$=a("a"),Npo=o("PegasusModel"),jpo=o(" (Pegasus model)"),Dpo=l(),u_=a("li"),xae=a("strong"),Gpo=o("perceiver"),Opo=o(" \u2014 "),A$=a("a"),Vpo=o("PerceiverModel"),Xpo=o(" (Perceiver model)"),zpo=l(),b_=a("li"),kae=a("strong"),Qpo=o("plbart"),Wpo=o(" \u2014 "),y$=a("a"),Hpo=o("PLBartModel"),Upo=o(" (PLBart model)"),Jpo=l(),v_=a("li"),Sae=a("strong"),Ypo=o("poolformer"),Kpo=o(" \u2014 "),L$=a("a"),Zpo=o("PoolFormerModel"),e_o=o(" (PoolFormer model)"),o_o=l(),F_=a("li"),Rae=a("strong"),r_o=o("prophetnet"),t_o=o(" \u2014 "),x$=a("a"),a_o=o("ProphetNetModel"),n_o=o(" (ProphetNet model)"),s_o=l(),T_=a("li"),Bae=a("strong"),l_o=o("qdqbert"),i_o=o(" \u2014 "),k$=a("a"),d_o=o("QDQBertModel"),c_o=o(" (QDQBert model)"),f_o=l(),M_=a("li"),Pae=a("strong"),m_o=o("reformer"),g_o=o(" \u2014 "),S$=a("a"),h_o=o("ReformerModel"),p_o=o(" (Reformer model)"),__o=l(),E_=a("li"),$ae=a("strong"),u_o=o("regnet"),b_o=o(" \u2014 "),R$=a("a"),v_o=o("RegNetModel"),F_o=o(" (RegNet model)"),T_o=l(),C_=a("li"),Iae=a("strong"),M_o=o("rembert"),E_o=o(" \u2014 "),B$=a("a"),C_o=o("RemBertModel"),w_o=o(" (RemBERT model)"),A_o=l(),w_=a("li"),qae=a("strong"),y_o=o("resnet"),L_o=o(" \u2014 "),P$=a("a"),x_o=o("ResNetModel"),k_o=o(" (ResNet model)"),S_o=l(),A_=a("li"),Nae=a("strong"),R_o=o("retribert"),B_o=o(" \u2014 "),$$=a("a"),P_o=o("RetriBertModel"),$_o=o(" (RetriBERT model)"),I_o=l(),y_=a("li"),jae=a("strong"),q_o=o("roberta"),N_o=o(" \u2014 "),I$=a("a"),j_o=o("RobertaModel"),D_o=o(" (RoBERTa model)"),G_o=l(),L_=a("li"),Dae=a("strong"),O_o=o("roformer"),V_o=o(" \u2014 "),q$=a("a"),X_o=o("RoFormerModel"),z_o=o(" (RoFormer model)"),Q_o=l(),x_=a("li"),Gae=a("strong"),W_o=o("segformer"),H_o=o(" \u2014 "),N$=a("a"),U_o=o("SegformerModel"),J_o=o(" (SegFormer model)"),Y_o=l(),k_=a("li"),Oae=a("strong"),K_o=o("sew"),Z_o=o(" \u2014 "),j$=a("a"),euo=o("SEWModel"),ouo=o(" (SEW model)"),ruo=l(),S_=a("li"),Vae=a("strong"),tuo=o("sew-d"),auo=o(" \u2014 "),D$=a("a"),nuo=o("SEWDModel"),suo=o(" (SEW-D model)"),luo=l(),R_=a("li"),Xae=a("strong"),iuo=o("speech_to_text"),duo=o(" \u2014 "),G$=a("a"),cuo=o("Speech2TextModel"),fuo=o(" (Speech2Text model)"),muo=l(),B_=a("li"),zae=a("strong"),guo=o("splinter"),huo=o(" \u2014 "),O$=a("a"),puo=o("SplinterModel"),_uo=o(" (Splinter model)"),uuo=l(),P_=a("li"),Qae=a("strong"),buo=o("squeezebert"),vuo=o(" \u2014 "),V$=a("a"),Fuo=o("SqueezeBertModel"),Tuo=o(" (SqueezeBERT model)"),Muo=l(),$_=a("li"),Wae=a("strong"),Euo=o("swin"),Cuo=o(" \u2014 "),X$=a("a"),wuo=o("SwinModel"),Auo=o(" (Swin model)"),yuo=l(),I_=a("li"),Hae=a("strong"),Luo=o("t5"),xuo=o(" \u2014 "),z$=a("a"),kuo=o("T5Model"),Suo=o(" (T5 model)"),Ruo=l(),q_=a("li"),Uae=a("strong"),Buo=o("tapas"),Puo=o(" \u2014 "),Q$=a("a"),$uo=o("TapasModel"),Iuo=o(" (TAPAS model)"),quo=l(),N_=a("li"),Jae=a("strong"),Nuo=o("transfo-xl"),juo=o(" \u2014 "),W$=a("a"),Duo=o("TransfoXLModel"),Guo=o(" (Transformer-XL model)"),Ouo=l(),j_=a("li"),Yae=a("strong"),Vuo=o("unispeech"),Xuo=o(" \u2014 "),H$=a("a"),zuo=o("UniSpeechModel"),Quo=o(" (UniSpeech model)"),Wuo=l(),D_=a("li"),Kae=a("strong"),Huo=o("unispeech-sat"),Uuo=o(" \u2014 "),U$=a("a"),Juo=o("UniSpeechSatModel"),Yuo=o(" (UniSpeechSat model)"),Kuo=l(),G_=a("li"),Zae=a("strong"),Zuo=o("van"),e2o=o(" \u2014 "),J$=a("a"),o2o=o("VanModel"),r2o=o(" (VAN model)"),t2o=l(),O_=a("li"),ene=a("strong"),a2o=o("vilt"),n2o=o(" \u2014 "),Y$=a("a"),s2o=o("ViltModel"),l2o=o(" (ViLT model)"),i2o=l(),V_=a("li"),one=a("strong"),d2o=o("vision-text-dual-encoder"),c2o=o(" \u2014 "),K$=a("a"),f2o=o("VisionTextDualEncoderModel"),m2o=o(" (VisionTextDualEncoder model)"),g2o=l(),X_=a("li"),rne=a("strong"),h2o=o("visual_bert"),p2o=o(" \u2014 "),Z$=a("a"),_2o=o("VisualBertModel"),u2o=o(" (VisualBert model)"),b2o=l(),z_=a("li"),tne=a("strong"),v2o=o("vit"),F2o=o(" \u2014 "),eI=a("a"),T2o=o("ViTModel"),M2o=o(" (ViT model)"),E2o=l(),Q_=a("li"),ane=a("strong"),C2o=o("vit_mae"),w2o=o(" \u2014 "),oI=a("a"),A2o=o("ViTMAEModel"),y2o=o(" (ViTMAE model)"),L2o=l(),W_=a("li"),nne=a("strong"),x2o=o("wav2vec2"),k2o=o(" \u2014 "),rI=a("a"),S2o=o("Wav2Vec2Model"),R2o=o(" (Wav2Vec2 model)"),B2o=l(),H_=a("li"),sne=a("strong"),P2o=o("wavlm"),$2o=o(" \u2014 "),tI=a("a"),I2o=o("WavLMModel"),q2o=o(" (WavLM model)"),N2o=l(),U_=a("li"),lne=a("strong"),j2o=o("xglm"),D2o=o(" \u2014 "),aI=a("a"),G2o=o("XGLMModel"),O2o=o(" (XGLM model)"),V2o=l(),J_=a("li"),ine=a("strong"),X2o=o("xlm"),z2o=o(" \u2014 "),nI=a("a"),Q2o=o("XLMModel"),W2o=o(" (XLM model)"),H2o=l(),Y_=a("li"),dne=a("strong"),U2o=o("xlm-prophetnet"),J2o=o(" \u2014 "),sI=a("a"),Y2o=o("XLMProphetNetModel"),K2o=o(" (XLMProphetNet model)"),Z2o=l(),K_=a("li"),cne=a("strong"),e1o=o("xlm-roberta"),o1o=o(" \u2014 "),lI=a("a"),r1o=o("XLMRobertaModel"),t1o=o(" (XLM-RoBERTa model)"),a1o=l(),Z_=a("li"),fne=a("strong"),n1o=o("xlm-roberta-xl"),s1o=o(" \u2014 "),iI=a("a"),l1o=o("XLMRobertaXLModel"),i1o=o(" (XLM-RoBERTa-XL model)"),d1o=l(),eu=a("li"),mne=a("strong"),c1o=o("xlnet"),f1o=o(" \u2014 "),dI=a("a"),m1o=o("XLNetModel"),g1o=o(" (XLNet model)"),h1o=l(),ou=a("li"),gne=a("strong"),p1o=o("yoso"),_1o=o(" \u2014 "),cI=a("a"),u1o=o("YosoModel"),b1o=o(" (YOSO model)"),v1o=l(),ru=a("p"),F1o=o("The model is set in evaluation mode by default using "),hne=a("code"),T1o=o("model.eval()"),M1o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pne=a("code"),E1o=o("model.train()"),C1o=l(),_ne=a("p"),w1o=o("Examples:"),A1o=l(),f(j3.$$.fragment),WPe=l(),dd=a("h2"),tu=a("a"),une=a("span"),f(D3.$$.fragment),y1o=l(),bne=a("span"),L1o=o("AutoModelForPreTraining"),HPe=l(),Yo=a("div"),f(G3.$$.fragment),x1o=l(),cd=a("p"),k1o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),fI=a("a"),S1o=o("from_pretrained()"),R1o=o(" class method or the "),mI=a("a"),B1o=o("from_config()"),P1o=o(` class
method.`),$1o=l(),O3=a("p"),I1o=o("This class cannot be instantiated directly using "),vne=a("code"),q1o=o("__init__()"),N1o=o(" (throws an error)."),j1o=l(),zr=a("div"),f(V3.$$.fragment),D1o=l(),Fne=a("p"),G1o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),O1o=l(),fd=a("p"),V1o=o(`Note:
Loading a model from its configuration file does `),Tne=a("strong"),X1o=o("not"),z1o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gI=a("a"),Q1o=o("from_pretrained()"),W1o=o(" to load the model weights."),H1o=l(),Mne=a("p"),U1o=o("Examples:"),J1o=l(),f(X3.$$.fragment),Y1o=l(),De=a("div"),f(z3.$$.fragment),K1o=l(),Ene=a("p"),Z1o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ebo=l(),za=a("p"),obo=o("The model class to instantiate is selected based on the "),Cne=a("code"),rbo=o("model_type"),tbo=o(` property of the config object (either
passed as an argument or loaded from `),wne=a("code"),abo=o("pretrained_model_name_or_path"),nbo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ane=a("code"),sbo=o("pretrained_model_name_or_path"),lbo=o(":"),ibo=l(),S=a("ul"),au=a("li"),yne=a("strong"),dbo=o("albert"),cbo=o(" \u2014 "),hI=a("a"),fbo=o("AlbertForPreTraining"),mbo=o(" (ALBERT model)"),gbo=l(),nu=a("li"),Lne=a("strong"),hbo=o("bart"),pbo=o(" \u2014 "),pI=a("a"),_bo=o("BartForConditionalGeneration"),ubo=o(" (BART model)"),bbo=l(),su=a("li"),xne=a("strong"),vbo=o("bert"),Fbo=o(" \u2014 "),_I=a("a"),Tbo=o("BertForPreTraining"),Mbo=o(" (BERT model)"),Ebo=l(),lu=a("li"),kne=a("strong"),Cbo=o("big_bird"),wbo=o(" \u2014 "),uI=a("a"),Abo=o("BigBirdForPreTraining"),ybo=o(" (BigBird model)"),Lbo=l(),iu=a("li"),Sne=a("strong"),xbo=o("camembert"),kbo=o(" \u2014 "),bI=a("a"),Sbo=o("CamembertForMaskedLM"),Rbo=o(" (CamemBERT model)"),Bbo=l(),du=a("li"),Rne=a("strong"),Pbo=o("ctrl"),$bo=o(" \u2014 "),vI=a("a"),Ibo=o("CTRLLMHeadModel"),qbo=o(" (CTRL model)"),Nbo=l(),cu=a("li"),Bne=a("strong"),jbo=o("data2vec-text"),Dbo=o(" \u2014 "),FI=a("a"),Gbo=o("Data2VecTextForMaskedLM"),Obo=o(" (Data2VecText model)"),Vbo=l(),fu=a("li"),Pne=a("strong"),Xbo=o("deberta"),zbo=o(" \u2014 "),TI=a("a"),Qbo=o("DebertaForMaskedLM"),Wbo=o(" (DeBERTa model)"),Hbo=l(),mu=a("li"),$ne=a("strong"),Ubo=o("deberta-v2"),Jbo=o(" \u2014 "),MI=a("a"),Ybo=o("DebertaV2ForMaskedLM"),Kbo=o(" (DeBERTa-v2 model)"),Zbo=l(),gu=a("li"),Ine=a("strong"),e6o=o("distilbert"),o6o=o(" \u2014 "),EI=a("a"),r6o=o("DistilBertForMaskedLM"),t6o=o(" (DistilBERT model)"),a6o=l(),hu=a("li"),qne=a("strong"),n6o=o("electra"),s6o=o(" \u2014 "),CI=a("a"),l6o=o("ElectraForPreTraining"),i6o=o(" (ELECTRA model)"),d6o=l(),pu=a("li"),Nne=a("strong"),c6o=o("flaubert"),f6o=o(" \u2014 "),wI=a("a"),m6o=o("FlaubertWithLMHeadModel"),g6o=o(" (FlauBERT model)"),h6o=l(),_u=a("li"),jne=a("strong"),p6o=o("fnet"),_6o=o(" \u2014 "),AI=a("a"),u6o=o("FNetForPreTraining"),b6o=o(" (FNet model)"),v6o=l(),uu=a("li"),Dne=a("strong"),F6o=o("fsmt"),T6o=o(" \u2014 "),yI=a("a"),M6o=o("FSMTForConditionalGeneration"),E6o=o(" (FairSeq Machine-Translation model)"),C6o=l(),bu=a("li"),Gne=a("strong"),w6o=o("funnel"),A6o=o(" \u2014 "),LI=a("a"),y6o=o("FunnelForPreTraining"),L6o=o(" (Funnel Transformer model)"),x6o=l(),vu=a("li"),One=a("strong"),k6o=o("gpt2"),S6o=o(" \u2014 "),xI=a("a"),R6o=o("GPT2LMHeadModel"),B6o=o(" (OpenAI GPT-2 model)"),P6o=l(),Fu=a("li"),Vne=a("strong"),$6o=o("ibert"),I6o=o(" \u2014 "),kI=a("a"),q6o=o("IBertForMaskedLM"),N6o=o(" (I-BERT model)"),j6o=l(),Tu=a("li"),Xne=a("strong"),D6o=o("layoutlm"),G6o=o(" \u2014 "),SI=a("a"),O6o=o("LayoutLMForMaskedLM"),V6o=o(" (LayoutLM model)"),X6o=l(),Mu=a("li"),zne=a("strong"),z6o=o("longformer"),Q6o=o(" \u2014 "),RI=a("a"),W6o=o("LongformerForMaskedLM"),H6o=o(" (Longformer model)"),U6o=l(),Eu=a("li"),Qne=a("strong"),J6o=o("longt5"),Y6o=o(" \u2014 "),BI=a("a"),K6o=o("LongT5ForConditionalGeneration"),Z6o=o(" (LongT5 model)"),evo=l(),Cu=a("li"),Wne=a("strong"),ovo=o("lxmert"),rvo=o(" \u2014 "),PI=a("a"),tvo=o("LxmertForPreTraining"),avo=o(" (LXMERT model)"),nvo=l(),wu=a("li"),Hne=a("strong"),svo=o("megatron-bert"),lvo=o(" \u2014 "),$I=a("a"),ivo=o("MegatronBertForPreTraining"),dvo=o(" (MegatronBert model)"),cvo=l(),Au=a("li"),Une=a("strong"),fvo=o("mobilebert"),mvo=o(" \u2014 "),II=a("a"),gvo=o("MobileBertForPreTraining"),hvo=o(" (MobileBERT model)"),pvo=l(),yu=a("li"),Jne=a("strong"),_vo=o("mpnet"),uvo=o(" \u2014 "),qI=a("a"),bvo=o("MPNetForMaskedLM"),vvo=o(" (MPNet model)"),Fvo=l(),Lu=a("li"),Yne=a("strong"),Tvo=o("openai-gpt"),Mvo=o(" \u2014 "),NI=a("a"),Evo=o("OpenAIGPTLMHeadModel"),Cvo=o(" (OpenAI GPT model)"),wvo=l(),xu=a("li"),Kne=a("strong"),Avo=o("retribert"),yvo=o(" \u2014 "),jI=a("a"),Lvo=o("RetriBertModel"),xvo=o(" (RetriBERT model)"),kvo=l(),ku=a("li"),Zne=a("strong"),Svo=o("roberta"),Rvo=o(" \u2014 "),DI=a("a"),Bvo=o("RobertaForMaskedLM"),Pvo=o(" (RoBERTa model)"),$vo=l(),Su=a("li"),ese=a("strong"),Ivo=o("squeezebert"),qvo=o(" \u2014 "),GI=a("a"),Nvo=o("SqueezeBertForMaskedLM"),jvo=o(" (SqueezeBERT model)"),Dvo=l(),Ru=a("li"),ose=a("strong"),Gvo=o("t5"),Ovo=o(" \u2014 "),OI=a("a"),Vvo=o("T5ForConditionalGeneration"),Xvo=o(" (T5 model)"),zvo=l(),Bu=a("li"),rse=a("strong"),Qvo=o("tapas"),Wvo=o(" \u2014 "),VI=a("a"),Hvo=o("TapasForMaskedLM"),Uvo=o(" (TAPAS model)"),Jvo=l(),Pu=a("li"),tse=a("strong"),Yvo=o("transfo-xl"),Kvo=o(" \u2014 "),XI=a("a"),Zvo=o("TransfoXLLMHeadModel"),eFo=o(" (Transformer-XL model)"),oFo=l(),$u=a("li"),ase=a("strong"),rFo=o("unispeech"),tFo=o(" \u2014 "),zI=a("a"),aFo=o("UniSpeechForPreTraining"),nFo=o(" (UniSpeech model)"),sFo=l(),Iu=a("li"),nse=a("strong"),lFo=o("unispeech-sat"),iFo=o(" \u2014 "),QI=a("a"),dFo=o("UniSpeechSatForPreTraining"),cFo=o(" (UniSpeechSat model)"),fFo=l(),qu=a("li"),sse=a("strong"),mFo=o("visual_bert"),gFo=o(" \u2014 "),WI=a("a"),hFo=o("VisualBertForPreTraining"),pFo=o(" (VisualBert model)"),_Fo=l(),Nu=a("li"),lse=a("strong"),uFo=o("vit_mae"),bFo=o(" \u2014 "),HI=a("a"),vFo=o("ViTMAEForPreTraining"),FFo=o(" (ViTMAE model)"),TFo=l(),ju=a("li"),ise=a("strong"),MFo=o("wav2vec2"),EFo=o(" \u2014 "),UI=a("a"),CFo=o("Wav2Vec2ForPreTraining"),wFo=o(" (Wav2Vec2 model)"),AFo=l(),Du=a("li"),dse=a("strong"),yFo=o("xlm"),LFo=o(" \u2014 "),JI=a("a"),xFo=o("XLMWithLMHeadModel"),kFo=o(" (XLM model)"),SFo=l(),Gu=a("li"),cse=a("strong"),RFo=o("xlm-roberta"),BFo=o(" \u2014 "),YI=a("a"),PFo=o("XLMRobertaForMaskedLM"),$Fo=o(" (XLM-RoBERTa model)"),IFo=l(),Ou=a("li"),fse=a("strong"),qFo=o("xlm-roberta-xl"),NFo=o(" \u2014 "),KI=a("a"),jFo=o("XLMRobertaXLForMaskedLM"),DFo=o(" (XLM-RoBERTa-XL model)"),GFo=l(),Vu=a("li"),mse=a("strong"),OFo=o("xlnet"),VFo=o(" \u2014 "),ZI=a("a"),XFo=o("XLNetLMHeadModel"),zFo=o(" (XLNet model)"),QFo=l(),Xu=a("p"),WFo=o("The model is set in evaluation mode by default using "),gse=a("code"),HFo=o("model.eval()"),UFo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hse=a("code"),JFo=o("model.train()"),YFo=l(),pse=a("p"),KFo=o("Examples:"),ZFo=l(),f(Q3.$$.fragment),UPe=l(),md=a("h2"),zu=a("a"),_se=a("span"),f(W3.$$.fragment),eTo=l(),use=a("span"),oTo=o("AutoModelForCausalLM"),JPe=l(),Ko=a("div"),f(H3.$$.fragment),rTo=l(),gd=a("p"),tTo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),eq=a("a"),aTo=o("from_pretrained()"),nTo=o(" class method or the "),oq=a("a"),sTo=o("from_config()"),lTo=o(` class
method.`),iTo=l(),U3=a("p"),dTo=o("This class cannot be instantiated directly using "),bse=a("code"),cTo=o("__init__()"),fTo=o(" (throws an error)."),mTo=l(),Qr=a("div"),f(J3.$$.fragment),gTo=l(),vse=a("p"),hTo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),pTo=l(),hd=a("p"),_To=o(`Note:
Loading a model from its configuration file does `),Fse=a("strong"),uTo=o("not"),bTo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rq=a("a"),vTo=o("from_pretrained()"),FTo=o(" to load the model weights."),TTo=l(),Tse=a("p"),MTo=o("Examples:"),ETo=l(),f(Y3.$$.fragment),CTo=l(),Ge=a("div"),f(K3.$$.fragment),wTo=l(),Mse=a("p"),ATo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),yTo=l(),Qa=a("p"),LTo=o("The model class to instantiate is selected based on the "),Ese=a("code"),xTo=o("model_type"),kTo=o(` property of the config object (either
passed as an argument or loaded from `),Cse=a("code"),STo=o("pretrained_model_name_or_path"),RTo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wse=a("code"),BTo=o("pretrained_model_name_or_path"),PTo=o(":"),$To=l(),$=a("ul"),Qu=a("li"),Ase=a("strong"),ITo=o("bart"),qTo=o(" \u2014 "),tq=a("a"),NTo=o("BartForCausalLM"),jTo=o(" (BART model)"),DTo=l(),Wu=a("li"),yse=a("strong"),GTo=o("bert"),OTo=o(" \u2014 "),aq=a("a"),VTo=o("BertLMHeadModel"),XTo=o(" (BERT model)"),zTo=l(),Hu=a("li"),Lse=a("strong"),QTo=o("bert-generation"),WTo=o(" \u2014 "),nq=a("a"),HTo=o("BertGenerationDecoder"),UTo=o(" (Bert Generation model)"),JTo=l(),Uu=a("li"),xse=a("strong"),YTo=o("big_bird"),KTo=o(" \u2014 "),sq=a("a"),ZTo=o("BigBirdForCausalLM"),e7o=o(" (BigBird model)"),o7o=l(),Ju=a("li"),kse=a("strong"),r7o=o("bigbird_pegasus"),t7o=o(" \u2014 "),lq=a("a"),a7o=o("BigBirdPegasusForCausalLM"),n7o=o(" (BigBirdPegasus model)"),s7o=l(),Yu=a("li"),Sse=a("strong"),l7o=o("blenderbot"),i7o=o(" \u2014 "),iq=a("a"),d7o=o("BlenderbotForCausalLM"),c7o=o(" (Blenderbot model)"),f7o=l(),Ku=a("li"),Rse=a("strong"),m7o=o("blenderbot-small"),g7o=o(" \u2014 "),dq=a("a"),h7o=o("BlenderbotSmallForCausalLM"),p7o=o(" (BlenderbotSmall model)"),_7o=l(),Zu=a("li"),Bse=a("strong"),u7o=o("camembert"),b7o=o(" \u2014 "),cq=a("a"),v7o=o("CamembertForCausalLM"),F7o=o(" (CamemBERT model)"),T7o=l(),e2=a("li"),Pse=a("strong"),M7o=o("ctrl"),E7o=o(" \u2014 "),fq=a("a"),C7o=o("CTRLLMHeadModel"),w7o=o(" (CTRL model)"),A7o=l(),o2=a("li"),$se=a("strong"),y7o=o("data2vec-text"),L7o=o(" \u2014 "),mq=a("a"),x7o=o("Data2VecTextForCausalLM"),k7o=o(" (Data2VecText model)"),S7o=l(),r2=a("li"),Ise=a("strong"),R7o=o("electra"),B7o=o(" \u2014 "),gq=a("a"),P7o=o("ElectraForCausalLM"),$7o=o(" (ELECTRA model)"),I7o=l(),t2=a("li"),qse=a("strong"),q7o=o("gpt2"),N7o=o(" \u2014 "),hq=a("a"),j7o=o("GPT2LMHeadModel"),D7o=o(" (OpenAI GPT-2 model)"),G7o=l(),a2=a("li"),Nse=a("strong"),O7o=o("gpt_neo"),V7o=o(" \u2014 "),pq=a("a"),X7o=o("GPTNeoForCausalLM"),z7o=o(" (GPT Neo model)"),Q7o=l(),n2=a("li"),jse=a("strong"),W7o=o("gptj"),H7o=o(" \u2014 "),_q=a("a"),U7o=o("GPTJForCausalLM"),J7o=o(" (GPT-J model)"),Y7o=l(),s2=a("li"),Dse=a("strong"),K7o=o("marian"),Z7o=o(" \u2014 "),uq=a("a"),e9o=o("MarianForCausalLM"),o9o=o(" (Marian model)"),r9o=l(),l2=a("li"),Gse=a("strong"),t9o=o("mbart"),a9o=o(" \u2014 "),bq=a("a"),n9o=o("MBartForCausalLM"),s9o=o(" (mBART model)"),l9o=l(),i2=a("li"),Ose=a("strong"),i9o=o("megatron-bert"),d9o=o(" \u2014 "),vq=a("a"),c9o=o("MegatronBertForCausalLM"),f9o=o(" (MegatronBert model)"),m9o=l(),d2=a("li"),Vse=a("strong"),g9o=o("openai-gpt"),h9o=o(" \u2014 "),Fq=a("a"),p9o=o("OpenAIGPTLMHeadModel"),_9o=o(" (OpenAI GPT model)"),u9o=l(),c2=a("li"),Xse=a("strong"),b9o=o("pegasus"),v9o=o(" \u2014 "),Tq=a("a"),F9o=o("PegasusForCausalLM"),T9o=o(" (Pegasus model)"),M9o=l(),f2=a("li"),zse=a("strong"),E9o=o("plbart"),C9o=o(" \u2014 "),Mq=a("a"),w9o=o("PLBartForCausalLM"),A9o=o(" (PLBart model)"),y9o=l(),m2=a("li"),Qse=a("strong"),L9o=o("prophetnet"),x9o=o(" \u2014 "),Eq=a("a"),k9o=o("ProphetNetForCausalLM"),S9o=o(" (ProphetNet model)"),R9o=l(),g2=a("li"),Wse=a("strong"),B9o=o("qdqbert"),P9o=o(" \u2014 "),Cq=a("a"),$9o=o("QDQBertLMHeadModel"),I9o=o(" (QDQBert model)"),q9o=l(),h2=a("li"),Hse=a("strong"),N9o=o("reformer"),j9o=o(" \u2014 "),wq=a("a"),D9o=o("ReformerModelWithLMHead"),G9o=o(" (Reformer model)"),O9o=l(),p2=a("li"),Use=a("strong"),V9o=o("rembert"),X9o=o(" \u2014 "),Aq=a("a"),z9o=o("RemBertForCausalLM"),Q9o=o(" (RemBERT model)"),W9o=l(),_2=a("li"),Jse=a("strong"),H9o=o("roberta"),U9o=o(" \u2014 "),yq=a("a"),J9o=o("RobertaForCausalLM"),Y9o=o(" (RoBERTa model)"),K9o=l(),u2=a("li"),Yse=a("strong"),Z9o=o("roformer"),eMo=o(" \u2014 "),Lq=a("a"),oMo=o("RoFormerForCausalLM"),rMo=o(" (RoFormer model)"),tMo=l(),b2=a("li"),Kse=a("strong"),aMo=o("speech_to_text_2"),nMo=o(" \u2014 "),xq=a("a"),sMo=o("Speech2Text2ForCausalLM"),lMo=o(" (Speech2Text2 model)"),iMo=l(),v2=a("li"),Zse=a("strong"),dMo=o("transfo-xl"),cMo=o(" \u2014 "),kq=a("a"),fMo=o("TransfoXLLMHeadModel"),mMo=o(" (Transformer-XL model)"),gMo=l(),F2=a("li"),ele=a("strong"),hMo=o("trocr"),pMo=o(" \u2014 "),Sq=a("a"),_Mo=o("TrOCRForCausalLM"),uMo=o(" (TrOCR model)"),bMo=l(),T2=a("li"),ole=a("strong"),vMo=o("xglm"),FMo=o(" \u2014 "),Rq=a("a"),TMo=o("XGLMForCausalLM"),MMo=o(" (XGLM model)"),EMo=l(),M2=a("li"),rle=a("strong"),CMo=o("xlm"),wMo=o(" \u2014 "),Bq=a("a"),AMo=o("XLMWithLMHeadModel"),yMo=o(" (XLM model)"),LMo=l(),E2=a("li"),tle=a("strong"),xMo=o("xlm-prophetnet"),kMo=o(" \u2014 "),Pq=a("a"),SMo=o("XLMProphetNetForCausalLM"),RMo=o(" (XLMProphetNet model)"),BMo=l(),C2=a("li"),ale=a("strong"),PMo=o("xlm-roberta"),$Mo=o(" \u2014 "),$q=a("a"),IMo=o("XLMRobertaForCausalLM"),qMo=o(" (XLM-RoBERTa model)"),NMo=l(),w2=a("li"),nle=a("strong"),jMo=o("xlm-roberta-xl"),DMo=o(" \u2014 "),Iq=a("a"),GMo=o("XLMRobertaXLForCausalLM"),OMo=o(" (XLM-RoBERTa-XL model)"),VMo=l(),A2=a("li"),sle=a("strong"),XMo=o("xlnet"),zMo=o(" \u2014 "),qq=a("a"),QMo=o("XLNetLMHeadModel"),WMo=o(" (XLNet model)"),HMo=l(),y2=a("p"),UMo=o("The model is set in evaluation mode by default using "),lle=a("code"),JMo=o("model.eval()"),YMo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ile=a("code"),KMo=o("model.train()"),ZMo=l(),dle=a("p"),e4o=o("Examples:"),o4o=l(),f(Z3.$$.fragment),YPe=l(),pd=a("h2"),L2=a("a"),cle=a("span"),f(eC.$$.fragment),r4o=l(),fle=a("span"),t4o=o("AutoModelForMaskedLM"),KPe=l(),Zo=a("div"),f(oC.$$.fragment),a4o=l(),_d=a("p"),n4o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Nq=a("a"),s4o=o("from_pretrained()"),l4o=o(" class method or the "),jq=a("a"),i4o=o("from_config()"),d4o=o(` class
method.`),c4o=l(),rC=a("p"),f4o=o("This class cannot be instantiated directly using "),mle=a("code"),m4o=o("__init__()"),g4o=o(" (throws an error)."),h4o=l(),Wr=a("div"),f(tC.$$.fragment),p4o=l(),gle=a("p"),_4o=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),u4o=l(),ud=a("p"),b4o=o(`Note:
Loading a model from its configuration file does `),hle=a("strong"),v4o=o("not"),F4o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dq=a("a"),T4o=o("from_pretrained()"),M4o=o(" to load the model weights."),E4o=l(),ple=a("p"),C4o=o("Examples:"),w4o=l(),f(aC.$$.fragment),A4o=l(),Oe=a("div"),f(nC.$$.fragment),y4o=l(),_le=a("p"),L4o=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),x4o=l(),Wa=a("p"),k4o=o("The model class to instantiate is selected based on the "),ule=a("code"),S4o=o("model_type"),R4o=o(` property of the config object (either
passed as an argument or loaded from `),ble=a("code"),B4o=o("pretrained_model_name_or_path"),P4o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vle=a("code"),$4o=o("pretrained_model_name_or_path"),I4o=o(":"),q4o=l(),I=a("ul"),x2=a("li"),Fle=a("strong"),N4o=o("albert"),j4o=o(" \u2014 "),Gq=a("a"),D4o=o("AlbertForMaskedLM"),G4o=o(" (ALBERT model)"),O4o=l(),k2=a("li"),Tle=a("strong"),V4o=o("bart"),X4o=o(" \u2014 "),Oq=a("a"),z4o=o("BartForConditionalGeneration"),Q4o=o(" (BART model)"),W4o=l(),S2=a("li"),Mle=a("strong"),H4o=o("bert"),U4o=o(" \u2014 "),Vq=a("a"),J4o=o("BertForMaskedLM"),Y4o=o(" (BERT model)"),K4o=l(),R2=a("li"),Ele=a("strong"),Z4o=o("big_bird"),eEo=o(" \u2014 "),Xq=a("a"),oEo=o("BigBirdForMaskedLM"),rEo=o(" (BigBird model)"),tEo=l(),B2=a("li"),Cle=a("strong"),aEo=o("camembert"),nEo=o(" \u2014 "),zq=a("a"),sEo=o("CamembertForMaskedLM"),lEo=o(" (CamemBERT model)"),iEo=l(),P2=a("li"),wle=a("strong"),dEo=o("convbert"),cEo=o(" \u2014 "),Qq=a("a"),fEo=o("ConvBertForMaskedLM"),mEo=o(" (ConvBERT model)"),gEo=l(),$2=a("li"),Ale=a("strong"),hEo=o("data2vec-text"),pEo=o(" \u2014 "),Wq=a("a"),_Eo=o("Data2VecTextForMaskedLM"),uEo=o(" (Data2VecText model)"),bEo=l(),I2=a("li"),yle=a("strong"),vEo=o("deberta"),FEo=o(" \u2014 "),Hq=a("a"),TEo=o("DebertaForMaskedLM"),MEo=o(" (DeBERTa model)"),EEo=l(),q2=a("li"),Lle=a("strong"),CEo=o("deberta-v2"),wEo=o(" \u2014 "),Uq=a("a"),AEo=o("DebertaV2ForMaskedLM"),yEo=o(" (DeBERTa-v2 model)"),LEo=l(),N2=a("li"),xle=a("strong"),xEo=o("distilbert"),kEo=o(" \u2014 "),Jq=a("a"),SEo=o("DistilBertForMaskedLM"),REo=o(" (DistilBERT model)"),BEo=l(),j2=a("li"),kle=a("strong"),PEo=o("electra"),$Eo=o(" \u2014 "),Yq=a("a"),IEo=o("ElectraForMaskedLM"),qEo=o(" (ELECTRA model)"),NEo=l(),D2=a("li"),Sle=a("strong"),jEo=o("flaubert"),DEo=o(" \u2014 "),Kq=a("a"),GEo=o("FlaubertWithLMHeadModel"),OEo=o(" (FlauBERT model)"),VEo=l(),G2=a("li"),Rle=a("strong"),XEo=o("fnet"),zEo=o(" \u2014 "),Zq=a("a"),QEo=o("FNetForMaskedLM"),WEo=o(" (FNet model)"),HEo=l(),O2=a("li"),Ble=a("strong"),UEo=o("funnel"),JEo=o(" \u2014 "),eN=a("a"),YEo=o("FunnelForMaskedLM"),KEo=o(" (Funnel Transformer model)"),ZEo=l(),V2=a("li"),Ple=a("strong"),e5o=o("ibert"),o5o=o(" \u2014 "),oN=a("a"),r5o=o("IBertForMaskedLM"),t5o=o(" (I-BERT model)"),a5o=l(),X2=a("li"),$le=a("strong"),n5o=o("layoutlm"),s5o=o(" \u2014 "),rN=a("a"),l5o=o("LayoutLMForMaskedLM"),i5o=o(" (LayoutLM model)"),d5o=l(),z2=a("li"),Ile=a("strong"),c5o=o("longformer"),f5o=o(" \u2014 "),tN=a("a"),m5o=o("LongformerForMaskedLM"),g5o=o(" (Longformer model)"),h5o=l(),Q2=a("li"),qle=a("strong"),p5o=o("mbart"),_5o=o(" \u2014 "),aN=a("a"),u5o=o("MBartForConditionalGeneration"),b5o=o(" (mBART model)"),v5o=l(),W2=a("li"),Nle=a("strong"),F5o=o("megatron-bert"),T5o=o(" \u2014 "),nN=a("a"),M5o=o("MegatronBertForMaskedLM"),E5o=o(" (MegatronBert model)"),C5o=l(),H2=a("li"),jle=a("strong"),w5o=o("mobilebert"),A5o=o(" \u2014 "),sN=a("a"),y5o=o("MobileBertForMaskedLM"),L5o=o(" (MobileBERT model)"),x5o=l(),U2=a("li"),Dle=a("strong"),k5o=o("mpnet"),S5o=o(" \u2014 "),lN=a("a"),R5o=o("MPNetForMaskedLM"),B5o=o(" (MPNet model)"),P5o=l(),J2=a("li"),Gle=a("strong"),$5o=o("nystromformer"),I5o=o(" \u2014 "),iN=a("a"),q5o=o("NystromformerForMaskedLM"),N5o=o(" (Nystromformer model)"),j5o=l(),Y2=a("li"),Ole=a("strong"),D5o=o("perceiver"),G5o=o(" \u2014 "),dN=a("a"),O5o=o("PerceiverForMaskedLM"),V5o=o(" (Perceiver model)"),X5o=l(),K2=a("li"),Vle=a("strong"),z5o=o("qdqbert"),Q5o=o(" \u2014 "),cN=a("a"),W5o=o("QDQBertForMaskedLM"),H5o=o(" (QDQBert model)"),U5o=l(),Z2=a("li"),Xle=a("strong"),J5o=o("reformer"),Y5o=o(" \u2014 "),fN=a("a"),K5o=o("ReformerForMaskedLM"),Z5o=o(" (Reformer model)"),e3o=l(),e1=a("li"),zle=a("strong"),o3o=o("rembert"),r3o=o(" \u2014 "),mN=a("a"),t3o=o("RemBertForMaskedLM"),a3o=o(" (RemBERT model)"),n3o=l(),o1=a("li"),Qle=a("strong"),s3o=o("roberta"),l3o=o(" \u2014 "),gN=a("a"),i3o=o("RobertaForMaskedLM"),d3o=o(" (RoBERTa model)"),c3o=l(),r1=a("li"),Wle=a("strong"),f3o=o("roformer"),m3o=o(" \u2014 "),hN=a("a"),g3o=o("RoFormerForMaskedLM"),h3o=o(" (RoFormer model)"),p3o=l(),t1=a("li"),Hle=a("strong"),_3o=o("squeezebert"),u3o=o(" \u2014 "),pN=a("a"),b3o=o("SqueezeBertForMaskedLM"),v3o=o(" (SqueezeBERT model)"),F3o=l(),a1=a("li"),Ule=a("strong"),T3o=o("tapas"),M3o=o(" \u2014 "),_N=a("a"),E3o=o("TapasForMaskedLM"),C3o=o(" (TAPAS model)"),w3o=l(),n1=a("li"),Jle=a("strong"),A3o=o("wav2vec2"),y3o=o(" \u2014 "),Yle=a("code"),L3o=o("Wav2Vec2ForMaskedLM"),x3o=o(" (Wav2Vec2 model)"),k3o=l(),s1=a("li"),Kle=a("strong"),S3o=o("xlm"),R3o=o(" \u2014 "),uN=a("a"),B3o=o("XLMWithLMHeadModel"),P3o=o(" (XLM model)"),$3o=l(),l1=a("li"),Zle=a("strong"),I3o=o("xlm-roberta"),q3o=o(" \u2014 "),bN=a("a"),N3o=o("XLMRobertaForMaskedLM"),j3o=o(" (XLM-RoBERTa model)"),D3o=l(),i1=a("li"),eie=a("strong"),G3o=o("xlm-roberta-xl"),O3o=o(" \u2014 "),vN=a("a"),V3o=o("XLMRobertaXLForMaskedLM"),X3o=o(" (XLM-RoBERTa-XL model)"),z3o=l(),d1=a("li"),oie=a("strong"),Q3o=o("yoso"),W3o=o(" \u2014 "),FN=a("a"),H3o=o("YosoForMaskedLM"),U3o=o(" (YOSO model)"),J3o=l(),c1=a("p"),Y3o=o("The model is set in evaluation mode by default using "),rie=a("code"),K3o=o("model.eval()"),Z3o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tie=a("code"),eCo=o("model.train()"),oCo=l(),aie=a("p"),rCo=o("Examples:"),tCo=l(),f(sC.$$.fragment),ZPe=l(),bd=a("h2"),f1=a("a"),nie=a("span"),f(lC.$$.fragment),aCo=l(),sie=a("span"),nCo=o("AutoModelForSeq2SeqLM"),e$e=l(),er=a("div"),f(iC.$$.fragment),sCo=l(),vd=a("p"),lCo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),TN=a("a"),iCo=o("from_pretrained()"),dCo=o(" class method or the "),MN=a("a"),cCo=o("from_config()"),fCo=o(` class
method.`),mCo=l(),dC=a("p"),gCo=o("This class cannot be instantiated directly using "),lie=a("code"),hCo=o("__init__()"),pCo=o(" (throws an error)."),_Co=l(),Hr=a("div"),f(cC.$$.fragment),uCo=l(),iie=a("p"),bCo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),vCo=l(),Fd=a("p"),FCo=o(`Note:
Loading a model from its configuration file does `),die=a("strong"),TCo=o("not"),MCo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EN=a("a"),ECo=o("from_pretrained()"),CCo=o(" to load the model weights."),wCo=l(),cie=a("p"),ACo=o("Examples:"),yCo=l(),f(fC.$$.fragment),LCo=l(),Ve=a("div"),f(mC.$$.fragment),xCo=l(),fie=a("p"),kCo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),SCo=l(),Ha=a("p"),RCo=o("The model class to instantiate is selected based on the "),mie=a("code"),BCo=o("model_type"),PCo=o(` property of the config object (either
passed as an argument or loaded from `),gie=a("code"),$Co=o("pretrained_model_name_or_path"),ICo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hie=a("code"),qCo=o("pretrained_model_name_or_path"),NCo=o(":"),jCo=l(),ne=a("ul"),m1=a("li"),pie=a("strong"),DCo=o("bart"),GCo=o(" \u2014 "),CN=a("a"),OCo=o("BartForConditionalGeneration"),VCo=o(" (BART model)"),XCo=l(),g1=a("li"),_ie=a("strong"),zCo=o("bigbird_pegasus"),QCo=o(" \u2014 "),wN=a("a"),WCo=o("BigBirdPegasusForConditionalGeneration"),HCo=o(" (BigBirdPegasus model)"),UCo=l(),h1=a("li"),uie=a("strong"),JCo=o("blenderbot"),YCo=o(" \u2014 "),AN=a("a"),KCo=o("BlenderbotForConditionalGeneration"),ZCo=o(" (Blenderbot model)"),ewo=l(),p1=a("li"),bie=a("strong"),owo=o("blenderbot-small"),rwo=o(" \u2014 "),yN=a("a"),two=o("BlenderbotSmallForConditionalGeneration"),awo=o(" (BlenderbotSmall model)"),nwo=l(),_1=a("li"),vie=a("strong"),swo=o("encoder-decoder"),lwo=o(" \u2014 "),LN=a("a"),iwo=o("EncoderDecoderModel"),dwo=o(" (Encoder decoder model)"),cwo=l(),u1=a("li"),Fie=a("strong"),fwo=o("fsmt"),mwo=o(" \u2014 "),xN=a("a"),gwo=o("FSMTForConditionalGeneration"),hwo=o(" (FairSeq Machine-Translation model)"),pwo=l(),b1=a("li"),Tie=a("strong"),_wo=o("led"),uwo=o(" \u2014 "),kN=a("a"),bwo=o("LEDForConditionalGeneration"),vwo=o(" (LED model)"),Fwo=l(),v1=a("li"),Mie=a("strong"),Two=o("longt5"),Mwo=o(" \u2014 "),SN=a("a"),Ewo=o("LongT5ForConditionalGeneration"),Cwo=o(" (LongT5 model)"),wwo=l(),F1=a("li"),Eie=a("strong"),Awo=o("m2m_100"),ywo=o(" \u2014 "),RN=a("a"),Lwo=o("M2M100ForConditionalGeneration"),xwo=o(" (M2M100 model)"),kwo=l(),T1=a("li"),Cie=a("strong"),Swo=o("marian"),Rwo=o(" \u2014 "),BN=a("a"),Bwo=o("MarianMTModel"),Pwo=o(" (Marian model)"),$wo=l(),M1=a("li"),wie=a("strong"),Iwo=o("mbart"),qwo=o(" \u2014 "),PN=a("a"),Nwo=o("MBartForConditionalGeneration"),jwo=o(" (mBART model)"),Dwo=l(),E1=a("li"),Aie=a("strong"),Gwo=o("mt5"),Owo=o(" \u2014 "),$N=a("a"),Vwo=o("MT5ForConditionalGeneration"),Xwo=o(" (mT5 model)"),zwo=l(),C1=a("li"),yie=a("strong"),Qwo=o("pegasus"),Wwo=o(" \u2014 "),IN=a("a"),Hwo=o("PegasusForConditionalGeneration"),Uwo=o(" (Pegasus model)"),Jwo=l(),w1=a("li"),Lie=a("strong"),Ywo=o("plbart"),Kwo=o(" \u2014 "),qN=a("a"),Zwo=o("PLBartForConditionalGeneration"),e0o=o(" (PLBart model)"),o0o=l(),A1=a("li"),xie=a("strong"),r0o=o("prophetnet"),t0o=o(" \u2014 "),NN=a("a"),a0o=o("ProphetNetForConditionalGeneration"),n0o=o(" (ProphetNet model)"),s0o=l(),y1=a("li"),kie=a("strong"),l0o=o("t5"),i0o=o(" \u2014 "),jN=a("a"),d0o=o("T5ForConditionalGeneration"),c0o=o(" (T5 model)"),f0o=l(),L1=a("li"),Sie=a("strong"),m0o=o("tapex"),g0o=o(" \u2014 "),DN=a("a"),h0o=o("BartForConditionalGeneration"),p0o=o(" (TAPEX model)"),_0o=l(),x1=a("li"),Rie=a("strong"),u0o=o("xlm-prophetnet"),b0o=o(" \u2014 "),GN=a("a"),v0o=o("XLMProphetNetForConditionalGeneration"),F0o=o(" (XLMProphetNet model)"),T0o=l(),k1=a("p"),M0o=o("The model is set in evaluation mode by default using "),Bie=a("code"),E0o=o("model.eval()"),C0o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pie=a("code"),w0o=o("model.train()"),A0o=l(),$ie=a("p"),y0o=o("Examples:"),L0o=l(),f(gC.$$.fragment),o$e=l(),Td=a("h2"),S1=a("a"),Iie=a("span"),f(hC.$$.fragment),x0o=l(),qie=a("span"),k0o=o("AutoModelForSequenceClassification"),r$e=l(),or=a("div"),f(pC.$$.fragment),S0o=l(),Md=a("p"),R0o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ON=a("a"),B0o=o("from_pretrained()"),P0o=o(" class method or the "),VN=a("a"),$0o=o("from_config()"),I0o=o(` class
method.`),q0o=l(),_C=a("p"),N0o=o("This class cannot be instantiated directly using "),Nie=a("code"),j0o=o("__init__()"),D0o=o(" (throws an error)."),G0o=l(),Ur=a("div"),f(uC.$$.fragment),O0o=l(),jie=a("p"),V0o=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),X0o=l(),Ed=a("p"),z0o=o(`Note:
Loading a model from its configuration file does `),Die=a("strong"),Q0o=o("not"),W0o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XN=a("a"),H0o=o("from_pretrained()"),U0o=o(" to load the model weights."),J0o=l(),Gie=a("p"),Y0o=o("Examples:"),K0o=l(),f(bC.$$.fragment),Z0o=l(),Xe=a("div"),f(vC.$$.fragment),eAo=l(),Oie=a("p"),oAo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),rAo=l(),Ua=a("p"),tAo=o("The model class to instantiate is selected based on the "),Vie=a("code"),aAo=o("model_type"),nAo=o(` property of the config object (either
passed as an argument or loaded from `),Xie=a("code"),sAo=o("pretrained_model_name_or_path"),lAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zie=a("code"),iAo=o("pretrained_model_name_or_path"),dAo=o(":"),cAo=l(),y=a("ul"),R1=a("li"),Qie=a("strong"),fAo=o("albert"),mAo=o(" \u2014 "),zN=a("a"),gAo=o("AlbertForSequenceClassification"),hAo=o(" (ALBERT model)"),pAo=l(),B1=a("li"),Wie=a("strong"),_Ao=o("bart"),uAo=o(" \u2014 "),QN=a("a"),bAo=o("BartForSequenceClassification"),vAo=o(" (BART model)"),FAo=l(),P1=a("li"),Hie=a("strong"),TAo=o("bert"),MAo=o(" \u2014 "),WN=a("a"),EAo=o("BertForSequenceClassification"),CAo=o(" (BERT model)"),wAo=l(),$1=a("li"),Uie=a("strong"),AAo=o("big_bird"),yAo=o(" \u2014 "),HN=a("a"),LAo=o("BigBirdForSequenceClassification"),xAo=o(" (BigBird model)"),kAo=l(),I1=a("li"),Jie=a("strong"),SAo=o("bigbird_pegasus"),RAo=o(" \u2014 "),UN=a("a"),BAo=o("BigBirdPegasusForSequenceClassification"),PAo=o(" (BigBirdPegasus model)"),$Ao=l(),q1=a("li"),Yie=a("strong"),IAo=o("camembert"),qAo=o(" \u2014 "),JN=a("a"),NAo=o("CamembertForSequenceClassification"),jAo=o(" (CamemBERT model)"),DAo=l(),N1=a("li"),Kie=a("strong"),GAo=o("canine"),OAo=o(" \u2014 "),YN=a("a"),VAo=o("CanineForSequenceClassification"),XAo=o(" (Canine model)"),zAo=l(),j1=a("li"),Zie=a("strong"),QAo=o("convbert"),WAo=o(" \u2014 "),KN=a("a"),HAo=o("ConvBertForSequenceClassification"),UAo=o(" (ConvBERT model)"),JAo=l(),D1=a("li"),ede=a("strong"),YAo=o("ctrl"),KAo=o(" \u2014 "),ZN=a("a"),ZAo=o("CTRLForSequenceClassification"),eyo=o(" (CTRL model)"),oyo=l(),G1=a("li"),ode=a("strong"),ryo=o("data2vec-text"),tyo=o(" \u2014 "),ej=a("a"),ayo=o("Data2VecTextForSequenceClassification"),nyo=o(" (Data2VecText model)"),syo=l(),O1=a("li"),rde=a("strong"),lyo=o("deberta"),iyo=o(" \u2014 "),oj=a("a"),dyo=o("DebertaForSequenceClassification"),cyo=o(" (DeBERTa model)"),fyo=l(),V1=a("li"),tde=a("strong"),myo=o("deberta-v2"),gyo=o(" \u2014 "),rj=a("a"),hyo=o("DebertaV2ForSequenceClassification"),pyo=o(" (DeBERTa-v2 model)"),_yo=l(),X1=a("li"),ade=a("strong"),uyo=o("distilbert"),byo=o(" \u2014 "),tj=a("a"),vyo=o("DistilBertForSequenceClassification"),Fyo=o(" (DistilBERT model)"),Tyo=l(),z1=a("li"),nde=a("strong"),Myo=o("electra"),Eyo=o(" \u2014 "),aj=a("a"),Cyo=o("ElectraForSequenceClassification"),wyo=o(" (ELECTRA model)"),Ayo=l(),Q1=a("li"),sde=a("strong"),yyo=o("flaubert"),Lyo=o(" \u2014 "),nj=a("a"),xyo=o("FlaubertForSequenceClassification"),kyo=o(" (FlauBERT model)"),Syo=l(),W1=a("li"),lde=a("strong"),Ryo=o("fnet"),Byo=o(" \u2014 "),sj=a("a"),Pyo=o("FNetForSequenceClassification"),$yo=o(" (FNet model)"),Iyo=l(),H1=a("li"),ide=a("strong"),qyo=o("funnel"),Nyo=o(" \u2014 "),lj=a("a"),jyo=o("FunnelForSequenceClassification"),Dyo=o(" (Funnel Transformer model)"),Gyo=l(),U1=a("li"),dde=a("strong"),Oyo=o("gpt2"),Vyo=o(" \u2014 "),ij=a("a"),Xyo=o("GPT2ForSequenceClassification"),zyo=o(" (OpenAI GPT-2 model)"),Qyo=l(),J1=a("li"),cde=a("strong"),Wyo=o("gpt_neo"),Hyo=o(" \u2014 "),dj=a("a"),Uyo=o("GPTNeoForSequenceClassification"),Jyo=o(" (GPT Neo model)"),Yyo=l(),Y1=a("li"),fde=a("strong"),Kyo=o("gptj"),Zyo=o(" \u2014 "),cj=a("a"),eLo=o("GPTJForSequenceClassification"),oLo=o(" (GPT-J model)"),rLo=l(),K1=a("li"),mde=a("strong"),tLo=o("ibert"),aLo=o(" \u2014 "),fj=a("a"),nLo=o("IBertForSequenceClassification"),sLo=o(" (I-BERT model)"),lLo=l(),Z1=a("li"),gde=a("strong"),iLo=o("layoutlm"),dLo=o(" \u2014 "),mj=a("a"),cLo=o("LayoutLMForSequenceClassification"),fLo=o(" (LayoutLM model)"),mLo=l(),eb=a("li"),hde=a("strong"),gLo=o("layoutlmv2"),hLo=o(" \u2014 "),gj=a("a"),pLo=o("LayoutLMv2ForSequenceClassification"),_Lo=o(" (LayoutLMv2 model)"),uLo=l(),ob=a("li"),pde=a("strong"),bLo=o("led"),vLo=o(" \u2014 "),hj=a("a"),FLo=o("LEDForSequenceClassification"),TLo=o(" (LED model)"),MLo=l(),rb=a("li"),_de=a("strong"),ELo=o("longformer"),CLo=o(" \u2014 "),pj=a("a"),wLo=o("LongformerForSequenceClassification"),ALo=o(" (Longformer model)"),yLo=l(),tb=a("li"),ude=a("strong"),LLo=o("mbart"),xLo=o(" \u2014 "),_j=a("a"),kLo=o("MBartForSequenceClassification"),SLo=o(" (mBART model)"),RLo=l(),ab=a("li"),bde=a("strong"),BLo=o("megatron-bert"),PLo=o(" \u2014 "),uj=a("a"),$Lo=o("MegatronBertForSequenceClassification"),ILo=o(" (MegatronBert model)"),qLo=l(),nb=a("li"),vde=a("strong"),NLo=o("mobilebert"),jLo=o(" \u2014 "),bj=a("a"),DLo=o("MobileBertForSequenceClassification"),GLo=o(" (MobileBERT model)"),OLo=l(),sb=a("li"),Fde=a("strong"),VLo=o("mpnet"),XLo=o(" \u2014 "),vj=a("a"),zLo=o("MPNetForSequenceClassification"),QLo=o(" (MPNet model)"),WLo=l(),lb=a("li"),Tde=a("strong"),HLo=o("nystromformer"),ULo=o(" \u2014 "),Fj=a("a"),JLo=o("NystromformerForSequenceClassification"),YLo=o(" (Nystromformer model)"),KLo=l(),ib=a("li"),Mde=a("strong"),ZLo=o("openai-gpt"),e8o=o(" \u2014 "),Tj=a("a"),o8o=o("OpenAIGPTForSequenceClassification"),r8o=o(" (OpenAI GPT model)"),t8o=l(),db=a("li"),Ede=a("strong"),a8o=o("perceiver"),n8o=o(" \u2014 "),Mj=a("a"),s8o=o("PerceiverForSequenceClassification"),l8o=o(" (Perceiver model)"),i8o=l(),cb=a("li"),Cde=a("strong"),d8o=o("plbart"),c8o=o(" \u2014 "),Ej=a("a"),f8o=o("PLBartForSequenceClassification"),m8o=o(" (PLBart model)"),g8o=l(),fb=a("li"),wde=a("strong"),h8o=o("qdqbert"),p8o=o(" \u2014 "),Cj=a("a"),_8o=o("QDQBertForSequenceClassification"),u8o=o(" (QDQBert model)"),b8o=l(),mb=a("li"),Ade=a("strong"),v8o=o("reformer"),F8o=o(" \u2014 "),wj=a("a"),T8o=o("ReformerForSequenceClassification"),M8o=o(" (Reformer model)"),E8o=l(),gb=a("li"),yde=a("strong"),C8o=o("rembert"),w8o=o(" \u2014 "),Aj=a("a"),A8o=o("RemBertForSequenceClassification"),y8o=o(" (RemBERT model)"),L8o=l(),hb=a("li"),Lde=a("strong"),x8o=o("roberta"),k8o=o(" \u2014 "),yj=a("a"),S8o=o("RobertaForSequenceClassification"),R8o=o(" (RoBERTa model)"),B8o=l(),pb=a("li"),xde=a("strong"),P8o=o("roformer"),$8o=o(" \u2014 "),Lj=a("a"),I8o=o("RoFormerForSequenceClassification"),q8o=o(" (RoFormer model)"),N8o=l(),_b=a("li"),kde=a("strong"),j8o=o("squeezebert"),D8o=o(" \u2014 "),xj=a("a"),G8o=o("SqueezeBertForSequenceClassification"),O8o=o(" (SqueezeBERT model)"),V8o=l(),ub=a("li"),Sde=a("strong"),X8o=o("tapas"),z8o=o(" \u2014 "),kj=a("a"),Q8o=o("TapasForSequenceClassification"),W8o=o(" (TAPAS model)"),H8o=l(),bb=a("li"),Rde=a("strong"),U8o=o("tapex"),J8o=o(" \u2014 "),Sj=a("a"),Y8o=o("BartForSequenceClassification"),K8o=o(" (TAPEX model)"),Z8o=l(),vb=a("li"),Bde=a("strong"),exo=o("transfo-xl"),oxo=o(" \u2014 "),Rj=a("a"),rxo=o("TransfoXLForSequenceClassification"),txo=o(" (Transformer-XL model)"),axo=l(),Fb=a("li"),Pde=a("strong"),nxo=o("xlm"),sxo=o(" \u2014 "),Bj=a("a"),lxo=o("XLMForSequenceClassification"),ixo=o(" (XLM model)"),dxo=l(),Tb=a("li"),$de=a("strong"),cxo=o("xlm-roberta"),fxo=o(" \u2014 "),Pj=a("a"),mxo=o("XLMRobertaForSequenceClassification"),gxo=o(" (XLM-RoBERTa model)"),hxo=l(),Mb=a("li"),Ide=a("strong"),pxo=o("xlm-roberta-xl"),_xo=o(" \u2014 "),$j=a("a"),uxo=o("XLMRobertaXLForSequenceClassification"),bxo=o(" (XLM-RoBERTa-XL model)"),vxo=l(),Eb=a("li"),qde=a("strong"),Fxo=o("xlnet"),Txo=o(" \u2014 "),Ij=a("a"),Mxo=o("XLNetForSequenceClassification"),Exo=o(" (XLNet model)"),Cxo=l(),Cb=a("li"),Nde=a("strong"),wxo=o("yoso"),Axo=o(" \u2014 "),qj=a("a"),yxo=o("YosoForSequenceClassification"),Lxo=o(" (YOSO model)"),xxo=l(),wb=a("p"),kxo=o("The model is set in evaluation mode by default using "),jde=a("code"),Sxo=o("model.eval()"),Rxo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dde=a("code"),Bxo=o("model.train()"),Pxo=l(),Gde=a("p"),$xo=o("Examples:"),Ixo=l(),f(FC.$$.fragment),t$e=l(),Cd=a("h2"),Ab=a("a"),Ode=a("span"),f(TC.$$.fragment),qxo=l(),Vde=a("span"),Nxo=o("AutoModelForMultipleChoice"),a$e=l(),rr=a("div"),f(MC.$$.fragment),jxo=l(),wd=a("p"),Dxo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Nj=a("a"),Gxo=o("from_pretrained()"),Oxo=o(" class method or the "),jj=a("a"),Vxo=o("from_config()"),Xxo=o(` class
method.`),zxo=l(),EC=a("p"),Qxo=o("This class cannot be instantiated directly using "),Xde=a("code"),Wxo=o("__init__()"),Hxo=o(" (throws an error)."),Uxo=l(),Jr=a("div"),f(CC.$$.fragment),Jxo=l(),zde=a("p"),Yxo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Kxo=l(),Ad=a("p"),Zxo=o(`Note:
Loading a model from its configuration file does `),Qde=a("strong"),eko=o("not"),oko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dj=a("a"),rko=o("from_pretrained()"),tko=o(" to load the model weights."),ako=l(),Wde=a("p"),nko=o("Examples:"),sko=l(),f(wC.$$.fragment),lko=l(),ze=a("div"),f(AC.$$.fragment),iko=l(),Hde=a("p"),dko=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),cko=l(),Ja=a("p"),fko=o("The model class to instantiate is selected based on the "),Ude=a("code"),mko=o("model_type"),gko=o(` property of the config object (either
passed as an argument or loaded from `),Jde=a("code"),hko=o("pretrained_model_name_or_path"),pko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yde=a("code"),_ko=o("pretrained_model_name_or_path"),uko=o(":"),bko=l(),G=a("ul"),yb=a("li"),Kde=a("strong"),vko=o("albert"),Fko=o(" \u2014 "),Gj=a("a"),Tko=o("AlbertForMultipleChoice"),Mko=o(" (ALBERT model)"),Eko=l(),Lb=a("li"),Zde=a("strong"),Cko=o("bert"),wko=o(" \u2014 "),Oj=a("a"),Ako=o("BertForMultipleChoice"),yko=o(" (BERT model)"),Lko=l(),xb=a("li"),ece=a("strong"),xko=o("big_bird"),kko=o(" \u2014 "),Vj=a("a"),Sko=o("BigBirdForMultipleChoice"),Rko=o(" (BigBird model)"),Bko=l(),kb=a("li"),oce=a("strong"),Pko=o("camembert"),$ko=o(" \u2014 "),Xj=a("a"),Iko=o("CamembertForMultipleChoice"),qko=o(" (CamemBERT model)"),Nko=l(),Sb=a("li"),rce=a("strong"),jko=o("canine"),Dko=o(" \u2014 "),zj=a("a"),Gko=o("CanineForMultipleChoice"),Oko=o(" (Canine model)"),Vko=l(),Rb=a("li"),tce=a("strong"),Xko=o("convbert"),zko=o(" \u2014 "),Qj=a("a"),Qko=o("ConvBertForMultipleChoice"),Wko=o(" (ConvBERT model)"),Hko=l(),Bb=a("li"),ace=a("strong"),Uko=o("data2vec-text"),Jko=o(" \u2014 "),Wj=a("a"),Yko=o("Data2VecTextForMultipleChoice"),Kko=o(" (Data2VecText model)"),Zko=l(),Pb=a("li"),nce=a("strong"),eSo=o("distilbert"),oSo=o(" \u2014 "),Hj=a("a"),rSo=o("DistilBertForMultipleChoice"),tSo=o(" (DistilBERT model)"),aSo=l(),$b=a("li"),sce=a("strong"),nSo=o("electra"),sSo=o(" \u2014 "),Uj=a("a"),lSo=o("ElectraForMultipleChoice"),iSo=o(" (ELECTRA model)"),dSo=l(),Ib=a("li"),lce=a("strong"),cSo=o("flaubert"),fSo=o(" \u2014 "),Jj=a("a"),mSo=o("FlaubertForMultipleChoice"),gSo=o(" (FlauBERT model)"),hSo=l(),qb=a("li"),ice=a("strong"),pSo=o("fnet"),_So=o(" \u2014 "),Yj=a("a"),uSo=o("FNetForMultipleChoice"),bSo=o(" (FNet model)"),vSo=l(),Nb=a("li"),dce=a("strong"),FSo=o("funnel"),TSo=o(" \u2014 "),Kj=a("a"),MSo=o("FunnelForMultipleChoice"),ESo=o(" (Funnel Transformer model)"),CSo=l(),jb=a("li"),cce=a("strong"),wSo=o("ibert"),ASo=o(" \u2014 "),Zj=a("a"),ySo=o("IBertForMultipleChoice"),LSo=o(" (I-BERT model)"),xSo=l(),Db=a("li"),fce=a("strong"),kSo=o("longformer"),SSo=o(" \u2014 "),eD=a("a"),RSo=o("LongformerForMultipleChoice"),BSo=o(" (Longformer model)"),PSo=l(),Gb=a("li"),mce=a("strong"),$So=o("megatron-bert"),ISo=o(" \u2014 "),oD=a("a"),qSo=o("MegatronBertForMultipleChoice"),NSo=o(" (MegatronBert model)"),jSo=l(),Ob=a("li"),gce=a("strong"),DSo=o("mobilebert"),GSo=o(" \u2014 "),rD=a("a"),OSo=o("MobileBertForMultipleChoice"),VSo=o(" (MobileBERT model)"),XSo=l(),Vb=a("li"),hce=a("strong"),zSo=o("mpnet"),QSo=o(" \u2014 "),tD=a("a"),WSo=o("MPNetForMultipleChoice"),HSo=o(" (MPNet model)"),USo=l(),Xb=a("li"),pce=a("strong"),JSo=o("nystromformer"),YSo=o(" \u2014 "),aD=a("a"),KSo=o("NystromformerForMultipleChoice"),ZSo=o(" (Nystromformer model)"),eRo=l(),zb=a("li"),_ce=a("strong"),oRo=o("qdqbert"),rRo=o(" \u2014 "),nD=a("a"),tRo=o("QDQBertForMultipleChoice"),aRo=o(" (QDQBert model)"),nRo=l(),Qb=a("li"),uce=a("strong"),sRo=o("rembert"),lRo=o(" \u2014 "),sD=a("a"),iRo=o("RemBertForMultipleChoice"),dRo=o(" (RemBERT model)"),cRo=l(),Wb=a("li"),bce=a("strong"),fRo=o("roberta"),mRo=o(" \u2014 "),lD=a("a"),gRo=o("RobertaForMultipleChoice"),hRo=o(" (RoBERTa model)"),pRo=l(),Hb=a("li"),vce=a("strong"),_Ro=o("roformer"),uRo=o(" \u2014 "),iD=a("a"),bRo=o("RoFormerForMultipleChoice"),vRo=o(" (RoFormer model)"),FRo=l(),Ub=a("li"),Fce=a("strong"),TRo=o("squeezebert"),MRo=o(" \u2014 "),dD=a("a"),ERo=o("SqueezeBertForMultipleChoice"),CRo=o(" (SqueezeBERT model)"),wRo=l(),Jb=a("li"),Tce=a("strong"),ARo=o("xlm"),yRo=o(" \u2014 "),cD=a("a"),LRo=o("XLMForMultipleChoice"),xRo=o(" (XLM model)"),kRo=l(),Yb=a("li"),Mce=a("strong"),SRo=o("xlm-roberta"),RRo=o(" \u2014 "),fD=a("a"),BRo=o("XLMRobertaForMultipleChoice"),PRo=o(" (XLM-RoBERTa model)"),$Ro=l(),Kb=a("li"),Ece=a("strong"),IRo=o("xlm-roberta-xl"),qRo=o(" \u2014 "),mD=a("a"),NRo=o("XLMRobertaXLForMultipleChoice"),jRo=o(" (XLM-RoBERTa-XL model)"),DRo=l(),Zb=a("li"),Cce=a("strong"),GRo=o("xlnet"),ORo=o(" \u2014 "),gD=a("a"),VRo=o("XLNetForMultipleChoice"),XRo=o(" (XLNet model)"),zRo=l(),e6=a("li"),wce=a("strong"),QRo=o("yoso"),WRo=o(" \u2014 "),hD=a("a"),HRo=o("YosoForMultipleChoice"),URo=o(" (YOSO model)"),JRo=l(),o6=a("p"),YRo=o("The model is set in evaluation mode by default using "),Ace=a("code"),KRo=o("model.eval()"),ZRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yce=a("code"),eBo=o("model.train()"),oBo=l(),Lce=a("p"),rBo=o("Examples:"),tBo=l(),f(yC.$$.fragment),n$e=l(),yd=a("h2"),r6=a("a"),xce=a("span"),f(LC.$$.fragment),aBo=l(),kce=a("span"),nBo=o("AutoModelForNextSentencePrediction"),s$e=l(),tr=a("div"),f(xC.$$.fragment),sBo=l(),Ld=a("p"),lBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),pD=a("a"),iBo=o("from_pretrained()"),dBo=o(" class method or the "),_D=a("a"),cBo=o("from_config()"),fBo=o(` class
method.`),mBo=l(),kC=a("p"),gBo=o("This class cannot be instantiated directly using "),Sce=a("code"),hBo=o("__init__()"),pBo=o(" (throws an error)."),_Bo=l(),Yr=a("div"),f(SC.$$.fragment),uBo=l(),Rce=a("p"),bBo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),vBo=l(),xd=a("p"),FBo=o(`Note:
Loading a model from its configuration file does `),Bce=a("strong"),TBo=o("not"),MBo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uD=a("a"),EBo=o("from_pretrained()"),CBo=o(" to load the model weights."),wBo=l(),Pce=a("p"),ABo=o("Examples:"),yBo=l(),f(RC.$$.fragment),LBo=l(),Qe=a("div"),f(BC.$$.fragment),xBo=l(),$ce=a("p"),kBo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),SBo=l(),Ya=a("p"),RBo=o("The model class to instantiate is selected based on the "),Ice=a("code"),BBo=o("model_type"),PBo=o(` property of the config object (either
passed as an argument or loaded from `),qce=a("code"),$Bo=o("pretrained_model_name_or_path"),IBo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nce=a("code"),qBo=o("pretrained_model_name_or_path"),NBo=o(":"),jBo=l(),da=a("ul"),t6=a("li"),jce=a("strong"),DBo=o("bert"),GBo=o(" \u2014 "),bD=a("a"),OBo=o("BertForNextSentencePrediction"),VBo=o(" (BERT model)"),XBo=l(),a6=a("li"),Dce=a("strong"),zBo=o("fnet"),QBo=o(" \u2014 "),vD=a("a"),WBo=o("FNetForNextSentencePrediction"),HBo=o(" (FNet model)"),UBo=l(),n6=a("li"),Gce=a("strong"),JBo=o("megatron-bert"),YBo=o(" \u2014 "),FD=a("a"),KBo=o("MegatronBertForNextSentencePrediction"),ZBo=o(" (MegatronBert model)"),ePo=l(),s6=a("li"),Oce=a("strong"),oPo=o("mobilebert"),rPo=o(" \u2014 "),TD=a("a"),tPo=o("MobileBertForNextSentencePrediction"),aPo=o(" (MobileBERT model)"),nPo=l(),l6=a("li"),Vce=a("strong"),sPo=o("qdqbert"),lPo=o(" \u2014 "),MD=a("a"),iPo=o("QDQBertForNextSentencePrediction"),dPo=o(" (QDQBert model)"),cPo=l(),i6=a("p"),fPo=o("The model is set in evaluation mode by default using "),Xce=a("code"),mPo=o("model.eval()"),gPo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zce=a("code"),hPo=o("model.train()"),pPo=l(),Qce=a("p"),_Po=o("Examples:"),uPo=l(),f(PC.$$.fragment),l$e=l(),kd=a("h2"),d6=a("a"),Wce=a("span"),f($C.$$.fragment),bPo=l(),Hce=a("span"),vPo=o("AutoModelForTokenClassification"),i$e=l(),ar=a("div"),f(IC.$$.fragment),FPo=l(),Sd=a("p"),TPo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ED=a("a"),MPo=o("from_pretrained()"),EPo=o(" class method or the "),CD=a("a"),CPo=o("from_config()"),wPo=o(` class
method.`),APo=l(),qC=a("p"),yPo=o("This class cannot be instantiated directly using "),Uce=a("code"),LPo=o("__init__()"),xPo=o(" (throws an error)."),kPo=l(),Kr=a("div"),f(NC.$$.fragment),SPo=l(),Jce=a("p"),RPo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),BPo=l(),Rd=a("p"),PPo=o(`Note:
Loading a model from its configuration file does `),Yce=a("strong"),$Po=o("not"),IPo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wD=a("a"),qPo=o("from_pretrained()"),NPo=o(" to load the model weights."),jPo=l(),Kce=a("p"),DPo=o("Examples:"),GPo=l(),f(jC.$$.fragment),OPo=l(),We=a("div"),f(DC.$$.fragment),VPo=l(),Zce=a("p"),XPo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),zPo=l(),Ka=a("p"),QPo=o("The model class to instantiate is selected based on the "),efe=a("code"),WPo=o("model_type"),HPo=o(` property of the config object (either
passed as an argument or loaded from `),ofe=a("code"),UPo=o("pretrained_model_name_or_path"),JPo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rfe=a("code"),YPo=o("pretrained_model_name_or_path"),KPo=o(":"),ZPo=l(),j=a("ul"),c6=a("li"),tfe=a("strong"),e$o=o("albert"),o$o=o(" \u2014 "),AD=a("a"),r$o=o("AlbertForTokenClassification"),t$o=o(" (ALBERT model)"),a$o=l(),f6=a("li"),afe=a("strong"),n$o=o("bert"),s$o=o(" \u2014 "),yD=a("a"),l$o=o("BertForTokenClassification"),i$o=o(" (BERT model)"),d$o=l(),m6=a("li"),nfe=a("strong"),c$o=o("big_bird"),f$o=o(" \u2014 "),LD=a("a"),m$o=o("BigBirdForTokenClassification"),g$o=o(" (BigBird model)"),h$o=l(),g6=a("li"),sfe=a("strong"),p$o=o("camembert"),_$o=o(" \u2014 "),xD=a("a"),u$o=o("CamembertForTokenClassification"),b$o=o(" (CamemBERT model)"),v$o=l(),h6=a("li"),lfe=a("strong"),F$o=o("canine"),T$o=o(" \u2014 "),kD=a("a"),M$o=o("CanineForTokenClassification"),E$o=o(" (Canine model)"),C$o=l(),p6=a("li"),ife=a("strong"),w$o=o("convbert"),A$o=o(" \u2014 "),SD=a("a"),y$o=o("ConvBertForTokenClassification"),L$o=o(" (ConvBERT model)"),x$o=l(),_6=a("li"),dfe=a("strong"),k$o=o("data2vec-text"),S$o=o(" \u2014 "),RD=a("a"),R$o=o("Data2VecTextForTokenClassification"),B$o=o(" (Data2VecText model)"),P$o=l(),u6=a("li"),cfe=a("strong"),$$o=o("deberta"),I$o=o(" \u2014 "),BD=a("a"),q$o=o("DebertaForTokenClassification"),N$o=o(" (DeBERTa model)"),j$o=l(),b6=a("li"),ffe=a("strong"),D$o=o("deberta-v2"),G$o=o(" \u2014 "),PD=a("a"),O$o=o("DebertaV2ForTokenClassification"),V$o=o(" (DeBERTa-v2 model)"),X$o=l(),v6=a("li"),mfe=a("strong"),z$o=o("distilbert"),Q$o=o(" \u2014 "),$D=a("a"),W$o=o("DistilBertForTokenClassification"),H$o=o(" (DistilBERT model)"),U$o=l(),F6=a("li"),gfe=a("strong"),J$o=o("electra"),Y$o=o(" \u2014 "),ID=a("a"),K$o=o("ElectraForTokenClassification"),Z$o=o(" (ELECTRA model)"),eIo=l(),T6=a("li"),hfe=a("strong"),oIo=o("flaubert"),rIo=o(" \u2014 "),qD=a("a"),tIo=o("FlaubertForTokenClassification"),aIo=o(" (FlauBERT model)"),nIo=l(),M6=a("li"),pfe=a("strong"),sIo=o("fnet"),lIo=o(" \u2014 "),ND=a("a"),iIo=o("FNetForTokenClassification"),dIo=o(" (FNet model)"),cIo=l(),E6=a("li"),_fe=a("strong"),fIo=o("funnel"),mIo=o(" \u2014 "),jD=a("a"),gIo=o("FunnelForTokenClassification"),hIo=o(" (Funnel Transformer model)"),pIo=l(),C6=a("li"),ufe=a("strong"),_Io=o("gpt2"),uIo=o(" \u2014 "),DD=a("a"),bIo=o("GPT2ForTokenClassification"),vIo=o(" (OpenAI GPT-2 model)"),FIo=l(),w6=a("li"),bfe=a("strong"),TIo=o("ibert"),MIo=o(" \u2014 "),GD=a("a"),EIo=o("IBertForTokenClassification"),CIo=o(" (I-BERT model)"),wIo=l(),A6=a("li"),vfe=a("strong"),AIo=o("layoutlm"),yIo=o(" \u2014 "),OD=a("a"),LIo=o("LayoutLMForTokenClassification"),xIo=o(" (LayoutLM model)"),kIo=l(),y6=a("li"),Ffe=a("strong"),SIo=o("layoutlmv2"),RIo=o(" \u2014 "),VD=a("a"),BIo=o("LayoutLMv2ForTokenClassification"),PIo=o(" (LayoutLMv2 model)"),$Io=l(),L6=a("li"),Tfe=a("strong"),IIo=o("longformer"),qIo=o(" \u2014 "),XD=a("a"),NIo=o("LongformerForTokenClassification"),jIo=o(" (Longformer model)"),DIo=l(),x6=a("li"),Mfe=a("strong"),GIo=o("megatron-bert"),OIo=o(" \u2014 "),zD=a("a"),VIo=o("MegatronBertForTokenClassification"),XIo=o(" (MegatronBert model)"),zIo=l(),k6=a("li"),Efe=a("strong"),QIo=o("mobilebert"),WIo=o(" \u2014 "),QD=a("a"),HIo=o("MobileBertForTokenClassification"),UIo=o(" (MobileBERT model)"),JIo=l(),S6=a("li"),Cfe=a("strong"),YIo=o("mpnet"),KIo=o(" \u2014 "),WD=a("a"),ZIo=o("MPNetForTokenClassification"),eqo=o(" (MPNet model)"),oqo=l(),R6=a("li"),wfe=a("strong"),rqo=o("nystromformer"),tqo=o(" \u2014 "),HD=a("a"),aqo=o("NystromformerForTokenClassification"),nqo=o(" (Nystromformer model)"),sqo=l(),B6=a("li"),Afe=a("strong"),lqo=o("qdqbert"),iqo=o(" \u2014 "),UD=a("a"),dqo=o("QDQBertForTokenClassification"),cqo=o(" (QDQBert model)"),fqo=l(),P6=a("li"),yfe=a("strong"),mqo=o("rembert"),gqo=o(" \u2014 "),JD=a("a"),hqo=o("RemBertForTokenClassification"),pqo=o(" (RemBERT model)"),_qo=l(),$6=a("li"),Lfe=a("strong"),uqo=o("roberta"),bqo=o(" \u2014 "),YD=a("a"),vqo=o("RobertaForTokenClassification"),Fqo=o(" (RoBERTa model)"),Tqo=l(),I6=a("li"),xfe=a("strong"),Mqo=o("roformer"),Eqo=o(" \u2014 "),KD=a("a"),Cqo=o("RoFormerForTokenClassification"),wqo=o(" (RoFormer model)"),Aqo=l(),q6=a("li"),kfe=a("strong"),yqo=o("squeezebert"),Lqo=o(" \u2014 "),ZD=a("a"),xqo=o("SqueezeBertForTokenClassification"),kqo=o(" (SqueezeBERT model)"),Sqo=l(),N6=a("li"),Sfe=a("strong"),Rqo=o("xlm"),Bqo=o(" \u2014 "),eG=a("a"),Pqo=o("XLMForTokenClassification"),$qo=o(" (XLM model)"),Iqo=l(),j6=a("li"),Rfe=a("strong"),qqo=o("xlm-roberta"),Nqo=o(" \u2014 "),oG=a("a"),jqo=o("XLMRobertaForTokenClassification"),Dqo=o(" (XLM-RoBERTa model)"),Gqo=l(),D6=a("li"),Bfe=a("strong"),Oqo=o("xlm-roberta-xl"),Vqo=o(" \u2014 "),rG=a("a"),Xqo=o("XLMRobertaXLForTokenClassification"),zqo=o(" (XLM-RoBERTa-XL model)"),Qqo=l(),G6=a("li"),Pfe=a("strong"),Wqo=o("xlnet"),Hqo=o(" \u2014 "),tG=a("a"),Uqo=o("XLNetForTokenClassification"),Jqo=o(" (XLNet model)"),Yqo=l(),O6=a("li"),$fe=a("strong"),Kqo=o("yoso"),Zqo=o(" \u2014 "),aG=a("a"),eNo=o("YosoForTokenClassification"),oNo=o(" (YOSO model)"),rNo=l(),V6=a("p"),tNo=o("The model is set in evaluation mode by default using "),Ife=a("code"),aNo=o("model.eval()"),nNo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qfe=a("code"),sNo=o("model.train()"),lNo=l(),Nfe=a("p"),iNo=o("Examples:"),dNo=l(),f(GC.$$.fragment),d$e=l(),Bd=a("h2"),X6=a("a"),jfe=a("span"),f(OC.$$.fragment),cNo=l(),Dfe=a("span"),fNo=o("AutoModelForQuestionAnswering"),c$e=l(),nr=a("div"),f(VC.$$.fragment),mNo=l(),Pd=a("p"),gNo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),nG=a("a"),hNo=o("from_pretrained()"),pNo=o(" class method or the "),sG=a("a"),_No=o("from_config()"),uNo=o(` class
method.`),bNo=l(),XC=a("p"),vNo=o("This class cannot be instantiated directly using "),Gfe=a("code"),FNo=o("__init__()"),TNo=o(" (throws an error)."),MNo=l(),Zr=a("div"),f(zC.$$.fragment),ENo=l(),Ofe=a("p"),CNo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),wNo=l(),$d=a("p"),ANo=o(`Note:
Loading a model from its configuration file does `),Vfe=a("strong"),yNo=o("not"),LNo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lG=a("a"),xNo=o("from_pretrained()"),kNo=o(" to load the model weights."),SNo=l(),Xfe=a("p"),RNo=o("Examples:"),BNo=l(),f(QC.$$.fragment),PNo=l(),He=a("div"),f(WC.$$.fragment),$No=l(),zfe=a("p"),INo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),qNo=l(),Za=a("p"),NNo=o("The model class to instantiate is selected based on the "),Qfe=a("code"),jNo=o("model_type"),DNo=o(` property of the config object (either
passed as an argument or loaded from `),Wfe=a("code"),GNo=o("pretrained_model_name_or_path"),ONo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hfe=a("code"),VNo=o("pretrained_model_name_or_path"),XNo=o(":"),zNo=l(),R=a("ul"),z6=a("li"),Ufe=a("strong"),QNo=o("albert"),WNo=o(" \u2014 "),iG=a("a"),HNo=o("AlbertForQuestionAnswering"),UNo=o(" (ALBERT model)"),JNo=l(),Q6=a("li"),Jfe=a("strong"),YNo=o("bart"),KNo=o(" \u2014 "),dG=a("a"),ZNo=o("BartForQuestionAnswering"),ejo=o(" (BART model)"),ojo=l(),W6=a("li"),Yfe=a("strong"),rjo=o("bert"),tjo=o(" \u2014 "),cG=a("a"),ajo=o("BertForQuestionAnswering"),njo=o(" (BERT model)"),sjo=l(),H6=a("li"),Kfe=a("strong"),ljo=o("big_bird"),ijo=o(" \u2014 "),fG=a("a"),djo=o("BigBirdForQuestionAnswering"),cjo=o(" (BigBird model)"),fjo=l(),U6=a("li"),Zfe=a("strong"),mjo=o("bigbird_pegasus"),gjo=o(" \u2014 "),mG=a("a"),hjo=o("BigBirdPegasusForQuestionAnswering"),pjo=o(" (BigBirdPegasus model)"),_jo=l(),J6=a("li"),eme=a("strong"),ujo=o("camembert"),bjo=o(" \u2014 "),gG=a("a"),vjo=o("CamembertForQuestionAnswering"),Fjo=o(" (CamemBERT model)"),Tjo=l(),Y6=a("li"),ome=a("strong"),Mjo=o("canine"),Ejo=o(" \u2014 "),hG=a("a"),Cjo=o("CanineForQuestionAnswering"),wjo=o(" (Canine model)"),Ajo=l(),K6=a("li"),rme=a("strong"),yjo=o("convbert"),Ljo=o(" \u2014 "),pG=a("a"),xjo=o("ConvBertForQuestionAnswering"),kjo=o(" (ConvBERT model)"),Sjo=l(),Z6=a("li"),tme=a("strong"),Rjo=o("data2vec-text"),Bjo=o(" \u2014 "),_G=a("a"),Pjo=o("Data2VecTextForQuestionAnswering"),$jo=o(" (Data2VecText model)"),Ijo=l(),ev=a("li"),ame=a("strong"),qjo=o("deberta"),Njo=o(" \u2014 "),uG=a("a"),jjo=o("DebertaForQuestionAnswering"),Djo=o(" (DeBERTa model)"),Gjo=l(),ov=a("li"),nme=a("strong"),Ojo=o("deberta-v2"),Vjo=o(" \u2014 "),bG=a("a"),Xjo=o("DebertaV2ForQuestionAnswering"),zjo=o(" (DeBERTa-v2 model)"),Qjo=l(),rv=a("li"),sme=a("strong"),Wjo=o("distilbert"),Hjo=o(" \u2014 "),vG=a("a"),Ujo=o("DistilBertForQuestionAnswering"),Jjo=o(" (DistilBERT model)"),Yjo=l(),tv=a("li"),lme=a("strong"),Kjo=o("electra"),Zjo=o(" \u2014 "),FG=a("a"),eDo=o("ElectraForQuestionAnswering"),oDo=o(" (ELECTRA model)"),rDo=l(),av=a("li"),ime=a("strong"),tDo=o("flaubert"),aDo=o(" \u2014 "),TG=a("a"),nDo=o("FlaubertForQuestionAnsweringSimple"),sDo=o(" (FlauBERT model)"),lDo=l(),nv=a("li"),dme=a("strong"),iDo=o("fnet"),dDo=o(" \u2014 "),MG=a("a"),cDo=o("FNetForQuestionAnswering"),fDo=o(" (FNet model)"),mDo=l(),sv=a("li"),cme=a("strong"),gDo=o("funnel"),hDo=o(" \u2014 "),EG=a("a"),pDo=o("FunnelForQuestionAnswering"),_Do=o(" (Funnel Transformer model)"),uDo=l(),lv=a("li"),fme=a("strong"),bDo=o("gptj"),vDo=o(" \u2014 "),CG=a("a"),FDo=o("GPTJForQuestionAnswering"),TDo=o(" (GPT-J model)"),MDo=l(),iv=a("li"),mme=a("strong"),EDo=o("ibert"),CDo=o(" \u2014 "),wG=a("a"),wDo=o("IBertForQuestionAnswering"),ADo=o(" (I-BERT model)"),yDo=l(),dv=a("li"),gme=a("strong"),LDo=o("layoutlmv2"),xDo=o(" \u2014 "),AG=a("a"),kDo=o("LayoutLMv2ForQuestionAnswering"),SDo=o(" (LayoutLMv2 model)"),RDo=l(),cv=a("li"),hme=a("strong"),BDo=o("led"),PDo=o(" \u2014 "),yG=a("a"),$Do=o("LEDForQuestionAnswering"),IDo=o(" (LED model)"),qDo=l(),fv=a("li"),pme=a("strong"),NDo=o("longformer"),jDo=o(" \u2014 "),LG=a("a"),DDo=o("LongformerForQuestionAnswering"),GDo=o(" (Longformer model)"),ODo=l(),mv=a("li"),_me=a("strong"),VDo=o("lxmert"),XDo=o(" \u2014 "),xG=a("a"),zDo=o("LxmertForQuestionAnswering"),QDo=o(" (LXMERT model)"),WDo=l(),gv=a("li"),ume=a("strong"),HDo=o("mbart"),UDo=o(" \u2014 "),kG=a("a"),JDo=o("MBartForQuestionAnswering"),YDo=o(" (mBART model)"),KDo=l(),hv=a("li"),bme=a("strong"),ZDo=o("megatron-bert"),eGo=o(" \u2014 "),SG=a("a"),oGo=o("MegatronBertForQuestionAnswering"),rGo=o(" (MegatronBert model)"),tGo=l(),pv=a("li"),vme=a("strong"),aGo=o("mobilebert"),nGo=o(" \u2014 "),RG=a("a"),sGo=o("MobileBertForQuestionAnswering"),lGo=o(" (MobileBERT model)"),iGo=l(),_v=a("li"),Fme=a("strong"),dGo=o("mpnet"),cGo=o(" \u2014 "),BG=a("a"),fGo=o("MPNetForQuestionAnswering"),mGo=o(" (MPNet model)"),gGo=l(),uv=a("li"),Tme=a("strong"),hGo=o("nystromformer"),pGo=o(" \u2014 "),PG=a("a"),_Go=o("NystromformerForQuestionAnswering"),uGo=o(" (Nystromformer model)"),bGo=l(),bv=a("li"),Mme=a("strong"),vGo=o("qdqbert"),FGo=o(" \u2014 "),$G=a("a"),TGo=o("QDQBertForQuestionAnswering"),MGo=o(" (QDQBert model)"),EGo=l(),vv=a("li"),Eme=a("strong"),CGo=o("reformer"),wGo=o(" \u2014 "),IG=a("a"),AGo=o("ReformerForQuestionAnswering"),yGo=o(" (Reformer model)"),LGo=l(),Fv=a("li"),Cme=a("strong"),xGo=o("rembert"),kGo=o(" \u2014 "),qG=a("a"),SGo=o("RemBertForQuestionAnswering"),RGo=o(" (RemBERT model)"),BGo=l(),Tv=a("li"),wme=a("strong"),PGo=o("roberta"),$Go=o(" \u2014 "),NG=a("a"),IGo=o("RobertaForQuestionAnswering"),qGo=o(" (RoBERTa model)"),NGo=l(),Mv=a("li"),Ame=a("strong"),jGo=o("roformer"),DGo=o(" \u2014 "),jG=a("a"),GGo=o("RoFormerForQuestionAnswering"),OGo=o(" (RoFormer model)"),VGo=l(),Ev=a("li"),yme=a("strong"),XGo=o("splinter"),zGo=o(" \u2014 "),DG=a("a"),QGo=o("SplinterForQuestionAnswering"),WGo=o(" (Splinter model)"),HGo=l(),Cv=a("li"),Lme=a("strong"),UGo=o("squeezebert"),JGo=o(" \u2014 "),GG=a("a"),YGo=o("SqueezeBertForQuestionAnswering"),KGo=o(" (SqueezeBERT model)"),ZGo=l(),wv=a("li"),xme=a("strong"),eOo=o("xlm"),oOo=o(" \u2014 "),OG=a("a"),rOo=o("XLMForQuestionAnsweringSimple"),tOo=o(" (XLM model)"),aOo=l(),Av=a("li"),kme=a("strong"),nOo=o("xlm-roberta"),sOo=o(" \u2014 "),VG=a("a"),lOo=o("XLMRobertaForQuestionAnswering"),iOo=o(" (XLM-RoBERTa model)"),dOo=l(),yv=a("li"),Sme=a("strong"),cOo=o("xlm-roberta-xl"),fOo=o(" \u2014 "),XG=a("a"),mOo=o("XLMRobertaXLForQuestionAnswering"),gOo=o(" (XLM-RoBERTa-XL model)"),hOo=l(),Lv=a("li"),Rme=a("strong"),pOo=o("xlnet"),_Oo=o(" \u2014 "),zG=a("a"),uOo=o("XLNetForQuestionAnsweringSimple"),bOo=o(" (XLNet model)"),vOo=l(),xv=a("li"),Bme=a("strong"),FOo=o("yoso"),TOo=o(" \u2014 "),QG=a("a"),MOo=o("YosoForQuestionAnswering"),EOo=o(" (YOSO model)"),COo=l(),kv=a("p"),wOo=o("The model is set in evaluation mode by default using "),Pme=a("code"),AOo=o("model.eval()"),yOo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$me=a("code"),LOo=o("model.train()"),xOo=l(),Ime=a("p"),kOo=o("Examples:"),SOo=l(),f(HC.$$.fragment),f$e=l(),Id=a("h2"),Sv=a("a"),qme=a("span"),f(UC.$$.fragment),ROo=l(),Nme=a("span"),BOo=o("AutoModelForTableQuestionAnswering"),m$e=l(),sr=a("div"),f(JC.$$.fragment),POo=l(),qd=a("p"),$Oo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),WG=a("a"),IOo=o("from_pretrained()"),qOo=o(" class method or the "),HG=a("a"),NOo=o("from_config()"),jOo=o(` class
method.`),DOo=l(),YC=a("p"),GOo=o("This class cannot be instantiated directly using "),jme=a("code"),OOo=o("__init__()"),VOo=o(" (throws an error)."),XOo=l(),et=a("div"),f(KC.$$.fragment),zOo=l(),Dme=a("p"),QOo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),WOo=l(),Nd=a("p"),HOo=o(`Note:
Loading a model from its configuration file does `),Gme=a("strong"),UOo=o("not"),JOo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UG=a("a"),YOo=o("from_pretrained()"),KOo=o(" to load the model weights."),ZOo=l(),Ome=a("p"),eVo=o("Examples:"),oVo=l(),f(ZC.$$.fragment),rVo=l(),Ue=a("div"),f(ew.$$.fragment),tVo=l(),Vme=a("p"),aVo=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),nVo=l(),en=a("p"),sVo=o("The model class to instantiate is selected based on the "),Xme=a("code"),lVo=o("model_type"),iVo=o(` property of the config object (either
passed as an argument or loaded from `),zme=a("code"),dVo=o("pretrained_model_name_or_path"),cVo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=a("code"),fVo=o("pretrained_model_name_or_path"),mVo=o(":"),gVo=l(),Wme=a("ul"),Rv=a("li"),Hme=a("strong"),hVo=o("tapas"),pVo=o(" \u2014 "),JG=a("a"),_Vo=o("TapasForQuestionAnswering"),uVo=o(" (TAPAS model)"),bVo=l(),Bv=a("p"),vVo=o("The model is set in evaluation mode by default using "),Ume=a("code"),FVo=o("model.eval()"),TVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jme=a("code"),MVo=o("model.train()"),EVo=l(),Yme=a("p"),CVo=o("Examples:"),wVo=l(),f(ow.$$.fragment),g$e=l(),jd=a("h2"),Pv=a("a"),Kme=a("span"),f(rw.$$.fragment),AVo=l(),Zme=a("span"),yVo=o("AutoModelForImageClassification"),h$e=l(),lr=a("div"),f(tw.$$.fragment),LVo=l(),Dd=a("p"),xVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),YG=a("a"),kVo=o("from_pretrained()"),SVo=o(" class method or the "),KG=a("a"),RVo=o("from_config()"),BVo=o(` class
method.`),PVo=l(),aw=a("p"),$Vo=o("This class cannot be instantiated directly using "),ege=a("code"),IVo=o("__init__()"),qVo=o(" (throws an error)."),NVo=l(),ot=a("div"),f(nw.$$.fragment),jVo=l(),oge=a("p"),DVo=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),GVo=l(),Gd=a("p"),OVo=o(`Note:
Loading a model from its configuration file does `),rge=a("strong"),VVo=o("not"),XVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZG=a("a"),zVo=o("from_pretrained()"),QVo=o(" to load the model weights."),WVo=l(),tge=a("p"),HVo=o("Examples:"),UVo=l(),f(sw.$$.fragment),JVo=l(),Je=a("div"),f(lw.$$.fragment),YVo=l(),age=a("p"),KVo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),ZVo=l(),on=a("p"),eXo=o("The model class to instantiate is selected based on the "),nge=a("code"),oXo=o("model_type"),rXo=o(` property of the config object (either
passed as an argument or loaded from `),sge=a("code"),tXo=o("pretrained_model_name_or_path"),aXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lge=a("code"),nXo=o("pretrained_model_name_or_path"),sXo=o(":"),lXo=l(),ce=a("ul"),$v=a("li"),ige=a("strong"),iXo=o("beit"),dXo=o(" \u2014 "),eO=a("a"),cXo=o("BeitForImageClassification"),fXo=o(" (BEiT model)"),mXo=l(),Iv=a("li"),dge=a("strong"),gXo=o("convnext"),hXo=o(" \u2014 "),oO=a("a"),pXo=o("ConvNextForImageClassification"),_Xo=o(" (ConvNext model)"),uXo=l(),qv=a("li"),cge=a("strong"),bXo=o("data2vec-vision"),vXo=o(" \u2014 "),rO=a("a"),FXo=o("Data2VecVisionForImageClassification"),TXo=o(" (Data2VecVision model)"),MXo=l(),Js=a("li"),fge=a("strong"),EXo=o("deit"),CXo=o(" \u2014 "),tO=a("a"),wXo=o("DeiTForImageClassification"),AXo=o(" or "),aO=a("a"),yXo=o("DeiTForImageClassificationWithTeacher"),LXo=o(" (DeiT model)"),xXo=l(),Nv=a("li"),mge=a("strong"),kXo=o("imagegpt"),SXo=o(" \u2014 "),nO=a("a"),RXo=o("ImageGPTForImageClassification"),BXo=o(" (ImageGPT model)"),PXo=l(),ma=a("li"),gge=a("strong"),$Xo=o("perceiver"),IXo=o(" \u2014 "),sO=a("a"),qXo=o("PerceiverForImageClassificationLearned"),NXo=o(" or "),lO=a("a"),jXo=o("PerceiverForImageClassificationFourier"),DXo=o(" or "),iO=a("a"),GXo=o("PerceiverForImageClassificationConvProcessing"),OXo=o(" (Perceiver model)"),VXo=l(),jv=a("li"),hge=a("strong"),XXo=o("poolformer"),zXo=o(" \u2014 "),dO=a("a"),QXo=o("PoolFormerForImageClassification"),WXo=o(" (PoolFormer model)"),HXo=l(),Dv=a("li"),pge=a("strong"),UXo=o("regnet"),JXo=o(" \u2014 "),cO=a("a"),YXo=o("RegNetForImageClassification"),KXo=o(" (RegNet model)"),ZXo=l(),Gv=a("li"),_ge=a("strong"),ezo=o("resnet"),ozo=o(" \u2014 "),fO=a("a"),rzo=o("ResNetForImageClassification"),tzo=o(" (ResNet model)"),azo=l(),Ov=a("li"),uge=a("strong"),nzo=o("segformer"),szo=o(" \u2014 "),mO=a("a"),lzo=o("SegformerForImageClassification"),izo=o(" (SegFormer model)"),dzo=l(),Vv=a("li"),bge=a("strong"),czo=o("swin"),fzo=o(" \u2014 "),gO=a("a"),mzo=o("SwinForImageClassification"),gzo=o(" (Swin model)"),hzo=l(),Xv=a("li"),vge=a("strong"),pzo=o("van"),_zo=o(" \u2014 "),hO=a("a"),uzo=o("VanForImageClassification"),bzo=o(" (VAN model)"),vzo=l(),zv=a("li"),Fge=a("strong"),Fzo=o("vit"),Tzo=o(" \u2014 "),pO=a("a"),Mzo=o("ViTForImageClassification"),Ezo=o(" (ViT model)"),Czo=l(),Qv=a("p"),wzo=o("The model is set in evaluation mode by default using "),Tge=a("code"),Azo=o("model.eval()"),yzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mge=a("code"),Lzo=o("model.train()"),xzo=l(),Ege=a("p"),kzo=o("Examples:"),Szo=l(),f(iw.$$.fragment),p$e=l(),Od=a("h2"),Wv=a("a"),Cge=a("span"),f(dw.$$.fragment),Rzo=l(),wge=a("span"),Bzo=o("AutoModelForVision2Seq"),_$e=l(),ir=a("div"),f(cw.$$.fragment),Pzo=l(),Vd=a("p"),$zo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),_O=a("a"),Izo=o("from_pretrained()"),qzo=o(" class method or the "),uO=a("a"),Nzo=o("from_config()"),jzo=o(` class
method.`),Dzo=l(),fw=a("p"),Gzo=o("This class cannot be instantiated directly using "),Age=a("code"),Ozo=o("__init__()"),Vzo=o(" (throws an error)."),Xzo=l(),rt=a("div"),f(mw.$$.fragment),zzo=l(),yge=a("p"),Qzo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Wzo=l(),Xd=a("p"),Hzo=o(`Note:
Loading a model from its configuration file does `),Lge=a("strong"),Uzo=o("not"),Jzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bO=a("a"),Yzo=o("from_pretrained()"),Kzo=o(" to load the model weights."),Zzo=l(),xge=a("p"),eQo=o("Examples:"),oQo=l(),f(gw.$$.fragment),rQo=l(),Ye=a("div"),f(hw.$$.fragment),tQo=l(),kge=a("p"),aQo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),nQo=l(),rn=a("p"),sQo=o("The model class to instantiate is selected based on the "),Sge=a("code"),lQo=o("model_type"),iQo=o(` property of the config object (either
passed as an argument or loaded from `),Rge=a("code"),dQo=o("pretrained_model_name_or_path"),cQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bge=a("code"),fQo=o("pretrained_model_name_or_path"),mQo=o(":"),gQo=l(),Pge=a("ul"),Hv=a("li"),$ge=a("strong"),hQo=o("vision-encoder-decoder"),pQo=o(" \u2014 "),vO=a("a"),_Qo=o("VisionEncoderDecoderModel"),uQo=o(" (Vision Encoder decoder model)"),bQo=l(),Uv=a("p"),vQo=o("The model is set in evaluation mode by default using "),Ige=a("code"),FQo=o("model.eval()"),TQo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qge=a("code"),MQo=o("model.train()"),EQo=l(),Nge=a("p"),CQo=o("Examples:"),wQo=l(),f(pw.$$.fragment),u$e=l(),zd=a("h2"),Jv=a("a"),jge=a("span"),f(_w.$$.fragment),AQo=l(),Dge=a("span"),yQo=o("AutoModelForAudioClassification"),b$e=l(),dr=a("div"),f(uw.$$.fragment),LQo=l(),Qd=a("p"),xQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),FO=a("a"),kQo=o("from_pretrained()"),SQo=o(" class method or the "),TO=a("a"),RQo=o("from_config()"),BQo=o(` class
method.`),PQo=l(),bw=a("p"),$Qo=o("This class cannot be instantiated directly using "),Gge=a("code"),IQo=o("__init__()"),qQo=o(" (throws an error)."),NQo=l(),tt=a("div"),f(vw.$$.fragment),jQo=l(),Oge=a("p"),DQo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),GQo=l(),Wd=a("p"),OQo=o(`Note:
Loading a model from its configuration file does `),Vge=a("strong"),VQo=o("not"),XQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MO=a("a"),zQo=o("from_pretrained()"),QQo=o(" to load the model weights."),WQo=l(),Xge=a("p"),HQo=o("Examples:"),UQo=l(),f(Fw.$$.fragment),JQo=l(),Ke=a("div"),f(Tw.$$.fragment),YQo=l(),zge=a("p"),KQo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),ZQo=l(),tn=a("p"),eWo=o("The model class to instantiate is selected based on the "),Qge=a("code"),oWo=o("model_type"),rWo=o(` property of the config object (either
passed as an argument or loaded from `),Wge=a("code"),tWo=o("pretrained_model_name_or_path"),aWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hge=a("code"),nWo=o("pretrained_model_name_or_path"),sWo=o(":"),lWo=l(),Be=a("ul"),Yv=a("li"),Uge=a("strong"),iWo=o("data2vec-audio"),dWo=o(" \u2014 "),EO=a("a"),cWo=o("Data2VecAudioForSequenceClassification"),fWo=o(" (Data2VecAudio model)"),mWo=l(),Kv=a("li"),Jge=a("strong"),gWo=o("hubert"),hWo=o(" \u2014 "),CO=a("a"),pWo=o("HubertForSequenceClassification"),_Wo=o(" (Hubert model)"),uWo=l(),Zv=a("li"),Yge=a("strong"),bWo=o("sew"),vWo=o(" \u2014 "),wO=a("a"),FWo=o("SEWForSequenceClassification"),TWo=o(" (SEW model)"),MWo=l(),eF=a("li"),Kge=a("strong"),EWo=o("sew-d"),CWo=o(" \u2014 "),AO=a("a"),wWo=o("SEWDForSequenceClassification"),AWo=o(" (SEW-D model)"),yWo=l(),oF=a("li"),Zge=a("strong"),LWo=o("unispeech"),xWo=o(" \u2014 "),yO=a("a"),kWo=o("UniSpeechForSequenceClassification"),SWo=o(" (UniSpeech model)"),RWo=l(),rF=a("li"),ehe=a("strong"),BWo=o("unispeech-sat"),PWo=o(" \u2014 "),LO=a("a"),$Wo=o("UniSpeechSatForSequenceClassification"),IWo=o(" (UniSpeechSat model)"),qWo=l(),tF=a("li"),ohe=a("strong"),NWo=o("wav2vec2"),jWo=o(" \u2014 "),xO=a("a"),DWo=o("Wav2Vec2ForSequenceClassification"),GWo=o(" (Wav2Vec2 model)"),OWo=l(),aF=a("li"),rhe=a("strong"),VWo=o("wavlm"),XWo=o(" \u2014 "),kO=a("a"),zWo=o("WavLMForSequenceClassification"),QWo=o(" (WavLM model)"),WWo=l(),nF=a("p"),HWo=o("The model is set in evaluation mode by default using "),the=a("code"),UWo=o("model.eval()"),JWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ahe=a("code"),YWo=o("model.train()"),KWo=l(),nhe=a("p"),ZWo=o("Examples:"),eHo=l(),f(Mw.$$.fragment),v$e=l(),Hd=a("h2"),sF=a("a"),she=a("span"),f(Ew.$$.fragment),oHo=l(),lhe=a("span"),rHo=o("AutoModelForAudioFrameClassification"),F$e=l(),cr=a("div"),f(Cw.$$.fragment),tHo=l(),Ud=a("p"),aHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),SO=a("a"),nHo=o("from_pretrained()"),sHo=o(" class method or the "),RO=a("a"),lHo=o("from_config()"),iHo=o(` class
method.`),dHo=l(),ww=a("p"),cHo=o("This class cannot be instantiated directly using "),ihe=a("code"),fHo=o("__init__()"),mHo=o(" (throws an error)."),gHo=l(),at=a("div"),f(Aw.$$.fragment),hHo=l(),dhe=a("p"),pHo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),_Ho=l(),Jd=a("p"),uHo=o(`Note:
Loading a model from its configuration file does `),che=a("strong"),bHo=o("not"),vHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BO=a("a"),FHo=o("from_pretrained()"),THo=o(" to load the model weights."),MHo=l(),fhe=a("p"),EHo=o("Examples:"),CHo=l(),f(yw.$$.fragment),wHo=l(),Ze=a("div"),f(Lw.$$.fragment),AHo=l(),mhe=a("p"),yHo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),LHo=l(),an=a("p"),xHo=o("The model class to instantiate is selected based on the "),ghe=a("code"),kHo=o("model_type"),SHo=o(` property of the config object (either
passed as an argument or loaded from `),hhe=a("code"),RHo=o("pretrained_model_name_or_path"),BHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),phe=a("code"),PHo=o("pretrained_model_name_or_path"),$Ho=o(":"),IHo=l(),nn=a("ul"),lF=a("li"),_he=a("strong"),qHo=o("data2vec-audio"),NHo=o(" \u2014 "),PO=a("a"),jHo=o("Data2VecAudioForAudioFrameClassification"),DHo=o(" (Data2VecAudio model)"),GHo=l(),iF=a("li"),uhe=a("strong"),OHo=o("unispeech-sat"),VHo=o(" \u2014 "),$O=a("a"),XHo=o("UniSpeechSatForAudioFrameClassification"),zHo=o(" (UniSpeechSat model)"),QHo=l(),dF=a("li"),bhe=a("strong"),WHo=o("wav2vec2"),HHo=o(" \u2014 "),IO=a("a"),UHo=o("Wav2Vec2ForAudioFrameClassification"),JHo=o(" (Wav2Vec2 model)"),YHo=l(),cF=a("li"),vhe=a("strong"),KHo=o("wavlm"),ZHo=o(" \u2014 "),qO=a("a"),eUo=o("WavLMForAudioFrameClassification"),oUo=o(" (WavLM model)"),rUo=l(),fF=a("p"),tUo=o("The model is set in evaluation mode by default using "),Fhe=a("code"),aUo=o("model.eval()"),nUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),The=a("code"),sUo=o("model.train()"),lUo=l(),Mhe=a("p"),iUo=o("Examples:"),dUo=l(),f(xw.$$.fragment),T$e=l(),Yd=a("h2"),mF=a("a"),Ehe=a("span"),f(kw.$$.fragment),cUo=l(),Che=a("span"),fUo=o("AutoModelForCTC"),M$e=l(),fr=a("div"),f(Sw.$$.fragment),mUo=l(),Kd=a("p"),gUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),NO=a("a"),hUo=o("from_pretrained()"),pUo=o(" class method or the "),jO=a("a"),_Uo=o("from_config()"),uUo=o(` class
method.`),bUo=l(),Rw=a("p"),vUo=o("This class cannot be instantiated directly using "),whe=a("code"),FUo=o("__init__()"),TUo=o(" (throws an error)."),MUo=l(),nt=a("div"),f(Bw.$$.fragment),EUo=l(),Ahe=a("p"),CUo=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),wUo=l(),Zd=a("p"),AUo=o(`Note:
Loading a model from its configuration file does `),yhe=a("strong"),yUo=o("not"),LUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DO=a("a"),xUo=o("from_pretrained()"),kUo=o(" to load the model weights."),SUo=l(),Lhe=a("p"),RUo=o("Examples:"),BUo=l(),f(Pw.$$.fragment),PUo=l(),eo=a("div"),f($w.$$.fragment),$Uo=l(),xhe=a("p"),IUo=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),qUo=l(),sn=a("p"),NUo=o("The model class to instantiate is selected based on the "),khe=a("code"),jUo=o("model_type"),DUo=o(` property of the config object (either
passed as an argument or loaded from `),She=a("code"),GUo=o("pretrained_model_name_or_path"),OUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rhe=a("code"),VUo=o("pretrained_model_name_or_path"),XUo=o(":"),zUo=l(),Pe=a("ul"),gF=a("li"),Bhe=a("strong"),QUo=o("data2vec-audio"),WUo=o(" \u2014 "),GO=a("a"),HUo=o("Data2VecAudioForCTC"),UUo=o(" (Data2VecAudio model)"),JUo=l(),hF=a("li"),Phe=a("strong"),YUo=o("hubert"),KUo=o(" \u2014 "),OO=a("a"),ZUo=o("HubertForCTC"),eJo=o(" (Hubert model)"),oJo=l(),pF=a("li"),$he=a("strong"),rJo=o("sew"),tJo=o(" \u2014 "),VO=a("a"),aJo=o("SEWForCTC"),nJo=o(" (SEW model)"),sJo=l(),_F=a("li"),Ihe=a("strong"),lJo=o("sew-d"),iJo=o(" \u2014 "),XO=a("a"),dJo=o("SEWDForCTC"),cJo=o(" (SEW-D model)"),fJo=l(),uF=a("li"),qhe=a("strong"),mJo=o("unispeech"),gJo=o(" \u2014 "),zO=a("a"),hJo=o("UniSpeechForCTC"),pJo=o(" (UniSpeech model)"),_Jo=l(),bF=a("li"),Nhe=a("strong"),uJo=o("unispeech-sat"),bJo=o(" \u2014 "),QO=a("a"),vJo=o("UniSpeechSatForCTC"),FJo=o(" (UniSpeechSat model)"),TJo=l(),vF=a("li"),jhe=a("strong"),MJo=o("wav2vec2"),EJo=o(" \u2014 "),WO=a("a"),CJo=o("Wav2Vec2ForCTC"),wJo=o(" (Wav2Vec2 model)"),AJo=l(),FF=a("li"),Dhe=a("strong"),yJo=o("wavlm"),LJo=o(" \u2014 "),HO=a("a"),xJo=o("WavLMForCTC"),kJo=o(" (WavLM model)"),SJo=l(),TF=a("p"),RJo=o("The model is set in evaluation mode by default using "),Ghe=a("code"),BJo=o("model.eval()"),PJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ohe=a("code"),$Jo=o("model.train()"),IJo=l(),Vhe=a("p"),qJo=o("Examples:"),NJo=l(),f(Iw.$$.fragment),E$e=l(),ec=a("h2"),MF=a("a"),Xhe=a("span"),f(qw.$$.fragment),jJo=l(),zhe=a("span"),DJo=o("AutoModelForSpeechSeq2Seq"),C$e=l(),mr=a("div"),f(Nw.$$.fragment),GJo=l(),oc=a("p"),OJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),UO=a("a"),VJo=o("from_pretrained()"),XJo=o(" class method or the "),JO=a("a"),zJo=o("from_config()"),QJo=o(` class
method.`),WJo=l(),jw=a("p"),HJo=o("This class cannot be instantiated directly using "),Qhe=a("code"),UJo=o("__init__()"),JJo=o(" (throws an error)."),YJo=l(),st=a("div"),f(Dw.$$.fragment),KJo=l(),Whe=a("p"),ZJo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),eYo=l(),rc=a("p"),oYo=o(`Note:
Loading a model from its configuration file does `),Hhe=a("strong"),rYo=o("not"),tYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YO=a("a"),aYo=o("from_pretrained()"),nYo=o(" to load the model weights."),sYo=l(),Uhe=a("p"),lYo=o("Examples:"),iYo=l(),f(Gw.$$.fragment),dYo=l(),oo=a("div"),f(Ow.$$.fragment),cYo=l(),Jhe=a("p"),fYo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),mYo=l(),ln=a("p"),gYo=o("The model class to instantiate is selected based on the "),Yhe=a("code"),hYo=o("model_type"),pYo=o(` property of the config object (either
passed as an argument or loaded from `),Khe=a("code"),_Yo=o("pretrained_model_name_or_path"),uYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zhe=a("code"),bYo=o("pretrained_model_name_or_path"),vYo=o(":"),FYo=l(),Vw=a("ul"),EF=a("li"),epe=a("strong"),TYo=o("speech-encoder-decoder"),MYo=o(" \u2014 "),KO=a("a"),EYo=o("SpeechEncoderDecoderModel"),CYo=o(" (Speech Encoder decoder model)"),wYo=l(),CF=a("li"),ope=a("strong"),AYo=o("speech_to_text"),yYo=o(" \u2014 "),ZO=a("a"),LYo=o("Speech2TextForConditionalGeneration"),xYo=o(" (Speech2Text model)"),kYo=l(),wF=a("p"),SYo=o("The model is set in evaluation mode by default using "),rpe=a("code"),RYo=o("model.eval()"),BYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tpe=a("code"),PYo=o("model.train()"),$Yo=l(),ape=a("p"),IYo=o("Examples:"),qYo=l(),f(Xw.$$.fragment),w$e=l(),tc=a("h2"),AF=a("a"),npe=a("span"),f(zw.$$.fragment),NYo=l(),spe=a("span"),jYo=o("AutoModelForAudioXVector"),A$e=l(),gr=a("div"),f(Qw.$$.fragment),DYo=l(),ac=a("p"),GYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),eV=a("a"),OYo=o("from_pretrained()"),VYo=o(" class method or the "),oV=a("a"),XYo=o("from_config()"),zYo=o(` class
method.`),QYo=l(),Ww=a("p"),WYo=o("This class cannot be instantiated directly using "),lpe=a("code"),HYo=o("__init__()"),UYo=o(" (throws an error)."),JYo=l(),lt=a("div"),f(Hw.$$.fragment),YYo=l(),ipe=a("p"),KYo=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),ZYo=l(),nc=a("p"),eKo=o(`Note:
Loading a model from its configuration file does `),dpe=a("strong"),oKo=o("not"),rKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rV=a("a"),tKo=o("from_pretrained()"),aKo=o(" to load the model weights."),nKo=l(),cpe=a("p"),sKo=o("Examples:"),lKo=l(),f(Uw.$$.fragment),iKo=l(),ro=a("div"),f(Jw.$$.fragment),dKo=l(),fpe=a("p"),cKo=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),fKo=l(),dn=a("p"),mKo=o("The model class to instantiate is selected based on the "),mpe=a("code"),gKo=o("model_type"),hKo=o(` property of the config object (either
passed as an argument or loaded from `),gpe=a("code"),pKo=o("pretrained_model_name_or_path"),_Ko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hpe=a("code"),uKo=o("pretrained_model_name_or_path"),bKo=o(":"),vKo=l(),cn=a("ul"),yF=a("li"),ppe=a("strong"),FKo=o("data2vec-audio"),TKo=o(" \u2014 "),tV=a("a"),MKo=o("Data2VecAudioForXVector"),EKo=o(" (Data2VecAudio model)"),CKo=l(),LF=a("li"),_pe=a("strong"),wKo=o("unispeech-sat"),AKo=o(" \u2014 "),aV=a("a"),yKo=o("UniSpeechSatForXVector"),LKo=o(" (UniSpeechSat model)"),xKo=l(),xF=a("li"),upe=a("strong"),kKo=o("wav2vec2"),SKo=o(" \u2014 "),nV=a("a"),RKo=o("Wav2Vec2ForXVector"),BKo=o(" (Wav2Vec2 model)"),PKo=l(),kF=a("li"),bpe=a("strong"),$Ko=o("wavlm"),IKo=o(" \u2014 "),sV=a("a"),qKo=o("WavLMForXVector"),NKo=o(" (WavLM model)"),jKo=l(),SF=a("p"),DKo=o("The model is set in evaluation mode by default using "),vpe=a("code"),GKo=o("model.eval()"),OKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fpe=a("code"),VKo=o("model.train()"),XKo=l(),Tpe=a("p"),zKo=o("Examples:"),QKo=l(),f(Yw.$$.fragment),y$e=l(),sc=a("h2"),RF=a("a"),Mpe=a("span"),f(Kw.$$.fragment),WKo=l(),Epe=a("span"),HKo=o("AutoModelForMaskedImageModeling"),L$e=l(),hr=a("div"),f(Zw.$$.fragment),UKo=l(),lc=a("p"),JKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),lV=a("a"),YKo=o("from_pretrained()"),KKo=o(" class method or the "),iV=a("a"),ZKo=o("from_config()"),eZo=o(` class
method.`),oZo=l(),e0=a("p"),rZo=o("This class cannot be instantiated directly using "),Cpe=a("code"),tZo=o("__init__()"),aZo=o(" (throws an error)."),nZo=l(),it=a("div"),f(o0.$$.fragment),sZo=l(),wpe=a("p"),lZo=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),iZo=l(),ic=a("p"),dZo=o(`Note:
Loading a model from its configuration file does `),Ape=a("strong"),cZo=o("not"),fZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dV=a("a"),mZo=o("from_pretrained()"),gZo=o(" to load the model weights."),hZo=l(),ype=a("p"),pZo=o("Examples:"),_Zo=l(),f(r0.$$.fragment),uZo=l(),to=a("div"),f(t0.$$.fragment),bZo=l(),Lpe=a("p"),vZo=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),FZo=l(),fn=a("p"),TZo=o("The model class to instantiate is selected based on the "),xpe=a("code"),MZo=o("model_type"),EZo=o(` property of the config object (either
passed as an argument or loaded from `),kpe=a("code"),CZo=o("pretrained_model_name_or_path"),wZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Spe=a("code"),AZo=o("pretrained_model_name_or_path"),yZo=o(":"),LZo=l(),dc=a("ul"),BF=a("li"),Rpe=a("strong"),xZo=o("deit"),kZo=o(" \u2014 "),cV=a("a"),SZo=o("DeiTForMaskedImageModeling"),RZo=o(" (DeiT model)"),BZo=l(),PF=a("li"),Bpe=a("strong"),PZo=o("swin"),$Zo=o(" \u2014 "),fV=a("a"),IZo=o("SwinForMaskedImageModeling"),qZo=o(" (Swin model)"),NZo=l(),$F=a("li"),Ppe=a("strong"),jZo=o("vit"),DZo=o(" \u2014 "),mV=a("a"),GZo=o("ViTForMaskedImageModeling"),OZo=o(" (ViT model)"),VZo=l(),IF=a("p"),XZo=o("The model is set in evaluation mode by default using "),$pe=a("code"),zZo=o("model.eval()"),QZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ipe=a("code"),WZo=o("model.train()"),HZo=l(),qpe=a("p"),UZo=o("Examples:"),JZo=l(),f(a0.$$.fragment),x$e=l(),cc=a("h2"),qF=a("a"),Npe=a("span"),f(n0.$$.fragment),YZo=l(),jpe=a("span"),KZo=o("AutoModelForObjectDetection"),k$e=l(),pr=a("div"),f(s0.$$.fragment),ZZo=l(),fc=a("p"),eer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),gV=a("a"),oer=o("from_pretrained()"),rer=o(" class method or the "),hV=a("a"),ter=o("from_config()"),aer=o(` class
method.`),ner=l(),l0=a("p"),ser=o("This class cannot be instantiated directly using "),Dpe=a("code"),ler=o("__init__()"),ier=o(" (throws an error)."),der=l(),dt=a("div"),f(i0.$$.fragment),cer=l(),Gpe=a("p"),fer=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),mer=l(),mc=a("p"),ger=o(`Note:
Loading a model from its configuration file does `),Ope=a("strong"),her=o("not"),per=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pV=a("a"),_er=o("from_pretrained()"),uer=o(" to load the model weights."),ber=l(),Vpe=a("p"),ver=o("Examples:"),Fer=l(),f(d0.$$.fragment),Ter=l(),ao=a("div"),f(c0.$$.fragment),Mer=l(),Xpe=a("p"),Eer=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Cer=l(),mn=a("p"),wer=o("The model class to instantiate is selected based on the "),zpe=a("code"),Aer=o("model_type"),yer=o(` property of the config object (either
passed as an argument or loaded from `),Qpe=a("code"),Ler=o("pretrained_model_name_or_path"),xer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wpe=a("code"),ker=o("pretrained_model_name_or_path"),Ser=o(":"),Rer=l(),Hpe=a("ul"),NF=a("li"),Upe=a("strong"),Ber=o("detr"),Per=o(" \u2014 "),_V=a("a"),$er=o("DetrForObjectDetection"),Ier=o(" (DETR model)"),qer=l(),jF=a("p"),Ner=o("The model is set in evaluation mode by default using "),Jpe=a("code"),jer=o("model.eval()"),Der=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=a("code"),Ger=o("model.train()"),Oer=l(),Kpe=a("p"),Ver=o("Examples:"),Xer=l(),f(f0.$$.fragment),S$e=l(),gc=a("h2"),DF=a("a"),Zpe=a("span"),f(m0.$$.fragment),zer=l(),e_e=a("span"),Qer=o("AutoModelForImageSegmentation"),R$e=l(),_r=a("div"),f(g0.$$.fragment),Wer=l(),hc=a("p"),Her=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),uV=a("a"),Uer=o("from_pretrained()"),Jer=o(" class method or the "),bV=a("a"),Yer=o("from_config()"),Ker=o(` class
method.`),Zer=l(),h0=a("p"),eor=o("This class cannot be instantiated directly using "),o_e=a("code"),oor=o("__init__()"),ror=o(" (throws an error)."),tor=l(),ct=a("div"),f(p0.$$.fragment),aor=l(),r_e=a("p"),nor=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),sor=l(),pc=a("p"),lor=o(`Note:
Loading a model from its configuration file does `),t_e=a("strong"),ior=o("not"),dor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vV=a("a"),cor=o("from_pretrained()"),mor=o(" to load the model weights."),gor=l(),a_e=a("p"),hor=o("Examples:"),por=l(),f(_0.$$.fragment),_or=l(),no=a("div"),f(u0.$$.fragment),uor=l(),n_e=a("p"),bor=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),vor=l(),gn=a("p"),For=o("The model class to instantiate is selected based on the "),s_e=a("code"),Tor=o("model_type"),Mor=o(` property of the config object (either
passed as an argument or loaded from `),l_e=a("code"),Eor=o("pretrained_model_name_or_path"),Cor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=a("code"),wor=o("pretrained_model_name_or_path"),Aor=o(":"),yor=l(),d_e=a("ul"),GF=a("li"),c_e=a("strong"),Lor=o("detr"),xor=o(" \u2014 "),FV=a("a"),kor=o("DetrForSegmentation"),Sor=o(" (DETR model)"),Ror=l(),OF=a("p"),Bor=o("The model is set in evaluation mode by default using "),f_e=a("code"),Por=o("model.eval()"),$or=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m_e=a("code"),Ior=o("model.train()"),qor=l(),g_e=a("p"),Nor=o("Examples:"),jor=l(),f(b0.$$.fragment),B$e=l(),_c=a("h2"),VF=a("a"),h_e=a("span"),f(v0.$$.fragment),Dor=l(),p_e=a("span"),Gor=o("AutoModelForSemanticSegmentation"),P$e=l(),ur=a("div"),f(F0.$$.fragment),Oor=l(),uc=a("p"),Vor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),TV=a("a"),Xor=o("from_pretrained()"),zor=o(" class method or the "),MV=a("a"),Qor=o("from_config()"),Wor=o(` class
method.`),Hor=l(),T0=a("p"),Uor=o("This class cannot be instantiated directly using "),__e=a("code"),Jor=o("__init__()"),Yor=o(" (throws an error)."),Kor=l(),ft=a("div"),f(M0.$$.fragment),Zor=l(),u_e=a("p"),err=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),orr=l(),bc=a("p"),rrr=o(`Note:
Loading a model from its configuration file does `),b_e=a("strong"),trr=o("not"),arr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EV=a("a"),nrr=o("from_pretrained()"),srr=o(" to load the model weights."),lrr=l(),v_e=a("p"),irr=o("Examples:"),drr=l(),f(E0.$$.fragment),crr=l(),so=a("div"),f(C0.$$.fragment),frr=l(),F_e=a("p"),mrr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),grr=l(),hn=a("p"),hrr=o("The model class to instantiate is selected based on the "),T_e=a("code"),prr=o("model_type"),_rr=o(` property of the config object (either
passed as an argument or loaded from `),M_e=a("code"),urr=o("pretrained_model_name_or_path"),brr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E_e=a("code"),vrr=o("pretrained_model_name_or_path"),Frr=o(":"),Trr=l(),pn=a("ul"),XF=a("li"),C_e=a("strong"),Mrr=o("beit"),Err=o(" \u2014 "),CV=a("a"),Crr=o("BeitForSemanticSegmentation"),wrr=o(" (BEiT model)"),Arr=l(),zF=a("li"),w_e=a("strong"),yrr=o("data2vec-vision"),Lrr=o(" \u2014 "),wV=a("a"),xrr=o("Data2VecVisionForSemanticSegmentation"),krr=o(" (Data2VecVision model)"),Srr=l(),QF=a("li"),A_e=a("strong"),Rrr=o("dpt"),Brr=o(" \u2014 "),AV=a("a"),Prr=o("DPTForSemanticSegmentation"),$rr=o(" (DPT model)"),Irr=l(),WF=a("li"),y_e=a("strong"),qrr=o("segformer"),Nrr=o(" \u2014 "),yV=a("a"),jrr=o("SegformerForSemanticSegmentation"),Drr=o(" (SegFormer model)"),Grr=l(),HF=a("p"),Orr=o("The model is set in evaluation mode by default using "),L_e=a("code"),Vrr=o("model.eval()"),Xrr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x_e=a("code"),zrr=o("model.train()"),Qrr=l(),k_e=a("p"),Wrr=o("Examples:"),Hrr=l(),f(w0.$$.fragment),$$e=l(),vc=a("h2"),UF=a("a"),S_e=a("span"),f(A0.$$.fragment),Urr=l(),R_e=a("span"),Jrr=o("AutoModelForInstanceSegmentation"),I$e=l(),br=a("div"),f(y0.$$.fragment),Yrr=l(),Fc=a("p"),Krr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),LV=a("a"),Zrr=o("from_pretrained()"),etr=o(" class method or the "),xV=a("a"),otr=o("from_config()"),rtr=o(` class
method.`),ttr=l(),L0=a("p"),atr=o("This class cannot be instantiated directly using "),B_e=a("code"),ntr=o("__init__()"),str=o(" (throws an error)."),ltr=l(),mt=a("div"),f(x0.$$.fragment),itr=l(),P_e=a("p"),dtr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),ctr=l(),Tc=a("p"),ftr=o(`Note:
Loading a model from its configuration file does `),$_e=a("strong"),mtr=o("not"),gtr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kV=a("a"),htr=o("from_pretrained()"),ptr=o(" to load the model weights."),_tr=l(),I_e=a("p"),utr=o("Examples:"),btr=l(),f(k0.$$.fragment),vtr=l(),lo=a("div"),f(S0.$$.fragment),Ftr=l(),q_e=a("p"),Ttr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Mtr=l(),_n=a("p"),Etr=o("The model class to instantiate is selected based on the "),N_e=a("code"),Ctr=o("model_type"),wtr=o(` property of the config object (either
passed as an argument or loaded from `),j_e=a("code"),Atr=o("pretrained_model_name_or_path"),ytr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D_e=a("code"),Ltr=o("pretrained_model_name_or_path"),xtr=o(":"),ktr=l(),G_e=a("ul"),JF=a("li"),O_e=a("strong"),Str=o("maskformer"),Rtr=o(" \u2014 "),SV=a("a"),Btr=o("MaskFormerForInstanceSegmentation"),Ptr=o(" (MaskFormer model)"),$tr=l(),YF=a("p"),Itr=o("The model is set in evaluation mode by default using "),V_e=a("code"),qtr=o("model.eval()"),Ntr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X_e=a("code"),jtr=o("model.train()"),Dtr=l(),z_e=a("p"),Gtr=o("Examples:"),Otr=l(),f(R0.$$.fragment),q$e=l(),Mc=a("h2"),KF=a("a"),Q_e=a("span"),f(B0.$$.fragment),Vtr=l(),W_e=a("span"),Xtr=o("TFAutoModel"),N$e=l(),vr=a("div"),f(P0.$$.fragment),ztr=l(),Ec=a("p"),Qtr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),RV=a("a"),Wtr=o("from_pretrained()"),Htr=o(" class method or the "),BV=a("a"),Utr=o("from_config()"),Jtr=o(` class
method.`),Ytr=l(),$0=a("p"),Ktr=o("This class cannot be instantiated directly using "),H_e=a("code"),Ztr=o("__init__()"),ear=o(" (throws an error)."),oar=l(),gt=a("div"),f(I0.$$.fragment),rar=l(),U_e=a("p"),tar=o("Instantiates one of the base model classes of the library from a configuration."),aar=l(),Cc=a("p"),nar=o(`Note:
Loading a model from its configuration file does `),J_e=a("strong"),sar=o("not"),lar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PV=a("a"),iar=o("from_pretrained()"),dar=o(" to load the model weights."),car=l(),Y_e=a("p"),far=o("Examples:"),mar=l(),f(q0.$$.fragment),gar=l(),po=a("div"),f(N0.$$.fragment),har=l(),K_e=a("p"),par=o("Instantiate one of the base model classes of the library from a pretrained model."),_ar=l(),un=a("p"),uar=o("The model class to instantiate is selected based on the "),Z_e=a("code"),bar=o("model_type"),Far=o(` property of the config object (either
passed as an argument or loaded from `),eue=a("code"),Tar=o("pretrained_model_name_or_path"),Mar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oue=a("code"),Ear=o("pretrained_model_name_or_path"),Car=o(":"),war=l(),x=a("ul"),ZF=a("li"),rue=a("strong"),Aar=o("albert"),yar=o(" \u2014 "),$V=a("a"),Lar=o("TFAlbertModel"),xar=o(" (ALBERT model)"),kar=l(),eT=a("li"),tue=a("strong"),Sar=o("bart"),Rar=o(" \u2014 "),IV=a("a"),Bar=o("TFBartModel"),Par=o(" (BART model)"),$ar=l(),oT=a("li"),aue=a("strong"),Iar=o("bert"),qar=o(" \u2014 "),qV=a("a"),Nar=o("TFBertModel"),jar=o(" (BERT model)"),Dar=l(),rT=a("li"),nue=a("strong"),Gar=o("blenderbot"),Oar=o(" \u2014 "),NV=a("a"),Var=o("TFBlenderbotModel"),Xar=o(" (Blenderbot model)"),zar=l(),tT=a("li"),sue=a("strong"),Qar=o("blenderbot-small"),War=o(" \u2014 "),jV=a("a"),Har=o("TFBlenderbotSmallModel"),Uar=o(" (BlenderbotSmall model)"),Jar=l(),aT=a("li"),lue=a("strong"),Yar=o("camembert"),Kar=o(" \u2014 "),DV=a("a"),Zar=o("TFCamembertModel"),enr=o(" (CamemBERT model)"),onr=l(),nT=a("li"),iue=a("strong"),rnr=o("clip"),tnr=o(" \u2014 "),GV=a("a"),anr=o("TFCLIPModel"),nnr=o(" (CLIP model)"),snr=l(),sT=a("li"),due=a("strong"),lnr=o("convbert"),inr=o(" \u2014 "),OV=a("a"),dnr=o("TFConvBertModel"),cnr=o(" (ConvBERT model)"),fnr=l(),lT=a("li"),cue=a("strong"),mnr=o("convnext"),gnr=o(" \u2014 "),VV=a("a"),hnr=o("TFConvNextModel"),pnr=o(" (ConvNext model)"),_nr=l(),iT=a("li"),fue=a("strong"),unr=o("ctrl"),bnr=o(" \u2014 "),XV=a("a"),vnr=o("TFCTRLModel"),Fnr=o(" (CTRL model)"),Tnr=l(),dT=a("li"),mue=a("strong"),Mnr=o("deberta"),Enr=o(" \u2014 "),zV=a("a"),Cnr=o("TFDebertaModel"),wnr=o(" (DeBERTa model)"),Anr=l(),cT=a("li"),gue=a("strong"),ynr=o("deberta-v2"),Lnr=o(" \u2014 "),QV=a("a"),xnr=o("TFDebertaV2Model"),knr=o(" (DeBERTa-v2 model)"),Snr=l(),fT=a("li"),hue=a("strong"),Rnr=o("distilbert"),Bnr=o(" \u2014 "),WV=a("a"),Pnr=o("TFDistilBertModel"),$nr=o(" (DistilBERT model)"),Inr=l(),mT=a("li"),pue=a("strong"),qnr=o("dpr"),Nnr=o(" \u2014 "),HV=a("a"),jnr=o("TFDPRQuestionEncoder"),Dnr=o(" (DPR model)"),Gnr=l(),gT=a("li"),_ue=a("strong"),Onr=o("electra"),Vnr=o(" \u2014 "),UV=a("a"),Xnr=o("TFElectraModel"),znr=o(" (ELECTRA model)"),Qnr=l(),hT=a("li"),uue=a("strong"),Wnr=o("flaubert"),Hnr=o(" \u2014 "),JV=a("a"),Unr=o("TFFlaubertModel"),Jnr=o(" (FlauBERT model)"),Ynr=l(),Ys=a("li"),bue=a("strong"),Knr=o("funnel"),Znr=o(" \u2014 "),YV=a("a"),esr=o("TFFunnelModel"),osr=o(" or "),KV=a("a"),rsr=o("TFFunnelBaseModel"),tsr=o(" (Funnel Transformer model)"),asr=l(),pT=a("li"),vue=a("strong"),nsr=o("gpt2"),ssr=o(" \u2014 "),ZV=a("a"),lsr=o("TFGPT2Model"),isr=o(" (OpenAI GPT-2 model)"),dsr=l(),_T=a("li"),Fue=a("strong"),csr=o("gptj"),fsr=o(" \u2014 "),eX=a("a"),msr=o("TFGPTJModel"),gsr=o(" (GPT-J model)"),hsr=l(),uT=a("li"),Tue=a("strong"),psr=o("hubert"),_sr=o(" \u2014 "),oX=a("a"),usr=o("TFHubertModel"),bsr=o(" (Hubert model)"),vsr=l(),bT=a("li"),Mue=a("strong"),Fsr=o("layoutlm"),Tsr=o(" \u2014 "),rX=a("a"),Msr=o("TFLayoutLMModel"),Esr=o(" (LayoutLM model)"),Csr=l(),vT=a("li"),Eue=a("strong"),wsr=o("led"),Asr=o(" \u2014 "),tX=a("a"),ysr=o("TFLEDModel"),Lsr=o(" (LED model)"),xsr=l(),FT=a("li"),Cue=a("strong"),ksr=o("longformer"),Ssr=o(" \u2014 "),aX=a("a"),Rsr=o("TFLongformerModel"),Bsr=o(" (Longformer model)"),Psr=l(),TT=a("li"),wue=a("strong"),$sr=o("lxmert"),Isr=o(" \u2014 "),nX=a("a"),qsr=o("TFLxmertModel"),Nsr=o(" (LXMERT model)"),jsr=l(),MT=a("li"),Aue=a("strong"),Dsr=o("marian"),Gsr=o(" \u2014 "),sX=a("a"),Osr=o("TFMarianModel"),Vsr=o(" (Marian model)"),Xsr=l(),ET=a("li"),yue=a("strong"),zsr=o("mbart"),Qsr=o(" \u2014 "),lX=a("a"),Wsr=o("TFMBartModel"),Hsr=o(" (mBART model)"),Usr=l(),CT=a("li"),Lue=a("strong"),Jsr=o("mobilebert"),Ysr=o(" \u2014 "),iX=a("a"),Ksr=o("TFMobileBertModel"),Zsr=o(" (MobileBERT model)"),elr=l(),wT=a("li"),xue=a("strong"),olr=o("mpnet"),rlr=o(" \u2014 "),dX=a("a"),tlr=o("TFMPNetModel"),alr=o(" (MPNet model)"),nlr=l(),AT=a("li"),kue=a("strong"),slr=o("mt5"),llr=o(" \u2014 "),cX=a("a"),ilr=o("TFMT5Model"),dlr=o(" (mT5 model)"),clr=l(),yT=a("li"),Sue=a("strong"),flr=o("openai-gpt"),mlr=o(" \u2014 "),fX=a("a"),glr=o("TFOpenAIGPTModel"),hlr=o(" (OpenAI GPT model)"),plr=l(),LT=a("li"),Rue=a("strong"),_lr=o("pegasus"),ulr=o(" \u2014 "),mX=a("a"),blr=o("TFPegasusModel"),vlr=o(" (Pegasus model)"),Flr=l(),xT=a("li"),Bue=a("strong"),Tlr=o("rembert"),Mlr=o(" \u2014 "),gX=a("a"),Elr=o("TFRemBertModel"),Clr=o(" (RemBERT model)"),wlr=l(),kT=a("li"),Pue=a("strong"),Alr=o("roberta"),ylr=o(" \u2014 "),hX=a("a"),Llr=o("TFRobertaModel"),xlr=o(" (RoBERTa model)"),klr=l(),ST=a("li"),$ue=a("strong"),Slr=o("roformer"),Rlr=o(" \u2014 "),pX=a("a"),Blr=o("TFRoFormerModel"),Plr=o(" (RoFormer model)"),$lr=l(),RT=a("li"),Iue=a("strong"),Ilr=o("speech_to_text"),qlr=o(" \u2014 "),_X=a("a"),Nlr=o("TFSpeech2TextModel"),jlr=o(" (Speech2Text model)"),Dlr=l(),BT=a("li"),que=a("strong"),Glr=o("t5"),Olr=o(" \u2014 "),uX=a("a"),Vlr=o("TFT5Model"),Xlr=o(" (T5 model)"),zlr=l(),PT=a("li"),Nue=a("strong"),Qlr=o("tapas"),Wlr=o(" \u2014 "),bX=a("a"),Hlr=o("TFTapasModel"),Ulr=o(" (TAPAS model)"),Jlr=l(),$T=a("li"),jue=a("strong"),Ylr=o("transfo-xl"),Klr=o(" \u2014 "),vX=a("a"),Zlr=o("TFTransfoXLModel"),eir=o(" (Transformer-XL model)"),oir=l(),IT=a("li"),Due=a("strong"),rir=o("vit"),tir=o(" \u2014 "),FX=a("a"),air=o("TFViTModel"),nir=o(" (ViT model)"),sir=l(),qT=a("li"),Gue=a("strong"),lir=o("vit_mae"),iir=o(" \u2014 "),TX=a("a"),dir=o("TFViTMAEModel"),cir=o(" (ViTMAE model)"),fir=l(),NT=a("li"),Oue=a("strong"),mir=o("wav2vec2"),gir=o(" \u2014 "),MX=a("a"),hir=o("TFWav2Vec2Model"),pir=o(" (Wav2Vec2 model)"),_ir=l(),jT=a("li"),Vue=a("strong"),uir=o("xlm"),bir=o(" \u2014 "),EX=a("a"),vir=o("TFXLMModel"),Fir=o(" (XLM model)"),Tir=l(),DT=a("li"),Xue=a("strong"),Mir=o("xlm-roberta"),Eir=o(" \u2014 "),CX=a("a"),Cir=o("TFXLMRobertaModel"),wir=o(" (XLM-RoBERTa model)"),Air=l(),GT=a("li"),zue=a("strong"),yir=o("xlnet"),Lir=o(" \u2014 "),wX=a("a"),xir=o("TFXLNetModel"),kir=o(" (XLNet model)"),Sir=l(),Que=a("p"),Rir=o("Examples:"),Bir=l(),f(j0.$$.fragment),j$e=l(),wc=a("h2"),OT=a("a"),Wue=a("span"),f(D0.$$.fragment),Pir=l(),Hue=a("span"),$ir=o("TFAutoModelForPreTraining"),D$e=l(),Fr=a("div"),f(G0.$$.fragment),Iir=l(),Ac=a("p"),qir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),AX=a("a"),Nir=o("from_pretrained()"),jir=o(" class method or the "),yX=a("a"),Dir=o("from_config()"),Gir=o(` class
method.`),Oir=l(),O0=a("p"),Vir=o("This class cannot be instantiated directly using "),Uue=a("code"),Xir=o("__init__()"),zir=o(" (throws an error)."),Qir=l(),ht=a("div"),f(V0.$$.fragment),Wir=l(),Jue=a("p"),Hir=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Uir=l(),yc=a("p"),Jir=o(`Note:
Loading a model from its configuration file does `),Yue=a("strong"),Yir=o("not"),Kir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LX=a("a"),Zir=o("from_pretrained()"),edr=o(" to load the model weights."),odr=l(),Kue=a("p"),rdr=o("Examples:"),tdr=l(),f(X0.$$.fragment),adr=l(),_o=a("div"),f(z0.$$.fragment),ndr=l(),Zue=a("p"),sdr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ldr=l(),bn=a("p"),idr=o("The model class to instantiate is selected based on the "),e2e=a("code"),ddr=o("model_type"),cdr=o(` property of the config object (either
passed as an argument or loaded from `),o2e=a("code"),fdr=o("pretrained_model_name_or_path"),mdr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r2e=a("code"),gdr=o("pretrained_model_name_or_path"),hdr=o(":"),pdr=l(),U=a("ul"),VT=a("li"),t2e=a("strong"),_dr=o("albert"),udr=o(" \u2014 "),xX=a("a"),bdr=o("TFAlbertForPreTraining"),vdr=o(" (ALBERT model)"),Fdr=l(),XT=a("li"),a2e=a("strong"),Tdr=o("bart"),Mdr=o(" \u2014 "),kX=a("a"),Edr=o("TFBartForConditionalGeneration"),Cdr=o(" (BART model)"),wdr=l(),zT=a("li"),n2e=a("strong"),Adr=o("bert"),ydr=o(" \u2014 "),SX=a("a"),Ldr=o("TFBertForPreTraining"),xdr=o(" (BERT model)"),kdr=l(),QT=a("li"),s2e=a("strong"),Sdr=o("camembert"),Rdr=o(" \u2014 "),RX=a("a"),Bdr=o("TFCamembertForMaskedLM"),Pdr=o(" (CamemBERT model)"),$dr=l(),WT=a("li"),l2e=a("strong"),Idr=o("ctrl"),qdr=o(" \u2014 "),BX=a("a"),Ndr=o("TFCTRLLMHeadModel"),jdr=o(" (CTRL model)"),Ddr=l(),HT=a("li"),i2e=a("strong"),Gdr=o("distilbert"),Odr=o(" \u2014 "),PX=a("a"),Vdr=o("TFDistilBertForMaskedLM"),Xdr=o(" (DistilBERT model)"),zdr=l(),UT=a("li"),d2e=a("strong"),Qdr=o("electra"),Wdr=o(" \u2014 "),$X=a("a"),Hdr=o("TFElectraForPreTraining"),Udr=o(" (ELECTRA model)"),Jdr=l(),JT=a("li"),c2e=a("strong"),Ydr=o("flaubert"),Kdr=o(" \u2014 "),IX=a("a"),Zdr=o("TFFlaubertWithLMHeadModel"),ecr=o(" (FlauBERT model)"),ocr=l(),YT=a("li"),f2e=a("strong"),rcr=o("funnel"),tcr=o(" \u2014 "),qX=a("a"),acr=o("TFFunnelForPreTraining"),ncr=o(" (Funnel Transformer model)"),scr=l(),KT=a("li"),m2e=a("strong"),lcr=o("gpt2"),icr=o(" \u2014 "),NX=a("a"),dcr=o("TFGPT2LMHeadModel"),ccr=o(" (OpenAI GPT-2 model)"),fcr=l(),ZT=a("li"),g2e=a("strong"),mcr=o("layoutlm"),gcr=o(" \u2014 "),jX=a("a"),hcr=o("TFLayoutLMForMaskedLM"),pcr=o(" (LayoutLM model)"),_cr=l(),e7=a("li"),h2e=a("strong"),ucr=o("lxmert"),bcr=o(" \u2014 "),DX=a("a"),vcr=o("TFLxmertForPreTraining"),Fcr=o(" (LXMERT model)"),Tcr=l(),o7=a("li"),p2e=a("strong"),Mcr=o("mobilebert"),Ecr=o(" \u2014 "),GX=a("a"),Ccr=o("TFMobileBertForPreTraining"),wcr=o(" (MobileBERT model)"),Acr=l(),r7=a("li"),_2e=a("strong"),ycr=o("mpnet"),Lcr=o(" \u2014 "),OX=a("a"),xcr=o("TFMPNetForMaskedLM"),kcr=o(" (MPNet model)"),Scr=l(),t7=a("li"),u2e=a("strong"),Rcr=o("openai-gpt"),Bcr=o(" \u2014 "),VX=a("a"),Pcr=o("TFOpenAIGPTLMHeadModel"),$cr=o(" (OpenAI GPT model)"),Icr=l(),a7=a("li"),b2e=a("strong"),qcr=o("roberta"),Ncr=o(" \u2014 "),XX=a("a"),jcr=o("TFRobertaForMaskedLM"),Dcr=o(" (RoBERTa model)"),Gcr=l(),n7=a("li"),v2e=a("strong"),Ocr=o("t5"),Vcr=o(" \u2014 "),zX=a("a"),Xcr=o("TFT5ForConditionalGeneration"),zcr=o(" (T5 model)"),Qcr=l(),s7=a("li"),F2e=a("strong"),Wcr=o("tapas"),Hcr=o(" \u2014 "),QX=a("a"),Ucr=o("TFTapasForMaskedLM"),Jcr=o(" (TAPAS model)"),Ycr=l(),l7=a("li"),T2e=a("strong"),Kcr=o("transfo-xl"),Zcr=o(" \u2014 "),WX=a("a"),efr=o("TFTransfoXLLMHeadModel"),ofr=o(" (Transformer-XL model)"),rfr=l(),i7=a("li"),M2e=a("strong"),tfr=o("vit_mae"),afr=o(" \u2014 "),HX=a("a"),nfr=o("TFViTMAEForPreTraining"),sfr=o(" (ViTMAE model)"),lfr=l(),d7=a("li"),E2e=a("strong"),ifr=o("xlm"),dfr=o(" \u2014 "),UX=a("a"),cfr=o("TFXLMWithLMHeadModel"),ffr=o(" (XLM model)"),mfr=l(),c7=a("li"),C2e=a("strong"),gfr=o("xlm-roberta"),hfr=o(" \u2014 "),JX=a("a"),pfr=o("TFXLMRobertaForMaskedLM"),_fr=o(" (XLM-RoBERTa model)"),ufr=l(),f7=a("li"),w2e=a("strong"),bfr=o("xlnet"),vfr=o(" \u2014 "),YX=a("a"),Ffr=o("TFXLNetLMHeadModel"),Tfr=o(" (XLNet model)"),Mfr=l(),A2e=a("p"),Efr=o("Examples:"),Cfr=l(),f(Q0.$$.fragment),G$e=l(),Lc=a("h2"),m7=a("a"),y2e=a("span"),f(W0.$$.fragment),wfr=l(),L2e=a("span"),Afr=o("TFAutoModelForCausalLM"),O$e=l(),Tr=a("div"),f(H0.$$.fragment),yfr=l(),xc=a("p"),Lfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),KX=a("a"),xfr=o("from_pretrained()"),kfr=o(" class method or the "),ZX=a("a"),Sfr=o("from_config()"),Rfr=o(` class
method.`),Bfr=l(),U0=a("p"),Pfr=o("This class cannot be instantiated directly using "),x2e=a("code"),$fr=o("__init__()"),Ifr=o(" (throws an error)."),qfr=l(),pt=a("div"),f(J0.$$.fragment),Nfr=l(),k2e=a("p"),jfr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Dfr=l(),kc=a("p"),Gfr=o(`Note:
Loading a model from its configuration file does `),S2e=a("strong"),Ofr=o("not"),Vfr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ez=a("a"),Xfr=o("from_pretrained()"),zfr=o(" to load the model weights."),Qfr=l(),R2e=a("p"),Wfr=o("Examples:"),Hfr=l(),f(Y0.$$.fragment),Ufr=l(),uo=a("div"),f(K0.$$.fragment),Jfr=l(),B2e=a("p"),Yfr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Kfr=l(),vn=a("p"),Zfr=o("The model class to instantiate is selected based on the "),P2e=a("code"),emr=o("model_type"),omr=o(` property of the config object (either
passed as an argument or loaded from `),$2e=a("code"),rmr=o("pretrained_model_name_or_path"),tmr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I2e=a("code"),amr=o("pretrained_model_name_or_path"),nmr=o(":"),smr=l(),he=a("ul"),g7=a("li"),q2e=a("strong"),lmr=o("bert"),imr=o(" \u2014 "),oz=a("a"),dmr=o("TFBertLMHeadModel"),cmr=o(" (BERT model)"),fmr=l(),h7=a("li"),N2e=a("strong"),mmr=o("camembert"),gmr=o(" \u2014 "),rz=a("a"),hmr=o("TFCamembertForCausalLM"),pmr=o(" (CamemBERT model)"),_mr=l(),p7=a("li"),j2e=a("strong"),umr=o("ctrl"),bmr=o(" \u2014 "),tz=a("a"),vmr=o("TFCTRLLMHeadModel"),Fmr=o(" (CTRL model)"),Tmr=l(),_7=a("li"),D2e=a("strong"),Mmr=o("gpt2"),Emr=o(" \u2014 "),az=a("a"),Cmr=o("TFGPT2LMHeadModel"),wmr=o(" (OpenAI GPT-2 model)"),Amr=l(),u7=a("li"),G2e=a("strong"),ymr=o("gptj"),Lmr=o(" \u2014 "),nz=a("a"),xmr=o("TFGPTJForCausalLM"),kmr=o(" (GPT-J model)"),Smr=l(),b7=a("li"),O2e=a("strong"),Rmr=o("openai-gpt"),Bmr=o(" \u2014 "),sz=a("a"),Pmr=o("TFOpenAIGPTLMHeadModel"),$mr=o(" (OpenAI GPT model)"),Imr=l(),v7=a("li"),V2e=a("strong"),qmr=o("rembert"),Nmr=o(" \u2014 "),lz=a("a"),jmr=o("TFRemBertForCausalLM"),Dmr=o(" (RemBERT model)"),Gmr=l(),F7=a("li"),X2e=a("strong"),Omr=o("roberta"),Vmr=o(" \u2014 "),iz=a("a"),Xmr=o("TFRobertaForCausalLM"),zmr=o(" (RoBERTa model)"),Qmr=l(),T7=a("li"),z2e=a("strong"),Wmr=o("roformer"),Hmr=o(" \u2014 "),dz=a("a"),Umr=o("TFRoFormerForCausalLM"),Jmr=o(" (RoFormer model)"),Ymr=l(),M7=a("li"),Q2e=a("strong"),Kmr=o("transfo-xl"),Zmr=o(" \u2014 "),cz=a("a"),egr=o("TFTransfoXLLMHeadModel"),ogr=o(" (Transformer-XL model)"),rgr=l(),E7=a("li"),W2e=a("strong"),tgr=o("xlm"),agr=o(" \u2014 "),fz=a("a"),ngr=o("TFXLMWithLMHeadModel"),sgr=o(" (XLM model)"),lgr=l(),C7=a("li"),H2e=a("strong"),igr=o("xlnet"),dgr=o(" \u2014 "),mz=a("a"),cgr=o("TFXLNetLMHeadModel"),fgr=o(" (XLNet model)"),mgr=l(),U2e=a("p"),ggr=o("Examples:"),hgr=l(),f(Z0.$$.fragment),V$e=l(),Sc=a("h2"),w7=a("a"),J2e=a("span"),f(eA.$$.fragment),pgr=l(),Y2e=a("span"),_gr=o("TFAutoModelForImageClassification"),X$e=l(),Mr=a("div"),f(oA.$$.fragment),ugr=l(),Rc=a("p"),bgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),gz=a("a"),vgr=o("from_pretrained()"),Fgr=o(" class method or the "),hz=a("a"),Tgr=o("from_config()"),Mgr=o(` class
method.`),Egr=l(),rA=a("p"),Cgr=o("This class cannot be instantiated directly using "),K2e=a("code"),wgr=o("__init__()"),Agr=o(" (throws an error)."),ygr=l(),_t=a("div"),f(tA.$$.fragment),Lgr=l(),Z2e=a("p"),xgr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),kgr=l(),Bc=a("p"),Sgr=o(`Note:
Loading a model from its configuration file does `),e1e=a("strong"),Rgr=o("not"),Bgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pz=a("a"),Pgr=o("from_pretrained()"),$gr=o(" to load the model weights."),Igr=l(),o1e=a("p"),qgr=o("Examples:"),Ngr=l(),f(aA.$$.fragment),jgr=l(),bo=a("div"),f(nA.$$.fragment),Dgr=l(),r1e=a("p"),Ggr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ogr=l(),Fn=a("p"),Vgr=o("The model class to instantiate is selected based on the "),t1e=a("code"),Xgr=o("model_type"),zgr=o(` property of the config object (either
passed as an argument or loaded from `),a1e=a("code"),Qgr=o("pretrained_model_name_or_path"),Wgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n1e=a("code"),Hgr=o("pretrained_model_name_or_path"),Ugr=o(":"),Jgr=l(),sA=a("ul"),A7=a("li"),s1e=a("strong"),Ygr=o("convnext"),Kgr=o(" \u2014 "),_z=a("a"),Zgr=o("TFConvNextForImageClassification"),ehr=o(" (ConvNext model)"),ohr=l(),y7=a("li"),l1e=a("strong"),rhr=o("vit"),thr=o(" \u2014 "),uz=a("a"),ahr=o("TFViTForImageClassification"),nhr=o(" (ViT model)"),shr=l(),i1e=a("p"),lhr=o("Examples:"),ihr=l(),f(lA.$$.fragment),z$e=l(),Pc=a("h2"),L7=a("a"),d1e=a("span"),f(iA.$$.fragment),dhr=l(),c1e=a("span"),chr=o("TFAutoModelForMaskedLM"),Q$e=l(),Er=a("div"),f(dA.$$.fragment),fhr=l(),$c=a("p"),mhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),bz=a("a"),ghr=o("from_pretrained()"),hhr=o(" class method or the "),vz=a("a"),phr=o("from_config()"),_hr=o(` class
method.`),uhr=l(),cA=a("p"),bhr=o("This class cannot be instantiated directly using "),f1e=a("code"),vhr=o("__init__()"),Fhr=o(" (throws an error)."),Thr=l(),ut=a("div"),f(fA.$$.fragment),Mhr=l(),m1e=a("p"),Ehr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Chr=l(),Ic=a("p"),whr=o(`Note:
Loading a model from its configuration file does `),g1e=a("strong"),Ahr=o("not"),yhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=a("a"),Lhr=o("from_pretrained()"),xhr=o(" to load the model weights."),khr=l(),h1e=a("p"),Shr=o("Examples:"),Rhr=l(),f(mA.$$.fragment),Bhr=l(),vo=a("div"),f(gA.$$.fragment),Phr=l(),p1e=a("p"),$hr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Ihr=l(),Tn=a("p"),qhr=o("The model class to instantiate is selected based on the "),_1e=a("code"),Nhr=o("model_type"),jhr=o(` property of the config object (either
passed as an argument or loaded from `),u1e=a("code"),Dhr=o("pretrained_model_name_or_path"),Ghr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b1e=a("code"),Ohr=o("pretrained_model_name_or_path"),Vhr=o(":"),Xhr=l(),K=a("ul"),x7=a("li"),v1e=a("strong"),zhr=o("albert"),Qhr=o(" \u2014 "),Tz=a("a"),Whr=o("TFAlbertForMaskedLM"),Hhr=o(" (ALBERT model)"),Uhr=l(),k7=a("li"),F1e=a("strong"),Jhr=o("bert"),Yhr=o(" \u2014 "),Mz=a("a"),Khr=o("TFBertForMaskedLM"),Zhr=o(" (BERT model)"),epr=l(),S7=a("li"),T1e=a("strong"),opr=o("camembert"),rpr=o(" \u2014 "),Ez=a("a"),tpr=o("TFCamembertForMaskedLM"),apr=o(" (CamemBERT model)"),npr=l(),R7=a("li"),M1e=a("strong"),spr=o("convbert"),lpr=o(" \u2014 "),Cz=a("a"),ipr=o("TFConvBertForMaskedLM"),dpr=o(" (ConvBERT model)"),cpr=l(),B7=a("li"),E1e=a("strong"),fpr=o("deberta"),mpr=o(" \u2014 "),wz=a("a"),gpr=o("TFDebertaForMaskedLM"),hpr=o(" (DeBERTa model)"),ppr=l(),P7=a("li"),C1e=a("strong"),_pr=o("deberta-v2"),upr=o(" \u2014 "),Az=a("a"),bpr=o("TFDebertaV2ForMaskedLM"),vpr=o(" (DeBERTa-v2 model)"),Fpr=l(),$7=a("li"),w1e=a("strong"),Tpr=o("distilbert"),Mpr=o(" \u2014 "),yz=a("a"),Epr=o("TFDistilBertForMaskedLM"),Cpr=o(" (DistilBERT model)"),wpr=l(),I7=a("li"),A1e=a("strong"),Apr=o("electra"),ypr=o(" \u2014 "),Lz=a("a"),Lpr=o("TFElectraForMaskedLM"),xpr=o(" (ELECTRA model)"),kpr=l(),q7=a("li"),y1e=a("strong"),Spr=o("flaubert"),Rpr=o(" \u2014 "),xz=a("a"),Bpr=o("TFFlaubertWithLMHeadModel"),Ppr=o(" (FlauBERT model)"),$pr=l(),N7=a("li"),L1e=a("strong"),Ipr=o("funnel"),qpr=o(" \u2014 "),kz=a("a"),Npr=o("TFFunnelForMaskedLM"),jpr=o(" (Funnel Transformer model)"),Dpr=l(),j7=a("li"),x1e=a("strong"),Gpr=o("layoutlm"),Opr=o(" \u2014 "),Sz=a("a"),Vpr=o("TFLayoutLMForMaskedLM"),Xpr=o(" (LayoutLM model)"),zpr=l(),D7=a("li"),k1e=a("strong"),Qpr=o("longformer"),Wpr=o(" \u2014 "),Rz=a("a"),Hpr=o("TFLongformerForMaskedLM"),Upr=o(" (Longformer model)"),Jpr=l(),G7=a("li"),S1e=a("strong"),Ypr=o("mobilebert"),Kpr=o(" \u2014 "),Bz=a("a"),Zpr=o("TFMobileBertForMaskedLM"),e_r=o(" (MobileBERT model)"),o_r=l(),O7=a("li"),R1e=a("strong"),r_r=o("mpnet"),t_r=o(" \u2014 "),Pz=a("a"),a_r=o("TFMPNetForMaskedLM"),n_r=o(" (MPNet model)"),s_r=l(),V7=a("li"),B1e=a("strong"),l_r=o("rembert"),i_r=o(" \u2014 "),$z=a("a"),d_r=o("TFRemBertForMaskedLM"),c_r=o(" (RemBERT model)"),f_r=l(),X7=a("li"),P1e=a("strong"),m_r=o("roberta"),g_r=o(" \u2014 "),Iz=a("a"),h_r=o("TFRobertaForMaskedLM"),p_r=o(" (RoBERTa model)"),__r=l(),z7=a("li"),$1e=a("strong"),u_r=o("roformer"),b_r=o(" \u2014 "),qz=a("a"),v_r=o("TFRoFormerForMaskedLM"),F_r=o(" (RoFormer model)"),T_r=l(),Q7=a("li"),I1e=a("strong"),M_r=o("tapas"),E_r=o(" \u2014 "),Nz=a("a"),C_r=o("TFTapasForMaskedLM"),w_r=o(" (TAPAS model)"),A_r=l(),W7=a("li"),q1e=a("strong"),y_r=o("xlm"),L_r=o(" \u2014 "),jz=a("a"),x_r=o("TFXLMWithLMHeadModel"),k_r=o(" (XLM model)"),S_r=l(),H7=a("li"),N1e=a("strong"),R_r=o("xlm-roberta"),B_r=o(" \u2014 "),Dz=a("a"),P_r=o("TFXLMRobertaForMaskedLM"),$_r=o(" (XLM-RoBERTa model)"),I_r=l(),j1e=a("p"),q_r=o("Examples:"),N_r=l(),f(hA.$$.fragment),W$e=l(),qc=a("h2"),U7=a("a"),D1e=a("span"),f(pA.$$.fragment),j_r=l(),G1e=a("span"),D_r=o("TFAutoModelForSeq2SeqLM"),H$e=l(),Cr=a("div"),f(_A.$$.fragment),G_r=l(),Nc=a("p"),O_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Gz=a("a"),V_r=o("from_pretrained()"),X_r=o(" class method or the "),Oz=a("a"),z_r=o("from_config()"),Q_r=o(` class
method.`),W_r=l(),uA=a("p"),H_r=o("This class cannot be instantiated directly using "),O1e=a("code"),U_r=o("__init__()"),J_r=o(" (throws an error)."),Y_r=l(),bt=a("div"),f(bA.$$.fragment),K_r=l(),V1e=a("p"),Z_r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),eur=l(),jc=a("p"),our=o(`Note:
Loading a model from its configuration file does `),X1e=a("strong"),rur=o("not"),tur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vz=a("a"),aur=o("from_pretrained()"),nur=o(" to load the model weights."),sur=l(),z1e=a("p"),lur=o("Examples:"),iur=l(),f(vA.$$.fragment),dur=l(),Fo=a("div"),f(FA.$$.fragment),cur=l(),Q1e=a("p"),fur=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),mur=l(),Mn=a("p"),gur=o("The model class to instantiate is selected based on the "),W1e=a("code"),hur=o("model_type"),pur=o(` property of the config object (either
passed as an argument or loaded from `),H1e=a("code"),_ur=o("pretrained_model_name_or_path"),uur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U1e=a("code"),bur=o("pretrained_model_name_or_path"),vur=o(":"),Fur=l(),Fe=a("ul"),J7=a("li"),J1e=a("strong"),Tur=o("bart"),Mur=o(" \u2014 "),Xz=a("a"),Eur=o("TFBartForConditionalGeneration"),Cur=o(" (BART model)"),wur=l(),Y7=a("li"),Y1e=a("strong"),Aur=o("blenderbot"),yur=o(" \u2014 "),zz=a("a"),Lur=o("TFBlenderbotForConditionalGeneration"),xur=o(" (Blenderbot model)"),kur=l(),K7=a("li"),K1e=a("strong"),Sur=o("blenderbot-small"),Rur=o(" \u2014 "),Qz=a("a"),Bur=o("TFBlenderbotSmallForConditionalGeneration"),Pur=o(" (BlenderbotSmall model)"),$ur=l(),Z7=a("li"),Z1e=a("strong"),Iur=o("encoder-decoder"),qur=o(" \u2014 "),Wz=a("a"),Nur=o("TFEncoderDecoderModel"),jur=o(" (Encoder decoder model)"),Dur=l(),e9=a("li"),ebe=a("strong"),Gur=o("led"),Our=o(" \u2014 "),Hz=a("a"),Vur=o("TFLEDForConditionalGeneration"),Xur=o(" (LED model)"),zur=l(),o9=a("li"),obe=a("strong"),Qur=o("marian"),Wur=o(" \u2014 "),Uz=a("a"),Hur=o("TFMarianMTModel"),Uur=o(" (Marian model)"),Jur=l(),r9=a("li"),rbe=a("strong"),Yur=o("mbart"),Kur=o(" \u2014 "),Jz=a("a"),Zur=o("TFMBartForConditionalGeneration"),e2r=o(" (mBART model)"),o2r=l(),t9=a("li"),tbe=a("strong"),r2r=o("mt5"),t2r=o(" \u2014 "),Yz=a("a"),a2r=o("TFMT5ForConditionalGeneration"),n2r=o(" (mT5 model)"),s2r=l(),a9=a("li"),abe=a("strong"),l2r=o("pegasus"),i2r=o(" \u2014 "),Kz=a("a"),d2r=o("TFPegasusForConditionalGeneration"),c2r=o(" (Pegasus model)"),f2r=l(),n9=a("li"),nbe=a("strong"),m2r=o("t5"),g2r=o(" \u2014 "),Zz=a("a"),h2r=o("TFT5ForConditionalGeneration"),p2r=o(" (T5 model)"),_2r=l(),sbe=a("p"),u2r=o("Examples:"),b2r=l(),f(TA.$$.fragment),U$e=l(),Dc=a("h2"),s9=a("a"),lbe=a("span"),f(MA.$$.fragment),v2r=l(),ibe=a("span"),F2r=o("TFAutoModelForSequenceClassification"),J$e=l(),wr=a("div"),f(EA.$$.fragment),T2r=l(),Gc=a("p"),M2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),eQ=a("a"),E2r=o("from_pretrained()"),C2r=o(" class method or the "),oQ=a("a"),w2r=o("from_config()"),A2r=o(` class
method.`),y2r=l(),CA=a("p"),L2r=o("This class cannot be instantiated directly using "),dbe=a("code"),x2r=o("__init__()"),k2r=o(" (throws an error)."),S2r=l(),vt=a("div"),f(wA.$$.fragment),R2r=l(),cbe=a("p"),B2r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),P2r=l(),Oc=a("p"),$2r=o(`Note:
Loading a model from its configuration file does `),fbe=a("strong"),I2r=o("not"),q2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rQ=a("a"),N2r=o("from_pretrained()"),j2r=o(" to load the model weights."),D2r=l(),mbe=a("p"),G2r=o("Examples:"),O2r=l(),f(AA.$$.fragment),V2r=l(),To=a("div"),f(yA.$$.fragment),X2r=l(),gbe=a("p"),z2r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Q2r=l(),En=a("p"),W2r=o("The model class to instantiate is selected based on the "),hbe=a("code"),H2r=o("model_type"),U2r=o(` property of the config object (either
passed as an argument or loaded from `),pbe=a("code"),J2r=o("pretrained_model_name_or_path"),Y2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_be=a("code"),K2r=o("pretrained_model_name_or_path"),Z2r=o(":"),e1r=l(),V=a("ul"),l9=a("li"),ube=a("strong"),o1r=o("albert"),r1r=o(" \u2014 "),tQ=a("a"),t1r=o("TFAlbertForSequenceClassification"),a1r=o(" (ALBERT model)"),n1r=l(),i9=a("li"),bbe=a("strong"),s1r=o("bert"),l1r=o(" \u2014 "),aQ=a("a"),i1r=o("TFBertForSequenceClassification"),d1r=o(" (BERT model)"),c1r=l(),d9=a("li"),vbe=a("strong"),f1r=o("camembert"),m1r=o(" \u2014 "),nQ=a("a"),g1r=o("TFCamembertForSequenceClassification"),h1r=o(" (CamemBERT model)"),p1r=l(),c9=a("li"),Fbe=a("strong"),_1r=o("convbert"),u1r=o(" \u2014 "),sQ=a("a"),b1r=o("TFConvBertForSequenceClassification"),v1r=o(" (ConvBERT model)"),F1r=l(),f9=a("li"),Tbe=a("strong"),T1r=o("ctrl"),M1r=o(" \u2014 "),lQ=a("a"),E1r=o("TFCTRLForSequenceClassification"),C1r=o(" (CTRL model)"),w1r=l(),m9=a("li"),Mbe=a("strong"),A1r=o("deberta"),y1r=o(" \u2014 "),iQ=a("a"),L1r=o("TFDebertaForSequenceClassification"),x1r=o(" (DeBERTa model)"),k1r=l(),g9=a("li"),Ebe=a("strong"),S1r=o("deberta-v2"),R1r=o(" \u2014 "),dQ=a("a"),B1r=o("TFDebertaV2ForSequenceClassification"),P1r=o(" (DeBERTa-v2 model)"),$1r=l(),h9=a("li"),Cbe=a("strong"),I1r=o("distilbert"),q1r=o(" \u2014 "),cQ=a("a"),N1r=o("TFDistilBertForSequenceClassification"),j1r=o(" (DistilBERT model)"),D1r=l(),p9=a("li"),wbe=a("strong"),G1r=o("electra"),O1r=o(" \u2014 "),fQ=a("a"),V1r=o("TFElectraForSequenceClassification"),X1r=o(" (ELECTRA model)"),z1r=l(),_9=a("li"),Abe=a("strong"),Q1r=o("flaubert"),W1r=o(" \u2014 "),mQ=a("a"),H1r=o("TFFlaubertForSequenceClassification"),U1r=o(" (FlauBERT model)"),J1r=l(),u9=a("li"),ybe=a("strong"),Y1r=o("funnel"),K1r=o(" \u2014 "),gQ=a("a"),Z1r=o("TFFunnelForSequenceClassification"),ebr=o(" (Funnel Transformer model)"),obr=l(),b9=a("li"),Lbe=a("strong"),rbr=o("gpt2"),tbr=o(" \u2014 "),hQ=a("a"),abr=o("TFGPT2ForSequenceClassification"),nbr=o(" (OpenAI GPT-2 model)"),sbr=l(),v9=a("li"),xbe=a("strong"),lbr=o("gptj"),ibr=o(" \u2014 "),pQ=a("a"),dbr=o("TFGPTJForSequenceClassification"),cbr=o(" (GPT-J model)"),fbr=l(),F9=a("li"),kbe=a("strong"),mbr=o("layoutlm"),gbr=o(" \u2014 "),_Q=a("a"),hbr=o("TFLayoutLMForSequenceClassification"),pbr=o(" (LayoutLM model)"),_br=l(),T9=a("li"),Sbe=a("strong"),ubr=o("longformer"),bbr=o(" \u2014 "),uQ=a("a"),vbr=o("TFLongformerForSequenceClassification"),Fbr=o(" (Longformer model)"),Tbr=l(),M9=a("li"),Rbe=a("strong"),Mbr=o("mobilebert"),Ebr=o(" \u2014 "),bQ=a("a"),Cbr=o("TFMobileBertForSequenceClassification"),wbr=o(" (MobileBERT model)"),Abr=l(),E9=a("li"),Bbe=a("strong"),ybr=o("mpnet"),Lbr=o(" \u2014 "),vQ=a("a"),xbr=o("TFMPNetForSequenceClassification"),kbr=o(" (MPNet model)"),Sbr=l(),C9=a("li"),Pbe=a("strong"),Rbr=o("openai-gpt"),Bbr=o(" \u2014 "),FQ=a("a"),Pbr=o("TFOpenAIGPTForSequenceClassification"),$br=o(" (OpenAI GPT model)"),Ibr=l(),w9=a("li"),$be=a("strong"),qbr=o("rembert"),Nbr=o(" \u2014 "),TQ=a("a"),jbr=o("TFRemBertForSequenceClassification"),Dbr=o(" (RemBERT model)"),Gbr=l(),A9=a("li"),Ibe=a("strong"),Obr=o("roberta"),Vbr=o(" \u2014 "),MQ=a("a"),Xbr=o("TFRobertaForSequenceClassification"),zbr=o(" (RoBERTa model)"),Qbr=l(),y9=a("li"),qbe=a("strong"),Wbr=o("roformer"),Hbr=o(" \u2014 "),EQ=a("a"),Ubr=o("TFRoFormerForSequenceClassification"),Jbr=o(" (RoFormer model)"),Ybr=l(),L9=a("li"),Nbe=a("strong"),Kbr=o("tapas"),Zbr=o(" \u2014 "),CQ=a("a"),e6r=o("TFTapasForSequenceClassification"),o6r=o(" (TAPAS model)"),r6r=l(),x9=a("li"),jbe=a("strong"),t6r=o("transfo-xl"),a6r=o(" \u2014 "),wQ=a("a"),n6r=o("TFTransfoXLForSequenceClassification"),s6r=o(" (Transformer-XL model)"),l6r=l(),k9=a("li"),Dbe=a("strong"),i6r=o("xlm"),d6r=o(" \u2014 "),AQ=a("a"),c6r=o("TFXLMForSequenceClassification"),f6r=o(" (XLM model)"),m6r=l(),S9=a("li"),Gbe=a("strong"),g6r=o("xlm-roberta"),h6r=o(" \u2014 "),yQ=a("a"),p6r=o("TFXLMRobertaForSequenceClassification"),_6r=o(" (XLM-RoBERTa model)"),u6r=l(),R9=a("li"),Obe=a("strong"),b6r=o("xlnet"),v6r=o(" \u2014 "),LQ=a("a"),F6r=o("TFXLNetForSequenceClassification"),T6r=o(" (XLNet model)"),M6r=l(),Vbe=a("p"),E6r=o("Examples:"),C6r=l(),f(LA.$$.fragment),Y$e=l(),Vc=a("h2"),B9=a("a"),Xbe=a("span"),f(xA.$$.fragment),w6r=l(),zbe=a("span"),A6r=o("TFAutoModelForMultipleChoice"),K$e=l(),Ar=a("div"),f(kA.$$.fragment),y6r=l(),Xc=a("p"),L6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),xQ=a("a"),x6r=o("from_pretrained()"),k6r=o(" class method or the "),kQ=a("a"),S6r=o("from_config()"),R6r=o(` class
method.`),B6r=l(),SA=a("p"),P6r=o("This class cannot be instantiated directly using "),Qbe=a("code"),$6r=o("__init__()"),I6r=o(" (throws an error)."),q6r=l(),Ft=a("div"),f(RA.$$.fragment),N6r=l(),Wbe=a("p"),j6r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),D6r=l(),zc=a("p"),G6r=o(`Note:
Loading a model from its configuration file does `),Hbe=a("strong"),O6r=o("not"),V6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=a("a"),X6r=o("from_pretrained()"),z6r=o(" to load the model weights."),Q6r=l(),Ube=a("p"),W6r=o("Examples:"),H6r=l(),f(BA.$$.fragment),U6r=l(),Mo=a("div"),f(PA.$$.fragment),J6r=l(),Jbe=a("p"),Y6r=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),K6r=l(),Cn=a("p"),Z6r=o("The model class to instantiate is selected based on the "),Ybe=a("code"),evr=o("model_type"),ovr=o(` property of the config object (either
passed as an argument or loaded from `),Kbe=a("code"),rvr=o("pretrained_model_name_or_path"),tvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zbe=a("code"),avr=o("pretrained_model_name_or_path"),nvr=o(":"),svr=l(),se=a("ul"),P9=a("li"),e6e=a("strong"),lvr=o("albert"),ivr=o(" \u2014 "),RQ=a("a"),dvr=o("TFAlbertForMultipleChoice"),cvr=o(" (ALBERT model)"),fvr=l(),$9=a("li"),o6e=a("strong"),mvr=o("bert"),gvr=o(" \u2014 "),BQ=a("a"),hvr=o("TFBertForMultipleChoice"),pvr=o(" (BERT model)"),_vr=l(),I9=a("li"),r6e=a("strong"),uvr=o("camembert"),bvr=o(" \u2014 "),PQ=a("a"),vvr=o("TFCamembertForMultipleChoice"),Fvr=o(" (CamemBERT model)"),Tvr=l(),q9=a("li"),t6e=a("strong"),Mvr=o("convbert"),Evr=o(" \u2014 "),$Q=a("a"),Cvr=o("TFConvBertForMultipleChoice"),wvr=o(" (ConvBERT model)"),Avr=l(),N9=a("li"),a6e=a("strong"),yvr=o("distilbert"),Lvr=o(" \u2014 "),IQ=a("a"),xvr=o("TFDistilBertForMultipleChoice"),kvr=o(" (DistilBERT model)"),Svr=l(),j9=a("li"),n6e=a("strong"),Rvr=o("electra"),Bvr=o(" \u2014 "),qQ=a("a"),Pvr=o("TFElectraForMultipleChoice"),$vr=o(" (ELECTRA model)"),Ivr=l(),D9=a("li"),s6e=a("strong"),qvr=o("flaubert"),Nvr=o(" \u2014 "),NQ=a("a"),jvr=o("TFFlaubertForMultipleChoice"),Dvr=o(" (FlauBERT model)"),Gvr=l(),G9=a("li"),l6e=a("strong"),Ovr=o("funnel"),Vvr=o(" \u2014 "),jQ=a("a"),Xvr=o("TFFunnelForMultipleChoice"),zvr=o(" (Funnel Transformer model)"),Qvr=l(),O9=a("li"),i6e=a("strong"),Wvr=o("longformer"),Hvr=o(" \u2014 "),DQ=a("a"),Uvr=o("TFLongformerForMultipleChoice"),Jvr=o(" (Longformer model)"),Yvr=l(),V9=a("li"),d6e=a("strong"),Kvr=o("mobilebert"),Zvr=o(" \u2014 "),GQ=a("a"),eFr=o("TFMobileBertForMultipleChoice"),oFr=o(" (MobileBERT model)"),rFr=l(),X9=a("li"),c6e=a("strong"),tFr=o("mpnet"),aFr=o(" \u2014 "),OQ=a("a"),nFr=o("TFMPNetForMultipleChoice"),sFr=o(" (MPNet model)"),lFr=l(),z9=a("li"),f6e=a("strong"),iFr=o("rembert"),dFr=o(" \u2014 "),VQ=a("a"),cFr=o("TFRemBertForMultipleChoice"),fFr=o(" (RemBERT model)"),mFr=l(),Q9=a("li"),m6e=a("strong"),gFr=o("roberta"),hFr=o(" \u2014 "),XQ=a("a"),pFr=o("TFRobertaForMultipleChoice"),_Fr=o(" (RoBERTa model)"),uFr=l(),W9=a("li"),g6e=a("strong"),bFr=o("roformer"),vFr=o(" \u2014 "),zQ=a("a"),FFr=o("TFRoFormerForMultipleChoice"),TFr=o(" (RoFormer model)"),MFr=l(),H9=a("li"),h6e=a("strong"),EFr=o("xlm"),CFr=o(" \u2014 "),QQ=a("a"),wFr=o("TFXLMForMultipleChoice"),AFr=o(" (XLM model)"),yFr=l(),U9=a("li"),p6e=a("strong"),LFr=o("xlm-roberta"),xFr=o(" \u2014 "),WQ=a("a"),kFr=o("TFXLMRobertaForMultipleChoice"),SFr=o(" (XLM-RoBERTa model)"),RFr=l(),J9=a("li"),_6e=a("strong"),BFr=o("xlnet"),PFr=o(" \u2014 "),HQ=a("a"),$Fr=o("TFXLNetForMultipleChoice"),IFr=o(" (XLNet model)"),qFr=l(),u6e=a("p"),NFr=o("Examples:"),jFr=l(),f($A.$$.fragment),Z$e=l(),Qc=a("h2"),Y9=a("a"),b6e=a("span"),f(IA.$$.fragment),DFr=l(),v6e=a("span"),GFr=o("TFAutoModelForTableQuestionAnswering"),eIe=l(),yr=a("div"),f(qA.$$.fragment),OFr=l(),Wc=a("p"),VFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),UQ=a("a"),XFr=o("from_pretrained()"),zFr=o(" class method or the "),JQ=a("a"),QFr=o("from_config()"),WFr=o(` class
method.`),HFr=l(),NA=a("p"),UFr=o("This class cannot be instantiated directly using "),F6e=a("code"),JFr=o("__init__()"),YFr=o(" (throws an error)."),KFr=l(),Tt=a("div"),f(jA.$$.fragment),ZFr=l(),T6e=a("p"),eTr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),oTr=l(),Hc=a("p"),rTr=o(`Note:
Loading a model from its configuration file does `),M6e=a("strong"),tTr=o("not"),aTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YQ=a("a"),nTr=o("from_pretrained()"),sTr=o(" to load the model weights."),lTr=l(),E6e=a("p"),iTr=o("Examples:"),dTr=l(),f(DA.$$.fragment),cTr=l(),Eo=a("div"),f(GA.$$.fragment),fTr=l(),C6e=a("p"),mTr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),gTr=l(),wn=a("p"),hTr=o("The model class to instantiate is selected based on the "),w6e=a("code"),pTr=o("model_type"),_Tr=o(` property of the config object (either
passed as an argument or loaded from `),A6e=a("code"),uTr=o("pretrained_model_name_or_path"),bTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y6e=a("code"),vTr=o("pretrained_model_name_or_path"),FTr=o(":"),TTr=l(),L6e=a("ul"),K9=a("li"),x6e=a("strong"),MTr=o("tapas"),ETr=o(" \u2014 "),KQ=a("a"),CTr=o("TFTapasForQuestionAnswering"),wTr=o(" (TAPAS model)"),ATr=l(),k6e=a("p"),yTr=o("Examples:"),LTr=l(),f(OA.$$.fragment),oIe=l(),Uc=a("h2"),Z9=a("a"),S6e=a("span"),f(VA.$$.fragment),xTr=l(),R6e=a("span"),kTr=o("TFAutoModelForTokenClassification"),rIe=l(),Lr=a("div"),f(XA.$$.fragment),STr=l(),Jc=a("p"),RTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ZQ=a("a"),BTr=o("from_pretrained()"),PTr=o(" class method or the "),eW=a("a"),$Tr=o("from_config()"),ITr=o(` class
method.`),qTr=l(),zA=a("p"),NTr=o("This class cannot be instantiated directly using "),B6e=a("code"),jTr=o("__init__()"),DTr=o(" (throws an error)."),GTr=l(),Mt=a("div"),f(QA.$$.fragment),OTr=l(),P6e=a("p"),VTr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),XTr=l(),Yc=a("p"),zTr=o(`Note:
Loading a model from its configuration file does `),$6e=a("strong"),QTr=o("not"),WTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oW=a("a"),HTr=o("from_pretrained()"),UTr=o(" to load the model weights."),JTr=l(),I6e=a("p"),YTr=o("Examples:"),KTr=l(),f(WA.$$.fragment),ZTr=l(),Co=a("div"),f(HA.$$.fragment),e7r=l(),q6e=a("p"),o7r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),r7r=l(),An=a("p"),t7r=o("The model class to instantiate is selected based on the "),N6e=a("code"),a7r=o("model_type"),n7r=o(` property of the config object (either
passed as an argument or loaded from `),j6e=a("code"),s7r=o("pretrained_model_name_or_path"),l7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D6e=a("code"),i7r=o("pretrained_model_name_or_path"),d7r=o(":"),c7r=l(),Z=a("ul"),eM=a("li"),G6e=a("strong"),f7r=o("albert"),m7r=o(" \u2014 "),rW=a("a"),g7r=o("TFAlbertForTokenClassification"),h7r=o(" (ALBERT model)"),p7r=l(),oM=a("li"),O6e=a("strong"),_7r=o("bert"),u7r=o(" \u2014 "),tW=a("a"),b7r=o("TFBertForTokenClassification"),v7r=o(" (BERT model)"),F7r=l(),rM=a("li"),V6e=a("strong"),T7r=o("camembert"),M7r=o(" \u2014 "),aW=a("a"),E7r=o("TFCamembertForTokenClassification"),C7r=o(" (CamemBERT model)"),w7r=l(),tM=a("li"),X6e=a("strong"),A7r=o("convbert"),y7r=o(" \u2014 "),nW=a("a"),L7r=o("TFConvBertForTokenClassification"),x7r=o(" (ConvBERT model)"),k7r=l(),aM=a("li"),z6e=a("strong"),S7r=o("deberta"),R7r=o(" \u2014 "),sW=a("a"),B7r=o("TFDebertaForTokenClassification"),P7r=o(" (DeBERTa model)"),$7r=l(),nM=a("li"),Q6e=a("strong"),I7r=o("deberta-v2"),q7r=o(" \u2014 "),lW=a("a"),N7r=o("TFDebertaV2ForTokenClassification"),j7r=o(" (DeBERTa-v2 model)"),D7r=l(),sM=a("li"),W6e=a("strong"),G7r=o("distilbert"),O7r=o(" \u2014 "),iW=a("a"),V7r=o("TFDistilBertForTokenClassification"),X7r=o(" (DistilBERT model)"),z7r=l(),lM=a("li"),H6e=a("strong"),Q7r=o("electra"),W7r=o(" \u2014 "),dW=a("a"),H7r=o("TFElectraForTokenClassification"),U7r=o(" (ELECTRA model)"),J7r=l(),iM=a("li"),U6e=a("strong"),Y7r=o("flaubert"),K7r=o(" \u2014 "),cW=a("a"),Z7r=o("TFFlaubertForTokenClassification"),e9r=o(" (FlauBERT model)"),o9r=l(),dM=a("li"),J6e=a("strong"),r9r=o("funnel"),t9r=o(" \u2014 "),fW=a("a"),a9r=o("TFFunnelForTokenClassification"),n9r=o(" (Funnel Transformer model)"),s9r=l(),cM=a("li"),Y6e=a("strong"),l9r=o("layoutlm"),i9r=o(" \u2014 "),mW=a("a"),d9r=o("TFLayoutLMForTokenClassification"),c9r=o(" (LayoutLM model)"),f9r=l(),fM=a("li"),K6e=a("strong"),m9r=o("longformer"),g9r=o(" \u2014 "),gW=a("a"),h9r=o("TFLongformerForTokenClassification"),p9r=o(" (Longformer model)"),_9r=l(),mM=a("li"),Z6e=a("strong"),u9r=o("mobilebert"),b9r=o(" \u2014 "),hW=a("a"),v9r=o("TFMobileBertForTokenClassification"),F9r=o(" (MobileBERT model)"),T9r=l(),gM=a("li"),eve=a("strong"),M9r=o("mpnet"),E9r=o(" \u2014 "),pW=a("a"),C9r=o("TFMPNetForTokenClassification"),w9r=o(" (MPNet model)"),A9r=l(),hM=a("li"),ove=a("strong"),y9r=o("rembert"),L9r=o(" \u2014 "),_W=a("a"),x9r=o("TFRemBertForTokenClassification"),k9r=o(" (RemBERT model)"),S9r=l(),pM=a("li"),rve=a("strong"),R9r=o("roberta"),B9r=o(" \u2014 "),uW=a("a"),P9r=o("TFRobertaForTokenClassification"),$9r=o(" (RoBERTa model)"),I9r=l(),_M=a("li"),tve=a("strong"),q9r=o("roformer"),N9r=o(" \u2014 "),bW=a("a"),j9r=o("TFRoFormerForTokenClassification"),D9r=o(" (RoFormer model)"),G9r=l(),uM=a("li"),ave=a("strong"),O9r=o("xlm"),V9r=o(" \u2014 "),vW=a("a"),X9r=o("TFXLMForTokenClassification"),z9r=o(" (XLM model)"),Q9r=l(),bM=a("li"),nve=a("strong"),W9r=o("xlm-roberta"),H9r=o(" \u2014 "),FW=a("a"),U9r=o("TFXLMRobertaForTokenClassification"),J9r=o(" (XLM-RoBERTa model)"),Y9r=l(),vM=a("li"),sve=a("strong"),K9r=o("xlnet"),Z9r=o(" \u2014 "),TW=a("a"),eMr=o("TFXLNetForTokenClassification"),oMr=o(" (XLNet model)"),rMr=l(),lve=a("p"),tMr=o("Examples:"),aMr=l(),f(UA.$$.fragment),tIe=l(),Kc=a("h2"),FM=a("a"),ive=a("span"),f(JA.$$.fragment),nMr=l(),dve=a("span"),sMr=o("TFAutoModelForQuestionAnswering"),aIe=l(),xr=a("div"),f(YA.$$.fragment),lMr=l(),Zc=a("p"),iMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),MW=a("a"),dMr=o("from_pretrained()"),cMr=o(" class method or the "),EW=a("a"),fMr=o("from_config()"),mMr=o(` class
method.`),gMr=l(),KA=a("p"),hMr=o("This class cannot be instantiated directly using "),cve=a("code"),pMr=o("__init__()"),_Mr=o(" (throws an error)."),uMr=l(),Et=a("div"),f(ZA.$$.fragment),bMr=l(),fve=a("p"),vMr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),FMr=l(),ef=a("p"),TMr=o(`Note:
Loading a model from its configuration file does `),mve=a("strong"),MMr=o("not"),EMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=a("a"),CMr=o("from_pretrained()"),wMr=o(" to load the model weights."),AMr=l(),gve=a("p"),yMr=o("Examples:"),LMr=l(),f(ey.$$.fragment),xMr=l(),wo=a("div"),f(oy.$$.fragment),kMr=l(),hve=a("p"),SMr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),RMr=l(),yn=a("p"),BMr=o("The model class to instantiate is selected based on the "),pve=a("code"),PMr=o("model_type"),$Mr=o(` property of the config object (either
passed as an argument or loaded from `),_ve=a("code"),IMr=o("pretrained_model_name_or_path"),qMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uve=a("code"),NMr=o("pretrained_model_name_or_path"),jMr=o(":"),DMr=l(),ee=a("ul"),TM=a("li"),bve=a("strong"),GMr=o("albert"),OMr=o(" \u2014 "),wW=a("a"),VMr=o("TFAlbertForQuestionAnswering"),XMr=o(" (ALBERT model)"),zMr=l(),MM=a("li"),vve=a("strong"),QMr=o("bert"),WMr=o(" \u2014 "),AW=a("a"),HMr=o("TFBertForQuestionAnswering"),UMr=o(" (BERT model)"),JMr=l(),EM=a("li"),Fve=a("strong"),YMr=o("camembert"),KMr=o(" \u2014 "),yW=a("a"),ZMr=o("TFCamembertForQuestionAnswering"),e4r=o(" (CamemBERT model)"),o4r=l(),CM=a("li"),Tve=a("strong"),r4r=o("convbert"),t4r=o(" \u2014 "),LW=a("a"),a4r=o("TFConvBertForQuestionAnswering"),n4r=o(" (ConvBERT model)"),s4r=l(),wM=a("li"),Mve=a("strong"),l4r=o("deberta"),i4r=o(" \u2014 "),xW=a("a"),d4r=o("TFDebertaForQuestionAnswering"),c4r=o(" (DeBERTa model)"),f4r=l(),AM=a("li"),Eve=a("strong"),m4r=o("deberta-v2"),g4r=o(" \u2014 "),kW=a("a"),h4r=o("TFDebertaV2ForQuestionAnswering"),p4r=o(" (DeBERTa-v2 model)"),_4r=l(),yM=a("li"),Cve=a("strong"),u4r=o("distilbert"),b4r=o(" \u2014 "),SW=a("a"),v4r=o("TFDistilBertForQuestionAnswering"),F4r=o(" (DistilBERT model)"),T4r=l(),LM=a("li"),wve=a("strong"),M4r=o("electra"),E4r=o(" \u2014 "),RW=a("a"),C4r=o("TFElectraForQuestionAnswering"),w4r=o(" (ELECTRA model)"),A4r=l(),xM=a("li"),Ave=a("strong"),y4r=o("flaubert"),L4r=o(" \u2014 "),BW=a("a"),x4r=o("TFFlaubertForQuestionAnsweringSimple"),k4r=o(" (FlauBERT model)"),S4r=l(),kM=a("li"),yve=a("strong"),R4r=o("funnel"),B4r=o(" \u2014 "),PW=a("a"),P4r=o("TFFunnelForQuestionAnswering"),$4r=o(" (Funnel Transformer model)"),I4r=l(),SM=a("li"),Lve=a("strong"),q4r=o("gptj"),N4r=o(" \u2014 "),$W=a("a"),j4r=o("TFGPTJForQuestionAnswering"),D4r=o(" (GPT-J model)"),G4r=l(),RM=a("li"),xve=a("strong"),O4r=o("longformer"),V4r=o(" \u2014 "),IW=a("a"),X4r=o("TFLongformerForQuestionAnswering"),z4r=o(" (Longformer model)"),Q4r=l(),BM=a("li"),kve=a("strong"),W4r=o("mobilebert"),H4r=o(" \u2014 "),qW=a("a"),U4r=o("TFMobileBertForQuestionAnswering"),J4r=o(" (MobileBERT model)"),Y4r=l(),PM=a("li"),Sve=a("strong"),K4r=o("mpnet"),Z4r=o(" \u2014 "),NW=a("a"),eEr=o("TFMPNetForQuestionAnswering"),oEr=o(" (MPNet model)"),rEr=l(),$M=a("li"),Rve=a("strong"),tEr=o("rembert"),aEr=o(" \u2014 "),jW=a("a"),nEr=o("TFRemBertForQuestionAnswering"),sEr=o(" (RemBERT model)"),lEr=l(),IM=a("li"),Bve=a("strong"),iEr=o("roberta"),dEr=o(" \u2014 "),DW=a("a"),cEr=o("TFRobertaForQuestionAnswering"),fEr=o(" (RoBERTa model)"),mEr=l(),qM=a("li"),Pve=a("strong"),gEr=o("roformer"),hEr=o(" \u2014 "),GW=a("a"),pEr=o("TFRoFormerForQuestionAnswering"),_Er=o(" (RoFormer model)"),uEr=l(),NM=a("li"),$ve=a("strong"),bEr=o("xlm"),vEr=o(" \u2014 "),OW=a("a"),FEr=o("TFXLMForQuestionAnsweringSimple"),TEr=o(" (XLM model)"),MEr=l(),jM=a("li"),Ive=a("strong"),EEr=o("xlm-roberta"),CEr=o(" \u2014 "),VW=a("a"),wEr=o("TFXLMRobertaForQuestionAnswering"),AEr=o(" (XLM-RoBERTa model)"),yEr=l(),DM=a("li"),qve=a("strong"),LEr=o("xlnet"),xEr=o(" \u2014 "),XW=a("a"),kEr=o("TFXLNetForQuestionAnsweringSimple"),SEr=o(" (XLNet model)"),REr=l(),Nve=a("p"),BEr=o("Examples:"),PEr=l(),f(ry.$$.fragment),nIe=l(),of=a("h2"),GM=a("a"),jve=a("span"),f(ty.$$.fragment),$Er=l(),Dve=a("span"),IEr=o("TFAutoModelForVision2Seq"),sIe=l(),kr=a("div"),f(ay.$$.fragment),qEr=l(),rf=a("p"),NEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),zW=a("a"),jEr=o("from_pretrained()"),DEr=o(" class method or the "),QW=a("a"),GEr=o("from_config()"),OEr=o(` class
method.`),VEr=l(),ny=a("p"),XEr=o("This class cannot be instantiated directly using "),Gve=a("code"),zEr=o("__init__()"),QEr=o(" (throws an error)."),WEr=l(),Ct=a("div"),f(sy.$$.fragment),HEr=l(),Ove=a("p"),UEr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),JEr=l(),tf=a("p"),YEr=o(`Note:
Loading a model from its configuration file does `),Vve=a("strong"),KEr=o("not"),ZEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=a("a"),e5r=o("from_pretrained()"),o5r=o(" to load the model weights."),r5r=l(),Xve=a("p"),t5r=o("Examples:"),a5r=l(),f(ly.$$.fragment),n5r=l(),Ao=a("div"),f(iy.$$.fragment),s5r=l(),zve=a("p"),l5r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),i5r=l(),Ln=a("p"),d5r=o("The model class to instantiate is selected based on the "),Qve=a("code"),c5r=o("model_type"),f5r=o(` property of the config object (either
passed as an argument or loaded from `),Wve=a("code"),m5r=o("pretrained_model_name_or_path"),g5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hve=a("code"),h5r=o("pretrained_model_name_or_path"),p5r=o(":"),_5r=l(),Uve=a("ul"),OM=a("li"),Jve=a("strong"),u5r=o("vision-encoder-decoder"),b5r=o(" \u2014 "),HW=a("a"),v5r=o("TFVisionEncoderDecoderModel"),F5r=o(" (Vision Encoder decoder model)"),T5r=l(),Yve=a("p"),M5r=o("Examples:"),E5r=l(),f(dy.$$.fragment),lIe=l(),af=a("h2"),VM=a("a"),Kve=a("span"),f(cy.$$.fragment),C5r=l(),Zve=a("span"),w5r=o("TFAutoModelForSpeechSeq2Seq"),iIe=l(),Sr=a("div"),f(fy.$$.fragment),A5r=l(),nf=a("p"),y5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),UW=a("a"),L5r=o("from_pretrained()"),x5r=o(" class method or the "),JW=a("a"),k5r=o("from_config()"),S5r=o(` class
method.`),R5r=l(),my=a("p"),B5r=o("This class cannot be instantiated directly using "),eFe=a("code"),P5r=o("__init__()"),$5r=o(" (throws an error)."),I5r=l(),wt=a("div"),f(gy.$$.fragment),q5r=l(),oFe=a("p"),N5r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),j5r=l(),sf=a("p"),D5r=o(`Note:
Loading a model from its configuration file does `),rFe=a("strong"),G5r=o("not"),O5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=a("a"),V5r=o("from_pretrained()"),X5r=o(" to load the model weights."),z5r=l(),tFe=a("p"),Q5r=o("Examples:"),W5r=l(),f(hy.$$.fragment),H5r=l(),yo=a("div"),f(py.$$.fragment),U5r=l(),aFe=a("p"),J5r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Y5r=l(),xn=a("p"),K5r=o("The model class to instantiate is selected based on the "),nFe=a("code"),Z5r=o("model_type"),e3r=o(` property of the config object (either
passed as an argument or loaded from `),sFe=a("code"),o3r=o("pretrained_model_name_or_path"),r3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lFe=a("code"),t3r=o("pretrained_model_name_or_path"),a3r=o(":"),n3r=l(),iFe=a("ul"),XM=a("li"),dFe=a("strong"),s3r=o("speech_to_text"),l3r=o(" \u2014 "),KW=a("a"),i3r=o("TFSpeech2TextForConditionalGeneration"),d3r=o(" (Speech2Text model)"),c3r=l(),cFe=a("p"),f3r=o("Examples:"),m3r=l(),f(_y.$$.fragment),dIe=l(),lf=a("h2"),zM=a("a"),fFe=a("span"),f(uy.$$.fragment),g3r=l(),mFe=a("span"),h3r=o("FlaxAutoModel"),cIe=l(),Rr=a("div"),f(by.$$.fragment),p3r=l(),df=a("p"),_3r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),ZW=a("a"),u3r=o("from_pretrained()"),b3r=o(" class method or the "),eH=a("a"),v3r=o("from_config()"),F3r=o(` class
method.`),T3r=l(),vy=a("p"),M3r=o("This class cannot be instantiated directly using "),gFe=a("code"),E3r=o("__init__()"),C3r=o(" (throws an error)."),w3r=l(),At=a("div"),f(Fy.$$.fragment),A3r=l(),hFe=a("p"),y3r=o("Instantiates one of the base model classes of the library from a configuration."),L3r=l(),cf=a("p"),x3r=o(`Note:
Loading a model from its configuration file does `),pFe=a("strong"),k3r=o("not"),S3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oH=a("a"),R3r=o("from_pretrained()"),B3r=o(" to load the model weights."),P3r=l(),_Fe=a("p"),$3r=o("Examples:"),I3r=l(),f(Ty.$$.fragment),q3r=l(),Lo=a("div"),f(My.$$.fragment),N3r=l(),uFe=a("p"),j3r=o("Instantiate one of the base model classes of the library from a pretrained model."),D3r=l(),kn=a("p"),G3r=o("The model class to instantiate is selected based on the "),bFe=a("code"),O3r=o("model_type"),V3r=o(` property of the config object (either
passed as an argument or loaded from `),vFe=a("code"),X3r=o("pretrained_model_name_or_path"),z3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FFe=a("code"),Q3r=o("pretrained_model_name_or_path"),W3r=o(":"),H3r=l(),X=a("ul"),QM=a("li"),TFe=a("strong"),U3r=o("albert"),J3r=o(" \u2014 "),rH=a("a"),Y3r=o("FlaxAlbertModel"),K3r=o(" (ALBERT model)"),Z3r=l(),WM=a("li"),MFe=a("strong"),eCr=o("bart"),oCr=o(" \u2014 "),tH=a("a"),rCr=o("FlaxBartModel"),tCr=o(" (BART model)"),aCr=l(),HM=a("li"),EFe=a("strong"),nCr=o("beit"),sCr=o(" \u2014 "),aH=a("a"),lCr=o("FlaxBeitModel"),iCr=o(" (BEiT model)"),dCr=l(),UM=a("li"),CFe=a("strong"),cCr=o("bert"),fCr=o(" \u2014 "),nH=a("a"),mCr=o("FlaxBertModel"),gCr=o(" (BERT model)"),hCr=l(),JM=a("li"),wFe=a("strong"),pCr=o("big_bird"),_Cr=o(" \u2014 "),sH=a("a"),uCr=o("FlaxBigBirdModel"),bCr=o(" (BigBird model)"),vCr=l(),YM=a("li"),AFe=a("strong"),FCr=o("blenderbot"),TCr=o(" \u2014 "),lH=a("a"),MCr=o("FlaxBlenderbotModel"),ECr=o(" (Blenderbot model)"),CCr=l(),KM=a("li"),yFe=a("strong"),wCr=o("blenderbot-small"),ACr=o(" \u2014 "),iH=a("a"),yCr=o("FlaxBlenderbotSmallModel"),LCr=o(" (BlenderbotSmall model)"),xCr=l(),ZM=a("li"),LFe=a("strong"),kCr=o("clip"),SCr=o(" \u2014 "),dH=a("a"),RCr=o("FlaxCLIPModel"),BCr=o(" (CLIP model)"),PCr=l(),e4=a("li"),xFe=a("strong"),$Cr=o("distilbert"),ICr=o(" \u2014 "),cH=a("a"),qCr=o("FlaxDistilBertModel"),NCr=o(" (DistilBERT model)"),jCr=l(),o4=a("li"),kFe=a("strong"),DCr=o("electra"),GCr=o(" \u2014 "),fH=a("a"),OCr=o("FlaxElectraModel"),VCr=o(" (ELECTRA model)"),XCr=l(),r4=a("li"),SFe=a("strong"),zCr=o("gpt2"),QCr=o(" \u2014 "),mH=a("a"),WCr=o("FlaxGPT2Model"),HCr=o(" (OpenAI GPT-2 model)"),UCr=l(),t4=a("li"),RFe=a("strong"),JCr=o("gpt_neo"),YCr=o(" \u2014 "),gH=a("a"),KCr=o("FlaxGPTNeoModel"),ZCr=o(" (GPT Neo model)"),ewr=l(),a4=a("li"),BFe=a("strong"),owr=o("gptj"),rwr=o(" \u2014 "),hH=a("a"),twr=o("FlaxGPTJModel"),awr=o(" (GPT-J model)"),nwr=l(),n4=a("li"),PFe=a("strong"),swr=o("longt5"),lwr=o(" \u2014 "),pH=a("a"),iwr=o("FlaxLongT5Model"),dwr=o(" (LongT5 model)"),cwr=l(),s4=a("li"),$Fe=a("strong"),fwr=o("marian"),mwr=o(" \u2014 "),_H=a("a"),gwr=o("FlaxMarianModel"),hwr=o(" (Marian model)"),pwr=l(),l4=a("li"),IFe=a("strong"),_wr=o("mbart"),uwr=o(" \u2014 "),uH=a("a"),bwr=o("FlaxMBartModel"),vwr=o(" (mBART model)"),Fwr=l(),i4=a("li"),qFe=a("strong"),Twr=o("mt5"),Mwr=o(" \u2014 "),bH=a("a"),Ewr=o("FlaxMT5Model"),Cwr=o(" (mT5 model)"),wwr=l(),d4=a("li"),NFe=a("strong"),Awr=o("pegasus"),ywr=o(" \u2014 "),vH=a("a"),Lwr=o("FlaxPegasusModel"),xwr=o(" (Pegasus model)"),kwr=l(),c4=a("li"),jFe=a("strong"),Swr=o("roberta"),Rwr=o(" \u2014 "),FH=a("a"),Bwr=o("FlaxRobertaModel"),Pwr=o(" (RoBERTa model)"),$wr=l(),f4=a("li"),DFe=a("strong"),Iwr=o("roformer"),qwr=o(" \u2014 "),TH=a("a"),Nwr=o("FlaxRoFormerModel"),jwr=o(" (RoFormer model)"),Dwr=l(),m4=a("li"),GFe=a("strong"),Gwr=o("t5"),Owr=o(" \u2014 "),MH=a("a"),Vwr=o("FlaxT5Model"),Xwr=o(" (T5 model)"),zwr=l(),g4=a("li"),OFe=a("strong"),Qwr=o("vision-text-dual-encoder"),Wwr=o(" \u2014 "),EH=a("a"),Hwr=o("FlaxVisionTextDualEncoderModel"),Uwr=o(" (VisionTextDualEncoder model)"),Jwr=l(),h4=a("li"),VFe=a("strong"),Ywr=o("vit"),Kwr=o(" \u2014 "),CH=a("a"),Zwr=o("FlaxViTModel"),e0r=o(" (ViT model)"),o0r=l(),p4=a("li"),XFe=a("strong"),r0r=o("wav2vec2"),t0r=o(" \u2014 "),wH=a("a"),a0r=o("FlaxWav2Vec2Model"),n0r=o(" (Wav2Vec2 model)"),s0r=l(),_4=a("li"),zFe=a("strong"),l0r=o("xglm"),i0r=o(" \u2014 "),AH=a("a"),d0r=o("FlaxXGLMModel"),c0r=o(" (XGLM model)"),f0r=l(),u4=a("li"),QFe=a("strong"),m0r=o("xlm-roberta"),g0r=o(" \u2014 "),yH=a("a"),h0r=o("FlaxXLMRobertaModel"),p0r=o(" (XLM-RoBERTa model)"),_0r=l(),WFe=a("p"),u0r=o("Examples:"),b0r=l(),f(Ey.$$.fragment),fIe=l(),ff=a("h2"),b4=a("a"),HFe=a("span"),f(Cy.$$.fragment),v0r=l(),UFe=a("span"),F0r=o("FlaxAutoModelForCausalLM"),mIe=l(),Br=a("div"),f(wy.$$.fragment),T0r=l(),mf=a("p"),M0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),LH=a("a"),E0r=o("from_pretrained()"),C0r=o(" class method or the "),xH=a("a"),w0r=o("from_config()"),A0r=o(` class
method.`),y0r=l(),Ay=a("p"),L0r=o("This class cannot be instantiated directly using "),JFe=a("code"),x0r=o("__init__()"),k0r=o(" (throws an error)."),S0r=l(),yt=a("div"),f(yy.$$.fragment),R0r=l(),YFe=a("p"),B0r=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),P0r=l(),gf=a("p"),$0r=o(`Note:
Loading a model from its configuration file does `),KFe=a("strong"),I0r=o("not"),q0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kH=a("a"),N0r=o("from_pretrained()"),j0r=o(" to load the model weights."),D0r=l(),ZFe=a("p"),G0r=o("Examples:"),O0r=l(),f(Ly.$$.fragment),V0r=l(),xo=a("div"),f(xy.$$.fragment),X0r=l(),eTe=a("p"),z0r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Q0r=l(),Sn=a("p"),W0r=o("The model class to instantiate is selected based on the "),oTe=a("code"),H0r=o("model_type"),U0r=o(` property of the config object (either
passed as an argument or loaded from `),rTe=a("code"),J0r=o("pretrained_model_name_or_path"),Y0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tTe=a("code"),K0r=o("pretrained_model_name_or_path"),Z0r=o(":"),eAr=l(),ca=a("ul"),v4=a("li"),aTe=a("strong"),oAr=o("bart"),rAr=o(" \u2014 "),SH=a("a"),tAr=o("FlaxBartForCausalLM"),aAr=o(" (BART model)"),nAr=l(),F4=a("li"),nTe=a("strong"),sAr=o("gpt2"),lAr=o(" \u2014 "),RH=a("a"),iAr=o("FlaxGPT2LMHeadModel"),dAr=o(" (OpenAI GPT-2 model)"),cAr=l(),T4=a("li"),sTe=a("strong"),fAr=o("gpt_neo"),mAr=o(" \u2014 "),BH=a("a"),gAr=o("FlaxGPTNeoForCausalLM"),hAr=o(" (GPT Neo model)"),pAr=l(),M4=a("li"),lTe=a("strong"),_Ar=o("gptj"),uAr=o(" \u2014 "),PH=a("a"),bAr=o("FlaxGPTJForCausalLM"),vAr=o(" (GPT-J model)"),FAr=l(),E4=a("li"),iTe=a("strong"),TAr=o("xglm"),MAr=o(" \u2014 "),$H=a("a"),EAr=o("FlaxXGLMForCausalLM"),CAr=o(" (XGLM model)"),wAr=l(),dTe=a("p"),AAr=o("Examples:"),yAr=l(),f(ky.$$.fragment),gIe=l(),hf=a("h2"),C4=a("a"),cTe=a("span"),f(Sy.$$.fragment),LAr=l(),fTe=a("span"),xAr=o("FlaxAutoModelForPreTraining"),hIe=l(),Pr=a("div"),f(Ry.$$.fragment),kAr=l(),pf=a("p"),SAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),IH=a("a"),RAr=o("from_pretrained()"),BAr=o(" class method or the "),qH=a("a"),PAr=o("from_config()"),$Ar=o(` class
method.`),IAr=l(),By=a("p"),qAr=o("This class cannot be instantiated directly using "),mTe=a("code"),NAr=o("__init__()"),jAr=o(" (throws an error)."),DAr=l(),Lt=a("div"),f(Py.$$.fragment),GAr=l(),gTe=a("p"),OAr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),VAr=l(),_f=a("p"),XAr=o(`Note:
Loading a model from its configuration file does `),hTe=a("strong"),zAr=o("not"),QAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NH=a("a"),WAr=o("from_pretrained()"),HAr=o(" to load the model weights."),UAr=l(),pTe=a("p"),JAr=o("Examples:"),YAr=l(),f($y.$$.fragment),KAr=l(),ko=a("div"),f(Iy.$$.fragment),ZAr=l(),_Te=a("p"),eyr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),oyr=l(),Rn=a("p"),ryr=o("The model class to instantiate is selected based on the "),uTe=a("code"),tyr=o("model_type"),ayr=o(` property of the config object (either
passed as an argument or loaded from `),bTe=a("code"),nyr=o("pretrained_model_name_or_path"),syr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vTe=a("code"),lyr=o("pretrained_model_name_or_path"),iyr=o(":"),dyr=l(),fe=a("ul"),w4=a("li"),FTe=a("strong"),cyr=o("albert"),fyr=o(" \u2014 "),jH=a("a"),myr=o("FlaxAlbertForPreTraining"),gyr=o(" (ALBERT model)"),hyr=l(),A4=a("li"),TTe=a("strong"),pyr=o("bart"),_yr=o(" \u2014 "),DH=a("a"),uyr=o("FlaxBartForConditionalGeneration"),byr=o(" (BART model)"),vyr=l(),y4=a("li"),MTe=a("strong"),Fyr=o("bert"),Tyr=o(" \u2014 "),GH=a("a"),Myr=o("FlaxBertForPreTraining"),Eyr=o(" (BERT model)"),Cyr=l(),L4=a("li"),ETe=a("strong"),wyr=o("big_bird"),Ayr=o(" \u2014 "),OH=a("a"),yyr=o("FlaxBigBirdForPreTraining"),Lyr=o(" (BigBird model)"),xyr=l(),x4=a("li"),CTe=a("strong"),kyr=o("electra"),Syr=o(" \u2014 "),VH=a("a"),Ryr=o("FlaxElectraForPreTraining"),Byr=o(" (ELECTRA model)"),Pyr=l(),k4=a("li"),wTe=a("strong"),$yr=o("longt5"),Iyr=o(" \u2014 "),XH=a("a"),qyr=o("FlaxLongT5ForConditionalGeneration"),Nyr=o(" (LongT5 model)"),jyr=l(),S4=a("li"),ATe=a("strong"),Dyr=o("mbart"),Gyr=o(" \u2014 "),zH=a("a"),Oyr=o("FlaxMBartForConditionalGeneration"),Vyr=o(" (mBART model)"),Xyr=l(),R4=a("li"),yTe=a("strong"),zyr=o("mt5"),Qyr=o(" \u2014 "),QH=a("a"),Wyr=o("FlaxMT5ForConditionalGeneration"),Hyr=o(" (mT5 model)"),Uyr=l(),B4=a("li"),LTe=a("strong"),Jyr=o("roberta"),Yyr=o(" \u2014 "),WH=a("a"),Kyr=o("FlaxRobertaForMaskedLM"),Zyr=o(" (RoBERTa model)"),eLr=l(),P4=a("li"),xTe=a("strong"),oLr=o("roformer"),rLr=o(" \u2014 "),HH=a("a"),tLr=o("FlaxRoFormerForMaskedLM"),aLr=o(" (RoFormer model)"),nLr=l(),$4=a("li"),kTe=a("strong"),sLr=o("t5"),lLr=o(" \u2014 "),UH=a("a"),iLr=o("FlaxT5ForConditionalGeneration"),dLr=o(" (T5 model)"),cLr=l(),I4=a("li"),STe=a("strong"),fLr=o("wav2vec2"),mLr=o(" \u2014 "),JH=a("a"),gLr=o("FlaxWav2Vec2ForPreTraining"),hLr=o(" (Wav2Vec2 model)"),pLr=l(),q4=a("li"),RTe=a("strong"),_Lr=o("xlm-roberta"),uLr=o(" \u2014 "),YH=a("a"),bLr=o("FlaxXLMRobertaForMaskedLM"),vLr=o(" (XLM-RoBERTa model)"),FLr=l(),BTe=a("p"),TLr=o("Examples:"),MLr=l(),f(qy.$$.fragment),pIe=l(),uf=a("h2"),N4=a("a"),PTe=a("span"),f(Ny.$$.fragment),ELr=l(),$Te=a("span"),CLr=o("FlaxAutoModelForMaskedLM"),_Ie=l(),$r=a("div"),f(jy.$$.fragment),wLr=l(),bf=a("p"),ALr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),KH=a("a"),yLr=o("from_pretrained()"),LLr=o(" class method or the "),ZH=a("a"),xLr=o("from_config()"),kLr=o(` class
method.`),SLr=l(),Dy=a("p"),RLr=o("This class cannot be instantiated directly using "),ITe=a("code"),BLr=o("__init__()"),PLr=o(" (throws an error)."),$Lr=l(),xt=a("div"),f(Gy.$$.fragment),ILr=l(),qTe=a("p"),qLr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),NLr=l(),vf=a("p"),jLr=o(`Note:
Loading a model from its configuration file does `),NTe=a("strong"),DLr=o("not"),GLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eU=a("a"),OLr=o("from_pretrained()"),VLr=o(" to load the model weights."),XLr=l(),jTe=a("p"),zLr=o("Examples:"),QLr=l(),f(Oy.$$.fragment),WLr=l(),So=a("div"),f(Vy.$$.fragment),HLr=l(),DTe=a("p"),ULr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),JLr=l(),Bn=a("p"),YLr=o("The model class to instantiate is selected based on the "),GTe=a("code"),KLr=o("model_type"),ZLr=o(` property of the config object (either
passed as an argument or loaded from `),OTe=a("code"),e8r=o("pretrained_model_name_or_path"),o8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VTe=a("code"),r8r=o("pretrained_model_name_or_path"),t8r=o(":"),a8r=l(),Te=a("ul"),j4=a("li"),XTe=a("strong"),n8r=o("albert"),s8r=o(" \u2014 "),oU=a("a"),l8r=o("FlaxAlbertForMaskedLM"),i8r=o(" (ALBERT model)"),d8r=l(),D4=a("li"),zTe=a("strong"),c8r=o("bart"),f8r=o(" \u2014 "),rU=a("a"),m8r=o("FlaxBartForConditionalGeneration"),g8r=o(" (BART model)"),h8r=l(),G4=a("li"),QTe=a("strong"),p8r=o("bert"),_8r=o(" \u2014 "),tU=a("a"),u8r=o("FlaxBertForMaskedLM"),b8r=o(" (BERT model)"),v8r=l(),O4=a("li"),WTe=a("strong"),F8r=o("big_bird"),T8r=o(" \u2014 "),aU=a("a"),M8r=o("FlaxBigBirdForMaskedLM"),E8r=o(" (BigBird model)"),C8r=l(),V4=a("li"),HTe=a("strong"),w8r=o("distilbert"),A8r=o(" \u2014 "),nU=a("a"),y8r=o("FlaxDistilBertForMaskedLM"),L8r=o(" (DistilBERT model)"),x8r=l(),X4=a("li"),UTe=a("strong"),k8r=o("electra"),S8r=o(" \u2014 "),sU=a("a"),R8r=o("FlaxElectraForMaskedLM"),B8r=o(" (ELECTRA model)"),P8r=l(),z4=a("li"),JTe=a("strong"),$8r=o("mbart"),I8r=o(" \u2014 "),lU=a("a"),q8r=o("FlaxMBartForConditionalGeneration"),N8r=o(" (mBART model)"),j8r=l(),Q4=a("li"),YTe=a("strong"),D8r=o("roberta"),G8r=o(" \u2014 "),iU=a("a"),O8r=o("FlaxRobertaForMaskedLM"),V8r=o(" (RoBERTa model)"),X8r=l(),W4=a("li"),KTe=a("strong"),z8r=o("roformer"),Q8r=o(" \u2014 "),dU=a("a"),W8r=o("FlaxRoFormerForMaskedLM"),H8r=o(" (RoFormer model)"),U8r=l(),H4=a("li"),ZTe=a("strong"),J8r=o("xlm-roberta"),Y8r=o(" \u2014 "),cU=a("a"),K8r=o("FlaxXLMRobertaForMaskedLM"),Z8r=o(" (XLM-RoBERTa model)"),exr=l(),e7e=a("p"),oxr=o("Examples:"),rxr=l(),f(Xy.$$.fragment),uIe=l(),Ff=a("h2"),U4=a("a"),o7e=a("span"),f(zy.$$.fragment),txr=l(),r7e=a("span"),axr=o("FlaxAutoModelForSeq2SeqLM"),bIe=l(),Ir=a("div"),f(Qy.$$.fragment),nxr=l(),Tf=a("p"),sxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),fU=a("a"),lxr=o("from_pretrained()"),ixr=o(" class method or the "),mU=a("a"),dxr=o("from_config()"),cxr=o(` class
method.`),fxr=l(),Wy=a("p"),mxr=o("This class cannot be instantiated directly using "),t7e=a("code"),gxr=o("__init__()"),hxr=o(" (throws an error)."),pxr=l(),kt=a("div"),f(Hy.$$.fragment),_xr=l(),a7e=a("p"),uxr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),bxr=l(),Mf=a("p"),vxr=o(`Note:
Loading a model from its configuration file does `),n7e=a("strong"),Fxr=o("not"),Txr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gU=a("a"),Mxr=o("from_pretrained()"),Exr=o(" to load the model weights."),Cxr=l(),s7e=a("p"),wxr=o("Examples:"),Axr=l(),f(Uy.$$.fragment),yxr=l(),Ro=a("div"),f(Jy.$$.fragment),Lxr=l(),l7e=a("p"),xxr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),kxr=l(),Pn=a("p"),Sxr=o("The model class to instantiate is selected based on the "),i7e=a("code"),Rxr=o("model_type"),Bxr=o(` property of the config object (either
passed as an argument or loaded from `),d7e=a("code"),Pxr=o("pretrained_model_name_or_path"),$xr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c7e=a("code"),Ixr=o("pretrained_model_name_or_path"),qxr=o(":"),Nxr=l(),Me=a("ul"),J4=a("li"),f7e=a("strong"),jxr=o("bart"),Dxr=o(" \u2014 "),hU=a("a"),Gxr=o("FlaxBartForConditionalGeneration"),Oxr=o(" (BART model)"),Vxr=l(),Y4=a("li"),m7e=a("strong"),Xxr=o("blenderbot"),zxr=o(" \u2014 "),pU=a("a"),Qxr=o("FlaxBlenderbotForConditionalGeneration"),Wxr=o(" (Blenderbot model)"),Hxr=l(),K4=a("li"),g7e=a("strong"),Uxr=o("blenderbot-small"),Jxr=o(" \u2014 "),_U=a("a"),Yxr=o("FlaxBlenderbotSmallForConditionalGeneration"),Kxr=o(" (BlenderbotSmall model)"),Zxr=l(),Z4=a("li"),h7e=a("strong"),ekr=o("encoder-decoder"),okr=o(" \u2014 "),uU=a("a"),rkr=o("FlaxEncoderDecoderModel"),tkr=o(" (Encoder decoder model)"),akr=l(),eE=a("li"),p7e=a("strong"),nkr=o("longt5"),skr=o(" \u2014 "),bU=a("a"),lkr=o("FlaxLongT5ForConditionalGeneration"),ikr=o(" (LongT5 model)"),dkr=l(),oE=a("li"),_7e=a("strong"),ckr=o("marian"),fkr=o(" \u2014 "),vU=a("a"),mkr=o("FlaxMarianMTModel"),gkr=o(" (Marian model)"),hkr=l(),rE=a("li"),u7e=a("strong"),pkr=o("mbart"),_kr=o(" \u2014 "),FU=a("a"),ukr=o("FlaxMBartForConditionalGeneration"),bkr=o(" (mBART model)"),vkr=l(),tE=a("li"),b7e=a("strong"),Fkr=o("mt5"),Tkr=o(" \u2014 "),TU=a("a"),Mkr=o("FlaxMT5ForConditionalGeneration"),Ekr=o(" (mT5 model)"),Ckr=l(),aE=a("li"),v7e=a("strong"),wkr=o("pegasus"),Akr=o(" \u2014 "),MU=a("a"),ykr=o("FlaxPegasusForConditionalGeneration"),Lkr=o(" (Pegasus model)"),xkr=l(),nE=a("li"),F7e=a("strong"),kkr=o("t5"),Skr=o(" \u2014 "),EU=a("a"),Rkr=o("FlaxT5ForConditionalGeneration"),Bkr=o(" (T5 model)"),Pkr=l(),T7e=a("p"),$kr=o("Examples:"),Ikr=l(),f(Yy.$$.fragment),vIe=l(),Ef=a("h2"),sE=a("a"),M7e=a("span"),f(Ky.$$.fragment),qkr=l(),E7e=a("span"),Nkr=o("FlaxAutoModelForSequenceClassification"),FIe=l(),qr=a("div"),f(Zy.$$.fragment),jkr=l(),Cf=a("p"),Dkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),CU=a("a"),Gkr=o("from_pretrained()"),Okr=o(" class method or the "),wU=a("a"),Vkr=o("from_config()"),Xkr=o(` class
method.`),zkr=l(),eL=a("p"),Qkr=o("This class cannot be instantiated directly using "),C7e=a("code"),Wkr=o("__init__()"),Hkr=o(" (throws an error)."),Ukr=l(),St=a("div"),f(oL.$$.fragment),Jkr=l(),w7e=a("p"),Ykr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Kkr=l(),wf=a("p"),Zkr=o(`Note:
Loading a model from its configuration file does `),A7e=a("strong"),eSr=o("not"),oSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),AU=a("a"),rSr=o("from_pretrained()"),tSr=o(" to load the model weights."),aSr=l(),y7e=a("p"),nSr=o("Examples:"),sSr=l(),f(rL.$$.fragment),lSr=l(),Bo=a("div"),f(tL.$$.fragment),iSr=l(),L7e=a("p"),dSr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),cSr=l(),$n=a("p"),fSr=o("The model class to instantiate is selected based on the "),x7e=a("code"),mSr=o("model_type"),gSr=o(` property of the config object (either
passed as an argument or loaded from `),k7e=a("code"),hSr=o("pretrained_model_name_or_path"),pSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S7e=a("code"),_Sr=o("pretrained_model_name_or_path"),uSr=o(":"),bSr=l(),Ee=a("ul"),lE=a("li"),R7e=a("strong"),vSr=o("albert"),FSr=o(" \u2014 "),yU=a("a"),TSr=o("FlaxAlbertForSequenceClassification"),MSr=o(" (ALBERT model)"),ESr=l(),iE=a("li"),B7e=a("strong"),CSr=o("bart"),wSr=o(" \u2014 "),LU=a("a"),ASr=o("FlaxBartForSequenceClassification"),ySr=o(" (BART model)"),LSr=l(),dE=a("li"),P7e=a("strong"),xSr=o("bert"),kSr=o(" \u2014 "),xU=a("a"),SSr=o("FlaxBertForSequenceClassification"),RSr=o(" (BERT model)"),BSr=l(),cE=a("li"),$7e=a("strong"),PSr=o("big_bird"),$Sr=o(" \u2014 "),kU=a("a"),ISr=o("FlaxBigBirdForSequenceClassification"),qSr=o(" (BigBird model)"),NSr=l(),fE=a("li"),I7e=a("strong"),jSr=o("distilbert"),DSr=o(" \u2014 "),SU=a("a"),GSr=o("FlaxDistilBertForSequenceClassification"),OSr=o(" (DistilBERT model)"),VSr=l(),mE=a("li"),q7e=a("strong"),XSr=o("electra"),zSr=o(" \u2014 "),RU=a("a"),QSr=o("FlaxElectraForSequenceClassification"),WSr=o(" (ELECTRA model)"),HSr=l(),gE=a("li"),N7e=a("strong"),USr=o("mbart"),JSr=o(" \u2014 "),BU=a("a"),YSr=o("FlaxMBartForSequenceClassification"),KSr=o(" (mBART model)"),ZSr=l(),hE=a("li"),j7e=a("strong"),eRr=o("roberta"),oRr=o(" \u2014 "),PU=a("a"),rRr=o("FlaxRobertaForSequenceClassification"),tRr=o(" (RoBERTa model)"),aRr=l(),pE=a("li"),D7e=a("strong"),nRr=o("roformer"),sRr=o(" \u2014 "),$U=a("a"),lRr=o("FlaxRoFormerForSequenceClassification"),iRr=o(" (RoFormer model)"),dRr=l(),_E=a("li"),G7e=a("strong"),cRr=o("xlm-roberta"),fRr=o(" \u2014 "),IU=a("a"),mRr=o("FlaxXLMRobertaForSequenceClassification"),gRr=o(" (XLM-RoBERTa model)"),hRr=l(),O7e=a("p"),pRr=o("Examples:"),_Rr=l(),f(aL.$$.fragment),TIe=l(),Af=a("h2"),uE=a("a"),V7e=a("span"),f(nL.$$.fragment),uRr=l(),X7e=a("span"),bRr=o("FlaxAutoModelForQuestionAnswering"),MIe=l(),Nr=a("div"),f(sL.$$.fragment),vRr=l(),yf=a("p"),FRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),qU=a("a"),TRr=o("from_pretrained()"),MRr=o(" class method or the "),NU=a("a"),ERr=o("from_config()"),CRr=o(` class
method.`),wRr=l(),lL=a("p"),ARr=o("This class cannot be instantiated directly using "),z7e=a("code"),yRr=o("__init__()"),LRr=o(" (throws an error)."),xRr=l(),Rt=a("div"),f(iL.$$.fragment),kRr=l(),Q7e=a("p"),SRr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),RRr=l(),Lf=a("p"),BRr=o(`Note:
Loading a model from its configuration file does `),W7e=a("strong"),PRr=o("not"),$Rr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jU=a("a"),IRr=o("from_pretrained()"),qRr=o(" to load the model weights."),NRr=l(),H7e=a("p"),jRr=o("Examples:"),DRr=l(),f(dL.$$.fragment),GRr=l(),Po=a("div"),f(cL.$$.fragment),ORr=l(),U7e=a("p"),VRr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),XRr=l(),In=a("p"),zRr=o("The model class to instantiate is selected based on the "),J7e=a("code"),QRr=o("model_type"),WRr=o(` property of the config object (either
passed as an argument or loaded from `),Y7e=a("code"),HRr=o("pretrained_model_name_or_path"),URr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K7e=a("code"),JRr=o("pretrained_model_name_or_path"),YRr=o(":"),KRr=l(),Ce=a("ul"),bE=a("li"),Z7e=a("strong"),ZRr=o("albert"),eBr=o(" \u2014 "),DU=a("a"),oBr=o("FlaxAlbertForQuestionAnswering"),rBr=o(" (ALBERT model)"),tBr=l(),vE=a("li"),e9e=a("strong"),aBr=o("bart"),nBr=o(" \u2014 "),GU=a("a"),sBr=o("FlaxBartForQuestionAnswering"),lBr=o(" (BART model)"),iBr=l(),FE=a("li"),o9e=a("strong"),dBr=o("bert"),cBr=o(" \u2014 "),OU=a("a"),fBr=o("FlaxBertForQuestionAnswering"),mBr=o(" (BERT model)"),gBr=l(),TE=a("li"),r9e=a("strong"),hBr=o("big_bird"),pBr=o(" \u2014 "),VU=a("a"),_Br=o("FlaxBigBirdForQuestionAnswering"),uBr=o(" (BigBird model)"),bBr=l(),ME=a("li"),t9e=a("strong"),vBr=o("distilbert"),FBr=o(" \u2014 "),XU=a("a"),TBr=o("FlaxDistilBertForQuestionAnswering"),MBr=o(" (DistilBERT model)"),EBr=l(),EE=a("li"),a9e=a("strong"),CBr=o("electra"),wBr=o(" \u2014 "),zU=a("a"),ABr=o("FlaxElectraForQuestionAnswering"),yBr=o(" (ELECTRA model)"),LBr=l(),CE=a("li"),n9e=a("strong"),xBr=o("mbart"),kBr=o(" \u2014 "),QU=a("a"),SBr=o("FlaxMBartForQuestionAnswering"),RBr=o(" (mBART model)"),BBr=l(),wE=a("li"),s9e=a("strong"),PBr=o("roberta"),$Br=o(" \u2014 "),WU=a("a"),IBr=o("FlaxRobertaForQuestionAnswering"),qBr=o(" (RoBERTa model)"),NBr=l(),AE=a("li"),l9e=a("strong"),jBr=o("roformer"),DBr=o(" \u2014 "),HU=a("a"),GBr=o("FlaxRoFormerForQuestionAnswering"),OBr=o(" (RoFormer model)"),VBr=l(),yE=a("li"),i9e=a("strong"),XBr=o("xlm-roberta"),zBr=o(" \u2014 "),UU=a("a"),QBr=o("FlaxXLMRobertaForQuestionAnswering"),WBr=o(" (XLM-RoBERTa model)"),HBr=l(),d9e=a("p"),UBr=o("Examples:"),JBr=l(),f(fL.$$.fragment),EIe=l(),xf=a("h2"),LE=a("a"),c9e=a("span"),f(mL.$$.fragment),YBr=l(),f9e=a("span"),KBr=o("FlaxAutoModelForTokenClassification"),CIe=l(),jr=a("div"),f(gL.$$.fragment),ZBr=l(),kf=a("p"),ePr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),JU=a("a"),oPr=o("from_pretrained()"),rPr=o(" class method or the "),YU=a("a"),tPr=o("from_config()"),aPr=o(` class
method.`),nPr=l(),hL=a("p"),sPr=o("This class cannot be instantiated directly using "),m9e=a("code"),lPr=o("__init__()"),iPr=o(" (throws an error)."),dPr=l(),Bt=a("div"),f(pL.$$.fragment),cPr=l(),g9e=a("p"),fPr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),mPr=l(),Sf=a("p"),gPr=o(`Note:
Loading a model from its configuration file does `),h9e=a("strong"),hPr=o("not"),pPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KU=a("a"),_Pr=o("from_pretrained()"),uPr=o(" to load the model weights."),bPr=l(),p9e=a("p"),vPr=o("Examples:"),FPr=l(),f(_L.$$.fragment),TPr=l(),$o=a("div"),f(uL.$$.fragment),MPr=l(),_9e=a("p"),EPr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),CPr=l(),qn=a("p"),wPr=o("The model class to instantiate is selected based on the "),u9e=a("code"),APr=o("model_type"),yPr=o(` property of the config object (either
passed as an argument or loaded from `),b9e=a("code"),LPr=o("pretrained_model_name_or_path"),xPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v9e=a("code"),kPr=o("pretrained_model_name_or_path"),SPr=o(":"),RPr=l(),$e=a("ul"),xE=a("li"),F9e=a("strong"),BPr=o("albert"),PPr=o(" \u2014 "),ZU=a("a"),$Pr=o("FlaxAlbertForTokenClassification"),IPr=o(" (ALBERT model)"),qPr=l(),kE=a("li"),T9e=a("strong"),NPr=o("bert"),jPr=o(" \u2014 "),eJ=a("a"),DPr=o("FlaxBertForTokenClassification"),GPr=o(" (BERT model)"),OPr=l(),SE=a("li"),M9e=a("strong"),VPr=o("big_bird"),XPr=o(" \u2014 "),oJ=a("a"),zPr=o("FlaxBigBirdForTokenClassification"),QPr=o(" (BigBird model)"),WPr=l(),RE=a("li"),E9e=a("strong"),HPr=o("distilbert"),UPr=o(" \u2014 "),rJ=a("a"),JPr=o("FlaxDistilBertForTokenClassification"),YPr=o(" (DistilBERT model)"),KPr=l(),BE=a("li"),C9e=a("strong"),ZPr=o("electra"),e$r=o(" \u2014 "),tJ=a("a"),o$r=o("FlaxElectraForTokenClassification"),r$r=o(" (ELECTRA model)"),t$r=l(),PE=a("li"),w9e=a("strong"),a$r=o("roberta"),n$r=o(" \u2014 "),aJ=a("a"),s$r=o("FlaxRobertaForTokenClassification"),l$r=o(" (RoBERTa model)"),i$r=l(),$E=a("li"),A9e=a("strong"),d$r=o("roformer"),c$r=o(" \u2014 "),nJ=a("a"),f$r=o("FlaxRoFormerForTokenClassification"),m$r=o(" (RoFormer model)"),g$r=l(),IE=a("li"),y9e=a("strong"),h$r=o("xlm-roberta"),p$r=o(" \u2014 "),sJ=a("a"),_$r=o("FlaxXLMRobertaForTokenClassification"),u$r=o(" (XLM-RoBERTa model)"),b$r=l(),L9e=a("p"),v$r=o("Examples:"),F$r=l(),f(bL.$$.fragment),wIe=l(),Rf=a("h2"),qE=a("a"),x9e=a("span"),f(vL.$$.fragment),T$r=l(),k9e=a("span"),M$r=o("FlaxAutoModelForMultipleChoice"),AIe=l(),Dr=a("div"),f(FL.$$.fragment),E$r=l(),Bf=a("p"),C$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),lJ=a("a"),w$r=o("from_pretrained()"),A$r=o(" class method or the "),iJ=a("a"),y$r=o("from_config()"),L$r=o(` class
method.`),x$r=l(),TL=a("p"),k$r=o("This class cannot be instantiated directly using "),S9e=a("code"),S$r=o("__init__()"),R$r=o(" (throws an error)."),B$r=l(),Pt=a("div"),f(ML.$$.fragment),P$r=l(),R9e=a("p"),$$r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),I$r=l(),Pf=a("p"),q$r=o(`Note:
Loading a model from its configuration file does `),B9e=a("strong"),N$r=o("not"),j$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dJ=a("a"),D$r=o("from_pretrained()"),G$r=o(" to load the model weights."),O$r=l(),P9e=a("p"),V$r=o("Examples:"),X$r=l(),f(EL.$$.fragment),z$r=l(),Io=a("div"),f(CL.$$.fragment),Q$r=l(),$9e=a("p"),W$r=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),H$r=l(),Nn=a("p"),U$r=o("The model class to instantiate is selected based on the "),I9e=a("code"),J$r=o("model_type"),Y$r=o(` property of the config object (either
passed as an argument or loaded from `),q9e=a("code"),K$r=o("pretrained_model_name_or_path"),Z$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N9e=a("code"),eIr=o("pretrained_model_name_or_path"),oIr=o(":"),rIr=l(),Ie=a("ul"),NE=a("li"),j9e=a("strong"),tIr=o("albert"),aIr=o(" \u2014 "),cJ=a("a"),nIr=o("FlaxAlbertForMultipleChoice"),sIr=o(" (ALBERT model)"),lIr=l(),jE=a("li"),D9e=a("strong"),iIr=o("bert"),dIr=o(" \u2014 "),fJ=a("a"),cIr=o("FlaxBertForMultipleChoice"),fIr=o(" (BERT model)"),mIr=l(),DE=a("li"),G9e=a("strong"),gIr=o("big_bird"),hIr=o(" \u2014 "),mJ=a("a"),pIr=o("FlaxBigBirdForMultipleChoice"),_Ir=o(" (BigBird model)"),uIr=l(),GE=a("li"),O9e=a("strong"),bIr=o("distilbert"),vIr=o(" \u2014 "),gJ=a("a"),FIr=o("FlaxDistilBertForMultipleChoice"),TIr=o(" (DistilBERT model)"),MIr=l(),OE=a("li"),V9e=a("strong"),EIr=o("electra"),CIr=o(" \u2014 "),hJ=a("a"),wIr=o("FlaxElectraForMultipleChoice"),AIr=o(" (ELECTRA model)"),yIr=l(),VE=a("li"),X9e=a("strong"),LIr=o("roberta"),xIr=o(" \u2014 "),pJ=a("a"),kIr=o("FlaxRobertaForMultipleChoice"),SIr=o(" (RoBERTa model)"),RIr=l(),XE=a("li"),z9e=a("strong"),BIr=o("roformer"),PIr=o(" \u2014 "),_J=a("a"),$Ir=o("FlaxRoFormerForMultipleChoice"),IIr=o(" (RoFormer model)"),qIr=l(),zE=a("li"),Q9e=a("strong"),NIr=o("xlm-roberta"),jIr=o(" \u2014 "),uJ=a("a"),DIr=o("FlaxXLMRobertaForMultipleChoice"),GIr=o(" (XLM-RoBERTa model)"),OIr=l(),W9e=a("p"),VIr=o("Examples:"),XIr=l(),f(wL.$$.fragment),yIe=l(),$f=a("h2"),QE=a("a"),H9e=a("span"),f(AL.$$.fragment),zIr=l(),U9e=a("span"),QIr=o("FlaxAutoModelForNextSentencePrediction"),LIe=l(),Gr=a("div"),f(yL.$$.fragment),WIr=l(),If=a("p"),HIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),bJ=a("a"),UIr=o("from_pretrained()"),JIr=o(" class method or the "),vJ=a("a"),YIr=o("from_config()"),KIr=o(` class
method.`),ZIr=l(),LL=a("p"),eqr=o("This class cannot be instantiated directly using "),J9e=a("code"),oqr=o("__init__()"),rqr=o(" (throws an error)."),tqr=l(),$t=a("div"),f(xL.$$.fragment),aqr=l(),Y9e=a("p"),nqr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),sqr=l(),qf=a("p"),lqr=o(`Note:
Loading a model from its configuration file does `),K9e=a("strong"),iqr=o("not"),dqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FJ=a("a"),cqr=o("from_pretrained()"),fqr=o(" to load the model weights."),mqr=l(),Z9e=a("p"),gqr=o("Examples:"),hqr=l(),f(kL.$$.fragment),pqr=l(),qo=a("div"),f(SL.$$.fragment),_qr=l(),eMe=a("p"),uqr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),bqr=l(),jn=a("p"),vqr=o("The model class to instantiate is selected based on the "),oMe=a("code"),Fqr=o("model_type"),Tqr=o(` property of the config object (either
passed as an argument or loaded from `),rMe=a("code"),Mqr=o("pretrained_model_name_or_path"),Eqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tMe=a("code"),Cqr=o("pretrained_model_name_or_path"),wqr=o(":"),Aqr=l(),aMe=a("ul"),WE=a("li"),nMe=a("strong"),yqr=o("bert"),Lqr=o(" \u2014 "),TJ=a("a"),xqr=o("FlaxBertForNextSentencePrediction"),kqr=o(" (BERT model)"),Sqr=l(),sMe=a("p"),Rqr=o("Examples:"),Bqr=l(),f(RL.$$.fragment),xIe=l(),Nf=a("h2"),HE=a("a"),lMe=a("span"),f(BL.$$.fragment),Pqr=l(),iMe=a("span"),$qr=o("FlaxAutoModelForImageClassification"),kIe=l(),Or=a("div"),f(PL.$$.fragment),Iqr=l(),jf=a("p"),qqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),MJ=a("a"),Nqr=o("from_pretrained()"),jqr=o(" class method or the "),EJ=a("a"),Dqr=o("from_config()"),Gqr=o(` class
method.`),Oqr=l(),$L=a("p"),Vqr=o("This class cannot be instantiated directly using "),dMe=a("code"),Xqr=o("__init__()"),zqr=o(" (throws an error)."),Qqr=l(),It=a("div"),f(IL.$$.fragment),Wqr=l(),cMe=a("p"),Hqr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Uqr=l(),Df=a("p"),Jqr=o(`Note:
Loading a model from its configuration file does `),fMe=a("strong"),Yqr=o("not"),Kqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CJ=a("a"),Zqr=o("from_pretrained()"),eNr=o(" to load the model weights."),oNr=l(),mMe=a("p"),rNr=o("Examples:"),tNr=l(),f(qL.$$.fragment),aNr=l(),No=a("div"),f(NL.$$.fragment),nNr=l(),gMe=a("p"),sNr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),lNr=l(),Dn=a("p"),iNr=o("The model class to instantiate is selected based on the "),hMe=a("code"),dNr=o("model_type"),cNr=o(` property of the config object (either
passed as an argument or loaded from `),pMe=a("code"),fNr=o("pretrained_model_name_or_path"),mNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Me=a("code"),gNr=o("pretrained_model_name_or_path"),hNr=o(":"),pNr=l(),jL=a("ul"),UE=a("li"),uMe=a("strong"),_Nr=o("beit"),uNr=o(" \u2014 "),wJ=a("a"),bNr=o("FlaxBeitForImageClassification"),vNr=o(" (BEiT model)"),FNr=l(),JE=a("li"),bMe=a("strong"),TNr=o("vit"),MNr=o(" \u2014 "),AJ=a("a"),ENr=o("FlaxViTForImageClassification"),CNr=o(" (ViT model)"),wNr=l(),vMe=a("p"),ANr=o("Examples:"),yNr=l(),f(DL.$$.fragment),SIe=l(),Gf=a("h2"),YE=a("a"),FMe=a("span"),f(GL.$$.fragment),LNr=l(),TMe=a("span"),xNr=o("FlaxAutoModelForVision2Seq"),RIe=l(),Vr=a("div"),f(OL.$$.fragment),kNr=l(),Of=a("p"),SNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),yJ=a("a"),RNr=o("from_pretrained()"),BNr=o(" class method or the "),LJ=a("a"),PNr=o("from_config()"),$Nr=o(` class
method.`),INr=l(),VL=a("p"),qNr=o("This class cannot be instantiated directly using "),MMe=a("code"),NNr=o("__init__()"),jNr=o(" (throws an error)."),DNr=l(),qt=a("div"),f(XL.$$.fragment),GNr=l(),EMe=a("p"),ONr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),VNr=l(),Vf=a("p"),XNr=o(`Note:
Loading a model from its configuration file does `),CMe=a("strong"),zNr=o("not"),QNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xJ=a("a"),WNr=o("from_pretrained()"),HNr=o(" to load the model weights."),UNr=l(),wMe=a("p"),JNr=o("Examples:"),YNr=l(),f(zL.$$.fragment),KNr=l(),jo=a("div"),f(QL.$$.fragment),ZNr=l(),AMe=a("p"),ejr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),ojr=l(),Gn=a("p"),rjr=o("The model class to instantiate is selected based on the "),yMe=a("code"),tjr=o("model_type"),ajr=o(` property of the config object (either
passed as an argument or loaded from `),LMe=a("code"),njr=o("pretrained_model_name_or_path"),sjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=a("code"),ljr=o("pretrained_model_name_or_path"),ijr=o(":"),djr=l(),kMe=a("ul"),KE=a("li"),SMe=a("strong"),cjr=o("vision-encoder-decoder"),fjr=o(" \u2014 "),kJ=a("a"),mjr=o("FlaxVisionEncoderDecoderModel"),gjr=o(" (Vision Encoder decoder model)"),hjr=l(),RMe=a("p"),pjr=o("Examples:"),_jr=l(),f(WL.$$.fragment),this.h()},l(c){const u=cLt('[data-svelte="svelte-1phssyn"]',document.head);oe=n(u,"META",{name:!0,content:!0}),u.forEach(t),co=i(c),ge=n(c,"H1",{class:!0});var HL=s(ge);Ae=n(HL,"A",{id:!0,class:!0,href:!0});var BMe=s(Ae);io=n(BMe,"SPAN",{});var PMe=s(io);m(ue.$$.fragment,PMe),PMe.forEach(t),BMe.forEach(t),we=i(HL),Xo=n(HL,"SPAN",{});var bjr=s(Xo);Qi=r(bjr,"Auto Classes"),bjr.forEach(t),HL.forEach(t),Qf=i(c),fa=n(c,"P",{});var PIe=s(fa);Wi=r(PIe,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Hi=n(PIe,"CODE",{});var vjr=s(Hi);Z5=r(vjr,"from_pretrained()"),vjr.forEach(t),Wf=r(PIe,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),PIe.forEach(t),Re=i(c),fo=n(c,"P",{});var ZE=s(fo);Ui=r(ZE,"Instantiating one of "),On=n(ZE,"A",{href:!0});var Fjr=s(On);e3=r(Fjr,"AutoConfig"),Fjr.forEach(t),Vn=r(ZE,", "),Xn=n(ZE,"A",{href:!0});var Tjr=s(Xn);o3=r(Tjr,"AutoModel"),Tjr.forEach(t),Ji=r(ZE,`, and
`),zn=n(ZE,"A",{href:!0});var Mjr=s(zn);r3=r(Mjr,"AutoTokenizer"),Mjr.forEach(t),Yi=r(ZE," will directly create a class of the relevant architecture. For instance"),ZE.forEach(t),Hf=i(c),m(Da.$$.fragment,c),mo=i(c),ve=n(c,"P",{});var $Ie=s(ve);ex=r($Ie,"will create a model that is an instance of "),Ki=n($Ie,"A",{href:!0});var Ejr=s(Ki);ox=r(Ejr,"BertModel"),Ejr.forEach(t),rx=r($Ie,"."),$Ie.forEach(t),zo=i(c),Ga=n(c,"P",{});var IIe=s(Ga);tx=r(IIe,"There is one class of "),Uf=n(IIe,"CODE",{});var Cjr=s(Uf);ax=r(Cjr,"AutoModel"),Cjr.forEach(t),zNe=r(IIe," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),IIe.forEach(t),RPe=i(c),Zi=n(c,"H2",{class:!0});var qIe=s(Zi);Jf=n(qIe,"A",{id:!0,class:!0,href:!0});var wjr=s(Jf);EK=n(wjr,"SPAN",{});var Ajr=s(EK);m(t3.$$.fragment,Ajr),Ajr.forEach(t),wjr.forEach(t),QNe=i(qIe),CK=n(qIe,"SPAN",{});var yjr=s(CK);WNe=r(yjr,"Extending the Auto Classes"),yjr.forEach(t),qIe.forEach(t),BPe=i(c),Qn=n(c,"P",{});var SJ=s(Qn);HNe=r(SJ,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),wK=n(SJ,"CODE",{});var Ljr=s(wK);UNe=r(Ljr,"NewModel"),Ljr.forEach(t),JNe=r(SJ,", make sure you have a "),AK=n(SJ,"CODE",{});var xjr=s(AK);YNe=r(xjr,"NewModelConfig"),xjr.forEach(t),KNe=r(SJ,` then you can add those to the auto
classes like this:`),SJ.forEach(t),PPe=i(c),m(a3.$$.fragment,c),$Pe=i(c),nx=n(c,"P",{});var kjr=s(nx);ZNe=r(kjr,"You will then be able to use the auto classes like you would usually do!"),kjr.forEach(t),IPe=i(c),m(Yf.$$.fragment,c),qPe=i(c),ed=n(c,"H2",{class:!0});var NIe=s(ed);Kf=n(NIe,"A",{id:!0,class:!0,href:!0});var Sjr=s(Kf);yK=n(Sjr,"SPAN",{});var Rjr=s(yK);m(n3.$$.fragment,Rjr),Rjr.forEach(t),Sjr.forEach(t),eje=i(NIe),LK=n(NIe,"SPAN",{});var Bjr=s(LK);oje=r(Bjr,"AutoConfig"),Bjr.forEach(t),NIe.forEach(t),NPe=i(c),Qo=n(c,"DIV",{class:!0});var Ks=s(Qo);m(s3.$$.fragment,Ks),rje=i(Ks),l3=n(Ks,"P",{});var jIe=s(l3);tje=r(jIe,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),sx=n(jIe,"A",{href:!0});var Pjr=s(sx);aje=r(Pjr,"from_pretrained()"),Pjr.forEach(t),nje=r(jIe," class method."),jIe.forEach(t),sje=i(Ks),i3=n(Ks,"P",{});var DIe=s(i3);lje=r(DIe,"This class cannot be instantiated directly using "),xK=n(DIe,"CODE",{});var $jr=s(xK);ije=r($jr,"__init__()"),$jr.forEach(t),dje=r(DIe," (throws an error)."),DIe.forEach(t),cje=i(Ks),go=n(Ks,"DIV",{class:!0});var ga=s(go);m(d3.$$.fragment,ga),fje=i(ga),kK=n(ga,"P",{});var Ijr=s(kK);mje=r(Ijr,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),Ijr.forEach(t),gje=i(ga),od=n(ga,"P",{});var RJ=s(od);hje=r(RJ,"The configuration class to instantiate is selected based on the "),SK=n(RJ,"CODE",{});var qjr=s(SK);pje=r(qjr,"model_type"),qjr.forEach(t),_je=r(RJ,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),RK=n(RJ,"CODE",{});var Njr=s(RK);uje=r(Njr,"pretrained_model_name_or_path"),Njr.forEach(t),bje=r(RJ,":"),RJ.forEach(t),vje=i(ga),v=n(ga,"UL",{});var F=s(v);Zf=n(F,"LI",{});var $Me=s(Zf);BK=n($Me,"STRONG",{});var jjr=s(BK);Fje=r(jjr,"albert"),jjr.forEach(t),Tje=r($Me," \u2014 "),lx=n($Me,"A",{href:!0});var Djr=s(lx);Mje=r(Djr,"AlbertConfig"),Djr.forEach(t),Eje=r($Me," (ALBERT model)"),$Me.forEach(t),Cje=i(F),em=n(F,"LI",{});var IMe=s(em);PK=n(IMe,"STRONG",{});var Gjr=s(PK);wje=r(Gjr,"bart"),Gjr.forEach(t),Aje=r(IMe," \u2014 "),ix=n(IMe,"A",{href:!0});var Ojr=s(ix);yje=r(Ojr,"BartConfig"),Ojr.forEach(t),Lje=r(IMe," (BART model)"),IMe.forEach(t),xje=i(F),om=n(F,"LI",{});var qMe=s(om);$K=n(qMe,"STRONG",{});var Vjr=s($K);kje=r(Vjr,"beit"),Vjr.forEach(t),Sje=r(qMe," \u2014 "),dx=n(qMe,"A",{href:!0});var Xjr=s(dx);Rje=r(Xjr,"BeitConfig"),Xjr.forEach(t),Bje=r(qMe," (BEiT model)"),qMe.forEach(t),Pje=i(F),rm=n(F,"LI",{});var NMe=s(rm);IK=n(NMe,"STRONG",{});var zjr=s(IK);$je=r(zjr,"bert"),zjr.forEach(t),Ije=r(NMe," \u2014 "),cx=n(NMe,"A",{href:!0});var Qjr=s(cx);qje=r(Qjr,"BertConfig"),Qjr.forEach(t),Nje=r(NMe," (BERT model)"),NMe.forEach(t),jje=i(F),tm=n(F,"LI",{});var jMe=s(tm);qK=n(jMe,"STRONG",{});var Wjr=s(qK);Dje=r(Wjr,"bert-generation"),Wjr.forEach(t),Gje=r(jMe," \u2014 "),fx=n(jMe,"A",{href:!0});var Hjr=s(fx);Oje=r(Hjr,"BertGenerationConfig"),Hjr.forEach(t),Vje=r(jMe," (Bert Generation model)"),jMe.forEach(t),Xje=i(F),am=n(F,"LI",{});var DMe=s(am);NK=n(DMe,"STRONG",{});var Ujr=s(NK);zje=r(Ujr,"big_bird"),Ujr.forEach(t),Qje=r(DMe," \u2014 "),mx=n(DMe,"A",{href:!0});var Jjr=s(mx);Wje=r(Jjr,"BigBirdConfig"),Jjr.forEach(t),Hje=r(DMe," (BigBird model)"),DMe.forEach(t),Uje=i(F),nm=n(F,"LI",{});var GMe=s(nm);jK=n(GMe,"STRONG",{});var Yjr=s(jK);Jje=r(Yjr,"bigbird_pegasus"),Yjr.forEach(t),Yje=r(GMe," \u2014 "),gx=n(GMe,"A",{href:!0});var Kjr=s(gx);Kje=r(Kjr,"BigBirdPegasusConfig"),Kjr.forEach(t),Zje=r(GMe," (BigBirdPegasus model)"),GMe.forEach(t),eDe=i(F),sm=n(F,"LI",{});var OMe=s(sm);DK=n(OMe,"STRONG",{});var Zjr=s(DK);oDe=r(Zjr,"blenderbot"),Zjr.forEach(t),rDe=r(OMe," \u2014 "),hx=n(OMe,"A",{href:!0});var eDr=s(hx);tDe=r(eDr,"BlenderbotConfig"),eDr.forEach(t),aDe=r(OMe," (Blenderbot model)"),OMe.forEach(t),nDe=i(F),lm=n(F,"LI",{});var VMe=s(lm);GK=n(VMe,"STRONG",{});var oDr=s(GK);sDe=r(oDr,"blenderbot-small"),oDr.forEach(t),lDe=r(VMe," \u2014 "),px=n(VMe,"A",{href:!0});var rDr=s(px);iDe=r(rDr,"BlenderbotSmallConfig"),rDr.forEach(t),dDe=r(VMe," (BlenderbotSmall model)"),VMe.forEach(t),cDe=i(F),im=n(F,"LI",{});var XMe=s(im);OK=n(XMe,"STRONG",{});var tDr=s(OK);fDe=r(tDr,"camembert"),tDr.forEach(t),mDe=r(XMe," \u2014 "),_x=n(XMe,"A",{href:!0});var aDr=s(_x);gDe=r(aDr,"CamembertConfig"),aDr.forEach(t),hDe=r(XMe," (CamemBERT model)"),XMe.forEach(t),pDe=i(F),dm=n(F,"LI",{});var zMe=s(dm);VK=n(zMe,"STRONG",{});var nDr=s(VK);_De=r(nDr,"canine"),nDr.forEach(t),uDe=r(zMe," \u2014 "),ux=n(zMe,"A",{href:!0});var sDr=s(ux);bDe=r(sDr,"CanineConfig"),sDr.forEach(t),vDe=r(zMe," (Canine model)"),zMe.forEach(t),FDe=i(F),cm=n(F,"LI",{});var QMe=s(cm);XK=n(QMe,"STRONG",{});var lDr=s(XK);TDe=r(lDr,"clip"),lDr.forEach(t),MDe=r(QMe," \u2014 "),bx=n(QMe,"A",{href:!0});var iDr=s(bx);EDe=r(iDr,"CLIPConfig"),iDr.forEach(t),CDe=r(QMe," (CLIP model)"),QMe.forEach(t),wDe=i(F),fm=n(F,"LI",{});var WMe=s(fm);zK=n(WMe,"STRONG",{});var dDr=s(zK);ADe=r(dDr,"convbert"),dDr.forEach(t),yDe=r(WMe," \u2014 "),vx=n(WMe,"A",{href:!0});var cDr=s(vx);LDe=r(cDr,"ConvBertConfig"),cDr.forEach(t),xDe=r(WMe," (ConvBERT model)"),WMe.forEach(t),kDe=i(F),mm=n(F,"LI",{});var HMe=s(mm);QK=n(HMe,"STRONG",{});var fDr=s(QK);SDe=r(fDr,"convnext"),fDr.forEach(t),RDe=r(HMe," \u2014 "),Fx=n(HMe,"A",{href:!0});var mDr=s(Fx);BDe=r(mDr,"ConvNextConfig"),mDr.forEach(t),PDe=r(HMe," (ConvNext model)"),HMe.forEach(t),$De=i(F),gm=n(F,"LI",{});var UMe=s(gm);WK=n(UMe,"STRONG",{});var gDr=s(WK);IDe=r(gDr,"ctrl"),gDr.forEach(t),qDe=r(UMe," \u2014 "),Tx=n(UMe,"A",{href:!0});var hDr=s(Tx);NDe=r(hDr,"CTRLConfig"),hDr.forEach(t),jDe=r(UMe," (CTRL model)"),UMe.forEach(t),DDe=i(F),hm=n(F,"LI",{});var JMe=s(hm);HK=n(JMe,"STRONG",{});var pDr=s(HK);GDe=r(pDr,"data2vec-audio"),pDr.forEach(t),ODe=r(JMe," \u2014 "),Mx=n(JMe,"A",{href:!0});var _Dr=s(Mx);VDe=r(_Dr,"Data2VecAudioConfig"),_Dr.forEach(t),XDe=r(JMe," (Data2VecAudio model)"),JMe.forEach(t),zDe=i(F),pm=n(F,"LI",{});var YMe=s(pm);UK=n(YMe,"STRONG",{});var uDr=s(UK);QDe=r(uDr,"data2vec-text"),uDr.forEach(t),WDe=r(YMe," \u2014 "),Ex=n(YMe,"A",{href:!0});var bDr=s(Ex);HDe=r(bDr,"Data2VecTextConfig"),bDr.forEach(t),UDe=r(YMe," (Data2VecText model)"),YMe.forEach(t),JDe=i(F),_m=n(F,"LI",{});var KMe=s(_m);JK=n(KMe,"STRONG",{});var vDr=s(JK);YDe=r(vDr,"data2vec-vision"),vDr.forEach(t),KDe=r(KMe," \u2014 "),Cx=n(KMe,"A",{href:!0});var FDr=s(Cx);ZDe=r(FDr,"Data2VecVisionConfig"),FDr.forEach(t),eGe=r(KMe," (Data2VecVision model)"),KMe.forEach(t),oGe=i(F),um=n(F,"LI",{});var ZMe=s(um);YK=n(ZMe,"STRONG",{});var TDr=s(YK);rGe=r(TDr,"deberta"),TDr.forEach(t),tGe=r(ZMe," \u2014 "),wx=n(ZMe,"A",{href:!0});var MDr=s(wx);aGe=r(MDr,"DebertaConfig"),MDr.forEach(t),nGe=r(ZMe," (DeBERTa model)"),ZMe.forEach(t),sGe=i(F),bm=n(F,"LI",{});var e4e=s(bm);KK=n(e4e,"STRONG",{});var EDr=s(KK);lGe=r(EDr,"deberta-v2"),EDr.forEach(t),iGe=r(e4e," \u2014 "),Ax=n(e4e,"A",{href:!0});var CDr=s(Ax);dGe=r(CDr,"DebertaV2Config"),CDr.forEach(t),cGe=r(e4e," (DeBERTa-v2 model)"),e4e.forEach(t),fGe=i(F),vm=n(F,"LI",{});var o4e=s(vm);ZK=n(o4e,"STRONG",{});var wDr=s(ZK);mGe=r(wDr,"decision_transformer"),wDr.forEach(t),gGe=r(o4e," \u2014 "),yx=n(o4e,"A",{href:!0});var ADr=s(yx);hGe=r(ADr,"DecisionTransformerConfig"),ADr.forEach(t),pGe=r(o4e," (Decision Transformer model)"),o4e.forEach(t),_Ge=i(F),Fm=n(F,"LI",{});var r4e=s(Fm);eZ=n(r4e,"STRONG",{});var yDr=s(eZ);uGe=r(yDr,"deit"),yDr.forEach(t),bGe=r(r4e," \u2014 "),Lx=n(r4e,"A",{href:!0});var LDr=s(Lx);vGe=r(LDr,"DeiTConfig"),LDr.forEach(t),FGe=r(r4e," (DeiT model)"),r4e.forEach(t),TGe=i(F),Tm=n(F,"LI",{});var t4e=s(Tm);oZ=n(t4e,"STRONG",{});var xDr=s(oZ);MGe=r(xDr,"detr"),xDr.forEach(t),EGe=r(t4e," \u2014 "),xx=n(t4e,"A",{href:!0});var kDr=s(xx);CGe=r(kDr,"DetrConfig"),kDr.forEach(t),wGe=r(t4e," (DETR model)"),t4e.forEach(t),AGe=i(F),Mm=n(F,"LI",{});var a4e=s(Mm);rZ=n(a4e,"STRONG",{});var SDr=s(rZ);yGe=r(SDr,"distilbert"),SDr.forEach(t),LGe=r(a4e," \u2014 "),kx=n(a4e,"A",{href:!0});var RDr=s(kx);xGe=r(RDr,"DistilBertConfig"),RDr.forEach(t),kGe=r(a4e," (DistilBERT model)"),a4e.forEach(t),SGe=i(F),Em=n(F,"LI",{});var n4e=s(Em);tZ=n(n4e,"STRONG",{});var BDr=s(tZ);RGe=r(BDr,"dpr"),BDr.forEach(t),BGe=r(n4e," \u2014 "),Sx=n(n4e,"A",{href:!0});var PDr=s(Sx);PGe=r(PDr,"DPRConfig"),PDr.forEach(t),$Ge=r(n4e," (DPR model)"),n4e.forEach(t),IGe=i(F),Cm=n(F,"LI",{});var s4e=s(Cm);aZ=n(s4e,"STRONG",{});var $Dr=s(aZ);qGe=r($Dr,"dpt"),$Dr.forEach(t),NGe=r(s4e," \u2014 "),Rx=n(s4e,"A",{href:!0});var IDr=s(Rx);jGe=r(IDr,"DPTConfig"),IDr.forEach(t),DGe=r(s4e," (DPT model)"),s4e.forEach(t),GGe=i(F),wm=n(F,"LI",{});var l4e=s(wm);nZ=n(l4e,"STRONG",{});var qDr=s(nZ);OGe=r(qDr,"electra"),qDr.forEach(t),VGe=r(l4e," \u2014 "),Bx=n(l4e,"A",{href:!0});var NDr=s(Bx);XGe=r(NDr,"ElectraConfig"),NDr.forEach(t),zGe=r(l4e," (ELECTRA model)"),l4e.forEach(t),QGe=i(F),Am=n(F,"LI",{});var i4e=s(Am);sZ=n(i4e,"STRONG",{});var jDr=s(sZ);WGe=r(jDr,"encoder-decoder"),jDr.forEach(t),HGe=r(i4e," \u2014 "),Px=n(i4e,"A",{href:!0});var DDr=s(Px);UGe=r(DDr,"EncoderDecoderConfig"),DDr.forEach(t),JGe=r(i4e," (Encoder decoder model)"),i4e.forEach(t),YGe=i(F),ym=n(F,"LI",{});var d4e=s(ym);lZ=n(d4e,"STRONG",{});var GDr=s(lZ);KGe=r(GDr,"flaubert"),GDr.forEach(t),ZGe=r(d4e," \u2014 "),$x=n(d4e,"A",{href:!0});var ODr=s($x);eOe=r(ODr,"FlaubertConfig"),ODr.forEach(t),oOe=r(d4e," (FlauBERT model)"),d4e.forEach(t),rOe=i(F),Lm=n(F,"LI",{});var c4e=s(Lm);iZ=n(c4e,"STRONG",{});var VDr=s(iZ);tOe=r(VDr,"fnet"),VDr.forEach(t),aOe=r(c4e," \u2014 "),Ix=n(c4e,"A",{href:!0});var XDr=s(Ix);nOe=r(XDr,"FNetConfig"),XDr.forEach(t),sOe=r(c4e," (FNet model)"),c4e.forEach(t),lOe=i(F),xm=n(F,"LI",{});var f4e=s(xm);dZ=n(f4e,"STRONG",{});var zDr=s(dZ);iOe=r(zDr,"fsmt"),zDr.forEach(t),dOe=r(f4e," \u2014 "),qx=n(f4e,"A",{href:!0});var QDr=s(qx);cOe=r(QDr,"FSMTConfig"),QDr.forEach(t),fOe=r(f4e," (FairSeq Machine-Translation model)"),f4e.forEach(t),mOe=i(F),km=n(F,"LI",{});var m4e=s(km);cZ=n(m4e,"STRONG",{});var WDr=s(cZ);gOe=r(WDr,"funnel"),WDr.forEach(t),hOe=r(m4e," \u2014 "),Nx=n(m4e,"A",{href:!0});var HDr=s(Nx);pOe=r(HDr,"FunnelConfig"),HDr.forEach(t),_Oe=r(m4e," (Funnel Transformer model)"),m4e.forEach(t),uOe=i(F),Sm=n(F,"LI",{});var g4e=s(Sm);fZ=n(g4e,"STRONG",{});var UDr=s(fZ);bOe=r(UDr,"glpn"),UDr.forEach(t),vOe=r(g4e," \u2014 "),jx=n(g4e,"A",{href:!0});var JDr=s(jx);FOe=r(JDr,"GLPNConfig"),JDr.forEach(t),TOe=r(g4e," (GLPN model)"),g4e.forEach(t),MOe=i(F),Rm=n(F,"LI",{});var h4e=s(Rm);mZ=n(h4e,"STRONG",{});var YDr=s(mZ);EOe=r(YDr,"gpt2"),YDr.forEach(t),COe=r(h4e," \u2014 "),Dx=n(h4e,"A",{href:!0});var KDr=s(Dx);wOe=r(KDr,"GPT2Config"),KDr.forEach(t),AOe=r(h4e," (OpenAI GPT-2 model)"),h4e.forEach(t),yOe=i(F),Bm=n(F,"LI",{});var p4e=s(Bm);gZ=n(p4e,"STRONG",{});var ZDr=s(gZ);LOe=r(ZDr,"gpt_neo"),ZDr.forEach(t),xOe=r(p4e," \u2014 "),Gx=n(p4e,"A",{href:!0});var eGr=s(Gx);kOe=r(eGr,"GPTNeoConfig"),eGr.forEach(t),SOe=r(p4e," (GPT Neo model)"),p4e.forEach(t),ROe=i(F),Pm=n(F,"LI",{});var _4e=s(Pm);hZ=n(_4e,"STRONG",{});var oGr=s(hZ);BOe=r(oGr,"gptj"),oGr.forEach(t),POe=r(_4e," \u2014 "),Ox=n(_4e,"A",{href:!0});var rGr=s(Ox);$Oe=r(rGr,"GPTJConfig"),rGr.forEach(t),IOe=r(_4e," (GPT-J model)"),_4e.forEach(t),qOe=i(F),$m=n(F,"LI",{});var u4e=s($m);pZ=n(u4e,"STRONG",{});var tGr=s(pZ);NOe=r(tGr,"hubert"),tGr.forEach(t),jOe=r(u4e," \u2014 "),Vx=n(u4e,"A",{href:!0});var aGr=s(Vx);DOe=r(aGr,"HubertConfig"),aGr.forEach(t),GOe=r(u4e," (Hubert model)"),u4e.forEach(t),OOe=i(F),Im=n(F,"LI",{});var b4e=s(Im);_Z=n(b4e,"STRONG",{});var nGr=s(_Z);VOe=r(nGr,"ibert"),nGr.forEach(t),XOe=r(b4e," \u2014 "),Xx=n(b4e,"A",{href:!0});var sGr=s(Xx);zOe=r(sGr,"IBertConfig"),sGr.forEach(t),QOe=r(b4e," (I-BERT model)"),b4e.forEach(t),WOe=i(F),qm=n(F,"LI",{});var v4e=s(qm);uZ=n(v4e,"STRONG",{});var lGr=s(uZ);HOe=r(lGr,"imagegpt"),lGr.forEach(t),UOe=r(v4e," \u2014 "),zx=n(v4e,"A",{href:!0});var iGr=s(zx);JOe=r(iGr,"ImageGPTConfig"),iGr.forEach(t),YOe=r(v4e," (ImageGPT model)"),v4e.forEach(t),KOe=i(F),Nm=n(F,"LI",{});var F4e=s(Nm);bZ=n(F4e,"STRONG",{});var dGr=s(bZ);ZOe=r(dGr,"layoutlm"),dGr.forEach(t),eVe=r(F4e," \u2014 "),Qx=n(F4e,"A",{href:!0});var cGr=s(Qx);oVe=r(cGr,"LayoutLMConfig"),cGr.forEach(t),rVe=r(F4e," (LayoutLM model)"),F4e.forEach(t),tVe=i(F),jm=n(F,"LI",{});var T4e=s(jm);vZ=n(T4e,"STRONG",{});var fGr=s(vZ);aVe=r(fGr,"layoutlmv2"),fGr.forEach(t),nVe=r(T4e," \u2014 "),Wx=n(T4e,"A",{href:!0});var mGr=s(Wx);sVe=r(mGr,"LayoutLMv2Config"),mGr.forEach(t),lVe=r(T4e," (LayoutLMv2 model)"),T4e.forEach(t),iVe=i(F),Dm=n(F,"LI",{});var M4e=s(Dm);FZ=n(M4e,"STRONG",{});var gGr=s(FZ);dVe=r(gGr,"led"),gGr.forEach(t),cVe=r(M4e," \u2014 "),Hx=n(M4e,"A",{href:!0});var hGr=s(Hx);fVe=r(hGr,"LEDConfig"),hGr.forEach(t),mVe=r(M4e," (LED model)"),M4e.forEach(t),gVe=i(F),Gm=n(F,"LI",{});var E4e=s(Gm);TZ=n(E4e,"STRONG",{});var pGr=s(TZ);hVe=r(pGr,"longformer"),pGr.forEach(t),pVe=r(E4e," \u2014 "),Ux=n(E4e,"A",{href:!0});var _Gr=s(Ux);_Ve=r(_Gr,"LongformerConfig"),_Gr.forEach(t),uVe=r(E4e," (Longformer model)"),E4e.forEach(t),bVe=i(F),Om=n(F,"LI",{});var C4e=s(Om);MZ=n(C4e,"STRONG",{});var uGr=s(MZ);vVe=r(uGr,"longt5"),uGr.forEach(t),FVe=r(C4e," \u2014 "),Jx=n(C4e,"A",{href:!0});var bGr=s(Jx);TVe=r(bGr,"LongT5Config"),bGr.forEach(t),MVe=r(C4e," (LongT5 model)"),C4e.forEach(t),EVe=i(F),Vm=n(F,"LI",{});var w4e=s(Vm);EZ=n(w4e,"STRONG",{});var vGr=s(EZ);CVe=r(vGr,"luke"),vGr.forEach(t),wVe=r(w4e," \u2014 "),Yx=n(w4e,"A",{href:!0});var FGr=s(Yx);AVe=r(FGr,"LukeConfig"),FGr.forEach(t),yVe=r(w4e," (LUKE model)"),w4e.forEach(t),LVe=i(F),Xm=n(F,"LI",{});var A4e=s(Xm);CZ=n(A4e,"STRONG",{});var TGr=s(CZ);xVe=r(TGr,"lxmert"),TGr.forEach(t),kVe=r(A4e," \u2014 "),Kx=n(A4e,"A",{href:!0});var MGr=s(Kx);SVe=r(MGr,"LxmertConfig"),MGr.forEach(t),RVe=r(A4e," (LXMERT model)"),A4e.forEach(t),BVe=i(F),zm=n(F,"LI",{});var y4e=s(zm);wZ=n(y4e,"STRONG",{});var EGr=s(wZ);PVe=r(EGr,"m2m_100"),EGr.forEach(t),$Ve=r(y4e," \u2014 "),Zx=n(y4e,"A",{href:!0});var CGr=s(Zx);IVe=r(CGr,"M2M100Config"),CGr.forEach(t),qVe=r(y4e," (M2M100 model)"),y4e.forEach(t),NVe=i(F),Qm=n(F,"LI",{});var L4e=s(Qm);AZ=n(L4e,"STRONG",{});var wGr=s(AZ);jVe=r(wGr,"marian"),wGr.forEach(t),DVe=r(L4e," \u2014 "),ek=n(L4e,"A",{href:!0});var AGr=s(ek);GVe=r(AGr,"MarianConfig"),AGr.forEach(t),OVe=r(L4e," (Marian model)"),L4e.forEach(t),VVe=i(F),Wm=n(F,"LI",{});var x4e=s(Wm);yZ=n(x4e,"STRONG",{});var yGr=s(yZ);XVe=r(yGr,"maskformer"),yGr.forEach(t),zVe=r(x4e," \u2014 "),ok=n(x4e,"A",{href:!0});var LGr=s(ok);QVe=r(LGr,"MaskFormerConfig"),LGr.forEach(t),WVe=r(x4e," (MaskFormer model)"),x4e.forEach(t),HVe=i(F),Hm=n(F,"LI",{});var k4e=s(Hm);LZ=n(k4e,"STRONG",{});var xGr=s(LZ);UVe=r(xGr,"mbart"),xGr.forEach(t),JVe=r(k4e," \u2014 "),rk=n(k4e,"A",{href:!0});var kGr=s(rk);YVe=r(kGr,"MBartConfig"),kGr.forEach(t),KVe=r(k4e," (mBART model)"),k4e.forEach(t),ZVe=i(F),Um=n(F,"LI",{});var S4e=s(Um);xZ=n(S4e,"STRONG",{});var SGr=s(xZ);eXe=r(SGr,"megatron-bert"),SGr.forEach(t),oXe=r(S4e," \u2014 "),tk=n(S4e,"A",{href:!0});var RGr=s(tk);rXe=r(RGr,"MegatronBertConfig"),RGr.forEach(t),tXe=r(S4e," (MegatronBert model)"),S4e.forEach(t),aXe=i(F),Jm=n(F,"LI",{});var R4e=s(Jm);kZ=n(R4e,"STRONG",{});var BGr=s(kZ);nXe=r(BGr,"mobilebert"),BGr.forEach(t),sXe=r(R4e," \u2014 "),ak=n(R4e,"A",{href:!0});var PGr=s(ak);lXe=r(PGr,"MobileBertConfig"),PGr.forEach(t),iXe=r(R4e," (MobileBERT model)"),R4e.forEach(t),dXe=i(F),Ym=n(F,"LI",{});var B4e=s(Ym);SZ=n(B4e,"STRONG",{});var $Gr=s(SZ);cXe=r($Gr,"mpnet"),$Gr.forEach(t),fXe=r(B4e," \u2014 "),nk=n(B4e,"A",{href:!0});var IGr=s(nk);mXe=r(IGr,"MPNetConfig"),IGr.forEach(t),gXe=r(B4e," (MPNet model)"),B4e.forEach(t),hXe=i(F),Km=n(F,"LI",{});var P4e=s(Km);RZ=n(P4e,"STRONG",{});var qGr=s(RZ);pXe=r(qGr,"mt5"),qGr.forEach(t),_Xe=r(P4e," \u2014 "),sk=n(P4e,"A",{href:!0});var NGr=s(sk);uXe=r(NGr,"MT5Config"),NGr.forEach(t),bXe=r(P4e," (mT5 model)"),P4e.forEach(t),vXe=i(F),Zm=n(F,"LI",{});var $4e=s(Zm);BZ=n($4e,"STRONG",{});var jGr=s(BZ);FXe=r(jGr,"nystromformer"),jGr.forEach(t),TXe=r($4e," \u2014 "),lk=n($4e,"A",{href:!0});var DGr=s(lk);MXe=r(DGr,"NystromformerConfig"),DGr.forEach(t),EXe=r($4e," (Nystromformer model)"),$4e.forEach(t),CXe=i(F),eg=n(F,"LI",{});var I4e=s(eg);PZ=n(I4e,"STRONG",{});var GGr=s(PZ);wXe=r(GGr,"openai-gpt"),GGr.forEach(t),AXe=r(I4e," \u2014 "),ik=n(I4e,"A",{href:!0});var OGr=s(ik);yXe=r(OGr,"OpenAIGPTConfig"),OGr.forEach(t),LXe=r(I4e," (OpenAI GPT model)"),I4e.forEach(t),xXe=i(F),og=n(F,"LI",{});var q4e=s(og);$Z=n(q4e,"STRONG",{});var VGr=s($Z);kXe=r(VGr,"pegasus"),VGr.forEach(t),SXe=r(q4e," \u2014 "),dk=n(q4e,"A",{href:!0});var XGr=s(dk);RXe=r(XGr,"PegasusConfig"),XGr.forEach(t),BXe=r(q4e," (Pegasus model)"),q4e.forEach(t),PXe=i(F),rg=n(F,"LI",{});var N4e=s(rg);IZ=n(N4e,"STRONG",{});var zGr=s(IZ);$Xe=r(zGr,"perceiver"),zGr.forEach(t),IXe=r(N4e," \u2014 "),ck=n(N4e,"A",{href:!0});var QGr=s(ck);qXe=r(QGr,"PerceiverConfig"),QGr.forEach(t),NXe=r(N4e," (Perceiver model)"),N4e.forEach(t),jXe=i(F),tg=n(F,"LI",{});var j4e=s(tg);qZ=n(j4e,"STRONG",{});var WGr=s(qZ);DXe=r(WGr,"plbart"),WGr.forEach(t),GXe=r(j4e," \u2014 "),fk=n(j4e,"A",{href:!0});var HGr=s(fk);OXe=r(HGr,"PLBartConfig"),HGr.forEach(t),VXe=r(j4e," (PLBart model)"),j4e.forEach(t),XXe=i(F),ag=n(F,"LI",{});var D4e=s(ag);NZ=n(D4e,"STRONG",{});var UGr=s(NZ);zXe=r(UGr,"poolformer"),UGr.forEach(t),QXe=r(D4e," \u2014 "),mk=n(D4e,"A",{href:!0});var JGr=s(mk);WXe=r(JGr,"PoolFormerConfig"),JGr.forEach(t),HXe=r(D4e," (PoolFormer model)"),D4e.forEach(t),UXe=i(F),ng=n(F,"LI",{});var G4e=s(ng);jZ=n(G4e,"STRONG",{});var YGr=s(jZ);JXe=r(YGr,"prophetnet"),YGr.forEach(t),YXe=r(G4e," \u2014 "),gk=n(G4e,"A",{href:!0});var KGr=s(gk);KXe=r(KGr,"ProphetNetConfig"),KGr.forEach(t),ZXe=r(G4e," (ProphetNet model)"),G4e.forEach(t),eze=i(F),sg=n(F,"LI",{});var O4e=s(sg);DZ=n(O4e,"STRONG",{});var ZGr=s(DZ);oze=r(ZGr,"qdqbert"),ZGr.forEach(t),rze=r(O4e," \u2014 "),hk=n(O4e,"A",{href:!0});var eOr=s(hk);tze=r(eOr,"QDQBertConfig"),eOr.forEach(t),aze=r(O4e," (QDQBert model)"),O4e.forEach(t),nze=i(F),lg=n(F,"LI",{});var V4e=s(lg);GZ=n(V4e,"STRONG",{});var oOr=s(GZ);sze=r(oOr,"rag"),oOr.forEach(t),lze=r(V4e," \u2014 "),pk=n(V4e,"A",{href:!0});var rOr=s(pk);ize=r(rOr,"RagConfig"),rOr.forEach(t),dze=r(V4e," (RAG model)"),V4e.forEach(t),cze=i(F),ig=n(F,"LI",{});var X4e=s(ig);OZ=n(X4e,"STRONG",{});var tOr=s(OZ);fze=r(tOr,"realm"),tOr.forEach(t),mze=r(X4e," \u2014 "),_k=n(X4e,"A",{href:!0});var aOr=s(_k);gze=r(aOr,"RealmConfig"),aOr.forEach(t),hze=r(X4e," (Realm model)"),X4e.forEach(t),pze=i(F),dg=n(F,"LI",{});var z4e=s(dg);VZ=n(z4e,"STRONG",{});var nOr=s(VZ);_ze=r(nOr,"reformer"),nOr.forEach(t),uze=r(z4e," \u2014 "),uk=n(z4e,"A",{href:!0});var sOr=s(uk);bze=r(sOr,"ReformerConfig"),sOr.forEach(t),vze=r(z4e," (Reformer model)"),z4e.forEach(t),Fze=i(F),cg=n(F,"LI",{});var Q4e=s(cg);XZ=n(Q4e,"STRONG",{});var lOr=s(XZ);Tze=r(lOr,"regnet"),lOr.forEach(t),Mze=r(Q4e," \u2014 "),bk=n(Q4e,"A",{href:!0});var iOr=s(bk);Eze=r(iOr,"RegNetConfig"),iOr.forEach(t),Cze=r(Q4e," (RegNet model)"),Q4e.forEach(t),wze=i(F),fg=n(F,"LI",{});var W4e=s(fg);zZ=n(W4e,"STRONG",{});var dOr=s(zZ);Aze=r(dOr,"rembert"),dOr.forEach(t),yze=r(W4e," \u2014 "),vk=n(W4e,"A",{href:!0});var cOr=s(vk);Lze=r(cOr,"RemBertConfig"),cOr.forEach(t),xze=r(W4e," (RemBERT model)"),W4e.forEach(t),kze=i(F),mg=n(F,"LI",{});var H4e=s(mg);QZ=n(H4e,"STRONG",{});var fOr=s(QZ);Sze=r(fOr,"resnet"),fOr.forEach(t),Rze=r(H4e," \u2014 "),Fk=n(H4e,"A",{href:!0});var mOr=s(Fk);Bze=r(mOr,"ResNetConfig"),mOr.forEach(t),Pze=r(H4e," (ResNet model)"),H4e.forEach(t),$ze=i(F),gg=n(F,"LI",{});var U4e=s(gg);WZ=n(U4e,"STRONG",{});var gOr=s(WZ);Ize=r(gOr,"retribert"),gOr.forEach(t),qze=r(U4e," \u2014 "),Tk=n(U4e,"A",{href:!0});var hOr=s(Tk);Nze=r(hOr,"RetriBertConfig"),hOr.forEach(t),jze=r(U4e," (RetriBERT model)"),U4e.forEach(t),Dze=i(F),hg=n(F,"LI",{});var J4e=s(hg);HZ=n(J4e,"STRONG",{});var pOr=s(HZ);Gze=r(pOr,"roberta"),pOr.forEach(t),Oze=r(J4e," \u2014 "),Mk=n(J4e,"A",{href:!0});var _Or=s(Mk);Vze=r(_Or,"RobertaConfig"),_Or.forEach(t),Xze=r(J4e," (RoBERTa model)"),J4e.forEach(t),zze=i(F),pg=n(F,"LI",{});var Y4e=s(pg);UZ=n(Y4e,"STRONG",{});var uOr=s(UZ);Qze=r(uOr,"roformer"),uOr.forEach(t),Wze=r(Y4e," \u2014 "),Ek=n(Y4e,"A",{href:!0});var bOr=s(Ek);Hze=r(bOr,"RoFormerConfig"),bOr.forEach(t),Uze=r(Y4e," (RoFormer model)"),Y4e.forEach(t),Jze=i(F),_g=n(F,"LI",{});var K4e=s(_g);JZ=n(K4e,"STRONG",{});var vOr=s(JZ);Yze=r(vOr,"segformer"),vOr.forEach(t),Kze=r(K4e," \u2014 "),Ck=n(K4e,"A",{href:!0});var FOr=s(Ck);Zze=r(FOr,"SegformerConfig"),FOr.forEach(t),eQe=r(K4e," (SegFormer model)"),K4e.forEach(t),oQe=i(F),ug=n(F,"LI",{});var Z4e=s(ug);YZ=n(Z4e,"STRONG",{});var TOr=s(YZ);rQe=r(TOr,"sew"),TOr.forEach(t),tQe=r(Z4e," \u2014 "),wk=n(Z4e,"A",{href:!0});var MOr=s(wk);aQe=r(MOr,"SEWConfig"),MOr.forEach(t),nQe=r(Z4e," (SEW model)"),Z4e.forEach(t),sQe=i(F),bg=n(F,"LI",{});var eEe=s(bg);KZ=n(eEe,"STRONG",{});var EOr=s(KZ);lQe=r(EOr,"sew-d"),EOr.forEach(t),iQe=r(eEe," \u2014 "),Ak=n(eEe,"A",{href:!0});var COr=s(Ak);dQe=r(COr,"SEWDConfig"),COr.forEach(t),cQe=r(eEe," (SEW-D model)"),eEe.forEach(t),fQe=i(F),vg=n(F,"LI",{});var oEe=s(vg);ZZ=n(oEe,"STRONG",{});var wOr=s(ZZ);mQe=r(wOr,"speech-encoder-decoder"),wOr.forEach(t),gQe=r(oEe," \u2014 "),yk=n(oEe,"A",{href:!0});var AOr=s(yk);hQe=r(AOr,"SpeechEncoderDecoderConfig"),AOr.forEach(t),pQe=r(oEe," (Speech Encoder decoder model)"),oEe.forEach(t),_Qe=i(F),Fg=n(F,"LI",{});var rEe=s(Fg);eee=n(rEe,"STRONG",{});var yOr=s(eee);uQe=r(yOr,"speech_to_text"),yOr.forEach(t),bQe=r(rEe," \u2014 "),Lk=n(rEe,"A",{href:!0});var LOr=s(Lk);vQe=r(LOr,"Speech2TextConfig"),LOr.forEach(t),FQe=r(rEe," (Speech2Text model)"),rEe.forEach(t),TQe=i(F),Tg=n(F,"LI",{});var tEe=s(Tg);oee=n(tEe,"STRONG",{});var xOr=s(oee);MQe=r(xOr,"speech_to_text_2"),xOr.forEach(t),EQe=r(tEe," \u2014 "),xk=n(tEe,"A",{href:!0});var kOr=s(xk);CQe=r(kOr,"Speech2Text2Config"),kOr.forEach(t),wQe=r(tEe," (Speech2Text2 model)"),tEe.forEach(t),AQe=i(F),Mg=n(F,"LI",{});var aEe=s(Mg);ree=n(aEe,"STRONG",{});var SOr=s(ree);yQe=r(SOr,"splinter"),SOr.forEach(t),LQe=r(aEe," \u2014 "),kk=n(aEe,"A",{href:!0});var ROr=s(kk);xQe=r(ROr,"SplinterConfig"),ROr.forEach(t),kQe=r(aEe," (Splinter model)"),aEe.forEach(t),SQe=i(F),Eg=n(F,"LI",{});var nEe=s(Eg);tee=n(nEe,"STRONG",{});var BOr=s(tee);RQe=r(BOr,"squeezebert"),BOr.forEach(t),BQe=r(nEe," \u2014 "),Sk=n(nEe,"A",{href:!0});var POr=s(Sk);PQe=r(POr,"SqueezeBertConfig"),POr.forEach(t),$Qe=r(nEe," (SqueezeBERT model)"),nEe.forEach(t),IQe=i(F),Cg=n(F,"LI",{});var sEe=s(Cg);aee=n(sEe,"STRONG",{});var $Or=s(aee);qQe=r($Or,"swin"),$Or.forEach(t),NQe=r(sEe," \u2014 "),Rk=n(sEe,"A",{href:!0});var IOr=s(Rk);jQe=r(IOr,"SwinConfig"),IOr.forEach(t),DQe=r(sEe," (Swin model)"),sEe.forEach(t),GQe=i(F),wg=n(F,"LI",{});var lEe=s(wg);nee=n(lEe,"STRONG",{});var qOr=s(nee);OQe=r(qOr,"t5"),qOr.forEach(t),VQe=r(lEe," \u2014 "),Bk=n(lEe,"A",{href:!0});var NOr=s(Bk);XQe=r(NOr,"T5Config"),NOr.forEach(t),zQe=r(lEe," (T5 model)"),lEe.forEach(t),QQe=i(F),Ag=n(F,"LI",{});var iEe=s(Ag);see=n(iEe,"STRONG",{});var jOr=s(see);WQe=r(jOr,"tapas"),jOr.forEach(t),HQe=r(iEe," \u2014 "),Pk=n(iEe,"A",{href:!0});var DOr=s(Pk);UQe=r(DOr,"TapasConfig"),DOr.forEach(t),JQe=r(iEe," (TAPAS model)"),iEe.forEach(t),YQe=i(F),yg=n(F,"LI",{});var dEe=s(yg);lee=n(dEe,"STRONG",{});var GOr=s(lee);KQe=r(GOr,"tapex"),GOr.forEach(t),ZQe=r(dEe," \u2014 "),$k=n(dEe,"A",{href:!0});var OOr=s($k);eWe=r(OOr,"BartConfig"),OOr.forEach(t),oWe=r(dEe," (TAPEX model)"),dEe.forEach(t),rWe=i(F),Lg=n(F,"LI",{});var cEe=s(Lg);iee=n(cEe,"STRONG",{});var VOr=s(iee);tWe=r(VOr,"transfo-xl"),VOr.forEach(t),aWe=r(cEe," \u2014 "),Ik=n(cEe,"A",{href:!0});var XOr=s(Ik);nWe=r(XOr,"TransfoXLConfig"),XOr.forEach(t),sWe=r(cEe," (Transformer-XL model)"),cEe.forEach(t),lWe=i(F),xg=n(F,"LI",{});var fEe=s(xg);dee=n(fEe,"STRONG",{});var zOr=s(dee);iWe=r(zOr,"trocr"),zOr.forEach(t),dWe=r(fEe," \u2014 "),qk=n(fEe,"A",{href:!0});var QOr=s(qk);cWe=r(QOr,"TrOCRConfig"),QOr.forEach(t),fWe=r(fEe," (TrOCR model)"),fEe.forEach(t),mWe=i(F),kg=n(F,"LI",{});var mEe=s(kg);cee=n(mEe,"STRONG",{});var WOr=s(cee);gWe=r(WOr,"unispeech"),WOr.forEach(t),hWe=r(mEe," \u2014 "),Nk=n(mEe,"A",{href:!0});var HOr=s(Nk);pWe=r(HOr,"UniSpeechConfig"),HOr.forEach(t),_We=r(mEe," (UniSpeech model)"),mEe.forEach(t),uWe=i(F),Sg=n(F,"LI",{});var gEe=s(Sg);fee=n(gEe,"STRONG",{});var UOr=s(fee);bWe=r(UOr,"unispeech-sat"),UOr.forEach(t),vWe=r(gEe," \u2014 "),jk=n(gEe,"A",{href:!0});var JOr=s(jk);FWe=r(JOr,"UniSpeechSatConfig"),JOr.forEach(t),TWe=r(gEe," (UniSpeechSat model)"),gEe.forEach(t),MWe=i(F),Rg=n(F,"LI",{});var hEe=s(Rg);mee=n(hEe,"STRONG",{});var YOr=s(mee);EWe=r(YOr,"van"),YOr.forEach(t),CWe=r(hEe," \u2014 "),Dk=n(hEe,"A",{href:!0});var KOr=s(Dk);wWe=r(KOr,"VanConfig"),KOr.forEach(t),AWe=r(hEe," (VAN model)"),hEe.forEach(t),yWe=i(F),Bg=n(F,"LI",{});var pEe=s(Bg);gee=n(pEe,"STRONG",{});var ZOr=s(gee);LWe=r(ZOr,"vilt"),ZOr.forEach(t),xWe=r(pEe," \u2014 "),Gk=n(pEe,"A",{href:!0});var eVr=s(Gk);kWe=r(eVr,"ViltConfig"),eVr.forEach(t),SWe=r(pEe," (ViLT model)"),pEe.forEach(t),RWe=i(F),Pg=n(F,"LI",{});var _Ee=s(Pg);hee=n(_Ee,"STRONG",{});var oVr=s(hee);BWe=r(oVr,"vision-encoder-decoder"),oVr.forEach(t),PWe=r(_Ee," \u2014 "),Ok=n(_Ee,"A",{href:!0});var rVr=s(Ok);$We=r(rVr,"VisionEncoderDecoderConfig"),rVr.forEach(t),IWe=r(_Ee," (Vision Encoder decoder model)"),_Ee.forEach(t),qWe=i(F),$g=n(F,"LI",{});var uEe=s($g);pee=n(uEe,"STRONG",{});var tVr=s(pee);NWe=r(tVr,"vision-text-dual-encoder"),tVr.forEach(t),jWe=r(uEe," \u2014 "),Vk=n(uEe,"A",{href:!0});var aVr=s(Vk);DWe=r(aVr,"VisionTextDualEncoderConfig"),aVr.forEach(t),GWe=r(uEe," (VisionTextDualEncoder model)"),uEe.forEach(t),OWe=i(F),Ig=n(F,"LI",{});var bEe=s(Ig);_ee=n(bEe,"STRONG",{});var nVr=s(_ee);VWe=r(nVr,"visual_bert"),nVr.forEach(t),XWe=r(bEe," \u2014 "),Xk=n(bEe,"A",{href:!0});var sVr=s(Xk);zWe=r(sVr,"VisualBertConfig"),sVr.forEach(t),QWe=r(bEe," (VisualBert model)"),bEe.forEach(t),WWe=i(F),qg=n(F,"LI",{});var vEe=s(qg);uee=n(vEe,"STRONG",{});var lVr=s(uee);HWe=r(lVr,"vit"),lVr.forEach(t),UWe=r(vEe," \u2014 "),zk=n(vEe,"A",{href:!0});var iVr=s(zk);JWe=r(iVr,"ViTConfig"),iVr.forEach(t),YWe=r(vEe," (ViT model)"),vEe.forEach(t),KWe=i(F),Ng=n(F,"LI",{});var FEe=s(Ng);bee=n(FEe,"STRONG",{});var dVr=s(bee);ZWe=r(dVr,"vit_mae"),dVr.forEach(t),eHe=r(FEe," \u2014 "),Qk=n(FEe,"A",{href:!0});var cVr=s(Qk);oHe=r(cVr,"ViTMAEConfig"),cVr.forEach(t),rHe=r(FEe," (ViTMAE model)"),FEe.forEach(t),tHe=i(F),jg=n(F,"LI",{});var TEe=s(jg);vee=n(TEe,"STRONG",{});var fVr=s(vee);aHe=r(fVr,"wav2vec2"),fVr.forEach(t),nHe=r(TEe," \u2014 "),Wk=n(TEe,"A",{href:!0});var mVr=s(Wk);sHe=r(mVr,"Wav2Vec2Config"),mVr.forEach(t),lHe=r(TEe," (Wav2Vec2 model)"),TEe.forEach(t),iHe=i(F),Dg=n(F,"LI",{});var MEe=s(Dg);Fee=n(MEe,"STRONG",{});var gVr=s(Fee);dHe=r(gVr,"wavlm"),gVr.forEach(t),cHe=r(MEe," \u2014 "),Hk=n(MEe,"A",{href:!0});var hVr=s(Hk);fHe=r(hVr,"WavLMConfig"),hVr.forEach(t),mHe=r(MEe," (WavLM model)"),MEe.forEach(t),gHe=i(F),Gg=n(F,"LI",{});var EEe=s(Gg);Tee=n(EEe,"STRONG",{});var pVr=s(Tee);hHe=r(pVr,"xglm"),pVr.forEach(t),pHe=r(EEe," \u2014 "),Uk=n(EEe,"A",{href:!0});var _Vr=s(Uk);_He=r(_Vr,"XGLMConfig"),_Vr.forEach(t),uHe=r(EEe," (XGLM model)"),EEe.forEach(t),bHe=i(F),Og=n(F,"LI",{});var CEe=s(Og);Mee=n(CEe,"STRONG",{});var uVr=s(Mee);vHe=r(uVr,"xlm"),uVr.forEach(t),FHe=r(CEe," \u2014 "),Jk=n(CEe,"A",{href:!0});var bVr=s(Jk);THe=r(bVr,"XLMConfig"),bVr.forEach(t),MHe=r(CEe," (XLM model)"),CEe.forEach(t),EHe=i(F),Vg=n(F,"LI",{});var wEe=s(Vg);Eee=n(wEe,"STRONG",{});var vVr=s(Eee);CHe=r(vVr,"xlm-prophetnet"),vVr.forEach(t),wHe=r(wEe," \u2014 "),Yk=n(wEe,"A",{href:!0});var FVr=s(Yk);AHe=r(FVr,"XLMProphetNetConfig"),FVr.forEach(t),yHe=r(wEe," (XLMProphetNet model)"),wEe.forEach(t),LHe=i(F),Xg=n(F,"LI",{});var AEe=s(Xg);Cee=n(AEe,"STRONG",{});var TVr=s(Cee);xHe=r(TVr,"xlm-roberta"),TVr.forEach(t),kHe=r(AEe," \u2014 "),Kk=n(AEe,"A",{href:!0});var MVr=s(Kk);SHe=r(MVr,"XLMRobertaConfig"),MVr.forEach(t),RHe=r(AEe," (XLM-RoBERTa model)"),AEe.forEach(t),BHe=i(F),zg=n(F,"LI",{});var yEe=s(zg);wee=n(yEe,"STRONG",{});var EVr=s(wee);PHe=r(EVr,"xlm-roberta-xl"),EVr.forEach(t),$He=r(yEe," \u2014 "),Zk=n(yEe,"A",{href:!0});var CVr=s(Zk);IHe=r(CVr,"XLMRobertaXLConfig"),CVr.forEach(t),qHe=r(yEe," (XLM-RoBERTa-XL model)"),yEe.forEach(t),NHe=i(F),Qg=n(F,"LI",{});var LEe=s(Qg);Aee=n(LEe,"STRONG",{});var wVr=s(Aee);jHe=r(wVr,"xlnet"),wVr.forEach(t),DHe=r(LEe," \u2014 "),eS=n(LEe,"A",{href:!0});var AVr=s(eS);GHe=r(AVr,"XLNetConfig"),AVr.forEach(t),OHe=r(LEe," (XLNet model)"),LEe.forEach(t),VHe=i(F),Wg=n(F,"LI",{});var xEe=s(Wg);yee=n(xEe,"STRONG",{});var yVr=s(yee);XHe=r(yVr,"yoso"),yVr.forEach(t),zHe=r(xEe," \u2014 "),oS=n(xEe,"A",{href:!0});var LVr=s(oS);QHe=r(LVr,"YosoConfig"),LVr.forEach(t),WHe=r(xEe," (YOSO model)"),xEe.forEach(t),F.forEach(t),HHe=i(ga),Lee=n(ga,"P",{});var xVr=s(Lee);UHe=r(xVr,"Examples:"),xVr.forEach(t),JHe=i(ga),m(c3.$$.fragment,ga),ga.forEach(t),YHe=i(Ks),Hg=n(Ks,"DIV",{class:!0});var GIe=s(Hg);m(f3.$$.fragment,GIe),KHe=i(GIe),xee=n(GIe,"P",{});var kVr=s(xee);ZHe=r(kVr,"Register a new configuration for this class."),kVr.forEach(t),GIe.forEach(t),Ks.forEach(t),jPe=i(c),rd=n(c,"H2",{class:!0});var OIe=s(rd);Ug=n(OIe,"A",{id:!0,class:!0,href:!0});var SVr=s(Ug);kee=n(SVr,"SPAN",{});var RVr=s(kee);m(m3.$$.fragment,RVr),RVr.forEach(t),SVr.forEach(t),eUe=i(OIe),See=n(OIe,"SPAN",{});var BVr=s(See);oUe=r(BVr,"AutoTokenizer"),BVr.forEach(t),OIe.forEach(t),DPe=i(c),Wo=n(c,"DIV",{class:!0});var Zs=s(Wo);m(g3.$$.fragment,Zs),rUe=i(Zs),h3=n(Zs,"P",{});var VIe=s(h3);tUe=r(VIe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),rS=n(VIe,"A",{href:!0});var PVr=s(rS);aUe=r(PVr,"AutoTokenizer.from_pretrained()"),PVr.forEach(t),nUe=r(VIe," class method."),VIe.forEach(t),sUe=i(Zs),p3=n(Zs,"P",{});var XIe=s(p3);lUe=r(XIe,"This class cannot be instantiated directly using "),Ree=n(XIe,"CODE",{});var $Vr=s(Ree);iUe=r($Vr,"__init__()"),$Vr.forEach(t),dUe=r(XIe," (throws an error)."),XIe.forEach(t),cUe=i(Zs),ho=n(Zs,"DIV",{class:!0});var ha=s(ho);m(_3.$$.fragment,ha),fUe=i(ha),Bee=n(ha,"P",{});var IVr=s(Bee);mUe=r(IVr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),IVr.forEach(t),gUe=i(ha),Oa=n(ha,"P",{});var e5=s(Oa);hUe=r(e5,"The tokenizer class to instantiate is selected based on the "),Pee=n(e5,"CODE",{});var qVr=s(Pee);pUe=r(qVr,"model_type"),qVr.forEach(t),_Ue=r(e5,` property of the config object (either
passed as an argument or loaded from `),$ee=n(e5,"CODE",{});var NVr=s($ee);uUe=r(NVr,"pretrained_model_name_or_path"),NVr.forEach(t),bUe=r(e5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Iee=n(e5,"CODE",{});var jVr=s(Iee);vUe=r(jVr,"pretrained_model_name_or_path"),jVr.forEach(t),FUe=r(e5,":"),e5.forEach(t),TUe=i(ha),E=n(ha,"UL",{});var C=s(E);Wn=n(C,"LI",{});var UL=s(Wn);qee=n(UL,"STRONG",{});var DVr=s(qee);MUe=r(DVr,"albert"),DVr.forEach(t),EUe=r(UL," \u2014 "),tS=n(UL,"A",{href:!0});var GVr=s(tS);CUe=r(GVr,"AlbertTokenizer"),GVr.forEach(t),wUe=r(UL," or "),aS=n(UL,"A",{href:!0});var OVr=s(aS);AUe=r(OVr,"AlbertTokenizerFast"),OVr.forEach(t),yUe=r(UL," (ALBERT model)"),UL.forEach(t),LUe=i(C),Hn=n(C,"LI",{});var JL=s(Hn);Nee=n(JL,"STRONG",{});var VVr=s(Nee);xUe=r(VVr,"bart"),VVr.forEach(t),kUe=r(JL," \u2014 "),nS=n(JL,"A",{href:!0});var XVr=s(nS);SUe=r(XVr,"BartTokenizer"),XVr.forEach(t),RUe=r(JL," or "),sS=n(JL,"A",{href:!0});var zVr=s(sS);BUe=r(zVr,"BartTokenizerFast"),zVr.forEach(t),PUe=r(JL," (BART model)"),JL.forEach(t),$Ue=i(C),Un=n(C,"LI",{});var YL=s(Un);jee=n(YL,"STRONG",{});var QVr=s(jee);IUe=r(QVr,"barthez"),QVr.forEach(t),qUe=r(YL," \u2014 "),lS=n(YL,"A",{href:!0});var WVr=s(lS);NUe=r(WVr,"BarthezTokenizer"),WVr.forEach(t),jUe=r(YL," or "),iS=n(YL,"A",{href:!0});var HVr=s(iS);DUe=r(HVr,"BarthezTokenizerFast"),HVr.forEach(t),GUe=r(YL," (BARThez model)"),YL.forEach(t),OUe=i(C),Jg=n(C,"LI",{});var kEe=s(Jg);Dee=n(kEe,"STRONG",{});var UVr=s(Dee);VUe=r(UVr,"bartpho"),UVr.forEach(t),XUe=r(kEe," \u2014 "),dS=n(kEe,"A",{href:!0});var JVr=s(dS);zUe=r(JVr,"BartphoTokenizer"),JVr.forEach(t),QUe=r(kEe," (BARTpho model)"),kEe.forEach(t),WUe=i(C),Jn=n(C,"LI",{});var KL=s(Jn);Gee=n(KL,"STRONG",{});var YVr=s(Gee);HUe=r(YVr,"bert"),YVr.forEach(t),UUe=r(KL," \u2014 "),cS=n(KL,"A",{href:!0});var KVr=s(cS);JUe=r(KVr,"BertTokenizer"),KVr.forEach(t),YUe=r(KL," or "),fS=n(KL,"A",{href:!0});var ZVr=s(fS);KUe=r(ZVr,"BertTokenizerFast"),ZVr.forEach(t),ZUe=r(KL," (BERT model)"),KL.forEach(t),eJe=i(C),Yg=n(C,"LI",{});var SEe=s(Yg);Oee=n(SEe,"STRONG",{});var eXr=s(Oee);oJe=r(eXr,"bert-generation"),eXr.forEach(t),rJe=r(SEe," \u2014 "),mS=n(SEe,"A",{href:!0});var oXr=s(mS);tJe=r(oXr,"BertGenerationTokenizer"),oXr.forEach(t),aJe=r(SEe," (Bert Generation model)"),SEe.forEach(t),nJe=i(C),Kg=n(C,"LI",{});var REe=s(Kg);Vee=n(REe,"STRONG",{});var rXr=s(Vee);sJe=r(rXr,"bert-japanese"),rXr.forEach(t),lJe=r(REe," \u2014 "),gS=n(REe,"A",{href:!0});var tXr=s(gS);iJe=r(tXr,"BertJapaneseTokenizer"),tXr.forEach(t),dJe=r(REe," (BertJapanese model)"),REe.forEach(t),cJe=i(C),Zg=n(C,"LI",{});var BEe=s(Zg);Xee=n(BEe,"STRONG",{});var aXr=s(Xee);fJe=r(aXr,"bertweet"),aXr.forEach(t),mJe=r(BEe," \u2014 "),hS=n(BEe,"A",{href:!0});var nXr=s(hS);gJe=r(nXr,"BertweetTokenizer"),nXr.forEach(t),hJe=r(BEe," (Bertweet model)"),BEe.forEach(t),pJe=i(C),Yn=n(C,"LI",{});var ZL=s(Yn);zee=n(ZL,"STRONG",{});var sXr=s(zee);_Je=r(sXr,"big_bird"),sXr.forEach(t),uJe=r(ZL," \u2014 "),pS=n(ZL,"A",{href:!0});var lXr=s(pS);bJe=r(lXr,"BigBirdTokenizer"),lXr.forEach(t),vJe=r(ZL," or "),_S=n(ZL,"A",{href:!0});var iXr=s(_S);FJe=r(iXr,"BigBirdTokenizerFast"),iXr.forEach(t),TJe=r(ZL," (BigBird model)"),ZL.forEach(t),MJe=i(C),Kn=n(C,"LI",{});var e8=s(Kn);Qee=n(e8,"STRONG",{});var dXr=s(Qee);EJe=r(dXr,"bigbird_pegasus"),dXr.forEach(t),CJe=r(e8," \u2014 "),uS=n(e8,"A",{href:!0});var cXr=s(uS);wJe=r(cXr,"PegasusTokenizer"),cXr.forEach(t),AJe=r(e8," or "),bS=n(e8,"A",{href:!0});var fXr=s(bS);yJe=r(fXr,"PegasusTokenizerFast"),fXr.forEach(t),LJe=r(e8," (BigBirdPegasus model)"),e8.forEach(t),xJe=i(C),Zn=n(C,"LI",{});var o8=s(Zn);Wee=n(o8,"STRONG",{});var mXr=s(Wee);kJe=r(mXr,"blenderbot"),mXr.forEach(t),SJe=r(o8," \u2014 "),vS=n(o8,"A",{href:!0});var gXr=s(vS);RJe=r(gXr,"BlenderbotTokenizer"),gXr.forEach(t),BJe=r(o8," or "),FS=n(o8,"A",{href:!0});var hXr=s(FS);PJe=r(hXr,"BlenderbotTokenizerFast"),hXr.forEach(t),$Je=r(o8," (Blenderbot model)"),o8.forEach(t),IJe=i(C),eh=n(C,"LI",{});var PEe=s(eh);Hee=n(PEe,"STRONG",{});var pXr=s(Hee);qJe=r(pXr,"blenderbot-small"),pXr.forEach(t),NJe=r(PEe," \u2014 "),TS=n(PEe,"A",{href:!0});var _Xr=s(TS);jJe=r(_Xr,"BlenderbotSmallTokenizer"),_Xr.forEach(t),DJe=r(PEe," (BlenderbotSmall model)"),PEe.forEach(t),GJe=i(C),oh=n(C,"LI",{});var $Ee=s(oh);Uee=n($Ee,"STRONG",{});var uXr=s(Uee);OJe=r(uXr,"byt5"),uXr.forEach(t),VJe=r($Ee," \u2014 "),MS=n($Ee,"A",{href:!0});var bXr=s(MS);XJe=r(bXr,"ByT5Tokenizer"),bXr.forEach(t),zJe=r($Ee," (ByT5 model)"),$Ee.forEach(t),QJe=i(C),es=n(C,"LI",{});var r8=s(es);Jee=n(r8,"STRONG",{});var vXr=s(Jee);WJe=r(vXr,"camembert"),vXr.forEach(t),HJe=r(r8," \u2014 "),ES=n(r8,"A",{href:!0});var FXr=s(ES);UJe=r(FXr,"CamembertTokenizer"),FXr.forEach(t),JJe=r(r8," or "),CS=n(r8,"A",{href:!0});var TXr=s(CS);YJe=r(TXr,"CamembertTokenizerFast"),TXr.forEach(t),KJe=r(r8," (CamemBERT model)"),r8.forEach(t),ZJe=i(C),rh=n(C,"LI",{});var IEe=s(rh);Yee=n(IEe,"STRONG",{});var MXr=s(Yee);eYe=r(MXr,"canine"),MXr.forEach(t),oYe=r(IEe," \u2014 "),wS=n(IEe,"A",{href:!0});var EXr=s(wS);rYe=r(EXr,"CanineTokenizer"),EXr.forEach(t),tYe=r(IEe," (Canine model)"),IEe.forEach(t),aYe=i(C),os=n(C,"LI",{});var t8=s(os);Kee=n(t8,"STRONG",{});var CXr=s(Kee);nYe=r(CXr,"clip"),CXr.forEach(t),sYe=r(t8," \u2014 "),AS=n(t8,"A",{href:!0});var wXr=s(AS);lYe=r(wXr,"CLIPTokenizer"),wXr.forEach(t),iYe=r(t8," or "),yS=n(t8,"A",{href:!0});var AXr=s(yS);dYe=r(AXr,"CLIPTokenizerFast"),AXr.forEach(t),cYe=r(t8," (CLIP model)"),t8.forEach(t),fYe=i(C),rs=n(C,"LI",{});var a8=s(rs);Zee=n(a8,"STRONG",{});var yXr=s(Zee);mYe=r(yXr,"convbert"),yXr.forEach(t),gYe=r(a8," \u2014 "),LS=n(a8,"A",{href:!0});var LXr=s(LS);hYe=r(LXr,"ConvBertTokenizer"),LXr.forEach(t),pYe=r(a8," or "),xS=n(a8,"A",{href:!0});var xXr=s(xS);_Ye=r(xXr,"ConvBertTokenizerFast"),xXr.forEach(t),uYe=r(a8," (ConvBERT model)"),a8.forEach(t),bYe=i(C),ts=n(C,"LI",{});var n8=s(ts);eoe=n(n8,"STRONG",{});var kXr=s(eoe);vYe=r(kXr,"cpm"),kXr.forEach(t),FYe=r(n8," \u2014 "),kS=n(n8,"A",{href:!0});var SXr=s(kS);TYe=r(SXr,"CpmTokenizer"),SXr.forEach(t),MYe=r(n8," or "),ooe=n(n8,"CODE",{});var RXr=s(ooe);EYe=r(RXr,"CpmTokenizerFast"),RXr.forEach(t),CYe=r(n8," (CPM model)"),n8.forEach(t),wYe=i(C),th=n(C,"LI",{});var qEe=s(th);roe=n(qEe,"STRONG",{});var BXr=s(roe);AYe=r(BXr,"ctrl"),BXr.forEach(t),yYe=r(qEe," \u2014 "),SS=n(qEe,"A",{href:!0});var PXr=s(SS);LYe=r(PXr,"CTRLTokenizer"),PXr.forEach(t),xYe=r(qEe," (CTRL model)"),qEe.forEach(t),kYe=i(C),as=n(C,"LI",{});var s8=s(as);toe=n(s8,"STRONG",{});var $Xr=s(toe);SYe=r($Xr,"data2vec-text"),$Xr.forEach(t),RYe=r(s8," \u2014 "),RS=n(s8,"A",{href:!0});var IXr=s(RS);BYe=r(IXr,"RobertaTokenizer"),IXr.forEach(t),PYe=r(s8," or "),BS=n(s8,"A",{href:!0});var qXr=s(BS);$Ye=r(qXr,"RobertaTokenizerFast"),qXr.forEach(t),IYe=r(s8," (Data2VecText model)"),s8.forEach(t),qYe=i(C),ns=n(C,"LI",{});var l8=s(ns);aoe=n(l8,"STRONG",{});var NXr=s(aoe);NYe=r(NXr,"deberta"),NXr.forEach(t),jYe=r(l8," \u2014 "),PS=n(l8,"A",{href:!0});var jXr=s(PS);DYe=r(jXr,"DebertaTokenizer"),jXr.forEach(t),GYe=r(l8," or "),$S=n(l8,"A",{href:!0});var DXr=s($S);OYe=r(DXr,"DebertaTokenizerFast"),DXr.forEach(t),VYe=r(l8," (DeBERTa model)"),l8.forEach(t),XYe=i(C),ss=n(C,"LI",{});var i8=s(ss);noe=n(i8,"STRONG",{});var GXr=s(noe);zYe=r(GXr,"deberta-v2"),GXr.forEach(t),QYe=r(i8," \u2014 "),IS=n(i8,"A",{href:!0});var OXr=s(IS);WYe=r(OXr,"DebertaV2Tokenizer"),OXr.forEach(t),HYe=r(i8," or "),qS=n(i8,"A",{href:!0});var VXr=s(qS);UYe=r(VXr,"DebertaV2TokenizerFast"),VXr.forEach(t),JYe=r(i8," (DeBERTa-v2 model)"),i8.forEach(t),YYe=i(C),ls=n(C,"LI",{});var d8=s(ls);soe=n(d8,"STRONG",{});var XXr=s(soe);KYe=r(XXr,"distilbert"),XXr.forEach(t),ZYe=r(d8," \u2014 "),NS=n(d8,"A",{href:!0});var zXr=s(NS);eKe=r(zXr,"DistilBertTokenizer"),zXr.forEach(t),oKe=r(d8," or "),jS=n(d8,"A",{href:!0});var QXr=s(jS);rKe=r(QXr,"DistilBertTokenizerFast"),QXr.forEach(t),tKe=r(d8," (DistilBERT model)"),d8.forEach(t),aKe=i(C),is=n(C,"LI",{});var c8=s(is);loe=n(c8,"STRONG",{});var WXr=s(loe);nKe=r(WXr,"dpr"),WXr.forEach(t),sKe=r(c8," \u2014 "),DS=n(c8,"A",{href:!0});var HXr=s(DS);lKe=r(HXr,"DPRQuestionEncoderTokenizer"),HXr.forEach(t),iKe=r(c8," or "),GS=n(c8,"A",{href:!0});var UXr=s(GS);dKe=r(UXr,"DPRQuestionEncoderTokenizerFast"),UXr.forEach(t),cKe=r(c8," (DPR model)"),c8.forEach(t),fKe=i(C),ds=n(C,"LI",{});var f8=s(ds);ioe=n(f8,"STRONG",{});var JXr=s(ioe);mKe=r(JXr,"electra"),JXr.forEach(t),gKe=r(f8," \u2014 "),OS=n(f8,"A",{href:!0});var YXr=s(OS);hKe=r(YXr,"ElectraTokenizer"),YXr.forEach(t),pKe=r(f8," or "),VS=n(f8,"A",{href:!0});var KXr=s(VS);_Ke=r(KXr,"ElectraTokenizerFast"),KXr.forEach(t),uKe=r(f8," (ELECTRA model)"),f8.forEach(t),bKe=i(C),ah=n(C,"LI",{});var NEe=s(ah);doe=n(NEe,"STRONG",{});var ZXr=s(doe);vKe=r(ZXr,"flaubert"),ZXr.forEach(t),FKe=r(NEe," \u2014 "),XS=n(NEe,"A",{href:!0});var ezr=s(XS);TKe=r(ezr,"FlaubertTokenizer"),ezr.forEach(t),MKe=r(NEe," (FlauBERT model)"),NEe.forEach(t),EKe=i(C),cs=n(C,"LI",{});var m8=s(cs);coe=n(m8,"STRONG",{});var ozr=s(coe);CKe=r(ozr,"fnet"),ozr.forEach(t),wKe=r(m8," \u2014 "),zS=n(m8,"A",{href:!0});var rzr=s(zS);AKe=r(rzr,"FNetTokenizer"),rzr.forEach(t),yKe=r(m8," or "),QS=n(m8,"A",{href:!0});var tzr=s(QS);LKe=r(tzr,"FNetTokenizerFast"),tzr.forEach(t),xKe=r(m8," (FNet model)"),m8.forEach(t),kKe=i(C),nh=n(C,"LI",{});var jEe=s(nh);foe=n(jEe,"STRONG",{});var azr=s(foe);SKe=r(azr,"fsmt"),azr.forEach(t),RKe=r(jEe," \u2014 "),WS=n(jEe,"A",{href:!0});var nzr=s(WS);BKe=r(nzr,"FSMTTokenizer"),nzr.forEach(t),PKe=r(jEe," (FairSeq Machine-Translation model)"),jEe.forEach(t),$Ke=i(C),fs=n(C,"LI",{});var g8=s(fs);moe=n(g8,"STRONG",{});var szr=s(moe);IKe=r(szr,"funnel"),szr.forEach(t),qKe=r(g8," \u2014 "),HS=n(g8,"A",{href:!0});var lzr=s(HS);NKe=r(lzr,"FunnelTokenizer"),lzr.forEach(t),jKe=r(g8," or "),US=n(g8,"A",{href:!0});var izr=s(US);DKe=r(izr,"FunnelTokenizerFast"),izr.forEach(t),GKe=r(g8," (Funnel Transformer model)"),g8.forEach(t),OKe=i(C),ms=n(C,"LI",{});var h8=s(ms);goe=n(h8,"STRONG",{});var dzr=s(goe);VKe=r(dzr,"gpt2"),dzr.forEach(t),XKe=r(h8," \u2014 "),JS=n(h8,"A",{href:!0});var czr=s(JS);zKe=r(czr,"GPT2Tokenizer"),czr.forEach(t),QKe=r(h8," or "),YS=n(h8,"A",{href:!0});var fzr=s(YS);WKe=r(fzr,"GPT2TokenizerFast"),fzr.forEach(t),HKe=r(h8," (OpenAI GPT-2 model)"),h8.forEach(t),UKe=i(C),gs=n(C,"LI",{});var p8=s(gs);hoe=n(p8,"STRONG",{});var mzr=s(hoe);JKe=r(mzr,"gpt_neo"),mzr.forEach(t),YKe=r(p8," \u2014 "),KS=n(p8,"A",{href:!0});var gzr=s(KS);KKe=r(gzr,"GPT2Tokenizer"),gzr.forEach(t),ZKe=r(p8," or "),ZS=n(p8,"A",{href:!0});var hzr=s(ZS);eZe=r(hzr,"GPT2TokenizerFast"),hzr.forEach(t),oZe=r(p8," (GPT Neo model)"),p8.forEach(t),rZe=i(C),hs=n(C,"LI",{});var _8=s(hs);poe=n(_8,"STRONG",{});var pzr=s(poe);tZe=r(pzr,"gptj"),pzr.forEach(t),aZe=r(_8," \u2014 "),eR=n(_8,"A",{href:!0});var _zr=s(eR);nZe=r(_zr,"GPT2Tokenizer"),_zr.forEach(t),sZe=r(_8," or "),oR=n(_8,"A",{href:!0});var uzr=s(oR);lZe=r(uzr,"GPT2TokenizerFast"),uzr.forEach(t),iZe=r(_8," (GPT-J model)"),_8.forEach(t),dZe=i(C),ps=n(C,"LI",{});var u8=s(ps);_oe=n(u8,"STRONG",{});var bzr=s(_oe);cZe=r(bzr,"herbert"),bzr.forEach(t),fZe=r(u8," \u2014 "),rR=n(u8,"A",{href:!0});var vzr=s(rR);mZe=r(vzr,"HerbertTokenizer"),vzr.forEach(t),gZe=r(u8," or "),tR=n(u8,"A",{href:!0});var Fzr=s(tR);hZe=r(Fzr,"HerbertTokenizerFast"),Fzr.forEach(t),pZe=r(u8," (HerBERT model)"),u8.forEach(t),_Ze=i(C),sh=n(C,"LI",{});var DEe=s(sh);uoe=n(DEe,"STRONG",{});var Tzr=s(uoe);uZe=r(Tzr,"hubert"),Tzr.forEach(t),bZe=r(DEe," \u2014 "),aR=n(DEe,"A",{href:!0});var Mzr=s(aR);vZe=r(Mzr,"Wav2Vec2CTCTokenizer"),Mzr.forEach(t),FZe=r(DEe," (Hubert model)"),DEe.forEach(t),TZe=i(C),_s=n(C,"LI",{});var b8=s(_s);boe=n(b8,"STRONG",{});var Ezr=s(boe);MZe=r(Ezr,"ibert"),Ezr.forEach(t),EZe=r(b8," \u2014 "),nR=n(b8,"A",{href:!0});var Czr=s(nR);CZe=r(Czr,"RobertaTokenizer"),Czr.forEach(t),wZe=r(b8," or "),sR=n(b8,"A",{href:!0});var wzr=s(sR);AZe=r(wzr,"RobertaTokenizerFast"),wzr.forEach(t),yZe=r(b8," (I-BERT model)"),b8.forEach(t),LZe=i(C),us=n(C,"LI",{});var v8=s(us);voe=n(v8,"STRONG",{});var Azr=s(voe);xZe=r(Azr,"layoutlm"),Azr.forEach(t),kZe=r(v8," \u2014 "),lR=n(v8,"A",{href:!0});var yzr=s(lR);SZe=r(yzr,"LayoutLMTokenizer"),yzr.forEach(t),RZe=r(v8," or "),iR=n(v8,"A",{href:!0});var Lzr=s(iR);BZe=r(Lzr,"LayoutLMTokenizerFast"),Lzr.forEach(t),PZe=r(v8," (LayoutLM model)"),v8.forEach(t),$Ze=i(C),bs=n(C,"LI",{});var F8=s(bs);Foe=n(F8,"STRONG",{});var xzr=s(Foe);IZe=r(xzr,"layoutlmv2"),xzr.forEach(t),qZe=r(F8," \u2014 "),dR=n(F8,"A",{href:!0});var kzr=s(dR);NZe=r(kzr,"LayoutLMv2Tokenizer"),kzr.forEach(t),jZe=r(F8," or "),cR=n(F8,"A",{href:!0});var Szr=s(cR);DZe=r(Szr,"LayoutLMv2TokenizerFast"),Szr.forEach(t),GZe=r(F8," (LayoutLMv2 model)"),F8.forEach(t),OZe=i(C),vs=n(C,"LI",{});var T8=s(vs);Toe=n(T8,"STRONG",{});var Rzr=s(Toe);VZe=r(Rzr,"layoutxlm"),Rzr.forEach(t),XZe=r(T8," \u2014 "),fR=n(T8,"A",{href:!0});var Bzr=s(fR);zZe=r(Bzr,"LayoutXLMTokenizer"),Bzr.forEach(t),QZe=r(T8," or "),mR=n(T8,"A",{href:!0});var Pzr=s(mR);WZe=r(Pzr,"LayoutXLMTokenizerFast"),Pzr.forEach(t),HZe=r(T8," (LayoutXLM model)"),T8.forEach(t),UZe=i(C),Fs=n(C,"LI",{});var M8=s(Fs);Moe=n(M8,"STRONG",{});var $zr=s(Moe);JZe=r($zr,"led"),$zr.forEach(t),YZe=r(M8," \u2014 "),gR=n(M8,"A",{href:!0});var Izr=s(gR);KZe=r(Izr,"LEDTokenizer"),Izr.forEach(t),ZZe=r(M8," or "),hR=n(M8,"A",{href:!0});var qzr=s(hR);eeo=r(qzr,"LEDTokenizerFast"),qzr.forEach(t),oeo=r(M8," (LED model)"),M8.forEach(t),reo=i(C),Ts=n(C,"LI",{});var E8=s(Ts);Eoe=n(E8,"STRONG",{});var Nzr=s(Eoe);teo=r(Nzr,"longformer"),Nzr.forEach(t),aeo=r(E8," \u2014 "),pR=n(E8,"A",{href:!0});var jzr=s(pR);neo=r(jzr,"LongformerTokenizer"),jzr.forEach(t),seo=r(E8," or "),_R=n(E8,"A",{href:!0});var Dzr=s(_R);leo=r(Dzr,"LongformerTokenizerFast"),Dzr.forEach(t),ieo=r(E8," (Longformer model)"),E8.forEach(t),deo=i(C),Ms=n(C,"LI",{});var C8=s(Ms);Coe=n(C8,"STRONG",{});var Gzr=s(Coe);ceo=r(Gzr,"longt5"),Gzr.forEach(t),feo=r(C8," \u2014 "),uR=n(C8,"A",{href:!0});var Ozr=s(uR);meo=r(Ozr,"T5Tokenizer"),Ozr.forEach(t),geo=r(C8," or "),bR=n(C8,"A",{href:!0});var Vzr=s(bR);heo=r(Vzr,"T5TokenizerFast"),Vzr.forEach(t),peo=r(C8," (LongT5 model)"),C8.forEach(t),_eo=i(C),lh=n(C,"LI",{});var GEe=s(lh);woe=n(GEe,"STRONG",{});var Xzr=s(woe);ueo=r(Xzr,"luke"),Xzr.forEach(t),beo=r(GEe," \u2014 "),vR=n(GEe,"A",{href:!0});var zzr=s(vR);veo=r(zzr,"LukeTokenizer"),zzr.forEach(t),Feo=r(GEe," (LUKE model)"),GEe.forEach(t),Teo=i(C),Es=n(C,"LI",{});var w8=s(Es);Aoe=n(w8,"STRONG",{});var Qzr=s(Aoe);Meo=r(Qzr,"lxmert"),Qzr.forEach(t),Eeo=r(w8," \u2014 "),FR=n(w8,"A",{href:!0});var Wzr=s(FR);Ceo=r(Wzr,"LxmertTokenizer"),Wzr.forEach(t),weo=r(w8," or "),TR=n(w8,"A",{href:!0});var Hzr=s(TR);Aeo=r(Hzr,"LxmertTokenizerFast"),Hzr.forEach(t),yeo=r(w8," (LXMERT model)"),w8.forEach(t),Leo=i(C),ih=n(C,"LI",{});var OEe=s(ih);yoe=n(OEe,"STRONG",{});var Uzr=s(yoe);xeo=r(Uzr,"m2m_100"),Uzr.forEach(t),keo=r(OEe," \u2014 "),MR=n(OEe,"A",{href:!0});var Jzr=s(MR);Seo=r(Jzr,"M2M100Tokenizer"),Jzr.forEach(t),Reo=r(OEe," (M2M100 model)"),OEe.forEach(t),Beo=i(C),dh=n(C,"LI",{});var VEe=s(dh);Loe=n(VEe,"STRONG",{});var Yzr=s(Loe);Peo=r(Yzr,"marian"),Yzr.forEach(t),$eo=r(VEe," \u2014 "),ER=n(VEe,"A",{href:!0});var Kzr=s(ER);Ieo=r(Kzr,"MarianTokenizer"),Kzr.forEach(t),qeo=r(VEe," (Marian model)"),VEe.forEach(t),Neo=i(C),Cs=n(C,"LI",{});var A8=s(Cs);xoe=n(A8,"STRONG",{});var Zzr=s(xoe);jeo=r(Zzr,"mbart"),Zzr.forEach(t),Deo=r(A8," \u2014 "),CR=n(A8,"A",{href:!0});var eQr=s(CR);Geo=r(eQr,"MBartTokenizer"),eQr.forEach(t),Oeo=r(A8," or "),wR=n(A8,"A",{href:!0});var oQr=s(wR);Veo=r(oQr,"MBartTokenizerFast"),oQr.forEach(t),Xeo=r(A8," (mBART model)"),A8.forEach(t),zeo=i(C),ws=n(C,"LI",{});var y8=s(ws);koe=n(y8,"STRONG",{});var rQr=s(koe);Qeo=r(rQr,"mbart50"),rQr.forEach(t),Weo=r(y8," \u2014 "),AR=n(y8,"A",{href:!0});var tQr=s(AR);Heo=r(tQr,"MBart50Tokenizer"),tQr.forEach(t),Ueo=r(y8," or "),yR=n(y8,"A",{href:!0});var aQr=s(yR);Jeo=r(aQr,"MBart50TokenizerFast"),aQr.forEach(t),Yeo=r(y8," (mBART-50 model)"),y8.forEach(t),Keo=i(C),As=n(C,"LI",{});var L8=s(As);Soe=n(L8,"STRONG",{});var nQr=s(Soe);Zeo=r(nQr,"megatron-bert"),nQr.forEach(t),eoo=r(L8," \u2014 "),LR=n(L8,"A",{href:!0});var sQr=s(LR);ooo=r(sQr,"BertTokenizer"),sQr.forEach(t),roo=r(L8," or "),xR=n(L8,"A",{href:!0});var lQr=s(xR);too=r(lQr,"BertTokenizerFast"),lQr.forEach(t),aoo=r(L8," (MegatronBert model)"),L8.forEach(t),noo=i(C),ch=n(C,"LI",{});var XEe=s(ch);Roe=n(XEe,"STRONG",{});var iQr=s(Roe);soo=r(iQr,"mluke"),iQr.forEach(t),loo=r(XEe," \u2014 "),kR=n(XEe,"A",{href:!0});var dQr=s(kR);ioo=r(dQr,"MLukeTokenizer"),dQr.forEach(t),doo=r(XEe," (mLUKE model)"),XEe.forEach(t),coo=i(C),ys=n(C,"LI",{});var x8=s(ys);Boe=n(x8,"STRONG",{});var cQr=s(Boe);foo=r(cQr,"mobilebert"),cQr.forEach(t),moo=r(x8," \u2014 "),SR=n(x8,"A",{href:!0});var fQr=s(SR);goo=r(fQr,"MobileBertTokenizer"),fQr.forEach(t),hoo=r(x8," or "),RR=n(x8,"A",{href:!0});var mQr=s(RR);poo=r(mQr,"MobileBertTokenizerFast"),mQr.forEach(t),_oo=r(x8," (MobileBERT model)"),x8.forEach(t),uoo=i(C),Ls=n(C,"LI",{});var k8=s(Ls);Poe=n(k8,"STRONG",{});var gQr=s(Poe);boo=r(gQr,"mpnet"),gQr.forEach(t),voo=r(k8," \u2014 "),BR=n(k8,"A",{href:!0});var hQr=s(BR);Foo=r(hQr,"MPNetTokenizer"),hQr.forEach(t),Too=r(k8," or "),PR=n(k8,"A",{href:!0});var pQr=s(PR);Moo=r(pQr,"MPNetTokenizerFast"),pQr.forEach(t),Eoo=r(k8," (MPNet model)"),k8.forEach(t),Coo=i(C),xs=n(C,"LI",{});var S8=s(xs);$oe=n(S8,"STRONG",{});var _Qr=s($oe);woo=r(_Qr,"mt5"),_Qr.forEach(t),Aoo=r(S8," \u2014 "),$R=n(S8,"A",{href:!0});var uQr=s($R);yoo=r(uQr,"MT5Tokenizer"),uQr.forEach(t),Loo=r(S8," or "),IR=n(S8,"A",{href:!0});var bQr=s(IR);xoo=r(bQr,"MT5TokenizerFast"),bQr.forEach(t),koo=r(S8," (mT5 model)"),S8.forEach(t),Soo=i(C),ks=n(C,"LI",{});var R8=s(ks);Ioe=n(R8,"STRONG",{});var vQr=s(Ioe);Roo=r(vQr,"nystromformer"),vQr.forEach(t),Boo=r(R8," \u2014 "),qR=n(R8,"A",{href:!0});var FQr=s(qR);Poo=r(FQr,"AlbertTokenizer"),FQr.forEach(t),$oo=r(R8," or "),NR=n(R8,"A",{href:!0});var TQr=s(NR);Ioo=r(TQr,"AlbertTokenizerFast"),TQr.forEach(t),qoo=r(R8," (Nystromformer model)"),R8.forEach(t),Noo=i(C),Ss=n(C,"LI",{});var B8=s(Ss);qoe=n(B8,"STRONG",{});var MQr=s(qoe);joo=r(MQr,"openai-gpt"),MQr.forEach(t),Doo=r(B8," \u2014 "),jR=n(B8,"A",{href:!0});var EQr=s(jR);Goo=r(EQr,"OpenAIGPTTokenizer"),EQr.forEach(t),Ooo=r(B8," or "),DR=n(B8,"A",{href:!0});var CQr=s(DR);Voo=r(CQr,"OpenAIGPTTokenizerFast"),CQr.forEach(t),Xoo=r(B8," (OpenAI GPT model)"),B8.forEach(t),zoo=i(C),Rs=n(C,"LI",{});var P8=s(Rs);Noe=n(P8,"STRONG",{});var wQr=s(Noe);Qoo=r(wQr,"pegasus"),wQr.forEach(t),Woo=r(P8," \u2014 "),GR=n(P8,"A",{href:!0});var AQr=s(GR);Hoo=r(AQr,"PegasusTokenizer"),AQr.forEach(t),Uoo=r(P8," or "),OR=n(P8,"A",{href:!0});var yQr=s(OR);Joo=r(yQr,"PegasusTokenizerFast"),yQr.forEach(t),Yoo=r(P8," (Pegasus model)"),P8.forEach(t),Koo=i(C),fh=n(C,"LI",{});var zEe=s(fh);joe=n(zEe,"STRONG",{});var LQr=s(joe);Zoo=r(LQr,"perceiver"),LQr.forEach(t),ero=r(zEe," \u2014 "),VR=n(zEe,"A",{href:!0});var xQr=s(VR);oro=r(xQr,"PerceiverTokenizer"),xQr.forEach(t),rro=r(zEe," (Perceiver model)"),zEe.forEach(t),tro=i(C),mh=n(C,"LI",{});var QEe=s(mh);Doe=n(QEe,"STRONG",{});var kQr=s(Doe);aro=r(kQr,"phobert"),kQr.forEach(t),nro=r(QEe," \u2014 "),XR=n(QEe,"A",{href:!0});var SQr=s(XR);sro=r(SQr,"PhobertTokenizer"),SQr.forEach(t),lro=r(QEe," (PhoBERT model)"),QEe.forEach(t),iro=i(C),gh=n(C,"LI",{});var WEe=s(gh);Goe=n(WEe,"STRONG",{});var RQr=s(Goe);dro=r(RQr,"plbart"),RQr.forEach(t),cro=r(WEe," \u2014 "),zR=n(WEe,"A",{href:!0});var BQr=s(zR);fro=r(BQr,"PLBartTokenizer"),BQr.forEach(t),mro=r(WEe," (PLBart model)"),WEe.forEach(t),gro=i(C),hh=n(C,"LI",{});var HEe=s(hh);Ooe=n(HEe,"STRONG",{});var PQr=s(Ooe);hro=r(PQr,"prophetnet"),PQr.forEach(t),pro=r(HEe," \u2014 "),QR=n(HEe,"A",{href:!0});var $Qr=s(QR);_ro=r($Qr,"ProphetNetTokenizer"),$Qr.forEach(t),uro=r(HEe," (ProphetNet model)"),HEe.forEach(t),bro=i(C),Bs=n(C,"LI",{});var $8=s(Bs);Voe=n($8,"STRONG",{});var IQr=s(Voe);vro=r(IQr,"qdqbert"),IQr.forEach(t),Fro=r($8," \u2014 "),WR=n($8,"A",{href:!0});var qQr=s(WR);Tro=r(qQr,"BertTokenizer"),qQr.forEach(t),Mro=r($8," or "),HR=n($8,"A",{href:!0});var NQr=s(HR);Ero=r(NQr,"BertTokenizerFast"),NQr.forEach(t),Cro=r($8," (QDQBert model)"),$8.forEach(t),wro=i(C),ph=n(C,"LI",{});var UEe=s(ph);Xoe=n(UEe,"STRONG",{});var jQr=s(Xoe);Aro=r(jQr,"rag"),jQr.forEach(t),yro=r(UEe," \u2014 "),UR=n(UEe,"A",{href:!0});var DQr=s(UR);Lro=r(DQr,"RagTokenizer"),DQr.forEach(t),xro=r(UEe," (RAG model)"),UEe.forEach(t),kro=i(C),Ps=n(C,"LI",{});var I8=s(Ps);zoe=n(I8,"STRONG",{});var GQr=s(zoe);Sro=r(GQr,"realm"),GQr.forEach(t),Rro=r(I8," \u2014 "),JR=n(I8,"A",{href:!0});var OQr=s(JR);Bro=r(OQr,"RealmTokenizer"),OQr.forEach(t),Pro=r(I8," or "),YR=n(I8,"A",{href:!0});var VQr=s(YR);$ro=r(VQr,"RealmTokenizerFast"),VQr.forEach(t),Iro=r(I8," (Realm model)"),I8.forEach(t),qro=i(C),$s=n(C,"LI",{});var q8=s($s);Qoe=n(q8,"STRONG",{});var XQr=s(Qoe);Nro=r(XQr,"reformer"),XQr.forEach(t),jro=r(q8," \u2014 "),KR=n(q8,"A",{href:!0});var zQr=s(KR);Dro=r(zQr,"ReformerTokenizer"),zQr.forEach(t),Gro=r(q8," or "),ZR=n(q8,"A",{href:!0});var QQr=s(ZR);Oro=r(QQr,"ReformerTokenizerFast"),QQr.forEach(t),Vro=r(q8," (Reformer model)"),q8.forEach(t),Xro=i(C),Is=n(C,"LI",{});var N8=s(Is);Woe=n(N8,"STRONG",{});var WQr=s(Woe);zro=r(WQr,"rembert"),WQr.forEach(t),Qro=r(N8," \u2014 "),eB=n(N8,"A",{href:!0});var HQr=s(eB);Wro=r(HQr,"RemBertTokenizer"),HQr.forEach(t),Hro=r(N8," or "),oB=n(N8,"A",{href:!0});var UQr=s(oB);Uro=r(UQr,"RemBertTokenizerFast"),UQr.forEach(t),Jro=r(N8," (RemBERT model)"),N8.forEach(t),Yro=i(C),qs=n(C,"LI",{});var j8=s(qs);Hoe=n(j8,"STRONG",{});var JQr=s(Hoe);Kro=r(JQr,"retribert"),JQr.forEach(t),Zro=r(j8," \u2014 "),rB=n(j8,"A",{href:!0});var YQr=s(rB);eto=r(YQr,"RetriBertTokenizer"),YQr.forEach(t),oto=r(j8," or "),tB=n(j8,"A",{href:!0});var KQr=s(tB);rto=r(KQr,"RetriBertTokenizerFast"),KQr.forEach(t),tto=r(j8," (RetriBERT model)"),j8.forEach(t),ato=i(C),Ns=n(C,"LI",{});var D8=s(Ns);Uoe=n(D8,"STRONG",{});var ZQr=s(Uoe);nto=r(ZQr,"roberta"),ZQr.forEach(t),sto=r(D8," \u2014 "),aB=n(D8,"A",{href:!0});var eWr=s(aB);lto=r(eWr,"RobertaTokenizer"),eWr.forEach(t),ito=r(D8," or "),nB=n(D8,"A",{href:!0});var oWr=s(nB);dto=r(oWr,"RobertaTokenizerFast"),oWr.forEach(t),cto=r(D8," (RoBERTa model)"),D8.forEach(t),fto=i(C),js=n(C,"LI",{});var G8=s(js);Joe=n(G8,"STRONG",{});var rWr=s(Joe);mto=r(rWr,"roformer"),rWr.forEach(t),gto=r(G8," \u2014 "),sB=n(G8,"A",{href:!0});var tWr=s(sB);hto=r(tWr,"RoFormerTokenizer"),tWr.forEach(t),pto=r(G8," or "),lB=n(G8,"A",{href:!0});var aWr=s(lB);_to=r(aWr,"RoFormerTokenizerFast"),aWr.forEach(t),uto=r(G8," (RoFormer model)"),G8.forEach(t),bto=i(C),_h=n(C,"LI",{});var JEe=s(_h);Yoe=n(JEe,"STRONG",{});var nWr=s(Yoe);vto=r(nWr,"speech_to_text"),nWr.forEach(t),Fto=r(JEe," \u2014 "),iB=n(JEe,"A",{href:!0});var sWr=s(iB);Tto=r(sWr,"Speech2TextTokenizer"),sWr.forEach(t),Mto=r(JEe," (Speech2Text model)"),JEe.forEach(t),Eto=i(C),uh=n(C,"LI",{});var YEe=s(uh);Koe=n(YEe,"STRONG",{});var lWr=s(Koe);Cto=r(lWr,"speech_to_text_2"),lWr.forEach(t),wto=r(YEe," \u2014 "),dB=n(YEe,"A",{href:!0});var iWr=s(dB);Ato=r(iWr,"Speech2Text2Tokenizer"),iWr.forEach(t),yto=r(YEe," (Speech2Text2 model)"),YEe.forEach(t),Lto=i(C),Ds=n(C,"LI",{});var O8=s(Ds);Zoe=n(O8,"STRONG",{});var dWr=s(Zoe);xto=r(dWr,"splinter"),dWr.forEach(t),kto=r(O8," \u2014 "),cB=n(O8,"A",{href:!0});var cWr=s(cB);Sto=r(cWr,"SplinterTokenizer"),cWr.forEach(t),Rto=r(O8," or "),fB=n(O8,"A",{href:!0});var fWr=s(fB);Bto=r(fWr,"SplinterTokenizerFast"),fWr.forEach(t),Pto=r(O8," (Splinter model)"),O8.forEach(t),$to=i(C),Gs=n(C,"LI",{});var V8=s(Gs);ere=n(V8,"STRONG",{});var mWr=s(ere);Ito=r(mWr,"squeezebert"),mWr.forEach(t),qto=r(V8," \u2014 "),mB=n(V8,"A",{href:!0});var gWr=s(mB);Nto=r(gWr,"SqueezeBertTokenizer"),gWr.forEach(t),jto=r(V8," or "),gB=n(V8,"A",{href:!0});var hWr=s(gB);Dto=r(hWr,"SqueezeBertTokenizerFast"),hWr.forEach(t),Gto=r(V8," (SqueezeBERT model)"),V8.forEach(t),Oto=i(C),Os=n(C,"LI",{});var X8=s(Os);ore=n(X8,"STRONG",{});var pWr=s(ore);Vto=r(pWr,"t5"),pWr.forEach(t),Xto=r(X8," \u2014 "),hB=n(X8,"A",{href:!0});var _Wr=s(hB);zto=r(_Wr,"T5Tokenizer"),_Wr.forEach(t),Qto=r(X8," or "),pB=n(X8,"A",{href:!0});var uWr=s(pB);Wto=r(uWr,"T5TokenizerFast"),uWr.forEach(t),Hto=r(X8," (T5 model)"),X8.forEach(t),Uto=i(C),bh=n(C,"LI",{});var KEe=s(bh);rre=n(KEe,"STRONG",{});var bWr=s(rre);Jto=r(bWr,"tapas"),bWr.forEach(t),Yto=r(KEe," \u2014 "),_B=n(KEe,"A",{href:!0});var vWr=s(_B);Kto=r(vWr,"TapasTokenizer"),vWr.forEach(t),Zto=r(KEe," (TAPAS model)"),KEe.forEach(t),eao=i(C),vh=n(C,"LI",{});var ZEe=s(vh);tre=n(ZEe,"STRONG",{});var FWr=s(tre);oao=r(FWr,"tapex"),FWr.forEach(t),rao=r(ZEe," \u2014 "),uB=n(ZEe,"A",{href:!0});var TWr=s(uB);tao=r(TWr,"TapexTokenizer"),TWr.forEach(t),aao=r(ZEe," (TAPEX model)"),ZEe.forEach(t),nao=i(C),Fh=n(C,"LI",{});var e5e=s(Fh);are=n(e5e,"STRONG",{});var MWr=s(are);sao=r(MWr,"transfo-xl"),MWr.forEach(t),lao=r(e5e," \u2014 "),bB=n(e5e,"A",{href:!0});var EWr=s(bB);iao=r(EWr,"TransfoXLTokenizer"),EWr.forEach(t),dao=r(e5e," (Transformer-XL model)"),e5e.forEach(t),cao=i(C),Vs=n(C,"LI",{});var z8=s(Vs);nre=n(z8,"STRONG",{});var CWr=s(nre);fao=r(CWr,"visual_bert"),CWr.forEach(t),mao=r(z8," \u2014 "),vB=n(z8,"A",{href:!0});var wWr=s(vB);gao=r(wWr,"BertTokenizer"),wWr.forEach(t),hao=r(z8," or "),FB=n(z8,"A",{href:!0});var AWr=s(FB);pao=r(AWr,"BertTokenizerFast"),AWr.forEach(t),_ao=r(z8," (VisualBert model)"),z8.forEach(t),uao=i(C),Th=n(C,"LI",{});var o5e=s(Th);sre=n(o5e,"STRONG",{});var yWr=s(sre);bao=r(yWr,"wav2vec2"),yWr.forEach(t),vao=r(o5e," \u2014 "),TB=n(o5e,"A",{href:!0});var LWr=s(TB);Fao=r(LWr,"Wav2Vec2CTCTokenizer"),LWr.forEach(t),Tao=r(o5e," (Wav2Vec2 model)"),o5e.forEach(t),Mao=i(C),Mh=n(C,"LI",{});var r5e=s(Mh);lre=n(r5e,"STRONG",{});var xWr=s(lre);Eao=r(xWr,"wav2vec2_phoneme"),xWr.forEach(t),Cao=r(r5e," \u2014 "),MB=n(r5e,"A",{href:!0});var kWr=s(MB);wao=r(kWr,"Wav2Vec2PhonemeCTCTokenizer"),kWr.forEach(t),Aao=r(r5e," (Wav2Vec2Phoneme model)"),r5e.forEach(t),yao=i(C),Xs=n(C,"LI",{});var Q8=s(Xs);ire=n(Q8,"STRONG",{});var SWr=s(ire);Lao=r(SWr,"xglm"),SWr.forEach(t),xao=r(Q8," \u2014 "),EB=n(Q8,"A",{href:!0});var RWr=s(EB);kao=r(RWr,"XGLMTokenizer"),RWr.forEach(t),Sao=r(Q8," or "),CB=n(Q8,"A",{href:!0});var BWr=s(CB);Rao=r(BWr,"XGLMTokenizerFast"),BWr.forEach(t),Bao=r(Q8," (XGLM model)"),Q8.forEach(t),Pao=i(C),Eh=n(C,"LI",{});var t5e=s(Eh);dre=n(t5e,"STRONG",{});var PWr=s(dre);$ao=r(PWr,"xlm"),PWr.forEach(t),Iao=r(t5e," \u2014 "),wB=n(t5e,"A",{href:!0});var $Wr=s(wB);qao=r($Wr,"XLMTokenizer"),$Wr.forEach(t),Nao=r(t5e," (XLM model)"),t5e.forEach(t),jao=i(C),Ch=n(C,"LI",{});var a5e=s(Ch);cre=n(a5e,"STRONG",{});var IWr=s(cre);Dao=r(IWr,"xlm-prophetnet"),IWr.forEach(t),Gao=r(a5e," \u2014 "),AB=n(a5e,"A",{href:!0});var qWr=s(AB);Oao=r(qWr,"XLMProphetNetTokenizer"),qWr.forEach(t),Vao=r(a5e," (XLMProphetNet model)"),a5e.forEach(t),Xao=i(C),zs=n(C,"LI",{});var W8=s(zs);fre=n(W8,"STRONG",{});var NWr=s(fre);zao=r(NWr,"xlm-roberta"),NWr.forEach(t),Qao=r(W8," \u2014 "),yB=n(W8,"A",{href:!0});var jWr=s(yB);Wao=r(jWr,"XLMRobertaTokenizer"),jWr.forEach(t),Hao=r(W8," or "),LB=n(W8,"A",{href:!0});var DWr=s(LB);Uao=r(DWr,"XLMRobertaTokenizerFast"),DWr.forEach(t),Jao=r(W8," (XLM-RoBERTa model)"),W8.forEach(t),Yao=i(C),Qs=n(C,"LI",{});var H8=s(Qs);mre=n(H8,"STRONG",{});var GWr=s(mre);Kao=r(GWr,"xlm-roberta-xl"),GWr.forEach(t),Zao=r(H8," \u2014 "),xB=n(H8,"A",{href:!0});var OWr=s(xB);eno=r(OWr,"RobertaTokenizer"),OWr.forEach(t),ono=r(H8," or "),kB=n(H8,"A",{href:!0});var VWr=s(kB);rno=r(VWr,"RobertaTokenizerFast"),VWr.forEach(t),tno=r(H8," (XLM-RoBERTa-XL model)"),H8.forEach(t),ano=i(C),Ws=n(C,"LI",{});var U8=s(Ws);gre=n(U8,"STRONG",{});var XWr=s(gre);nno=r(XWr,"xlnet"),XWr.forEach(t),sno=r(U8," \u2014 "),SB=n(U8,"A",{href:!0});var zWr=s(SB);lno=r(zWr,"XLNetTokenizer"),zWr.forEach(t),ino=r(U8," or "),RB=n(U8,"A",{href:!0});var QWr=s(RB);dno=r(QWr,"XLNetTokenizerFast"),QWr.forEach(t),cno=r(U8," (XLNet model)"),U8.forEach(t),fno=i(C),Hs=n(C,"LI",{});var J8=s(Hs);hre=n(J8,"STRONG",{});var WWr=s(hre);mno=r(WWr,"yoso"),WWr.forEach(t),gno=r(J8," \u2014 "),BB=n(J8,"A",{href:!0});var HWr=s(BB);hno=r(HWr,"AlbertTokenizer"),HWr.forEach(t),pno=r(J8," or "),PB=n(J8,"A",{href:!0});var UWr=s(PB);_no=r(UWr,"AlbertTokenizerFast"),UWr.forEach(t),uno=r(J8," (YOSO model)"),J8.forEach(t),C.forEach(t),bno=i(ha),pre=n(ha,"P",{});var JWr=s(pre);vno=r(JWr,"Examples:"),JWr.forEach(t),Fno=i(ha),m(u3.$$.fragment,ha),ha.forEach(t),Tno=i(Zs),wh=n(Zs,"DIV",{class:!0});var zIe=s(wh);m(b3.$$.fragment,zIe),Mno=i(zIe),_re=n(zIe,"P",{});var YWr=s(_re);Eno=r(YWr,"Register a new tokenizer in this mapping."),YWr.forEach(t),zIe.forEach(t),Zs.forEach(t),GPe=i(c),td=n(c,"H2",{class:!0});var QIe=s(td);Ah=n(QIe,"A",{id:!0,class:!0,href:!0});var KWr=s(Ah);ure=n(KWr,"SPAN",{});var ZWr=s(ure);m(v3.$$.fragment,ZWr),ZWr.forEach(t),KWr.forEach(t),Cno=i(QIe),bre=n(QIe,"SPAN",{});var eHr=s(bre);wno=r(eHr,"AutoFeatureExtractor"),eHr.forEach(t),QIe.forEach(t),OPe=i(c),Ho=n(c,"DIV",{class:!0});var el=s(Ho);m(F3.$$.fragment,el),Ano=i(el),T3=n(el,"P",{});var WIe=s(T3);yno=r(WIe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),$B=n(WIe,"A",{href:!0});var oHr=s($B);Lno=r(oHr,"AutoFeatureExtractor.from_pretrained()"),oHr.forEach(t),xno=r(WIe," class method."),WIe.forEach(t),kno=i(el),M3=n(el,"P",{});var HIe=s(M3);Sno=r(HIe,"This class cannot be instantiated directly using "),vre=n(HIe,"CODE",{});var rHr=s(vre);Rno=r(rHr,"__init__()"),rHr.forEach(t),Bno=r(HIe," (throws an error)."),HIe.forEach(t),Pno=i(el),qe=n(el,"DIV",{class:!0});var Nt=s(qe);m(E3.$$.fragment,Nt),$no=i(Nt),Fre=n(Nt,"P",{});var tHr=s(Fre);Ino=r(tHr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),tHr.forEach(t),qno=i(Nt),Va=n(Nt,"P",{});var o5=s(Va);Nno=r(o5,"The feature extractor class to instantiate is selected based on the "),Tre=n(o5,"CODE",{});var aHr=s(Tre);jno=r(aHr,"model_type"),aHr.forEach(t),Dno=r(o5,` property of the config object
(either passed as an argument or loaded from `),Mre=n(o5,"CODE",{});var nHr=s(Mre);Gno=r(nHr,"pretrained_model_name_or_path"),nHr.forEach(t),Ono=r(o5,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ere=n(o5,"CODE",{});var sHr=s(Ere);Vno=r(sHr,"pretrained_model_name_or_path"),sHr.forEach(t),Xno=r(o5,":"),o5.forEach(t),zno=i(Nt),H=n(Nt,"UL",{});var J=s(H);yh=n(J,"LI",{});var n5e=s(yh);Cre=n(n5e,"STRONG",{});var lHr=s(Cre);Qno=r(lHr,"beit"),lHr.forEach(t),Wno=r(n5e," \u2014 "),IB=n(n5e,"A",{href:!0});var iHr=s(IB);Hno=r(iHr,"BeitFeatureExtractor"),iHr.forEach(t),Uno=r(n5e," (BEiT model)"),n5e.forEach(t),Jno=i(J),Lh=n(J,"LI",{});var s5e=s(Lh);wre=n(s5e,"STRONG",{});var dHr=s(wre);Yno=r(dHr,"clip"),dHr.forEach(t),Kno=r(s5e," \u2014 "),qB=n(s5e,"A",{href:!0});var cHr=s(qB);Zno=r(cHr,"CLIPFeatureExtractor"),cHr.forEach(t),eso=r(s5e," (CLIP model)"),s5e.forEach(t),oso=i(J),xh=n(J,"LI",{});var l5e=s(xh);Are=n(l5e,"STRONG",{});var fHr=s(Are);rso=r(fHr,"convnext"),fHr.forEach(t),tso=r(l5e," \u2014 "),NB=n(l5e,"A",{href:!0});var mHr=s(NB);aso=r(mHr,"ConvNextFeatureExtractor"),mHr.forEach(t),nso=r(l5e," (ConvNext model)"),l5e.forEach(t),sso=i(J),kh=n(J,"LI",{});var i5e=s(kh);yre=n(i5e,"STRONG",{});var gHr=s(yre);lso=r(gHr,"data2vec-audio"),gHr.forEach(t),iso=r(i5e," \u2014 "),jB=n(i5e,"A",{href:!0});var hHr=s(jB);dso=r(hHr,"Wav2Vec2FeatureExtractor"),hHr.forEach(t),cso=r(i5e," (Data2VecAudio model)"),i5e.forEach(t),fso=i(J),Sh=n(J,"LI",{});var d5e=s(Sh);Lre=n(d5e,"STRONG",{});var pHr=s(Lre);mso=r(pHr,"data2vec-vision"),pHr.forEach(t),gso=r(d5e," \u2014 "),DB=n(d5e,"A",{href:!0});var _Hr=s(DB);hso=r(_Hr,"BeitFeatureExtractor"),_Hr.forEach(t),pso=r(d5e," (Data2VecVision model)"),d5e.forEach(t),_so=i(J),Rh=n(J,"LI",{});var c5e=s(Rh);xre=n(c5e,"STRONG",{});var uHr=s(xre);uso=r(uHr,"deit"),uHr.forEach(t),bso=r(c5e," \u2014 "),GB=n(c5e,"A",{href:!0});var bHr=s(GB);vso=r(bHr,"DeiTFeatureExtractor"),bHr.forEach(t),Fso=r(c5e," (DeiT model)"),c5e.forEach(t),Tso=i(J),Bh=n(J,"LI",{});var f5e=s(Bh);kre=n(f5e,"STRONG",{});var vHr=s(kre);Mso=r(vHr,"detr"),vHr.forEach(t),Eso=r(f5e," \u2014 "),OB=n(f5e,"A",{href:!0});var FHr=s(OB);Cso=r(FHr,"DetrFeatureExtractor"),FHr.forEach(t),wso=r(f5e," (DETR model)"),f5e.forEach(t),Aso=i(J),Ph=n(J,"LI",{});var m5e=s(Ph);Sre=n(m5e,"STRONG",{});var THr=s(Sre);yso=r(THr,"dpt"),THr.forEach(t),Lso=r(m5e," \u2014 "),VB=n(m5e,"A",{href:!0});var MHr=s(VB);xso=r(MHr,"DPTFeatureExtractor"),MHr.forEach(t),kso=r(m5e," (DPT model)"),m5e.forEach(t),Sso=i(J),$h=n(J,"LI",{});var g5e=s($h);Rre=n(g5e,"STRONG",{});var EHr=s(Rre);Rso=r(EHr,"glpn"),EHr.forEach(t),Bso=r(g5e," \u2014 "),XB=n(g5e,"A",{href:!0});var CHr=s(XB);Pso=r(CHr,"GLPNFeatureExtractor"),CHr.forEach(t),$so=r(g5e," (GLPN model)"),g5e.forEach(t),Iso=i(J),Ih=n(J,"LI",{});var h5e=s(Ih);Bre=n(h5e,"STRONG",{});var wHr=s(Bre);qso=r(wHr,"hubert"),wHr.forEach(t),Nso=r(h5e," \u2014 "),zB=n(h5e,"A",{href:!0});var AHr=s(zB);jso=r(AHr,"Wav2Vec2FeatureExtractor"),AHr.forEach(t),Dso=r(h5e," (Hubert model)"),h5e.forEach(t),Gso=i(J),qh=n(J,"LI",{});var p5e=s(qh);Pre=n(p5e,"STRONG",{});var yHr=s(Pre);Oso=r(yHr,"layoutlmv2"),yHr.forEach(t),Vso=r(p5e," \u2014 "),QB=n(p5e,"A",{href:!0});var LHr=s(QB);Xso=r(LHr,"LayoutLMv2FeatureExtractor"),LHr.forEach(t),zso=r(p5e," (LayoutLMv2 model)"),p5e.forEach(t),Qso=i(J),Nh=n(J,"LI",{});var _5e=s(Nh);$re=n(_5e,"STRONG",{});var xHr=s($re);Wso=r(xHr,"maskformer"),xHr.forEach(t),Hso=r(_5e," \u2014 "),WB=n(_5e,"A",{href:!0});var kHr=s(WB);Uso=r(kHr,"MaskFormerFeatureExtractor"),kHr.forEach(t),Jso=r(_5e," (MaskFormer model)"),_5e.forEach(t),Yso=i(J),jh=n(J,"LI",{});var u5e=s(jh);Ire=n(u5e,"STRONG",{});var SHr=s(Ire);Kso=r(SHr,"perceiver"),SHr.forEach(t),Zso=r(u5e," \u2014 "),HB=n(u5e,"A",{href:!0});var RHr=s(HB);elo=r(RHr,"PerceiverFeatureExtractor"),RHr.forEach(t),olo=r(u5e," (Perceiver model)"),u5e.forEach(t),rlo=i(J),Dh=n(J,"LI",{});var b5e=s(Dh);qre=n(b5e,"STRONG",{});var BHr=s(qre);tlo=r(BHr,"poolformer"),BHr.forEach(t),alo=r(b5e," \u2014 "),UB=n(b5e,"A",{href:!0});var PHr=s(UB);nlo=r(PHr,"PoolFormerFeatureExtractor"),PHr.forEach(t),slo=r(b5e," (PoolFormer model)"),b5e.forEach(t),llo=i(J),Gh=n(J,"LI",{});var v5e=s(Gh);Nre=n(v5e,"STRONG",{});var $Hr=s(Nre);ilo=r($Hr,"regnet"),$Hr.forEach(t),dlo=r(v5e," \u2014 "),JB=n(v5e,"A",{href:!0});var IHr=s(JB);clo=r(IHr,"ConvNextFeatureExtractor"),IHr.forEach(t),flo=r(v5e," (RegNet model)"),v5e.forEach(t),mlo=i(J),Oh=n(J,"LI",{});var F5e=s(Oh);jre=n(F5e,"STRONG",{});var qHr=s(jre);glo=r(qHr,"resnet"),qHr.forEach(t),hlo=r(F5e," \u2014 "),YB=n(F5e,"A",{href:!0});var NHr=s(YB);plo=r(NHr,"ConvNextFeatureExtractor"),NHr.forEach(t),_lo=r(F5e," (ResNet model)"),F5e.forEach(t),ulo=i(J),Vh=n(J,"LI",{});var T5e=s(Vh);Dre=n(T5e,"STRONG",{});var jHr=s(Dre);blo=r(jHr,"segformer"),jHr.forEach(t),vlo=r(T5e," \u2014 "),KB=n(T5e,"A",{href:!0});var DHr=s(KB);Flo=r(DHr,"SegformerFeatureExtractor"),DHr.forEach(t),Tlo=r(T5e," (SegFormer model)"),T5e.forEach(t),Mlo=i(J),Xh=n(J,"LI",{});var M5e=s(Xh);Gre=n(M5e,"STRONG",{});var GHr=s(Gre);Elo=r(GHr,"speech_to_text"),GHr.forEach(t),Clo=r(M5e," \u2014 "),ZB=n(M5e,"A",{href:!0});var OHr=s(ZB);wlo=r(OHr,"Speech2TextFeatureExtractor"),OHr.forEach(t),Alo=r(M5e," (Speech2Text model)"),M5e.forEach(t),ylo=i(J),zh=n(J,"LI",{});var E5e=s(zh);Ore=n(E5e,"STRONG",{});var VHr=s(Ore);Llo=r(VHr,"swin"),VHr.forEach(t),xlo=r(E5e," \u2014 "),eP=n(E5e,"A",{href:!0});var XHr=s(eP);klo=r(XHr,"ViTFeatureExtractor"),XHr.forEach(t),Slo=r(E5e," (Swin model)"),E5e.forEach(t),Rlo=i(J),Qh=n(J,"LI",{});var C5e=s(Qh);Vre=n(C5e,"STRONG",{});var zHr=s(Vre);Blo=r(zHr,"van"),zHr.forEach(t),Plo=r(C5e," \u2014 "),oP=n(C5e,"A",{href:!0});var QHr=s(oP);$lo=r(QHr,"ConvNextFeatureExtractor"),QHr.forEach(t),Ilo=r(C5e," (VAN model)"),C5e.forEach(t),qlo=i(J),Wh=n(J,"LI",{});var w5e=s(Wh);Xre=n(w5e,"STRONG",{});var WHr=s(Xre);Nlo=r(WHr,"vit"),WHr.forEach(t),jlo=r(w5e," \u2014 "),rP=n(w5e,"A",{href:!0});var HHr=s(rP);Dlo=r(HHr,"ViTFeatureExtractor"),HHr.forEach(t),Glo=r(w5e," (ViT model)"),w5e.forEach(t),Olo=i(J),Hh=n(J,"LI",{});var A5e=s(Hh);zre=n(A5e,"STRONG",{});var UHr=s(zre);Vlo=r(UHr,"vit_mae"),UHr.forEach(t),Xlo=r(A5e," \u2014 "),tP=n(A5e,"A",{href:!0});var JHr=s(tP);zlo=r(JHr,"ViTFeatureExtractor"),JHr.forEach(t),Qlo=r(A5e," (ViTMAE model)"),A5e.forEach(t),Wlo=i(J),Uh=n(J,"LI",{});var y5e=s(Uh);Qre=n(y5e,"STRONG",{});var YHr=s(Qre);Hlo=r(YHr,"wav2vec2"),YHr.forEach(t),Ulo=r(y5e," \u2014 "),aP=n(y5e,"A",{href:!0});var KHr=s(aP);Jlo=r(KHr,"Wav2Vec2FeatureExtractor"),KHr.forEach(t),Ylo=r(y5e," (Wav2Vec2 model)"),y5e.forEach(t),J.forEach(t),Klo=i(Nt),m(Jh.$$.fragment,Nt),Zlo=i(Nt),Wre=n(Nt,"P",{});var ZHr=s(Wre);eio=r(ZHr,"Examples:"),ZHr.forEach(t),oio=i(Nt),m(C3.$$.fragment,Nt),Nt.forEach(t),rio=i(el),Yh=n(el,"DIV",{class:!0});var UIe=s(Yh);m(w3.$$.fragment,UIe),tio=i(UIe),Hre=n(UIe,"P",{});var eUr=s(Hre);aio=r(eUr,"Register a new feature extractor for this class."),eUr.forEach(t),UIe.forEach(t),el.forEach(t),VPe=i(c),ad=n(c,"H2",{class:!0});var JIe=s(ad);Kh=n(JIe,"A",{id:!0,class:!0,href:!0});var oUr=s(Kh);Ure=n(oUr,"SPAN",{});var rUr=s(Ure);m(A3.$$.fragment,rUr),rUr.forEach(t),oUr.forEach(t),nio=i(JIe),Jre=n(JIe,"SPAN",{});var tUr=s(Jre);sio=r(tUr,"AutoProcessor"),tUr.forEach(t),JIe.forEach(t),XPe=i(c),Uo=n(c,"DIV",{class:!0});var ol=s(Uo);m(y3.$$.fragment,ol),lio=i(ol),L3=n(ol,"P",{});var YIe=s(L3);iio=r(YIe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),nP=n(YIe,"A",{href:!0});var aUr=s(nP);dio=r(aUr,"AutoProcessor.from_pretrained()"),aUr.forEach(t),cio=r(YIe," class method."),YIe.forEach(t),fio=i(ol),x3=n(ol,"P",{});var KIe=s(x3);mio=r(KIe,"This class cannot be instantiated directly using "),Yre=n(KIe,"CODE",{});var nUr=s(Yre);gio=r(nUr,"__init__()"),nUr.forEach(t),hio=r(KIe," (throws an error)."),KIe.forEach(t),pio=i(ol),Ne=n(ol,"DIV",{class:!0});var jt=s(Ne);m(k3.$$.fragment,jt),_io=i(jt),Kre=n(jt,"P",{});var sUr=s(Kre);uio=r(sUr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),sUr.forEach(t),bio=i(jt),nd=n(jt,"P",{});var BJ=s(nd);vio=r(BJ,"The processor class to instantiate is selected based on the "),Zre=n(BJ,"CODE",{});var lUr=s(Zre);Fio=r(lUr,"model_type"),lUr.forEach(t),Tio=r(BJ,` property of the config object (either
passed as an argument or loaded from `),ete=n(BJ,"CODE",{});var iUr=s(ete);Mio=r(iUr,"pretrained_model_name_or_path"),iUr.forEach(t),Eio=r(BJ," if possible):"),BJ.forEach(t),Cio=i(jt),de=n(jt,"UL",{});var me=s(de);Zh=n(me,"LI",{});var L5e=s(Zh);ote=n(L5e,"STRONG",{});var dUr=s(ote);wio=r(dUr,"clip"),dUr.forEach(t),Aio=r(L5e," \u2014 "),sP=n(L5e,"A",{href:!0});var cUr=s(sP);yio=r(cUr,"CLIPProcessor"),cUr.forEach(t),Lio=r(L5e," (CLIP model)"),L5e.forEach(t),xio=i(me),ep=n(me,"LI",{});var x5e=s(ep);rte=n(x5e,"STRONG",{});var fUr=s(rte);kio=r(fUr,"layoutlmv2"),fUr.forEach(t),Sio=r(x5e," \u2014 "),lP=n(x5e,"A",{href:!0});var mUr=s(lP);Rio=r(mUr,"LayoutLMv2Processor"),mUr.forEach(t),Bio=r(x5e," (LayoutLMv2 model)"),x5e.forEach(t),Pio=i(me),op=n(me,"LI",{});var k5e=s(op);tte=n(k5e,"STRONG",{});var gUr=s(tte);$io=r(gUr,"layoutxlm"),gUr.forEach(t),Iio=r(k5e," \u2014 "),iP=n(k5e,"A",{href:!0});var hUr=s(iP);qio=r(hUr,"LayoutXLMProcessor"),hUr.forEach(t),Nio=r(k5e," (LayoutXLM model)"),k5e.forEach(t),jio=i(me),rp=n(me,"LI",{});var S5e=s(rp);ate=n(S5e,"STRONG",{});var pUr=s(ate);Dio=r(pUr,"sew"),pUr.forEach(t),Gio=r(S5e," \u2014 "),dP=n(S5e,"A",{href:!0});var _Ur=s(dP);Oio=r(_Ur,"Wav2Vec2Processor"),_Ur.forEach(t),Vio=r(S5e," (SEW model)"),S5e.forEach(t),Xio=i(me),tp=n(me,"LI",{});var R5e=s(tp);nte=n(R5e,"STRONG",{});var uUr=s(nte);zio=r(uUr,"sew-d"),uUr.forEach(t),Qio=r(R5e," \u2014 "),cP=n(R5e,"A",{href:!0});var bUr=s(cP);Wio=r(bUr,"Wav2Vec2Processor"),bUr.forEach(t),Hio=r(R5e," (SEW-D model)"),R5e.forEach(t),Uio=i(me),ap=n(me,"LI",{});var B5e=s(ap);ste=n(B5e,"STRONG",{});var vUr=s(ste);Jio=r(vUr,"speech_to_text"),vUr.forEach(t),Yio=r(B5e," \u2014 "),fP=n(B5e,"A",{href:!0});var FUr=s(fP);Kio=r(FUr,"Speech2TextProcessor"),FUr.forEach(t),Zio=r(B5e," (Speech2Text model)"),B5e.forEach(t),edo=i(me),np=n(me,"LI",{});var P5e=s(np);lte=n(P5e,"STRONG",{});var TUr=s(lte);odo=r(TUr,"speech_to_text_2"),TUr.forEach(t),rdo=r(P5e," \u2014 "),mP=n(P5e,"A",{href:!0});var MUr=s(mP);tdo=r(MUr,"Speech2Text2Processor"),MUr.forEach(t),ado=r(P5e," (Speech2Text2 model)"),P5e.forEach(t),ndo=i(me),sp=n(me,"LI",{});var $5e=s(sp);ite=n($5e,"STRONG",{});var EUr=s(ite);sdo=r(EUr,"trocr"),EUr.forEach(t),ldo=r($5e," \u2014 "),gP=n($5e,"A",{href:!0});var CUr=s(gP);ido=r(CUr,"TrOCRProcessor"),CUr.forEach(t),ddo=r($5e," (TrOCR model)"),$5e.forEach(t),cdo=i(me),lp=n(me,"LI",{});var I5e=s(lp);dte=n(I5e,"STRONG",{});var wUr=s(dte);fdo=r(wUr,"unispeech"),wUr.forEach(t),mdo=r(I5e," \u2014 "),hP=n(I5e,"A",{href:!0});var AUr=s(hP);gdo=r(AUr,"Wav2Vec2Processor"),AUr.forEach(t),hdo=r(I5e," (UniSpeech model)"),I5e.forEach(t),pdo=i(me),ip=n(me,"LI",{});var q5e=s(ip);cte=n(q5e,"STRONG",{});var yUr=s(cte);_do=r(yUr,"unispeech-sat"),yUr.forEach(t),udo=r(q5e," \u2014 "),pP=n(q5e,"A",{href:!0});var LUr=s(pP);bdo=r(LUr,"Wav2Vec2Processor"),LUr.forEach(t),vdo=r(q5e," (UniSpeechSat model)"),q5e.forEach(t),Fdo=i(me),dp=n(me,"LI",{});var N5e=s(dp);fte=n(N5e,"STRONG",{});var xUr=s(fte);Tdo=r(xUr,"vilt"),xUr.forEach(t),Mdo=r(N5e," \u2014 "),_P=n(N5e,"A",{href:!0});var kUr=s(_P);Edo=r(kUr,"ViltProcessor"),kUr.forEach(t),Cdo=r(N5e," (ViLT model)"),N5e.forEach(t),wdo=i(me),cp=n(me,"LI",{});var j5e=s(cp);mte=n(j5e,"STRONG",{});var SUr=s(mte);Ado=r(SUr,"vision-text-dual-encoder"),SUr.forEach(t),ydo=r(j5e," \u2014 "),uP=n(j5e,"A",{href:!0});var RUr=s(uP);Ldo=r(RUr,"VisionTextDualEncoderProcessor"),RUr.forEach(t),xdo=r(j5e," (VisionTextDualEncoder model)"),j5e.forEach(t),kdo=i(me),fp=n(me,"LI",{});var D5e=s(fp);gte=n(D5e,"STRONG",{});var BUr=s(gte);Sdo=r(BUr,"wav2vec2"),BUr.forEach(t),Rdo=r(D5e," \u2014 "),bP=n(D5e,"A",{href:!0});var PUr=s(bP);Bdo=r(PUr,"Wav2Vec2Processor"),PUr.forEach(t),Pdo=r(D5e," (Wav2Vec2 model)"),D5e.forEach(t),$do=i(me),mp=n(me,"LI",{});var G5e=s(mp);hte=n(G5e,"STRONG",{});var $Ur=s(hte);Ido=r($Ur,"wavlm"),$Ur.forEach(t),qdo=r(G5e," \u2014 "),vP=n(G5e,"A",{href:!0});var IUr=s(vP);Ndo=r(IUr,"Wav2Vec2Processor"),IUr.forEach(t),jdo=r(G5e," (WavLM model)"),G5e.forEach(t),me.forEach(t),Ddo=i(jt),m(gp.$$.fragment,jt),Gdo=i(jt),pte=n(jt,"P",{});var qUr=s(pte);Odo=r(qUr,"Examples:"),qUr.forEach(t),Vdo=i(jt),m(S3.$$.fragment,jt),jt.forEach(t),Xdo=i(ol),hp=n(ol,"DIV",{class:!0});var ZIe=s(hp);m(R3.$$.fragment,ZIe),zdo=i(ZIe),_te=n(ZIe,"P",{});var NUr=s(_te);Qdo=r(NUr,"Register a new processor for this class."),NUr.forEach(t),ZIe.forEach(t),ol.forEach(t),zPe=i(c),sd=n(c,"H2",{class:!0});var eqe=s(sd);pp=n(eqe,"A",{id:!0,class:!0,href:!0});var jUr=s(pp);ute=n(jUr,"SPAN",{});var DUr=s(ute);m(B3.$$.fragment,DUr),DUr.forEach(t),jUr.forEach(t),Wdo=i(eqe),bte=n(eqe,"SPAN",{});var GUr=s(bte);Hdo=r(GUr,"AutoModel"),GUr.forEach(t),eqe.forEach(t),QPe=i(c),Jo=n(c,"DIV",{class:!0});var rl=s(Jo);m(P3.$$.fragment,rl),Udo=i(rl),ld=n(rl,"P",{});var PJ=s(ld);Jdo=r(PJ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),FP=n(PJ,"A",{href:!0});var OUr=s(FP);Ydo=r(OUr,"from_pretrained()"),OUr.forEach(t),Kdo=r(PJ," class method or the "),TP=n(PJ,"A",{href:!0});var VUr=s(TP);Zdo=r(VUr,"from_config()"),VUr.forEach(t),eco=r(PJ,` class
method.`),PJ.forEach(t),oco=i(rl),$3=n(rl,"P",{});var oqe=s($3);rco=r(oqe,"This class cannot be instantiated directly using "),vte=n(oqe,"CODE",{});var XUr=s(vte);tco=r(XUr,"__init__()"),XUr.forEach(t),aco=r(oqe," (throws an error)."),oqe.forEach(t),nco=i(rl),Xr=n(rl,"DIV",{class:!0});var tl=s(Xr);m(I3.$$.fragment,tl),sco=i(tl),Fte=n(tl,"P",{});var zUr=s(Fte);lco=r(zUr,"Instantiates one of the base model classes of the library from a configuration."),zUr.forEach(t),ico=i(tl),id=n(tl,"P",{});var $J=s(id);dco=r($J,`Note:
Loading a model from its configuration file does `),Tte=n($J,"STRONG",{});var QUr=s(Tte);cco=r(QUr,"not"),QUr.forEach(t),fco=r($J,` load the model weights. It only affects the
model\u2019s configuration. Use `),MP=n($J,"A",{href:!0});var WUr=s(MP);mco=r(WUr,"from_pretrained()"),WUr.forEach(t),gco=r($J," to load the model weights."),$J.forEach(t),hco=i(tl),Mte=n(tl,"P",{});var HUr=s(Mte);pco=r(HUr,"Examples:"),HUr.forEach(t),_co=i(tl),m(q3.$$.fragment,tl),tl.forEach(t),uco=i(rl),je=n(rl,"DIV",{class:!0});var Dt=s(je);m(N3.$$.fragment,Dt),bco=i(Dt),Ete=n(Dt,"P",{});var UUr=s(Ete);vco=r(UUr,"Instantiate one of the base model classes of the library from a pretrained model."),UUr.forEach(t),Fco=i(Dt),Xa=n(Dt,"P",{});var r5=s(Xa);Tco=r(r5,"The model class to instantiate is selected based on the "),Cte=n(r5,"CODE",{});var JUr=s(Cte);Mco=r(JUr,"model_type"),JUr.forEach(t),Eco=r(r5,` property of the config object (either
passed as an argument or loaded from `),wte=n(r5,"CODE",{});var YUr=s(wte);Cco=r(YUr,"pretrained_model_name_or_path"),YUr.forEach(t),wco=r(r5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ate=n(r5,"CODE",{});var KUr=s(Ate);Aco=r(KUr,"pretrained_model_name_or_path"),KUr.forEach(t),yco=r(r5,":"),r5.forEach(t),Lco=i(Dt),T=n(Dt,"UL",{});var M=s(T);_p=n(M,"LI",{});var O5e=s(_p);yte=n(O5e,"STRONG",{});var ZUr=s(yte);xco=r(ZUr,"albert"),ZUr.forEach(t),kco=r(O5e," \u2014 "),EP=n(O5e,"A",{href:!0});var eJr=s(EP);Sco=r(eJr,"AlbertModel"),eJr.forEach(t),Rco=r(O5e," (ALBERT model)"),O5e.forEach(t),Bco=i(M),up=n(M,"LI",{});var V5e=s(up);Lte=n(V5e,"STRONG",{});var oJr=s(Lte);Pco=r(oJr,"bart"),oJr.forEach(t),$co=r(V5e," \u2014 "),CP=n(V5e,"A",{href:!0});var rJr=s(CP);Ico=r(rJr,"BartModel"),rJr.forEach(t),qco=r(V5e," (BART model)"),V5e.forEach(t),Nco=i(M),bp=n(M,"LI",{});var X5e=s(bp);xte=n(X5e,"STRONG",{});var tJr=s(xte);jco=r(tJr,"beit"),tJr.forEach(t),Dco=r(X5e," \u2014 "),wP=n(X5e,"A",{href:!0});var aJr=s(wP);Gco=r(aJr,"BeitModel"),aJr.forEach(t),Oco=r(X5e," (BEiT model)"),X5e.forEach(t),Vco=i(M),vp=n(M,"LI",{});var z5e=s(vp);kte=n(z5e,"STRONG",{});var nJr=s(kte);Xco=r(nJr,"bert"),nJr.forEach(t),zco=r(z5e," \u2014 "),AP=n(z5e,"A",{href:!0});var sJr=s(AP);Qco=r(sJr,"BertModel"),sJr.forEach(t),Wco=r(z5e," (BERT model)"),z5e.forEach(t),Hco=i(M),Fp=n(M,"LI",{});var Q5e=s(Fp);Ste=n(Q5e,"STRONG",{});var lJr=s(Ste);Uco=r(lJr,"bert-generation"),lJr.forEach(t),Jco=r(Q5e," \u2014 "),yP=n(Q5e,"A",{href:!0});var iJr=s(yP);Yco=r(iJr,"BertGenerationEncoder"),iJr.forEach(t),Kco=r(Q5e," (Bert Generation model)"),Q5e.forEach(t),Zco=i(M),Tp=n(M,"LI",{});var W5e=s(Tp);Rte=n(W5e,"STRONG",{});var dJr=s(Rte);efo=r(dJr,"big_bird"),dJr.forEach(t),ofo=r(W5e," \u2014 "),LP=n(W5e,"A",{href:!0});var cJr=s(LP);rfo=r(cJr,"BigBirdModel"),cJr.forEach(t),tfo=r(W5e," (BigBird model)"),W5e.forEach(t),afo=i(M),Mp=n(M,"LI",{});var H5e=s(Mp);Bte=n(H5e,"STRONG",{});var fJr=s(Bte);nfo=r(fJr,"bigbird_pegasus"),fJr.forEach(t),sfo=r(H5e," \u2014 "),xP=n(H5e,"A",{href:!0});var mJr=s(xP);lfo=r(mJr,"BigBirdPegasusModel"),mJr.forEach(t),ifo=r(H5e," (BigBirdPegasus model)"),H5e.forEach(t),dfo=i(M),Ep=n(M,"LI",{});var U5e=s(Ep);Pte=n(U5e,"STRONG",{});var gJr=s(Pte);cfo=r(gJr,"blenderbot"),gJr.forEach(t),ffo=r(U5e," \u2014 "),kP=n(U5e,"A",{href:!0});var hJr=s(kP);mfo=r(hJr,"BlenderbotModel"),hJr.forEach(t),gfo=r(U5e," (Blenderbot model)"),U5e.forEach(t),hfo=i(M),Cp=n(M,"LI",{});var J5e=s(Cp);$te=n(J5e,"STRONG",{});var pJr=s($te);pfo=r(pJr,"blenderbot-small"),pJr.forEach(t),_fo=r(J5e," \u2014 "),SP=n(J5e,"A",{href:!0});var _Jr=s(SP);ufo=r(_Jr,"BlenderbotSmallModel"),_Jr.forEach(t),bfo=r(J5e," (BlenderbotSmall model)"),J5e.forEach(t),vfo=i(M),wp=n(M,"LI",{});var Y5e=s(wp);Ite=n(Y5e,"STRONG",{});var uJr=s(Ite);Ffo=r(uJr,"camembert"),uJr.forEach(t),Tfo=r(Y5e," \u2014 "),RP=n(Y5e,"A",{href:!0});var bJr=s(RP);Mfo=r(bJr,"CamembertModel"),bJr.forEach(t),Efo=r(Y5e," (CamemBERT model)"),Y5e.forEach(t),Cfo=i(M),Ap=n(M,"LI",{});var K5e=s(Ap);qte=n(K5e,"STRONG",{});var vJr=s(qte);wfo=r(vJr,"canine"),vJr.forEach(t),Afo=r(K5e," \u2014 "),BP=n(K5e,"A",{href:!0});var FJr=s(BP);yfo=r(FJr,"CanineModel"),FJr.forEach(t),Lfo=r(K5e," (Canine model)"),K5e.forEach(t),xfo=i(M),yp=n(M,"LI",{});var Z5e=s(yp);Nte=n(Z5e,"STRONG",{});var TJr=s(Nte);kfo=r(TJr,"clip"),TJr.forEach(t),Sfo=r(Z5e," \u2014 "),PP=n(Z5e,"A",{href:!0});var MJr=s(PP);Rfo=r(MJr,"CLIPModel"),MJr.forEach(t),Bfo=r(Z5e," (CLIP model)"),Z5e.forEach(t),Pfo=i(M),Lp=n(M,"LI",{});var e3e=s(Lp);jte=n(e3e,"STRONG",{});var EJr=s(jte);$fo=r(EJr,"convbert"),EJr.forEach(t),Ifo=r(e3e," \u2014 "),$P=n(e3e,"A",{href:!0});var CJr=s($P);qfo=r(CJr,"ConvBertModel"),CJr.forEach(t),Nfo=r(e3e," (ConvBERT model)"),e3e.forEach(t),jfo=i(M),xp=n(M,"LI",{});var o3e=s(xp);Dte=n(o3e,"STRONG",{});var wJr=s(Dte);Dfo=r(wJr,"convnext"),wJr.forEach(t),Gfo=r(o3e," \u2014 "),IP=n(o3e,"A",{href:!0});var AJr=s(IP);Ofo=r(AJr,"ConvNextModel"),AJr.forEach(t),Vfo=r(o3e," (ConvNext model)"),o3e.forEach(t),Xfo=i(M),kp=n(M,"LI",{});var r3e=s(kp);Gte=n(r3e,"STRONG",{});var yJr=s(Gte);zfo=r(yJr,"ctrl"),yJr.forEach(t),Qfo=r(r3e," \u2014 "),qP=n(r3e,"A",{href:!0});var LJr=s(qP);Wfo=r(LJr,"CTRLModel"),LJr.forEach(t),Hfo=r(r3e," (CTRL model)"),r3e.forEach(t),Ufo=i(M),Sp=n(M,"LI",{});var t3e=s(Sp);Ote=n(t3e,"STRONG",{});var xJr=s(Ote);Jfo=r(xJr,"data2vec-audio"),xJr.forEach(t),Yfo=r(t3e," \u2014 "),NP=n(t3e,"A",{href:!0});var kJr=s(NP);Kfo=r(kJr,"Data2VecAudioModel"),kJr.forEach(t),Zfo=r(t3e," (Data2VecAudio model)"),t3e.forEach(t),emo=i(M),Rp=n(M,"LI",{});var a3e=s(Rp);Vte=n(a3e,"STRONG",{});var SJr=s(Vte);omo=r(SJr,"data2vec-text"),SJr.forEach(t),rmo=r(a3e," \u2014 "),jP=n(a3e,"A",{href:!0});var RJr=s(jP);tmo=r(RJr,"Data2VecTextModel"),RJr.forEach(t),amo=r(a3e," (Data2VecText model)"),a3e.forEach(t),nmo=i(M),Bp=n(M,"LI",{});var n3e=s(Bp);Xte=n(n3e,"STRONG",{});var BJr=s(Xte);smo=r(BJr,"data2vec-vision"),BJr.forEach(t),lmo=r(n3e," \u2014 "),DP=n(n3e,"A",{href:!0});var PJr=s(DP);imo=r(PJr,"Data2VecVisionModel"),PJr.forEach(t),dmo=r(n3e," (Data2VecVision model)"),n3e.forEach(t),cmo=i(M),Pp=n(M,"LI",{});var s3e=s(Pp);zte=n(s3e,"STRONG",{});var $Jr=s(zte);fmo=r($Jr,"deberta"),$Jr.forEach(t),mmo=r(s3e," \u2014 "),GP=n(s3e,"A",{href:!0});var IJr=s(GP);gmo=r(IJr,"DebertaModel"),IJr.forEach(t),hmo=r(s3e," (DeBERTa model)"),s3e.forEach(t),pmo=i(M),$p=n(M,"LI",{});var l3e=s($p);Qte=n(l3e,"STRONG",{});var qJr=s(Qte);_mo=r(qJr,"deberta-v2"),qJr.forEach(t),umo=r(l3e," \u2014 "),OP=n(l3e,"A",{href:!0});var NJr=s(OP);bmo=r(NJr,"DebertaV2Model"),NJr.forEach(t),vmo=r(l3e," (DeBERTa-v2 model)"),l3e.forEach(t),Fmo=i(M),Ip=n(M,"LI",{});var i3e=s(Ip);Wte=n(i3e,"STRONG",{});var jJr=s(Wte);Tmo=r(jJr,"decision_transformer"),jJr.forEach(t),Mmo=r(i3e," \u2014 "),VP=n(i3e,"A",{href:!0});var DJr=s(VP);Emo=r(DJr,"DecisionTransformerModel"),DJr.forEach(t),Cmo=r(i3e," (Decision Transformer model)"),i3e.forEach(t),wmo=i(M),qp=n(M,"LI",{});var d3e=s(qp);Hte=n(d3e,"STRONG",{});var GJr=s(Hte);Amo=r(GJr,"deit"),GJr.forEach(t),ymo=r(d3e," \u2014 "),XP=n(d3e,"A",{href:!0});var OJr=s(XP);Lmo=r(OJr,"DeiTModel"),OJr.forEach(t),xmo=r(d3e," (DeiT model)"),d3e.forEach(t),kmo=i(M),Np=n(M,"LI",{});var c3e=s(Np);Ute=n(c3e,"STRONG",{});var VJr=s(Ute);Smo=r(VJr,"detr"),VJr.forEach(t),Rmo=r(c3e," \u2014 "),zP=n(c3e,"A",{href:!0});var XJr=s(zP);Bmo=r(XJr,"DetrModel"),XJr.forEach(t),Pmo=r(c3e," (DETR model)"),c3e.forEach(t),$mo=i(M),jp=n(M,"LI",{});var f3e=s(jp);Jte=n(f3e,"STRONG",{});var zJr=s(Jte);Imo=r(zJr,"distilbert"),zJr.forEach(t),qmo=r(f3e," \u2014 "),QP=n(f3e,"A",{href:!0});var QJr=s(QP);Nmo=r(QJr,"DistilBertModel"),QJr.forEach(t),jmo=r(f3e," (DistilBERT model)"),f3e.forEach(t),Dmo=i(M),Dp=n(M,"LI",{});var m3e=s(Dp);Yte=n(m3e,"STRONG",{});var WJr=s(Yte);Gmo=r(WJr,"dpr"),WJr.forEach(t),Omo=r(m3e," \u2014 "),WP=n(m3e,"A",{href:!0});var HJr=s(WP);Vmo=r(HJr,"DPRQuestionEncoder"),HJr.forEach(t),Xmo=r(m3e," (DPR model)"),m3e.forEach(t),zmo=i(M),Gp=n(M,"LI",{});var g3e=s(Gp);Kte=n(g3e,"STRONG",{});var UJr=s(Kte);Qmo=r(UJr,"dpt"),UJr.forEach(t),Wmo=r(g3e," \u2014 "),HP=n(g3e,"A",{href:!0});var JJr=s(HP);Hmo=r(JJr,"DPTModel"),JJr.forEach(t),Umo=r(g3e," (DPT model)"),g3e.forEach(t),Jmo=i(M),Op=n(M,"LI",{});var h3e=s(Op);Zte=n(h3e,"STRONG",{});var YJr=s(Zte);Ymo=r(YJr,"electra"),YJr.forEach(t),Kmo=r(h3e," \u2014 "),UP=n(h3e,"A",{href:!0});var KJr=s(UP);Zmo=r(KJr,"ElectraModel"),KJr.forEach(t),ego=r(h3e," (ELECTRA model)"),h3e.forEach(t),ogo=i(M),Vp=n(M,"LI",{});var p3e=s(Vp);eae=n(p3e,"STRONG",{});var ZJr=s(eae);rgo=r(ZJr,"flaubert"),ZJr.forEach(t),tgo=r(p3e," \u2014 "),JP=n(p3e,"A",{href:!0});var eYr=s(JP);ago=r(eYr,"FlaubertModel"),eYr.forEach(t),ngo=r(p3e," (FlauBERT model)"),p3e.forEach(t),sgo=i(M),Xp=n(M,"LI",{});var _3e=s(Xp);oae=n(_3e,"STRONG",{});var oYr=s(oae);lgo=r(oYr,"fnet"),oYr.forEach(t),igo=r(_3e," \u2014 "),YP=n(_3e,"A",{href:!0});var rYr=s(YP);dgo=r(rYr,"FNetModel"),rYr.forEach(t),cgo=r(_3e," (FNet model)"),_3e.forEach(t),fgo=i(M),zp=n(M,"LI",{});var u3e=s(zp);rae=n(u3e,"STRONG",{});var tYr=s(rae);mgo=r(tYr,"fsmt"),tYr.forEach(t),ggo=r(u3e," \u2014 "),KP=n(u3e,"A",{href:!0});var aYr=s(KP);hgo=r(aYr,"FSMTModel"),aYr.forEach(t),pgo=r(u3e," (FairSeq Machine-Translation model)"),u3e.forEach(t),_go=i(M),Us=n(M,"LI",{});var Y8=s(Us);tae=n(Y8,"STRONG",{});var nYr=s(tae);ugo=r(nYr,"funnel"),nYr.forEach(t),bgo=r(Y8," \u2014 "),ZP=n(Y8,"A",{href:!0});var sYr=s(ZP);vgo=r(sYr,"FunnelModel"),sYr.forEach(t),Fgo=r(Y8," or "),e$=n(Y8,"A",{href:!0});var lYr=s(e$);Tgo=r(lYr,"FunnelBaseModel"),lYr.forEach(t),Mgo=r(Y8," (Funnel Transformer model)"),Y8.forEach(t),Ego=i(M),Qp=n(M,"LI",{});var b3e=s(Qp);aae=n(b3e,"STRONG",{});var iYr=s(aae);Cgo=r(iYr,"glpn"),iYr.forEach(t),wgo=r(b3e," \u2014 "),o$=n(b3e,"A",{href:!0});var dYr=s(o$);Ago=r(dYr,"GLPNModel"),dYr.forEach(t),ygo=r(b3e," (GLPN model)"),b3e.forEach(t),Lgo=i(M),Wp=n(M,"LI",{});var v3e=s(Wp);nae=n(v3e,"STRONG",{});var cYr=s(nae);xgo=r(cYr,"gpt2"),cYr.forEach(t),kgo=r(v3e," \u2014 "),r$=n(v3e,"A",{href:!0});var fYr=s(r$);Sgo=r(fYr,"GPT2Model"),fYr.forEach(t),Rgo=r(v3e," (OpenAI GPT-2 model)"),v3e.forEach(t),Bgo=i(M),Hp=n(M,"LI",{});var F3e=s(Hp);sae=n(F3e,"STRONG",{});var mYr=s(sae);Pgo=r(mYr,"gpt_neo"),mYr.forEach(t),$go=r(F3e," \u2014 "),t$=n(F3e,"A",{href:!0});var gYr=s(t$);Igo=r(gYr,"GPTNeoModel"),gYr.forEach(t),qgo=r(F3e," (GPT Neo model)"),F3e.forEach(t),Ngo=i(M),Up=n(M,"LI",{});var T3e=s(Up);lae=n(T3e,"STRONG",{});var hYr=s(lae);jgo=r(hYr,"gptj"),hYr.forEach(t),Dgo=r(T3e," \u2014 "),a$=n(T3e,"A",{href:!0});var pYr=s(a$);Ggo=r(pYr,"GPTJModel"),pYr.forEach(t),Ogo=r(T3e," (GPT-J model)"),T3e.forEach(t),Vgo=i(M),Jp=n(M,"LI",{});var M3e=s(Jp);iae=n(M3e,"STRONG",{});var _Yr=s(iae);Xgo=r(_Yr,"hubert"),_Yr.forEach(t),zgo=r(M3e," \u2014 "),n$=n(M3e,"A",{href:!0});var uYr=s(n$);Qgo=r(uYr,"HubertModel"),uYr.forEach(t),Wgo=r(M3e," (Hubert model)"),M3e.forEach(t),Hgo=i(M),Yp=n(M,"LI",{});var E3e=s(Yp);dae=n(E3e,"STRONG",{});var bYr=s(dae);Ugo=r(bYr,"ibert"),bYr.forEach(t),Jgo=r(E3e," \u2014 "),s$=n(E3e,"A",{href:!0});var vYr=s(s$);Ygo=r(vYr,"IBertModel"),vYr.forEach(t),Kgo=r(E3e," (I-BERT model)"),E3e.forEach(t),Zgo=i(M),Kp=n(M,"LI",{});var C3e=s(Kp);cae=n(C3e,"STRONG",{});var FYr=s(cae);eho=r(FYr,"imagegpt"),FYr.forEach(t),oho=r(C3e," \u2014 "),l$=n(C3e,"A",{href:!0});var TYr=s(l$);rho=r(TYr,"ImageGPTModel"),TYr.forEach(t),tho=r(C3e," (ImageGPT model)"),C3e.forEach(t),aho=i(M),Zp=n(M,"LI",{});var w3e=s(Zp);fae=n(w3e,"STRONG",{});var MYr=s(fae);nho=r(MYr,"layoutlm"),MYr.forEach(t),sho=r(w3e," \u2014 "),i$=n(w3e,"A",{href:!0});var EYr=s(i$);lho=r(EYr,"LayoutLMModel"),EYr.forEach(t),iho=r(w3e," (LayoutLM model)"),w3e.forEach(t),dho=i(M),e_=n(M,"LI",{});var A3e=s(e_);mae=n(A3e,"STRONG",{});var CYr=s(mae);cho=r(CYr,"layoutlmv2"),CYr.forEach(t),fho=r(A3e," \u2014 "),d$=n(A3e,"A",{href:!0});var wYr=s(d$);mho=r(wYr,"LayoutLMv2Model"),wYr.forEach(t),gho=r(A3e," (LayoutLMv2 model)"),A3e.forEach(t),hho=i(M),o_=n(M,"LI",{});var y3e=s(o_);gae=n(y3e,"STRONG",{});var AYr=s(gae);pho=r(AYr,"led"),AYr.forEach(t),_ho=r(y3e," \u2014 "),c$=n(y3e,"A",{href:!0});var yYr=s(c$);uho=r(yYr,"LEDModel"),yYr.forEach(t),bho=r(y3e," (LED model)"),y3e.forEach(t),vho=i(M),r_=n(M,"LI",{});var L3e=s(r_);hae=n(L3e,"STRONG",{});var LYr=s(hae);Fho=r(LYr,"longformer"),LYr.forEach(t),Tho=r(L3e," \u2014 "),f$=n(L3e,"A",{href:!0});var xYr=s(f$);Mho=r(xYr,"LongformerModel"),xYr.forEach(t),Eho=r(L3e," (Longformer model)"),L3e.forEach(t),Cho=i(M),t_=n(M,"LI",{});var x3e=s(t_);pae=n(x3e,"STRONG",{});var kYr=s(pae);who=r(kYr,"longt5"),kYr.forEach(t),Aho=r(x3e," \u2014 "),m$=n(x3e,"A",{href:!0});var SYr=s(m$);yho=r(SYr,"LongT5Model"),SYr.forEach(t),Lho=r(x3e," (LongT5 model)"),x3e.forEach(t),xho=i(M),a_=n(M,"LI",{});var k3e=s(a_);_ae=n(k3e,"STRONG",{});var RYr=s(_ae);kho=r(RYr,"luke"),RYr.forEach(t),Sho=r(k3e," \u2014 "),g$=n(k3e,"A",{href:!0});var BYr=s(g$);Rho=r(BYr,"LukeModel"),BYr.forEach(t),Bho=r(k3e," (LUKE model)"),k3e.forEach(t),Pho=i(M),n_=n(M,"LI",{});var S3e=s(n_);uae=n(S3e,"STRONG",{});var PYr=s(uae);$ho=r(PYr,"lxmert"),PYr.forEach(t),Iho=r(S3e," \u2014 "),h$=n(S3e,"A",{href:!0});var $Yr=s(h$);qho=r($Yr,"LxmertModel"),$Yr.forEach(t),Nho=r(S3e," (LXMERT model)"),S3e.forEach(t),jho=i(M),s_=n(M,"LI",{});var R3e=s(s_);bae=n(R3e,"STRONG",{});var IYr=s(bae);Dho=r(IYr,"m2m_100"),IYr.forEach(t),Gho=r(R3e," \u2014 "),p$=n(R3e,"A",{href:!0});var qYr=s(p$);Oho=r(qYr,"M2M100Model"),qYr.forEach(t),Vho=r(R3e," (M2M100 model)"),R3e.forEach(t),Xho=i(M),l_=n(M,"LI",{});var B3e=s(l_);vae=n(B3e,"STRONG",{});var NYr=s(vae);zho=r(NYr,"marian"),NYr.forEach(t),Qho=r(B3e," \u2014 "),_$=n(B3e,"A",{href:!0});var jYr=s(_$);Who=r(jYr,"MarianModel"),jYr.forEach(t),Hho=r(B3e," (Marian model)"),B3e.forEach(t),Uho=i(M),i_=n(M,"LI",{});var P3e=s(i_);Fae=n(P3e,"STRONG",{});var DYr=s(Fae);Jho=r(DYr,"maskformer"),DYr.forEach(t),Yho=r(P3e," \u2014 "),u$=n(P3e,"A",{href:!0});var GYr=s(u$);Kho=r(GYr,"MaskFormerModel"),GYr.forEach(t),Zho=r(P3e," (MaskFormer model)"),P3e.forEach(t),epo=i(M),d_=n(M,"LI",{});var $3e=s(d_);Tae=n($3e,"STRONG",{});var OYr=s(Tae);opo=r(OYr,"mbart"),OYr.forEach(t),rpo=r($3e," \u2014 "),b$=n($3e,"A",{href:!0});var VYr=s(b$);tpo=r(VYr,"MBartModel"),VYr.forEach(t),apo=r($3e," (mBART model)"),$3e.forEach(t),npo=i(M),c_=n(M,"LI",{});var I3e=s(c_);Mae=n(I3e,"STRONG",{});var XYr=s(Mae);spo=r(XYr,"megatron-bert"),XYr.forEach(t),lpo=r(I3e," \u2014 "),v$=n(I3e,"A",{href:!0});var zYr=s(v$);ipo=r(zYr,"MegatronBertModel"),zYr.forEach(t),dpo=r(I3e," (MegatronBert model)"),I3e.forEach(t),cpo=i(M),f_=n(M,"LI",{});var q3e=s(f_);Eae=n(q3e,"STRONG",{});var QYr=s(Eae);fpo=r(QYr,"mobilebert"),QYr.forEach(t),mpo=r(q3e," \u2014 "),F$=n(q3e,"A",{href:!0});var WYr=s(F$);gpo=r(WYr,"MobileBertModel"),WYr.forEach(t),hpo=r(q3e," (MobileBERT model)"),q3e.forEach(t),ppo=i(M),m_=n(M,"LI",{});var N3e=s(m_);Cae=n(N3e,"STRONG",{});var HYr=s(Cae);_po=r(HYr,"mpnet"),HYr.forEach(t),upo=r(N3e," \u2014 "),T$=n(N3e,"A",{href:!0});var UYr=s(T$);bpo=r(UYr,"MPNetModel"),UYr.forEach(t),vpo=r(N3e," (MPNet model)"),N3e.forEach(t),Fpo=i(M),g_=n(M,"LI",{});var j3e=s(g_);wae=n(j3e,"STRONG",{});var JYr=s(wae);Tpo=r(JYr,"mt5"),JYr.forEach(t),Mpo=r(j3e," \u2014 "),M$=n(j3e,"A",{href:!0});var YYr=s(M$);Epo=r(YYr,"MT5Model"),YYr.forEach(t),Cpo=r(j3e," (mT5 model)"),j3e.forEach(t),wpo=i(M),h_=n(M,"LI",{});var D3e=s(h_);Aae=n(D3e,"STRONG",{});var KYr=s(Aae);Apo=r(KYr,"nystromformer"),KYr.forEach(t),ypo=r(D3e," \u2014 "),E$=n(D3e,"A",{href:!0});var ZYr=s(E$);Lpo=r(ZYr,"NystromformerModel"),ZYr.forEach(t),xpo=r(D3e," (Nystromformer model)"),D3e.forEach(t),kpo=i(M),p_=n(M,"LI",{});var G3e=s(p_);yae=n(G3e,"STRONG",{});var eKr=s(yae);Spo=r(eKr,"openai-gpt"),eKr.forEach(t),Rpo=r(G3e," \u2014 "),C$=n(G3e,"A",{href:!0});var oKr=s(C$);Bpo=r(oKr,"OpenAIGPTModel"),oKr.forEach(t),Ppo=r(G3e," (OpenAI GPT model)"),G3e.forEach(t),$po=i(M),__=n(M,"LI",{});var O3e=s(__);Lae=n(O3e,"STRONG",{});var rKr=s(Lae);Ipo=r(rKr,"pegasus"),rKr.forEach(t),qpo=r(O3e," \u2014 "),w$=n(O3e,"A",{href:!0});var tKr=s(w$);Npo=r(tKr,"PegasusModel"),tKr.forEach(t),jpo=r(O3e," (Pegasus model)"),O3e.forEach(t),Dpo=i(M),u_=n(M,"LI",{});var V3e=s(u_);xae=n(V3e,"STRONG",{});var aKr=s(xae);Gpo=r(aKr,"perceiver"),aKr.forEach(t),Opo=r(V3e," \u2014 "),A$=n(V3e,"A",{href:!0});var nKr=s(A$);Vpo=r(nKr,"PerceiverModel"),nKr.forEach(t),Xpo=r(V3e," (Perceiver model)"),V3e.forEach(t),zpo=i(M),b_=n(M,"LI",{});var X3e=s(b_);kae=n(X3e,"STRONG",{});var sKr=s(kae);Qpo=r(sKr,"plbart"),sKr.forEach(t),Wpo=r(X3e," \u2014 "),y$=n(X3e,"A",{href:!0});var lKr=s(y$);Hpo=r(lKr,"PLBartModel"),lKr.forEach(t),Upo=r(X3e," (PLBart model)"),X3e.forEach(t),Jpo=i(M),v_=n(M,"LI",{});var z3e=s(v_);Sae=n(z3e,"STRONG",{});var iKr=s(Sae);Ypo=r(iKr,"poolformer"),iKr.forEach(t),Kpo=r(z3e," \u2014 "),L$=n(z3e,"A",{href:!0});var dKr=s(L$);Zpo=r(dKr,"PoolFormerModel"),dKr.forEach(t),e_o=r(z3e," (PoolFormer model)"),z3e.forEach(t),o_o=i(M),F_=n(M,"LI",{});var Q3e=s(F_);Rae=n(Q3e,"STRONG",{});var cKr=s(Rae);r_o=r(cKr,"prophetnet"),cKr.forEach(t),t_o=r(Q3e," \u2014 "),x$=n(Q3e,"A",{href:!0});var fKr=s(x$);a_o=r(fKr,"ProphetNetModel"),fKr.forEach(t),n_o=r(Q3e," (ProphetNet model)"),Q3e.forEach(t),s_o=i(M),T_=n(M,"LI",{});var W3e=s(T_);Bae=n(W3e,"STRONG",{});var mKr=s(Bae);l_o=r(mKr,"qdqbert"),mKr.forEach(t),i_o=r(W3e," \u2014 "),k$=n(W3e,"A",{href:!0});var gKr=s(k$);d_o=r(gKr,"QDQBertModel"),gKr.forEach(t),c_o=r(W3e," (QDQBert model)"),W3e.forEach(t),f_o=i(M),M_=n(M,"LI",{});var H3e=s(M_);Pae=n(H3e,"STRONG",{});var hKr=s(Pae);m_o=r(hKr,"reformer"),hKr.forEach(t),g_o=r(H3e," \u2014 "),S$=n(H3e,"A",{href:!0});var pKr=s(S$);h_o=r(pKr,"ReformerModel"),pKr.forEach(t),p_o=r(H3e," (Reformer model)"),H3e.forEach(t),__o=i(M),E_=n(M,"LI",{});var U3e=s(E_);$ae=n(U3e,"STRONG",{});var _Kr=s($ae);u_o=r(_Kr,"regnet"),_Kr.forEach(t),b_o=r(U3e," \u2014 "),R$=n(U3e,"A",{href:!0});var uKr=s(R$);v_o=r(uKr,"RegNetModel"),uKr.forEach(t),F_o=r(U3e," (RegNet model)"),U3e.forEach(t),T_o=i(M),C_=n(M,"LI",{});var J3e=s(C_);Iae=n(J3e,"STRONG",{});var bKr=s(Iae);M_o=r(bKr,"rembert"),bKr.forEach(t),E_o=r(J3e," \u2014 "),B$=n(J3e,"A",{href:!0});var vKr=s(B$);C_o=r(vKr,"RemBertModel"),vKr.forEach(t),w_o=r(J3e," (RemBERT model)"),J3e.forEach(t),A_o=i(M),w_=n(M,"LI",{});var Y3e=s(w_);qae=n(Y3e,"STRONG",{});var FKr=s(qae);y_o=r(FKr,"resnet"),FKr.forEach(t),L_o=r(Y3e," \u2014 "),P$=n(Y3e,"A",{href:!0});var TKr=s(P$);x_o=r(TKr,"ResNetModel"),TKr.forEach(t),k_o=r(Y3e," (ResNet model)"),Y3e.forEach(t),S_o=i(M),A_=n(M,"LI",{});var K3e=s(A_);Nae=n(K3e,"STRONG",{});var MKr=s(Nae);R_o=r(MKr,"retribert"),MKr.forEach(t),B_o=r(K3e," \u2014 "),$$=n(K3e,"A",{href:!0});var EKr=s($$);P_o=r(EKr,"RetriBertModel"),EKr.forEach(t),$_o=r(K3e," (RetriBERT model)"),K3e.forEach(t),I_o=i(M),y_=n(M,"LI",{});var Z3e=s(y_);jae=n(Z3e,"STRONG",{});var CKr=s(jae);q_o=r(CKr,"roberta"),CKr.forEach(t),N_o=r(Z3e," \u2014 "),I$=n(Z3e,"A",{href:!0});var wKr=s(I$);j_o=r(wKr,"RobertaModel"),wKr.forEach(t),D_o=r(Z3e," (RoBERTa model)"),Z3e.forEach(t),G_o=i(M),L_=n(M,"LI",{});var eCe=s(L_);Dae=n(eCe,"STRONG",{});var AKr=s(Dae);O_o=r(AKr,"roformer"),AKr.forEach(t),V_o=r(eCe," \u2014 "),q$=n(eCe,"A",{href:!0});var yKr=s(q$);X_o=r(yKr,"RoFormerModel"),yKr.forEach(t),z_o=r(eCe," (RoFormer model)"),eCe.forEach(t),Q_o=i(M),x_=n(M,"LI",{});var oCe=s(x_);Gae=n(oCe,"STRONG",{});var LKr=s(Gae);W_o=r(LKr,"segformer"),LKr.forEach(t),H_o=r(oCe," \u2014 "),N$=n(oCe,"A",{href:!0});var xKr=s(N$);U_o=r(xKr,"SegformerModel"),xKr.forEach(t),J_o=r(oCe," (SegFormer model)"),oCe.forEach(t),Y_o=i(M),k_=n(M,"LI",{});var rCe=s(k_);Oae=n(rCe,"STRONG",{});var kKr=s(Oae);K_o=r(kKr,"sew"),kKr.forEach(t),Z_o=r(rCe," \u2014 "),j$=n(rCe,"A",{href:!0});var SKr=s(j$);euo=r(SKr,"SEWModel"),SKr.forEach(t),ouo=r(rCe," (SEW model)"),rCe.forEach(t),ruo=i(M),S_=n(M,"LI",{});var tCe=s(S_);Vae=n(tCe,"STRONG",{});var RKr=s(Vae);tuo=r(RKr,"sew-d"),RKr.forEach(t),auo=r(tCe," \u2014 "),D$=n(tCe,"A",{href:!0});var BKr=s(D$);nuo=r(BKr,"SEWDModel"),BKr.forEach(t),suo=r(tCe," (SEW-D model)"),tCe.forEach(t),luo=i(M),R_=n(M,"LI",{});var aCe=s(R_);Xae=n(aCe,"STRONG",{});var PKr=s(Xae);iuo=r(PKr,"speech_to_text"),PKr.forEach(t),duo=r(aCe," \u2014 "),G$=n(aCe,"A",{href:!0});var $Kr=s(G$);cuo=r($Kr,"Speech2TextModel"),$Kr.forEach(t),fuo=r(aCe," (Speech2Text model)"),aCe.forEach(t),muo=i(M),B_=n(M,"LI",{});var nCe=s(B_);zae=n(nCe,"STRONG",{});var IKr=s(zae);guo=r(IKr,"splinter"),IKr.forEach(t),huo=r(nCe," \u2014 "),O$=n(nCe,"A",{href:!0});var qKr=s(O$);puo=r(qKr,"SplinterModel"),qKr.forEach(t),_uo=r(nCe," (Splinter model)"),nCe.forEach(t),uuo=i(M),P_=n(M,"LI",{});var sCe=s(P_);Qae=n(sCe,"STRONG",{});var NKr=s(Qae);buo=r(NKr,"squeezebert"),NKr.forEach(t),vuo=r(sCe," \u2014 "),V$=n(sCe,"A",{href:!0});var jKr=s(V$);Fuo=r(jKr,"SqueezeBertModel"),jKr.forEach(t),Tuo=r(sCe," (SqueezeBERT model)"),sCe.forEach(t),Muo=i(M),$_=n(M,"LI",{});var lCe=s($_);Wae=n(lCe,"STRONG",{});var DKr=s(Wae);Euo=r(DKr,"swin"),DKr.forEach(t),Cuo=r(lCe," \u2014 "),X$=n(lCe,"A",{href:!0});var GKr=s(X$);wuo=r(GKr,"SwinModel"),GKr.forEach(t),Auo=r(lCe," (Swin model)"),lCe.forEach(t),yuo=i(M),I_=n(M,"LI",{});var iCe=s(I_);Hae=n(iCe,"STRONG",{});var OKr=s(Hae);Luo=r(OKr,"t5"),OKr.forEach(t),xuo=r(iCe," \u2014 "),z$=n(iCe,"A",{href:!0});var VKr=s(z$);kuo=r(VKr,"T5Model"),VKr.forEach(t),Suo=r(iCe," (T5 model)"),iCe.forEach(t),Ruo=i(M),q_=n(M,"LI",{});var dCe=s(q_);Uae=n(dCe,"STRONG",{});var XKr=s(Uae);Buo=r(XKr,"tapas"),XKr.forEach(t),Puo=r(dCe," \u2014 "),Q$=n(dCe,"A",{href:!0});var zKr=s(Q$);$uo=r(zKr,"TapasModel"),zKr.forEach(t),Iuo=r(dCe," (TAPAS model)"),dCe.forEach(t),quo=i(M),N_=n(M,"LI",{});var cCe=s(N_);Jae=n(cCe,"STRONG",{});var QKr=s(Jae);Nuo=r(QKr,"transfo-xl"),QKr.forEach(t),juo=r(cCe," \u2014 "),W$=n(cCe,"A",{href:!0});var WKr=s(W$);Duo=r(WKr,"TransfoXLModel"),WKr.forEach(t),Guo=r(cCe," (Transformer-XL model)"),cCe.forEach(t),Ouo=i(M),j_=n(M,"LI",{});var fCe=s(j_);Yae=n(fCe,"STRONG",{});var HKr=s(Yae);Vuo=r(HKr,"unispeech"),HKr.forEach(t),Xuo=r(fCe," \u2014 "),H$=n(fCe,"A",{href:!0});var UKr=s(H$);zuo=r(UKr,"UniSpeechModel"),UKr.forEach(t),Quo=r(fCe," (UniSpeech model)"),fCe.forEach(t),Wuo=i(M),D_=n(M,"LI",{});var mCe=s(D_);Kae=n(mCe,"STRONG",{});var JKr=s(Kae);Huo=r(JKr,"unispeech-sat"),JKr.forEach(t),Uuo=r(mCe," \u2014 "),U$=n(mCe,"A",{href:!0});var YKr=s(U$);Juo=r(YKr,"UniSpeechSatModel"),YKr.forEach(t),Yuo=r(mCe," (UniSpeechSat model)"),mCe.forEach(t),Kuo=i(M),G_=n(M,"LI",{});var gCe=s(G_);Zae=n(gCe,"STRONG",{});var KKr=s(Zae);Zuo=r(KKr,"van"),KKr.forEach(t),e2o=r(gCe," \u2014 "),J$=n(gCe,"A",{href:!0});var ZKr=s(J$);o2o=r(ZKr,"VanModel"),ZKr.forEach(t),r2o=r(gCe," (VAN model)"),gCe.forEach(t),t2o=i(M),O_=n(M,"LI",{});var hCe=s(O_);ene=n(hCe,"STRONG",{});var eZr=s(ene);a2o=r(eZr,"vilt"),eZr.forEach(t),n2o=r(hCe," \u2014 "),Y$=n(hCe,"A",{href:!0});var oZr=s(Y$);s2o=r(oZr,"ViltModel"),oZr.forEach(t),l2o=r(hCe," (ViLT model)"),hCe.forEach(t),i2o=i(M),V_=n(M,"LI",{});var pCe=s(V_);one=n(pCe,"STRONG",{});var rZr=s(one);d2o=r(rZr,"vision-text-dual-encoder"),rZr.forEach(t),c2o=r(pCe," \u2014 "),K$=n(pCe,"A",{href:!0});var tZr=s(K$);f2o=r(tZr,"VisionTextDualEncoderModel"),tZr.forEach(t),m2o=r(pCe," (VisionTextDualEncoder model)"),pCe.forEach(t),g2o=i(M),X_=n(M,"LI",{});var _Ce=s(X_);rne=n(_Ce,"STRONG",{});var aZr=s(rne);h2o=r(aZr,"visual_bert"),aZr.forEach(t),p2o=r(_Ce," \u2014 "),Z$=n(_Ce,"A",{href:!0});var nZr=s(Z$);_2o=r(nZr,"VisualBertModel"),nZr.forEach(t),u2o=r(_Ce," (VisualBert model)"),_Ce.forEach(t),b2o=i(M),z_=n(M,"LI",{});var uCe=s(z_);tne=n(uCe,"STRONG",{});var sZr=s(tne);v2o=r(sZr,"vit"),sZr.forEach(t),F2o=r(uCe," \u2014 "),eI=n(uCe,"A",{href:!0});var lZr=s(eI);T2o=r(lZr,"ViTModel"),lZr.forEach(t),M2o=r(uCe," (ViT model)"),uCe.forEach(t),E2o=i(M),Q_=n(M,"LI",{});var bCe=s(Q_);ane=n(bCe,"STRONG",{});var iZr=s(ane);C2o=r(iZr,"vit_mae"),iZr.forEach(t),w2o=r(bCe," \u2014 "),oI=n(bCe,"A",{href:!0});var dZr=s(oI);A2o=r(dZr,"ViTMAEModel"),dZr.forEach(t),y2o=r(bCe," (ViTMAE model)"),bCe.forEach(t),L2o=i(M),W_=n(M,"LI",{});var vCe=s(W_);nne=n(vCe,"STRONG",{});var cZr=s(nne);x2o=r(cZr,"wav2vec2"),cZr.forEach(t),k2o=r(vCe," \u2014 "),rI=n(vCe,"A",{href:!0});var fZr=s(rI);S2o=r(fZr,"Wav2Vec2Model"),fZr.forEach(t),R2o=r(vCe," (Wav2Vec2 model)"),vCe.forEach(t),B2o=i(M),H_=n(M,"LI",{});var FCe=s(H_);sne=n(FCe,"STRONG",{});var mZr=s(sne);P2o=r(mZr,"wavlm"),mZr.forEach(t),$2o=r(FCe," \u2014 "),tI=n(FCe,"A",{href:!0});var gZr=s(tI);I2o=r(gZr,"WavLMModel"),gZr.forEach(t),q2o=r(FCe," (WavLM model)"),FCe.forEach(t),N2o=i(M),U_=n(M,"LI",{});var TCe=s(U_);lne=n(TCe,"STRONG",{});var hZr=s(lne);j2o=r(hZr,"xglm"),hZr.forEach(t),D2o=r(TCe," \u2014 "),aI=n(TCe,"A",{href:!0});var pZr=s(aI);G2o=r(pZr,"XGLMModel"),pZr.forEach(t),O2o=r(TCe," (XGLM model)"),TCe.forEach(t),V2o=i(M),J_=n(M,"LI",{});var MCe=s(J_);ine=n(MCe,"STRONG",{});var _Zr=s(ine);X2o=r(_Zr,"xlm"),_Zr.forEach(t),z2o=r(MCe," \u2014 "),nI=n(MCe,"A",{href:!0});var uZr=s(nI);Q2o=r(uZr,"XLMModel"),uZr.forEach(t),W2o=r(MCe," (XLM model)"),MCe.forEach(t),H2o=i(M),Y_=n(M,"LI",{});var ECe=s(Y_);dne=n(ECe,"STRONG",{});var bZr=s(dne);U2o=r(bZr,"xlm-prophetnet"),bZr.forEach(t),J2o=r(ECe," \u2014 "),sI=n(ECe,"A",{href:!0});var vZr=s(sI);Y2o=r(vZr,"XLMProphetNetModel"),vZr.forEach(t),K2o=r(ECe," (XLMProphetNet model)"),ECe.forEach(t),Z2o=i(M),K_=n(M,"LI",{});var CCe=s(K_);cne=n(CCe,"STRONG",{});var FZr=s(cne);e1o=r(FZr,"xlm-roberta"),FZr.forEach(t),o1o=r(CCe," \u2014 "),lI=n(CCe,"A",{href:!0});var TZr=s(lI);r1o=r(TZr,"XLMRobertaModel"),TZr.forEach(t),t1o=r(CCe," (XLM-RoBERTa model)"),CCe.forEach(t),a1o=i(M),Z_=n(M,"LI",{});var wCe=s(Z_);fne=n(wCe,"STRONG",{});var MZr=s(fne);n1o=r(MZr,"xlm-roberta-xl"),MZr.forEach(t),s1o=r(wCe," \u2014 "),iI=n(wCe,"A",{href:!0});var EZr=s(iI);l1o=r(EZr,"XLMRobertaXLModel"),EZr.forEach(t),i1o=r(wCe," (XLM-RoBERTa-XL model)"),wCe.forEach(t),d1o=i(M),eu=n(M,"LI",{});var ACe=s(eu);mne=n(ACe,"STRONG",{});var CZr=s(mne);c1o=r(CZr,"xlnet"),CZr.forEach(t),f1o=r(ACe," \u2014 "),dI=n(ACe,"A",{href:!0});var wZr=s(dI);m1o=r(wZr,"XLNetModel"),wZr.forEach(t),g1o=r(ACe," (XLNet model)"),ACe.forEach(t),h1o=i(M),ou=n(M,"LI",{});var yCe=s(ou);gne=n(yCe,"STRONG",{});var AZr=s(gne);p1o=r(AZr,"yoso"),AZr.forEach(t),_1o=r(yCe," \u2014 "),cI=n(yCe,"A",{href:!0});var yZr=s(cI);u1o=r(yZr,"YosoModel"),yZr.forEach(t),b1o=r(yCe," (YOSO model)"),yCe.forEach(t),M.forEach(t),v1o=i(Dt),ru=n(Dt,"P",{});var LCe=s(ru);F1o=r(LCe,"The model is set in evaluation mode by default using "),hne=n(LCe,"CODE",{});var LZr=s(hne);T1o=r(LZr,"model.eval()"),LZr.forEach(t),M1o=r(LCe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pne=n(LCe,"CODE",{});var xZr=s(pne);E1o=r(xZr,"model.train()"),xZr.forEach(t),LCe.forEach(t),C1o=i(Dt),_ne=n(Dt,"P",{});var kZr=s(_ne);w1o=r(kZr,"Examples:"),kZr.forEach(t),A1o=i(Dt),m(j3.$$.fragment,Dt),Dt.forEach(t),rl.forEach(t),WPe=i(c),dd=n(c,"H2",{class:!0});var rqe=s(dd);tu=n(rqe,"A",{id:!0,class:!0,href:!0});var SZr=s(tu);une=n(SZr,"SPAN",{});var RZr=s(une);m(D3.$$.fragment,RZr),RZr.forEach(t),SZr.forEach(t),y1o=i(rqe),bne=n(rqe,"SPAN",{});var BZr=s(bne);L1o=r(BZr,"AutoModelForPreTraining"),BZr.forEach(t),rqe.forEach(t),HPe=i(c),Yo=n(c,"DIV",{class:!0});var al=s(Yo);m(G3.$$.fragment,al),x1o=i(al),cd=n(al,"P",{});var IJ=s(cd);k1o=r(IJ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),fI=n(IJ,"A",{href:!0});var PZr=s(fI);S1o=r(PZr,"from_pretrained()"),PZr.forEach(t),R1o=r(IJ," class method or the "),mI=n(IJ,"A",{href:!0});var $Zr=s(mI);B1o=r($Zr,"from_config()"),$Zr.forEach(t),P1o=r(IJ,` class
method.`),IJ.forEach(t),$1o=i(al),O3=n(al,"P",{});var tqe=s(O3);I1o=r(tqe,"This class cannot be instantiated directly using "),vne=n(tqe,"CODE",{});var IZr=s(vne);q1o=r(IZr,"__init__()"),IZr.forEach(t),N1o=r(tqe," (throws an error)."),tqe.forEach(t),j1o=i(al),zr=n(al,"DIV",{class:!0});var nl=s(zr);m(V3.$$.fragment,nl),D1o=i(nl),Fne=n(nl,"P",{});var qZr=s(Fne);G1o=r(qZr,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),qZr.forEach(t),O1o=i(nl),fd=n(nl,"P",{});var qJ=s(fd);V1o=r(qJ,`Note:
Loading a model from its configuration file does `),Tne=n(qJ,"STRONG",{});var NZr=s(Tne);X1o=r(NZr,"not"),NZr.forEach(t),z1o=r(qJ,` load the model weights. It only affects the
model\u2019s configuration. Use `),gI=n(qJ,"A",{href:!0});var jZr=s(gI);Q1o=r(jZr,"from_pretrained()"),jZr.forEach(t),W1o=r(qJ," to load the model weights."),qJ.forEach(t),H1o=i(nl),Mne=n(nl,"P",{});var DZr=s(Mne);U1o=r(DZr,"Examples:"),DZr.forEach(t),J1o=i(nl),m(X3.$$.fragment,nl),nl.forEach(t),Y1o=i(al),De=n(al,"DIV",{class:!0});var Gt=s(De);m(z3.$$.fragment,Gt),K1o=i(Gt),Ene=n(Gt,"P",{});var GZr=s(Ene);Z1o=r(GZr,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),GZr.forEach(t),ebo=i(Gt),za=n(Gt,"P",{});var t5=s(za);obo=r(t5,"The model class to instantiate is selected based on the "),Cne=n(t5,"CODE",{});var OZr=s(Cne);rbo=r(OZr,"model_type"),OZr.forEach(t),tbo=r(t5,` property of the config object (either
passed as an argument or loaded from `),wne=n(t5,"CODE",{});var VZr=s(wne);abo=r(VZr,"pretrained_model_name_or_path"),VZr.forEach(t),nbo=r(t5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ane=n(t5,"CODE",{});var XZr=s(Ane);sbo=r(XZr,"pretrained_model_name_or_path"),XZr.forEach(t),lbo=r(t5,":"),t5.forEach(t),ibo=i(Gt),S=n(Gt,"UL",{});var B=s(S);au=n(B,"LI",{});var xCe=s(au);yne=n(xCe,"STRONG",{});var zZr=s(yne);dbo=r(zZr,"albert"),zZr.forEach(t),cbo=r(xCe," \u2014 "),hI=n(xCe,"A",{href:!0});var QZr=s(hI);fbo=r(QZr,"AlbertForPreTraining"),QZr.forEach(t),mbo=r(xCe," (ALBERT model)"),xCe.forEach(t),gbo=i(B),nu=n(B,"LI",{});var kCe=s(nu);Lne=n(kCe,"STRONG",{});var WZr=s(Lne);hbo=r(WZr,"bart"),WZr.forEach(t),pbo=r(kCe," \u2014 "),pI=n(kCe,"A",{href:!0});var HZr=s(pI);_bo=r(HZr,"BartForConditionalGeneration"),HZr.forEach(t),ubo=r(kCe," (BART model)"),kCe.forEach(t),bbo=i(B),su=n(B,"LI",{});var SCe=s(su);xne=n(SCe,"STRONG",{});var UZr=s(xne);vbo=r(UZr,"bert"),UZr.forEach(t),Fbo=r(SCe," \u2014 "),_I=n(SCe,"A",{href:!0});var JZr=s(_I);Tbo=r(JZr,"BertForPreTraining"),JZr.forEach(t),Mbo=r(SCe," (BERT model)"),SCe.forEach(t),Ebo=i(B),lu=n(B,"LI",{});var RCe=s(lu);kne=n(RCe,"STRONG",{});var YZr=s(kne);Cbo=r(YZr,"big_bird"),YZr.forEach(t),wbo=r(RCe," \u2014 "),uI=n(RCe,"A",{href:!0});var KZr=s(uI);Abo=r(KZr,"BigBirdForPreTraining"),KZr.forEach(t),ybo=r(RCe," (BigBird model)"),RCe.forEach(t),Lbo=i(B),iu=n(B,"LI",{});var BCe=s(iu);Sne=n(BCe,"STRONG",{});var ZZr=s(Sne);xbo=r(ZZr,"camembert"),ZZr.forEach(t),kbo=r(BCe," \u2014 "),bI=n(BCe,"A",{href:!0});var eet=s(bI);Sbo=r(eet,"CamembertForMaskedLM"),eet.forEach(t),Rbo=r(BCe," (CamemBERT model)"),BCe.forEach(t),Bbo=i(B),du=n(B,"LI",{});var PCe=s(du);Rne=n(PCe,"STRONG",{});var oet=s(Rne);Pbo=r(oet,"ctrl"),oet.forEach(t),$bo=r(PCe," \u2014 "),vI=n(PCe,"A",{href:!0});var ret=s(vI);Ibo=r(ret,"CTRLLMHeadModel"),ret.forEach(t),qbo=r(PCe," (CTRL model)"),PCe.forEach(t),Nbo=i(B),cu=n(B,"LI",{});var $Ce=s(cu);Bne=n($Ce,"STRONG",{});var tet=s(Bne);jbo=r(tet,"data2vec-text"),tet.forEach(t),Dbo=r($Ce," \u2014 "),FI=n($Ce,"A",{href:!0});var aet=s(FI);Gbo=r(aet,"Data2VecTextForMaskedLM"),aet.forEach(t),Obo=r($Ce," (Data2VecText model)"),$Ce.forEach(t),Vbo=i(B),fu=n(B,"LI",{});var ICe=s(fu);Pne=n(ICe,"STRONG",{});var net=s(Pne);Xbo=r(net,"deberta"),net.forEach(t),zbo=r(ICe," \u2014 "),TI=n(ICe,"A",{href:!0});var set=s(TI);Qbo=r(set,"DebertaForMaskedLM"),set.forEach(t),Wbo=r(ICe," (DeBERTa model)"),ICe.forEach(t),Hbo=i(B),mu=n(B,"LI",{});var qCe=s(mu);$ne=n(qCe,"STRONG",{});var iet=s($ne);Ubo=r(iet,"deberta-v2"),iet.forEach(t),Jbo=r(qCe," \u2014 "),MI=n(qCe,"A",{href:!0});var det=s(MI);Ybo=r(det,"DebertaV2ForMaskedLM"),det.forEach(t),Kbo=r(qCe," (DeBERTa-v2 model)"),qCe.forEach(t),Zbo=i(B),gu=n(B,"LI",{});var NCe=s(gu);Ine=n(NCe,"STRONG",{});var cet=s(Ine);e6o=r(cet,"distilbert"),cet.forEach(t),o6o=r(NCe," \u2014 "),EI=n(NCe,"A",{href:!0});var fet=s(EI);r6o=r(fet,"DistilBertForMaskedLM"),fet.forEach(t),t6o=r(NCe," (DistilBERT model)"),NCe.forEach(t),a6o=i(B),hu=n(B,"LI",{});var jCe=s(hu);qne=n(jCe,"STRONG",{});var met=s(qne);n6o=r(met,"electra"),met.forEach(t),s6o=r(jCe," \u2014 "),CI=n(jCe,"A",{href:!0});var get=s(CI);l6o=r(get,"ElectraForPreTraining"),get.forEach(t),i6o=r(jCe," (ELECTRA model)"),jCe.forEach(t),d6o=i(B),pu=n(B,"LI",{});var DCe=s(pu);Nne=n(DCe,"STRONG",{});var het=s(Nne);c6o=r(het,"flaubert"),het.forEach(t),f6o=r(DCe," \u2014 "),wI=n(DCe,"A",{href:!0});var pet=s(wI);m6o=r(pet,"FlaubertWithLMHeadModel"),pet.forEach(t),g6o=r(DCe," (FlauBERT model)"),DCe.forEach(t),h6o=i(B),_u=n(B,"LI",{});var GCe=s(_u);jne=n(GCe,"STRONG",{});var _et=s(jne);p6o=r(_et,"fnet"),_et.forEach(t),_6o=r(GCe," \u2014 "),AI=n(GCe,"A",{href:!0});var uet=s(AI);u6o=r(uet,"FNetForPreTraining"),uet.forEach(t),b6o=r(GCe," (FNet model)"),GCe.forEach(t),v6o=i(B),uu=n(B,"LI",{});var OCe=s(uu);Dne=n(OCe,"STRONG",{});var bet=s(Dne);F6o=r(bet,"fsmt"),bet.forEach(t),T6o=r(OCe," \u2014 "),yI=n(OCe,"A",{href:!0});var vet=s(yI);M6o=r(vet,"FSMTForConditionalGeneration"),vet.forEach(t),E6o=r(OCe," (FairSeq Machine-Translation model)"),OCe.forEach(t),C6o=i(B),bu=n(B,"LI",{});var VCe=s(bu);Gne=n(VCe,"STRONG",{});var Fet=s(Gne);w6o=r(Fet,"funnel"),Fet.forEach(t),A6o=r(VCe," \u2014 "),LI=n(VCe,"A",{href:!0});var Tet=s(LI);y6o=r(Tet,"FunnelForPreTraining"),Tet.forEach(t),L6o=r(VCe," (Funnel Transformer model)"),VCe.forEach(t),x6o=i(B),vu=n(B,"LI",{});var XCe=s(vu);One=n(XCe,"STRONG",{});var Met=s(One);k6o=r(Met,"gpt2"),Met.forEach(t),S6o=r(XCe," \u2014 "),xI=n(XCe,"A",{href:!0});var Eet=s(xI);R6o=r(Eet,"GPT2LMHeadModel"),Eet.forEach(t),B6o=r(XCe," (OpenAI GPT-2 model)"),XCe.forEach(t),P6o=i(B),Fu=n(B,"LI",{});var zCe=s(Fu);Vne=n(zCe,"STRONG",{});var Cet=s(Vne);$6o=r(Cet,"ibert"),Cet.forEach(t),I6o=r(zCe," \u2014 "),kI=n(zCe,"A",{href:!0});var wet=s(kI);q6o=r(wet,"IBertForMaskedLM"),wet.forEach(t),N6o=r(zCe," (I-BERT model)"),zCe.forEach(t),j6o=i(B),Tu=n(B,"LI",{});var QCe=s(Tu);Xne=n(QCe,"STRONG",{});var Aet=s(Xne);D6o=r(Aet,"layoutlm"),Aet.forEach(t),G6o=r(QCe," \u2014 "),SI=n(QCe,"A",{href:!0});var yet=s(SI);O6o=r(yet,"LayoutLMForMaskedLM"),yet.forEach(t),V6o=r(QCe," (LayoutLM model)"),QCe.forEach(t),X6o=i(B),Mu=n(B,"LI",{});var WCe=s(Mu);zne=n(WCe,"STRONG",{});var Let=s(zne);z6o=r(Let,"longformer"),Let.forEach(t),Q6o=r(WCe," \u2014 "),RI=n(WCe,"A",{href:!0});var xet=s(RI);W6o=r(xet,"LongformerForMaskedLM"),xet.forEach(t),H6o=r(WCe," (Longformer model)"),WCe.forEach(t),U6o=i(B),Eu=n(B,"LI",{});var HCe=s(Eu);Qne=n(HCe,"STRONG",{});var ket=s(Qne);J6o=r(ket,"longt5"),ket.forEach(t),Y6o=r(HCe," \u2014 "),BI=n(HCe,"A",{href:!0});var Set=s(BI);K6o=r(Set,"LongT5ForConditionalGeneration"),Set.forEach(t),Z6o=r(HCe," (LongT5 model)"),HCe.forEach(t),evo=i(B),Cu=n(B,"LI",{});var UCe=s(Cu);Wne=n(UCe,"STRONG",{});var Ret=s(Wne);ovo=r(Ret,"lxmert"),Ret.forEach(t),rvo=r(UCe," \u2014 "),PI=n(UCe,"A",{href:!0});var Bet=s(PI);tvo=r(Bet,"LxmertForPreTraining"),Bet.forEach(t),avo=r(UCe," (LXMERT model)"),UCe.forEach(t),nvo=i(B),wu=n(B,"LI",{});var JCe=s(wu);Hne=n(JCe,"STRONG",{});var Pet=s(Hne);svo=r(Pet,"megatron-bert"),Pet.forEach(t),lvo=r(JCe," \u2014 "),$I=n(JCe,"A",{href:!0});var $et=s($I);ivo=r($et,"MegatronBertForPreTraining"),$et.forEach(t),dvo=r(JCe," (MegatronBert model)"),JCe.forEach(t),cvo=i(B),Au=n(B,"LI",{});var YCe=s(Au);Une=n(YCe,"STRONG",{});var Iet=s(Une);fvo=r(Iet,"mobilebert"),Iet.forEach(t),mvo=r(YCe," \u2014 "),II=n(YCe,"A",{href:!0});var qet=s(II);gvo=r(qet,"MobileBertForPreTraining"),qet.forEach(t),hvo=r(YCe," (MobileBERT model)"),YCe.forEach(t),pvo=i(B),yu=n(B,"LI",{});var KCe=s(yu);Jne=n(KCe,"STRONG",{});var Net=s(Jne);_vo=r(Net,"mpnet"),Net.forEach(t),uvo=r(KCe," \u2014 "),qI=n(KCe,"A",{href:!0});var jet=s(qI);bvo=r(jet,"MPNetForMaskedLM"),jet.forEach(t),vvo=r(KCe," (MPNet model)"),KCe.forEach(t),Fvo=i(B),Lu=n(B,"LI",{});var ZCe=s(Lu);Yne=n(ZCe,"STRONG",{});var Det=s(Yne);Tvo=r(Det,"openai-gpt"),Det.forEach(t),Mvo=r(ZCe," \u2014 "),NI=n(ZCe,"A",{href:!0});var Get=s(NI);Evo=r(Get,"OpenAIGPTLMHeadModel"),Get.forEach(t),Cvo=r(ZCe," (OpenAI GPT model)"),ZCe.forEach(t),wvo=i(B),xu=n(B,"LI",{});var ewe=s(xu);Kne=n(ewe,"STRONG",{});var Oet=s(Kne);Avo=r(Oet,"retribert"),Oet.forEach(t),yvo=r(ewe," \u2014 "),jI=n(ewe,"A",{href:!0});var Vet=s(jI);Lvo=r(Vet,"RetriBertModel"),Vet.forEach(t),xvo=r(ewe," (RetriBERT model)"),ewe.forEach(t),kvo=i(B),ku=n(B,"LI",{});var owe=s(ku);Zne=n(owe,"STRONG",{});var Xet=s(Zne);Svo=r(Xet,"roberta"),Xet.forEach(t),Rvo=r(owe," \u2014 "),DI=n(owe,"A",{href:!0});var zet=s(DI);Bvo=r(zet,"RobertaForMaskedLM"),zet.forEach(t),Pvo=r(owe," (RoBERTa model)"),owe.forEach(t),$vo=i(B),Su=n(B,"LI",{});var rwe=s(Su);ese=n(rwe,"STRONG",{});var Qet=s(ese);Ivo=r(Qet,"squeezebert"),Qet.forEach(t),qvo=r(rwe," \u2014 "),GI=n(rwe,"A",{href:!0});var Wet=s(GI);Nvo=r(Wet,"SqueezeBertForMaskedLM"),Wet.forEach(t),jvo=r(rwe," (SqueezeBERT model)"),rwe.forEach(t),Dvo=i(B),Ru=n(B,"LI",{});var twe=s(Ru);ose=n(twe,"STRONG",{});var Het=s(ose);Gvo=r(Het,"t5"),Het.forEach(t),Ovo=r(twe," \u2014 "),OI=n(twe,"A",{href:!0});var Uet=s(OI);Vvo=r(Uet,"T5ForConditionalGeneration"),Uet.forEach(t),Xvo=r(twe," (T5 model)"),twe.forEach(t),zvo=i(B),Bu=n(B,"LI",{});var awe=s(Bu);rse=n(awe,"STRONG",{});var Jet=s(rse);Qvo=r(Jet,"tapas"),Jet.forEach(t),Wvo=r(awe," \u2014 "),VI=n(awe,"A",{href:!0});var Yet=s(VI);Hvo=r(Yet,"TapasForMaskedLM"),Yet.forEach(t),Uvo=r(awe," (TAPAS model)"),awe.forEach(t),Jvo=i(B),Pu=n(B,"LI",{});var nwe=s(Pu);tse=n(nwe,"STRONG",{});var Ket=s(tse);Yvo=r(Ket,"transfo-xl"),Ket.forEach(t),Kvo=r(nwe," \u2014 "),XI=n(nwe,"A",{href:!0});var Zet=s(XI);Zvo=r(Zet,"TransfoXLLMHeadModel"),Zet.forEach(t),eFo=r(nwe," (Transformer-XL model)"),nwe.forEach(t),oFo=i(B),$u=n(B,"LI",{});var swe=s($u);ase=n(swe,"STRONG",{});var eot=s(ase);rFo=r(eot,"unispeech"),eot.forEach(t),tFo=r(swe," \u2014 "),zI=n(swe,"A",{href:!0});var oot=s(zI);aFo=r(oot,"UniSpeechForPreTraining"),oot.forEach(t),nFo=r(swe," (UniSpeech model)"),swe.forEach(t),sFo=i(B),Iu=n(B,"LI",{});var lwe=s(Iu);nse=n(lwe,"STRONG",{});var rot=s(nse);lFo=r(rot,"unispeech-sat"),rot.forEach(t),iFo=r(lwe," \u2014 "),QI=n(lwe,"A",{href:!0});var tot=s(QI);dFo=r(tot,"UniSpeechSatForPreTraining"),tot.forEach(t),cFo=r(lwe," (UniSpeechSat model)"),lwe.forEach(t),fFo=i(B),qu=n(B,"LI",{});var iwe=s(qu);sse=n(iwe,"STRONG",{});var aot=s(sse);mFo=r(aot,"visual_bert"),aot.forEach(t),gFo=r(iwe," \u2014 "),WI=n(iwe,"A",{href:!0});var not=s(WI);hFo=r(not,"VisualBertForPreTraining"),not.forEach(t),pFo=r(iwe," (VisualBert model)"),iwe.forEach(t),_Fo=i(B),Nu=n(B,"LI",{});var dwe=s(Nu);lse=n(dwe,"STRONG",{});var sot=s(lse);uFo=r(sot,"vit_mae"),sot.forEach(t),bFo=r(dwe," \u2014 "),HI=n(dwe,"A",{href:!0});var lot=s(HI);vFo=r(lot,"ViTMAEForPreTraining"),lot.forEach(t),FFo=r(dwe," (ViTMAE model)"),dwe.forEach(t),TFo=i(B),ju=n(B,"LI",{});var cwe=s(ju);ise=n(cwe,"STRONG",{});var iot=s(ise);MFo=r(iot,"wav2vec2"),iot.forEach(t),EFo=r(cwe," \u2014 "),UI=n(cwe,"A",{href:!0});var dot=s(UI);CFo=r(dot,"Wav2Vec2ForPreTraining"),dot.forEach(t),wFo=r(cwe," (Wav2Vec2 model)"),cwe.forEach(t),AFo=i(B),Du=n(B,"LI",{});var fwe=s(Du);dse=n(fwe,"STRONG",{});var cot=s(dse);yFo=r(cot,"xlm"),cot.forEach(t),LFo=r(fwe," \u2014 "),JI=n(fwe,"A",{href:!0});var fot=s(JI);xFo=r(fot,"XLMWithLMHeadModel"),fot.forEach(t),kFo=r(fwe," (XLM model)"),fwe.forEach(t),SFo=i(B),Gu=n(B,"LI",{});var mwe=s(Gu);cse=n(mwe,"STRONG",{});var mot=s(cse);RFo=r(mot,"xlm-roberta"),mot.forEach(t),BFo=r(mwe," \u2014 "),YI=n(mwe,"A",{href:!0});var got=s(YI);PFo=r(got,"XLMRobertaForMaskedLM"),got.forEach(t),$Fo=r(mwe," (XLM-RoBERTa model)"),mwe.forEach(t),IFo=i(B),Ou=n(B,"LI",{});var gwe=s(Ou);fse=n(gwe,"STRONG",{});var hot=s(fse);qFo=r(hot,"xlm-roberta-xl"),hot.forEach(t),NFo=r(gwe," \u2014 "),KI=n(gwe,"A",{href:!0});var pot=s(KI);jFo=r(pot,"XLMRobertaXLForMaskedLM"),pot.forEach(t),DFo=r(gwe," (XLM-RoBERTa-XL model)"),gwe.forEach(t),GFo=i(B),Vu=n(B,"LI",{});var hwe=s(Vu);mse=n(hwe,"STRONG",{});var _ot=s(mse);OFo=r(_ot,"xlnet"),_ot.forEach(t),VFo=r(hwe," \u2014 "),ZI=n(hwe,"A",{href:!0});var uot=s(ZI);XFo=r(uot,"XLNetLMHeadModel"),uot.forEach(t),zFo=r(hwe," (XLNet model)"),hwe.forEach(t),B.forEach(t),QFo=i(Gt),Xu=n(Gt,"P",{});var pwe=s(Xu);WFo=r(pwe,"The model is set in evaluation mode by default using "),gse=n(pwe,"CODE",{});var bot=s(gse);HFo=r(bot,"model.eval()"),bot.forEach(t),UFo=r(pwe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hse=n(pwe,"CODE",{});var vot=s(hse);JFo=r(vot,"model.train()"),vot.forEach(t),pwe.forEach(t),YFo=i(Gt),pse=n(Gt,"P",{});var Fot=s(pse);KFo=r(Fot,"Examples:"),Fot.forEach(t),ZFo=i(Gt),m(Q3.$$.fragment,Gt),Gt.forEach(t),al.forEach(t),UPe=i(c),md=n(c,"H2",{class:!0});var aqe=s(md);zu=n(aqe,"A",{id:!0,class:!0,href:!0});var Tot=s(zu);_se=n(Tot,"SPAN",{});var Mot=s(_se);m(W3.$$.fragment,Mot),Mot.forEach(t),Tot.forEach(t),eTo=i(aqe),use=n(aqe,"SPAN",{});var Eot=s(use);oTo=r(Eot,"AutoModelForCausalLM"),Eot.forEach(t),aqe.forEach(t),JPe=i(c),Ko=n(c,"DIV",{class:!0});var sl=s(Ko);m(H3.$$.fragment,sl),rTo=i(sl),gd=n(sl,"P",{});var NJ=s(gd);tTo=r(NJ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),eq=n(NJ,"A",{href:!0});var Cot=s(eq);aTo=r(Cot,"from_pretrained()"),Cot.forEach(t),nTo=r(NJ," class method or the "),oq=n(NJ,"A",{href:!0});var wot=s(oq);sTo=r(wot,"from_config()"),wot.forEach(t),lTo=r(NJ,` class
method.`),NJ.forEach(t),iTo=i(sl),U3=n(sl,"P",{});var nqe=s(U3);dTo=r(nqe,"This class cannot be instantiated directly using "),bse=n(nqe,"CODE",{});var Aot=s(bse);cTo=r(Aot,"__init__()"),Aot.forEach(t),fTo=r(nqe," (throws an error)."),nqe.forEach(t),mTo=i(sl),Qr=n(sl,"DIV",{class:!0});var ll=s(Qr);m(J3.$$.fragment,ll),gTo=i(ll),vse=n(ll,"P",{});var yot=s(vse);hTo=r(yot,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yot.forEach(t),pTo=i(ll),hd=n(ll,"P",{});var jJ=s(hd);_To=r(jJ,`Note:
Loading a model from its configuration file does `),Fse=n(jJ,"STRONG",{});var Lot=s(Fse);uTo=r(Lot,"not"),Lot.forEach(t),bTo=r(jJ,` load the model weights. It only affects the
model\u2019s configuration. Use `),rq=n(jJ,"A",{href:!0});var xot=s(rq);vTo=r(xot,"from_pretrained()"),xot.forEach(t),FTo=r(jJ," to load the model weights."),jJ.forEach(t),TTo=i(ll),Tse=n(ll,"P",{});var kot=s(Tse);MTo=r(kot,"Examples:"),kot.forEach(t),ETo=i(ll),m(Y3.$$.fragment,ll),ll.forEach(t),CTo=i(sl),Ge=n(sl,"DIV",{class:!0});var Ot=s(Ge);m(K3.$$.fragment,Ot),wTo=i(Ot),Mse=n(Ot,"P",{});var Sot=s(Mse);ATo=r(Sot,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Sot.forEach(t),yTo=i(Ot),Qa=n(Ot,"P",{});var a5=s(Qa);LTo=r(a5,"The model class to instantiate is selected based on the "),Ese=n(a5,"CODE",{});var Rot=s(Ese);xTo=r(Rot,"model_type"),Rot.forEach(t),kTo=r(a5,` property of the config object (either
passed as an argument or loaded from `),Cse=n(a5,"CODE",{});var Bot=s(Cse);STo=r(Bot,"pretrained_model_name_or_path"),Bot.forEach(t),RTo=r(a5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wse=n(a5,"CODE",{});var Pot=s(wse);BTo=r(Pot,"pretrained_model_name_or_path"),Pot.forEach(t),PTo=r(a5,":"),a5.forEach(t),$To=i(Ot),$=n(Ot,"UL",{});var q=s($);Qu=n(q,"LI",{});var _we=s(Qu);Ase=n(_we,"STRONG",{});var $ot=s(Ase);ITo=r($ot,"bart"),$ot.forEach(t),qTo=r(_we," \u2014 "),tq=n(_we,"A",{href:!0});var Iot=s(tq);NTo=r(Iot,"BartForCausalLM"),Iot.forEach(t),jTo=r(_we," (BART model)"),_we.forEach(t),DTo=i(q),Wu=n(q,"LI",{});var uwe=s(Wu);yse=n(uwe,"STRONG",{});var qot=s(yse);GTo=r(qot,"bert"),qot.forEach(t),OTo=r(uwe," \u2014 "),aq=n(uwe,"A",{href:!0});var Not=s(aq);VTo=r(Not,"BertLMHeadModel"),Not.forEach(t),XTo=r(uwe," (BERT model)"),uwe.forEach(t),zTo=i(q),Hu=n(q,"LI",{});var bwe=s(Hu);Lse=n(bwe,"STRONG",{});var jot=s(Lse);QTo=r(jot,"bert-generation"),jot.forEach(t),WTo=r(bwe," \u2014 "),nq=n(bwe,"A",{href:!0});var Dot=s(nq);HTo=r(Dot,"BertGenerationDecoder"),Dot.forEach(t),UTo=r(bwe," (Bert Generation model)"),bwe.forEach(t),JTo=i(q),Uu=n(q,"LI",{});var vwe=s(Uu);xse=n(vwe,"STRONG",{});var Got=s(xse);YTo=r(Got,"big_bird"),Got.forEach(t),KTo=r(vwe," \u2014 "),sq=n(vwe,"A",{href:!0});var Oot=s(sq);ZTo=r(Oot,"BigBirdForCausalLM"),Oot.forEach(t),e7o=r(vwe," (BigBird model)"),vwe.forEach(t),o7o=i(q),Ju=n(q,"LI",{});var Fwe=s(Ju);kse=n(Fwe,"STRONG",{});var Vot=s(kse);r7o=r(Vot,"bigbird_pegasus"),Vot.forEach(t),t7o=r(Fwe," \u2014 "),lq=n(Fwe,"A",{href:!0});var Xot=s(lq);a7o=r(Xot,"BigBirdPegasusForCausalLM"),Xot.forEach(t),n7o=r(Fwe," (BigBirdPegasus model)"),Fwe.forEach(t),s7o=i(q),Yu=n(q,"LI",{});var Twe=s(Yu);Sse=n(Twe,"STRONG",{});var zot=s(Sse);l7o=r(zot,"blenderbot"),zot.forEach(t),i7o=r(Twe," \u2014 "),iq=n(Twe,"A",{href:!0});var Qot=s(iq);d7o=r(Qot,"BlenderbotForCausalLM"),Qot.forEach(t),c7o=r(Twe," (Blenderbot model)"),Twe.forEach(t),f7o=i(q),Ku=n(q,"LI",{});var Mwe=s(Ku);Rse=n(Mwe,"STRONG",{});var Wot=s(Rse);m7o=r(Wot,"blenderbot-small"),Wot.forEach(t),g7o=r(Mwe," \u2014 "),dq=n(Mwe,"A",{href:!0});var Hot=s(dq);h7o=r(Hot,"BlenderbotSmallForCausalLM"),Hot.forEach(t),p7o=r(Mwe," (BlenderbotSmall model)"),Mwe.forEach(t),_7o=i(q),Zu=n(q,"LI",{});var Ewe=s(Zu);Bse=n(Ewe,"STRONG",{});var Uot=s(Bse);u7o=r(Uot,"camembert"),Uot.forEach(t),b7o=r(Ewe," \u2014 "),cq=n(Ewe,"A",{href:!0});var Jot=s(cq);v7o=r(Jot,"CamembertForCausalLM"),Jot.forEach(t),F7o=r(Ewe," (CamemBERT model)"),Ewe.forEach(t),T7o=i(q),e2=n(q,"LI",{});var Cwe=s(e2);Pse=n(Cwe,"STRONG",{});var Yot=s(Pse);M7o=r(Yot,"ctrl"),Yot.forEach(t),E7o=r(Cwe," \u2014 "),fq=n(Cwe,"A",{href:!0});var Kot=s(fq);C7o=r(Kot,"CTRLLMHeadModel"),Kot.forEach(t),w7o=r(Cwe," (CTRL model)"),Cwe.forEach(t),A7o=i(q),o2=n(q,"LI",{});var wwe=s(o2);$se=n(wwe,"STRONG",{});var Zot=s($se);y7o=r(Zot,"data2vec-text"),Zot.forEach(t),L7o=r(wwe," \u2014 "),mq=n(wwe,"A",{href:!0});var ert=s(mq);x7o=r(ert,"Data2VecTextForCausalLM"),ert.forEach(t),k7o=r(wwe," (Data2VecText model)"),wwe.forEach(t),S7o=i(q),r2=n(q,"LI",{});var Awe=s(r2);Ise=n(Awe,"STRONG",{});var ort=s(Ise);R7o=r(ort,"electra"),ort.forEach(t),B7o=r(Awe," \u2014 "),gq=n(Awe,"A",{href:!0});var rrt=s(gq);P7o=r(rrt,"ElectraForCausalLM"),rrt.forEach(t),$7o=r(Awe," (ELECTRA model)"),Awe.forEach(t),I7o=i(q),t2=n(q,"LI",{});var ywe=s(t2);qse=n(ywe,"STRONG",{});var trt=s(qse);q7o=r(trt,"gpt2"),trt.forEach(t),N7o=r(ywe," \u2014 "),hq=n(ywe,"A",{href:!0});var art=s(hq);j7o=r(art,"GPT2LMHeadModel"),art.forEach(t),D7o=r(ywe," (OpenAI GPT-2 model)"),ywe.forEach(t),G7o=i(q),a2=n(q,"LI",{});var Lwe=s(a2);Nse=n(Lwe,"STRONG",{});var nrt=s(Nse);O7o=r(nrt,"gpt_neo"),nrt.forEach(t),V7o=r(Lwe," \u2014 "),pq=n(Lwe,"A",{href:!0});var srt=s(pq);X7o=r(srt,"GPTNeoForCausalLM"),srt.forEach(t),z7o=r(Lwe," (GPT Neo model)"),Lwe.forEach(t),Q7o=i(q),n2=n(q,"LI",{});var xwe=s(n2);jse=n(xwe,"STRONG",{});var lrt=s(jse);W7o=r(lrt,"gptj"),lrt.forEach(t),H7o=r(xwe," \u2014 "),_q=n(xwe,"A",{href:!0});var irt=s(_q);U7o=r(irt,"GPTJForCausalLM"),irt.forEach(t),J7o=r(xwe," (GPT-J model)"),xwe.forEach(t),Y7o=i(q),s2=n(q,"LI",{});var kwe=s(s2);Dse=n(kwe,"STRONG",{});var drt=s(Dse);K7o=r(drt,"marian"),drt.forEach(t),Z7o=r(kwe," \u2014 "),uq=n(kwe,"A",{href:!0});var crt=s(uq);e9o=r(crt,"MarianForCausalLM"),crt.forEach(t),o9o=r(kwe," (Marian model)"),kwe.forEach(t),r9o=i(q),l2=n(q,"LI",{});var Swe=s(l2);Gse=n(Swe,"STRONG",{});var frt=s(Gse);t9o=r(frt,"mbart"),frt.forEach(t),a9o=r(Swe," \u2014 "),bq=n(Swe,"A",{href:!0});var mrt=s(bq);n9o=r(mrt,"MBartForCausalLM"),mrt.forEach(t),s9o=r(Swe," (mBART model)"),Swe.forEach(t),l9o=i(q),i2=n(q,"LI",{});var Rwe=s(i2);Ose=n(Rwe,"STRONG",{});var grt=s(Ose);i9o=r(grt,"megatron-bert"),grt.forEach(t),d9o=r(Rwe," \u2014 "),vq=n(Rwe,"A",{href:!0});var hrt=s(vq);c9o=r(hrt,"MegatronBertForCausalLM"),hrt.forEach(t),f9o=r(Rwe," (MegatronBert model)"),Rwe.forEach(t),m9o=i(q),d2=n(q,"LI",{});var Bwe=s(d2);Vse=n(Bwe,"STRONG",{});var prt=s(Vse);g9o=r(prt,"openai-gpt"),prt.forEach(t),h9o=r(Bwe," \u2014 "),Fq=n(Bwe,"A",{href:!0});var _rt=s(Fq);p9o=r(_rt,"OpenAIGPTLMHeadModel"),_rt.forEach(t),_9o=r(Bwe," (OpenAI GPT model)"),Bwe.forEach(t),u9o=i(q),c2=n(q,"LI",{});var Pwe=s(c2);Xse=n(Pwe,"STRONG",{});var urt=s(Xse);b9o=r(urt,"pegasus"),urt.forEach(t),v9o=r(Pwe," \u2014 "),Tq=n(Pwe,"A",{href:!0});var brt=s(Tq);F9o=r(brt,"PegasusForCausalLM"),brt.forEach(t),T9o=r(Pwe," (Pegasus model)"),Pwe.forEach(t),M9o=i(q),f2=n(q,"LI",{});var $we=s(f2);zse=n($we,"STRONG",{});var vrt=s(zse);E9o=r(vrt,"plbart"),vrt.forEach(t),C9o=r($we," \u2014 "),Mq=n($we,"A",{href:!0});var Frt=s(Mq);w9o=r(Frt,"PLBartForCausalLM"),Frt.forEach(t),A9o=r($we," (PLBart model)"),$we.forEach(t),y9o=i(q),m2=n(q,"LI",{});var Iwe=s(m2);Qse=n(Iwe,"STRONG",{});var Trt=s(Qse);L9o=r(Trt,"prophetnet"),Trt.forEach(t),x9o=r(Iwe," \u2014 "),Eq=n(Iwe,"A",{href:!0});var Mrt=s(Eq);k9o=r(Mrt,"ProphetNetForCausalLM"),Mrt.forEach(t),S9o=r(Iwe," (ProphetNet model)"),Iwe.forEach(t),R9o=i(q),g2=n(q,"LI",{});var qwe=s(g2);Wse=n(qwe,"STRONG",{});var Ert=s(Wse);B9o=r(Ert,"qdqbert"),Ert.forEach(t),P9o=r(qwe," \u2014 "),Cq=n(qwe,"A",{href:!0});var Crt=s(Cq);$9o=r(Crt,"QDQBertLMHeadModel"),Crt.forEach(t),I9o=r(qwe," (QDQBert model)"),qwe.forEach(t),q9o=i(q),h2=n(q,"LI",{});var Nwe=s(h2);Hse=n(Nwe,"STRONG",{});var wrt=s(Hse);N9o=r(wrt,"reformer"),wrt.forEach(t),j9o=r(Nwe," \u2014 "),wq=n(Nwe,"A",{href:!0});var Art=s(wq);D9o=r(Art,"ReformerModelWithLMHead"),Art.forEach(t),G9o=r(Nwe," (Reformer model)"),Nwe.forEach(t),O9o=i(q),p2=n(q,"LI",{});var jwe=s(p2);Use=n(jwe,"STRONG",{});var yrt=s(Use);V9o=r(yrt,"rembert"),yrt.forEach(t),X9o=r(jwe," \u2014 "),Aq=n(jwe,"A",{href:!0});var Lrt=s(Aq);z9o=r(Lrt,"RemBertForCausalLM"),Lrt.forEach(t),Q9o=r(jwe," (RemBERT model)"),jwe.forEach(t),W9o=i(q),_2=n(q,"LI",{});var Dwe=s(_2);Jse=n(Dwe,"STRONG",{});var xrt=s(Jse);H9o=r(xrt,"roberta"),xrt.forEach(t),U9o=r(Dwe," \u2014 "),yq=n(Dwe,"A",{href:!0});var krt=s(yq);J9o=r(krt,"RobertaForCausalLM"),krt.forEach(t),Y9o=r(Dwe," (RoBERTa model)"),Dwe.forEach(t),K9o=i(q),u2=n(q,"LI",{});var Gwe=s(u2);Yse=n(Gwe,"STRONG",{});var Srt=s(Yse);Z9o=r(Srt,"roformer"),Srt.forEach(t),eMo=r(Gwe," \u2014 "),Lq=n(Gwe,"A",{href:!0});var Rrt=s(Lq);oMo=r(Rrt,"RoFormerForCausalLM"),Rrt.forEach(t),rMo=r(Gwe," (RoFormer model)"),Gwe.forEach(t),tMo=i(q),b2=n(q,"LI",{});var Owe=s(b2);Kse=n(Owe,"STRONG",{});var Brt=s(Kse);aMo=r(Brt,"speech_to_text_2"),Brt.forEach(t),nMo=r(Owe," \u2014 "),xq=n(Owe,"A",{href:!0});var Prt=s(xq);sMo=r(Prt,"Speech2Text2ForCausalLM"),Prt.forEach(t),lMo=r(Owe," (Speech2Text2 model)"),Owe.forEach(t),iMo=i(q),v2=n(q,"LI",{});var Vwe=s(v2);Zse=n(Vwe,"STRONG",{});var $rt=s(Zse);dMo=r($rt,"transfo-xl"),$rt.forEach(t),cMo=r(Vwe," \u2014 "),kq=n(Vwe,"A",{href:!0});var Irt=s(kq);fMo=r(Irt,"TransfoXLLMHeadModel"),Irt.forEach(t),mMo=r(Vwe," (Transformer-XL model)"),Vwe.forEach(t),gMo=i(q),F2=n(q,"LI",{});var Xwe=s(F2);ele=n(Xwe,"STRONG",{});var qrt=s(ele);hMo=r(qrt,"trocr"),qrt.forEach(t),pMo=r(Xwe," \u2014 "),Sq=n(Xwe,"A",{href:!0});var Nrt=s(Sq);_Mo=r(Nrt,"TrOCRForCausalLM"),Nrt.forEach(t),uMo=r(Xwe," (TrOCR model)"),Xwe.forEach(t),bMo=i(q),T2=n(q,"LI",{});var zwe=s(T2);ole=n(zwe,"STRONG",{});var jrt=s(ole);vMo=r(jrt,"xglm"),jrt.forEach(t),FMo=r(zwe," \u2014 "),Rq=n(zwe,"A",{href:!0});var Drt=s(Rq);TMo=r(Drt,"XGLMForCausalLM"),Drt.forEach(t),MMo=r(zwe," (XGLM model)"),zwe.forEach(t),EMo=i(q),M2=n(q,"LI",{});var Qwe=s(M2);rle=n(Qwe,"STRONG",{});var Grt=s(rle);CMo=r(Grt,"xlm"),Grt.forEach(t),wMo=r(Qwe," \u2014 "),Bq=n(Qwe,"A",{href:!0});var Ort=s(Bq);AMo=r(Ort,"XLMWithLMHeadModel"),Ort.forEach(t),yMo=r(Qwe," (XLM model)"),Qwe.forEach(t),LMo=i(q),E2=n(q,"LI",{});var Wwe=s(E2);tle=n(Wwe,"STRONG",{});var Vrt=s(tle);xMo=r(Vrt,"xlm-prophetnet"),Vrt.forEach(t),kMo=r(Wwe," \u2014 "),Pq=n(Wwe,"A",{href:!0});var Xrt=s(Pq);SMo=r(Xrt,"XLMProphetNetForCausalLM"),Xrt.forEach(t),RMo=r(Wwe," (XLMProphetNet model)"),Wwe.forEach(t),BMo=i(q),C2=n(q,"LI",{});var Hwe=s(C2);ale=n(Hwe,"STRONG",{});var zrt=s(ale);PMo=r(zrt,"xlm-roberta"),zrt.forEach(t),$Mo=r(Hwe," \u2014 "),$q=n(Hwe,"A",{href:!0});var Qrt=s($q);IMo=r(Qrt,"XLMRobertaForCausalLM"),Qrt.forEach(t),qMo=r(Hwe," (XLM-RoBERTa model)"),Hwe.forEach(t),NMo=i(q),w2=n(q,"LI",{});var Uwe=s(w2);nle=n(Uwe,"STRONG",{});var Wrt=s(nle);jMo=r(Wrt,"xlm-roberta-xl"),Wrt.forEach(t),DMo=r(Uwe," \u2014 "),Iq=n(Uwe,"A",{href:!0});var Hrt=s(Iq);GMo=r(Hrt,"XLMRobertaXLForCausalLM"),Hrt.forEach(t),OMo=r(Uwe," (XLM-RoBERTa-XL model)"),Uwe.forEach(t),VMo=i(q),A2=n(q,"LI",{});var Jwe=s(A2);sle=n(Jwe,"STRONG",{});var Urt=s(sle);XMo=r(Urt,"xlnet"),Urt.forEach(t),zMo=r(Jwe," \u2014 "),qq=n(Jwe,"A",{href:!0});var Jrt=s(qq);QMo=r(Jrt,"XLNetLMHeadModel"),Jrt.forEach(t),WMo=r(Jwe," (XLNet model)"),Jwe.forEach(t),q.forEach(t),HMo=i(Ot),y2=n(Ot,"P",{});var Ywe=s(y2);UMo=r(Ywe,"The model is set in evaluation mode by default using "),lle=n(Ywe,"CODE",{});var Yrt=s(lle);JMo=r(Yrt,"model.eval()"),Yrt.forEach(t),YMo=r(Ywe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ile=n(Ywe,"CODE",{});var Krt=s(ile);KMo=r(Krt,"model.train()"),Krt.forEach(t),Ywe.forEach(t),ZMo=i(Ot),dle=n(Ot,"P",{});var Zrt=s(dle);e4o=r(Zrt,"Examples:"),Zrt.forEach(t),o4o=i(Ot),m(Z3.$$.fragment,Ot),Ot.forEach(t),sl.forEach(t),YPe=i(c),pd=n(c,"H2",{class:!0});var sqe=s(pd);L2=n(sqe,"A",{id:!0,class:!0,href:!0});var ett=s(L2);cle=n(ett,"SPAN",{});var ott=s(cle);m(eC.$$.fragment,ott),ott.forEach(t),ett.forEach(t),r4o=i(sqe),fle=n(sqe,"SPAN",{});var rtt=s(fle);t4o=r(rtt,"AutoModelForMaskedLM"),rtt.forEach(t),sqe.forEach(t),KPe=i(c),Zo=n(c,"DIV",{class:!0});var il=s(Zo);m(oC.$$.fragment,il),a4o=i(il),_d=n(il,"P",{});var DJ=s(_d);n4o=r(DJ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Nq=n(DJ,"A",{href:!0});var ttt=s(Nq);s4o=r(ttt,"from_pretrained()"),ttt.forEach(t),l4o=r(DJ," class method or the "),jq=n(DJ,"A",{href:!0});var att=s(jq);i4o=r(att,"from_config()"),att.forEach(t),d4o=r(DJ,` class
method.`),DJ.forEach(t),c4o=i(il),rC=n(il,"P",{});var lqe=s(rC);f4o=r(lqe,"This class cannot be instantiated directly using "),mle=n(lqe,"CODE",{});var ntt=s(mle);m4o=r(ntt,"__init__()"),ntt.forEach(t),g4o=r(lqe," (throws an error)."),lqe.forEach(t),h4o=i(il),Wr=n(il,"DIV",{class:!0});var dl=s(Wr);m(tC.$$.fragment,dl),p4o=i(dl),gle=n(dl,"P",{});var stt=s(gle);_4o=r(stt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),stt.forEach(t),u4o=i(dl),ud=n(dl,"P",{});var GJ=s(ud);b4o=r(GJ,`Note:
Loading a model from its configuration file does `),hle=n(GJ,"STRONG",{});var ltt=s(hle);v4o=r(ltt,"not"),ltt.forEach(t),F4o=r(GJ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dq=n(GJ,"A",{href:!0});var itt=s(Dq);T4o=r(itt,"from_pretrained()"),itt.forEach(t),M4o=r(GJ," to load the model weights."),GJ.forEach(t),E4o=i(dl),ple=n(dl,"P",{});var dtt=s(ple);C4o=r(dtt,"Examples:"),dtt.forEach(t),w4o=i(dl),m(aC.$$.fragment,dl),dl.forEach(t),A4o=i(il),Oe=n(il,"DIV",{class:!0});var Vt=s(Oe);m(nC.$$.fragment,Vt),y4o=i(Vt),_le=n(Vt,"P",{});var ctt=s(_le);L4o=r(ctt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ctt.forEach(t),x4o=i(Vt),Wa=n(Vt,"P",{});var n5=s(Wa);k4o=r(n5,"The model class to instantiate is selected based on the "),ule=n(n5,"CODE",{});var ftt=s(ule);S4o=r(ftt,"model_type"),ftt.forEach(t),R4o=r(n5,` property of the config object (either
passed as an argument or loaded from `),ble=n(n5,"CODE",{});var mtt=s(ble);B4o=r(mtt,"pretrained_model_name_or_path"),mtt.forEach(t),P4o=r(n5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vle=n(n5,"CODE",{});var gtt=s(vle);$4o=r(gtt,"pretrained_model_name_or_path"),gtt.forEach(t),I4o=r(n5,":"),n5.forEach(t),q4o=i(Vt),I=n(Vt,"UL",{});var N=s(I);x2=n(N,"LI",{});var Kwe=s(x2);Fle=n(Kwe,"STRONG",{});var htt=s(Fle);N4o=r(htt,"albert"),htt.forEach(t),j4o=r(Kwe," \u2014 "),Gq=n(Kwe,"A",{href:!0});var ptt=s(Gq);D4o=r(ptt,"AlbertForMaskedLM"),ptt.forEach(t),G4o=r(Kwe," (ALBERT model)"),Kwe.forEach(t),O4o=i(N),k2=n(N,"LI",{});var Zwe=s(k2);Tle=n(Zwe,"STRONG",{});var _tt=s(Tle);V4o=r(_tt,"bart"),_tt.forEach(t),X4o=r(Zwe," \u2014 "),Oq=n(Zwe,"A",{href:!0});var utt=s(Oq);z4o=r(utt,"BartForConditionalGeneration"),utt.forEach(t),Q4o=r(Zwe," (BART model)"),Zwe.forEach(t),W4o=i(N),S2=n(N,"LI",{});var e0e=s(S2);Mle=n(e0e,"STRONG",{});var btt=s(Mle);H4o=r(btt,"bert"),btt.forEach(t),U4o=r(e0e," \u2014 "),Vq=n(e0e,"A",{href:!0});var vtt=s(Vq);J4o=r(vtt,"BertForMaskedLM"),vtt.forEach(t),Y4o=r(e0e," (BERT model)"),e0e.forEach(t),K4o=i(N),R2=n(N,"LI",{});var o0e=s(R2);Ele=n(o0e,"STRONG",{});var Ftt=s(Ele);Z4o=r(Ftt,"big_bird"),Ftt.forEach(t),eEo=r(o0e," \u2014 "),Xq=n(o0e,"A",{href:!0});var Ttt=s(Xq);oEo=r(Ttt,"BigBirdForMaskedLM"),Ttt.forEach(t),rEo=r(o0e," (BigBird model)"),o0e.forEach(t),tEo=i(N),B2=n(N,"LI",{});var r0e=s(B2);Cle=n(r0e,"STRONG",{});var Mtt=s(Cle);aEo=r(Mtt,"camembert"),Mtt.forEach(t),nEo=r(r0e," \u2014 "),zq=n(r0e,"A",{href:!0});var Ett=s(zq);sEo=r(Ett,"CamembertForMaskedLM"),Ett.forEach(t),lEo=r(r0e," (CamemBERT model)"),r0e.forEach(t),iEo=i(N),P2=n(N,"LI",{});var t0e=s(P2);wle=n(t0e,"STRONG",{});var Ctt=s(wle);dEo=r(Ctt,"convbert"),Ctt.forEach(t),cEo=r(t0e," \u2014 "),Qq=n(t0e,"A",{href:!0});var wtt=s(Qq);fEo=r(wtt,"ConvBertForMaskedLM"),wtt.forEach(t),mEo=r(t0e," (ConvBERT model)"),t0e.forEach(t),gEo=i(N),$2=n(N,"LI",{});var a0e=s($2);Ale=n(a0e,"STRONG",{});var Att=s(Ale);hEo=r(Att,"data2vec-text"),Att.forEach(t),pEo=r(a0e," \u2014 "),Wq=n(a0e,"A",{href:!0});var ytt=s(Wq);_Eo=r(ytt,"Data2VecTextForMaskedLM"),ytt.forEach(t),uEo=r(a0e," (Data2VecText model)"),a0e.forEach(t),bEo=i(N),I2=n(N,"LI",{});var n0e=s(I2);yle=n(n0e,"STRONG",{});var Ltt=s(yle);vEo=r(Ltt,"deberta"),Ltt.forEach(t),FEo=r(n0e," \u2014 "),Hq=n(n0e,"A",{href:!0});var xtt=s(Hq);TEo=r(xtt,"DebertaForMaskedLM"),xtt.forEach(t),MEo=r(n0e," (DeBERTa model)"),n0e.forEach(t),EEo=i(N),q2=n(N,"LI",{});var s0e=s(q2);Lle=n(s0e,"STRONG",{});var ktt=s(Lle);CEo=r(ktt,"deberta-v2"),ktt.forEach(t),wEo=r(s0e," \u2014 "),Uq=n(s0e,"A",{href:!0});var Stt=s(Uq);AEo=r(Stt,"DebertaV2ForMaskedLM"),Stt.forEach(t),yEo=r(s0e," (DeBERTa-v2 model)"),s0e.forEach(t),LEo=i(N),N2=n(N,"LI",{});var l0e=s(N2);xle=n(l0e,"STRONG",{});var Rtt=s(xle);xEo=r(Rtt,"distilbert"),Rtt.forEach(t),kEo=r(l0e," \u2014 "),Jq=n(l0e,"A",{href:!0});var Btt=s(Jq);SEo=r(Btt,"DistilBertForMaskedLM"),Btt.forEach(t),REo=r(l0e," (DistilBERT model)"),l0e.forEach(t),BEo=i(N),j2=n(N,"LI",{});var i0e=s(j2);kle=n(i0e,"STRONG",{});var Ptt=s(kle);PEo=r(Ptt,"electra"),Ptt.forEach(t),$Eo=r(i0e," \u2014 "),Yq=n(i0e,"A",{href:!0});var $tt=s(Yq);IEo=r($tt,"ElectraForMaskedLM"),$tt.forEach(t),qEo=r(i0e," (ELECTRA model)"),i0e.forEach(t),NEo=i(N),D2=n(N,"LI",{});var d0e=s(D2);Sle=n(d0e,"STRONG",{});var Itt=s(Sle);jEo=r(Itt,"flaubert"),Itt.forEach(t),DEo=r(d0e," \u2014 "),Kq=n(d0e,"A",{href:!0});var qtt=s(Kq);GEo=r(qtt,"FlaubertWithLMHeadModel"),qtt.forEach(t),OEo=r(d0e," (FlauBERT model)"),d0e.forEach(t),VEo=i(N),G2=n(N,"LI",{});var c0e=s(G2);Rle=n(c0e,"STRONG",{});var Ntt=s(Rle);XEo=r(Ntt,"fnet"),Ntt.forEach(t),zEo=r(c0e," \u2014 "),Zq=n(c0e,"A",{href:!0});var jtt=s(Zq);QEo=r(jtt,"FNetForMaskedLM"),jtt.forEach(t),WEo=r(c0e," (FNet model)"),c0e.forEach(t),HEo=i(N),O2=n(N,"LI",{});var f0e=s(O2);Ble=n(f0e,"STRONG",{});var Dtt=s(Ble);UEo=r(Dtt,"funnel"),Dtt.forEach(t),JEo=r(f0e," \u2014 "),eN=n(f0e,"A",{href:!0});var Gtt=s(eN);YEo=r(Gtt,"FunnelForMaskedLM"),Gtt.forEach(t),KEo=r(f0e," (Funnel Transformer model)"),f0e.forEach(t),ZEo=i(N),V2=n(N,"LI",{});var m0e=s(V2);Ple=n(m0e,"STRONG",{});var Ott=s(Ple);e5o=r(Ott,"ibert"),Ott.forEach(t),o5o=r(m0e," \u2014 "),oN=n(m0e,"A",{href:!0});var Vtt=s(oN);r5o=r(Vtt,"IBertForMaskedLM"),Vtt.forEach(t),t5o=r(m0e," (I-BERT model)"),m0e.forEach(t),a5o=i(N),X2=n(N,"LI",{});var g0e=s(X2);$le=n(g0e,"STRONG",{});var Xtt=s($le);n5o=r(Xtt,"layoutlm"),Xtt.forEach(t),s5o=r(g0e," \u2014 "),rN=n(g0e,"A",{href:!0});var ztt=s(rN);l5o=r(ztt,"LayoutLMForMaskedLM"),ztt.forEach(t),i5o=r(g0e," (LayoutLM model)"),g0e.forEach(t),d5o=i(N),z2=n(N,"LI",{});var h0e=s(z2);Ile=n(h0e,"STRONG",{});var Qtt=s(Ile);c5o=r(Qtt,"longformer"),Qtt.forEach(t),f5o=r(h0e," \u2014 "),tN=n(h0e,"A",{href:!0});var Wtt=s(tN);m5o=r(Wtt,"LongformerForMaskedLM"),Wtt.forEach(t),g5o=r(h0e," (Longformer model)"),h0e.forEach(t),h5o=i(N),Q2=n(N,"LI",{});var p0e=s(Q2);qle=n(p0e,"STRONG",{});var Htt=s(qle);p5o=r(Htt,"mbart"),Htt.forEach(t),_5o=r(p0e," \u2014 "),aN=n(p0e,"A",{href:!0});var Utt=s(aN);u5o=r(Utt,"MBartForConditionalGeneration"),Utt.forEach(t),b5o=r(p0e," (mBART model)"),p0e.forEach(t),v5o=i(N),W2=n(N,"LI",{});var _0e=s(W2);Nle=n(_0e,"STRONG",{});var Jtt=s(Nle);F5o=r(Jtt,"megatron-bert"),Jtt.forEach(t),T5o=r(_0e," \u2014 "),nN=n(_0e,"A",{href:!0});var Ytt=s(nN);M5o=r(Ytt,"MegatronBertForMaskedLM"),Ytt.forEach(t),E5o=r(_0e," (MegatronBert model)"),_0e.forEach(t),C5o=i(N),H2=n(N,"LI",{});var u0e=s(H2);jle=n(u0e,"STRONG",{});var Ktt=s(jle);w5o=r(Ktt,"mobilebert"),Ktt.forEach(t),A5o=r(u0e," \u2014 "),sN=n(u0e,"A",{href:!0});var Ztt=s(sN);y5o=r(Ztt,"MobileBertForMaskedLM"),Ztt.forEach(t),L5o=r(u0e," (MobileBERT model)"),u0e.forEach(t),x5o=i(N),U2=n(N,"LI",{});var b0e=s(U2);Dle=n(b0e,"STRONG",{});var eat=s(Dle);k5o=r(eat,"mpnet"),eat.forEach(t),S5o=r(b0e," \u2014 "),lN=n(b0e,"A",{href:!0});var oat=s(lN);R5o=r(oat,"MPNetForMaskedLM"),oat.forEach(t),B5o=r(b0e," (MPNet model)"),b0e.forEach(t),P5o=i(N),J2=n(N,"LI",{});var v0e=s(J2);Gle=n(v0e,"STRONG",{});var rat=s(Gle);$5o=r(rat,"nystromformer"),rat.forEach(t),I5o=r(v0e," \u2014 "),iN=n(v0e,"A",{href:!0});var tat=s(iN);q5o=r(tat,"NystromformerForMaskedLM"),tat.forEach(t),N5o=r(v0e," (Nystromformer model)"),v0e.forEach(t),j5o=i(N),Y2=n(N,"LI",{});var F0e=s(Y2);Ole=n(F0e,"STRONG",{});var aat=s(Ole);D5o=r(aat,"perceiver"),aat.forEach(t),G5o=r(F0e," \u2014 "),dN=n(F0e,"A",{href:!0});var nat=s(dN);O5o=r(nat,"PerceiverForMaskedLM"),nat.forEach(t),V5o=r(F0e," (Perceiver model)"),F0e.forEach(t),X5o=i(N),K2=n(N,"LI",{});var T0e=s(K2);Vle=n(T0e,"STRONG",{});var sat=s(Vle);z5o=r(sat,"qdqbert"),sat.forEach(t),Q5o=r(T0e," \u2014 "),cN=n(T0e,"A",{href:!0});var lat=s(cN);W5o=r(lat,"QDQBertForMaskedLM"),lat.forEach(t),H5o=r(T0e," (QDQBert model)"),T0e.forEach(t),U5o=i(N),Z2=n(N,"LI",{});var M0e=s(Z2);Xle=n(M0e,"STRONG",{});var iat=s(Xle);J5o=r(iat,"reformer"),iat.forEach(t),Y5o=r(M0e," \u2014 "),fN=n(M0e,"A",{href:!0});var dat=s(fN);K5o=r(dat,"ReformerForMaskedLM"),dat.forEach(t),Z5o=r(M0e," (Reformer model)"),M0e.forEach(t),e3o=i(N),e1=n(N,"LI",{});var E0e=s(e1);zle=n(E0e,"STRONG",{});var cat=s(zle);o3o=r(cat,"rembert"),cat.forEach(t),r3o=r(E0e," \u2014 "),mN=n(E0e,"A",{href:!0});var fat=s(mN);t3o=r(fat,"RemBertForMaskedLM"),fat.forEach(t),a3o=r(E0e," (RemBERT model)"),E0e.forEach(t),n3o=i(N),o1=n(N,"LI",{});var C0e=s(o1);Qle=n(C0e,"STRONG",{});var mat=s(Qle);s3o=r(mat,"roberta"),mat.forEach(t),l3o=r(C0e," \u2014 "),gN=n(C0e,"A",{href:!0});var gat=s(gN);i3o=r(gat,"RobertaForMaskedLM"),gat.forEach(t),d3o=r(C0e," (RoBERTa model)"),C0e.forEach(t),c3o=i(N),r1=n(N,"LI",{});var w0e=s(r1);Wle=n(w0e,"STRONG",{});var hat=s(Wle);f3o=r(hat,"roformer"),hat.forEach(t),m3o=r(w0e," \u2014 "),hN=n(w0e,"A",{href:!0});var pat=s(hN);g3o=r(pat,"RoFormerForMaskedLM"),pat.forEach(t),h3o=r(w0e," (RoFormer model)"),w0e.forEach(t),p3o=i(N),t1=n(N,"LI",{});var A0e=s(t1);Hle=n(A0e,"STRONG",{});var _at=s(Hle);_3o=r(_at,"squeezebert"),_at.forEach(t),u3o=r(A0e," \u2014 "),pN=n(A0e,"A",{href:!0});var uat=s(pN);b3o=r(uat,"SqueezeBertForMaskedLM"),uat.forEach(t),v3o=r(A0e," (SqueezeBERT model)"),A0e.forEach(t),F3o=i(N),a1=n(N,"LI",{});var y0e=s(a1);Ule=n(y0e,"STRONG",{});var bat=s(Ule);T3o=r(bat,"tapas"),bat.forEach(t),M3o=r(y0e," \u2014 "),_N=n(y0e,"A",{href:!0});var vat=s(_N);E3o=r(vat,"TapasForMaskedLM"),vat.forEach(t),C3o=r(y0e," (TAPAS model)"),y0e.forEach(t),w3o=i(N),n1=n(N,"LI",{});var L0e=s(n1);Jle=n(L0e,"STRONG",{});var Fat=s(Jle);A3o=r(Fat,"wav2vec2"),Fat.forEach(t),y3o=r(L0e," \u2014 "),Yle=n(L0e,"CODE",{});var Tat=s(Yle);L3o=r(Tat,"Wav2Vec2ForMaskedLM"),Tat.forEach(t),x3o=r(L0e," (Wav2Vec2 model)"),L0e.forEach(t),k3o=i(N),s1=n(N,"LI",{});var x0e=s(s1);Kle=n(x0e,"STRONG",{});var Mat=s(Kle);S3o=r(Mat,"xlm"),Mat.forEach(t),R3o=r(x0e," \u2014 "),uN=n(x0e,"A",{href:!0});var Eat=s(uN);B3o=r(Eat,"XLMWithLMHeadModel"),Eat.forEach(t),P3o=r(x0e," (XLM model)"),x0e.forEach(t),$3o=i(N),l1=n(N,"LI",{});var k0e=s(l1);Zle=n(k0e,"STRONG",{});var Cat=s(Zle);I3o=r(Cat,"xlm-roberta"),Cat.forEach(t),q3o=r(k0e," \u2014 "),bN=n(k0e,"A",{href:!0});var wat=s(bN);N3o=r(wat,"XLMRobertaForMaskedLM"),wat.forEach(t),j3o=r(k0e," (XLM-RoBERTa model)"),k0e.forEach(t),D3o=i(N),i1=n(N,"LI",{});var S0e=s(i1);eie=n(S0e,"STRONG",{});var Aat=s(eie);G3o=r(Aat,"xlm-roberta-xl"),Aat.forEach(t),O3o=r(S0e," \u2014 "),vN=n(S0e,"A",{href:!0});var yat=s(vN);V3o=r(yat,"XLMRobertaXLForMaskedLM"),yat.forEach(t),X3o=r(S0e," (XLM-RoBERTa-XL model)"),S0e.forEach(t),z3o=i(N),d1=n(N,"LI",{});var R0e=s(d1);oie=n(R0e,"STRONG",{});var Lat=s(oie);Q3o=r(Lat,"yoso"),Lat.forEach(t),W3o=r(R0e," \u2014 "),FN=n(R0e,"A",{href:!0});var xat=s(FN);H3o=r(xat,"YosoForMaskedLM"),xat.forEach(t),U3o=r(R0e," (YOSO model)"),R0e.forEach(t),N.forEach(t),J3o=i(Vt),c1=n(Vt,"P",{});var B0e=s(c1);Y3o=r(B0e,"The model is set in evaluation mode by default using "),rie=n(B0e,"CODE",{});var kat=s(rie);K3o=r(kat,"model.eval()"),kat.forEach(t),Z3o=r(B0e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tie=n(B0e,"CODE",{});var Sat=s(tie);eCo=r(Sat,"model.train()"),Sat.forEach(t),B0e.forEach(t),oCo=i(Vt),aie=n(Vt,"P",{});var Rat=s(aie);rCo=r(Rat,"Examples:"),Rat.forEach(t),tCo=i(Vt),m(sC.$$.fragment,Vt),Vt.forEach(t),il.forEach(t),ZPe=i(c),bd=n(c,"H2",{class:!0});var iqe=s(bd);f1=n(iqe,"A",{id:!0,class:!0,href:!0});var Bat=s(f1);nie=n(Bat,"SPAN",{});var Pat=s(nie);m(lC.$$.fragment,Pat),Pat.forEach(t),Bat.forEach(t),aCo=i(iqe),sie=n(iqe,"SPAN",{});var $at=s(sie);nCo=r($at,"AutoModelForSeq2SeqLM"),$at.forEach(t),iqe.forEach(t),e$e=i(c),er=n(c,"DIV",{class:!0});var cl=s(er);m(iC.$$.fragment,cl),sCo=i(cl),vd=n(cl,"P",{});var OJ=s(vd);lCo=r(OJ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),TN=n(OJ,"A",{href:!0});var Iat=s(TN);iCo=r(Iat,"from_pretrained()"),Iat.forEach(t),dCo=r(OJ," class method or the "),MN=n(OJ,"A",{href:!0});var qat=s(MN);cCo=r(qat,"from_config()"),qat.forEach(t),fCo=r(OJ,` class
method.`),OJ.forEach(t),mCo=i(cl),dC=n(cl,"P",{});var dqe=s(dC);gCo=r(dqe,"This class cannot be instantiated directly using "),lie=n(dqe,"CODE",{});var Nat=s(lie);hCo=r(Nat,"__init__()"),Nat.forEach(t),pCo=r(dqe," (throws an error)."),dqe.forEach(t),_Co=i(cl),Hr=n(cl,"DIV",{class:!0});var fl=s(Hr);m(cC.$$.fragment,fl),uCo=i(fl),iie=n(fl,"P",{});var jat=s(iie);bCo=r(jat,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),jat.forEach(t),vCo=i(fl),Fd=n(fl,"P",{});var VJ=s(Fd);FCo=r(VJ,`Note:
Loading a model from its configuration file does `),die=n(VJ,"STRONG",{});var Dat=s(die);TCo=r(Dat,"not"),Dat.forEach(t),MCo=r(VJ,` load the model weights. It only affects the
model\u2019s configuration. Use `),EN=n(VJ,"A",{href:!0});var Gat=s(EN);ECo=r(Gat,"from_pretrained()"),Gat.forEach(t),CCo=r(VJ," to load the model weights."),VJ.forEach(t),wCo=i(fl),cie=n(fl,"P",{});var Oat=s(cie);ACo=r(Oat,"Examples:"),Oat.forEach(t),yCo=i(fl),m(fC.$$.fragment,fl),fl.forEach(t),LCo=i(cl),Ve=n(cl,"DIV",{class:!0});var Xt=s(Ve);m(mC.$$.fragment,Xt),xCo=i(Xt),fie=n(Xt,"P",{});var Vat=s(fie);kCo=r(Vat,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Vat.forEach(t),SCo=i(Xt),Ha=n(Xt,"P",{});var s5=s(Ha);RCo=r(s5,"The model class to instantiate is selected based on the "),mie=n(s5,"CODE",{});var Xat=s(mie);BCo=r(Xat,"model_type"),Xat.forEach(t),PCo=r(s5,` property of the config object (either
passed as an argument or loaded from `),gie=n(s5,"CODE",{});var zat=s(gie);$Co=r(zat,"pretrained_model_name_or_path"),zat.forEach(t),ICo=r(s5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hie=n(s5,"CODE",{});var Qat=s(hie);qCo=r(Qat,"pretrained_model_name_or_path"),Qat.forEach(t),NCo=r(s5,":"),s5.forEach(t),jCo=i(Xt),ne=n(Xt,"UL",{});var le=s(ne);m1=n(le,"LI",{});var P0e=s(m1);pie=n(P0e,"STRONG",{});var Wat=s(pie);DCo=r(Wat,"bart"),Wat.forEach(t),GCo=r(P0e," \u2014 "),CN=n(P0e,"A",{href:!0});var Hat=s(CN);OCo=r(Hat,"BartForConditionalGeneration"),Hat.forEach(t),VCo=r(P0e," (BART model)"),P0e.forEach(t),XCo=i(le),g1=n(le,"LI",{});var $0e=s(g1);_ie=n($0e,"STRONG",{});var Uat=s(_ie);zCo=r(Uat,"bigbird_pegasus"),Uat.forEach(t),QCo=r($0e," \u2014 "),wN=n($0e,"A",{href:!0});var Jat=s(wN);WCo=r(Jat,"BigBirdPegasusForConditionalGeneration"),Jat.forEach(t),HCo=r($0e," (BigBirdPegasus model)"),$0e.forEach(t),UCo=i(le),h1=n(le,"LI",{});var I0e=s(h1);uie=n(I0e,"STRONG",{});var Yat=s(uie);JCo=r(Yat,"blenderbot"),Yat.forEach(t),YCo=r(I0e," \u2014 "),AN=n(I0e,"A",{href:!0});var Kat=s(AN);KCo=r(Kat,"BlenderbotForConditionalGeneration"),Kat.forEach(t),ZCo=r(I0e," (Blenderbot model)"),I0e.forEach(t),ewo=i(le),p1=n(le,"LI",{});var q0e=s(p1);bie=n(q0e,"STRONG",{});var Zat=s(bie);owo=r(Zat,"blenderbot-small"),Zat.forEach(t),rwo=r(q0e," \u2014 "),yN=n(q0e,"A",{href:!0});var ent=s(yN);two=r(ent,"BlenderbotSmallForConditionalGeneration"),ent.forEach(t),awo=r(q0e," (BlenderbotSmall model)"),q0e.forEach(t),nwo=i(le),_1=n(le,"LI",{});var N0e=s(_1);vie=n(N0e,"STRONG",{});var ont=s(vie);swo=r(ont,"encoder-decoder"),ont.forEach(t),lwo=r(N0e," \u2014 "),LN=n(N0e,"A",{href:!0});var rnt=s(LN);iwo=r(rnt,"EncoderDecoderModel"),rnt.forEach(t),dwo=r(N0e," (Encoder decoder model)"),N0e.forEach(t),cwo=i(le),u1=n(le,"LI",{});var j0e=s(u1);Fie=n(j0e,"STRONG",{});var tnt=s(Fie);fwo=r(tnt,"fsmt"),tnt.forEach(t),mwo=r(j0e," \u2014 "),xN=n(j0e,"A",{href:!0});var ant=s(xN);gwo=r(ant,"FSMTForConditionalGeneration"),ant.forEach(t),hwo=r(j0e," (FairSeq Machine-Translation model)"),j0e.forEach(t),pwo=i(le),b1=n(le,"LI",{});var D0e=s(b1);Tie=n(D0e,"STRONG",{});var nnt=s(Tie);_wo=r(nnt,"led"),nnt.forEach(t),uwo=r(D0e," \u2014 "),kN=n(D0e,"A",{href:!0});var snt=s(kN);bwo=r(snt,"LEDForConditionalGeneration"),snt.forEach(t),vwo=r(D0e," (LED model)"),D0e.forEach(t),Fwo=i(le),v1=n(le,"LI",{});var G0e=s(v1);Mie=n(G0e,"STRONG",{});var lnt=s(Mie);Two=r(lnt,"longt5"),lnt.forEach(t),Mwo=r(G0e," \u2014 "),SN=n(G0e,"A",{href:!0});var int=s(SN);Ewo=r(int,"LongT5ForConditionalGeneration"),int.forEach(t),Cwo=r(G0e," (LongT5 model)"),G0e.forEach(t),wwo=i(le),F1=n(le,"LI",{});var O0e=s(F1);Eie=n(O0e,"STRONG",{});var dnt=s(Eie);Awo=r(dnt,"m2m_100"),dnt.forEach(t),ywo=r(O0e," \u2014 "),RN=n(O0e,"A",{href:!0});var cnt=s(RN);Lwo=r(cnt,"M2M100ForConditionalGeneration"),cnt.forEach(t),xwo=r(O0e," (M2M100 model)"),O0e.forEach(t),kwo=i(le),T1=n(le,"LI",{});var V0e=s(T1);Cie=n(V0e,"STRONG",{});var fnt=s(Cie);Swo=r(fnt,"marian"),fnt.forEach(t),Rwo=r(V0e," \u2014 "),BN=n(V0e,"A",{href:!0});var mnt=s(BN);Bwo=r(mnt,"MarianMTModel"),mnt.forEach(t),Pwo=r(V0e," (Marian model)"),V0e.forEach(t),$wo=i(le),M1=n(le,"LI",{});var X0e=s(M1);wie=n(X0e,"STRONG",{});var gnt=s(wie);Iwo=r(gnt,"mbart"),gnt.forEach(t),qwo=r(X0e," \u2014 "),PN=n(X0e,"A",{href:!0});var hnt=s(PN);Nwo=r(hnt,"MBartForConditionalGeneration"),hnt.forEach(t),jwo=r(X0e," (mBART model)"),X0e.forEach(t),Dwo=i(le),E1=n(le,"LI",{});var z0e=s(E1);Aie=n(z0e,"STRONG",{});var pnt=s(Aie);Gwo=r(pnt,"mt5"),pnt.forEach(t),Owo=r(z0e," \u2014 "),$N=n(z0e,"A",{href:!0});var _nt=s($N);Vwo=r(_nt,"MT5ForConditionalGeneration"),_nt.forEach(t),Xwo=r(z0e," (mT5 model)"),z0e.forEach(t),zwo=i(le),C1=n(le,"LI",{});var Q0e=s(C1);yie=n(Q0e,"STRONG",{});var unt=s(yie);Qwo=r(unt,"pegasus"),unt.forEach(t),Wwo=r(Q0e," \u2014 "),IN=n(Q0e,"A",{href:!0});var bnt=s(IN);Hwo=r(bnt,"PegasusForConditionalGeneration"),bnt.forEach(t),Uwo=r(Q0e," (Pegasus model)"),Q0e.forEach(t),Jwo=i(le),w1=n(le,"LI",{});var W0e=s(w1);Lie=n(W0e,"STRONG",{});var vnt=s(Lie);Ywo=r(vnt,"plbart"),vnt.forEach(t),Kwo=r(W0e," \u2014 "),qN=n(W0e,"A",{href:!0});var Fnt=s(qN);Zwo=r(Fnt,"PLBartForConditionalGeneration"),Fnt.forEach(t),e0o=r(W0e," (PLBart model)"),W0e.forEach(t),o0o=i(le),A1=n(le,"LI",{});var H0e=s(A1);xie=n(H0e,"STRONG",{});var Tnt=s(xie);r0o=r(Tnt,"prophetnet"),Tnt.forEach(t),t0o=r(H0e," \u2014 "),NN=n(H0e,"A",{href:!0});var Mnt=s(NN);a0o=r(Mnt,"ProphetNetForConditionalGeneration"),Mnt.forEach(t),n0o=r(H0e," (ProphetNet model)"),H0e.forEach(t),s0o=i(le),y1=n(le,"LI",{});var U0e=s(y1);kie=n(U0e,"STRONG",{});var Ent=s(kie);l0o=r(Ent,"t5"),Ent.forEach(t),i0o=r(U0e," \u2014 "),jN=n(U0e,"A",{href:!0});var Cnt=s(jN);d0o=r(Cnt,"T5ForConditionalGeneration"),Cnt.forEach(t),c0o=r(U0e," (T5 model)"),U0e.forEach(t),f0o=i(le),L1=n(le,"LI",{});var J0e=s(L1);Sie=n(J0e,"STRONG",{});var wnt=s(Sie);m0o=r(wnt,"tapex"),wnt.forEach(t),g0o=r(J0e," \u2014 "),DN=n(J0e,"A",{href:!0});var Ant=s(DN);h0o=r(Ant,"BartForConditionalGeneration"),Ant.forEach(t),p0o=r(J0e," (TAPEX model)"),J0e.forEach(t),_0o=i(le),x1=n(le,"LI",{});var Y0e=s(x1);Rie=n(Y0e,"STRONG",{});var ynt=s(Rie);u0o=r(ynt,"xlm-prophetnet"),ynt.forEach(t),b0o=r(Y0e," \u2014 "),GN=n(Y0e,"A",{href:!0});var Lnt=s(GN);v0o=r(Lnt,"XLMProphetNetForConditionalGeneration"),Lnt.forEach(t),F0o=r(Y0e," (XLMProphetNet model)"),Y0e.forEach(t),le.forEach(t),T0o=i(Xt),k1=n(Xt,"P",{});var K0e=s(k1);M0o=r(K0e,"The model is set in evaluation mode by default using "),Bie=n(K0e,"CODE",{});var xnt=s(Bie);E0o=r(xnt,"model.eval()"),xnt.forEach(t),C0o=r(K0e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pie=n(K0e,"CODE",{});var knt=s(Pie);w0o=r(knt,"model.train()"),knt.forEach(t),K0e.forEach(t),A0o=i(Xt),$ie=n(Xt,"P",{});var Snt=s($ie);y0o=r(Snt,"Examples:"),Snt.forEach(t),L0o=i(Xt),m(gC.$$.fragment,Xt),Xt.forEach(t),cl.forEach(t),o$e=i(c),Td=n(c,"H2",{class:!0});var cqe=s(Td);S1=n(cqe,"A",{id:!0,class:!0,href:!0});var Rnt=s(S1);Iie=n(Rnt,"SPAN",{});var Bnt=s(Iie);m(hC.$$.fragment,Bnt),Bnt.forEach(t),Rnt.forEach(t),x0o=i(cqe),qie=n(cqe,"SPAN",{});var Pnt=s(qie);k0o=r(Pnt,"AutoModelForSequenceClassification"),Pnt.forEach(t),cqe.forEach(t),r$e=i(c),or=n(c,"DIV",{class:!0});var ml=s(or);m(pC.$$.fragment,ml),S0o=i(ml),Md=n(ml,"P",{});var XJ=s(Md);R0o=r(XJ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ON=n(XJ,"A",{href:!0});var $nt=s(ON);B0o=r($nt,"from_pretrained()"),$nt.forEach(t),P0o=r(XJ," class method or the "),VN=n(XJ,"A",{href:!0});var Int=s(VN);$0o=r(Int,"from_config()"),Int.forEach(t),I0o=r(XJ,` class
method.`),XJ.forEach(t),q0o=i(ml),_C=n(ml,"P",{});var fqe=s(_C);N0o=r(fqe,"This class cannot be instantiated directly using "),Nie=n(fqe,"CODE",{});var qnt=s(Nie);j0o=r(qnt,"__init__()"),qnt.forEach(t),D0o=r(fqe," (throws an error)."),fqe.forEach(t),G0o=i(ml),Ur=n(ml,"DIV",{class:!0});var gl=s(Ur);m(uC.$$.fragment,gl),O0o=i(gl),jie=n(gl,"P",{});var Nnt=s(jie);V0o=r(Nnt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Nnt.forEach(t),X0o=i(gl),Ed=n(gl,"P",{});var zJ=s(Ed);z0o=r(zJ,`Note:
Loading a model from its configuration file does `),Die=n(zJ,"STRONG",{});var jnt=s(Die);Q0o=r(jnt,"not"),jnt.forEach(t),W0o=r(zJ,` load the model weights. It only affects the
model\u2019s configuration. Use `),XN=n(zJ,"A",{href:!0});var Dnt=s(XN);H0o=r(Dnt,"from_pretrained()"),Dnt.forEach(t),U0o=r(zJ," to load the model weights."),zJ.forEach(t),J0o=i(gl),Gie=n(gl,"P",{});var Gnt=s(Gie);Y0o=r(Gnt,"Examples:"),Gnt.forEach(t),K0o=i(gl),m(bC.$$.fragment,gl),gl.forEach(t),Z0o=i(ml),Xe=n(ml,"DIV",{class:!0});var zt=s(Xe);m(vC.$$.fragment,zt),eAo=i(zt),Oie=n(zt,"P",{});var Ont=s(Oie);oAo=r(Ont,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Ont.forEach(t),rAo=i(zt),Ua=n(zt,"P",{});var l5=s(Ua);tAo=r(l5,"The model class to instantiate is selected based on the "),Vie=n(l5,"CODE",{});var Vnt=s(Vie);aAo=r(Vnt,"model_type"),Vnt.forEach(t),nAo=r(l5,` property of the config object (either
passed as an argument or loaded from `),Xie=n(l5,"CODE",{});var Xnt=s(Xie);sAo=r(Xnt,"pretrained_model_name_or_path"),Xnt.forEach(t),lAo=r(l5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zie=n(l5,"CODE",{});var znt=s(zie);iAo=r(znt,"pretrained_model_name_or_path"),znt.forEach(t),dAo=r(l5,":"),l5.forEach(t),cAo=i(zt),y=n(zt,"UL",{});var L=s(y);R1=n(L,"LI",{});var Z0e=s(R1);Qie=n(Z0e,"STRONG",{});var Qnt=s(Qie);fAo=r(Qnt,"albert"),Qnt.forEach(t),mAo=r(Z0e," \u2014 "),zN=n(Z0e,"A",{href:!0});var Wnt=s(zN);gAo=r(Wnt,"AlbertForSequenceClassification"),Wnt.forEach(t),hAo=r(Z0e," (ALBERT model)"),Z0e.forEach(t),pAo=i(L),B1=n(L,"LI",{});var eAe=s(B1);Wie=n(eAe,"STRONG",{});var Hnt=s(Wie);_Ao=r(Hnt,"bart"),Hnt.forEach(t),uAo=r(eAe," \u2014 "),QN=n(eAe,"A",{href:!0});var Unt=s(QN);bAo=r(Unt,"BartForSequenceClassification"),Unt.forEach(t),vAo=r(eAe," (BART model)"),eAe.forEach(t),FAo=i(L),P1=n(L,"LI",{});var oAe=s(P1);Hie=n(oAe,"STRONG",{});var Jnt=s(Hie);TAo=r(Jnt,"bert"),Jnt.forEach(t),MAo=r(oAe," \u2014 "),WN=n(oAe,"A",{href:!0});var Ynt=s(WN);EAo=r(Ynt,"BertForSequenceClassification"),Ynt.forEach(t),CAo=r(oAe," (BERT model)"),oAe.forEach(t),wAo=i(L),$1=n(L,"LI",{});var rAe=s($1);Uie=n(rAe,"STRONG",{});var Knt=s(Uie);AAo=r(Knt,"big_bird"),Knt.forEach(t),yAo=r(rAe," \u2014 "),HN=n(rAe,"A",{href:!0});var Znt=s(HN);LAo=r(Znt,"BigBirdForSequenceClassification"),Znt.forEach(t),xAo=r(rAe," (BigBird model)"),rAe.forEach(t),kAo=i(L),I1=n(L,"LI",{});var tAe=s(I1);Jie=n(tAe,"STRONG",{});var est=s(Jie);SAo=r(est,"bigbird_pegasus"),est.forEach(t),RAo=r(tAe," \u2014 "),UN=n(tAe,"A",{href:!0});var ost=s(UN);BAo=r(ost,"BigBirdPegasusForSequenceClassification"),ost.forEach(t),PAo=r(tAe," (BigBirdPegasus model)"),tAe.forEach(t),$Ao=i(L),q1=n(L,"LI",{});var aAe=s(q1);Yie=n(aAe,"STRONG",{});var rst=s(Yie);IAo=r(rst,"camembert"),rst.forEach(t),qAo=r(aAe," \u2014 "),JN=n(aAe,"A",{href:!0});var tst=s(JN);NAo=r(tst,"CamembertForSequenceClassification"),tst.forEach(t),jAo=r(aAe," (CamemBERT model)"),aAe.forEach(t),DAo=i(L),N1=n(L,"LI",{});var nAe=s(N1);Kie=n(nAe,"STRONG",{});var ast=s(Kie);GAo=r(ast,"canine"),ast.forEach(t),OAo=r(nAe," \u2014 "),YN=n(nAe,"A",{href:!0});var nst=s(YN);VAo=r(nst,"CanineForSequenceClassification"),nst.forEach(t),XAo=r(nAe," (Canine model)"),nAe.forEach(t),zAo=i(L),j1=n(L,"LI",{});var sAe=s(j1);Zie=n(sAe,"STRONG",{});var sst=s(Zie);QAo=r(sst,"convbert"),sst.forEach(t),WAo=r(sAe," \u2014 "),KN=n(sAe,"A",{href:!0});var lst=s(KN);HAo=r(lst,"ConvBertForSequenceClassification"),lst.forEach(t),UAo=r(sAe," (ConvBERT model)"),sAe.forEach(t),JAo=i(L),D1=n(L,"LI",{});var lAe=s(D1);ede=n(lAe,"STRONG",{});var ist=s(ede);YAo=r(ist,"ctrl"),ist.forEach(t),KAo=r(lAe," \u2014 "),ZN=n(lAe,"A",{href:!0});var dst=s(ZN);ZAo=r(dst,"CTRLForSequenceClassification"),dst.forEach(t),eyo=r(lAe," (CTRL model)"),lAe.forEach(t),oyo=i(L),G1=n(L,"LI",{});var iAe=s(G1);ode=n(iAe,"STRONG",{});var cst=s(ode);ryo=r(cst,"data2vec-text"),cst.forEach(t),tyo=r(iAe," \u2014 "),ej=n(iAe,"A",{href:!0});var fst=s(ej);ayo=r(fst,"Data2VecTextForSequenceClassification"),fst.forEach(t),nyo=r(iAe," (Data2VecText model)"),iAe.forEach(t),syo=i(L),O1=n(L,"LI",{});var dAe=s(O1);rde=n(dAe,"STRONG",{});var mst=s(rde);lyo=r(mst,"deberta"),mst.forEach(t),iyo=r(dAe," \u2014 "),oj=n(dAe,"A",{href:!0});var gst=s(oj);dyo=r(gst,"DebertaForSequenceClassification"),gst.forEach(t),cyo=r(dAe," (DeBERTa model)"),dAe.forEach(t),fyo=i(L),V1=n(L,"LI",{});var cAe=s(V1);tde=n(cAe,"STRONG",{});var hst=s(tde);myo=r(hst,"deberta-v2"),hst.forEach(t),gyo=r(cAe," \u2014 "),rj=n(cAe,"A",{href:!0});var pst=s(rj);hyo=r(pst,"DebertaV2ForSequenceClassification"),pst.forEach(t),pyo=r(cAe," (DeBERTa-v2 model)"),cAe.forEach(t),_yo=i(L),X1=n(L,"LI",{});var fAe=s(X1);ade=n(fAe,"STRONG",{});var _st=s(ade);uyo=r(_st,"distilbert"),_st.forEach(t),byo=r(fAe," \u2014 "),tj=n(fAe,"A",{href:!0});var ust=s(tj);vyo=r(ust,"DistilBertForSequenceClassification"),ust.forEach(t),Fyo=r(fAe," (DistilBERT model)"),fAe.forEach(t),Tyo=i(L),z1=n(L,"LI",{});var mAe=s(z1);nde=n(mAe,"STRONG",{});var bst=s(nde);Myo=r(bst,"electra"),bst.forEach(t),Eyo=r(mAe," \u2014 "),aj=n(mAe,"A",{href:!0});var vst=s(aj);Cyo=r(vst,"ElectraForSequenceClassification"),vst.forEach(t),wyo=r(mAe," (ELECTRA model)"),mAe.forEach(t),Ayo=i(L),Q1=n(L,"LI",{});var gAe=s(Q1);sde=n(gAe,"STRONG",{});var Fst=s(sde);yyo=r(Fst,"flaubert"),Fst.forEach(t),Lyo=r(gAe," \u2014 "),nj=n(gAe,"A",{href:!0});var Tst=s(nj);xyo=r(Tst,"FlaubertForSequenceClassification"),Tst.forEach(t),kyo=r(gAe," (FlauBERT model)"),gAe.forEach(t),Syo=i(L),W1=n(L,"LI",{});var hAe=s(W1);lde=n(hAe,"STRONG",{});var Mst=s(lde);Ryo=r(Mst,"fnet"),Mst.forEach(t),Byo=r(hAe," \u2014 "),sj=n(hAe,"A",{href:!0});var Est=s(sj);Pyo=r(Est,"FNetForSequenceClassification"),Est.forEach(t),$yo=r(hAe," (FNet model)"),hAe.forEach(t),Iyo=i(L),H1=n(L,"LI",{});var pAe=s(H1);ide=n(pAe,"STRONG",{});var Cst=s(ide);qyo=r(Cst,"funnel"),Cst.forEach(t),Nyo=r(pAe," \u2014 "),lj=n(pAe,"A",{href:!0});var wst=s(lj);jyo=r(wst,"FunnelForSequenceClassification"),wst.forEach(t),Dyo=r(pAe," (Funnel Transformer model)"),pAe.forEach(t),Gyo=i(L),U1=n(L,"LI",{});var _Ae=s(U1);dde=n(_Ae,"STRONG",{});var Ast=s(dde);Oyo=r(Ast,"gpt2"),Ast.forEach(t),Vyo=r(_Ae," \u2014 "),ij=n(_Ae,"A",{href:!0});var yst=s(ij);Xyo=r(yst,"GPT2ForSequenceClassification"),yst.forEach(t),zyo=r(_Ae," (OpenAI GPT-2 model)"),_Ae.forEach(t),Qyo=i(L),J1=n(L,"LI",{});var uAe=s(J1);cde=n(uAe,"STRONG",{});var Lst=s(cde);Wyo=r(Lst,"gpt_neo"),Lst.forEach(t),Hyo=r(uAe," \u2014 "),dj=n(uAe,"A",{href:!0});var xst=s(dj);Uyo=r(xst,"GPTNeoForSequenceClassification"),xst.forEach(t),Jyo=r(uAe," (GPT Neo model)"),uAe.forEach(t),Yyo=i(L),Y1=n(L,"LI",{});var bAe=s(Y1);fde=n(bAe,"STRONG",{});var kst=s(fde);Kyo=r(kst,"gptj"),kst.forEach(t),Zyo=r(bAe," \u2014 "),cj=n(bAe,"A",{href:!0});var Sst=s(cj);eLo=r(Sst,"GPTJForSequenceClassification"),Sst.forEach(t),oLo=r(bAe," (GPT-J model)"),bAe.forEach(t),rLo=i(L),K1=n(L,"LI",{});var vAe=s(K1);mde=n(vAe,"STRONG",{});var Rst=s(mde);tLo=r(Rst,"ibert"),Rst.forEach(t),aLo=r(vAe," \u2014 "),fj=n(vAe,"A",{href:!0});var Bst=s(fj);nLo=r(Bst,"IBertForSequenceClassification"),Bst.forEach(t),sLo=r(vAe," (I-BERT model)"),vAe.forEach(t),lLo=i(L),Z1=n(L,"LI",{});var FAe=s(Z1);gde=n(FAe,"STRONG",{});var Pst=s(gde);iLo=r(Pst,"layoutlm"),Pst.forEach(t),dLo=r(FAe," \u2014 "),mj=n(FAe,"A",{href:!0});var $st=s(mj);cLo=r($st,"LayoutLMForSequenceClassification"),$st.forEach(t),fLo=r(FAe," (LayoutLM model)"),FAe.forEach(t),mLo=i(L),eb=n(L,"LI",{});var TAe=s(eb);hde=n(TAe,"STRONG",{});var Ist=s(hde);gLo=r(Ist,"layoutlmv2"),Ist.forEach(t),hLo=r(TAe," \u2014 "),gj=n(TAe,"A",{href:!0});var qst=s(gj);pLo=r(qst,"LayoutLMv2ForSequenceClassification"),qst.forEach(t),_Lo=r(TAe," (LayoutLMv2 model)"),TAe.forEach(t),uLo=i(L),ob=n(L,"LI",{});var MAe=s(ob);pde=n(MAe,"STRONG",{});var Nst=s(pde);bLo=r(Nst,"led"),Nst.forEach(t),vLo=r(MAe," \u2014 "),hj=n(MAe,"A",{href:!0});var jst=s(hj);FLo=r(jst,"LEDForSequenceClassification"),jst.forEach(t),TLo=r(MAe," (LED model)"),MAe.forEach(t),MLo=i(L),rb=n(L,"LI",{});var EAe=s(rb);_de=n(EAe,"STRONG",{});var Dst=s(_de);ELo=r(Dst,"longformer"),Dst.forEach(t),CLo=r(EAe," \u2014 "),pj=n(EAe,"A",{href:!0});var Gst=s(pj);wLo=r(Gst,"LongformerForSequenceClassification"),Gst.forEach(t),ALo=r(EAe," (Longformer model)"),EAe.forEach(t),yLo=i(L),tb=n(L,"LI",{});var CAe=s(tb);ude=n(CAe,"STRONG",{});var Ost=s(ude);LLo=r(Ost,"mbart"),Ost.forEach(t),xLo=r(CAe," \u2014 "),_j=n(CAe,"A",{href:!0});var Vst=s(_j);kLo=r(Vst,"MBartForSequenceClassification"),Vst.forEach(t),SLo=r(CAe," (mBART model)"),CAe.forEach(t),RLo=i(L),ab=n(L,"LI",{});var wAe=s(ab);bde=n(wAe,"STRONG",{});var Xst=s(bde);BLo=r(Xst,"megatron-bert"),Xst.forEach(t),PLo=r(wAe," \u2014 "),uj=n(wAe,"A",{href:!0});var zst=s(uj);$Lo=r(zst,"MegatronBertForSequenceClassification"),zst.forEach(t),ILo=r(wAe," (MegatronBert model)"),wAe.forEach(t),qLo=i(L),nb=n(L,"LI",{});var AAe=s(nb);vde=n(AAe,"STRONG",{});var Qst=s(vde);NLo=r(Qst,"mobilebert"),Qst.forEach(t),jLo=r(AAe," \u2014 "),bj=n(AAe,"A",{href:!0});var Wst=s(bj);DLo=r(Wst,"MobileBertForSequenceClassification"),Wst.forEach(t),GLo=r(AAe," (MobileBERT model)"),AAe.forEach(t),OLo=i(L),sb=n(L,"LI",{});var yAe=s(sb);Fde=n(yAe,"STRONG",{});var Hst=s(Fde);VLo=r(Hst,"mpnet"),Hst.forEach(t),XLo=r(yAe," \u2014 "),vj=n(yAe,"A",{href:!0});var Ust=s(vj);zLo=r(Ust,"MPNetForSequenceClassification"),Ust.forEach(t),QLo=r(yAe," (MPNet model)"),yAe.forEach(t),WLo=i(L),lb=n(L,"LI",{});var LAe=s(lb);Tde=n(LAe,"STRONG",{});var Jst=s(Tde);HLo=r(Jst,"nystromformer"),Jst.forEach(t),ULo=r(LAe," \u2014 "),Fj=n(LAe,"A",{href:!0});var Yst=s(Fj);JLo=r(Yst,"NystromformerForSequenceClassification"),Yst.forEach(t),YLo=r(LAe," (Nystromformer model)"),LAe.forEach(t),KLo=i(L),ib=n(L,"LI",{});var xAe=s(ib);Mde=n(xAe,"STRONG",{});var Kst=s(Mde);ZLo=r(Kst,"openai-gpt"),Kst.forEach(t),e8o=r(xAe," \u2014 "),Tj=n(xAe,"A",{href:!0});var Zst=s(Tj);o8o=r(Zst,"OpenAIGPTForSequenceClassification"),Zst.forEach(t),r8o=r(xAe," (OpenAI GPT model)"),xAe.forEach(t),t8o=i(L),db=n(L,"LI",{});var kAe=s(db);Ede=n(kAe,"STRONG",{});var elt=s(Ede);a8o=r(elt,"perceiver"),elt.forEach(t),n8o=r(kAe," \u2014 "),Mj=n(kAe,"A",{href:!0});var olt=s(Mj);s8o=r(olt,"PerceiverForSequenceClassification"),olt.forEach(t),l8o=r(kAe," (Perceiver model)"),kAe.forEach(t),i8o=i(L),cb=n(L,"LI",{});var SAe=s(cb);Cde=n(SAe,"STRONG",{});var rlt=s(Cde);d8o=r(rlt,"plbart"),rlt.forEach(t),c8o=r(SAe," \u2014 "),Ej=n(SAe,"A",{href:!0});var tlt=s(Ej);f8o=r(tlt,"PLBartForSequenceClassification"),tlt.forEach(t),m8o=r(SAe," (PLBart model)"),SAe.forEach(t),g8o=i(L),fb=n(L,"LI",{});var RAe=s(fb);wde=n(RAe,"STRONG",{});var alt=s(wde);h8o=r(alt,"qdqbert"),alt.forEach(t),p8o=r(RAe," \u2014 "),Cj=n(RAe,"A",{href:!0});var nlt=s(Cj);_8o=r(nlt,"QDQBertForSequenceClassification"),nlt.forEach(t),u8o=r(RAe," (QDQBert model)"),RAe.forEach(t),b8o=i(L),mb=n(L,"LI",{});var BAe=s(mb);Ade=n(BAe,"STRONG",{});var slt=s(Ade);v8o=r(slt,"reformer"),slt.forEach(t),F8o=r(BAe," \u2014 "),wj=n(BAe,"A",{href:!0});var llt=s(wj);T8o=r(llt,"ReformerForSequenceClassification"),llt.forEach(t),M8o=r(BAe," (Reformer model)"),BAe.forEach(t),E8o=i(L),gb=n(L,"LI",{});var PAe=s(gb);yde=n(PAe,"STRONG",{});var ilt=s(yde);C8o=r(ilt,"rembert"),ilt.forEach(t),w8o=r(PAe," \u2014 "),Aj=n(PAe,"A",{href:!0});var dlt=s(Aj);A8o=r(dlt,"RemBertForSequenceClassification"),dlt.forEach(t),y8o=r(PAe," (RemBERT model)"),PAe.forEach(t),L8o=i(L),hb=n(L,"LI",{});var $Ae=s(hb);Lde=n($Ae,"STRONG",{});var clt=s(Lde);x8o=r(clt,"roberta"),clt.forEach(t),k8o=r($Ae," \u2014 "),yj=n($Ae,"A",{href:!0});var flt=s(yj);S8o=r(flt,"RobertaForSequenceClassification"),flt.forEach(t),R8o=r($Ae," (RoBERTa model)"),$Ae.forEach(t),B8o=i(L),pb=n(L,"LI",{});var IAe=s(pb);xde=n(IAe,"STRONG",{});var mlt=s(xde);P8o=r(mlt,"roformer"),mlt.forEach(t),$8o=r(IAe," \u2014 "),Lj=n(IAe,"A",{href:!0});var glt=s(Lj);I8o=r(glt,"RoFormerForSequenceClassification"),glt.forEach(t),q8o=r(IAe," (RoFormer model)"),IAe.forEach(t),N8o=i(L),_b=n(L,"LI",{});var qAe=s(_b);kde=n(qAe,"STRONG",{});var hlt=s(kde);j8o=r(hlt,"squeezebert"),hlt.forEach(t),D8o=r(qAe," \u2014 "),xj=n(qAe,"A",{href:!0});var plt=s(xj);G8o=r(plt,"SqueezeBertForSequenceClassification"),plt.forEach(t),O8o=r(qAe," (SqueezeBERT model)"),qAe.forEach(t),V8o=i(L),ub=n(L,"LI",{});var NAe=s(ub);Sde=n(NAe,"STRONG",{});var _lt=s(Sde);X8o=r(_lt,"tapas"),_lt.forEach(t),z8o=r(NAe," \u2014 "),kj=n(NAe,"A",{href:!0});var ult=s(kj);Q8o=r(ult,"TapasForSequenceClassification"),ult.forEach(t),W8o=r(NAe," (TAPAS model)"),NAe.forEach(t),H8o=i(L),bb=n(L,"LI",{});var jAe=s(bb);Rde=n(jAe,"STRONG",{});var blt=s(Rde);U8o=r(blt,"tapex"),blt.forEach(t),J8o=r(jAe," \u2014 "),Sj=n(jAe,"A",{href:!0});var vlt=s(Sj);Y8o=r(vlt,"BartForSequenceClassification"),vlt.forEach(t),K8o=r(jAe," (TAPEX model)"),jAe.forEach(t),Z8o=i(L),vb=n(L,"LI",{});var DAe=s(vb);Bde=n(DAe,"STRONG",{});var Flt=s(Bde);exo=r(Flt,"transfo-xl"),Flt.forEach(t),oxo=r(DAe," \u2014 "),Rj=n(DAe,"A",{href:!0});var Tlt=s(Rj);rxo=r(Tlt,"TransfoXLForSequenceClassification"),Tlt.forEach(t),txo=r(DAe," (Transformer-XL model)"),DAe.forEach(t),axo=i(L),Fb=n(L,"LI",{});var GAe=s(Fb);Pde=n(GAe,"STRONG",{});var Mlt=s(Pde);nxo=r(Mlt,"xlm"),Mlt.forEach(t),sxo=r(GAe," \u2014 "),Bj=n(GAe,"A",{href:!0});var Elt=s(Bj);lxo=r(Elt,"XLMForSequenceClassification"),Elt.forEach(t),ixo=r(GAe," (XLM model)"),GAe.forEach(t),dxo=i(L),Tb=n(L,"LI",{});var OAe=s(Tb);$de=n(OAe,"STRONG",{});var Clt=s($de);cxo=r(Clt,"xlm-roberta"),Clt.forEach(t),fxo=r(OAe," \u2014 "),Pj=n(OAe,"A",{href:!0});var wlt=s(Pj);mxo=r(wlt,"XLMRobertaForSequenceClassification"),wlt.forEach(t),gxo=r(OAe," (XLM-RoBERTa model)"),OAe.forEach(t),hxo=i(L),Mb=n(L,"LI",{});var VAe=s(Mb);Ide=n(VAe,"STRONG",{});var Alt=s(Ide);pxo=r(Alt,"xlm-roberta-xl"),Alt.forEach(t),_xo=r(VAe," \u2014 "),$j=n(VAe,"A",{href:!0});var ylt=s($j);uxo=r(ylt,"XLMRobertaXLForSequenceClassification"),ylt.forEach(t),bxo=r(VAe," (XLM-RoBERTa-XL model)"),VAe.forEach(t),vxo=i(L),Eb=n(L,"LI",{});var XAe=s(Eb);qde=n(XAe,"STRONG",{});var Llt=s(qde);Fxo=r(Llt,"xlnet"),Llt.forEach(t),Txo=r(XAe," \u2014 "),Ij=n(XAe,"A",{href:!0});var xlt=s(Ij);Mxo=r(xlt,"XLNetForSequenceClassification"),xlt.forEach(t),Exo=r(XAe," (XLNet model)"),XAe.forEach(t),Cxo=i(L),Cb=n(L,"LI",{});var zAe=s(Cb);Nde=n(zAe,"STRONG",{});var klt=s(Nde);wxo=r(klt,"yoso"),klt.forEach(t),Axo=r(zAe," \u2014 "),qj=n(zAe,"A",{href:!0});var Slt=s(qj);yxo=r(Slt,"YosoForSequenceClassification"),Slt.forEach(t),Lxo=r(zAe," (YOSO model)"),zAe.forEach(t),L.forEach(t),xxo=i(zt),wb=n(zt,"P",{});var QAe=s(wb);kxo=r(QAe,"The model is set in evaluation mode by default using "),jde=n(QAe,"CODE",{});var Rlt=s(jde);Sxo=r(Rlt,"model.eval()"),Rlt.forEach(t),Rxo=r(QAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dde=n(QAe,"CODE",{});var Blt=s(Dde);Bxo=r(Blt,"model.train()"),Blt.forEach(t),QAe.forEach(t),Pxo=i(zt),Gde=n(zt,"P",{});var Plt=s(Gde);$xo=r(Plt,"Examples:"),Plt.forEach(t),Ixo=i(zt),m(FC.$$.fragment,zt),zt.forEach(t),ml.forEach(t),t$e=i(c),Cd=n(c,"H2",{class:!0});var mqe=s(Cd);Ab=n(mqe,"A",{id:!0,class:!0,href:!0});var $lt=s(Ab);Ode=n($lt,"SPAN",{});var Ilt=s(Ode);m(TC.$$.fragment,Ilt),Ilt.forEach(t),$lt.forEach(t),qxo=i(mqe),Vde=n(mqe,"SPAN",{});var qlt=s(Vde);Nxo=r(qlt,"AutoModelForMultipleChoice"),qlt.forEach(t),mqe.forEach(t),a$e=i(c),rr=n(c,"DIV",{class:!0});var hl=s(rr);m(MC.$$.fragment,hl),jxo=i(hl),wd=n(hl,"P",{});var QJ=s(wd);Dxo=r(QJ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Nj=n(QJ,"A",{href:!0});var Nlt=s(Nj);Gxo=r(Nlt,"from_pretrained()"),Nlt.forEach(t),Oxo=r(QJ," class method or the "),jj=n(QJ,"A",{href:!0});var jlt=s(jj);Vxo=r(jlt,"from_config()"),jlt.forEach(t),Xxo=r(QJ,` class
method.`),QJ.forEach(t),zxo=i(hl),EC=n(hl,"P",{});var gqe=s(EC);Qxo=r(gqe,"This class cannot be instantiated directly using "),Xde=n(gqe,"CODE",{});var Dlt=s(Xde);Wxo=r(Dlt,"__init__()"),Dlt.forEach(t),Hxo=r(gqe," (throws an error)."),gqe.forEach(t),Uxo=i(hl),Jr=n(hl,"DIV",{class:!0});var pl=s(Jr);m(CC.$$.fragment,pl),Jxo=i(pl),zde=n(pl,"P",{});var Glt=s(zde);Yxo=r(Glt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Glt.forEach(t),Kxo=i(pl),Ad=n(pl,"P",{});var WJ=s(Ad);Zxo=r(WJ,`Note:
Loading a model from its configuration file does `),Qde=n(WJ,"STRONG",{});var Olt=s(Qde);eko=r(Olt,"not"),Olt.forEach(t),oko=r(WJ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dj=n(WJ,"A",{href:!0});var Vlt=s(Dj);rko=r(Vlt,"from_pretrained()"),Vlt.forEach(t),tko=r(WJ," to load the model weights."),WJ.forEach(t),ako=i(pl),Wde=n(pl,"P",{});var Xlt=s(Wde);nko=r(Xlt,"Examples:"),Xlt.forEach(t),sko=i(pl),m(wC.$$.fragment,pl),pl.forEach(t),lko=i(hl),ze=n(hl,"DIV",{class:!0});var Qt=s(ze);m(AC.$$.fragment,Qt),iko=i(Qt),Hde=n(Qt,"P",{});var zlt=s(Hde);dko=r(zlt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),zlt.forEach(t),cko=i(Qt),Ja=n(Qt,"P",{});var i5=s(Ja);fko=r(i5,"The model class to instantiate is selected based on the "),Ude=n(i5,"CODE",{});var Qlt=s(Ude);mko=r(Qlt,"model_type"),Qlt.forEach(t),gko=r(i5,` property of the config object (either
passed as an argument or loaded from `),Jde=n(i5,"CODE",{});var Wlt=s(Jde);hko=r(Wlt,"pretrained_model_name_or_path"),Wlt.forEach(t),pko=r(i5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yde=n(i5,"CODE",{});var Hlt=s(Yde);_ko=r(Hlt,"pretrained_model_name_or_path"),Hlt.forEach(t),uko=r(i5,":"),i5.forEach(t),bko=i(Qt),G=n(Qt,"UL",{});var O=s(G);yb=n(O,"LI",{});var WAe=s(yb);Kde=n(WAe,"STRONG",{});var Ult=s(Kde);vko=r(Ult,"albert"),Ult.forEach(t),Fko=r(WAe," \u2014 "),Gj=n(WAe,"A",{href:!0});var Jlt=s(Gj);Tko=r(Jlt,"AlbertForMultipleChoice"),Jlt.forEach(t),Mko=r(WAe," (ALBERT model)"),WAe.forEach(t),Eko=i(O),Lb=n(O,"LI",{});var HAe=s(Lb);Zde=n(HAe,"STRONG",{});var Ylt=s(Zde);Cko=r(Ylt,"bert"),Ylt.forEach(t),wko=r(HAe," \u2014 "),Oj=n(HAe,"A",{href:!0});var Klt=s(Oj);Ako=r(Klt,"BertForMultipleChoice"),Klt.forEach(t),yko=r(HAe," (BERT model)"),HAe.forEach(t),Lko=i(O),xb=n(O,"LI",{});var UAe=s(xb);ece=n(UAe,"STRONG",{});var Zlt=s(ece);xko=r(Zlt,"big_bird"),Zlt.forEach(t),kko=r(UAe," \u2014 "),Vj=n(UAe,"A",{href:!0});var eit=s(Vj);Sko=r(eit,"BigBirdForMultipleChoice"),eit.forEach(t),Rko=r(UAe," (BigBird model)"),UAe.forEach(t),Bko=i(O),kb=n(O,"LI",{});var JAe=s(kb);oce=n(JAe,"STRONG",{});var oit=s(oce);Pko=r(oit,"camembert"),oit.forEach(t),$ko=r(JAe," \u2014 "),Xj=n(JAe,"A",{href:!0});var rit=s(Xj);Iko=r(rit,"CamembertForMultipleChoice"),rit.forEach(t),qko=r(JAe," (CamemBERT model)"),JAe.forEach(t),Nko=i(O),Sb=n(O,"LI",{});var YAe=s(Sb);rce=n(YAe,"STRONG",{});var tit=s(rce);jko=r(tit,"canine"),tit.forEach(t),Dko=r(YAe," \u2014 "),zj=n(YAe,"A",{href:!0});var ait=s(zj);Gko=r(ait,"CanineForMultipleChoice"),ait.forEach(t),Oko=r(YAe," (Canine model)"),YAe.forEach(t),Vko=i(O),Rb=n(O,"LI",{});var KAe=s(Rb);tce=n(KAe,"STRONG",{});var nit=s(tce);Xko=r(nit,"convbert"),nit.forEach(t),zko=r(KAe," \u2014 "),Qj=n(KAe,"A",{href:!0});var sit=s(Qj);Qko=r(sit,"ConvBertForMultipleChoice"),sit.forEach(t),Wko=r(KAe," (ConvBERT model)"),KAe.forEach(t),Hko=i(O),Bb=n(O,"LI",{});var ZAe=s(Bb);ace=n(ZAe,"STRONG",{});var lit=s(ace);Uko=r(lit,"data2vec-text"),lit.forEach(t),Jko=r(ZAe," \u2014 "),Wj=n(ZAe,"A",{href:!0});var iit=s(Wj);Yko=r(iit,"Data2VecTextForMultipleChoice"),iit.forEach(t),Kko=r(ZAe," (Data2VecText model)"),ZAe.forEach(t),Zko=i(O),Pb=n(O,"LI",{});var eye=s(Pb);nce=n(eye,"STRONG",{});var dit=s(nce);eSo=r(dit,"distilbert"),dit.forEach(t),oSo=r(eye," \u2014 "),Hj=n(eye,"A",{href:!0});var cit=s(Hj);rSo=r(cit,"DistilBertForMultipleChoice"),cit.forEach(t),tSo=r(eye," (DistilBERT model)"),eye.forEach(t),aSo=i(O),$b=n(O,"LI",{});var oye=s($b);sce=n(oye,"STRONG",{});var fit=s(sce);nSo=r(fit,"electra"),fit.forEach(t),sSo=r(oye," \u2014 "),Uj=n(oye,"A",{href:!0});var mit=s(Uj);lSo=r(mit,"ElectraForMultipleChoice"),mit.forEach(t),iSo=r(oye," (ELECTRA model)"),oye.forEach(t),dSo=i(O),Ib=n(O,"LI",{});var rye=s(Ib);lce=n(rye,"STRONG",{});var git=s(lce);cSo=r(git,"flaubert"),git.forEach(t),fSo=r(rye," \u2014 "),Jj=n(rye,"A",{href:!0});var hit=s(Jj);mSo=r(hit,"FlaubertForMultipleChoice"),hit.forEach(t),gSo=r(rye," (FlauBERT model)"),rye.forEach(t),hSo=i(O),qb=n(O,"LI",{});var tye=s(qb);ice=n(tye,"STRONG",{});var pit=s(ice);pSo=r(pit,"fnet"),pit.forEach(t),_So=r(tye," \u2014 "),Yj=n(tye,"A",{href:!0});var _it=s(Yj);uSo=r(_it,"FNetForMultipleChoice"),_it.forEach(t),bSo=r(tye," (FNet model)"),tye.forEach(t),vSo=i(O),Nb=n(O,"LI",{});var aye=s(Nb);dce=n(aye,"STRONG",{});var uit=s(dce);FSo=r(uit,"funnel"),uit.forEach(t),TSo=r(aye," \u2014 "),Kj=n(aye,"A",{href:!0});var bit=s(Kj);MSo=r(bit,"FunnelForMultipleChoice"),bit.forEach(t),ESo=r(aye," (Funnel Transformer model)"),aye.forEach(t),CSo=i(O),jb=n(O,"LI",{});var nye=s(jb);cce=n(nye,"STRONG",{});var vit=s(cce);wSo=r(vit,"ibert"),vit.forEach(t),ASo=r(nye," \u2014 "),Zj=n(nye,"A",{href:!0});var Fit=s(Zj);ySo=r(Fit,"IBertForMultipleChoice"),Fit.forEach(t),LSo=r(nye," (I-BERT model)"),nye.forEach(t),xSo=i(O),Db=n(O,"LI",{});var sye=s(Db);fce=n(sye,"STRONG",{});var Tit=s(fce);kSo=r(Tit,"longformer"),Tit.forEach(t),SSo=r(sye," \u2014 "),eD=n(sye,"A",{href:!0});var Mit=s(eD);RSo=r(Mit,"LongformerForMultipleChoice"),Mit.forEach(t),BSo=r(sye," (Longformer model)"),sye.forEach(t),PSo=i(O),Gb=n(O,"LI",{});var lye=s(Gb);mce=n(lye,"STRONG",{});var Eit=s(mce);$So=r(Eit,"megatron-bert"),Eit.forEach(t),ISo=r(lye," \u2014 "),oD=n(lye,"A",{href:!0});var Cit=s(oD);qSo=r(Cit,"MegatronBertForMultipleChoice"),Cit.forEach(t),NSo=r(lye," (MegatronBert model)"),lye.forEach(t),jSo=i(O),Ob=n(O,"LI",{});var iye=s(Ob);gce=n(iye,"STRONG",{});var wit=s(gce);DSo=r(wit,"mobilebert"),wit.forEach(t),GSo=r(iye," \u2014 "),rD=n(iye,"A",{href:!0});var Ait=s(rD);OSo=r(Ait,"MobileBertForMultipleChoice"),Ait.forEach(t),VSo=r(iye," (MobileBERT model)"),iye.forEach(t),XSo=i(O),Vb=n(O,"LI",{});var dye=s(Vb);hce=n(dye,"STRONG",{});var yit=s(hce);zSo=r(yit,"mpnet"),yit.forEach(t),QSo=r(dye," \u2014 "),tD=n(dye,"A",{href:!0});var Lit=s(tD);WSo=r(Lit,"MPNetForMultipleChoice"),Lit.forEach(t),HSo=r(dye," (MPNet model)"),dye.forEach(t),USo=i(O),Xb=n(O,"LI",{});var cye=s(Xb);pce=n(cye,"STRONG",{});var xit=s(pce);JSo=r(xit,"nystromformer"),xit.forEach(t),YSo=r(cye," \u2014 "),aD=n(cye,"A",{href:!0});var kit=s(aD);KSo=r(kit,"NystromformerForMultipleChoice"),kit.forEach(t),ZSo=r(cye," (Nystromformer model)"),cye.forEach(t),eRo=i(O),zb=n(O,"LI",{});var fye=s(zb);_ce=n(fye,"STRONG",{});var Sit=s(_ce);oRo=r(Sit,"qdqbert"),Sit.forEach(t),rRo=r(fye," \u2014 "),nD=n(fye,"A",{href:!0});var Rit=s(nD);tRo=r(Rit,"QDQBertForMultipleChoice"),Rit.forEach(t),aRo=r(fye," (QDQBert model)"),fye.forEach(t),nRo=i(O),Qb=n(O,"LI",{});var mye=s(Qb);uce=n(mye,"STRONG",{});var Bit=s(uce);sRo=r(Bit,"rembert"),Bit.forEach(t),lRo=r(mye," \u2014 "),sD=n(mye,"A",{href:!0});var Pit=s(sD);iRo=r(Pit,"RemBertForMultipleChoice"),Pit.forEach(t),dRo=r(mye," (RemBERT model)"),mye.forEach(t),cRo=i(O),Wb=n(O,"LI",{});var gye=s(Wb);bce=n(gye,"STRONG",{});var $it=s(bce);fRo=r($it,"roberta"),$it.forEach(t),mRo=r(gye," \u2014 "),lD=n(gye,"A",{href:!0});var Iit=s(lD);gRo=r(Iit,"RobertaForMultipleChoice"),Iit.forEach(t),hRo=r(gye," (RoBERTa model)"),gye.forEach(t),pRo=i(O),Hb=n(O,"LI",{});var hye=s(Hb);vce=n(hye,"STRONG",{});var qit=s(vce);_Ro=r(qit,"roformer"),qit.forEach(t),uRo=r(hye," \u2014 "),iD=n(hye,"A",{href:!0});var Nit=s(iD);bRo=r(Nit,"RoFormerForMultipleChoice"),Nit.forEach(t),vRo=r(hye," (RoFormer model)"),hye.forEach(t),FRo=i(O),Ub=n(O,"LI",{});var pye=s(Ub);Fce=n(pye,"STRONG",{});var jit=s(Fce);TRo=r(jit,"squeezebert"),jit.forEach(t),MRo=r(pye," \u2014 "),dD=n(pye,"A",{href:!0});var Dit=s(dD);ERo=r(Dit,"SqueezeBertForMultipleChoice"),Dit.forEach(t),CRo=r(pye," (SqueezeBERT model)"),pye.forEach(t),wRo=i(O),Jb=n(O,"LI",{});var _ye=s(Jb);Tce=n(_ye,"STRONG",{});var Git=s(Tce);ARo=r(Git,"xlm"),Git.forEach(t),yRo=r(_ye," \u2014 "),cD=n(_ye,"A",{href:!0});var Oit=s(cD);LRo=r(Oit,"XLMForMultipleChoice"),Oit.forEach(t),xRo=r(_ye," (XLM model)"),_ye.forEach(t),kRo=i(O),Yb=n(O,"LI",{});var uye=s(Yb);Mce=n(uye,"STRONG",{});var Vit=s(Mce);SRo=r(Vit,"xlm-roberta"),Vit.forEach(t),RRo=r(uye," \u2014 "),fD=n(uye,"A",{href:!0});var Xit=s(fD);BRo=r(Xit,"XLMRobertaForMultipleChoice"),Xit.forEach(t),PRo=r(uye," (XLM-RoBERTa model)"),uye.forEach(t),$Ro=i(O),Kb=n(O,"LI",{});var bye=s(Kb);Ece=n(bye,"STRONG",{});var zit=s(Ece);IRo=r(zit,"xlm-roberta-xl"),zit.forEach(t),qRo=r(bye," \u2014 "),mD=n(bye,"A",{href:!0});var Qit=s(mD);NRo=r(Qit,"XLMRobertaXLForMultipleChoice"),Qit.forEach(t),jRo=r(bye," (XLM-RoBERTa-XL model)"),bye.forEach(t),DRo=i(O),Zb=n(O,"LI",{});var vye=s(Zb);Cce=n(vye,"STRONG",{});var Wit=s(Cce);GRo=r(Wit,"xlnet"),Wit.forEach(t),ORo=r(vye," \u2014 "),gD=n(vye,"A",{href:!0});var Hit=s(gD);VRo=r(Hit,"XLNetForMultipleChoice"),Hit.forEach(t),XRo=r(vye," (XLNet model)"),vye.forEach(t),zRo=i(O),e6=n(O,"LI",{});var Fye=s(e6);wce=n(Fye,"STRONG",{});var Uit=s(wce);QRo=r(Uit,"yoso"),Uit.forEach(t),WRo=r(Fye," \u2014 "),hD=n(Fye,"A",{href:!0});var Jit=s(hD);HRo=r(Jit,"YosoForMultipleChoice"),Jit.forEach(t),URo=r(Fye," (YOSO model)"),Fye.forEach(t),O.forEach(t),JRo=i(Qt),o6=n(Qt,"P",{});var Tye=s(o6);YRo=r(Tye,"The model is set in evaluation mode by default using "),Ace=n(Tye,"CODE",{});var Yit=s(Ace);KRo=r(Yit,"model.eval()"),Yit.forEach(t),ZRo=r(Tye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yce=n(Tye,"CODE",{});var Kit=s(yce);eBo=r(Kit,"model.train()"),Kit.forEach(t),Tye.forEach(t),oBo=i(Qt),Lce=n(Qt,"P",{});var Zit=s(Lce);rBo=r(Zit,"Examples:"),Zit.forEach(t),tBo=i(Qt),m(yC.$$.fragment,Qt),Qt.forEach(t),hl.forEach(t),n$e=i(c),yd=n(c,"H2",{class:!0});var hqe=s(yd);r6=n(hqe,"A",{id:!0,class:!0,href:!0});var edt=s(r6);xce=n(edt,"SPAN",{});var odt=s(xce);m(LC.$$.fragment,odt),odt.forEach(t),edt.forEach(t),aBo=i(hqe),kce=n(hqe,"SPAN",{});var rdt=s(kce);nBo=r(rdt,"AutoModelForNextSentencePrediction"),rdt.forEach(t),hqe.forEach(t),s$e=i(c),tr=n(c,"DIV",{class:!0});var _l=s(tr);m(xC.$$.fragment,_l),sBo=i(_l),Ld=n(_l,"P",{});var HJ=s(Ld);lBo=r(HJ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),pD=n(HJ,"A",{href:!0});var tdt=s(pD);iBo=r(tdt,"from_pretrained()"),tdt.forEach(t),dBo=r(HJ," class method or the "),_D=n(HJ,"A",{href:!0});var adt=s(_D);cBo=r(adt,"from_config()"),adt.forEach(t),fBo=r(HJ,` class
method.`),HJ.forEach(t),mBo=i(_l),kC=n(_l,"P",{});var pqe=s(kC);gBo=r(pqe,"This class cannot be instantiated directly using "),Sce=n(pqe,"CODE",{});var ndt=s(Sce);hBo=r(ndt,"__init__()"),ndt.forEach(t),pBo=r(pqe," (throws an error)."),pqe.forEach(t),_Bo=i(_l),Yr=n(_l,"DIV",{class:!0});var ul=s(Yr);m(SC.$$.fragment,ul),uBo=i(ul),Rce=n(ul,"P",{});var sdt=s(Rce);bBo=r(sdt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),sdt.forEach(t),vBo=i(ul),xd=n(ul,"P",{});var UJ=s(xd);FBo=r(UJ,`Note:
Loading a model from its configuration file does `),Bce=n(UJ,"STRONG",{});var ldt=s(Bce);TBo=r(ldt,"not"),ldt.forEach(t),MBo=r(UJ,` load the model weights. It only affects the
model\u2019s configuration. Use `),uD=n(UJ,"A",{href:!0});var idt=s(uD);EBo=r(idt,"from_pretrained()"),idt.forEach(t),CBo=r(UJ," to load the model weights."),UJ.forEach(t),wBo=i(ul),Pce=n(ul,"P",{});var ddt=s(Pce);ABo=r(ddt,"Examples:"),ddt.forEach(t),yBo=i(ul),m(RC.$$.fragment,ul),ul.forEach(t),LBo=i(_l),Qe=n(_l,"DIV",{class:!0});var Wt=s(Qe);m(BC.$$.fragment,Wt),xBo=i(Wt),$ce=n(Wt,"P",{});var cdt=s($ce);kBo=r(cdt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),cdt.forEach(t),SBo=i(Wt),Ya=n(Wt,"P",{});var d5=s(Ya);RBo=r(d5,"The model class to instantiate is selected based on the "),Ice=n(d5,"CODE",{});var fdt=s(Ice);BBo=r(fdt,"model_type"),fdt.forEach(t),PBo=r(d5,` property of the config object (either
passed as an argument or loaded from `),qce=n(d5,"CODE",{});var mdt=s(qce);$Bo=r(mdt,"pretrained_model_name_or_path"),mdt.forEach(t),IBo=r(d5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nce=n(d5,"CODE",{});var gdt=s(Nce);qBo=r(gdt,"pretrained_model_name_or_path"),gdt.forEach(t),NBo=r(d5,":"),d5.forEach(t),jBo=i(Wt),da=n(Wt,"UL",{});var bl=s(da);t6=n(bl,"LI",{});var Mye=s(t6);jce=n(Mye,"STRONG",{});var hdt=s(jce);DBo=r(hdt,"bert"),hdt.forEach(t),GBo=r(Mye," \u2014 "),bD=n(Mye,"A",{href:!0});var pdt=s(bD);OBo=r(pdt,"BertForNextSentencePrediction"),pdt.forEach(t),VBo=r(Mye," (BERT model)"),Mye.forEach(t),XBo=i(bl),a6=n(bl,"LI",{});var Eye=s(a6);Dce=n(Eye,"STRONG",{});var _dt=s(Dce);zBo=r(_dt,"fnet"),_dt.forEach(t),QBo=r(Eye," \u2014 "),vD=n(Eye,"A",{href:!0});var udt=s(vD);WBo=r(udt,"FNetForNextSentencePrediction"),udt.forEach(t),HBo=r(Eye," (FNet model)"),Eye.forEach(t),UBo=i(bl),n6=n(bl,"LI",{});var Cye=s(n6);Gce=n(Cye,"STRONG",{});var bdt=s(Gce);JBo=r(bdt,"megatron-bert"),bdt.forEach(t),YBo=r(Cye," \u2014 "),FD=n(Cye,"A",{href:!0});var vdt=s(FD);KBo=r(vdt,"MegatronBertForNextSentencePrediction"),vdt.forEach(t),ZBo=r(Cye," (MegatronBert model)"),Cye.forEach(t),ePo=i(bl),s6=n(bl,"LI",{});var wye=s(s6);Oce=n(wye,"STRONG",{});var Fdt=s(Oce);oPo=r(Fdt,"mobilebert"),Fdt.forEach(t),rPo=r(wye," \u2014 "),TD=n(wye,"A",{href:!0});var Tdt=s(TD);tPo=r(Tdt,"MobileBertForNextSentencePrediction"),Tdt.forEach(t),aPo=r(wye," (MobileBERT model)"),wye.forEach(t),nPo=i(bl),l6=n(bl,"LI",{});var Aye=s(l6);Vce=n(Aye,"STRONG",{});var Mdt=s(Vce);sPo=r(Mdt,"qdqbert"),Mdt.forEach(t),lPo=r(Aye," \u2014 "),MD=n(Aye,"A",{href:!0});var Edt=s(MD);iPo=r(Edt,"QDQBertForNextSentencePrediction"),Edt.forEach(t),dPo=r(Aye," (QDQBert model)"),Aye.forEach(t),bl.forEach(t),cPo=i(Wt),i6=n(Wt,"P",{});var yye=s(i6);fPo=r(yye,"The model is set in evaluation mode by default using "),Xce=n(yye,"CODE",{});var Cdt=s(Xce);mPo=r(Cdt,"model.eval()"),Cdt.forEach(t),gPo=r(yye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zce=n(yye,"CODE",{});var wdt=s(zce);hPo=r(wdt,"model.train()"),wdt.forEach(t),yye.forEach(t),pPo=i(Wt),Qce=n(Wt,"P",{});var Adt=s(Qce);_Po=r(Adt,"Examples:"),Adt.forEach(t),uPo=i(Wt),m(PC.$$.fragment,Wt),Wt.forEach(t),_l.forEach(t),l$e=i(c),kd=n(c,"H2",{class:!0});var _qe=s(kd);d6=n(_qe,"A",{id:!0,class:!0,href:!0});var ydt=s(d6);Wce=n(ydt,"SPAN",{});var Ldt=s(Wce);m($C.$$.fragment,Ldt),Ldt.forEach(t),ydt.forEach(t),bPo=i(_qe),Hce=n(_qe,"SPAN",{});var xdt=s(Hce);vPo=r(xdt,"AutoModelForTokenClassification"),xdt.forEach(t),_qe.forEach(t),i$e=i(c),ar=n(c,"DIV",{class:!0});var vl=s(ar);m(IC.$$.fragment,vl),FPo=i(vl),Sd=n(vl,"P",{});var JJ=s(Sd);TPo=r(JJ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ED=n(JJ,"A",{href:!0});var kdt=s(ED);MPo=r(kdt,"from_pretrained()"),kdt.forEach(t),EPo=r(JJ," class method or the "),CD=n(JJ,"A",{href:!0});var Sdt=s(CD);CPo=r(Sdt,"from_config()"),Sdt.forEach(t),wPo=r(JJ,` class
method.`),JJ.forEach(t),APo=i(vl),qC=n(vl,"P",{});var uqe=s(qC);yPo=r(uqe,"This class cannot be instantiated directly using "),Uce=n(uqe,"CODE",{});var Rdt=s(Uce);LPo=r(Rdt,"__init__()"),Rdt.forEach(t),xPo=r(uqe," (throws an error)."),uqe.forEach(t),kPo=i(vl),Kr=n(vl,"DIV",{class:!0});var Fl=s(Kr);m(NC.$$.fragment,Fl),SPo=i(Fl),Jce=n(Fl,"P",{});var Bdt=s(Jce);RPo=r(Bdt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Bdt.forEach(t),BPo=i(Fl),Rd=n(Fl,"P",{});var YJ=s(Rd);PPo=r(YJ,`Note:
Loading a model from its configuration file does `),Yce=n(YJ,"STRONG",{});var Pdt=s(Yce);$Po=r(Pdt,"not"),Pdt.forEach(t),IPo=r(YJ,` load the model weights. It only affects the
model\u2019s configuration. Use `),wD=n(YJ,"A",{href:!0});var $dt=s(wD);qPo=r($dt,"from_pretrained()"),$dt.forEach(t),NPo=r(YJ," to load the model weights."),YJ.forEach(t),jPo=i(Fl),Kce=n(Fl,"P",{});var Idt=s(Kce);DPo=r(Idt,"Examples:"),Idt.forEach(t),GPo=i(Fl),m(jC.$$.fragment,Fl),Fl.forEach(t),OPo=i(vl),We=n(vl,"DIV",{class:!0});var Ht=s(We);m(DC.$$.fragment,Ht),VPo=i(Ht),Zce=n(Ht,"P",{});var qdt=s(Zce);XPo=r(qdt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),qdt.forEach(t),zPo=i(Ht),Ka=n(Ht,"P",{});var c5=s(Ka);QPo=r(c5,"The model class to instantiate is selected based on the "),efe=n(c5,"CODE",{});var Ndt=s(efe);WPo=r(Ndt,"model_type"),Ndt.forEach(t),HPo=r(c5,` property of the config object (either
passed as an argument or loaded from `),ofe=n(c5,"CODE",{});var jdt=s(ofe);UPo=r(jdt,"pretrained_model_name_or_path"),jdt.forEach(t),JPo=r(c5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rfe=n(c5,"CODE",{});var Ddt=s(rfe);YPo=r(Ddt,"pretrained_model_name_or_path"),Ddt.forEach(t),KPo=r(c5,":"),c5.forEach(t),ZPo=i(Ht),j=n(Ht,"UL",{});var D=s(j);c6=n(D,"LI",{});var Lye=s(c6);tfe=n(Lye,"STRONG",{});var Gdt=s(tfe);e$o=r(Gdt,"albert"),Gdt.forEach(t),o$o=r(Lye," \u2014 "),AD=n(Lye,"A",{href:!0});var Odt=s(AD);r$o=r(Odt,"AlbertForTokenClassification"),Odt.forEach(t),t$o=r(Lye," (ALBERT model)"),Lye.forEach(t),a$o=i(D),f6=n(D,"LI",{});var xye=s(f6);afe=n(xye,"STRONG",{});var Vdt=s(afe);n$o=r(Vdt,"bert"),Vdt.forEach(t),s$o=r(xye," \u2014 "),yD=n(xye,"A",{href:!0});var Xdt=s(yD);l$o=r(Xdt,"BertForTokenClassification"),Xdt.forEach(t),i$o=r(xye," (BERT model)"),xye.forEach(t),d$o=i(D),m6=n(D,"LI",{});var kye=s(m6);nfe=n(kye,"STRONG",{});var zdt=s(nfe);c$o=r(zdt,"big_bird"),zdt.forEach(t),f$o=r(kye," \u2014 "),LD=n(kye,"A",{href:!0});var Qdt=s(LD);m$o=r(Qdt,"BigBirdForTokenClassification"),Qdt.forEach(t),g$o=r(kye," (BigBird model)"),kye.forEach(t),h$o=i(D),g6=n(D,"LI",{});var Sye=s(g6);sfe=n(Sye,"STRONG",{});var Wdt=s(sfe);p$o=r(Wdt,"camembert"),Wdt.forEach(t),_$o=r(Sye," \u2014 "),xD=n(Sye,"A",{href:!0});var Hdt=s(xD);u$o=r(Hdt,"CamembertForTokenClassification"),Hdt.forEach(t),b$o=r(Sye," (CamemBERT model)"),Sye.forEach(t),v$o=i(D),h6=n(D,"LI",{});var Rye=s(h6);lfe=n(Rye,"STRONG",{});var Udt=s(lfe);F$o=r(Udt,"canine"),Udt.forEach(t),T$o=r(Rye," \u2014 "),kD=n(Rye,"A",{href:!0});var Jdt=s(kD);M$o=r(Jdt,"CanineForTokenClassification"),Jdt.forEach(t),E$o=r(Rye," (Canine model)"),Rye.forEach(t),C$o=i(D),p6=n(D,"LI",{});var Bye=s(p6);ife=n(Bye,"STRONG",{});var Ydt=s(ife);w$o=r(Ydt,"convbert"),Ydt.forEach(t),A$o=r(Bye," \u2014 "),SD=n(Bye,"A",{href:!0});var Kdt=s(SD);y$o=r(Kdt,"ConvBertForTokenClassification"),Kdt.forEach(t),L$o=r(Bye," (ConvBERT model)"),Bye.forEach(t),x$o=i(D),_6=n(D,"LI",{});var Pye=s(_6);dfe=n(Pye,"STRONG",{});var Zdt=s(dfe);k$o=r(Zdt,"data2vec-text"),Zdt.forEach(t),S$o=r(Pye," \u2014 "),RD=n(Pye,"A",{href:!0});var ect=s(RD);R$o=r(ect,"Data2VecTextForTokenClassification"),ect.forEach(t),B$o=r(Pye," (Data2VecText model)"),Pye.forEach(t),P$o=i(D),u6=n(D,"LI",{});var $ye=s(u6);cfe=n($ye,"STRONG",{});var oct=s(cfe);$$o=r(oct,"deberta"),oct.forEach(t),I$o=r($ye," \u2014 "),BD=n($ye,"A",{href:!0});var rct=s(BD);q$o=r(rct,"DebertaForTokenClassification"),rct.forEach(t),N$o=r($ye," (DeBERTa model)"),$ye.forEach(t),j$o=i(D),b6=n(D,"LI",{});var Iye=s(b6);ffe=n(Iye,"STRONG",{});var tct=s(ffe);D$o=r(tct,"deberta-v2"),tct.forEach(t),G$o=r(Iye," \u2014 "),PD=n(Iye,"A",{href:!0});var act=s(PD);O$o=r(act,"DebertaV2ForTokenClassification"),act.forEach(t),V$o=r(Iye," (DeBERTa-v2 model)"),Iye.forEach(t),X$o=i(D),v6=n(D,"LI",{});var qye=s(v6);mfe=n(qye,"STRONG",{});var nct=s(mfe);z$o=r(nct,"distilbert"),nct.forEach(t),Q$o=r(qye," \u2014 "),$D=n(qye,"A",{href:!0});var sct=s($D);W$o=r(sct,"DistilBertForTokenClassification"),sct.forEach(t),H$o=r(qye," (DistilBERT model)"),qye.forEach(t),U$o=i(D),F6=n(D,"LI",{});var Nye=s(F6);gfe=n(Nye,"STRONG",{});var lct=s(gfe);J$o=r(lct,"electra"),lct.forEach(t),Y$o=r(Nye," \u2014 "),ID=n(Nye,"A",{href:!0});var ict=s(ID);K$o=r(ict,"ElectraForTokenClassification"),ict.forEach(t),Z$o=r(Nye," (ELECTRA model)"),Nye.forEach(t),eIo=i(D),T6=n(D,"LI",{});var jye=s(T6);hfe=n(jye,"STRONG",{});var dct=s(hfe);oIo=r(dct,"flaubert"),dct.forEach(t),rIo=r(jye," \u2014 "),qD=n(jye,"A",{href:!0});var cct=s(qD);tIo=r(cct,"FlaubertForTokenClassification"),cct.forEach(t),aIo=r(jye," (FlauBERT model)"),jye.forEach(t),nIo=i(D),M6=n(D,"LI",{});var Dye=s(M6);pfe=n(Dye,"STRONG",{});var fct=s(pfe);sIo=r(fct,"fnet"),fct.forEach(t),lIo=r(Dye," \u2014 "),ND=n(Dye,"A",{href:!0});var mct=s(ND);iIo=r(mct,"FNetForTokenClassification"),mct.forEach(t),dIo=r(Dye," (FNet model)"),Dye.forEach(t),cIo=i(D),E6=n(D,"LI",{});var Gye=s(E6);_fe=n(Gye,"STRONG",{});var gct=s(_fe);fIo=r(gct,"funnel"),gct.forEach(t),mIo=r(Gye," \u2014 "),jD=n(Gye,"A",{href:!0});var hct=s(jD);gIo=r(hct,"FunnelForTokenClassification"),hct.forEach(t),hIo=r(Gye," (Funnel Transformer model)"),Gye.forEach(t),pIo=i(D),C6=n(D,"LI",{});var Oye=s(C6);ufe=n(Oye,"STRONG",{});var pct=s(ufe);_Io=r(pct,"gpt2"),pct.forEach(t),uIo=r(Oye," \u2014 "),DD=n(Oye,"A",{href:!0});var _ct=s(DD);bIo=r(_ct,"GPT2ForTokenClassification"),_ct.forEach(t),vIo=r(Oye," (OpenAI GPT-2 model)"),Oye.forEach(t),FIo=i(D),w6=n(D,"LI",{});var Vye=s(w6);bfe=n(Vye,"STRONG",{});var uct=s(bfe);TIo=r(uct,"ibert"),uct.forEach(t),MIo=r(Vye," \u2014 "),GD=n(Vye,"A",{href:!0});var bct=s(GD);EIo=r(bct,"IBertForTokenClassification"),bct.forEach(t),CIo=r(Vye," (I-BERT model)"),Vye.forEach(t),wIo=i(D),A6=n(D,"LI",{});var Xye=s(A6);vfe=n(Xye,"STRONG",{});var vct=s(vfe);AIo=r(vct,"layoutlm"),vct.forEach(t),yIo=r(Xye," \u2014 "),OD=n(Xye,"A",{href:!0});var Fct=s(OD);LIo=r(Fct,"LayoutLMForTokenClassification"),Fct.forEach(t),xIo=r(Xye," (LayoutLM model)"),Xye.forEach(t),kIo=i(D),y6=n(D,"LI",{});var zye=s(y6);Ffe=n(zye,"STRONG",{});var Tct=s(Ffe);SIo=r(Tct,"layoutlmv2"),Tct.forEach(t),RIo=r(zye," \u2014 "),VD=n(zye,"A",{href:!0});var Mct=s(VD);BIo=r(Mct,"LayoutLMv2ForTokenClassification"),Mct.forEach(t),PIo=r(zye," (LayoutLMv2 model)"),zye.forEach(t),$Io=i(D),L6=n(D,"LI",{});var Qye=s(L6);Tfe=n(Qye,"STRONG",{});var Ect=s(Tfe);IIo=r(Ect,"longformer"),Ect.forEach(t),qIo=r(Qye," \u2014 "),XD=n(Qye,"A",{href:!0});var Cct=s(XD);NIo=r(Cct,"LongformerForTokenClassification"),Cct.forEach(t),jIo=r(Qye," (Longformer model)"),Qye.forEach(t),DIo=i(D),x6=n(D,"LI",{});var Wye=s(x6);Mfe=n(Wye,"STRONG",{});var wct=s(Mfe);GIo=r(wct,"megatron-bert"),wct.forEach(t),OIo=r(Wye," \u2014 "),zD=n(Wye,"A",{href:!0});var Act=s(zD);VIo=r(Act,"MegatronBertForTokenClassification"),Act.forEach(t),XIo=r(Wye," (MegatronBert model)"),Wye.forEach(t),zIo=i(D),k6=n(D,"LI",{});var Hye=s(k6);Efe=n(Hye,"STRONG",{});var yct=s(Efe);QIo=r(yct,"mobilebert"),yct.forEach(t),WIo=r(Hye," \u2014 "),QD=n(Hye,"A",{href:!0});var Lct=s(QD);HIo=r(Lct,"MobileBertForTokenClassification"),Lct.forEach(t),UIo=r(Hye," (MobileBERT model)"),Hye.forEach(t),JIo=i(D),S6=n(D,"LI",{});var Uye=s(S6);Cfe=n(Uye,"STRONG",{});var xct=s(Cfe);YIo=r(xct,"mpnet"),xct.forEach(t),KIo=r(Uye," \u2014 "),WD=n(Uye,"A",{href:!0});var kct=s(WD);ZIo=r(kct,"MPNetForTokenClassification"),kct.forEach(t),eqo=r(Uye," (MPNet model)"),Uye.forEach(t),oqo=i(D),R6=n(D,"LI",{});var Jye=s(R6);wfe=n(Jye,"STRONG",{});var Sct=s(wfe);rqo=r(Sct,"nystromformer"),Sct.forEach(t),tqo=r(Jye," \u2014 "),HD=n(Jye,"A",{href:!0});var Rct=s(HD);aqo=r(Rct,"NystromformerForTokenClassification"),Rct.forEach(t),nqo=r(Jye," (Nystromformer model)"),Jye.forEach(t),sqo=i(D),B6=n(D,"LI",{});var Yye=s(B6);Afe=n(Yye,"STRONG",{});var Bct=s(Afe);lqo=r(Bct,"qdqbert"),Bct.forEach(t),iqo=r(Yye," \u2014 "),UD=n(Yye,"A",{href:!0});var Pct=s(UD);dqo=r(Pct,"QDQBertForTokenClassification"),Pct.forEach(t),cqo=r(Yye," (QDQBert model)"),Yye.forEach(t),fqo=i(D),P6=n(D,"LI",{});var Kye=s(P6);yfe=n(Kye,"STRONG",{});var $ct=s(yfe);mqo=r($ct,"rembert"),$ct.forEach(t),gqo=r(Kye," \u2014 "),JD=n(Kye,"A",{href:!0});var Ict=s(JD);hqo=r(Ict,"RemBertForTokenClassification"),Ict.forEach(t),pqo=r(Kye," (RemBERT model)"),Kye.forEach(t),_qo=i(D),$6=n(D,"LI",{});var Zye=s($6);Lfe=n(Zye,"STRONG",{});var qct=s(Lfe);uqo=r(qct,"roberta"),qct.forEach(t),bqo=r(Zye," \u2014 "),YD=n(Zye,"A",{href:!0});var Nct=s(YD);vqo=r(Nct,"RobertaForTokenClassification"),Nct.forEach(t),Fqo=r(Zye," (RoBERTa model)"),Zye.forEach(t),Tqo=i(D),I6=n(D,"LI",{});var eLe=s(I6);xfe=n(eLe,"STRONG",{});var jct=s(xfe);Mqo=r(jct,"roformer"),jct.forEach(t),Eqo=r(eLe," \u2014 "),KD=n(eLe,"A",{href:!0});var Dct=s(KD);Cqo=r(Dct,"RoFormerForTokenClassification"),Dct.forEach(t),wqo=r(eLe," (RoFormer model)"),eLe.forEach(t),Aqo=i(D),q6=n(D,"LI",{});var oLe=s(q6);kfe=n(oLe,"STRONG",{});var Gct=s(kfe);yqo=r(Gct,"squeezebert"),Gct.forEach(t),Lqo=r(oLe," \u2014 "),ZD=n(oLe,"A",{href:!0});var Oct=s(ZD);xqo=r(Oct,"SqueezeBertForTokenClassification"),Oct.forEach(t),kqo=r(oLe," (SqueezeBERT model)"),oLe.forEach(t),Sqo=i(D),N6=n(D,"LI",{});var rLe=s(N6);Sfe=n(rLe,"STRONG",{});var Vct=s(Sfe);Rqo=r(Vct,"xlm"),Vct.forEach(t),Bqo=r(rLe," \u2014 "),eG=n(rLe,"A",{href:!0});var Xct=s(eG);Pqo=r(Xct,"XLMForTokenClassification"),Xct.forEach(t),$qo=r(rLe," (XLM model)"),rLe.forEach(t),Iqo=i(D),j6=n(D,"LI",{});var tLe=s(j6);Rfe=n(tLe,"STRONG",{});var zct=s(Rfe);qqo=r(zct,"xlm-roberta"),zct.forEach(t),Nqo=r(tLe," \u2014 "),oG=n(tLe,"A",{href:!0});var Qct=s(oG);jqo=r(Qct,"XLMRobertaForTokenClassification"),Qct.forEach(t),Dqo=r(tLe," (XLM-RoBERTa model)"),tLe.forEach(t),Gqo=i(D),D6=n(D,"LI",{});var aLe=s(D6);Bfe=n(aLe,"STRONG",{});var Wct=s(Bfe);Oqo=r(Wct,"xlm-roberta-xl"),Wct.forEach(t),Vqo=r(aLe," \u2014 "),rG=n(aLe,"A",{href:!0});var Hct=s(rG);Xqo=r(Hct,"XLMRobertaXLForTokenClassification"),Hct.forEach(t),zqo=r(aLe," (XLM-RoBERTa-XL model)"),aLe.forEach(t),Qqo=i(D),G6=n(D,"LI",{});var nLe=s(G6);Pfe=n(nLe,"STRONG",{});var Uct=s(Pfe);Wqo=r(Uct,"xlnet"),Uct.forEach(t),Hqo=r(nLe," \u2014 "),tG=n(nLe,"A",{href:!0});var Jct=s(tG);Uqo=r(Jct,"XLNetForTokenClassification"),Jct.forEach(t),Jqo=r(nLe," (XLNet model)"),nLe.forEach(t),Yqo=i(D),O6=n(D,"LI",{});var sLe=s(O6);$fe=n(sLe,"STRONG",{});var Yct=s($fe);Kqo=r(Yct,"yoso"),Yct.forEach(t),Zqo=r(sLe," \u2014 "),aG=n(sLe,"A",{href:!0});var Kct=s(aG);eNo=r(Kct,"YosoForTokenClassification"),Kct.forEach(t),oNo=r(sLe," (YOSO model)"),sLe.forEach(t),D.forEach(t),rNo=i(Ht),V6=n(Ht,"P",{});var lLe=s(V6);tNo=r(lLe,"The model is set in evaluation mode by default using "),Ife=n(lLe,"CODE",{});var Zct=s(Ife);aNo=r(Zct,"model.eval()"),Zct.forEach(t),nNo=r(lLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qfe=n(lLe,"CODE",{});var eft=s(qfe);sNo=r(eft,"model.train()"),eft.forEach(t),lLe.forEach(t),lNo=i(Ht),Nfe=n(Ht,"P",{});var oft=s(Nfe);iNo=r(oft,"Examples:"),oft.forEach(t),dNo=i(Ht),m(GC.$$.fragment,Ht),Ht.forEach(t),vl.forEach(t),d$e=i(c),Bd=n(c,"H2",{class:!0});var bqe=s(Bd);X6=n(bqe,"A",{id:!0,class:!0,href:!0});var rft=s(X6);jfe=n(rft,"SPAN",{});var tft=s(jfe);m(OC.$$.fragment,tft),tft.forEach(t),rft.forEach(t),cNo=i(bqe),Dfe=n(bqe,"SPAN",{});var aft=s(Dfe);fNo=r(aft,"AutoModelForQuestionAnswering"),aft.forEach(t),bqe.forEach(t),c$e=i(c),nr=n(c,"DIV",{class:!0});var Tl=s(nr);m(VC.$$.fragment,Tl),mNo=i(Tl),Pd=n(Tl,"P",{});var KJ=s(Pd);gNo=r(KJ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),nG=n(KJ,"A",{href:!0});var nft=s(nG);hNo=r(nft,"from_pretrained()"),nft.forEach(t),pNo=r(KJ," class method or the "),sG=n(KJ,"A",{href:!0});var sft=s(sG);_No=r(sft,"from_config()"),sft.forEach(t),uNo=r(KJ,` class
method.`),KJ.forEach(t),bNo=i(Tl),XC=n(Tl,"P",{});var vqe=s(XC);vNo=r(vqe,"This class cannot be instantiated directly using "),Gfe=n(vqe,"CODE",{});var lft=s(Gfe);FNo=r(lft,"__init__()"),lft.forEach(t),TNo=r(vqe," (throws an error)."),vqe.forEach(t),MNo=i(Tl),Zr=n(Tl,"DIV",{class:!0});var Ml=s(Zr);m(zC.$$.fragment,Ml),ENo=i(Ml),Ofe=n(Ml,"P",{});var ift=s(Ofe);CNo=r(ift,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),ift.forEach(t),wNo=i(Ml),$d=n(Ml,"P",{});var ZJ=s($d);ANo=r(ZJ,`Note:
Loading a model from its configuration file does `),Vfe=n(ZJ,"STRONG",{});var dft=s(Vfe);yNo=r(dft,"not"),dft.forEach(t),LNo=r(ZJ,` load the model weights. It only affects the
model\u2019s configuration. Use `),lG=n(ZJ,"A",{href:!0});var cft=s(lG);xNo=r(cft,"from_pretrained()"),cft.forEach(t),kNo=r(ZJ," to load the model weights."),ZJ.forEach(t),SNo=i(Ml),Xfe=n(Ml,"P",{});var fft=s(Xfe);RNo=r(fft,"Examples:"),fft.forEach(t),BNo=i(Ml),m(QC.$$.fragment,Ml),Ml.forEach(t),PNo=i(Tl),He=n(Tl,"DIV",{class:!0});var Ut=s(He);m(WC.$$.fragment,Ut),$No=i(Ut),zfe=n(Ut,"P",{});var mft=s(zfe);INo=r(mft,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),mft.forEach(t),qNo=i(Ut),Za=n(Ut,"P",{});var f5=s(Za);NNo=r(f5,"The model class to instantiate is selected based on the "),Qfe=n(f5,"CODE",{});var gft=s(Qfe);jNo=r(gft,"model_type"),gft.forEach(t),DNo=r(f5,` property of the config object (either
passed as an argument or loaded from `),Wfe=n(f5,"CODE",{});var hft=s(Wfe);GNo=r(hft,"pretrained_model_name_or_path"),hft.forEach(t),ONo=r(f5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hfe=n(f5,"CODE",{});var pft=s(Hfe);VNo=r(pft,"pretrained_model_name_or_path"),pft.forEach(t),XNo=r(f5,":"),f5.forEach(t),zNo=i(Ut),R=n(Ut,"UL",{});var P=s(R);z6=n(P,"LI",{});var iLe=s(z6);Ufe=n(iLe,"STRONG",{});var _ft=s(Ufe);QNo=r(_ft,"albert"),_ft.forEach(t),WNo=r(iLe," \u2014 "),iG=n(iLe,"A",{href:!0});var uft=s(iG);HNo=r(uft,"AlbertForQuestionAnswering"),uft.forEach(t),UNo=r(iLe," (ALBERT model)"),iLe.forEach(t),JNo=i(P),Q6=n(P,"LI",{});var dLe=s(Q6);Jfe=n(dLe,"STRONG",{});var bft=s(Jfe);YNo=r(bft,"bart"),bft.forEach(t),KNo=r(dLe," \u2014 "),dG=n(dLe,"A",{href:!0});var vft=s(dG);ZNo=r(vft,"BartForQuestionAnswering"),vft.forEach(t),ejo=r(dLe," (BART model)"),dLe.forEach(t),ojo=i(P),W6=n(P,"LI",{});var cLe=s(W6);Yfe=n(cLe,"STRONG",{});var Fft=s(Yfe);rjo=r(Fft,"bert"),Fft.forEach(t),tjo=r(cLe," \u2014 "),cG=n(cLe,"A",{href:!0});var Tft=s(cG);ajo=r(Tft,"BertForQuestionAnswering"),Tft.forEach(t),njo=r(cLe," (BERT model)"),cLe.forEach(t),sjo=i(P),H6=n(P,"LI",{});var fLe=s(H6);Kfe=n(fLe,"STRONG",{});var Mft=s(Kfe);ljo=r(Mft,"big_bird"),Mft.forEach(t),ijo=r(fLe," \u2014 "),fG=n(fLe,"A",{href:!0});var Eft=s(fG);djo=r(Eft,"BigBirdForQuestionAnswering"),Eft.forEach(t),cjo=r(fLe," (BigBird model)"),fLe.forEach(t),fjo=i(P),U6=n(P,"LI",{});var mLe=s(U6);Zfe=n(mLe,"STRONG",{});var Cft=s(Zfe);mjo=r(Cft,"bigbird_pegasus"),Cft.forEach(t),gjo=r(mLe," \u2014 "),mG=n(mLe,"A",{href:!0});var wft=s(mG);hjo=r(wft,"BigBirdPegasusForQuestionAnswering"),wft.forEach(t),pjo=r(mLe," (BigBirdPegasus model)"),mLe.forEach(t),_jo=i(P),J6=n(P,"LI",{});var gLe=s(J6);eme=n(gLe,"STRONG",{});var Aft=s(eme);ujo=r(Aft,"camembert"),Aft.forEach(t),bjo=r(gLe," \u2014 "),gG=n(gLe,"A",{href:!0});var yft=s(gG);vjo=r(yft,"CamembertForQuestionAnswering"),yft.forEach(t),Fjo=r(gLe," (CamemBERT model)"),gLe.forEach(t),Tjo=i(P),Y6=n(P,"LI",{});var hLe=s(Y6);ome=n(hLe,"STRONG",{});var Lft=s(ome);Mjo=r(Lft,"canine"),Lft.forEach(t),Ejo=r(hLe," \u2014 "),hG=n(hLe,"A",{href:!0});var xft=s(hG);Cjo=r(xft,"CanineForQuestionAnswering"),xft.forEach(t),wjo=r(hLe," (Canine model)"),hLe.forEach(t),Ajo=i(P),K6=n(P,"LI",{});var pLe=s(K6);rme=n(pLe,"STRONG",{});var kft=s(rme);yjo=r(kft,"convbert"),kft.forEach(t),Ljo=r(pLe," \u2014 "),pG=n(pLe,"A",{href:!0});var Sft=s(pG);xjo=r(Sft,"ConvBertForQuestionAnswering"),Sft.forEach(t),kjo=r(pLe," (ConvBERT model)"),pLe.forEach(t),Sjo=i(P),Z6=n(P,"LI",{});var _Le=s(Z6);tme=n(_Le,"STRONG",{});var Rft=s(tme);Rjo=r(Rft,"data2vec-text"),Rft.forEach(t),Bjo=r(_Le," \u2014 "),_G=n(_Le,"A",{href:!0});var Bft=s(_G);Pjo=r(Bft,"Data2VecTextForQuestionAnswering"),Bft.forEach(t),$jo=r(_Le," (Data2VecText model)"),_Le.forEach(t),Ijo=i(P),ev=n(P,"LI",{});var uLe=s(ev);ame=n(uLe,"STRONG",{});var Pft=s(ame);qjo=r(Pft,"deberta"),Pft.forEach(t),Njo=r(uLe," \u2014 "),uG=n(uLe,"A",{href:!0});var $ft=s(uG);jjo=r($ft,"DebertaForQuestionAnswering"),$ft.forEach(t),Djo=r(uLe," (DeBERTa model)"),uLe.forEach(t),Gjo=i(P),ov=n(P,"LI",{});var bLe=s(ov);nme=n(bLe,"STRONG",{});var Ift=s(nme);Ojo=r(Ift,"deberta-v2"),Ift.forEach(t),Vjo=r(bLe," \u2014 "),bG=n(bLe,"A",{href:!0});var qft=s(bG);Xjo=r(qft,"DebertaV2ForQuestionAnswering"),qft.forEach(t),zjo=r(bLe," (DeBERTa-v2 model)"),bLe.forEach(t),Qjo=i(P),rv=n(P,"LI",{});var vLe=s(rv);sme=n(vLe,"STRONG",{});var Nft=s(sme);Wjo=r(Nft,"distilbert"),Nft.forEach(t),Hjo=r(vLe," \u2014 "),vG=n(vLe,"A",{href:!0});var jft=s(vG);Ujo=r(jft,"DistilBertForQuestionAnswering"),jft.forEach(t),Jjo=r(vLe," (DistilBERT model)"),vLe.forEach(t),Yjo=i(P),tv=n(P,"LI",{});var FLe=s(tv);lme=n(FLe,"STRONG",{});var Dft=s(lme);Kjo=r(Dft,"electra"),Dft.forEach(t),Zjo=r(FLe," \u2014 "),FG=n(FLe,"A",{href:!0});var Gft=s(FG);eDo=r(Gft,"ElectraForQuestionAnswering"),Gft.forEach(t),oDo=r(FLe," (ELECTRA model)"),FLe.forEach(t),rDo=i(P),av=n(P,"LI",{});var TLe=s(av);ime=n(TLe,"STRONG",{});var Oft=s(ime);tDo=r(Oft,"flaubert"),Oft.forEach(t),aDo=r(TLe," \u2014 "),TG=n(TLe,"A",{href:!0});var Vft=s(TG);nDo=r(Vft,"FlaubertForQuestionAnsweringSimple"),Vft.forEach(t),sDo=r(TLe," (FlauBERT model)"),TLe.forEach(t),lDo=i(P),nv=n(P,"LI",{});var MLe=s(nv);dme=n(MLe,"STRONG",{});var Xft=s(dme);iDo=r(Xft,"fnet"),Xft.forEach(t),dDo=r(MLe," \u2014 "),MG=n(MLe,"A",{href:!0});var zft=s(MG);cDo=r(zft,"FNetForQuestionAnswering"),zft.forEach(t),fDo=r(MLe," (FNet model)"),MLe.forEach(t),mDo=i(P),sv=n(P,"LI",{});var ELe=s(sv);cme=n(ELe,"STRONG",{});var Qft=s(cme);gDo=r(Qft,"funnel"),Qft.forEach(t),hDo=r(ELe," \u2014 "),EG=n(ELe,"A",{href:!0});var Wft=s(EG);pDo=r(Wft,"FunnelForQuestionAnswering"),Wft.forEach(t),_Do=r(ELe," (Funnel Transformer model)"),ELe.forEach(t),uDo=i(P),lv=n(P,"LI",{});var CLe=s(lv);fme=n(CLe,"STRONG",{});var Hft=s(fme);bDo=r(Hft,"gptj"),Hft.forEach(t),vDo=r(CLe," \u2014 "),CG=n(CLe,"A",{href:!0});var Uft=s(CG);FDo=r(Uft,"GPTJForQuestionAnswering"),Uft.forEach(t),TDo=r(CLe," (GPT-J model)"),CLe.forEach(t),MDo=i(P),iv=n(P,"LI",{});var wLe=s(iv);mme=n(wLe,"STRONG",{});var Jft=s(mme);EDo=r(Jft,"ibert"),Jft.forEach(t),CDo=r(wLe," \u2014 "),wG=n(wLe,"A",{href:!0});var Yft=s(wG);wDo=r(Yft,"IBertForQuestionAnswering"),Yft.forEach(t),ADo=r(wLe," (I-BERT model)"),wLe.forEach(t),yDo=i(P),dv=n(P,"LI",{});var ALe=s(dv);gme=n(ALe,"STRONG",{});var Kft=s(gme);LDo=r(Kft,"layoutlmv2"),Kft.forEach(t),xDo=r(ALe," \u2014 "),AG=n(ALe,"A",{href:!0});var Zft=s(AG);kDo=r(Zft,"LayoutLMv2ForQuestionAnswering"),Zft.forEach(t),SDo=r(ALe," (LayoutLMv2 model)"),ALe.forEach(t),RDo=i(P),cv=n(P,"LI",{});var yLe=s(cv);hme=n(yLe,"STRONG",{});var emt=s(hme);BDo=r(emt,"led"),emt.forEach(t),PDo=r(yLe," \u2014 "),yG=n(yLe,"A",{href:!0});var omt=s(yG);$Do=r(omt,"LEDForQuestionAnswering"),omt.forEach(t),IDo=r(yLe," (LED model)"),yLe.forEach(t),qDo=i(P),fv=n(P,"LI",{});var LLe=s(fv);pme=n(LLe,"STRONG",{});var rmt=s(pme);NDo=r(rmt,"longformer"),rmt.forEach(t),jDo=r(LLe," \u2014 "),LG=n(LLe,"A",{href:!0});var tmt=s(LG);DDo=r(tmt,"LongformerForQuestionAnswering"),tmt.forEach(t),GDo=r(LLe," (Longformer model)"),LLe.forEach(t),ODo=i(P),mv=n(P,"LI",{});var xLe=s(mv);_me=n(xLe,"STRONG",{});var amt=s(_me);VDo=r(amt,"lxmert"),amt.forEach(t),XDo=r(xLe," \u2014 "),xG=n(xLe,"A",{href:!0});var nmt=s(xG);zDo=r(nmt,"LxmertForQuestionAnswering"),nmt.forEach(t),QDo=r(xLe," (LXMERT model)"),xLe.forEach(t),WDo=i(P),gv=n(P,"LI",{});var kLe=s(gv);ume=n(kLe,"STRONG",{});var smt=s(ume);HDo=r(smt,"mbart"),smt.forEach(t),UDo=r(kLe," \u2014 "),kG=n(kLe,"A",{href:!0});var lmt=s(kG);JDo=r(lmt,"MBartForQuestionAnswering"),lmt.forEach(t),YDo=r(kLe," (mBART model)"),kLe.forEach(t),KDo=i(P),hv=n(P,"LI",{});var SLe=s(hv);bme=n(SLe,"STRONG",{});var imt=s(bme);ZDo=r(imt,"megatron-bert"),imt.forEach(t),eGo=r(SLe," \u2014 "),SG=n(SLe,"A",{href:!0});var dmt=s(SG);oGo=r(dmt,"MegatronBertForQuestionAnswering"),dmt.forEach(t),rGo=r(SLe," (MegatronBert model)"),SLe.forEach(t),tGo=i(P),pv=n(P,"LI",{});var RLe=s(pv);vme=n(RLe,"STRONG",{});var cmt=s(vme);aGo=r(cmt,"mobilebert"),cmt.forEach(t),nGo=r(RLe," \u2014 "),RG=n(RLe,"A",{href:!0});var fmt=s(RG);sGo=r(fmt,"MobileBertForQuestionAnswering"),fmt.forEach(t),lGo=r(RLe," (MobileBERT model)"),RLe.forEach(t),iGo=i(P),_v=n(P,"LI",{});var BLe=s(_v);Fme=n(BLe,"STRONG",{});var mmt=s(Fme);dGo=r(mmt,"mpnet"),mmt.forEach(t),cGo=r(BLe," \u2014 "),BG=n(BLe,"A",{href:!0});var gmt=s(BG);fGo=r(gmt,"MPNetForQuestionAnswering"),gmt.forEach(t),mGo=r(BLe," (MPNet model)"),BLe.forEach(t),gGo=i(P),uv=n(P,"LI",{});var PLe=s(uv);Tme=n(PLe,"STRONG",{});var hmt=s(Tme);hGo=r(hmt,"nystromformer"),hmt.forEach(t),pGo=r(PLe," \u2014 "),PG=n(PLe,"A",{href:!0});var pmt=s(PG);_Go=r(pmt,"NystromformerForQuestionAnswering"),pmt.forEach(t),uGo=r(PLe," (Nystromformer model)"),PLe.forEach(t),bGo=i(P),bv=n(P,"LI",{});var $Le=s(bv);Mme=n($Le,"STRONG",{});var _mt=s(Mme);vGo=r(_mt,"qdqbert"),_mt.forEach(t),FGo=r($Le," \u2014 "),$G=n($Le,"A",{href:!0});var umt=s($G);TGo=r(umt,"QDQBertForQuestionAnswering"),umt.forEach(t),MGo=r($Le," (QDQBert model)"),$Le.forEach(t),EGo=i(P),vv=n(P,"LI",{});var ILe=s(vv);Eme=n(ILe,"STRONG",{});var bmt=s(Eme);CGo=r(bmt,"reformer"),bmt.forEach(t),wGo=r(ILe," \u2014 "),IG=n(ILe,"A",{href:!0});var vmt=s(IG);AGo=r(vmt,"ReformerForQuestionAnswering"),vmt.forEach(t),yGo=r(ILe," (Reformer model)"),ILe.forEach(t),LGo=i(P),Fv=n(P,"LI",{});var qLe=s(Fv);Cme=n(qLe,"STRONG",{});var Fmt=s(Cme);xGo=r(Fmt,"rembert"),Fmt.forEach(t),kGo=r(qLe," \u2014 "),qG=n(qLe,"A",{href:!0});var Tmt=s(qG);SGo=r(Tmt,"RemBertForQuestionAnswering"),Tmt.forEach(t),RGo=r(qLe," (RemBERT model)"),qLe.forEach(t),BGo=i(P),Tv=n(P,"LI",{});var NLe=s(Tv);wme=n(NLe,"STRONG",{});var Mmt=s(wme);PGo=r(Mmt,"roberta"),Mmt.forEach(t),$Go=r(NLe," \u2014 "),NG=n(NLe,"A",{href:!0});var Emt=s(NG);IGo=r(Emt,"RobertaForQuestionAnswering"),Emt.forEach(t),qGo=r(NLe," (RoBERTa model)"),NLe.forEach(t),NGo=i(P),Mv=n(P,"LI",{});var jLe=s(Mv);Ame=n(jLe,"STRONG",{});var Cmt=s(Ame);jGo=r(Cmt,"roformer"),Cmt.forEach(t),DGo=r(jLe," \u2014 "),jG=n(jLe,"A",{href:!0});var wmt=s(jG);GGo=r(wmt,"RoFormerForQuestionAnswering"),wmt.forEach(t),OGo=r(jLe," (RoFormer model)"),jLe.forEach(t),VGo=i(P),Ev=n(P,"LI",{});var DLe=s(Ev);yme=n(DLe,"STRONG",{});var Amt=s(yme);XGo=r(Amt,"splinter"),Amt.forEach(t),zGo=r(DLe," \u2014 "),DG=n(DLe,"A",{href:!0});var ymt=s(DG);QGo=r(ymt,"SplinterForQuestionAnswering"),ymt.forEach(t),WGo=r(DLe," (Splinter model)"),DLe.forEach(t),HGo=i(P),Cv=n(P,"LI",{});var GLe=s(Cv);Lme=n(GLe,"STRONG",{});var Lmt=s(Lme);UGo=r(Lmt,"squeezebert"),Lmt.forEach(t),JGo=r(GLe," \u2014 "),GG=n(GLe,"A",{href:!0});var xmt=s(GG);YGo=r(xmt,"SqueezeBertForQuestionAnswering"),xmt.forEach(t),KGo=r(GLe," (SqueezeBERT model)"),GLe.forEach(t),ZGo=i(P),wv=n(P,"LI",{});var OLe=s(wv);xme=n(OLe,"STRONG",{});var kmt=s(xme);eOo=r(kmt,"xlm"),kmt.forEach(t),oOo=r(OLe," \u2014 "),OG=n(OLe,"A",{href:!0});var Smt=s(OG);rOo=r(Smt,"XLMForQuestionAnsweringSimple"),Smt.forEach(t),tOo=r(OLe," (XLM model)"),OLe.forEach(t),aOo=i(P),Av=n(P,"LI",{});var VLe=s(Av);kme=n(VLe,"STRONG",{});var Rmt=s(kme);nOo=r(Rmt,"xlm-roberta"),Rmt.forEach(t),sOo=r(VLe," \u2014 "),VG=n(VLe,"A",{href:!0});var Bmt=s(VG);lOo=r(Bmt,"XLMRobertaForQuestionAnswering"),Bmt.forEach(t),iOo=r(VLe," (XLM-RoBERTa model)"),VLe.forEach(t),dOo=i(P),yv=n(P,"LI",{});var XLe=s(yv);Sme=n(XLe,"STRONG",{});var Pmt=s(Sme);cOo=r(Pmt,"xlm-roberta-xl"),Pmt.forEach(t),fOo=r(XLe," \u2014 "),XG=n(XLe,"A",{href:!0});var $mt=s(XG);mOo=r($mt,"XLMRobertaXLForQuestionAnswering"),$mt.forEach(t),gOo=r(XLe," (XLM-RoBERTa-XL model)"),XLe.forEach(t),hOo=i(P),Lv=n(P,"LI",{});var zLe=s(Lv);Rme=n(zLe,"STRONG",{});var Imt=s(Rme);pOo=r(Imt,"xlnet"),Imt.forEach(t),_Oo=r(zLe," \u2014 "),zG=n(zLe,"A",{href:!0});var qmt=s(zG);uOo=r(qmt,"XLNetForQuestionAnsweringSimple"),qmt.forEach(t),bOo=r(zLe," (XLNet model)"),zLe.forEach(t),vOo=i(P),xv=n(P,"LI",{});var QLe=s(xv);Bme=n(QLe,"STRONG",{});var Nmt=s(Bme);FOo=r(Nmt,"yoso"),Nmt.forEach(t),TOo=r(QLe," \u2014 "),QG=n(QLe,"A",{href:!0});var jmt=s(QG);MOo=r(jmt,"YosoForQuestionAnswering"),jmt.forEach(t),EOo=r(QLe," (YOSO model)"),QLe.forEach(t),P.forEach(t),COo=i(Ut),kv=n(Ut,"P",{});var WLe=s(kv);wOo=r(WLe,"The model is set in evaluation mode by default using "),Pme=n(WLe,"CODE",{});var Dmt=s(Pme);AOo=r(Dmt,"model.eval()"),Dmt.forEach(t),yOo=r(WLe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$me=n(WLe,"CODE",{});var Gmt=s($me);LOo=r(Gmt,"model.train()"),Gmt.forEach(t),WLe.forEach(t),xOo=i(Ut),Ime=n(Ut,"P",{});var Omt=s(Ime);kOo=r(Omt,"Examples:"),Omt.forEach(t),SOo=i(Ut),m(HC.$$.fragment,Ut),Ut.forEach(t),Tl.forEach(t),f$e=i(c),Id=n(c,"H2",{class:!0});var Fqe=s(Id);Sv=n(Fqe,"A",{id:!0,class:!0,href:!0});var Vmt=s(Sv);qme=n(Vmt,"SPAN",{});var Xmt=s(qme);m(UC.$$.fragment,Xmt),Xmt.forEach(t),Vmt.forEach(t),ROo=i(Fqe),Nme=n(Fqe,"SPAN",{});var zmt=s(Nme);BOo=r(zmt,"AutoModelForTableQuestionAnswering"),zmt.forEach(t),Fqe.forEach(t),m$e=i(c),sr=n(c,"DIV",{class:!0});var El=s(sr);m(JC.$$.fragment,El),POo=i(El),qd=n(El,"P",{});var eY=s(qd);$Oo=r(eY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),WG=n(eY,"A",{href:!0});var Qmt=s(WG);IOo=r(Qmt,"from_pretrained()"),Qmt.forEach(t),qOo=r(eY," class method or the "),HG=n(eY,"A",{href:!0});var Wmt=s(HG);NOo=r(Wmt,"from_config()"),Wmt.forEach(t),jOo=r(eY,` class
method.`),eY.forEach(t),DOo=i(El),YC=n(El,"P",{});var Tqe=s(YC);GOo=r(Tqe,"This class cannot be instantiated directly using "),jme=n(Tqe,"CODE",{});var Hmt=s(jme);OOo=r(Hmt,"__init__()"),Hmt.forEach(t),VOo=r(Tqe," (throws an error)."),Tqe.forEach(t),XOo=i(El),et=n(El,"DIV",{class:!0});var Cl=s(et);m(KC.$$.fragment,Cl),zOo=i(Cl),Dme=n(Cl,"P",{});var Umt=s(Dme);QOo=r(Umt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Umt.forEach(t),WOo=i(Cl),Nd=n(Cl,"P",{});var oY=s(Nd);HOo=r(oY,`Note:
Loading a model from its configuration file does `),Gme=n(oY,"STRONG",{});var Jmt=s(Gme);UOo=r(Jmt,"not"),Jmt.forEach(t),JOo=r(oY,` load the model weights. It only affects the
model\u2019s configuration. Use `),UG=n(oY,"A",{href:!0});var Ymt=s(UG);YOo=r(Ymt,"from_pretrained()"),Ymt.forEach(t),KOo=r(oY," to load the model weights."),oY.forEach(t),ZOo=i(Cl),Ome=n(Cl,"P",{});var Kmt=s(Ome);eVo=r(Kmt,"Examples:"),Kmt.forEach(t),oVo=i(Cl),m(ZC.$$.fragment,Cl),Cl.forEach(t),rVo=i(El),Ue=n(El,"DIV",{class:!0});var Jt=s(Ue);m(ew.$$.fragment,Jt),tVo=i(Jt),Vme=n(Jt,"P",{});var Zmt=s(Vme);aVo=r(Zmt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Zmt.forEach(t),nVo=i(Jt),en=n(Jt,"P",{});var m5=s(en);sVo=r(m5,"The model class to instantiate is selected based on the "),Xme=n(m5,"CODE",{});var egt=s(Xme);lVo=r(egt,"model_type"),egt.forEach(t),iVo=r(m5,` property of the config object (either
passed as an argument or loaded from `),zme=n(m5,"CODE",{});var ogt=s(zme);dVo=r(ogt,"pretrained_model_name_or_path"),ogt.forEach(t),cVo=r(m5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=n(m5,"CODE",{});var rgt=s(Qme);fVo=r(rgt,"pretrained_model_name_or_path"),rgt.forEach(t),mVo=r(m5,":"),m5.forEach(t),gVo=i(Jt),Wme=n(Jt,"UL",{});var tgt=s(Wme);Rv=n(tgt,"LI",{});var HLe=s(Rv);Hme=n(HLe,"STRONG",{});var agt=s(Hme);hVo=r(agt,"tapas"),agt.forEach(t),pVo=r(HLe," \u2014 "),JG=n(HLe,"A",{href:!0});var ngt=s(JG);_Vo=r(ngt,"TapasForQuestionAnswering"),ngt.forEach(t),uVo=r(HLe," (TAPAS model)"),HLe.forEach(t),tgt.forEach(t),bVo=i(Jt),Bv=n(Jt,"P",{});var ULe=s(Bv);vVo=r(ULe,"The model is set in evaluation mode by default using "),Ume=n(ULe,"CODE",{});var sgt=s(Ume);FVo=r(sgt,"model.eval()"),sgt.forEach(t),TVo=r(ULe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jme=n(ULe,"CODE",{});var lgt=s(Jme);MVo=r(lgt,"model.train()"),lgt.forEach(t),ULe.forEach(t),EVo=i(Jt),Yme=n(Jt,"P",{});var igt=s(Yme);CVo=r(igt,"Examples:"),igt.forEach(t),wVo=i(Jt),m(ow.$$.fragment,Jt),Jt.forEach(t),El.forEach(t),g$e=i(c),jd=n(c,"H2",{class:!0});var Mqe=s(jd);Pv=n(Mqe,"A",{id:!0,class:!0,href:!0});var dgt=s(Pv);Kme=n(dgt,"SPAN",{});var cgt=s(Kme);m(rw.$$.fragment,cgt),cgt.forEach(t),dgt.forEach(t),AVo=i(Mqe),Zme=n(Mqe,"SPAN",{});var fgt=s(Zme);yVo=r(fgt,"AutoModelForImageClassification"),fgt.forEach(t),Mqe.forEach(t),h$e=i(c),lr=n(c,"DIV",{class:!0});var wl=s(lr);m(tw.$$.fragment,wl),LVo=i(wl),Dd=n(wl,"P",{});var rY=s(Dd);xVo=r(rY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),YG=n(rY,"A",{href:!0});var mgt=s(YG);kVo=r(mgt,"from_pretrained()"),mgt.forEach(t),SVo=r(rY," class method or the "),KG=n(rY,"A",{href:!0});var ggt=s(KG);RVo=r(ggt,"from_config()"),ggt.forEach(t),BVo=r(rY,` class
method.`),rY.forEach(t),PVo=i(wl),aw=n(wl,"P",{});var Eqe=s(aw);$Vo=r(Eqe,"This class cannot be instantiated directly using "),ege=n(Eqe,"CODE",{});var hgt=s(ege);IVo=r(hgt,"__init__()"),hgt.forEach(t),qVo=r(Eqe," (throws an error)."),Eqe.forEach(t),NVo=i(wl),ot=n(wl,"DIV",{class:!0});var Al=s(ot);m(nw.$$.fragment,Al),jVo=i(Al),oge=n(Al,"P",{});var pgt=s(oge);DVo=r(pgt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),pgt.forEach(t),GVo=i(Al),Gd=n(Al,"P",{});var tY=s(Gd);OVo=r(tY,`Note:
Loading a model from its configuration file does `),rge=n(tY,"STRONG",{});var _gt=s(rge);VVo=r(_gt,"not"),_gt.forEach(t),XVo=r(tY,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZG=n(tY,"A",{href:!0});var ugt=s(ZG);zVo=r(ugt,"from_pretrained()"),ugt.forEach(t),QVo=r(tY," to load the model weights."),tY.forEach(t),WVo=i(Al),tge=n(Al,"P",{});var bgt=s(tge);HVo=r(bgt,"Examples:"),bgt.forEach(t),UVo=i(Al),m(sw.$$.fragment,Al),Al.forEach(t),JVo=i(wl),Je=n(wl,"DIV",{class:!0});var Yt=s(Je);m(lw.$$.fragment,Yt),YVo=i(Yt),age=n(Yt,"P",{});var vgt=s(age);KVo=r(vgt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),vgt.forEach(t),ZVo=i(Yt),on=n(Yt,"P",{});var g5=s(on);eXo=r(g5,"The model class to instantiate is selected based on the "),nge=n(g5,"CODE",{});var Fgt=s(nge);oXo=r(Fgt,"model_type"),Fgt.forEach(t),rXo=r(g5,` property of the config object (either
passed as an argument or loaded from `),sge=n(g5,"CODE",{});var Tgt=s(sge);tXo=r(Tgt,"pretrained_model_name_or_path"),Tgt.forEach(t),aXo=r(g5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lge=n(g5,"CODE",{});var Mgt=s(lge);nXo=r(Mgt,"pretrained_model_name_or_path"),Mgt.forEach(t),sXo=r(g5,":"),g5.forEach(t),lXo=i(Yt),ce=n(Yt,"UL",{});var pe=s(ce);$v=n(pe,"LI",{});var JLe=s($v);ige=n(JLe,"STRONG",{});var Egt=s(ige);iXo=r(Egt,"beit"),Egt.forEach(t),dXo=r(JLe," \u2014 "),eO=n(JLe,"A",{href:!0});var Cgt=s(eO);cXo=r(Cgt,"BeitForImageClassification"),Cgt.forEach(t),fXo=r(JLe," (BEiT model)"),JLe.forEach(t),mXo=i(pe),Iv=n(pe,"LI",{});var YLe=s(Iv);dge=n(YLe,"STRONG",{});var wgt=s(dge);gXo=r(wgt,"convnext"),wgt.forEach(t),hXo=r(YLe," \u2014 "),oO=n(YLe,"A",{href:!0});var Agt=s(oO);pXo=r(Agt,"ConvNextForImageClassification"),Agt.forEach(t),_Xo=r(YLe," (ConvNext model)"),YLe.forEach(t),uXo=i(pe),qv=n(pe,"LI",{});var KLe=s(qv);cge=n(KLe,"STRONG",{});var ygt=s(cge);bXo=r(ygt,"data2vec-vision"),ygt.forEach(t),vXo=r(KLe," \u2014 "),rO=n(KLe,"A",{href:!0});var Lgt=s(rO);FXo=r(Lgt,"Data2VecVisionForImageClassification"),Lgt.forEach(t),TXo=r(KLe," (Data2VecVision model)"),KLe.forEach(t),MXo=i(pe),Js=n(pe,"LI",{});var K8=s(Js);fge=n(K8,"STRONG",{});var xgt=s(fge);EXo=r(xgt,"deit"),xgt.forEach(t),CXo=r(K8," \u2014 "),tO=n(K8,"A",{href:!0});var kgt=s(tO);wXo=r(kgt,"DeiTForImageClassification"),kgt.forEach(t),AXo=r(K8," or "),aO=n(K8,"A",{href:!0});var Sgt=s(aO);yXo=r(Sgt,"DeiTForImageClassificationWithTeacher"),Sgt.forEach(t),LXo=r(K8," (DeiT model)"),K8.forEach(t),xXo=i(pe),Nv=n(pe,"LI",{});var ZLe=s(Nv);mge=n(ZLe,"STRONG",{});var Rgt=s(mge);kXo=r(Rgt,"imagegpt"),Rgt.forEach(t),SXo=r(ZLe," \u2014 "),nO=n(ZLe,"A",{href:!0});var Bgt=s(nO);RXo=r(Bgt,"ImageGPTForImageClassification"),Bgt.forEach(t),BXo=r(ZLe," (ImageGPT model)"),ZLe.forEach(t),PXo=i(pe),ma=n(pe,"LI",{});var Xf=s(ma);gge=n(Xf,"STRONG",{});var Pgt=s(gge);$Xo=r(Pgt,"perceiver"),Pgt.forEach(t),IXo=r(Xf," \u2014 "),sO=n(Xf,"A",{href:!0});var $gt=s(sO);qXo=r($gt,"PerceiverForImageClassificationLearned"),$gt.forEach(t),NXo=r(Xf," or "),lO=n(Xf,"A",{href:!0});var Igt=s(lO);jXo=r(Igt,"PerceiverForImageClassificationFourier"),Igt.forEach(t),DXo=r(Xf," or "),iO=n(Xf,"A",{href:!0});var qgt=s(iO);GXo=r(qgt,"PerceiverForImageClassificationConvProcessing"),qgt.forEach(t),OXo=r(Xf," (Perceiver model)"),Xf.forEach(t),VXo=i(pe),jv=n(pe,"LI",{});var e8e=s(jv);hge=n(e8e,"STRONG",{});var Ngt=s(hge);XXo=r(Ngt,"poolformer"),Ngt.forEach(t),zXo=r(e8e," \u2014 "),dO=n(e8e,"A",{href:!0});var jgt=s(dO);QXo=r(jgt,"PoolFormerForImageClassification"),jgt.forEach(t),WXo=r(e8e," (PoolFormer model)"),e8e.forEach(t),HXo=i(pe),Dv=n(pe,"LI",{});var o8e=s(Dv);pge=n(o8e,"STRONG",{});var Dgt=s(pge);UXo=r(Dgt,"regnet"),Dgt.forEach(t),JXo=r(o8e," \u2014 "),cO=n(o8e,"A",{href:!0});var Ggt=s(cO);YXo=r(Ggt,"RegNetForImageClassification"),Ggt.forEach(t),KXo=r(o8e," (RegNet model)"),o8e.forEach(t),ZXo=i(pe),Gv=n(pe,"LI",{});var r8e=s(Gv);_ge=n(r8e,"STRONG",{});var Ogt=s(_ge);ezo=r(Ogt,"resnet"),Ogt.forEach(t),ozo=r(r8e," \u2014 "),fO=n(r8e,"A",{href:!0});var Vgt=s(fO);rzo=r(Vgt,"ResNetForImageClassification"),Vgt.forEach(t),tzo=r(r8e," (ResNet model)"),r8e.forEach(t),azo=i(pe),Ov=n(pe,"LI",{});var t8e=s(Ov);uge=n(t8e,"STRONG",{});var Xgt=s(uge);nzo=r(Xgt,"segformer"),Xgt.forEach(t),szo=r(t8e," \u2014 "),mO=n(t8e,"A",{href:!0});var zgt=s(mO);lzo=r(zgt,"SegformerForImageClassification"),zgt.forEach(t),izo=r(t8e," (SegFormer model)"),t8e.forEach(t),dzo=i(pe),Vv=n(pe,"LI",{});var a8e=s(Vv);bge=n(a8e,"STRONG",{});var Qgt=s(bge);czo=r(Qgt,"swin"),Qgt.forEach(t),fzo=r(a8e," \u2014 "),gO=n(a8e,"A",{href:!0});var Wgt=s(gO);mzo=r(Wgt,"SwinForImageClassification"),Wgt.forEach(t),gzo=r(a8e," (Swin model)"),a8e.forEach(t),hzo=i(pe),Xv=n(pe,"LI",{});var n8e=s(Xv);vge=n(n8e,"STRONG",{});var Hgt=s(vge);pzo=r(Hgt,"van"),Hgt.forEach(t),_zo=r(n8e," \u2014 "),hO=n(n8e,"A",{href:!0});var Ugt=s(hO);uzo=r(Ugt,"VanForImageClassification"),Ugt.forEach(t),bzo=r(n8e," (VAN model)"),n8e.forEach(t),vzo=i(pe),zv=n(pe,"LI",{});var s8e=s(zv);Fge=n(s8e,"STRONG",{});var Jgt=s(Fge);Fzo=r(Jgt,"vit"),Jgt.forEach(t),Tzo=r(s8e," \u2014 "),pO=n(s8e,"A",{href:!0});var Ygt=s(pO);Mzo=r(Ygt,"ViTForImageClassification"),Ygt.forEach(t),Ezo=r(s8e," (ViT model)"),s8e.forEach(t),pe.forEach(t),Czo=i(Yt),Qv=n(Yt,"P",{});var l8e=s(Qv);wzo=r(l8e,"The model is set in evaluation mode by default using "),Tge=n(l8e,"CODE",{});var Kgt=s(Tge);Azo=r(Kgt,"model.eval()"),Kgt.forEach(t),yzo=r(l8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mge=n(l8e,"CODE",{});var Zgt=s(Mge);Lzo=r(Zgt,"model.train()"),Zgt.forEach(t),l8e.forEach(t),xzo=i(Yt),Ege=n(Yt,"P",{});var eht=s(Ege);kzo=r(eht,"Examples:"),eht.forEach(t),Szo=i(Yt),m(iw.$$.fragment,Yt),Yt.forEach(t),wl.forEach(t),p$e=i(c),Od=n(c,"H2",{class:!0});var Cqe=s(Od);Wv=n(Cqe,"A",{id:!0,class:!0,href:!0});var oht=s(Wv);Cge=n(oht,"SPAN",{});var rht=s(Cge);m(dw.$$.fragment,rht),rht.forEach(t),oht.forEach(t),Rzo=i(Cqe),wge=n(Cqe,"SPAN",{});var tht=s(wge);Bzo=r(tht,"AutoModelForVision2Seq"),tht.forEach(t),Cqe.forEach(t),_$e=i(c),ir=n(c,"DIV",{class:!0});var yl=s(ir);m(cw.$$.fragment,yl),Pzo=i(yl),Vd=n(yl,"P",{});var aY=s(Vd);$zo=r(aY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),_O=n(aY,"A",{href:!0});var aht=s(_O);Izo=r(aht,"from_pretrained()"),aht.forEach(t),qzo=r(aY," class method or the "),uO=n(aY,"A",{href:!0});var nht=s(uO);Nzo=r(nht,"from_config()"),nht.forEach(t),jzo=r(aY,` class
method.`),aY.forEach(t),Dzo=i(yl),fw=n(yl,"P",{});var wqe=s(fw);Gzo=r(wqe,"This class cannot be instantiated directly using "),Age=n(wqe,"CODE",{});var sht=s(Age);Ozo=r(sht,"__init__()"),sht.forEach(t),Vzo=r(wqe," (throws an error)."),wqe.forEach(t),Xzo=i(yl),rt=n(yl,"DIV",{class:!0});var Ll=s(rt);m(mw.$$.fragment,Ll),zzo=i(Ll),yge=n(Ll,"P",{});var lht=s(yge);Qzo=r(lht,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),lht.forEach(t),Wzo=i(Ll),Xd=n(Ll,"P",{});var nY=s(Xd);Hzo=r(nY,`Note:
Loading a model from its configuration file does `),Lge=n(nY,"STRONG",{});var iht=s(Lge);Uzo=r(iht,"not"),iht.forEach(t),Jzo=r(nY,` load the model weights. It only affects the
model\u2019s configuration. Use `),bO=n(nY,"A",{href:!0});var dht=s(bO);Yzo=r(dht,"from_pretrained()"),dht.forEach(t),Kzo=r(nY," to load the model weights."),nY.forEach(t),Zzo=i(Ll),xge=n(Ll,"P",{});var cht=s(xge);eQo=r(cht,"Examples:"),cht.forEach(t),oQo=i(Ll),m(gw.$$.fragment,Ll),Ll.forEach(t),rQo=i(yl),Ye=n(yl,"DIV",{class:!0});var Kt=s(Ye);m(hw.$$.fragment,Kt),tQo=i(Kt),kge=n(Kt,"P",{});var fht=s(kge);aQo=r(fht,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),fht.forEach(t),nQo=i(Kt),rn=n(Kt,"P",{});var h5=s(rn);sQo=r(h5,"The model class to instantiate is selected based on the "),Sge=n(h5,"CODE",{});var mht=s(Sge);lQo=r(mht,"model_type"),mht.forEach(t),iQo=r(h5,` property of the config object (either
passed as an argument or loaded from `),Rge=n(h5,"CODE",{});var ght=s(Rge);dQo=r(ght,"pretrained_model_name_or_path"),ght.forEach(t),cQo=r(h5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bge=n(h5,"CODE",{});var hht=s(Bge);fQo=r(hht,"pretrained_model_name_or_path"),hht.forEach(t),mQo=r(h5,":"),h5.forEach(t),gQo=i(Kt),Pge=n(Kt,"UL",{});var pht=s(Pge);Hv=n(pht,"LI",{});var i8e=s(Hv);$ge=n(i8e,"STRONG",{});var _ht=s($ge);hQo=r(_ht,"vision-encoder-decoder"),_ht.forEach(t),pQo=r(i8e," \u2014 "),vO=n(i8e,"A",{href:!0});var uht=s(vO);_Qo=r(uht,"VisionEncoderDecoderModel"),uht.forEach(t),uQo=r(i8e," (Vision Encoder decoder model)"),i8e.forEach(t),pht.forEach(t),bQo=i(Kt),Uv=n(Kt,"P",{});var d8e=s(Uv);vQo=r(d8e,"The model is set in evaluation mode by default using "),Ige=n(d8e,"CODE",{});var bht=s(Ige);FQo=r(bht,"model.eval()"),bht.forEach(t),TQo=r(d8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qge=n(d8e,"CODE",{});var vht=s(qge);MQo=r(vht,"model.train()"),vht.forEach(t),d8e.forEach(t),EQo=i(Kt),Nge=n(Kt,"P",{});var Fht=s(Nge);CQo=r(Fht,"Examples:"),Fht.forEach(t),wQo=i(Kt),m(pw.$$.fragment,Kt),Kt.forEach(t),yl.forEach(t),u$e=i(c),zd=n(c,"H2",{class:!0});var Aqe=s(zd);Jv=n(Aqe,"A",{id:!0,class:!0,href:!0});var Tht=s(Jv);jge=n(Tht,"SPAN",{});var Mht=s(jge);m(_w.$$.fragment,Mht),Mht.forEach(t),Tht.forEach(t),AQo=i(Aqe),Dge=n(Aqe,"SPAN",{});var Eht=s(Dge);yQo=r(Eht,"AutoModelForAudioClassification"),Eht.forEach(t),Aqe.forEach(t),b$e=i(c),dr=n(c,"DIV",{class:!0});var xl=s(dr);m(uw.$$.fragment,xl),LQo=i(xl),Qd=n(xl,"P",{});var sY=s(Qd);xQo=r(sY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),FO=n(sY,"A",{href:!0});var Cht=s(FO);kQo=r(Cht,"from_pretrained()"),Cht.forEach(t),SQo=r(sY," class method or the "),TO=n(sY,"A",{href:!0});var wht=s(TO);RQo=r(wht,"from_config()"),wht.forEach(t),BQo=r(sY,` class
method.`),sY.forEach(t),PQo=i(xl),bw=n(xl,"P",{});var yqe=s(bw);$Qo=r(yqe,"This class cannot be instantiated directly using "),Gge=n(yqe,"CODE",{});var Aht=s(Gge);IQo=r(Aht,"__init__()"),Aht.forEach(t),qQo=r(yqe," (throws an error)."),yqe.forEach(t),NQo=i(xl),tt=n(xl,"DIV",{class:!0});var kl=s(tt);m(vw.$$.fragment,kl),jQo=i(kl),Oge=n(kl,"P",{});var yht=s(Oge);DQo=r(yht,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),yht.forEach(t),GQo=i(kl),Wd=n(kl,"P",{});var lY=s(Wd);OQo=r(lY,`Note:
Loading a model from its configuration file does `),Vge=n(lY,"STRONG",{});var Lht=s(Vge);VQo=r(Lht,"not"),Lht.forEach(t),XQo=r(lY,` load the model weights. It only affects the
model\u2019s configuration. Use `),MO=n(lY,"A",{href:!0});var xht=s(MO);zQo=r(xht,"from_pretrained()"),xht.forEach(t),QQo=r(lY," to load the model weights."),lY.forEach(t),WQo=i(kl),Xge=n(kl,"P",{});var kht=s(Xge);HQo=r(kht,"Examples:"),kht.forEach(t),UQo=i(kl),m(Fw.$$.fragment,kl),kl.forEach(t),JQo=i(xl),Ke=n(xl,"DIV",{class:!0});var Zt=s(Ke);m(Tw.$$.fragment,Zt),YQo=i(Zt),zge=n(Zt,"P",{});var Sht=s(zge);KQo=r(Sht,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Sht.forEach(t),ZQo=i(Zt),tn=n(Zt,"P",{});var p5=s(tn);eWo=r(p5,"The model class to instantiate is selected based on the "),Qge=n(p5,"CODE",{});var Rht=s(Qge);oWo=r(Rht,"model_type"),Rht.forEach(t),rWo=r(p5,` property of the config object (either
passed as an argument or loaded from `),Wge=n(p5,"CODE",{});var Bht=s(Wge);tWo=r(Bht,"pretrained_model_name_or_path"),Bht.forEach(t),aWo=r(p5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hge=n(p5,"CODE",{});var Pht=s(Hge);nWo=r(Pht,"pretrained_model_name_or_path"),Pht.forEach(t),sWo=r(p5,":"),p5.forEach(t),lWo=i(Zt),Be=n(Zt,"UL",{});var Do=s(Be);Yv=n(Do,"LI",{});var c8e=s(Yv);Uge=n(c8e,"STRONG",{});var $ht=s(Uge);iWo=r($ht,"data2vec-audio"),$ht.forEach(t),dWo=r(c8e," \u2014 "),EO=n(c8e,"A",{href:!0});var Iht=s(EO);cWo=r(Iht,"Data2VecAudioForSequenceClassification"),Iht.forEach(t),fWo=r(c8e," (Data2VecAudio model)"),c8e.forEach(t),mWo=i(Do),Kv=n(Do,"LI",{});var f8e=s(Kv);Jge=n(f8e,"STRONG",{});var qht=s(Jge);gWo=r(qht,"hubert"),qht.forEach(t),hWo=r(f8e," \u2014 "),CO=n(f8e,"A",{href:!0});var Nht=s(CO);pWo=r(Nht,"HubertForSequenceClassification"),Nht.forEach(t),_Wo=r(f8e," (Hubert model)"),f8e.forEach(t),uWo=i(Do),Zv=n(Do,"LI",{});var m8e=s(Zv);Yge=n(m8e,"STRONG",{});var jht=s(Yge);bWo=r(jht,"sew"),jht.forEach(t),vWo=r(m8e," \u2014 "),wO=n(m8e,"A",{href:!0});var Dht=s(wO);FWo=r(Dht,"SEWForSequenceClassification"),Dht.forEach(t),TWo=r(m8e," (SEW model)"),m8e.forEach(t),MWo=i(Do),eF=n(Do,"LI",{});var g8e=s(eF);Kge=n(g8e,"STRONG",{});var Ght=s(Kge);EWo=r(Ght,"sew-d"),Ght.forEach(t),CWo=r(g8e," \u2014 "),AO=n(g8e,"A",{href:!0});var Oht=s(AO);wWo=r(Oht,"SEWDForSequenceClassification"),Oht.forEach(t),AWo=r(g8e," (SEW-D model)"),g8e.forEach(t),yWo=i(Do),oF=n(Do,"LI",{});var h8e=s(oF);Zge=n(h8e,"STRONG",{});var Vht=s(Zge);LWo=r(Vht,"unispeech"),Vht.forEach(t),xWo=r(h8e," \u2014 "),yO=n(h8e,"A",{href:!0});var Xht=s(yO);kWo=r(Xht,"UniSpeechForSequenceClassification"),Xht.forEach(t),SWo=r(h8e," (UniSpeech model)"),h8e.forEach(t),RWo=i(Do),rF=n(Do,"LI",{});var p8e=s(rF);ehe=n(p8e,"STRONG",{});var zht=s(ehe);BWo=r(zht,"unispeech-sat"),zht.forEach(t),PWo=r(p8e," \u2014 "),LO=n(p8e,"A",{href:!0});var Qht=s(LO);$Wo=r(Qht,"UniSpeechSatForSequenceClassification"),Qht.forEach(t),IWo=r(p8e," (UniSpeechSat model)"),p8e.forEach(t),qWo=i(Do),tF=n(Do,"LI",{});var _8e=s(tF);ohe=n(_8e,"STRONG",{});var Wht=s(ohe);NWo=r(Wht,"wav2vec2"),Wht.forEach(t),jWo=r(_8e," \u2014 "),xO=n(_8e,"A",{href:!0});var Hht=s(xO);DWo=r(Hht,"Wav2Vec2ForSequenceClassification"),Hht.forEach(t),GWo=r(_8e," (Wav2Vec2 model)"),_8e.forEach(t),OWo=i(Do),aF=n(Do,"LI",{});var u8e=s(aF);rhe=n(u8e,"STRONG",{});var Uht=s(rhe);VWo=r(Uht,"wavlm"),Uht.forEach(t),XWo=r(u8e," \u2014 "),kO=n(u8e,"A",{href:!0});var Jht=s(kO);zWo=r(Jht,"WavLMForSequenceClassification"),Jht.forEach(t),QWo=r(u8e," (WavLM model)"),u8e.forEach(t),Do.forEach(t),WWo=i(Zt),nF=n(Zt,"P",{});var b8e=s(nF);HWo=r(b8e,"The model is set in evaluation mode by default using "),the=n(b8e,"CODE",{});var Yht=s(the);UWo=r(Yht,"model.eval()"),Yht.forEach(t),JWo=r(b8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ahe=n(b8e,"CODE",{});var Kht=s(ahe);YWo=r(Kht,"model.train()"),Kht.forEach(t),b8e.forEach(t),KWo=i(Zt),nhe=n(Zt,"P",{});var Zht=s(nhe);ZWo=r(Zht,"Examples:"),Zht.forEach(t),eHo=i(Zt),m(Mw.$$.fragment,Zt),Zt.forEach(t),xl.forEach(t),v$e=i(c),Hd=n(c,"H2",{class:!0});var Lqe=s(Hd);sF=n(Lqe,"A",{id:!0,class:!0,href:!0});var ept=s(sF);she=n(ept,"SPAN",{});var opt=s(she);m(Ew.$$.fragment,opt),opt.forEach(t),ept.forEach(t),oHo=i(Lqe),lhe=n(Lqe,"SPAN",{});var rpt=s(lhe);rHo=r(rpt,"AutoModelForAudioFrameClassification"),rpt.forEach(t),Lqe.forEach(t),F$e=i(c),cr=n(c,"DIV",{class:!0});var Sl=s(cr);m(Cw.$$.fragment,Sl),tHo=i(Sl),Ud=n(Sl,"P",{});var iY=s(Ud);aHo=r(iY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),SO=n(iY,"A",{href:!0});var tpt=s(SO);nHo=r(tpt,"from_pretrained()"),tpt.forEach(t),sHo=r(iY," class method or the "),RO=n(iY,"A",{href:!0});var apt=s(RO);lHo=r(apt,"from_config()"),apt.forEach(t),iHo=r(iY,` class
method.`),iY.forEach(t),dHo=i(Sl),ww=n(Sl,"P",{});var xqe=s(ww);cHo=r(xqe,"This class cannot be instantiated directly using "),ihe=n(xqe,"CODE",{});var npt=s(ihe);fHo=r(npt,"__init__()"),npt.forEach(t),mHo=r(xqe," (throws an error)."),xqe.forEach(t),gHo=i(Sl),at=n(Sl,"DIV",{class:!0});var Rl=s(at);m(Aw.$$.fragment,Rl),hHo=i(Rl),dhe=n(Rl,"P",{});var spt=s(dhe);pHo=r(spt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),spt.forEach(t),_Ho=i(Rl),Jd=n(Rl,"P",{});var dY=s(Jd);uHo=r(dY,`Note:
Loading a model from its configuration file does `),che=n(dY,"STRONG",{});var lpt=s(che);bHo=r(lpt,"not"),lpt.forEach(t),vHo=r(dY,` load the model weights. It only affects the
model\u2019s configuration. Use `),BO=n(dY,"A",{href:!0});var ipt=s(BO);FHo=r(ipt,"from_pretrained()"),ipt.forEach(t),THo=r(dY," to load the model weights."),dY.forEach(t),MHo=i(Rl),fhe=n(Rl,"P",{});var dpt=s(fhe);EHo=r(dpt,"Examples:"),dpt.forEach(t),CHo=i(Rl),m(yw.$$.fragment,Rl),Rl.forEach(t),wHo=i(Sl),Ze=n(Sl,"DIV",{class:!0});var ea=s(Ze);m(Lw.$$.fragment,ea),AHo=i(ea),mhe=n(ea,"P",{});var cpt=s(mhe);yHo=r(cpt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),cpt.forEach(t),LHo=i(ea),an=n(ea,"P",{});var _5=s(an);xHo=r(_5,"The model class to instantiate is selected based on the "),ghe=n(_5,"CODE",{});var fpt=s(ghe);kHo=r(fpt,"model_type"),fpt.forEach(t),SHo=r(_5,` property of the config object (either
passed as an argument or loaded from `),hhe=n(_5,"CODE",{});var mpt=s(hhe);RHo=r(mpt,"pretrained_model_name_or_path"),mpt.forEach(t),BHo=r(_5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),phe=n(_5,"CODE",{});var gpt=s(phe);PHo=r(gpt,"pretrained_model_name_or_path"),gpt.forEach(t),$Ho=r(_5,":"),_5.forEach(t),IHo=i(ea),nn=n(ea,"UL",{});var u5=s(nn);lF=n(u5,"LI",{});var v8e=s(lF);_he=n(v8e,"STRONG",{});var hpt=s(_he);qHo=r(hpt,"data2vec-audio"),hpt.forEach(t),NHo=r(v8e," \u2014 "),PO=n(v8e,"A",{href:!0});var ppt=s(PO);jHo=r(ppt,"Data2VecAudioForAudioFrameClassification"),ppt.forEach(t),DHo=r(v8e," (Data2VecAudio model)"),v8e.forEach(t),GHo=i(u5),iF=n(u5,"LI",{});var F8e=s(iF);uhe=n(F8e,"STRONG",{});var _pt=s(uhe);OHo=r(_pt,"unispeech-sat"),_pt.forEach(t),VHo=r(F8e," \u2014 "),$O=n(F8e,"A",{href:!0});var upt=s($O);XHo=r(upt,"UniSpeechSatForAudioFrameClassification"),upt.forEach(t),zHo=r(F8e," (UniSpeechSat model)"),F8e.forEach(t),QHo=i(u5),dF=n(u5,"LI",{});var T8e=s(dF);bhe=n(T8e,"STRONG",{});var bpt=s(bhe);WHo=r(bpt,"wav2vec2"),bpt.forEach(t),HHo=r(T8e," \u2014 "),IO=n(T8e,"A",{href:!0});var vpt=s(IO);UHo=r(vpt,"Wav2Vec2ForAudioFrameClassification"),vpt.forEach(t),JHo=r(T8e," (Wav2Vec2 model)"),T8e.forEach(t),YHo=i(u5),cF=n(u5,"LI",{});var M8e=s(cF);vhe=n(M8e,"STRONG",{});var Fpt=s(vhe);KHo=r(Fpt,"wavlm"),Fpt.forEach(t),ZHo=r(M8e," \u2014 "),qO=n(M8e,"A",{href:!0});var Tpt=s(qO);eUo=r(Tpt,"WavLMForAudioFrameClassification"),Tpt.forEach(t),oUo=r(M8e," (WavLM model)"),M8e.forEach(t),u5.forEach(t),rUo=i(ea),fF=n(ea,"P",{});var E8e=s(fF);tUo=r(E8e,"The model is set in evaluation mode by default using "),Fhe=n(E8e,"CODE",{});var Mpt=s(Fhe);aUo=r(Mpt,"model.eval()"),Mpt.forEach(t),nUo=r(E8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),The=n(E8e,"CODE",{});var Ept=s(The);sUo=r(Ept,"model.train()"),Ept.forEach(t),E8e.forEach(t),lUo=i(ea),Mhe=n(ea,"P",{});var Cpt=s(Mhe);iUo=r(Cpt,"Examples:"),Cpt.forEach(t),dUo=i(ea),m(xw.$$.fragment,ea),ea.forEach(t),Sl.forEach(t),T$e=i(c),Yd=n(c,"H2",{class:!0});var kqe=s(Yd);mF=n(kqe,"A",{id:!0,class:!0,href:!0});var wpt=s(mF);Ehe=n(wpt,"SPAN",{});var Apt=s(Ehe);m(kw.$$.fragment,Apt),Apt.forEach(t),wpt.forEach(t),cUo=i(kqe),Che=n(kqe,"SPAN",{});var ypt=s(Che);fUo=r(ypt,"AutoModelForCTC"),ypt.forEach(t),kqe.forEach(t),M$e=i(c),fr=n(c,"DIV",{class:!0});var Bl=s(fr);m(Sw.$$.fragment,Bl),mUo=i(Bl),Kd=n(Bl,"P",{});var cY=s(Kd);gUo=r(cY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),NO=n(cY,"A",{href:!0});var Lpt=s(NO);hUo=r(Lpt,"from_pretrained()"),Lpt.forEach(t),pUo=r(cY," class method or the "),jO=n(cY,"A",{href:!0});var xpt=s(jO);_Uo=r(xpt,"from_config()"),xpt.forEach(t),uUo=r(cY,` class
method.`),cY.forEach(t),bUo=i(Bl),Rw=n(Bl,"P",{});var Sqe=s(Rw);vUo=r(Sqe,"This class cannot be instantiated directly using "),whe=n(Sqe,"CODE",{});var kpt=s(whe);FUo=r(kpt,"__init__()"),kpt.forEach(t),TUo=r(Sqe," (throws an error)."),Sqe.forEach(t),MUo=i(Bl),nt=n(Bl,"DIV",{class:!0});var Pl=s(nt);m(Bw.$$.fragment,Pl),EUo=i(Pl),Ahe=n(Pl,"P",{});var Spt=s(Ahe);CUo=r(Spt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Spt.forEach(t),wUo=i(Pl),Zd=n(Pl,"P",{});var fY=s(Zd);AUo=r(fY,`Note:
Loading a model from its configuration file does `),yhe=n(fY,"STRONG",{});var Rpt=s(yhe);yUo=r(Rpt,"not"),Rpt.forEach(t),LUo=r(fY,` load the model weights. It only affects the
model\u2019s configuration. Use `),DO=n(fY,"A",{href:!0});var Bpt=s(DO);xUo=r(Bpt,"from_pretrained()"),Bpt.forEach(t),kUo=r(fY," to load the model weights."),fY.forEach(t),SUo=i(Pl),Lhe=n(Pl,"P",{});var Ppt=s(Lhe);RUo=r(Ppt,"Examples:"),Ppt.forEach(t),BUo=i(Pl),m(Pw.$$.fragment,Pl),Pl.forEach(t),PUo=i(Bl),eo=n(Bl,"DIV",{class:!0});var oa=s(eo);m($w.$$.fragment,oa),$Uo=i(oa),xhe=n(oa,"P",{});var $pt=s(xhe);IUo=r($pt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),$pt.forEach(t),qUo=i(oa),sn=n(oa,"P",{});var b5=s(sn);NUo=r(b5,"The model class to instantiate is selected based on the "),khe=n(b5,"CODE",{});var Ipt=s(khe);jUo=r(Ipt,"model_type"),Ipt.forEach(t),DUo=r(b5,` property of the config object (either
passed as an argument or loaded from `),She=n(b5,"CODE",{});var qpt=s(She);GUo=r(qpt,"pretrained_model_name_or_path"),qpt.forEach(t),OUo=r(b5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rhe=n(b5,"CODE",{});var Npt=s(Rhe);VUo=r(Npt,"pretrained_model_name_or_path"),Npt.forEach(t),XUo=r(b5,":"),b5.forEach(t),zUo=i(oa),Pe=n(oa,"UL",{});var Go=s(Pe);gF=n(Go,"LI",{});var C8e=s(gF);Bhe=n(C8e,"STRONG",{});var jpt=s(Bhe);QUo=r(jpt,"data2vec-audio"),jpt.forEach(t),WUo=r(C8e," \u2014 "),GO=n(C8e,"A",{href:!0});var Dpt=s(GO);HUo=r(Dpt,"Data2VecAudioForCTC"),Dpt.forEach(t),UUo=r(C8e," (Data2VecAudio model)"),C8e.forEach(t),JUo=i(Go),hF=n(Go,"LI",{});var w8e=s(hF);Phe=n(w8e,"STRONG",{});var Gpt=s(Phe);YUo=r(Gpt,"hubert"),Gpt.forEach(t),KUo=r(w8e," \u2014 "),OO=n(w8e,"A",{href:!0});var Opt=s(OO);ZUo=r(Opt,"HubertForCTC"),Opt.forEach(t),eJo=r(w8e," (Hubert model)"),w8e.forEach(t),oJo=i(Go),pF=n(Go,"LI",{});var A8e=s(pF);$he=n(A8e,"STRONG",{});var Vpt=s($he);rJo=r(Vpt,"sew"),Vpt.forEach(t),tJo=r(A8e," \u2014 "),VO=n(A8e,"A",{href:!0});var Xpt=s(VO);aJo=r(Xpt,"SEWForCTC"),Xpt.forEach(t),nJo=r(A8e," (SEW model)"),A8e.forEach(t),sJo=i(Go),_F=n(Go,"LI",{});var y8e=s(_F);Ihe=n(y8e,"STRONG",{});var zpt=s(Ihe);lJo=r(zpt,"sew-d"),zpt.forEach(t),iJo=r(y8e," \u2014 "),XO=n(y8e,"A",{href:!0});var Qpt=s(XO);dJo=r(Qpt,"SEWDForCTC"),Qpt.forEach(t),cJo=r(y8e," (SEW-D model)"),y8e.forEach(t),fJo=i(Go),uF=n(Go,"LI",{});var L8e=s(uF);qhe=n(L8e,"STRONG",{});var Wpt=s(qhe);mJo=r(Wpt,"unispeech"),Wpt.forEach(t),gJo=r(L8e," \u2014 "),zO=n(L8e,"A",{href:!0});var Hpt=s(zO);hJo=r(Hpt,"UniSpeechForCTC"),Hpt.forEach(t),pJo=r(L8e," (UniSpeech model)"),L8e.forEach(t),_Jo=i(Go),bF=n(Go,"LI",{});var x8e=s(bF);Nhe=n(x8e,"STRONG",{});var Upt=s(Nhe);uJo=r(Upt,"unispeech-sat"),Upt.forEach(t),bJo=r(x8e," \u2014 "),QO=n(x8e,"A",{href:!0});var Jpt=s(QO);vJo=r(Jpt,"UniSpeechSatForCTC"),Jpt.forEach(t),FJo=r(x8e," (UniSpeechSat model)"),x8e.forEach(t),TJo=i(Go),vF=n(Go,"LI",{});var k8e=s(vF);jhe=n(k8e,"STRONG",{});var Ypt=s(jhe);MJo=r(Ypt,"wav2vec2"),Ypt.forEach(t),EJo=r(k8e," \u2014 "),WO=n(k8e,"A",{href:!0});var Kpt=s(WO);CJo=r(Kpt,"Wav2Vec2ForCTC"),Kpt.forEach(t),wJo=r(k8e," (Wav2Vec2 model)"),k8e.forEach(t),AJo=i(Go),FF=n(Go,"LI",{});var S8e=s(FF);Dhe=n(S8e,"STRONG",{});var Zpt=s(Dhe);yJo=r(Zpt,"wavlm"),Zpt.forEach(t),LJo=r(S8e," \u2014 "),HO=n(S8e,"A",{href:!0});var e_t=s(HO);xJo=r(e_t,"WavLMForCTC"),e_t.forEach(t),kJo=r(S8e," (WavLM model)"),S8e.forEach(t),Go.forEach(t),SJo=i(oa),TF=n(oa,"P",{});var R8e=s(TF);RJo=r(R8e,"The model is set in evaluation mode by default using "),Ghe=n(R8e,"CODE",{});var o_t=s(Ghe);BJo=r(o_t,"model.eval()"),o_t.forEach(t),PJo=r(R8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ohe=n(R8e,"CODE",{});var r_t=s(Ohe);$Jo=r(r_t,"model.train()"),r_t.forEach(t),R8e.forEach(t),IJo=i(oa),Vhe=n(oa,"P",{});var t_t=s(Vhe);qJo=r(t_t,"Examples:"),t_t.forEach(t),NJo=i(oa),m(Iw.$$.fragment,oa),oa.forEach(t),Bl.forEach(t),E$e=i(c),ec=n(c,"H2",{class:!0});var Rqe=s(ec);MF=n(Rqe,"A",{id:!0,class:!0,href:!0});var a_t=s(MF);Xhe=n(a_t,"SPAN",{});var n_t=s(Xhe);m(qw.$$.fragment,n_t),n_t.forEach(t),a_t.forEach(t),jJo=i(Rqe),zhe=n(Rqe,"SPAN",{});var s_t=s(zhe);DJo=r(s_t,"AutoModelForSpeechSeq2Seq"),s_t.forEach(t),Rqe.forEach(t),C$e=i(c),mr=n(c,"DIV",{class:!0});var $l=s(mr);m(Nw.$$.fragment,$l),GJo=i($l),oc=n($l,"P",{});var mY=s(oc);OJo=r(mY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),UO=n(mY,"A",{href:!0});var l_t=s(UO);VJo=r(l_t,"from_pretrained()"),l_t.forEach(t),XJo=r(mY," class method or the "),JO=n(mY,"A",{href:!0});var i_t=s(JO);zJo=r(i_t,"from_config()"),i_t.forEach(t),QJo=r(mY,` class
method.`),mY.forEach(t),WJo=i($l),jw=n($l,"P",{});var Bqe=s(jw);HJo=r(Bqe,"This class cannot be instantiated directly using "),Qhe=n(Bqe,"CODE",{});var d_t=s(Qhe);UJo=r(d_t,"__init__()"),d_t.forEach(t),JJo=r(Bqe," (throws an error)."),Bqe.forEach(t),YJo=i($l),st=n($l,"DIV",{class:!0});var Il=s(st);m(Dw.$$.fragment,Il),KJo=i(Il),Whe=n(Il,"P",{});var c_t=s(Whe);ZJo=r(c_t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),c_t.forEach(t),eYo=i(Il),rc=n(Il,"P",{});var gY=s(rc);oYo=r(gY,`Note:
Loading a model from its configuration file does `),Hhe=n(gY,"STRONG",{});var f_t=s(Hhe);rYo=r(f_t,"not"),f_t.forEach(t),tYo=r(gY,` load the model weights. It only affects the
model\u2019s configuration. Use `),YO=n(gY,"A",{href:!0});var m_t=s(YO);aYo=r(m_t,"from_pretrained()"),m_t.forEach(t),nYo=r(gY," to load the model weights."),gY.forEach(t),sYo=i(Il),Uhe=n(Il,"P",{});var g_t=s(Uhe);lYo=r(g_t,"Examples:"),g_t.forEach(t),iYo=i(Il),m(Gw.$$.fragment,Il),Il.forEach(t),dYo=i($l),oo=n($l,"DIV",{class:!0});var ra=s(oo);m(Ow.$$.fragment,ra),cYo=i(ra),Jhe=n(ra,"P",{});var h_t=s(Jhe);fYo=r(h_t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),h_t.forEach(t),mYo=i(ra),ln=n(ra,"P",{});var v5=s(ln);gYo=r(v5,"The model class to instantiate is selected based on the "),Yhe=n(v5,"CODE",{});var p_t=s(Yhe);hYo=r(p_t,"model_type"),p_t.forEach(t),pYo=r(v5,` property of the config object (either
passed as an argument or loaded from `),Khe=n(v5,"CODE",{});var __t=s(Khe);_Yo=r(__t,"pretrained_model_name_or_path"),__t.forEach(t),uYo=r(v5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zhe=n(v5,"CODE",{});var u_t=s(Zhe);bYo=r(u_t,"pretrained_model_name_or_path"),u_t.forEach(t),vYo=r(v5,":"),v5.forEach(t),FYo=i(ra),Vw=n(ra,"UL",{});var Pqe=s(Vw);EF=n(Pqe,"LI",{});var B8e=s(EF);epe=n(B8e,"STRONG",{});var b_t=s(epe);TYo=r(b_t,"speech-encoder-decoder"),b_t.forEach(t),MYo=r(B8e," \u2014 "),KO=n(B8e,"A",{href:!0});var v_t=s(KO);EYo=r(v_t,"SpeechEncoderDecoderModel"),v_t.forEach(t),CYo=r(B8e," (Speech Encoder decoder model)"),B8e.forEach(t),wYo=i(Pqe),CF=n(Pqe,"LI",{});var P8e=s(CF);ope=n(P8e,"STRONG",{});var F_t=s(ope);AYo=r(F_t,"speech_to_text"),F_t.forEach(t),yYo=r(P8e," \u2014 "),ZO=n(P8e,"A",{href:!0});var T_t=s(ZO);LYo=r(T_t,"Speech2TextForConditionalGeneration"),T_t.forEach(t),xYo=r(P8e," (Speech2Text model)"),P8e.forEach(t),Pqe.forEach(t),kYo=i(ra),wF=n(ra,"P",{});var $8e=s(wF);SYo=r($8e,"The model is set in evaluation mode by default using "),rpe=n($8e,"CODE",{});var M_t=s(rpe);RYo=r(M_t,"model.eval()"),M_t.forEach(t),BYo=r($8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tpe=n($8e,"CODE",{});var E_t=s(tpe);PYo=r(E_t,"model.train()"),E_t.forEach(t),$8e.forEach(t),$Yo=i(ra),ape=n(ra,"P",{});var C_t=s(ape);IYo=r(C_t,"Examples:"),C_t.forEach(t),qYo=i(ra),m(Xw.$$.fragment,ra),ra.forEach(t),$l.forEach(t),w$e=i(c),tc=n(c,"H2",{class:!0});var $qe=s(tc);AF=n($qe,"A",{id:!0,class:!0,href:!0});var w_t=s(AF);npe=n(w_t,"SPAN",{});var A_t=s(npe);m(zw.$$.fragment,A_t),A_t.forEach(t),w_t.forEach(t),NYo=i($qe),spe=n($qe,"SPAN",{});var y_t=s(spe);jYo=r(y_t,"AutoModelForAudioXVector"),y_t.forEach(t),$qe.forEach(t),A$e=i(c),gr=n(c,"DIV",{class:!0});var ql=s(gr);m(Qw.$$.fragment,ql),DYo=i(ql),ac=n(ql,"P",{});var hY=s(ac);GYo=r(hY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),eV=n(hY,"A",{href:!0});var L_t=s(eV);OYo=r(L_t,"from_pretrained()"),L_t.forEach(t),VYo=r(hY," class method or the "),oV=n(hY,"A",{href:!0});var x_t=s(oV);XYo=r(x_t,"from_config()"),x_t.forEach(t),zYo=r(hY,` class
method.`),hY.forEach(t),QYo=i(ql),Ww=n(ql,"P",{});var Iqe=s(Ww);WYo=r(Iqe,"This class cannot be instantiated directly using "),lpe=n(Iqe,"CODE",{});var k_t=s(lpe);HYo=r(k_t,"__init__()"),k_t.forEach(t),UYo=r(Iqe," (throws an error)."),Iqe.forEach(t),JYo=i(ql),lt=n(ql,"DIV",{class:!0});var Nl=s(lt);m(Hw.$$.fragment,Nl),YYo=i(Nl),ipe=n(Nl,"P",{});var S_t=s(ipe);KYo=r(S_t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),S_t.forEach(t),ZYo=i(Nl),nc=n(Nl,"P",{});var pY=s(nc);eKo=r(pY,`Note:
Loading a model from its configuration file does `),dpe=n(pY,"STRONG",{});var R_t=s(dpe);oKo=r(R_t,"not"),R_t.forEach(t),rKo=r(pY,` load the model weights. It only affects the
model\u2019s configuration. Use `),rV=n(pY,"A",{href:!0});var B_t=s(rV);tKo=r(B_t,"from_pretrained()"),B_t.forEach(t),aKo=r(pY," to load the model weights."),pY.forEach(t),nKo=i(Nl),cpe=n(Nl,"P",{});var P_t=s(cpe);sKo=r(P_t,"Examples:"),P_t.forEach(t),lKo=i(Nl),m(Uw.$$.fragment,Nl),Nl.forEach(t),iKo=i(ql),ro=n(ql,"DIV",{class:!0});var ta=s(ro);m(Jw.$$.fragment,ta),dKo=i(ta),fpe=n(ta,"P",{});var $_t=s(fpe);cKo=r($_t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),$_t.forEach(t),fKo=i(ta),dn=n(ta,"P",{});var F5=s(dn);mKo=r(F5,"The model class to instantiate is selected based on the "),mpe=n(F5,"CODE",{});var I_t=s(mpe);gKo=r(I_t,"model_type"),I_t.forEach(t),hKo=r(F5,` property of the config object (either
passed as an argument or loaded from `),gpe=n(F5,"CODE",{});var q_t=s(gpe);pKo=r(q_t,"pretrained_model_name_or_path"),q_t.forEach(t),_Ko=r(F5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hpe=n(F5,"CODE",{});var N_t=s(hpe);uKo=r(N_t,"pretrained_model_name_or_path"),N_t.forEach(t),bKo=r(F5,":"),F5.forEach(t),vKo=i(ta),cn=n(ta,"UL",{});var T5=s(cn);yF=n(T5,"LI",{});var I8e=s(yF);ppe=n(I8e,"STRONG",{});var j_t=s(ppe);FKo=r(j_t,"data2vec-audio"),j_t.forEach(t),TKo=r(I8e," \u2014 "),tV=n(I8e,"A",{href:!0});var D_t=s(tV);MKo=r(D_t,"Data2VecAudioForXVector"),D_t.forEach(t),EKo=r(I8e," (Data2VecAudio model)"),I8e.forEach(t),CKo=i(T5),LF=n(T5,"LI",{});var q8e=s(LF);_pe=n(q8e,"STRONG",{});var G_t=s(_pe);wKo=r(G_t,"unispeech-sat"),G_t.forEach(t),AKo=r(q8e," \u2014 "),aV=n(q8e,"A",{href:!0});var O_t=s(aV);yKo=r(O_t,"UniSpeechSatForXVector"),O_t.forEach(t),LKo=r(q8e," (UniSpeechSat model)"),q8e.forEach(t),xKo=i(T5),xF=n(T5,"LI",{});var N8e=s(xF);upe=n(N8e,"STRONG",{});var V_t=s(upe);kKo=r(V_t,"wav2vec2"),V_t.forEach(t),SKo=r(N8e," \u2014 "),nV=n(N8e,"A",{href:!0});var X_t=s(nV);RKo=r(X_t,"Wav2Vec2ForXVector"),X_t.forEach(t),BKo=r(N8e," (Wav2Vec2 model)"),N8e.forEach(t),PKo=i(T5),kF=n(T5,"LI",{});var j8e=s(kF);bpe=n(j8e,"STRONG",{});var z_t=s(bpe);$Ko=r(z_t,"wavlm"),z_t.forEach(t),IKo=r(j8e," \u2014 "),sV=n(j8e,"A",{href:!0});var Q_t=s(sV);qKo=r(Q_t,"WavLMForXVector"),Q_t.forEach(t),NKo=r(j8e," (WavLM model)"),j8e.forEach(t),T5.forEach(t),jKo=i(ta),SF=n(ta,"P",{});var D8e=s(SF);DKo=r(D8e,"The model is set in evaluation mode by default using "),vpe=n(D8e,"CODE",{});var W_t=s(vpe);GKo=r(W_t,"model.eval()"),W_t.forEach(t),OKo=r(D8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fpe=n(D8e,"CODE",{});var H_t=s(Fpe);VKo=r(H_t,"model.train()"),H_t.forEach(t),D8e.forEach(t),XKo=i(ta),Tpe=n(ta,"P",{});var U_t=s(Tpe);zKo=r(U_t,"Examples:"),U_t.forEach(t),QKo=i(ta),m(Yw.$$.fragment,ta),ta.forEach(t),ql.forEach(t),y$e=i(c),sc=n(c,"H2",{class:!0});var qqe=s(sc);RF=n(qqe,"A",{id:!0,class:!0,href:!0});var J_t=s(RF);Mpe=n(J_t,"SPAN",{});var Y_t=s(Mpe);m(Kw.$$.fragment,Y_t),Y_t.forEach(t),J_t.forEach(t),WKo=i(qqe),Epe=n(qqe,"SPAN",{});var K_t=s(Epe);HKo=r(K_t,"AutoModelForMaskedImageModeling"),K_t.forEach(t),qqe.forEach(t),L$e=i(c),hr=n(c,"DIV",{class:!0});var jl=s(hr);m(Zw.$$.fragment,jl),UKo=i(jl),lc=n(jl,"P",{});var _Y=s(lc);JKo=r(_Y,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),lV=n(_Y,"A",{href:!0});var Z_t=s(lV);YKo=r(Z_t,"from_pretrained()"),Z_t.forEach(t),KKo=r(_Y," class method or the "),iV=n(_Y,"A",{href:!0});var eut=s(iV);ZKo=r(eut,"from_config()"),eut.forEach(t),eZo=r(_Y,` class
method.`),_Y.forEach(t),oZo=i(jl),e0=n(jl,"P",{});var Nqe=s(e0);rZo=r(Nqe,"This class cannot be instantiated directly using "),Cpe=n(Nqe,"CODE",{});var out=s(Cpe);tZo=r(out,"__init__()"),out.forEach(t),aZo=r(Nqe," (throws an error)."),Nqe.forEach(t),nZo=i(jl),it=n(jl,"DIV",{class:!0});var Dl=s(it);m(o0.$$.fragment,Dl),sZo=i(Dl),wpe=n(Dl,"P",{});var rut=s(wpe);lZo=r(rut,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),rut.forEach(t),iZo=i(Dl),ic=n(Dl,"P",{});var uY=s(ic);dZo=r(uY,`Note:
Loading a model from its configuration file does `),Ape=n(uY,"STRONG",{});var tut=s(Ape);cZo=r(tut,"not"),tut.forEach(t),fZo=r(uY,` load the model weights. It only affects the
model\u2019s configuration. Use `),dV=n(uY,"A",{href:!0});var aut=s(dV);mZo=r(aut,"from_pretrained()"),aut.forEach(t),gZo=r(uY," to load the model weights."),uY.forEach(t),hZo=i(Dl),ype=n(Dl,"P",{});var nut=s(ype);pZo=r(nut,"Examples:"),nut.forEach(t),_Zo=i(Dl),m(r0.$$.fragment,Dl),Dl.forEach(t),uZo=i(jl),to=n(jl,"DIV",{class:!0});var aa=s(to);m(t0.$$.fragment,aa),bZo=i(aa),Lpe=n(aa,"P",{});var sut=s(Lpe);vZo=r(sut,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),sut.forEach(t),FZo=i(aa),fn=n(aa,"P",{});var M5=s(fn);TZo=r(M5,"The model class to instantiate is selected based on the "),xpe=n(M5,"CODE",{});var lut=s(xpe);MZo=r(lut,"model_type"),lut.forEach(t),EZo=r(M5,` property of the config object (either
passed as an argument or loaded from `),kpe=n(M5,"CODE",{});var iut=s(kpe);CZo=r(iut,"pretrained_model_name_or_path"),iut.forEach(t),wZo=r(M5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Spe=n(M5,"CODE",{});var dut=s(Spe);AZo=r(dut,"pretrained_model_name_or_path"),dut.forEach(t),yZo=r(M5,":"),M5.forEach(t),LZo=i(aa),dc=n(aa,"UL",{});var bY=s(dc);BF=n(bY,"LI",{});var G8e=s(BF);Rpe=n(G8e,"STRONG",{});var cut=s(Rpe);xZo=r(cut,"deit"),cut.forEach(t),kZo=r(G8e," \u2014 "),cV=n(G8e,"A",{href:!0});var fut=s(cV);SZo=r(fut,"DeiTForMaskedImageModeling"),fut.forEach(t),RZo=r(G8e," (DeiT model)"),G8e.forEach(t),BZo=i(bY),PF=n(bY,"LI",{});var O8e=s(PF);Bpe=n(O8e,"STRONG",{});var mut=s(Bpe);PZo=r(mut,"swin"),mut.forEach(t),$Zo=r(O8e," \u2014 "),fV=n(O8e,"A",{href:!0});var gut=s(fV);IZo=r(gut,"SwinForMaskedImageModeling"),gut.forEach(t),qZo=r(O8e," (Swin model)"),O8e.forEach(t),NZo=i(bY),$F=n(bY,"LI",{});var V8e=s($F);Ppe=n(V8e,"STRONG",{});var hut=s(Ppe);jZo=r(hut,"vit"),hut.forEach(t),DZo=r(V8e," \u2014 "),mV=n(V8e,"A",{href:!0});var put=s(mV);GZo=r(put,"ViTForMaskedImageModeling"),put.forEach(t),OZo=r(V8e," (ViT model)"),V8e.forEach(t),bY.forEach(t),VZo=i(aa),IF=n(aa,"P",{});var X8e=s(IF);XZo=r(X8e,"The model is set in evaluation mode by default using "),$pe=n(X8e,"CODE",{});var _ut=s($pe);zZo=r(_ut,"model.eval()"),_ut.forEach(t),QZo=r(X8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ipe=n(X8e,"CODE",{});var uut=s(Ipe);WZo=r(uut,"model.train()"),uut.forEach(t),X8e.forEach(t),HZo=i(aa),qpe=n(aa,"P",{});var but=s(qpe);UZo=r(but,"Examples:"),but.forEach(t),JZo=i(aa),m(a0.$$.fragment,aa),aa.forEach(t),jl.forEach(t),x$e=i(c),cc=n(c,"H2",{class:!0});var jqe=s(cc);qF=n(jqe,"A",{id:!0,class:!0,href:!0});var vut=s(qF);Npe=n(vut,"SPAN",{});var Fut=s(Npe);m(n0.$$.fragment,Fut),Fut.forEach(t),vut.forEach(t),YZo=i(jqe),jpe=n(jqe,"SPAN",{});var Tut=s(jpe);KZo=r(Tut,"AutoModelForObjectDetection"),Tut.forEach(t),jqe.forEach(t),k$e=i(c),pr=n(c,"DIV",{class:!0});var Gl=s(pr);m(s0.$$.fragment,Gl),ZZo=i(Gl),fc=n(Gl,"P",{});var vY=s(fc);eer=r(vY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),gV=n(vY,"A",{href:!0});var Mut=s(gV);oer=r(Mut,"from_pretrained()"),Mut.forEach(t),rer=r(vY," class method or the "),hV=n(vY,"A",{href:!0});var Eut=s(hV);ter=r(Eut,"from_config()"),Eut.forEach(t),aer=r(vY,` class
method.`),vY.forEach(t),ner=i(Gl),l0=n(Gl,"P",{});var Dqe=s(l0);ser=r(Dqe,"This class cannot be instantiated directly using "),Dpe=n(Dqe,"CODE",{});var Cut=s(Dpe);ler=r(Cut,"__init__()"),Cut.forEach(t),ier=r(Dqe," (throws an error)."),Dqe.forEach(t),der=i(Gl),dt=n(Gl,"DIV",{class:!0});var Ol=s(dt);m(i0.$$.fragment,Ol),cer=i(Ol),Gpe=n(Ol,"P",{});var wut=s(Gpe);fer=r(wut,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),wut.forEach(t),mer=i(Ol),mc=n(Ol,"P",{});var FY=s(mc);ger=r(FY,`Note:
Loading a model from its configuration file does `),Ope=n(FY,"STRONG",{});var Aut=s(Ope);her=r(Aut,"not"),Aut.forEach(t),per=r(FY,` load the model weights. It only affects the
model\u2019s configuration. Use `),pV=n(FY,"A",{href:!0});var yut=s(pV);_er=r(yut,"from_pretrained()"),yut.forEach(t),uer=r(FY," to load the model weights."),FY.forEach(t),ber=i(Ol),Vpe=n(Ol,"P",{});var Lut=s(Vpe);ver=r(Lut,"Examples:"),Lut.forEach(t),Fer=i(Ol),m(d0.$$.fragment,Ol),Ol.forEach(t),Ter=i(Gl),ao=n(Gl,"DIV",{class:!0});var na=s(ao);m(c0.$$.fragment,na),Mer=i(na),Xpe=n(na,"P",{});var xut=s(Xpe);Eer=r(xut,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),xut.forEach(t),Cer=i(na),mn=n(na,"P",{});var E5=s(mn);wer=r(E5,"The model class to instantiate is selected based on the "),zpe=n(E5,"CODE",{});var kut=s(zpe);Aer=r(kut,"model_type"),kut.forEach(t),yer=r(E5,` property of the config object (either
passed as an argument or loaded from `),Qpe=n(E5,"CODE",{});var Sut=s(Qpe);Ler=r(Sut,"pretrained_model_name_or_path"),Sut.forEach(t),xer=r(E5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wpe=n(E5,"CODE",{});var Rut=s(Wpe);ker=r(Rut,"pretrained_model_name_or_path"),Rut.forEach(t),Ser=r(E5,":"),E5.forEach(t),Rer=i(na),Hpe=n(na,"UL",{});var But=s(Hpe);NF=n(But,"LI",{});var z8e=s(NF);Upe=n(z8e,"STRONG",{});var Put=s(Upe);Ber=r(Put,"detr"),Put.forEach(t),Per=r(z8e," \u2014 "),_V=n(z8e,"A",{href:!0});var $ut=s(_V);$er=r($ut,"DetrForObjectDetection"),$ut.forEach(t),Ier=r(z8e," (DETR model)"),z8e.forEach(t),But.forEach(t),qer=i(na),jF=n(na,"P",{});var Q8e=s(jF);Ner=r(Q8e,"The model is set in evaluation mode by default using "),Jpe=n(Q8e,"CODE",{});var Iut=s(Jpe);jer=r(Iut,"model.eval()"),Iut.forEach(t),Der=r(Q8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ype=n(Q8e,"CODE",{});var qut=s(Ype);Ger=r(qut,"model.train()"),qut.forEach(t),Q8e.forEach(t),Oer=i(na),Kpe=n(na,"P",{});var Nut=s(Kpe);Ver=r(Nut,"Examples:"),Nut.forEach(t),Xer=i(na),m(f0.$$.fragment,na),na.forEach(t),Gl.forEach(t),S$e=i(c),gc=n(c,"H2",{class:!0});var Gqe=s(gc);DF=n(Gqe,"A",{id:!0,class:!0,href:!0});var jut=s(DF);Zpe=n(jut,"SPAN",{});var Dut=s(Zpe);m(m0.$$.fragment,Dut),Dut.forEach(t),jut.forEach(t),zer=i(Gqe),e_e=n(Gqe,"SPAN",{});var Gut=s(e_e);Qer=r(Gut,"AutoModelForImageSegmentation"),Gut.forEach(t),Gqe.forEach(t),R$e=i(c),_r=n(c,"DIV",{class:!0});var Vl=s(_r);m(g0.$$.fragment,Vl),Wer=i(Vl),hc=n(Vl,"P",{});var TY=s(hc);Her=r(TY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),uV=n(TY,"A",{href:!0});var Out=s(uV);Uer=r(Out,"from_pretrained()"),Out.forEach(t),Jer=r(TY," class method or the "),bV=n(TY,"A",{href:!0});var Vut=s(bV);Yer=r(Vut,"from_config()"),Vut.forEach(t),Ker=r(TY,` class
method.`),TY.forEach(t),Zer=i(Vl),h0=n(Vl,"P",{});var Oqe=s(h0);eor=r(Oqe,"This class cannot be instantiated directly using "),o_e=n(Oqe,"CODE",{});var Xut=s(o_e);oor=r(Xut,"__init__()"),Xut.forEach(t),ror=r(Oqe," (throws an error)."),Oqe.forEach(t),tor=i(Vl),ct=n(Vl,"DIV",{class:!0});var Xl=s(ct);m(p0.$$.fragment,Xl),aor=i(Xl),r_e=n(Xl,"P",{});var zut=s(r_e);nor=r(zut,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),zut.forEach(t),sor=i(Xl),pc=n(Xl,"P",{});var MY=s(pc);lor=r(MY,`Note:
Loading a model from its configuration file does `),t_e=n(MY,"STRONG",{});var Qut=s(t_e);ior=r(Qut,"not"),Qut.forEach(t),dor=r(MY,` load the model weights. It only affects the
model\u2019s configuration. Use `),vV=n(MY,"A",{href:!0});var Wut=s(vV);cor=r(Wut,"from_pretrained()"),Wut.forEach(t),mor=r(MY," to load the model weights."),MY.forEach(t),gor=i(Xl),a_e=n(Xl,"P",{});var Hut=s(a_e);hor=r(Hut,"Examples:"),Hut.forEach(t),por=i(Xl),m(_0.$$.fragment,Xl),Xl.forEach(t),_or=i(Vl),no=n(Vl,"DIV",{class:!0});var sa=s(no);m(u0.$$.fragment,sa),uor=i(sa),n_e=n(sa,"P",{});var Uut=s(n_e);bor=r(Uut,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Uut.forEach(t),vor=i(sa),gn=n(sa,"P",{});var C5=s(gn);For=r(C5,"The model class to instantiate is selected based on the "),s_e=n(C5,"CODE",{});var Jut=s(s_e);Tor=r(Jut,"model_type"),Jut.forEach(t),Mor=r(C5,` property of the config object (either
passed as an argument or loaded from `),l_e=n(C5,"CODE",{});var Yut=s(l_e);Eor=r(Yut,"pretrained_model_name_or_path"),Yut.forEach(t),Cor=r(C5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=n(C5,"CODE",{});var Kut=s(i_e);wor=r(Kut,"pretrained_model_name_or_path"),Kut.forEach(t),Aor=r(C5,":"),C5.forEach(t),yor=i(sa),d_e=n(sa,"UL",{});var Zut=s(d_e);GF=n(Zut,"LI",{});var W8e=s(GF);c_e=n(W8e,"STRONG",{});var e2t=s(c_e);Lor=r(e2t,"detr"),e2t.forEach(t),xor=r(W8e," \u2014 "),FV=n(W8e,"A",{href:!0});var o2t=s(FV);kor=r(o2t,"DetrForSegmentation"),o2t.forEach(t),Sor=r(W8e," (DETR model)"),W8e.forEach(t),Zut.forEach(t),Ror=i(sa),OF=n(sa,"P",{});var H8e=s(OF);Bor=r(H8e,"The model is set in evaluation mode by default using "),f_e=n(H8e,"CODE",{});var r2t=s(f_e);Por=r(r2t,"model.eval()"),r2t.forEach(t),$or=r(H8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m_e=n(H8e,"CODE",{});var t2t=s(m_e);Ior=r(t2t,"model.train()"),t2t.forEach(t),H8e.forEach(t),qor=i(sa),g_e=n(sa,"P",{});var a2t=s(g_e);Nor=r(a2t,"Examples:"),a2t.forEach(t),jor=i(sa),m(b0.$$.fragment,sa),sa.forEach(t),Vl.forEach(t),B$e=i(c),_c=n(c,"H2",{class:!0});var Vqe=s(_c);VF=n(Vqe,"A",{id:!0,class:!0,href:!0});var n2t=s(VF);h_e=n(n2t,"SPAN",{});var s2t=s(h_e);m(v0.$$.fragment,s2t),s2t.forEach(t),n2t.forEach(t),Dor=i(Vqe),p_e=n(Vqe,"SPAN",{});var l2t=s(p_e);Gor=r(l2t,"AutoModelForSemanticSegmentation"),l2t.forEach(t),Vqe.forEach(t),P$e=i(c),ur=n(c,"DIV",{class:!0});var zl=s(ur);m(F0.$$.fragment,zl),Oor=i(zl),uc=n(zl,"P",{});var EY=s(uc);Vor=r(EY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),TV=n(EY,"A",{href:!0});var i2t=s(TV);Xor=r(i2t,"from_pretrained()"),i2t.forEach(t),zor=r(EY," class method or the "),MV=n(EY,"A",{href:!0});var d2t=s(MV);Qor=r(d2t,"from_config()"),d2t.forEach(t),Wor=r(EY,` class
method.`),EY.forEach(t),Hor=i(zl),T0=n(zl,"P",{});var Xqe=s(T0);Uor=r(Xqe,"This class cannot be instantiated directly using "),__e=n(Xqe,"CODE",{});var c2t=s(__e);Jor=r(c2t,"__init__()"),c2t.forEach(t),Yor=r(Xqe," (throws an error)."),Xqe.forEach(t),Kor=i(zl),ft=n(zl,"DIV",{class:!0});var Ql=s(ft);m(M0.$$.fragment,Ql),Zor=i(Ql),u_e=n(Ql,"P",{});var f2t=s(u_e);err=r(f2t,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),f2t.forEach(t),orr=i(Ql),bc=n(Ql,"P",{});var CY=s(bc);rrr=r(CY,`Note:
Loading a model from its configuration file does `),b_e=n(CY,"STRONG",{});var m2t=s(b_e);trr=r(m2t,"not"),m2t.forEach(t),arr=r(CY,` load the model weights. It only affects the
model\u2019s configuration. Use `),EV=n(CY,"A",{href:!0});var g2t=s(EV);nrr=r(g2t,"from_pretrained()"),g2t.forEach(t),srr=r(CY," to load the model weights."),CY.forEach(t),lrr=i(Ql),v_e=n(Ql,"P",{});var h2t=s(v_e);irr=r(h2t,"Examples:"),h2t.forEach(t),drr=i(Ql),m(E0.$$.fragment,Ql),Ql.forEach(t),crr=i(zl),so=n(zl,"DIV",{class:!0});var la=s(so);m(C0.$$.fragment,la),frr=i(la),F_e=n(la,"P",{});var p2t=s(F_e);mrr=r(p2t,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),p2t.forEach(t),grr=i(la),hn=n(la,"P",{});var w5=s(hn);hrr=r(w5,"The model class to instantiate is selected based on the "),T_e=n(w5,"CODE",{});var _2t=s(T_e);prr=r(_2t,"model_type"),_2t.forEach(t),_rr=r(w5,` property of the config object (either
passed as an argument or loaded from `),M_e=n(w5,"CODE",{});var u2t=s(M_e);urr=r(u2t,"pretrained_model_name_or_path"),u2t.forEach(t),brr=r(w5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E_e=n(w5,"CODE",{});var b2t=s(E_e);vrr=r(b2t,"pretrained_model_name_or_path"),b2t.forEach(t),Frr=r(w5,":"),w5.forEach(t),Trr=i(la),pn=n(la,"UL",{});var A5=s(pn);XF=n(A5,"LI",{});var U8e=s(XF);C_e=n(U8e,"STRONG",{});var v2t=s(C_e);Mrr=r(v2t,"beit"),v2t.forEach(t),Err=r(U8e," \u2014 "),CV=n(U8e,"A",{href:!0});var F2t=s(CV);Crr=r(F2t,"BeitForSemanticSegmentation"),F2t.forEach(t),wrr=r(U8e," (BEiT model)"),U8e.forEach(t),Arr=i(A5),zF=n(A5,"LI",{});var J8e=s(zF);w_e=n(J8e,"STRONG",{});var T2t=s(w_e);yrr=r(T2t,"data2vec-vision"),T2t.forEach(t),Lrr=r(J8e," \u2014 "),wV=n(J8e,"A",{href:!0});var M2t=s(wV);xrr=r(M2t,"Data2VecVisionForSemanticSegmentation"),M2t.forEach(t),krr=r(J8e," (Data2VecVision model)"),J8e.forEach(t),Srr=i(A5),QF=n(A5,"LI",{});var Y8e=s(QF);A_e=n(Y8e,"STRONG",{});var E2t=s(A_e);Rrr=r(E2t,"dpt"),E2t.forEach(t),Brr=r(Y8e," \u2014 "),AV=n(Y8e,"A",{href:!0});var C2t=s(AV);Prr=r(C2t,"DPTForSemanticSegmentation"),C2t.forEach(t),$rr=r(Y8e," (DPT model)"),Y8e.forEach(t),Irr=i(A5),WF=n(A5,"LI",{});var K8e=s(WF);y_e=n(K8e,"STRONG",{});var w2t=s(y_e);qrr=r(w2t,"segformer"),w2t.forEach(t),Nrr=r(K8e," \u2014 "),yV=n(K8e,"A",{href:!0});var A2t=s(yV);jrr=r(A2t,"SegformerForSemanticSegmentation"),A2t.forEach(t),Drr=r(K8e," (SegFormer model)"),K8e.forEach(t),A5.forEach(t),Grr=i(la),HF=n(la,"P",{});var Z8e=s(HF);Orr=r(Z8e,"The model is set in evaluation mode by default using "),L_e=n(Z8e,"CODE",{});var y2t=s(L_e);Vrr=r(y2t,"model.eval()"),y2t.forEach(t),Xrr=r(Z8e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x_e=n(Z8e,"CODE",{});var L2t=s(x_e);zrr=r(L2t,"model.train()"),L2t.forEach(t),Z8e.forEach(t),Qrr=i(la),k_e=n(la,"P",{});var x2t=s(k_e);Wrr=r(x2t,"Examples:"),x2t.forEach(t),Hrr=i(la),m(w0.$$.fragment,la),la.forEach(t),zl.forEach(t),$$e=i(c),vc=n(c,"H2",{class:!0});var zqe=s(vc);UF=n(zqe,"A",{id:!0,class:!0,href:!0});var k2t=s(UF);S_e=n(k2t,"SPAN",{});var S2t=s(S_e);m(A0.$$.fragment,S2t),S2t.forEach(t),k2t.forEach(t),Urr=i(zqe),R_e=n(zqe,"SPAN",{});var R2t=s(R_e);Jrr=r(R2t,"AutoModelForInstanceSegmentation"),R2t.forEach(t),zqe.forEach(t),I$e=i(c),br=n(c,"DIV",{class:!0});var Wl=s(br);m(y0.$$.fragment,Wl),Yrr=i(Wl),Fc=n(Wl,"P",{});var wY=s(Fc);Krr=r(wY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),LV=n(wY,"A",{href:!0});var B2t=s(LV);Zrr=r(B2t,"from_pretrained()"),B2t.forEach(t),etr=r(wY," class method or the "),xV=n(wY,"A",{href:!0});var P2t=s(xV);otr=r(P2t,"from_config()"),P2t.forEach(t),rtr=r(wY,` class
method.`),wY.forEach(t),ttr=i(Wl),L0=n(Wl,"P",{});var Qqe=s(L0);atr=r(Qqe,"This class cannot be instantiated directly using "),B_e=n(Qqe,"CODE",{});var $2t=s(B_e);ntr=r($2t,"__init__()"),$2t.forEach(t),str=r(Qqe," (throws an error)."),Qqe.forEach(t),ltr=i(Wl),mt=n(Wl,"DIV",{class:!0});var Hl=s(mt);m(x0.$$.fragment,Hl),itr=i(Hl),P_e=n(Hl,"P",{});var I2t=s(P_e);dtr=r(I2t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),I2t.forEach(t),ctr=i(Hl),Tc=n(Hl,"P",{});var AY=s(Tc);ftr=r(AY,`Note:
Loading a model from its configuration file does `),$_e=n(AY,"STRONG",{});var q2t=s($_e);mtr=r(q2t,"not"),q2t.forEach(t),gtr=r(AY,` load the model weights. It only affects the
model\u2019s configuration. Use `),kV=n(AY,"A",{href:!0});var N2t=s(kV);htr=r(N2t,"from_pretrained()"),N2t.forEach(t),ptr=r(AY," to load the model weights."),AY.forEach(t),_tr=i(Hl),I_e=n(Hl,"P",{});var j2t=s(I_e);utr=r(j2t,"Examples:"),j2t.forEach(t),btr=i(Hl),m(k0.$$.fragment,Hl),Hl.forEach(t),vtr=i(Wl),lo=n(Wl,"DIV",{class:!0});var ia=s(lo);m(S0.$$.fragment,ia),Ftr=i(ia),q_e=n(ia,"P",{});var D2t=s(q_e);Ttr=r(D2t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),D2t.forEach(t),Mtr=i(ia),_n=n(ia,"P",{});var y5=s(_n);Etr=r(y5,"The model class to instantiate is selected based on the "),N_e=n(y5,"CODE",{});var G2t=s(N_e);Ctr=r(G2t,"model_type"),G2t.forEach(t),wtr=r(y5,` property of the config object (either
passed as an argument or loaded from `),j_e=n(y5,"CODE",{});var O2t=s(j_e);Atr=r(O2t,"pretrained_model_name_or_path"),O2t.forEach(t),ytr=r(y5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D_e=n(y5,"CODE",{});var V2t=s(D_e);Ltr=r(V2t,"pretrained_model_name_or_path"),V2t.forEach(t),xtr=r(y5,":"),y5.forEach(t),ktr=i(ia),G_e=n(ia,"UL",{});var X2t=s(G_e);JF=n(X2t,"LI",{});var exe=s(JF);O_e=n(exe,"STRONG",{});var z2t=s(O_e);Str=r(z2t,"maskformer"),z2t.forEach(t),Rtr=r(exe," \u2014 "),SV=n(exe,"A",{href:!0});var Q2t=s(SV);Btr=r(Q2t,"MaskFormerForInstanceSegmentation"),Q2t.forEach(t),Ptr=r(exe," (MaskFormer model)"),exe.forEach(t),X2t.forEach(t),$tr=i(ia),YF=n(ia,"P",{});var oxe=s(YF);Itr=r(oxe,"The model is set in evaluation mode by default using "),V_e=n(oxe,"CODE",{});var W2t=s(V_e);qtr=r(W2t,"model.eval()"),W2t.forEach(t),Ntr=r(oxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X_e=n(oxe,"CODE",{});var H2t=s(X_e);jtr=r(H2t,"model.train()"),H2t.forEach(t),oxe.forEach(t),Dtr=i(ia),z_e=n(ia,"P",{});var U2t=s(z_e);Gtr=r(U2t,"Examples:"),U2t.forEach(t),Otr=i(ia),m(R0.$$.fragment,ia),ia.forEach(t),Wl.forEach(t),q$e=i(c),Mc=n(c,"H2",{class:!0});var Wqe=s(Mc);KF=n(Wqe,"A",{id:!0,class:!0,href:!0});var J2t=s(KF);Q_e=n(J2t,"SPAN",{});var Y2t=s(Q_e);m(B0.$$.fragment,Y2t),Y2t.forEach(t),J2t.forEach(t),Vtr=i(Wqe),W_e=n(Wqe,"SPAN",{});var K2t=s(W_e);Xtr=r(K2t,"TFAutoModel"),K2t.forEach(t),Wqe.forEach(t),N$e=i(c),vr=n(c,"DIV",{class:!0});var Ul=s(vr);m(P0.$$.fragment,Ul),ztr=i(Ul),Ec=n(Ul,"P",{});var yY=s(Ec);Qtr=r(yY,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),RV=n(yY,"A",{href:!0});var Z2t=s(RV);Wtr=r(Z2t,"from_pretrained()"),Z2t.forEach(t),Htr=r(yY," class method or the "),BV=n(yY,"A",{href:!0});var e1t=s(BV);Utr=r(e1t,"from_config()"),e1t.forEach(t),Jtr=r(yY,` class
method.`),yY.forEach(t),Ytr=i(Ul),$0=n(Ul,"P",{});var Hqe=s($0);Ktr=r(Hqe,"This class cannot be instantiated directly using "),H_e=n(Hqe,"CODE",{});var o1t=s(H_e);Ztr=r(o1t,"__init__()"),o1t.forEach(t),ear=r(Hqe," (throws an error)."),Hqe.forEach(t),oar=i(Ul),gt=n(Ul,"DIV",{class:!0});var Jl=s(gt);m(I0.$$.fragment,Jl),rar=i(Jl),U_e=n(Jl,"P",{});var r1t=s(U_e);tar=r(r1t,"Instantiates one of the base model classes of the library from a configuration."),r1t.forEach(t),aar=i(Jl),Cc=n(Jl,"P",{});var LY=s(Cc);nar=r(LY,`Note:
Loading a model from its configuration file does `),J_e=n(LY,"STRONG",{});var t1t=s(J_e);sar=r(t1t,"not"),t1t.forEach(t),lar=r(LY,` load the model weights. It only affects the
model\u2019s configuration. Use `),PV=n(LY,"A",{href:!0});var a1t=s(PV);iar=r(a1t,"from_pretrained()"),a1t.forEach(t),dar=r(LY," to load the model weights."),LY.forEach(t),car=i(Jl),Y_e=n(Jl,"P",{});var n1t=s(Y_e);far=r(n1t,"Examples:"),n1t.forEach(t),mar=i(Jl),m(q0.$$.fragment,Jl),Jl.forEach(t),gar=i(Ul),po=n(Ul,"DIV",{class:!0});var pa=s(po);m(N0.$$.fragment,pa),har=i(pa),K_e=n(pa,"P",{});var s1t=s(K_e);par=r(s1t,"Instantiate one of the base model classes of the library from a pretrained model."),s1t.forEach(t),_ar=i(pa),un=n(pa,"P",{});var L5=s(un);uar=r(L5,"The model class to instantiate is selected based on the "),Z_e=n(L5,"CODE",{});var l1t=s(Z_e);bar=r(l1t,"model_type"),l1t.forEach(t),Far=r(L5,` property of the config object (either
passed as an argument or loaded from `),eue=n(L5,"CODE",{});var i1t=s(eue);Tar=r(i1t,"pretrained_model_name_or_path"),i1t.forEach(t),Mar=r(L5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oue=n(L5,"CODE",{});var d1t=s(oue);Ear=r(d1t,"pretrained_model_name_or_path"),d1t.forEach(t),Car=r(L5,":"),L5.forEach(t),war=i(pa),x=n(pa,"UL",{});var k=s(x);ZF=n(k,"LI",{});var rxe=s(ZF);rue=n(rxe,"STRONG",{});var c1t=s(rue);Aar=r(c1t,"albert"),c1t.forEach(t),yar=r(rxe," \u2014 "),$V=n(rxe,"A",{href:!0});var f1t=s($V);Lar=r(f1t,"TFAlbertModel"),f1t.forEach(t),xar=r(rxe," (ALBERT model)"),rxe.forEach(t),kar=i(k),eT=n(k,"LI",{});var txe=s(eT);tue=n(txe,"STRONG",{});var m1t=s(tue);Sar=r(m1t,"bart"),m1t.forEach(t),Rar=r(txe," \u2014 "),IV=n(txe,"A",{href:!0});var g1t=s(IV);Bar=r(g1t,"TFBartModel"),g1t.forEach(t),Par=r(txe," (BART model)"),txe.forEach(t),$ar=i(k),oT=n(k,"LI",{});var axe=s(oT);aue=n(axe,"STRONG",{});var h1t=s(aue);Iar=r(h1t,"bert"),h1t.forEach(t),qar=r(axe," \u2014 "),qV=n(axe,"A",{href:!0});var p1t=s(qV);Nar=r(p1t,"TFBertModel"),p1t.forEach(t),jar=r(axe," (BERT model)"),axe.forEach(t),Dar=i(k),rT=n(k,"LI",{});var nxe=s(rT);nue=n(nxe,"STRONG",{});var _1t=s(nue);Gar=r(_1t,"blenderbot"),_1t.forEach(t),Oar=r(nxe," \u2014 "),NV=n(nxe,"A",{href:!0});var u1t=s(NV);Var=r(u1t,"TFBlenderbotModel"),u1t.forEach(t),Xar=r(nxe," (Blenderbot model)"),nxe.forEach(t),zar=i(k),tT=n(k,"LI",{});var sxe=s(tT);sue=n(sxe,"STRONG",{});var b1t=s(sue);Qar=r(b1t,"blenderbot-small"),b1t.forEach(t),War=r(sxe," \u2014 "),jV=n(sxe,"A",{href:!0});var v1t=s(jV);Har=r(v1t,"TFBlenderbotSmallModel"),v1t.forEach(t),Uar=r(sxe," (BlenderbotSmall model)"),sxe.forEach(t),Jar=i(k),aT=n(k,"LI",{});var lxe=s(aT);lue=n(lxe,"STRONG",{});var F1t=s(lue);Yar=r(F1t,"camembert"),F1t.forEach(t),Kar=r(lxe," \u2014 "),DV=n(lxe,"A",{href:!0});var T1t=s(DV);Zar=r(T1t,"TFCamembertModel"),T1t.forEach(t),enr=r(lxe," (CamemBERT model)"),lxe.forEach(t),onr=i(k),nT=n(k,"LI",{});var ixe=s(nT);iue=n(ixe,"STRONG",{});var M1t=s(iue);rnr=r(M1t,"clip"),M1t.forEach(t),tnr=r(ixe," \u2014 "),GV=n(ixe,"A",{href:!0});var E1t=s(GV);anr=r(E1t,"TFCLIPModel"),E1t.forEach(t),nnr=r(ixe," (CLIP model)"),ixe.forEach(t),snr=i(k),sT=n(k,"LI",{});var dxe=s(sT);due=n(dxe,"STRONG",{});var C1t=s(due);lnr=r(C1t,"convbert"),C1t.forEach(t),inr=r(dxe," \u2014 "),OV=n(dxe,"A",{href:!0});var w1t=s(OV);dnr=r(w1t,"TFConvBertModel"),w1t.forEach(t),cnr=r(dxe," (ConvBERT model)"),dxe.forEach(t),fnr=i(k),lT=n(k,"LI",{});var cxe=s(lT);cue=n(cxe,"STRONG",{});var A1t=s(cue);mnr=r(A1t,"convnext"),A1t.forEach(t),gnr=r(cxe," \u2014 "),VV=n(cxe,"A",{href:!0});var y1t=s(VV);hnr=r(y1t,"TFConvNextModel"),y1t.forEach(t),pnr=r(cxe," (ConvNext model)"),cxe.forEach(t),_nr=i(k),iT=n(k,"LI",{});var fxe=s(iT);fue=n(fxe,"STRONG",{});var L1t=s(fue);unr=r(L1t,"ctrl"),L1t.forEach(t),bnr=r(fxe," \u2014 "),XV=n(fxe,"A",{href:!0});var x1t=s(XV);vnr=r(x1t,"TFCTRLModel"),x1t.forEach(t),Fnr=r(fxe," (CTRL model)"),fxe.forEach(t),Tnr=i(k),dT=n(k,"LI",{});var mxe=s(dT);mue=n(mxe,"STRONG",{});var k1t=s(mue);Mnr=r(k1t,"deberta"),k1t.forEach(t),Enr=r(mxe," \u2014 "),zV=n(mxe,"A",{href:!0});var S1t=s(zV);Cnr=r(S1t,"TFDebertaModel"),S1t.forEach(t),wnr=r(mxe," (DeBERTa model)"),mxe.forEach(t),Anr=i(k),cT=n(k,"LI",{});var gxe=s(cT);gue=n(gxe,"STRONG",{});var R1t=s(gue);ynr=r(R1t,"deberta-v2"),R1t.forEach(t),Lnr=r(gxe," \u2014 "),QV=n(gxe,"A",{href:!0});var B1t=s(QV);xnr=r(B1t,"TFDebertaV2Model"),B1t.forEach(t),knr=r(gxe," (DeBERTa-v2 model)"),gxe.forEach(t),Snr=i(k),fT=n(k,"LI",{});var hxe=s(fT);hue=n(hxe,"STRONG",{});var P1t=s(hue);Rnr=r(P1t,"distilbert"),P1t.forEach(t),Bnr=r(hxe," \u2014 "),WV=n(hxe,"A",{href:!0});var $1t=s(WV);Pnr=r($1t,"TFDistilBertModel"),$1t.forEach(t),$nr=r(hxe," (DistilBERT model)"),hxe.forEach(t),Inr=i(k),mT=n(k,"LI",{});var pxe=s(mT);pue=n(pxe,"STRONG",{});var I1t=s(pue);qnr=r(I1t,"dpr"),I1t.forEach(t),Nnr=r(pxe," \u2014 "),HV=n(pxe,"A",{href:!0});var q1t=s(HV);jnr=r(q1t,"TFDPRQuestionEncoder"),q1t.forEach(t),Dnr=r(pxe," (DPR model)"),pxe.forEach(t),Gnr=i(k),gT=n(k,"LI",{});var _xe=s(gT);_ue=n(_xe,"STRONG",{});var N1t=s(_ue);Onr=r(N1t,"electra"),N1t.forEach(t),Vnr=r(_xe," \u2014 "),UV=n(_xe,"A",{href:!0});var j1t=s(UV);Xnr=r(j1t,"TFElectraModel"),j1t.forEach(t),znr=r(_xe," (ELECTRA model)"),_xe.forEach(t),Qnr=i(k),hT=n(k,"LI",{});var uxe=s(hT);uue=n(uxe,"STRONG",{});var D1t=s(uue);Wnr=r(D1t,"flaubert"),D1t.forEach(t),Hnr=r(uxe," \u2014 "),JV=n(uxe,"A",{href:!0});var G1t=s(JV);Unr=r(G1t,"TFFlaubertModel"),G1t.forEach(t),Jnr=r(uxe," (FlauBERT model)"),uxe.forEach(t),Ynr=i(k),Ys=n(k,"LI",{});var Z8=s(Ys);bue=n(Z8,"STRONG",{});var O1t=s(bue);Knr=r(O1t,"funnel"),O1t.forEach(t),Znr=r(Z8," \u2014 "),YV=n(Z8,"A",{href:!0});var V1t=s(YV);esr=r(V1t,"TFFunnelModel"),V1t.forEach(t),osr=r(Z8," or "),KV=n(Z8,"A",{href:!0});var X1t=s(KV);rsr=r(X1t,"TFFunnelBaseModel"),X1t.forEach(t),tsr=r(Z8," (Funnel Transformer model)"),Z8.forEach(t),asr=i(k),pT=n(k,"LI",{});var bxe=s(pT);vue=n(bxe,"STRONG",{});var z1t=s(vue);nsr=r(z1t,"gpt2"),z1t.forEach(t),ssr=r(bxe," \u2014 "),ZV=n(bxe,"A",{href:!0});var Q1t=s(ZV);lsr=r(Q1t,"TFGPT2Model"),Q1t.forEach(t),isr=r(bxe," (OpenAI GPT-2 model)"),bxe.forEach(t),dsr=i(k),_T=n(k,"LI",{});var vxe=s(_T);Fue=n(vxe,"STRONG",{});var W1t=s(Fue);csr=r(W1t,"gptj"),W1t.forEach(t),fsr=r(vxe," \u2014 "),eX=n(vxe,"A",{href:!0});var H1t=s(eX);msr=r(H1t,"TFGPTJModel"),H1t.forEach(t),gsr=r(vxe," (GPT-J model)"),vxe.forEach(t),hsr=i(k),uT=n(k,"LI",{});var Fxe=s(uT);Tue=n(Fxe,"STRONG",{});var U1t=s(Tue);psr=r(U1t,"hubert"),U1t.forEach(t),_sr=r(Fxe," \u2014 "),oX=n(Fxe,"A",{href:!0});var J1t=s(oX);usr=r(J1t,"TFHubertModel"),J1t.forEach(t),bsr=r(Fxe," (Hubert model)"),Fxe.forEach(t),vsr=i(k),bT=n(k,"LI",{});var Txe=s(bT);Mue=n(Txe,"STRONG",{});var Y1t=s(Mue);Fsr=r(Y1t,"layoutlm"),Y1t.forEach(t),Tsr=r(Txe," \u2014 "),rX=n(Txe,"A",{href:!0});var K1t=s(rX);Msr=r(K1t,"TFLayoutLMModel"),K1t.forEach(t),Esr=r(Txe," (LayoutLM model)"),Txe.forEach(t),Csr=i(k),vT=n(k,"LI",{});var Mxe=s(vT);Eue=n(Mxe,"STRONG",{});var Z1t=s(Eue);wsr=r(Z1t,"led"),Z1t.forEach(t),Asr=r(Mxe," \u2014 "),tX=n(Mxe,"A",{href:!0});var ebt=s(tX);ysr=r(ebt,"TFLEDModel"),ebt.forEach(t),Lsr=r(Mxe," (LED model)"),Mxe.forEach(t),xsr=i(k),FT=n(k,"LI",{});var Exe=s(FT);Cue=n(Exe,"STRONG",{});var obt=s(Cue);ksr=r(obt,"longformer"),obt.forEach(t),Ssr=r(Exe," \u2014 "),aX=n(Exe,"A",{href:!0});var rbt=s(aX);Rsr=r(rbt,"TFLongformerModel"),rbt.forEach(t),Bsr=r(Exe," (Longformer model)"),Exe.forEach(t),Psr=i(k),TT=n(k,"LI",{});var Cxe=s(TT);wue=n(Cxe,"STRONG",{});var tbt=s(wue);$sr=r(tbt,"lxmert"),tbt.forEach(t),Isr=r(Cxe," \u2014 "),nX=n(Cxe,"A",{href:!0});var abt=s(nX);qsr=r(abt,"TFLxmertModel"),abt.forEach(t),Nsr=r(Cxe," (LXMERT model)"),Cxe.forEach(t),jsr=i(k),MT=n(k,"LI",{});var wxe=s(MT);Aue=n(wxe,"STRONG",{});var nbt=s(Aue);Dsr=r(nbt,"marian"),nbt.forEach(t),Gsr=r(wxe," \u2014 "),sX=n(wxe,"A",{href:!0});var sbt=s(sX);Osr=r(sbt,"TFMarianModel"),sbt.forEach(t),Vsr=r(wxe," (Marian model)"),wxe.forEach(t),Xsr=i(k),ET=n(k,"LI",{});var Axe=s(ET);yue=n(Axe,"STRONG",{});var lbt=s(yue);zsr=r(lbt,"mbart"),lbt.forEach(t),Qsr=r(Axe," \u2014 "),lX=n(Axe,"A",{href:!0});var ibt=s(lX);Wsr=r(ibt,"TFMBartModel"),ibt.forEach(t),Hsr=r(Axe," (mBART model)"),Axe.forEach(t),Usr=i(k),CT=n(k,"LI",{});var yxe=s(CT);Lue=n(yxe,"STRONG",{});var dbt=s(Lue);Jsr=r(dbt,"mobilebert"),dbt.forEach(t),Ysr=r(yxe," \u2014 "),iX=n(yxe,"A",{href:!0});var cbt=s(iX);Ksr=r(cbt,"TFMobileBertModel"),cbt.forEach(t),Zsr=r(yxe," (MobileBERT model)"),yxe.forEach(t),elr=i(k),wT=n(k,"LI",{});var Lxe=s(wT);xue=n(Lxe,"STRONG",{});var fbt=s(xue);olr=r(fbt,"mpnet"),fbt.forEach(t),rlr=r(Lxe," \u2014 "),dX=n(Lxe,"A",{href:!0});var mbt=s(dX);tlr=r(mbt,"TFMPNetModel"),mbt.forEach(t),alr=r(Lxe," (MPNet model)"),Lxe.forEach(t),nlr=i(k),AT=n(k,"LI",{});var xxe=s(AT);kue=n(xxe,"STRONG",{});var gbt=s(kue);slr=r(gbt,"mt5"),gbt.forEach(t),llr=r(xxe," \u2014 "),cX=n(xxe,"A",{href:!0});var hbt=s(cX);ilr=r(hbt,"TFMT5Model"),hbt.forEach(t),dlr=r(xxe," (mT5 model)"),xxe.forEach(t),clr=i(k),yT=n(k,"LI",{});var kxe=s(yT);Sue=n(kxe,"STRONG",{});var pbt=s(Sue);flr=r(pbt,"openai-gpt"),pbt.forEach(t),mlr=r(kxe," \u2014 "),fX=n(kxe,"A",{href:!0});var _bt=s(fX);glr=r(_bt,"TFOpenAIGPTModel"),_bt.forEach(t),hlr=r(kxe," (OpenAI GPT model)"),kxe.forEach(t),plr=i(k),LT=n(k,"LI",{});var Sxe=s(LT);Rue=n(Sxe,"STRONG",{});var ubt=s(Rue);_lr=r(ubt,"pegasus"),ubt.forEach(t),ulr=r(Sxe," \u2014 "),mX=n(Sxe,"A",{href:!0});var bbt=s(mX);blr=r(bbt,"TFPegasusModel"),bbt.forEach(t),vlr=r(Sxe," (Pegasus model)"),Sxe.forEach(t),Flr=i(k),xT=n(k,"LI",{});var Rxe=s(xT);Bue=n(Rxe,"STRONG",{});var vbt=s(Bue);Tlr=r(vbt,"rembert"),vbt.forEach(t),Mlr=r(Rxe," \u2014 "),gX=n(Rxe,"A",{href:!0});var Fbt=s(gX);Elr=r(Fbt,"TFRemBertModel"),Fbt.forEach(t),Clr=r(Rxe," (RemBERT model)"),Rxe.forEach(t),wlr=i(k),kT=n(k,"LI",{});var Bxe=s(kT);Pue=n(Bxe,"STRONG",{});var Tbt=s(Pue);Alr=r(Tbt,"roberta"),Tbt.forEach(t),ylr=r(Bxe," \u2014 "),hX=n(Bxe,"A",{href:!0});var Mbt=s(hX);Llr=r(Mbt,"TFRobertaModel"),Mbt.forEach(t),xlr=r(Bxe," (RoBERTa model)"),Bxe.forEach(t),klr=i(k),ST=n(k,"LI",{});var Pxe=s(ST);$ue=n(Pxe,"STRONG",{});var Ebt=s($ue);Slr=r(Ebt,"roformer"),Ebt.forEach(t),Rlr=r(Pxe," \u2014 "),pX=n(Pxe,"A",{href:!0});var Cbt=s(pX);Blr=r(Cbt,"TFRoFormerModel"),Cbt.forEach(t),Plr=r(Pxe," (RoFormer model)"),Pxe.forEach(t),$lr=i(k),RT=n(k,"LI",{});var $xe=s(RT);Iue=n($xe,"STRONG",{});var wbt=s(Iue);Ilr=r(wbt,"speech_to_text"),wbt.forEach(t),qlr=r($xe," \u2014 "),_X=n($xe,"A",{href:!0});var Abt=s(_X);Nlr=r(Abt,"TFSpeech2TextModel"),Abt.forEach(t),jlr=r($xe," (Speech2Text model)"),$xe.forEach(t),Dlr=i(k),BT=n(k,"LI",{});var Ixe=s(BT);que=n(Ixe,"STRONG",{});var ybt=s(que);Glr=r(ybt,"t5"),ybt.forEach(t),Olr=r(Ixe," \u2014 "),uX=n(Ixe,"A",{href:!0});var Lbt=s(uX);Vlr=r(Lbt,"TFT5Model"),Lbt.forEach(t),Xlr=r(Ixe," (T5 model)"),Ixe.forEach(t),zlr=i(k),PT=n(k,"LI",{});var qxe=s(PT);Nue=n(qxe,"STRONG",{});var xbt=s(Nue);Qlr=r(xbt,"tapas"),xbt.forEach(t),Wlr=r(qxe," \u2014 "),bX=n(qxe,"A",{href:!0});var kbt=s(bX);Hlr=r(kbt,"TFTapasModel"),kbt.forEach(t),Ulr=r(qxe," (TAPAS model)"),qxe.forEach(t),Jlr=i(k),$T=n(k,"LI",{});var Nxe=s($T);jue=n(Nxe,"STRONG",{});var Sbt=s(jue);Ylr=r(Sbt,"transfo-xl"),Sbt.forEach(t),Klr=r(Nxe," \u2014 "),vX=n(Nxe,"A",{href:!0});var Rbt=s(vX);Zlr=r(Rbt,"TFTransfoXLModel"),Rbt.forEach(t),eir=r(Nxe," (Transformer-XL model)"),Nxe.forEach(t),oir=i(k),IT=n(k,"LI",{});var jxe=s(IT);Due=n(jxe,"STRONG",{});var Bbt=s(Due);rir=r(Bbt,"vit"),Bbt.forEach(t),tir=r(jxe," \u2014 "),FX=n(jxe,"A",{href:!0});var Pbt=s(FX);air=r(Pbt,"TFViTModel"),Pbt.forEach(t),nir=r(jxe," (ViT model)"),jxe.forEach(t),sir=i(k),qT=n(k,"LI",{});var Dxe=s(qT);Gue=n(Dxe,"STRONG",{});var $bt=s(Gue);lir=r($bt,"vit_mae"),$bt.forEach(t),iir=r(Dxe," \u2014 "),TX=n(Dxe,"A",{href:!0});var Ibt=s(TX);dir=r(Ibt,"TFViTMAEModel"),Ibt.forEach(t),cir=r(Dxe," (ViTMAE model)"),Dxe.forEach(t),fir=i(k),NT=n(k,"LI",{});var Gxe=s(NT);Oue=n(Gxe,"STRONG",{});var qbt=s(Oue);mir=r(qbt,"wav2vec2"),qbt.forEach(t),gir=r(Gxe," \u2014 "),MX=n(Gxe,"A",{href:!0});var Nbt=s(MX);hir=r(Nbt,"TFWav2Vec2Model"),Nbt.forEach(t),pir=r(Gxe," (Wav2Vec2 model)"),Gxe.forEach(t),_ir=i(k),jT=n(k,"LI",{});var Oxe=s(jT);Vue=n(Oxe,"STRONG",{});var jbt=s(Vue);uir=r(jbt,"xlm"),jbt.forEach(t),bir=r(Oxe," \u2014 "),EX=n(Oxe,"A",{href:!0});var Dbt=s(EX);vir=r(Dbt,"TFXLMModel"),Dbt.forEach(t),Fir=r(Oxe," (XLM model)"),Oxe.forEach(t),Tir=i(k),DT=n(k,"LI",{});var Vxe=s(DT);Xue=n(Vxe,"STRONG",{});var Gbt=s(Xue);Mir=r(Gbt,"xlm-roberta"),Gbt.forEach(t),Eir=r(Vxe," \u2014 "),CX=n(Vxe,"A",{href:!0});var Obt=s(CX);Cir=r(Obt,"TFXLMRobertaModel"),Obt.forEach(t),wir=r(Vxe," (XLM-RoBERTa model)"),Vxe.forEach(t),Air=i(k),GT=n(k,"LI",{});var Xxe=s(GT);zue=n(Xxe,"STRONG",{});var Vbt=s(zue);yir=r(Vbt,"xlnet"),Vbt.forEach(t),Lir=r(Xxe," \u2014 "),wX=n(Xxe,"A",{href:!0});var Xbt=s(wX);xir=r(Xbt,"TFXLNetModel"),Xbt.forEach(t),kir=r(Xxe," (XLNet model)"),Xxe.forEach(t),k.forEach(t),Sir=i(pa),Que=n(pa,"P",{});var zbt=s(Que);Rir=r(zbt,"Examples:"),zbt.forEach(t),Bir=i(pa),m(j0.$$.fragment,pa),pa.forEach(t),Ul.forEach(t),j$e=i(c),wc=n(c,"H2",{class:!0});var Uqe=s(wc);OT=n(Uqe,"A",{id:!0,class:!0,href:!0});var Qbt=s(OT);Wue=n(Qbt,"SPAN",{});var Wbt=s(Wue);m(D0.$$.fragment,Wbt),Wbt.forEach(t),Qbt.forEach(t),Pir=i(Uqe),Hue=n(Uqe,"SPAN",{});var Hbt=s(Hue);$ir=r(Hbt,"TFAutoModelForPreTraining"),Hbt.forEach(t),Uqe.forEach(t),D$e=i(c),Fr=n(c,"DIV",{class:!0});var Yl=s(Fr);m(G0.$$.fragment,Yl),Iir=i(Yl),Ac=n(Yl,"P",{});var xY=s(Ac);qir=r(xY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),AX=n(xY,"A",{href:!0});var Ubt=s(AX);Nir=r(Ubt,"from_pretrained()"),Ubt.forEach(t),jir=r(xY," class method or the "),yX=n(xY,"A",{href:!0});var Jbt=s(yX);Dir=r(Jbt,"from_config()"),Jbt.forEach(t),Gir=r(xY,` class
method.`),xY.forEach(t),Oir=i(Yl),O0=n(Yl,"P",{});var Jqe=s(O0);Vir=r(Jqe,"This class cannot be instantiated directly using "),Uue=n(Jqe,"CODE",{});var Ybt=s(Uue);Xir=r(Ybt,"__init__()"),Ybt.forEach(t),zir=r(Jqe," (throws an error)."),Jqe.forEach(t),Qir=i(Yl),ht=n(Yl,"DIV",{class:!0});var Kl=s(ht);m(V0.$$.fragment,Kl),Wir=i(Kl),Jue=n(Kl,"P",{});var Kbt=s(Jue);Hir=r(Kbt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Kbt.forEach(t),Uir=i(Kl),yc=n(Kl,"P",{});var kY=s(yc);Jir=r(kY,`Note:
Loading a model from its configuration file does `),Yue=n(kY,"STRONG",{});var Zbt=s(Yue);Yir=r(Zbt,"not"),Zbt.forEach(t),Kir=r(kY,` load the model weights. It only affects the
model\u2019s configuration. Use `),LX=n(kY,"A",{href:!0});var e6t=s(LX);Zir=r(e6t,"from_pretrained()"),e6t.forEach(t),edr=r(kY," to load the model weights."),kY.forEach(t),odr=i(Kl),Kue=n(Kl,"P",{});var o6t=s(Kue);rdr=r(o6t,"Examples:"),o6t.forEach(t),tdr=i(Kl),m(X0.$$.fragment,Kl),Kl.forEach(t),adr=i(Yl),_o=n(Yl,"DIV",{class:!0});var _a=s(_o);m(z0.$$.fragment,_a),ndr=i(_a),Zue=n(_a,"P",{});var r6t=s(Zue);sdr=r(r6t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),r6t.forEach(t),ldr=i(_a),bn=n(_a,"P",{});var x5=s(bn);idr=r(x5,"The model class to instantiate is selected based on the "),e2e=n(x5,"CODE",{});var t6t=s(e2e);ddr=r(t6t,"model_type"),t6t.forEach(t),cdr=r(x5,` property of the config object (either
passed as an argument or loaded from `),o2e=n(x5,"CODE",{});var a6t=s(o2e);fdr=r(a6t,"pretrained_model_name_or_path"),a6t.forEach(t),mdr=r(x5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r2e=n(x5,"CODE",{});var n6t=s(r2e);gdr=r(n6t,"pretrained_model_name_or_path"),n6t.forEach(t),hdr=r(x5,":"),x5.forEach(t),pdr=i(_a),U=n(_a,"UL",{});var Y=s(U);VT=n(Y,"LI",{});var zxe=s(VT);t2e=n(zxe,"STRONG",{});var s6t=s(t2e);_dr=r(s6t,"albert"),s6t.forEach(t),udr=r(zxe," \u2014 "),xX=n(zxe,"A",{href:!0});var l6t=s(xX);bdr=r(l6t,"TFAlbertForPreTraining"),l6t.forEach(t),vdr=r(zxe," (ALBERT model)"),zxe.forEach(t),Fdr=i(Y),XT=n(Y,"LI",{});var Qxe=s(XT);a2e=n(Qxe,"STRONG",{});var i6t=s(a2e);Tdr=r(i6t,"bart"),i6t.forEach(t),Mdr=r(Qxe," \u2014 "),kX=n(Qxe,"A",{href:!0});var d6t=s(kX);Edr=r(d6t,"TFBartForConditionalGeneration"),d6t.forEach(t),Cdr=r(Qxe," (BART model)"),Qxe.forEach(t),wdr=i(Y),zT=n(Y,"LI",{});var Wxe=s(zT);n2e=n(Wxe,"STRONG",{});var c6t=s(n2e);Adr=r(c6t,"bert"),c6t.forEach(t),ydr=r(Wxe," \u2014 "),SX=n(Wxe,"A",{href:!0});var f6t=s(SX);Ldr=r(f6t,"TFBertForPreTraining"),f6t.forEach(t),xdr=r(Wxe," (BERT model)"),Wxe.forEach(t),kdr=i(Y),QT=n(Y,"LI",{});var Hxe=s(QT);s2e=n(Hxe,"STRONG",{});var m6t=s(s2e);Sdr=r(m6t,"camembert"),m6t.forEach(t),Rdr=r(Hxe," \u2014 "),RX=n(Hxe,"A",{href:!0});var g6t=s(RX);Bdr=r(g6t,"TFCamembertForMaskedLM"),g6t.forEach(t),Pdr=r(Hxe," (CamemBERT model)"),Hxe.forEach(t),$dr=i(Y),WT=n(Y,"LI",{});var Uxe=s(WT);l2e=n(Uxe,"STRONG",{});var h6t=s(l2e);Idr=r(h6t,"ctrl"),h6t.forEach(t),qdr=r(Uxe," \u2014 "),BX=n(Uxe,"A",{href:!0});var p6t=s(BX);Ndr=r(p6t,"TFCTRLLMHeadModel"),p6t.forEach(t),jdr=r(Uxe," (CTRL model)"),Uxe.forEach(t),Ddr=i(Y),HT=n(Y,"LI",{});var Jxe=s(HT);i2e=n(Jxe,"STRONG",{});var _6t=s(i2e);Gdr=r(_6t,"distilbert"),_6t.forEach(t),Odr=r(Jxe," \u2014 "),PX=n(Jxe,"A",{href:!0});var u6t=s(PX);Vdr=r(u6t,"TFDistilBertForMaskedLM"),u6t.forEach(t),Xdr=r(Jxe," (DistilBERT model)"),Jxe.forEach(t),zdr=i(Y),UT=n(Y,"LI",{});var Yxe=s(UT);d2e=n(Yxe,"STRONG",{});var b6t=s(d2e);Qdr=r(b6t,"electra"),b6t.forEach(t),Wdr=r(Yxe," \u2014 "),$X=n(Yxe,"A",{href:!0});var v6t=s($X);Hdr=r(v6t,"TFElectraForPreTraining"),v6t.forEach(t),Udr=r(Yxe," (ELECTRA model)"),Yxe.forEach(t),Jdr=i(Y),JT=n(Y,"LI",{});var Kxe=s(JT);c2e=n(Kxe,"STRONG",{});var F6t=s(c2e);Ydr=r(F6t,"flaubert"),F6t.forEach(t),Kdr=r(Kxe," \u2014 "),IX=n(Kxe,"A",{href:!0});var T6t=s(IX);Zdr=r(T6t,"TFFlaubertWithLMHeadModel"),T6t.forEach(t),ecr=r(Kxe," (FlauBERT model)"),Kxe.forEach(t),ocr=i(Y),YT=n(Y,"LI",{});var Zxe=s(YT);f2e=n(Zxe,"STRONG",{});var M6t=s(f2e);rcr=r(M6t,"funnel"),M6t.forEach(t),tcr=r(Zxe," \u2014 "),qX=n(Zxe,"A",{href:!0});var E6t=s(qX);acr=r(E6t,"TFFunnelForPreTraining"),E6t.forEach(t),ncr=r(Zxe," (Funnel Transformer model)"),Zxe.forEach(t),scr=i(Y),KT=n(Y,"LI",{});var eke=s(KT);m2e=n(eke,"STRONG",{});var C6t=s(m2e);lcr=r(C6t,"gpt2"),C6t.forEach(t),icr=r(eke," \u2014 "),NX=n(eke,"A",{href:!0});var w6t=s(NX);dcr=r(w6t,"TFGPT2LMHeadModel"),w6t.forEach(t),ccr=r(eke," (OpenAI GPT-2 model)"),eke.forEach(t),fcr=i(Y),ZT=n(Y,"LI",{});var oke=s(ZT);g2e=n(oke,"STRONG",{});var A6t=s(g2e);mcr=r(A6t,"layoutlm"),A6t.forEach(t),gcr=r(oke," \u2014 "),jX=n(oke,"A",{href:!0});var y6t=s(jX);hcr=r(y6t,"TFLayoutLMForMaskedLM"),y6t.forEach(t),pcr=r(oke," (LayoutLM model)"),oke.forEach(t),_cr=i(Y),e7=n(Y,"LI",{});var rke=s(e7);h2e=n(rke,"STRONG",{});var L6t=s(h2e);ucr=r(L6t,"lxmert"),L6t.forEach(t),bcr=r(rke," \u2014 "),DX=n(rke,"A",{href:!0});var x6t=s(DX);vcr=r(x6t,"TFLxmertForPreTraining"),x6t.forEach(t),Fcr=r(rke," (LXMERT model)"),rke.forEach(t),Tcr=i(Y),o7=n(Y,"LI",{});var tke=s(o7);p2e=n(tke,"STRONG",{});var k6t=s(p2e);Mcr=r(k6t,"mobilebert"),k6t.forEach(t),Ecr=r(tke," \u2014 "),GX=n(tke,"A",{href:!0});var S6t=s(GX);Ccr=r(S6t,"TFMobileBertForPreTraining"),S6t.forEach(t),wcr=r(tke," (MobileBERT model)"),tke.forEach(t),Acr=i(Y),r7=n(Y,"LI",{});var ake=s(r7);_2e=n(ake,"STRONG",{});var R6t=s(_2e);ycr=r(R6t,"mpnet"),R6t.forEach(t),Lcr=r(ake," \u2014 "),OX=n(ake,"A",{href:!0});var B6t=s(OX);xcr=r(B6t,"TFMPNetForMaskedLM"),B6t.forEach(t),kcr=r(ake," (MPNet model)"),ake.forEach(t),Scr=i(Y),t7=n(Y,"LI",{});var nke=s(t7);u2e=n(nke,"STRONG",{});var P6t=s(u2e);Rcr=r(P6t,"openai-gpt"),P6t.forEach(t),Bcr=r(nke," \u2014 "),VX=n(nke,"A",{href:!0});var $6t=s(VX);Pcr=r($6t,"TFOpenAIGPTLMHeadModel"),$6t.forEach(t),$cr=r(nke," (OpenAI GPT model)"),nke.forEach(t),Icr=i(Y),a7=n(Y,"LI",{});var ske=s(a7);b2e=n(ske,"STRONG",{});var I6t=s(b2e);qcr=r(I6t,"roberta"),I6t.forEach(t),Ncr=r(ske," \u2014 "),XX=n(ske,"A",{href:!0});var q6t=s(XX);jcr=r(q6t,"TFRobertaForMaskedLM"),q6t.forEach(t),Dcr=r(ske," (RoBERTa model)"),ske.forEach(t),Gcr=i(Y),n7=n(Y,"LI",{});var lke=s(n7);v2e=n(lke,"STRONG",{});var N6t=s(v2e);Ocr=r(N6t,"t5"),N6t.forEach(t),Vcr=r(lke," \u2014 "),zX=n(lke,"A",{href:!0});var j6t=s(zX);Xcr=r(j6t,"TFT5ForConditionalGeneration"),j6t.forEach(t),zcr=r(lke," (T5 model)"),lke.forEach(t),Qcr=i(Y),s7=n(Y,"LI",{});var ike=s(s7);F2e=n(ike,"STRONG",{});var D6t=s(F2e);Wcr=r(D6t,"tapas"),D6t.forEach(t),Hcr=r(ike," \u2014 "),QX=n(ike,"A",{href:!0});var G6t=s(QX);Ucr=r(G6t,"TFTapasForMaskedLM"),G6t.forEach(t),Jcr=r(ike," (TAPAS model)"),ike.forEach(t),Ycr=i(Y),l7=n(Y,"LI",{});var dke=s(l7);T2e=n(dke,"STRONG",{});var O6t=s(T2e);Kcr=r(O6t,"transfo-xl"),O6t.forEach(t),Zcr=r(dke," \u2014 "),WX=n(dke,"A",{href:!0});var V6t=s(WX);efr=r(V6t,"TFTransfoXLLMHeadModel"),V6t.forEach(t),ofr=r(dke," (Transformer-XL model)"),dke.forEach(t),rfr=i(Y),i7=n(Y,"LI",{});var cke=s(i7);M2e=n(cke,"STRONG",{});var X6t=s(M2e);tfr=r(X6t,"vit_mae"),X6t.forEach(t),afr=r(cke," \u2014 "),HX=n(cke,"A",{href:!0});var z6t=s(HX);nfr=r(z6t,"TFViTMAEForPreTraining"),z6t.forEach(t),sfr=r(cke," (ViTMAE model)"),cke.forEach(t),lfr=i(Y),d7=n(Y,"LI",{});var fke=s(d7);E2e=n(fke,"STRONG",{});var Q6t=s(E2e);ifr=r(Q6t,"xlm"),Q6t.forEach(t),dfr=r(fke," \u2014 "),UX=n(fke,"A",{href:!0});var W6t=s(UX);cfr=r(W6t,"TFXLMWithLMHeadModel"),W6t.forEach(t),ffr=r(fke," (XLM model)"),fke.forEach(t),mfr=i(Y),c7=n(Y,"LI",{});var mke=s(c7);C2e=n(mke,"STRONG",{});var H6t=s(C2e);gfr=r(H6t,"xlm-roberta"),H6t.forEach(t),hfr=r(mke," \u2014 "),JX=n(mke,"A",{href:!0});var U6t=s(JX);pfr=r(U6t,"TFXLMRobertaForMaskedLM"),U6t.forEach(t),_fr=r(mke," (XLM-RoBERTa model)"),mke.forEach(t),ufr=i(Y),f7=n(Y,"LI",{});var gke=s(f7);w2e=n(gke,"STRONG",{});var J6t=s(w2e);bfr=r(J6t,"xlnet"),J6t.forEach(t),vfr=r(gke," \u2014 "),YX=n(gke,"A",{href:!0});var Y6t=s(YX);Ffr=r(Y6t,"TFXLNetLMHeadModel"),Y6t.forEach(t),Tfr=r(gke," (XLNet model)"),gke.forEach(t),Y.forEach(t),Mfr=i(_a),A2e=n(_a,"P",{});var K6t=s(A2e);Efr=r(K6t,"Examples:"),K6t.forEach(t),Cfr=i(_a),m(Q0.$$.fragment,_a),_a.forEach(t),Yl.forEach(t),G$e=i(c),Lc=n(c,"H2",{class:!0});var Yqe=s(Lc);m7=n(Yqe,"A",{id:!0,class:!0,href:!0});var Z6t=s(m7);y2e=n(Z6t,"SPAN",{});var evt=s(y2e);m(W0.$$.fragment,evt),evt.forEach(t),Z6t.forEach(t),wfr=i(Yqe),L2e=n(Yqe,"SPAN",{});var ovt=s(L2e);Afr=r(ovt,"TFAutoModelForCausalLM"),ovt.forEach(t),Yqe.forEach(t),O$e=i(c),Tr=n(c,"DIV",{class:!0});var Zl=s(Tr);m(H0.$$.fragment,Zl),yfr=i(Zl),xc=n(Zl,"P",{});var SY=s(xc);Lfr=r(SY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),KX=n(SY,"A",{href:!0});var rvt=s(KX);xfr=r(rvt,"from_pretrained()"),rvt.forEach(t),kfr=r(SY," class method or the "),ZX=n(SY,"A",{href:!0});var tvt=s(ZX);Sfr=r(tvt,"from_config()"),tvt.forEach(t),Rfr=r(SY,` class
method.`),SY.forEach(t),Bfr=i(Zl),U0=n(Zl,"P",{});var Kqe=s(U0);Pfr=r(Kqe,"This class cannot be instantiated directly using "),x2e=n(Kqe,"CODE",{});var avt=s(x2e);$fr=r(avt,"__init__()"),avt.forEach(t),Ifr=r(Kqe," (throws an error)."),Kqe.forEach(t),qfr=i(Zl),pt=n(Zl,"DIV",{class:!0});var ei=s(pt);m(J0.$$.fragment,ei),Nfr=i(ei),k2e=n(ei,"P",{});var nvt=s(k2e);jfr=r(nvt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),nvt.forEach(t),Dfr=i(ei),kc=n(ei,"P",{});var RY=s(kc);Gfr=r(RY,`Note:
Loading a model from its configuration file does `),S2e=n(RY,"STRONG",{});var svt=s(S2e);Ofr=r(svt,"not"),svt.forEach(t),Vfr=r(RY,` load the model weights. It only affects the
model\u2019s configuration. Use `),ez=n(RY,"A",{href:!0});var lvt=s(ez);Xfr=r(lvt,"from_pretrained()"),lvt.forEach(t),zfr=r(RY," to load the model weights."),RY.forEach(t),Qfr=i(ei),R2e=n(ei,"P",{});var ivt=s(R2e);Wfr=r(ivt,"Examples:"),ivt.forEach(t),Hfr=i(ei),m(Y0.$$.fragment,ei),ei.forEach(t),Ufr=i(Zl),uo=n(Zl,"DIV",{class:!0});var ua=s(uo);m(K0.$$.fragment,ua),Jfr=i(ua),B2e=n(ua,"P",{});var dvt=s(B2e);Yfr=r(dvt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),dvt.forEach(t),Kfr=i(ua),vn=n(ua,"P",{});var k5=s(vn);Zfr=r(k5,"The model class to instantiate is selected based on the "),P2e=n(k5,"CODE",{});var cvt=s(P2e);emr=r(cvt,"model_type"),cvt.forEach(t),omr=r(k5,` property of the config object (either
passed as an argument or loaded from `),$2e=n(k5,"CODE",{});var fvt=s($2e);rmr=r(fvt,"pretrained_model_name_or_path"),fvt.forEach(t),tmr=r(k5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I2e=n(k5,"CODE",{});var mvt=s(I2e);amr=r(mvt,"pretrained_model_name_or_path"),mvt.forEach(t),nmr=r(k5,":"),k5.forEach(t),smr=i(ua),he=n(ua,"UL",{});var be=s(he);g7=n(be,"LI",{});var hke=s(g7);q2e=n(hke,"STRONG",{});var gvt=s(q2e);lmr=r(gvt,"bert"),gvt.forEach(t),imr=r(hke," \u2014 "),oz=n(hke,"A",{href:!0});var hvt=s(oz);dmr=r(hvt,"TFBertLMHeadModel"),hvt.forEach(t),cmr=r(hke," (BERT model)"),hke.forEach(t),fmr=i(be),h7=n(be,"LI",{});var pke=s(h7);N2e=n(pke,"STRONG",{});var pvt=s(N2e);mmr=r(pvt,"camembert"),pvt.forEach(t),gmr=r(pke," \u2014 "),rz=n(pke,"A",{href:!0});var _vt=s(rz);hmr=r(_vt,"TFCamembertForCausalLM"),_vt.forEach(t),pmr=r(pke," (CamemBERT model)"),pke.forEach(t),_mr=i(be),p7=n(be,"LI",{});var _ke=s(p7);j2e=n(_ke,"STRONG",{});var uvt=s(j2e);umr=r(uvt,"ctrl"),uvt.forEach(t),bmr=r(_ke," \u2014 "),tz=n(_ke,"A",{href:!0});var bvt=s(tz);vmr=r(bvt,"TFCTRLLMHeadModel"),bvt.forEach(t),Fmr=r(_ke," (CTRL model)"),_ke.forEach(t),Tmr=i(be),_7=n(be,"LI",{});var uke=s(_7);D2e=n(uke,"STRONG",{});var vvt=s(D2e);Mmr=r(vvt,"gpt2"),vvt.forEach(t),Emr=r(uke," \u2014 "),az=n(uke,"A",{href:!0});var Fvt=s(az);Cmr=r(Fvt,"TFGPT2LMHeadModel"),Fvt.forEach(t),wmr=r(uke," (OpenAI GPT-2 model)"),uke.forEach(t),Amr=i(be),u7=n(be,"LI",{});var bke=s(u7);G2e=n(bke,"STRONG",{});var Tvt=s(G2e);ymr=r(Tvt,"gptj"),Tvt.forEach(t),Lmr=r(bke," \u2014 "),nz=n(bke,"A",{href:!0});var Mvt=s(nz);xmr=r(Mvt,"TFGPTJForCausalLM"),Mvt.forEach(t),kmr=r(bke," (GPT-J model)"),bke.forEach(t),Smr=i(be),b7=n(be,"LI",{});var vke=s(b7);O2e=n(vke,"STRONG",{});var Evt=s(O2e);Rmr=r(Evt,"openai-gpt"),Evt.forEach(t),Bmr=r(vke," \u2014 "),sz=n(vke,"A",{href:!0});var Cvt=s(sz);Pmr=r(Cvt,"TFOpenAIGPTLMHeadModel"),Cvt.forEach(t),$mr=r(vke," (OpenAI GPT model)"),vke.forEach(t),Imr=i(be),v7=n(be,"LI",{});var Fke=s(v7);V2e=n(Fke,"STRONG",{});var wvt=s(V2e);qmr=r(wvt,"rembert"),wvt.forEach(t),Nmr=r(Fke," \u2014 "),lz=n(Fke,"A",{href:!0});var Avt=s(lz);jmr=r(Avt,"TFRemBertForCausalLM"),Avt.forEach(t),Dmr=r(Fke," (RemBERT model)"),Fke.forEach(t),Gmr=i(be),F7=n(be,"LI",{});var Tke=s(F7);X2e=n(Tke,"STRONG",{});var yvt=s(X2e);Omr=r(yvt,"roberta"),yvt.forEach(t),Vmr=r(Tke," \u2014 "),iz=n(Tke,"A",{href:!0});var Lvt=s(iz);Xmr=r(Lvt,"TFRobertaForCausalLM"),Lvt.forEach(t),zmr=r(Tke," (RoBERTa model)"),Tke.forEach(t),Qmr=i(be),T7=n(be,"LI",{});var Mke=s(T7);z2e=n(Mke,"STRONG",{});var xvt=s(z2e);Wmr=r(xvt,"roformer"),xvt.forEach(t),Hmr=r(Mke," \u2014 "),dz=n(Mke,"A",{href:!0});var kvt=s(dz);Umr=r(kvt,"TFRoFormerForCausalLM"),kvt.forEach(t),Jmr=r(Mke," (RoFormer model)"),Mke.forEach(t),Ymr=i(be),M7=n(be,"LI",{});var Eke=s(M7);Q2e=n(Eke,"STRONG",{});var Svt=s(Q2e);Kmr=r(Svt,"transfo-xl"),Svt.forEach(t),Zmr=r(Eke," \u2014 "),cz=n(Eke,"A",{href:!0});var Rvt=s(cz);egr=r(Rvt,"TFTransfoXLLMHeadModel"),Rvt.forEach(t),ogr=r(Eke," (Transformer-XL model)"),Eke.forEach(t),rgr=i(be),E7=n(be,"LI",{});var Cke=s(E7);W2e=n(Cke,"STRONG",{});var Bvt=s(W2e);tgr=r(Bvt,"xlm"),Bvt.forEach(t),agr=r(Cke," \u2014 "),fz=n(Cke,"A",{href:!0});var Pvt=s(fz);ngr=r(Pvt,"TFXLMWithLMHeadModel"),Pvt.forEach(t),sgr=r(Cke," (XLM model)"),Cke.forEach(t),lgr=i(be),C7=n(be,"LI",{});var wke=s(C7);H2e=n(wke,"STRONG",{});var $vt=s(H2e);igr=r($vt,"xlnet"),$vt.forEach(t),dgr=r(wke," \u2014 "),mz=n(wke,"A",{href:!0});var Ivt=s(mz);cgr=r(Ivt,"TFXLNetLMHeadModel"),Ivt.forEach(t),fgr=r(wke," (XLNet model)"),wke.forEach(t),be.forEach(t),mgr=i(ua),U2e=n(ua,"P",{});var qvt=s(U2e);ggr=r(qvt,"Examples:"),qvt.forEach(t),hgr=i(ua),m(Z0.$$.fragment,ua),ua.forEach(t),Zl.forEach(t),V$e=i(c),Sc=n(c,"H2",{class:!0});var Zqe=s(Sc);w7=n(Zqe,"A",{id:!0,class:!0,href:!0});var Nvt=s(w7);J2e=n(Nvt,"SPAN",{});var jvt=s(J2e);m(eA.$$.fragment,jvt),jvt.forEach(t),Nvt.forEach(t),pgr=i(Zqe),Y2e=n(Zqe,"SPAN",{});var Dvt=s(Y2e);_gr=r(Dvt,"TFAutoModelForImageClassification"),Dvt.forEach(t),Zqe.forEach(t),X$e=i(c),Mr=n(c,"DIV",{class:!0});var oi=s(Mr);m(oA.$$.fragment,oi),ugr=i(oi),Rc=n(oi,"P",{});var BY=s(Rc);bgr=r(BY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),gz=n(BY,"A",{href:!0});var Gvt=s(gz);vgr=r(Gvt,"from_pretrained()"),Gvt.forEach(t),Fgr=r(BY," class method or the "),hz=n(BY,"A",{href:!0});var Ovt=s(hz);Tgr=r(Ovt,"from_config()"),Ovt.forEach(t),Mgr=r(BY,` class
method.`),BY.forEach(t),Egr=i(oi),rA=n(oi,"P",{});var eNe=s(rA);Cgr=r(eNe,"This class cannot be instantiated directly using "),K2e=n(eNe,"CODE",{});var Vvt=s(K2e);wgr=r(Vvt,"__init__()"),Vvt.forEach(t),Agr=r(eNe," (throws an error)."),eNe.forEach(t),ygr=i(oi),_t=n(oi,"DIV",{class:!0});var ri=s(_t);m(tA.$$.fragment,ri),Lgr=i(ri),Z2e=n(ri,"P",{});var Xvt=s(Z2e);xgr=r(Xvt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Xvt.forEach(t),kgr=i(ri),Bc=n(ri,"P",{});var PY=s(Bc);Sgr=r(PY,`Note:
Loading a model from its configuration file does `),e1e=n(PY,"STRONG",{});var zvt=s(e1e);Rgr=r(zvt,"not"),zvt.forEach(t),Bgr=r(PY,` load the model weights. It only affects the
model\u2019s configuration. Use `),pz=n(PY,"A",{href:!0});var Qvt=s(pz);Pgr=r(Qvt,"from_pretrained()"),Qvt.forEach(t),$gr=r(PY," to load the model weights."),PY.forEach(t),Igr=i(ri),o1e=n(ri,"P",{});var Wvt=s(o1e);qgr=r(Wvt,"Examples:"),Wvt.forEach(t),Ngr=i(ri),m(aA.$$.fragment,ri),ri.forEach(t),jgr=i(oi),bo=n(oi,"DIV",{class:!0});var ba=s(bo);m(nA.$$.fragment,ba),Dgr=i(ba),r1e=n(ba,"P",{});var Hvt=s(r1e);Ggr=r(Hvt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Hvt.forEach(t),Ogr=i(ba),Fn=n(ba,"P",{});var S5=s(Fn);Vgr=r(S5,"The model class to instantiate is selected based on the "),t1e=n(S5,"CODE",{});var Uvt=s(t1e);Xgr=r(Uvt,"model_type"),Uvt.forEach(t),zgr=r(S5,` property of the config object (either
passed as an argument or loaded from `),a1e=n(S5,"CODE",{});var Jvt=s(a1e);Qgr=r(Jvt,"pretrained_model_name_or_path"),Jvt.forEach(t),Wgr=r(S5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n1e=n(S5,"CODE",{});var Yvt=s(n1e);Hgr=r(Yvt,"pretrained_model_name_or_path"),Yvt.forEach(t),Ugr=r(S5,":"),S5.forEach(t),Jgr=i(ba),sA=n(ba,"UL",{});var oNe=s(sA);A7=n(oNe,"LI",{});var Ake=s(A7);s1e=n(Ake,"STRONG",{});var Kvt=s(s1e);Ygr=r(Kvt,"convnext"),Kvt.forEach(t),Kgr=r(Ake," \u2014 "),_z=n(Ake,"A",{href:!0});var Zvt=s(_z);Zgr=r(Zvt,"TFConvNextForImageClassification"),Zvt.forEach(t),ehr=r(Ake," (ConvNext model)"),Ake.forEach(t),ohr=i(oNe),y7=n(oNe,"LI",{});var yke=s(y7);l1e=n(yke,"STRONG",{});var eFt=s(l1e);rhr=r(eFt,"vit"),eFt.forEach(t),thr=r(yke," \u2014 "),uz=n(yke,"A",{href:!0});var oFt=s(uz);ahr=r(oFt,"TFViTForImageClassification"),oFt.forEach(t),nhr=r(yke," (ViT model)"),yke.forEach(t),oNe.forEach(t),shr=i(ba),i1e=n(ba,"P",{});var rFt=s(i1e);lhr=r(rFt,"Examples:"),rFt.forEach(t),ihr=i(ba),m(lA.$$.fragment,ba),ba.forEach(t),oi.forEach(t),z$e=i(c),Pc=n(c,"H2",{class:!0});var rNe=s(Pc);L7=n(rNe,"A",{id:!0,class:!0,href:!0});var tFt=s(L7);d1e=n(tFt,"SPAN",{});var aFt=s(d1e);m(iA.$$.fragment,aFt),aFt.forEach(t),tFt.forEach(t),dhr=i(rNe),c1e=n(rNe,"SPAN",{});var nFt=s(c1e);chr=r(nFt,"TFAutoModelForMaskedLM"),nFt.forEach(t),rNe.forEach(t),Q$e=i(c),Er=n(c,"DIV",{class:!0});var ti=s(Er);m(dA.$$.fragment,ti),fhr=i(ti),$c=n(ti,"P",{});var $Y=s($c);mhr=r($Y,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),bz=n($Y,"A",{href:!0});var sFt=s(bz);ghr=r(sFt,"from_pretrained()"),sFt.forEach(t),hhr=r($Y," class method or the "),vz=n($Y,"A",{href:!0});var lFt=s(vz);phr=r(lFt,"from_config()"),lFt.forEach(t),_hr=r($Y,` class
method.`),$Y.forEach(t),uhr=i(ti),cA=n(ti,"P",{});var tNe=s(cA);bhr=r(tNe,"This class cannot be instantiated directly using "),f1e=n(tNe,"CODE",{});var iFt=s(f1e);vhr=r(iFt,"__init__()"),iFt.forEach(t),Fhr=r(tNe," (throws an error)."),tNe.forEach(t),Thr=i(ti),ut=n(ti,"DIV",{class:!0});var ai=s(ut);m(fA.$$.fragment,ai),Mhr=i(ai),m1e=n(ai,"P",{});var dFt=s(m1e);Ehr=r(dFt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),dFt.forEach(t),Chr=i(ai),Ic=n(ai,"P",{});var IY=s(Ic);whr=r(IY,`Note:
Loading a model from its configuration file does `),g1e=n(IY,"STRONG",{});var cFt=s(g1e);Ahr=r(cFt,"not"),cFt.forEach(t),yhr=r(IY,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fz=n(IY,"A",{href:!0});var fFt=s(Fz);Lhr=r(fFt,"from_pretrained()"),fFt.forEach(t),xhr=r(IY," to load the model weights."),IY.forEach(t),khr=i(ai),h1e=n(ai,"P",{});var mFt=s(h1e);Shr=r(mFt,"Examples:"),mFt.forEach(t),Rhr=i(ai),m(mA.$$.fragment,ai),ai.forEach(t),Bhr=i(ti),vo=n(ti,"DIV",{class:!0});var va=s(vo);m(gA.$$.fragment,va),Phr=i(va),p1e=n(va,"P",{});var gFt=s(p1e);$hr=r(gFt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),gFt.forEach(t),Ihr=i(va),Tn=n(va,"P",{});var R5=s(Tn);qhr=r(R5,"The model class to instantiate is selected based on the "),_1e=n(R5,"CODE",{});var hFt=s(_1e);Nhr=r(hFt,"model_type"),hFt.forEach(t),jhr=r(R5,` property of the config object (either
passed as an argument or loaded from `),u1e=n(R5,"CODE",{});var pFt=s(u1e);Dhr=r(pFt,"pretrained_model_name_or_path"),pFt.forEach(t),Ghr=r(R5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b1e=n(R5,"CODE",{});var _Ft=s(b1e);Ohr=r(_Ft,"pretrained_model_name_or_path"),_Ft.forEach(t),Vhr=r(R5,":"),R5.forEach(t),Xhr=i(va),K=n(va,"UL",{});var re=s(K);x7=n(re,"LI",{});var Lke=s(x7);v1e=n(Lke,"STRONG",{});var uFt=s(v1e);zhr=r(uFt,"albert"),uFt.forEach(t),Qhr=r(Lke," \u2014 "),Tz=n(Lke,"A",{href:!0});var bFt=s(Tz);Whr=r(bFt,"TFAlbertForMaskedLM"),bFt.forEach(t),Hhr=r(Lke," (ALBERT model)"),Lke.forEach(t),Uhr=i(re),k7=n(re,"LI",{});var xke=s(k7);F1e=n(xke,"STRONG",{});var vFt=s(F1e);Jhr=r(vFt,"bert"),vFt.forEach(t),Yhr=r(xke," \u2014 "),Mz=n(xke,"A",{href:!0});var FFt=s(Mz);Khr=r(FFt,"TFBertForMaskedLM"),FFt.forEach(t),Zhr=r(xke," (BERT model)"),xke.forEach(t),epr=i(re),S7=n(re,"LI",{});var kke=s(S7);T1e=n(kke,"STRONG",{});var TFt=s(T1e);opr=r(TFt,"camembert"),TFt.forEach(t),rpr=r(kke," \u2014 "),Ez=n(kke,"A",{href:!0});var MFt=s(Ez);tpr=r(MFt,"TFCamembertForMaskedLM"),MFt.forEach(t),apr=r(kke," (CamemBERT model)"),kke.forEach(t),npr=i(re),R7=n(re,"LI",{});var Ske=s(R7);M1e=n(Ske,"STRONG",{});var EFt=s(M1e);spr=r(EFt,"convbert"),EFt.forEach(t),lpr=r(Ske," \u2014 "),Cz=n(Ske,"A",{href:!0});var CFt=s(Cz);ipr=r(CFt,"TFConvBertForMaskedLM"),CFt.forEach(t),dpr=r(Ske," (ConvBERT model)"),Ske.forEach(t),cpr=i(re),B7=n(re,"LI",{});var Rke=s(B7);E1e=n(Rke,"STRONG",{});var wFt=s(E1e);fpr=r(wFt,"deberta"),wFt.forEach(t),mpr=r(Rke," \u2014 "),wz=n(Rke,"A",{href:!0});var AFt=s(wz);gpr=r(AFt,"TFDebertaForMaskedLM"),AFt.forEach(t),hpr=r(Rke," (DeBERTa model)"),Rke.forEach(t),ppr=i(re),P7=n(re,"LI",{});var Bke=s(P7);C1e=n(Bke,"STRONG",{});var yFt=s(C1e);_pr=r(yFt,"deberta-v2"),yFt.forEach(t),upr=r(Bke," \u2014 "),Az=n(Bke,"A",{href:!0});var LFt=s(Az);bpr=r(LFt,"TFDebertaV2ForMaskedLM"),LFt.forEach(t),vpr=r(Bke," (DeBERTa-v2 model)"),Bke.forEach(t),Fpr=i(re),$7=n(re,"LI",{});var Pke=s($7);w1e=n(Pke,"STRONG",{});var xFt=s(w1e);Tpr=r(xFt,"distilbert"),xFt.forEach(t),Mpr=r(Pke," \u2014 "),yz=n(Pke,"A",{href:!0});var kFt=s(yz);Epr=r(kFt,"TFDistilBertForMaskedLM"),kFt.forEach(t),Cpr=r(Pke," (DistilBERT model)"),Pke.forEach(t),wpr=i(re),I7=n(re,"LI",{});var $ke=s(I7);A1e=n($ke,"STRONG",{});var SFt=s(A1e);Apr=r(SFt,"electra"),SFt.forEach(t),ypr=r($ke," \u2014 "),Lz=n($ke,"A",{href:!0});var RFt=s(Lz);Lpr=r(RFt,"TFElectraForMaskedLM"),RFt.forEach(t),xpr=r($ke," (ELECTRA model)"),$ke.forEach(t),kpr=i(re),q7=n(re,"LI",{});var Ike=s(q7);y1e=n(Ike,"STRONG",{});var BFt=s(y1e);Spr=r(BFt,"flaubert"),BFt.forEach(t),Rpr=r(Ike," \u2014 "),xz=n(Ike,"A",{href:!0});var PFt=s(xz);Bpr=r(PFt,"TFFlaubertWithLMHeadModel"),PFt.forEach(t),Ppr=r(Ike," (FlauBERT model)"),Ike.forEach(t),$pr=i(re),N7=n(re,"LI",{});var qke=s(N7);L1e=n(qke,"STRONG",{});var $Ft=s(L1e);Ipr=r($Ft,"funnel"),$Ft.forEach(t),qpr=r(qke," \u2014 "),kz=n(qke,"A",{href:!0});var IFt=s(kz);Npr=r(IFt,"TFFunnelForMaskedLM"),IFt.forEach(t),jpr=r(qke," (Funnel Transformer model)"),qke.forEach(t),Dpr=i(re),j7=n(re,"LI",{});var Nke=s(j7);x1e=n(Nke,"STRONG",{});var qFt=s(x1e);Gpr=r(qFt,"layoutlm"),qFt.forEach(t),Opr=r(Nke," \u2014 "),Sz=n(Nke,"A",{href:!0});var NFt=s(Sz);Vpr=r(NFt,"TFLayoutLMForMaskedLM"),NFt.forEach(t),Xpr=r(Nke," (LayoutLM model)"),Nke.forEach(t),zpr=i(re),D7=n(re,"LI",{});var jke=s(D7);k1e=n(jke,"STRONG",{});var jFt=s(k1e);Qpr=r(jFt,"longformer"),jFt.forEach(t),Wpr=r(jke," \u2014 "),Rz=n(jke,"A",{href:!0});var DFt=s(Rz);Hpr=r(DFt,"TFLongformerForMaskedLM"),DFt.forEach(t),Upr=r(jke," (Longformer model)"),jke.forEach(t),Jpr=i(re),G7=n(re,"LI",{});var Dke=s(G7);S1e=n(Dke,"STRONG",{});var GFt=s(S1e);Ypr=r(GFt,"mobilebert"),GFt.forEach(t),Kpr=r(Dke," \u2014 "),Bz=n(Dke,"A",{href:!0});var OFt=s(Bz);Zpr=r(OFt,"TFMobileBertForMaskedLM"),OFt.forEach(t),e_r=r(Dke," (MobileBERT model)"),Dke.forEach(t),o_r=i(re),O7=n(re,"LI",{});var Gke=s(O7);R1e=n(Gke,"STRONG",{});var VFt=s(R1e);r_r=r(VFt,"mpnet"),VFt.forEach(t),t_r=r(Gke," \u2014 "),Pz=n(Gke,"A",{href:!0});var XFt=s(Pz);a_r=r(XFt,"TFMPNetForMaskedLM"),XFt.forEach(t),n_r=r(Gke," (MPNet model)"),Gke.forEach(t),s_r=i(re),V7=n(re,"LI",{});var Oke=s(V7);B1e=n(Oke,"STRONG",{});var zFt=s(B1e);l_r=r(zFt,"rembert"),zFt.forEach(t),i_r=r(Oke," \u2014 "),$z=n(Oke,"A",{href:!0});var QFt=s($z);d_r=r(QFt,"TFRemBertForMaskedLM"),QFt.forEach(t),c_r=r(Oke," (RemBERT model)"),Oke.forEach(t),f_r=i(re),X7=n(re,"LI",{});var Vke=s(X7);P1e=n(Vke,"STRONG",{});var WFt=s(P1e);m_r=r(WFt,"roberta"),WFt.forEach(t),g_r=r(Vke," \u2014 "),Iz=n(Vke,"A",{href:!0});var HFt=s(Iz);h_r=r(HFt,"TFRobertaForMaskedLM"),HFt.forEach(t),p_r=r(Vke," (RoBERTa model)"),Vke.forEach(t),__r=i(re),z7=n(re,"LI",{});var Xke=s(z7);$1e=n(Xke,"STRONG",{});var UFt=s($1e);u_r=r(UFt,"roformer"),UFt.forEach(t),b_r=r(Xke," \u2014 "),qz=n(Xke,"A",{href:!0});var JFt=s(qz);v_r=r(JFt,"TFRoFormerForMaskedLM"),JFt.forEach(t),F_r=r(Xke," (RoFormer model)"),Xke.forEach(t),T_r=i(re),Q7=n(re,"LI",{});var zke=s(Q7);I1e=n(zke,"STRONG",{});var YFt=s(I1e);M_r=r(YFt,"tapas"),YFt.forEach(t),E_r=r(zke," \u2014 "),Nz=n(zke,"A",{href:!0});var KFt=s(Nz);C_r=r(KFt,"TFTapasForMaskedLM"),KFt.forEach(t),w_r=r(zke," (TAPAS model)"),zke.forEach(t),A_r=i(re),W7=n(re,"LI",{});var Qke=s(W7);q1e=n(Qke,"STRONG",{});var ZFt=s(q1e);y_r=r(ZFt,"xlm"),ZFt.forEach(t),L_r=r(Qke," \u2014 "),jz=n(Qke,"A",{href:!0});var eTt=s(jz);x_r=r(eTt,"TFXLMWithLMHeadModel"),eTt.forEach(t),k_r=r(Qke," (XLM model)"),Qke.forEach(t),S_r=i(re),H7=n(re,"LI",{});var Wke=s(H7);N1e=n(Wke,"STRONG",{});var oTt=s(N1e);R_r=r(oTt,"xlm-roberta"),oTt.forEach(t),B_r=r(Wke," \u2014 "),Dz=n(Wke,"A",{href:!0});var rTt=s(Dz);P_r=r(rTt,"TFXLMRobertaForMaskedLM"),rTt.forEach(t),$_r=r(Wke," (XLM-RoBERTa model)"),Wke.forEach(t),re.forEach(t),I_r=i(va),j1e=n(va,"P",{});var tTt=s(j1e);q_r=r(tTt,"Examples:"),tTt.forEach(t),N_r=i(va),m(hA.$$.fragment,va),va.forEach(t),ti.forEach(t),W$e=i(c),qc=n(c,"H2",{class:!0});var aNe=s(qc);U7=n(aNe,"A",{id:!0,class:!0,href:!0});var aTt=s(U7);D1e=n(aTt,"SPAN",{});var nTt=s(D1e);m(pA.$$.fragment,nTt),nTt.forEach(t),aTt.forEach(t),j_r=i(aNe),G1e=n(aNe,"SPAN",{});var sTt=s(G1e);D_r=r(sTt,"TFAutoModelForSeq2SeqLM"),sTt.forEach(t),aNe.forEach(t),H$e=i(c),Cr=n(c,"DIV",{class:!0});var ni=s(Cr);m(_A.$$.fragment,ni),G_r=i(ni),Nc=n(ni,"P",{});var qY=s(Nc);O_r=r(qY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Gz=n(qY,"A",{href:!0});var lTt=s(Gz);V_r=r(lTt,"from_pretrained()"),lTt.forEach(t),X_r=r(qY," class method or the "),Oz=n(qY,"A",{href:!0});var iTt=s(Oz);z_r=r(iTt,"from_config()"),iTt.forEach(t),Q_r=r(qY,` class
method.`),qY.forEach(t),W_r=i(ni),uA=n(ni,"P",{});var nNe=s(uA);H_r=r(nNe,"This class cannot be instantiated directly using "),O1e=n(nNe,"CODE",{});var dTt=s(O1e);U_r=r(dTt,"__init__()"),dTt.forEach(t),J_r=r(nNe," (throws an error)."),nNe.forEach(t),Y_r=i(ni),bt=n(ni,"DIV",{class:!0});var si=s(bt);m(bA.$$.fragment,si),K_r=i(si),V1e=n(si,"P",{});var cTt=s(V1e);Z_r=r(cTt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),cTt.forEach(t),eur=i(si),jc=n(si,"P",{});var NY=s(jc);our=r(NY,`Note:
Loading a model from its configuration file does `),X1e=n(NY,"STRONG",{});var fTt=s(X1e);rur=r(fTt,"not"),fTt.forEach(t),tur=r(NY,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vz=n(NY,"A",{href:!0});var mTt=s(Vz);aur=r(mTt,"from_pretrained()"),mTt.forEach(t),nur=r(NY," to load the model weights."),NY.forEach(t),sur=i(si),z1e=n(si,"P",{});var gTt=s(z1e);lur=r(gTt,"Examples:"),gTt.forEach(t),iur=i(si),m(vA.$$.fragment,si),si.forEach(t),dur=i(ni),Fo=n(ni,"DIV",{class:!0});var Fa=s(Fo);m(FA.$$.fragment,Fa),cur=i(Fa),Q1e=n(Fa,"P",{});var hTt=s(Q1e);fur=r(hTt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),hTt.forEach(t),mur=i(Fa),Mn=n(Fa,"P",{});var B5=s(Mn);gur=r(B5,"The model class to instantiate is selected based on the "),W1e=n(B5,"CODE",{});var pTt=s(W1e);hur=r(pTt,"model_type"),pTt.forEach(t),pur=r(B5,` property of the config object (either
passed as an argument or loaded from `),H1e=n(B5,"CODE",{});var _Tt=s(H1e);_ur=r(_Tt,"pretrained_model_name_or_path"),_Tt.forEach(t),uur=r(B5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),U1e=n(B5,"CODE",{});var uTt=s(U1e);bur=r(uTt,"pretrained_model_name_or_path"),uTt.forEach(t),vur=r(B5,":"),B5.forEach(t),Fur=i(Fa),Fe=n(Fa,"UL",{});var ye=s(Fe);J7=n(ye,"LI",{});var Hke=s(J7);J1e=n(Hke,"STRONG",{});var bTt=s(J1e);Tur=r(bTt,"bart"),bTt.forEach(t),Mur=r(Hke," \u2014 "),Xz=n(Hke,"A",{href:!0});var vTt=s(Xz);Eur=r(vTt,"TFBartForConditionalGeneration"),vTt.forEach(t),Cur=r(Hke," (BART model)"),Hke.forEach(t),wur=i(ye),Y7=n(ye,"LI",{});var Uke=s(Y7);Y1e=n(Uke,"STRONG",{});var FTt=s(Y1e);Aur=r(FTt,"blenderbot"),FTt.forEach(t),yur=r(Uke," \u2014 "),zz=n(Uke,"A",{href:!0});var TTt=s(zz);Lur=r(TTt,"TFBlenderbotForConditionalGeneration"),TTt.forEach(t),xur=r(Uke," (Blenderbot model)"),Uke.forEach(t),kur=i(ye),K7=n(ye,"LI",{});var Jke=s(K7);K1e=n(Jke,"STRONG",{});var MTt=s(K1e);Sur=r(MTt,"blenderbot-small"),MTt.forEach(t),Rur=r(Jke," \u2014 "),Qz=n(Jke,"A",{href:!0});var ETt=s(Qz);Bur=r(ETt,"TFBlenderbotSmallForConditionalGeneration"),ETt.forEach(t),Pur=r(Jke," (BlenderbotSmall model)"),Jke.forEach(t),$ur=i(ye),Z7=n(ye,"LI",{});var Yke=s(Z7);Z1e=n(Yke,"STRONG",{});var CTt=s(Z1e);Iur=r(CTt,"encoder-decoder"),CTt.forEach(t),qur=r(Yke," \u2014 "),Wz=n(Yke,"A",{href:!0});var wTt=s(Wz);Nur=r(wTt,"TFEncoderDecoderModel"),wTt.forEach(t),jur=r(Yke," (Encoder decoder model)"),Yke.forEach(t),Dur=i(ye),e9=n(ye,"LI",{});var Kke=s(e9);ebe=n(Kke,"STRONG",{});var ATt=s(ebe);Gur=r(ATt,"led"),ATt.forEach(t),Our=r(Kke," \u2014 "),Hz=n(Kke,"A",{href:!0});var yTt=s(Hz);Vur=r(yTt,"TFLEDForConditionalGeneration"),yTt.forEach(t),Xur=r(Kke," (LED model)"),Kke.forEach(t),zur=i(ye),o9=n(ye,"LI",{});var Zke=s(o9);obe=n(Zke,"STRONG",{});var LTt=s(obe);Qur=r(LTt,"marian"),LTt.forEach(t),Wur=r(Zke," \u2014 "),Uz=n(Zke,"A",{href:!0});var xTt=s(Uz);Hur=r(xTt,"TFMarianMTModel"),xTt.forEach(t),Uur=r(Zke," (Marian model)"),Zke.forEach(t),Jur=i(ye),r9=n(ye,"LI",{});var eSe=s(r9);rbe=n(eSe,"STRONG",{});var kTt=s(rbe);Yur=r(kTt,"mbart"),kTt.forEach(t),Kur=r(eSe," \u2014 "),Jz=n(eSe,"A",{href:!0});var STt=s(Jz);Zur=r(STt,"TFMBartForConditionalGeneration"),STt.forEach(t),e2r=r(eSe," (mBART model)"),eSe.forEach(t),o2r=i(ye),t9=n(ye,"LI",{});var oSe=s(t9);tbe=n(oSe,"STRONG",{});var RTt=s(tbe);r2r=r(RTt,"mt5"),RTt.forEach(t),t2r=r(oSe," \u2014 "),Yz=n(oSe,"A",{href:!0});var BTt=s(Yz);a2r=r(BTt,"TFMT5ForConditionalGeneration"),BTt.forEach(t),n2r=r(oSe," (mT5 model)"),oSe.forEach(t),s2r=i(ye),a9=n(ye,"LI",{});var rSe=s(a9);abe=n(rSe,"STRONG",{});var PTt=s(abe);l2r=r(PTt,"pegasus"),PTt.forEach(t),i2r=r(rSe," \u2014 "),Kz=n(rSe,"A",{href:!0});var $Tt=s(Kz);d2r=r($Tt,"TFPegasusForConditionalGeneration"),$Tt.forEach(t),c2r=r(rSe," (Pegasus model)"),rSe.forEach(t),f2r=i(ye),n9=n(ye,"LI",{});var tSe=s(n9);nbe=n(tSe,"STRONG",{});var ITt=s(nbe);m2r=r(ITt,"t5"),ITt.forEach(t),g2r=r(tSe," \u2014 "),Zz=n(tSe,"A",{href:!0});var qTt=s(Zz);h2r=r(qTt,"TFT5ForConditionalGeneration"),qTt.forEach(t),p2r=r(tSe," (T5 model)"),tSe.forEach(t),ye.forEach(t),_2r=i(Fa),sbe=n(Fa,"P",{});var NTt=s(sbe);u2r=r(NTt,"Examples:"),NTt.forEach(t),b2r=i(Fa),m(TA.$$.fragment,Fa),Fa.forEach(t),ni.forEach(t),U$e=i(c),Dc=n(c,"H2",{class:!0});var sNe=s(Dc);s9=n(sNe,"A",{id:!0,class:!0,href:!0});var jTt=s(s9);lbe=n(jTt,"SPAN",{});var DTt=s(lbe);m(MA.$$.fragment,DTt),DTt.forEach(t),jTt.forEach(t),v2r=i(sNe),ibe=n(sNe,"SPAN",{});var GTt=s(ibe);F2r=r(GTt,"TFAutoModelForSequenceClassification"),GTt.forEach(t),sNe.forEach(t),J$e=i(c),wr=n(c,"DIV",{class:!0});var li=s(wr);m(EA.$$.fragment,li),T2r=i(li),Gc=n(li,"P",{});var jY=s(Gc);M2r=r(jY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),eQ=n(jY,"A",{href:!0});var OTt=s(eQ);E2r=r(OTt,"from_pretrained()"),OTt.forEach(t),C2r=r(jY," class method or the "),oQ=n(jY,"A",{href:!0});var VTt=s(oQ);w2r=r(VTt,"from_config()"),VTt.forEach(t),A2r=r(jY,` class
method.`),jY.forEach(t),y2r=i(li),CA=n(li,"P",{});var lNe=s(CA);L2r=r(lNe,"This class cannot be instantiated directly using "),dbe=n(lNe,"CODE",{});var XTt=s(dbe);x2r=r(XTt,"__init__()"),XTt.forEach(t),k2r=r(lNe," (throws an error)."),lNe.forEach(t),S2r=i(li),vt=n(li,"DIV",{class:!0});var ii=s(vt);m(wA.$$.fragment,ii),R2r=i(ii),cbe=n(ii,"P",{});var zTt=s(cbe);B2r=r(zTt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),zTt.forEach(t),P2r=i(ii),Oc=n(ii,"P",{});var DY=s(Oc);$2r=r(DY,`Note:
Loading a model from its configuration file does `),fbe=n(DY,"STRONG",{});var QTt=s(fbe);I2r=r(QTt,"not"),QTt.forEach(t),q2r=r(DY,` load the model weights. It only affects the
model\u2019s configuration. Use `),rQ=n(DY,"A",{href:!0});var WTt=s(rQ);N2r=r(WTt,"from_pretrained()"),WTt.forEach(t),j2r=r(DY," to load the model weights."),DY.forEach(t),D2r=i(ii),mbe=n(ii,"P",{});var HTt=s(mbe);G2r=r(HTt,"Examples:"),HTt.forEach(t),O2r=i(ii),m(AA.$$.fragment,ii),ii.forEach(t),V2r=i(li),To=n(li,"DIV",{class:!0});var Ta=s(To);m(yA.$$.fragment,Ta),X2r=i(Ta),gbe=n(Ta,"P",{});var UTt=s(gbe);z2r=r(UTt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),UTt.forEach(t),Q2r=i(Ta),En=n(Ta,"P",{});var P5=s(En);W2r=r(P5,"The model class to instantiate is selected based on the "),hbe=n(P5,"CODE",{});var JTt=s(hbe);H2r=r(JTt,"model_type"),JTt.forEach(t),U2r=r(P5,` property of the config object (either
passed as an argument or loaded from `),pbe=n(P5,"CODE",{});var YTt=s(pbe);J2r=r(YTt,"pretrained_model_name_or_path"),YTt.forEach(t),Y2r=r(P5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_be=n(P5,"CODE",{});var KTt=s(_be);K2r=r(KTt,"pretrained_model_name_or_path"),KTt.forEach(t),Z2r=r(P5,":"),P5.forEach(t),e1r=i(Ta),V=n(Ta,"UL",{});var Q=s(V);l9=n(Q,"LI",{});var aSe=s(l9);ube=n(aSe,"STRONG",{});var ZTt=s(ube);o1r=r(ZTt,"albert"),ZTt.forEach(t),r1r=r(aSe," \u2014 "),tQ=n(aSe,"A",{href:!0});var e7t=s(tQ);t1r=r(e7t,"TFAlbertForSequenceClassification"),e7t.forEach(t),a1r=r(aSe," (ALBERT model)"),aSe.forEach(t),n1r=i(Q),i9=n(Q,"LI",{});var nSe=s(i9);bbe=n(nSe,"STRONG",{});var o7t=s(bbe);s1r=r(o7t,"bert"),o7t.forEach(t),l1r=r(nSe," \u2014 "),aQ=n(nSe,"A",{href:!0});var r7t=s(aQ);i1r=r(r7t,"TFBertForSequenceClassification"),r7t.forEach(t),d1r=r(nSe," (BERT model)"),nSe.forEach(t),c1r=i(Q),d9=n(Q,"LI",{});var sSe=s(d9);vbe=n(sSe,"STRONG",{});var t7t=s(vbe);f1r=r(t7t,"camembert"),t7t.forEach(t),m1r=r(sSe," \u2014 "),nQ=n(sSe,"A",{href:!0});var a7t=s(nQ);g1r=r(a7t,"TFCamembertForSequenceClassification"),a7t.forEach(t),h1r=r(sSe," (CamemBERT model)"),sSe.forEach(t),p1r=i(Q),c9=n(Q,"LI",{});var lSe=s(c9);Fbe=n(lSe,"STRONG",{});var n7t=s(Fbe);_1r=r(n7t,"convbert"),n7t.forEach(t),u1r=r(lSe," \u2014 "),sQ=n(lSe,"A",{href:!0});var s7t=s(sQ);b1r=r(s7t,"TFConvBertForSequenceClassification"),s7t.forEach(t),v1r=r(lSe," (ConvBERT model)"),lSe.forEach(t),F1r=i(Q),f9=n(Q,"LI",{});var iSe=s(f9);Tbe=n(iSe,"STRONG",{});var l7t=s(Tbe);T1r=r(l7t,"ctrl"),l7t.forEach(t),M1r=r(iSe," \u2014 "),lQ=n(iSe,"A",{href:!0});var i7t=s(lQ);E1r=r(i7t,"TFCTRLForSequenceClassification"),i7t.forEach(t),C1r=r(iSe," (CTRL model)"),iSe.forEach(t),w1r=i(Q),m9=n(Q,"LI",{});var dSe=s(m9);Mbe=n(dSe,"STRONG",{});var d7t=s(Mbe);A1r=r(d7t,"deberta"),d7t.forEach(t),y1r=r(dSe," \u2014 "),iQ=n(dSe,"A",{href:!0});var c7t=s(iQ);L1r=r(c7t,"TFDebertaForSequenceClassification"),c7t.forEach(t),x1r=r(dSe," (DeBERTa model)"),dSe.forEach(t),k1r=i(Q),g9=n(Q,"LI",{});var cSe=s(g9);Ebe=n(cSe,"STRONG",{});var f7t=s(Ebe);S1r=r(f7t,"deberta-v2"),f7t.forEach(t),R1r=r(cSe," \u2014 "),dQ=n(cSe,"A",{href:!0});var m7t=s(dQ);B1r=r(m7t,"TFDebertaV2ForSequenceClassification"),m7t.forEach(t),P1r=r(cSe," (DeBERTa-v2 model)"),cSe.forEach(t),$1r=i(Q),h9=n(Q,"LI",{});var fSe=s(h9);Cbe=n(fSe,"STRONG",{});var g7t=s(Cbe);I1r=r(g7t,"distilbert"),g7t.forEach(t),q1r=r(fSe," \u2014 "),cQ=n(fSe,"A",{href:!0});var h7t=s(cQ);N1r=r(h7t,"TFDistilBertForSequenceClassification"),h7t.forEach(t),j1r=r(fSe," (DistilBERT model)"),fSe.forEach(t),D1r=i(Q),p9=n(Q,"LI",{});var mSe=s(p9);wbe=n(mSe,"STRONG",{});var p7t=s(wbe);G1r=r(p7t,"electra"),p7t.forEach(t),O1r=r(mSe," \u2014 "),fQ=n(mSe,"A",{href:!0});var _7t=s(fQ);V1r=r(_7t,"TFElectraForSequenceClassification"),_7t.forEach(t),X1r=r(mSe," (ELECTRA model)"),mSe.forEach(t),z1r=i(Q),_9=n(Q,"LI",{});var gSe=s(_9);Abe=n(gSe,"STRONG",{});var u7t=s(Abe);Q1r=r(u7t,"flaubert"),u7t.forEach(t),W1r=r(gSe," \u2014 "),mQ=n(gSe,"A",{href:!0});var b7t=s(mQ);H1r=r(b7t,"TFFlaubertForSequenceClassification"),b7t.forEach(t),U1r=r(gSe," (FlauBERT model)"),gSe.forEach(t),J1r=i(Q),u9=n(Q,"LI",{});var hSe=s(u9);ybe=n(hSe,"STRONG",{});var v7t=s(ybe);Y1r=r(v7t,"funnel"),v7t.forEach(t),K1r=r(hSe," \u2014 "),gQ=n(hSe,"A",{href:!0});var F7t=s(gQ);Z1r=r(F7t,"TFFunnelForSequenceClassification"),F7t.forEach(t),ebr=r(hSe," (Funnel Transformer model)"),hSe.forEach(t),obr=i(Q),b9=n(Q,"LI",{});var pSe=s(b9);Lbe=n(pSe,"STRONG",{});var T7t=s(Lbe);rbr=r(T7t,"gpt2"),T7t.forEach(t),tbr=r(pSe," \u2014 "),hQ=n(pSe,"A",{href:!0});var M7t=s(hQ);abr=r(M7t,"TFGPT2ForSequenceClassification"),M7t.forEach(t),nbr=r(pSe," (OpenAI GPT-2 model)"),pSe.forEach(t),sbr=i(Q),v9=n(Q,"LI",{});var _Se=s(v9);xbe=n(_Se,"STRONG",{});var E7t=s(xbe);lbr=r(E7t,"gptj"),E7t.forEach(t),ibr=r(_Se," \u2014 "),pQ=n(_Se,"A",{href:!0});var C7t=s(pQ);dbr=r(C7t,"TFGPTJForSequenceClassification"),C7t.forEach(t),cbr=r(_Se," (GPT-J model)"),_Se.forEach(t),fbr=i(Q),F9=n(Q,"LI",{});var uSe=s(F9);kbe=n(uSe,"STRONG",{});var w7t=s(kbe);mbr=r(w7t,"layoutlm"),w7t.forEach(t),gbr=r(uSe," \u2014 "),_Q=n(uSe,"A",{href:!0});var A7t=s(_Q);hbr=r(A7t,"TFLayoutLMForSequenceClassification"),A7t.forEach(t),pbr=r(uSe," (LayoutLM model)"),uSe.forEach(t),_br=i(Q),T9=n(Q,"LI",{});var bSe=s(T9);Sbe=n(bSe,"STRONG",{});var y7t=s(Sbe);ubr=r(y7t,"longformer"),y7t.forEach(t),bbr=r(bSe," \u2014 "),uQ=n(bSe,"A",{href:!0});var L7t=s(uQ);vbr=r(L7t,"TFLongformerForSequenceClassification"),L7t.forEach(t),Fbr=r(bSe," (Longformer model)"),bSe.forEach(t),Tbr=i(Q),M9=n(Q,"LI",{});var vSe=s(M9);Rbe=n(vSe,"STRONG",{});var x7t=s(Rbe);Mbr=r(x7t,"mobilebert"),x7t.forEach(t),Ebr=r(vSe," \u2014 "),bQ=n(vSe,"A",{href:!0});var k7t=s(bQ);Cbr=r(k7t,"TFMobileBertForSequenceClassification"),k7t.forEach(t),wbr=r(vSe," (MobileBERT model)"),vSe.forEach(t),Abr=i(Q),E9=n(Q,"LI",{});var FSe=s(E9);Bbe=n(FSe,"STRONG",{});var S7t=s(Bbe);ybr=r(S7t,"mpnet"),S7t.forEach(t),Lbr=r(FSe," \u2014 "),vQ=n(FSe,"A",{href:!0});var R7t=s(vQ);xbr=r(R7t,"TFMPNetForSequenceClassification"),R7t.forEach(t),kbr=r(FSe," (MPNet model)"),FSe.forEach(t),Sbr=i(Q),C9=n(Q,"LI",{});var TSe=s(C9);Pbe=n(TSe,"STRONG",{});var B7t=s(Pbe);Rbr=r(B7t,"openai-gpt"),B7t.forEach(t),Bbr=r(TSe," \u2014 "),FQ=n(TSe,"A",{href:!0});var P7t=s(FQ);Pbr=r(P7t,"TFOpenAIGPTForSequenceClassification"),P7t.forEach(t),$br=r(TSe," (OpenAI GPT model)"),TSe.forEach(t),Ibr=i(Q),w9=n(Q,"LI",{});var MSe=s(w9);$be=n(MSe,"STRONG",{});var $7t=s($be);qbr=r($7t,"rembert"),$7t.forEach(t),Nbr=r(MSe," \u2014 "),TQ=n(MSe,"A",{href:!0});var I7t=s(TQ);jbr=r(I7t,"TFRemBertForSequenceClassification"),I7t.forEach(t),Dbr=r(MSe," (RemBERT model)"),MSe.forEach(t),Gbr=i(Q),A9=n(Q,"LI",{});var ESe=s(A9);Ibe=n(ESe,"STRONG",{});var q7t=s(Ibe);Obr=r(q7t,"roberta"),q7t.forEach(t),Vbr=r(ESe," \u2014 "),MQ=n(ESe,"A",{href:!0});var N7t=s(MQ);Xbr=r(N7t,"TFRobertaForSequenceClassification"),N7t.forEach(t),zbr=r(ESe," (RoBERTa model)"),ESe.forEach(t),Qbr=i(Q),y9=n(Q,"LI",{});var CSe=s(y9);qbe=n(CSe,"STRONG",{});var j7t=s(qbe);Wbr=r(j7t,"roformer"),j7t.forEach(t),Hbr=r(CSe," \u2014 "),EQ=n(CSe,"A",{href:!0});var D7t=s(EQ);Ubr=r(D7t,"TFRoFormerForSequenceClassification"),D7t.forEach(t),Jbr=r(CSe," (RoFormer model)"),CSe.forEach(t),Ybr=i(Q),L9=n(Q,"LI",{});var wSe=s(L9);Nbe=n(wSe,"STRONG",{});var G7t=s(Nbe);Kbr=r(G7t,"tapas"),G7t.forEach(t),Zbr=r(wSe," \u2014 "),CQ=n(wSe,"A",{href:!0});var O7t=s(CQ);e6r=r(O7t,"TFTapasForSequenceClassification"),O7t.forEach(t),o6r=r(wSe," (TAPAS model)"),wSe.forEach(t),r6r=i(Q),x9=n(Q,"LI",{});var ASe=s(x9);jbe=n(ASe,"STRONG",{});var V7t=s(jbe);t6r=r(V7t,"transfo-xl"),V7t.forEach(t),a6r=r(ASe," \u2014 "),wQ=n(ASe,"A",{href:!0});var X7t=s(wQ);n6r=r(X7t,"TFTransfoXLForSequenceClassification"),X7t.forEach(t),s6r=r(ASe," (Transformer-XL model)"),ASe.forEach(t),l6r=i(Q),k9=n(Q,"LI",{});var ySe=s(k9);Dbe=n(ySe,"STRONG",{});var z7t=s(Dbe);i6r=r(z7t,"xlm"),z7t.forEach(t),d6r=r(ySe," \u2014 "),AQ=n(ySe,"A",{href:!0});var Q7t=s(AQ);c6r=r(Q7t,"TFXLMForSequenceClassification"),Q7t.forEach(t),f6r=r(ySe," (XLM model)"),ySe.forEach(t),m6r=i(Q),S9=n(Q,"LI",{});var LSe=s(S9);Gbe=n(LSe,"STRONG",{});var W7t=s(Gbe);g6r=r(W7t,"xlm-roberta"),W7t.forEach(t),h6r=r(LSe," \u2014 "),yQ=n(LSe,"A",{href:!0});var H7t=s(yQ);p6r=r(H7t,"TFXLMRobertaForSequenceClassification"),H7t.forEach(t),_6r=r(LSe," (XLM-RoBERTa model)"),LSe.forEach(t),u6r=i(Q),R9=n(Q,"LI",{});var xSe=s(R9);Obe=n(xSe,"STRONG",{});var U7t=s(Obe);b6r=r(U7t,"xlnet"),U7t.forEach(t),v6r=r(xSe," \u2014 "),LQ=n(xSe,"A",{href:!0});var J7t=s(LQ);F6r=r(J7t,"TFXLNetForSequenceClassification"),J7t.forEach(t),T6r=r(xSe," (XLNet model)"),xSe.forEach(t),Q.forEach(t),M6r=i(Ta),Vbe=n(Ta,"P",{});var Y7t=s(Vbe);E6r=r(Y7t,"Examples:"),Y7t.forEach(t),C6r=i(Ta),m(LA.$$.fragment,Ta),Ta.forEach(t),li.forEach(t),Y$e=i(c),Vc=n(c,"H2",{class:!0});var iNe=s(Vc);B9=n(iNe,"A",{id:!0,class:!0,href:!0});var K7t=s(B9);Xbe=n(K7t,"SPAN",{});var Z7t=s(Xbe);m(xA.$$.fragment,Z7t),Z7t.forEach(t),K7t.forEach(t),w6r=i(iNe),zbe=n(iNe,"SPAN",{});var e9t=s(zbe);A6r=r(e9t,"TFAutoModelForMultipleChoice"),e9t.forEach(t),iNe.forEach(t),K$e=i(c),Ar=n(c,"DIV",{class:!0});var di=s(Ar);m(kA.$$.fragment,di),y6r=i(di),Xc=n(di,"P",{});var GY=s(Xc);L6r=r(GY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),xQ=n(GY,"A",{href:!0});var o9t=s(xQ);x6r=r(o9t,"from_pretrained()"),o9t.forEach(t),k6r=r(GY," class method or the "),kQ=n(GY,"A",{href:!0});var r9t=s(kQ);S6r=r(r9t,"from_config()"),r9t.forEach(t),R6r=r(GY,` class
method.`),GY.forEach(t),B6r=i(di),SA=n(di,"P",{});var dNe=s(SA);P6r=r(dNe,"This class cannot be instantiated directly using "),Qbe=n(dNe,"CODE",{});var t9t=s(Qbe);$6r=r(t9t,"__init__()"),t9t.forEach(t),I6r=r(dNe," (throws an error)."),dNe.forEach(t),q6r=i(di),Ft=n(di,"DIV",{class:!0});var ci=s(Ft);m(RA.$$.fragment,ci),N6r=i(ci),Wbe=n(ci,"P",{});var a9t=s(Wbe);j6r=r(a9t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),a9t.forEach(t),D6r=i(ci),zc=n(ci,"P",{});var OY=s(zc);G6r=r(OY,`Note:
Loading a model from its configuration file does `),Hbe=n(OY,"STRONG",{});var n9t=s(Hbe);O6r=r(n9t,"not"),n9t.forEach(t),V6r=r(OY,` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=n(OY,"A",{href:!0});var s9t=s(SQ);X6r=r(s9t,"from_pretrained()"),s9t.forEach(t),z6r=r(OY," to load the model weights."),OY.forEach(t),Q6r=i(ci),Ube=n(ci,"P",{});var l9t=s(Ube);W6r=r(l9t,"Examples:"),l9t.forEach(t),H6r=i(ci),m(BA.$$.fragment,ci),ci.forEach(t),U6r=i(di),Mo=n(di,"DIV",{class:!0});var Ma=s(Mo);m(PA.$$.fragment,Ma),J6r=i(Ma),Jbe=n(Ma,"P",{});var i9t=s(Jbe);Y6r=r(i9t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),i9t.forEach(t),K6r=i(Ma),Cn=n(Ma,"P",{});var $5=s(Cn);Z6r=r($5,"The model class to instantiate is selected based on the "),Ybe=n($5,"CODE",{});var d9t=s(Ybe);evr=r(d9t,"model_type"),d9t.forEach(t),ovr=r($5,` property of the config object (either
passed as an argument or loaded from `),Kbe=n($5,"CODE",{});var c9t=s(Kbe);rvr=r(c9t,"pretrained_model_name_or_path"),c9t.forEach(t),tvr=r($5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zbe=n($5,"CODE",{});var f9t=s(Zbe);avr=r(f9t,"pretrained_model_name_or_path"),f9t.forEach(t),nvr=r($5,":"),$5.forEach(t),svr=i(Ma),se=n(Ma,"UL",{});var ie=s(se);P9=n(ie,"LI",{});var kSe=s(P9);e6e=n(kSe,"STRONG",{});var m9t=s(e6e);lvr=r(m9t,"albert"),m9t.forEach(t),ivr=r(kSe," \u2014 "),RQ=n(kSe,"A",{href:!0});var g9t=s(RQ);dvr=r(g9t,"TFAlbertForMultipleChoice"),g9t.forEach(t),cvr=r(kSe," (ALBERT model)"),kSe.forEach(t),fvr=i(ie),$9=n(ie,"LI",{});var SSe=s($9);o6e=n(SSe,"STRONG",{});var h9t=s(o6e);mvr=r(h9t,"bert"),h9t.forEach(t),gvr=r(SSe," \u2014 "),BQ=n(SSe,"A",{href:!0});var p9t=s(BQ);hvr=r(p9t,"TFBertForMultipleChoice"),p9t.forEach(t),pvr=r(SSe," (BERT model)"),SSe.forEach(t),_vr=i(ie),I9=n(ie,"LI",{});var RSe=s(I9);r6e=n(RSe,"STRONG",{});var _9t=s(r6e);uvr=r(_9t,"camembert"),_9t.forEach(t),bvr=r(RSe," \u2014 "),PQ=n(RSe,"A",{href:!0});var u9t=s(PQ);vvr=r(u9t,"TFCamembertForMultipleChoice"),u9t.forEach(t),Fvr=r(RSe," (CamemBERT model)"),RSe.forEach(t),Tvr=i(ie),q9=n(ie,"LI",{});var BSe=s(q9);t6e=n(BSe,"STRONG",{});var b9t=s(t6e);Mvr=r(b9t,"convbert"),b9t.forEach(t),Evr=r(BSe," \u2014 "),$Q=n(BSe,"A",{href:!0});var v9t=s($Q);Cvr=r(v9t,"TFConvBertForMultipleChoice"),v9t.forEach(t),wvr=r(BSe," (ConvBERT model)"),BSe.forEach(t),Avr=i(ie),N9=n(ie,"LI",{});var PSe=s(N9);a6e=n(PSe,"STRONG",{});var F9t=s(a6e);yvr=r(F9t,"distilbert"),F9t.forEach(t),Lvr=r(PSe," \u2014 "),IQ=n(PSe,"A",{href:!0});var T9t=s(IQ);xvr=r(T9t,"TFDistilBertForMultipleChoice"),T9t.forEach(t),kvr=r(PSe," (DistilBERT model)"),PSe.forEach(t),Svr=i(ie),j9=n(ie,"LI",{});var $Se=s(j9);n6e=n($Se,"STRONG",{});var M9t=s(n6e);Rvr=r(M9t,"electra"),M9t.forEach(t),Bvr=r($Se," \u2014 "),qQ=n($Se,"A",{href:!0});var E9t=s(qQ);Pvr=r(E9t,"TFElectraForMultipleChoice"),E9t.forEach(t),$vr=r($Se," (ELECTRA model)"),$Se.forEach(t),Ivr=i(ie),D9=n(ie,"LI",{});var ISe=s(D9);s6e=n(ISe,"STRONG",{});var C9t=s(s6e);qvr=r(C9t,"flaubert"),C9t.forEach(t),Nvr=r(ISe," \u2014 "),NQ=n(ISe,"A",{href:!0});var w9t=s(NQ);jvr=r(w9t,"TFFlaubertForMultipleChoice"),w9t.forEach(t),Dvr=r(ISe," (FlauBERT model)"),ISe.forEach(t),Gvr=i(ie),G9=n(ie,"LI",{});var qSe=s(G9);l6e=n(qSe,"STRONG",{});var A9t=s(l6e);Ovr=r(A9t,"funnel"),A9t.forEach(t),Vvr=r(qSe," \u2014 "),jQ=n(qSe,"A",{href:!0});var y9t=s(jQ);Xvr=r(y9t,"TFFunnelForMultipleChoice"),y9t.forEach(t),zvr=r(qSe," (Funnel Transformer model)"),qSe.forEach(t),Qvr=i(ie),O9=n(ie,"LI",{});var NSe=s(O9);i6e=n(NSe,"STRONG",{});var L9t=s(i6e);Wvr=r(L9t,"longformer"),L9t.forEach(t),Hvr=r(NSe," \u2014 "),DQ=n(NSe,"A",{href:!0});var x9t=s(DQ);Uvr=r(x9t,"TFLongformerForMultipleChoice"),x9t.forEach(t),Jvr=r(NSe," (Longformer model)"),NSe.forEach(t),Yvr=i(ie),V9=n(ie,"LI",{});var jSe=s(V9);d6e=n(jSe,"STRONG",{});var k9t=s(d6e);Kvr=r(k9t,"mobilebert"),k9t.forEach(t),Zvr=r(jSe," \u2014 "),GQ=n(jSe,"A",{href:!0});var S9t=s(GQ);eFr=r(S9t,"TFMobileBertForMultipleChoice"),S9t.forEach(t),oFr=r(jSe," (MobileBERT model)"),jSe.forEach(t),rFr=i(ie),X9=n(ie,"LI",{});var DSe=s(X9);c6e=n(DSe,"STRONG",{});var R9t=s(c6e);tFr=r(R9t,"mpnet"),R9t.forEach(t),aFr=r(DSe," \u2014 "),OQ=n(DSe,"A",{href:!0});var B9t=s(OQ);nFr=r(B9t,"TFMPNetForMultipleChoice"),B9t.forEach(t),sFr=r(DSe," (MPNet model)"),DSe.forEach(t),lFr=i(ie),z9=n(ie,"LI",{});var GSe=s(z9);f6e=n(GSe,"STRONG",{});var P9t=s(f6e);iFr=r(P9t,"rembert"),P9t.forEach(t),dFr=r(GSe," \u2014 "),VQ=n(GSe,"A",{href:!0});var $9t=s(VQ);cFr=r($9t,"TFRemBertForMultipleChoice"),$9t.forEach(t),fFr=r(GSe," (RemBERT model)"),GSe.forEach(t),mFr=i(ie),Q9=n(ie,"LI",{});var OSe=s(Q9);m6e=n(OSe,"STRONG",{});var I9t=s(m6e);gFr=r(I9t,"roberta"),I9t.forEach(t),hFr=r(OSe," \u2014 "),XQ=n(OSe,"A",{href:!0});var q9t=s(XQ);pFr=r(q9t,"TFRobertaForMultipleChoice"),q9t.forEach(t),_Fr=r(OSe," (RoBERTa model)"),OSe.forEach(t),uFr=i(ie),W9=n(ie,"LI",{});var VSe=s(W9);g6e=n(VSe,"STRONG",{});var N9t=s(g6e);bFr=r(N9t,"roformer"),N9t.forEach(t),vFr=r(VSe," \u2014 "),zQ=n(VSe,"A",{href:!0});var j9t=s(zQ);FFr=r(j9t,"TFRoFormerForMultipleChoice"),j9t.forEach(t),TFr=r(VSe," (RoFormer model)"),VSe.forEach(t),MFr=i(ie),H9=n(ie,"LI",{});var XSe=s(H9);h6e=n(XSe,"STRONG",{});var D9t=s(h6e);EFr=r(D9t,"xlm"),D9t.forEach(t),CFr=r(XSe," \u2014 "),QQ=n(XSe,"A",{href:!0});var G9t=s(QQ);wFr=r(G9t,"TFXLMForMultipleChoice"),G9t.forEach(t),AFr=r(XSe," (XLM model)"),XSe.forEach(t),yFr=i(ie),U9=n(ie,"LI",{});var zSe=s(U9);p6e=n(zSe,"STRONG",{});var O9t=s(p6e);LFr=r(O9t,"xlm-roberta"),O9t.forEach(t),xFr=r(zSe," \u2014 "),WQ=n(zSe,"A",{href:!0});var V9t=s(WQ);kFr=r(V9t,"TFXLMRobertaForMultipleChoice"),V9t.forEach(t),SFr=r(zSe," (XLM-RoBERTa model)"),zSe.forEach(t),RFr=i(ie),J9=n(ie,"LI",{});var QSe=s(J9);_6e=n(QSe,"STRONG",{});var X9t=s(_6e);BFr=r(X9t,"xlnet"),X9t.forEach(t),PFr=r(QSe," \u2014 "),HQ=n(QSe,"A",{href:!0});var z9t=s(HQ);$Fr=r(z9t,"TFXLNetForMultipleChoice"),z9t.forEach(t),IFr=r(QSe," (XLNet model)"),QSe.forEach(t),ie.forEach(t),qFr=i(Ma),u6e=n(Ma,"P",{});var Q9t=s(u6e);NFr=r(Q9t,"Examples:"),Q9t.forEach(t),jFr=i(Ma),m($A.$$.fragment,Ma),Ma.forEach(t),di.forEach(t),Z$e=i(c),Qc=n(c,"H2",{class:!0});var cNe=s(Qc);Y9=n(cNe,"A",{id:!0,class:!0,href:!0});var W9t=s(Y9);b6e=n(W9t,"SPAN",{});var H9t=s(b6e);m(IA.$$.fragment,H9t),H9t.forEach(t),W9t.forEach(t),DFr=i(cNe),v6e=n(cNe,"SPAN",{});var U9t=s(v6e);GFr=r(U9t,"TFAutoModelForTableQuestionAnswering"),U9t.forEach(t),cNe.forEach(t),eIe=i(c),yr=n(c,"DIV",{class:!0});var fi=s(yr);m(qA.$$.fragment,fi),OFr=i(fi),Wc=n(fi,"P",{});var VY=s(Wc);VFr=r(VY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),UQ=n(VY,"A",{href:!0});var J9t=s(UQ);XFr=r(J9t,"from_pretrained()"),J9t.forEach(t),zFr=r(VY," class method or the "),JQ=n(VY,"A",{href:!0});var Y9t=s(JQ);QFr=r(Y9t,"from_config()"),Y9t.forEach(t),WFr=r(VY,` class
method.`),VY.forEach(t),HFr=i(fi),NA=n(fi,"P",{});var fNe=s(NA);UFr=r(fNe,"This class cannot be instantiated directly using "),F6e=n(fNe,"CODE",{});var K9t=s(F6e);JFr=r(K9t,"__init__()"),K9t.forEach(t),YFr=r(fNe," (throws an error)."),fNe.forEach(t),KFr=i(fi),Tt=n(fi,"DIV",{class:!0});var mi=s(Tt);m(jA.$$.fragment,mi),ZFr=i(mi),T6e=n(mi,"P",{});var Z9t=s(T6e);eTr=r(Z9t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Z9t.forEach(t),oTr=i(mi),Hc=n(mi,"P",{});var XY=s(Hc);rTr=r(XY,`Note:
Loading a model from its configuration file does `),M6e=n(XY,"STRONG",{});var eMt=s(M6e);tTr=r(eMt,"not"),eMt.forEach(t),aTr=r(XY,` load the model weights. It only affects the
model\u2019s configuration. Use `),YQ=n(XY,"A",{href:!0});var oMt=s(YQ);nTr=r(oMt,"from_pretrained()"),oMt.forEach(t),sTr=r(XY," to load the model weights."),XY.forEach(t),lTr=i(mi),E6e=n(mi,"P",{});var rMt=s(E6e);iTr=r(rMt,"Examples:"),rMt.forEach(t),dTr=i(mi),m(DA.$$.fragment,mi),mi.forEach(t),cTr=i(fi),Eo=n(fi,"DIV",{class:!0});var Ea=s(Eo);m(GA.$$.fragment,Ea),fTr=i(Ea),C6e=n(Ea,"P",{});var tMt=s(C6e);mTr=r(tMt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),tMt.forEach(t),gTr=i(Ea),wn=n(Ea,"P",{});var I5=s(wn);hTr=r(I5,"The model class to instantiate is selected based on the "),w6e=n(I5,"CODE",{});var aMt=s(w6e);pTr=r(aMt,"model_type"),aMt.forEach(t),_Tr=r(I5,` property of the config object (either
passed as an argument or loaded from `),A6e=n(I5,"CODE",{});var nMt=s(A6e);uTr=r(nMt,"pretrained_model_name_or_path"),nMt.forEach(t),bTr=r(I5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y6e=n(I5,"CODE",{});var sMt=s(y6e);vTr=r(sMt,"pretrained_model_name_or_path"),sMt.forEach(t),FTr=r(I5,":"),I5.forEach(t),TTr=i(Ea),L6e=n(Ea,"UL",{});var lMt=s(L6e);K9=n(lMt,"LI",{});var WSe=s(K9);x6e=n(WSe,"STRONG",{});var iMt=s(x6e);MTr=r(iMt,"tapas"),iMt.forEach(t),ETr=r(WSe," \u2014 "),KQ=n(WSe,"A",{href:!0});var dMt=s(KQ);CTr=r(dMt,"TFTapasForQuestionAnswering"),dMt.forEach(t),wTr=r(WSe," (TAPAS model)"),WSe.forEach(t),lMt.forEach(t),ATr=i(Ea),k6e=n(Ea,"P",{});var cMt=s(k6e);yTr=r(cMt,"Examples:"),cMt.forEach(t),LTr=i(Ea),m(OA.$$.fragment,Ea),Ea.forEach(t),fi.forEach(t),oIe=i(c),Uc=n(c,"H2",{class:!0});var mNe=s(Uc);Z9=n(mNe,"A",{id:!0,class:!0,href:!0});var fMt=s(Z9);S6e=n(fMt,"SPAN",{});var mMt=s(S6e);m(VA.$$.fragment,mMt),mMt.forEach(t),fMt.forEach(t),xTr=i(mNe),R6e=n(mNe,"SPAN",{});var gMt=s(R6e);kTr=r(gMt,"TFAutoModelForTokenClassification"),gMt.forEach(t),mNe.forEach(t),rIe=i(c),Lr=n(c,"DIV",{class:!0});var gi=s(Lr);m(XA.$$.fragment,gi),STr=i(gi),Jc=n(gi,"P",{});var zY=s(Jc);RTr=r(zY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),ZQ=n(zY,"A",{href:!0});var hMt=s(ZQ);BTr=r(hMt,"from_pretrained()"),hMt.forEach(t),PTr=r(zY," class method or the "),eW=n(zY,"A",{href:!0});var pMt=s(eW);$Tr=r(pMt,"from_config()"),pMt.forEach(t),ITr=r(zY,` class
method.`),zY.forEach(t),qTr=i(gi),zA=n(gi,"P",{});var gNe=s(zA);NTr=r(gNe,"This class cannot be instantiated directly using "),B6e=n(gNe,"CODE",{});var _Mt=s(B6e);jTr=r(_Mt,"__init__()"),_Mt.forEach(t),DTr=r(gNe," (throws an error)."),gNe.forEach(t),GTr=i(gi),Mt=n(gi,"DIV",{class:!0});var hi=s(Mt);m(QA.$$.fragment,hi),OTr=i(hi),P6e=n(hi,"P",{});var uMt=s(P6e);VTr=r(uMt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),uMt.forEach(t),XTr=i(hi),Yc=n(hi,"P",{});var QY=s(Yc);zTr=r(QY,`Note:
Loading a model from its configuration file does `),$6e=n(QY,"STRONG",{});var bMt=s($6e);QTr=r(bMt,"not"),bMt.forEach(t),WTr=r(QY,` load the model weights. It only affects the
model\u2019s configuration. Use `),oW=n(QY,"A",{href:!0});var vMt=s(oW);HTr=r(vMt,"from_pretrained()"),vMt.forEach(t),UTr=r(QY," to load the model weights."),QY.forEach(t),JTr=i(hi),I6e=n(hi,"P",{});var FMt=s(I6e);YTr=r(FMt,"Examples:"),FMt.forEach(t),KTr=i(hi),m(WA.$$.fragment,hi),hi.forEach(t),ZTr=i(gi),Co=n(gi,"DIV",{class:!0});var Ca=s(Co);m(HA.$$.fragment,Ca),e7r=i(Ca),q6e=n(Ca,"P",{});var TMt=s(q6e);o7r=r(TMt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),TMt.forEach(t),r7r=i(Ca),An=n(Ca,"P",{});var q5=s(An);t7r=r(q5,"The model class to instantiate is selected based on the "),N6e=n(q5,"CODE",{});var MMt=s(N6e);a7r=r(MMt,"model_type"),MMt.forEach(t),n7r=r(q5,` property of the config object (either
passed as an argument or loaded from `),j6e=n(q5,"CODE",{});var EMt=s(j6e);s7r=r(EMt,"pretrained_model_name_or_path"),EMt.forEach(t),l7r=r(q5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D6e=n(q5,"CODE",{});var CMt=s(D6e);i7r=r(CMt,"pretrained_model_name_or_path"),CMt.forEach(t),d7r=r(q5,":"),q5.forEach(t),c7r=i(Ca),Z=n(Ca,"UL",{});var te=s(Z);eM=n(te,"LI",{});var HSe=s(eM);G6e=n(HSe,"STRONG",{});var wMt=s(G6e);f7r=r(wMt,"albert"),wMt.forEach(t),m7r=r(HSe," \u2014 "),rW=n(HSe,"A",{href:!0});var AMt=s(rW);g7r=r(AMt,"TFAlbertForTokenClassification"),AMt.forEach(t),h7r=r(HSe," (ALBERT model)"),HSe.forEach(t),p7r=i(te),oM=n(te,"LI",{});var USe=s(oM);O6e=n(USe,"STRONG",{});var yMt=s(O6e);_7r=r(yMt,"bert"),yMt.forEach(t),u7r=r(USe," \u2014 "),tW=n(USe,"A",{href:!0});var LMt=s(tW);b7r=r(LMt,"TFBertForTokenClassification"),LMt.forEach(t),v7r=r(USe," (BERT model)"),USe.forEach(t),F7r=i(te),rM=n(te,"LI",{});var JSe=s(rM);V6e=n(JSe,"STRONG",{});var xMt=s(V6e);T7r=r(xMt,"camembert"),xMt.forEach(t),M7r=r(JSe," \u2014 "),aW=n(JSe,"A",{href:!0});var kMt=s(aW);E7r=r(kMt,"TFCamembertForTokenClassification"),kMt.forEach(t),C7r=r(JSe," (CamemBERT model)"),JSe.forEach(t),w7r=i(te),tM=n(te,"LI",{});var YSe=s(tM);X6e=n(YSe,"STRONG",{});var SMt=s(X6e);A7r=r(SMt,"convbert"),SMt.forEach(t),y7r=r(YSe," \u2014 "),nW=n(YSe,"A",{href:!0});var RMt=s(nW);L7r=r(RMt,"TFConvBertForTokenClassification"),RMt.forEach(t),x7r=r(YSe," (ConvBERT model)"),YSe.forEach(t),k7r=i(te),aM=n(te,"LI",{});var KSe=s(aM);z6e=n(KSe,"STRONG",{});var BMt=s(z6e);S7r=r(BMt,"deberta"),BMt.forEach(t),R7r=r(KSe," \u2014 "),sW=n(KSe,"A",{href:!0});var PMt=s(sW);B7r=r(PMt,"TFDebertaForTokenClassification"),PMt.forEach(t),P7r=r(KSe," (DeBERTa model)"),KSe.forEach(t),$7r=i(te),nM=n(te,"LI",{});var ZSe=s(nM);Q6e=n(ZSe,"STRONG",{});var $Mt=s(Q6e);I7r=r($Mt,"deberta-v2"),$Mt.forEach(t),q7r=r(ZSe," \u2014 "),lW=n(ZSe,"A",{href:!0});var IMt=s(lW);N7r=r(IMt,"TFDebertaV2ForTokenClassification"),IMt.forEach(t),j7r=r(ZSe," (DeBERTa-v2 model)"),ZSe.forEach(t),D7r=i(te),sM=n(te,"LI",{});var eRe=s(sM);W6e=n(eRe,"STRONG",{});var qMt=s(W6e);G7r=r(qMt,"distilbert"),qMt.forEach(t),O7r=r(eRe," \u2014 "),iW=n(eRe,"A",{href:!0});var NMt=s(iW);V7r=r(NMt,"TFDistilBertForTokenClassification"),NMt.forEach(t),X7r=r(eRe," (DistilBERT model)"),eRe.forEach(t),z7r=i(te),lM=n(te,"LI",{});var oRe=s(lM);H6e=n(oRe,"STRONG",{});var jMt=s(H6e);Q7r=r(jMt,"electra"),jMt.forEach(t),W7r=r(oRe," \u2014 "),dW=n(oRe,"A",{href:!0});var DMt=s(dW);H7r=r(DMt,"TFElectraForTokenClassification"),DMt.forEach(t),U7r=r(oRe," (ELECTRA model)"),oRe.forEach(t),J7r=i(te),iM=n(te,"LI",{});var rRe=s(iM);U6e=n(rRe,"STRONG",{});var GMt=s(U6e);Y7r=r(GMt,"flaubert"),GMt.forEach(t),K7r=r(rRe," \u2014 "),cW=n(rRe,"A",{href:!0});var OMt=s(cW);Z7r=r(OMt,"TFFlaubertForTokenClassification"),OMt.forEach(t),e9r=r(rRe," (FlauBERT model)"),rRe.forEach(t),o9r=i(te),dM=n(te,"LI",{});var tRe=s(dM);J6e=n(tRe,"STRONG",{});var VMt=s(J6e);r9r=r(VMt,"funnel"),VMt.forEach(t),t9r=r(tRe," \u2014 "),fW=n(tRe,"A",{href:!0});var XMt=s(fW);a9r=r(XMt,"TFFunnelForTokenClassification"),XMt.forEach(t),n9r=r(tRe," (Funnel Transformer model)"),tRe.forEach(t),s9r=i(te),cM=n(te,"LI",{});var aRe=s(cM);Y6e=n(aRe,"STRONG",{});var zMt=s(Y6e);l9r=r(zMt,"layoutlm"),zMt.forEach(t),i9r=r(aRe," \u2014 "),mW=n(aRe,"A",{href:!0});var QMt=s(mW);d9r=r(QMt,"TFLayoutLMForTokenClassification"),QMt.forEach(t),c9r=r(aRe," (LayoutLM model)"),aRe.forEach(t),f9r=i(te),fM=n(te,"LI",{});var nRe=s(fM);K6e=n(nRe,"STRONG",{});var WMt=s(K6e);m9r=r(WMt,"longformer"),WMt.forEach(t),g9r=r(nRe," \u2014 "),gW=n(nRe,"A",{href:!0});var HMt=s(gW);h9r=r(HMt,"TFLongformerForTokenClassification"),HMt.forEach(t),p9r=r(nRe," (Longformer model)"),nRe.forEach(t),_9r=i(te),mM=n(te,"LI",{});var sRe=s(mM);Z6e=n(sRe,"STRONG",{});var UMt=s(Z6e);u9r=r(UMt,"mobilebert"),UMt.forEach(t),b9r=r(sRe," \u2014 "),hW=n(sRe,"A",{href:!0});var JMt=s(hW);v9r=r(JMt,"TFMobileBertForTokenClassification"),JMt.forEach(t),F9r=r(sRe," (MobileBERT model)"),sRe.forEach(t),T9r=i(te),gM=n(te,"LI",{});var lRe=s(gM);eve=n(lRe,"STRONG",{});var YMt=s(eve);M9r=r(YMt,"mpnet"),YMt.forEach(t),E9r=r(lRe," \u2014 "),pW=n(lRe,"A",{href:!0});var KMt=s(pW);C9r=r(KMt,"TFMPNetForTokenClassification"),KMt.forEach(t),w9r=r(lRe," (MPNet model)"),lRe.forEach(t),A9r=i(te),hM=n(te,"LI",{});var iRe=s(hM);ove=n(iRe,"STRONG",{});var ZMt=s(ove);y9r=r(ZMt,"rembert"),ZMt.forEach(t),L9r=r(iRe," \u2014 "),_W=n(iRe,"A",{href:!0});var e4t=s(_W);x9r=r(e4t,"TFRemBertForTokenClassification"),e4t.forEach(t),k9r=r(iRe," (RemBERT model)"),iRe.forEach(t),S9r=i(te),pM=n(te,"LI",{});var dRe=s(pM);rve=n(dRe,"STRONG",{});var o4t=s(rve);R9r=r(o4t,"roberta"),o4t.forEach(t),B9r=r(dRe," \u2014 "),uW=n(dRe,"A",{href:!0});var r4t=s(uW);P9r=r(r4t,"TFRobertaForTokenClassification"),r4t.forEach(t),$9r=r(dRe," (RoBERTa model)"),dRe.forEach(t),I9r=i(te),_M=n(te,"LI",{});var cRe=s(_M);tve=n(cRe,"STRONG",{});var t4t=s(tve);q9r=r(t4t,"roformer"),t4t.forEach(t),N9r=r(cRe," \u2014 "),bW=n(cRe,"A",{href:!0});var a4t=s(bW);j9r=r(a4t,"TFRoFormerForTokenClassification"),a4t.forEach(t),D9r=r(cRe," (RoFormer model)"),cRe.forEach(t),G9r=i(te),uM=n(te,"LI",{});var fRe=s(uM);ave=n(fRe,"STRONG",{});var n4t=s(ave);O9r=r(n4t,"xlm"),n4t.forEach(t),V9r=r(fRe," \u2014 "),vW=n(fRe,"A",{href:!0});var s4t=s(vW);X9r=r(s4t,"TFXLMForTokenClassification"),s4t.forEach(t),z9r=r(fRe," (XLM model)"),fRe.forEach(t),Q9r=i(te),bM=n(te,"LI",{});var mRe=s(bM);nve=n(mRe,"STRONG",{});var l4t=s(nve);W9r=r(l4t,"xlm-roberta"),l4t.forEach(t),H9r=r(mRe," \u2014 "),FW=n(mRe,"A",{href:!0});var i4t=s(FW);U9r=r(i4t,"TFXLMRobertaForTokenClassification"),i4t.forEach(t),J9r=r(mRe," (XLM-RoBERTa model)"),mRe.forEach(t),Y9r=i(te),vM=n(te,"LI",{});var gRe=s(vM);sve=n(gRe,"STRONG",{});var d4t=s(sve);K9r=r(d4t,"xlnet"),d4t.forEach(t),Z9r=r(gRe," \u2014 "),TW=n(gRe,"A",{href:!0});var c4t=s(TW);eMr=r(c4t,"TFXLNetForTokenClassification"),c4t.forEach(t),oMr=r(gRe," (XLNet model)"),gRe.forEach(t),te.forEach(t),rMr=i(Ca),lve=n(Ca,"P",{});var f4t=s(lve);tMr=r(f4t,"Examples:"),f4t.forEach(t),aMr=i(Ca),m(UA.$$.fragment,Ca),Ca.forEach(t),gi.forEach(t),tIe=i(c),Kc=n(c,"H2",{class:!0});var hNe=s(Kc);FM=n(hNe,"A",{id:!0,class:!0,href:!0});var m4t=s(FM);ive=n(m4t,"SPAN",{});var g4t=s(ive);m(JA.$$.fragment,g4t),g4t.forEach(t),m4t.forEach(t),nMr=i(hNe),dve=n(hNe,"SPAN",{});var h4t=s(dve);sMr=r(h4t,"TFAutoModelForQuestionAnswering"),h4t.forEach(t),hNe.forEach(t),aIe=i(c),xr=n(c,"DIV",{class:!0});var pi=s(xr);m(YA.$$.fragment,pi),lMr=i(pi),Zc=n(pi,"P",{});var WY=s(Zc);iMr=r(WY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),MW=n(WY,"A",{href:!0});var p4t=s(MW);dMr=r(p4t,"from_pretrained()"),p4t.forEach(t),cMr=r(WY," class method or the "),EW=n(WY,"A",{href:!0});var _4t=s(EW);fMr=r(_4t,"from_config()"),_4t.forEach(t),mMr=r(WY,` class
method.`),WY.forEach(t),gMr=i(pi),KA=n(pi,"P",{});var pNe=s(KA);hMr=r(pNe,"This class cannot be instantiated directly using "),cve=n(pNe,"CODE",{});var u4t=s(cve);pMr=r(u4t,"__init__()"),u4t.forEach(t),_Mr=r(pNe," (throws an error)."),pNe.forEach(t),uMr=i(pi),Et=n(pi,"DIV",{class:!0});var _i=s(Et);m(ZA.$$.fragment,_i),bMr=i(_i),fve=n(_i,"P",{});var b4t=s(fve);vMr=r(b4t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),b4t.forEach(t),FMr=i(_i),ef=n(_i,"P",{});var HY=s(ef);TMr=r(HY,`Note:
Loading a model from its configuration file does `),mve=n(HY,"STRONG",{});var v4t=s(mve);MMr=r(v4t,"not"),v4t.forEach(t),EMr=r(HY,` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=n(HY,"A",{href:!0});var F4t=s(CW);CMr=r(F4t,"from_pretrained()"),F4t.forEach(t),wMr=r(HY," to load the model weights."),HY.forEach(t),AMr=i(_i),gve=n(_i,"P",{});var T4t=s(gve);yMr=r(T4t,"Examples:"),T4t.forEach(t),LMr=i(_i),m(ey.$$.fragment,_i),_i.forEach(t),xMr=i(pi),wo=n(pi,"DIV",{class:!0});var wa=s(wo);m(oy.$$.fragment,wa),kMr=i(wa),hve=n(wa,"P",{});var M4t=s(hve);SMr=r(M4t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),M4t.forEach(t),RMr=i(wa),yn=n(wa,"P",{});var N5=s(yn);BMr=r(N5,"The model class to instantiate is selected based on the "),pve=n(N5,"CODE",{});var E4t=s(pve);PMr=r(E4t,"model_type"),E4t.forEach(t),$Mr=r(N5,` property of the config object (either
passed as an argument or loaded from `),_ve=n(N5,"CODE",{});var C4t=s(_ve);IMr=r(C4t,"pretrained_model_name_or_path"),C4t.forEach(t),qMr=r(N5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uve=n(N5,"CODE",{});var w4t=s(uve);NMr=r(w4t,"pretrained_model_name_or_path"),w4t.forEach(t),jMr=r(N5,":"),N5.forEach(t),DMr=i(wa),ee=n(wa,"UL",{});var ae=s(ee);TM=n(ae,"LI",{});var hRe=s(TM);bve=n(hRe,"STRONG",{});var A4t=s(bve);GMr=r(A4t,"albert"),A4t.forEach(t),OMr=r(hRe," \u2014 "),wW=n(hRe,"A",{href:!0});var y4t=s(wW);VMr=r(y4t,"TFAlbertForQuestionAnswering"),y4t.forEach(t),XMr=r(hRe," (ALBERT model)"),hRe.forEach(t),zMr=i(ae),MM=n(ae,"LI",{});var pRe=s(MM);vve=n(pRe,"STRONG",{});var L4t=s(vve);QMr=r(L4t,"bert"),L4t.forEach(t),WMr=r(pRe," \u2014 "),AW=n(pRe,"A",{href:!0});var x4t=s(AW);HMr=r(x4t,"TFBertForQuestionAnswering"),x4t.forEach(t),UMr=r(pRe," (BERT model)"),pRe.forEach(t),JMr=i(ae),EM=n(ae,"LI",{});var _Re=s(EM);Fve=n(_Re,"STRONG",{});var k4t=s(Fve);YMr=r(k4t,"camembert"),k4t.forEach(t),KMr=r(_Re," \u2014 "),yW=n(_Re,"A",{href:!0});var S4t=s(yW);ZMr=r(S4t,"TFCamembertForQuestionAnswering"),S4t.forEach(t),e4r=r(_Re," (CamemBERT model)"),_Re.forEach(t),o4r=i(ae),CM=n(ae,"LI",{});var uRe=s(CM);Tve=n(uRe,"STRONG",{});var R4t=s(Tve);r4r=r(R4t,"convbert"),R4t.forEach(t),t4r=r(uRe," \u2014 "),LW=n(uRe,"A",{href:!0});var B4t=s(LW);a4r=r(B4t,"TFConvBertForQuestionAnswering"),B4t.forEach(t),n4r=r(uRe," (ConvBERT model)"),uRe.forEach(t),s4r=i(ae),wM=n(ae,"LI",{});var bRe=s(wM);Mve=n(bRe,"STRONG",{});var P4t=s(Mve);l4r=r(P4t,"deberta"),P4t.forEach(t),i4r=r(bRe," \u2014 "),xW=n(bRe,"A",{href:!0});var $4t=s(xW);d4r=r($4t,"TFDebertaForQuestionAnswering"),$4t.forEach(t),c4r=r(bRe," (DeBERTa model)"),bRe.forEach(t),f4r=i(ae),AM=n(ae,"LI",{});var vRe=s(AM);Eve=n(vRe,"STRONG",{});var I4t=s(Eve);m4r=r(I4t,"deberta-v2"),I4t.forEach(t),g4r=r(vRe," \u2014 "),kW=n(vRe,"A",{href:!0});var q4t=s(kW);h4r=r(q4t,"TFDebertaV2ForQuestionAnswering"),q4t.forEach(t),p4r=r(vRe," (DeBERTa-v2 model)"),vRe.forEach(t),_4r=i(ae),yM=n(ae,"LI",{});var FRe=s(yM);Cve=n(FRe,"STRONG",{});var N4t=s(Cve);u4r=r(N4t,"distilbert"),N4t.forEach(t),b4r=r(FRe," \u2014 "),SW=n(FRe,"A",{href:!0});var j4t=s(SW);v4r=r(j4t,"TFDistilBertForQuestionAnswering"),j4t.forEach(t),F4r=r(FRe," (DistilBERT model)"),FRe.forEach(t),T4r=i(ae),LM=n(ae,"LI",{});var TRe=s(LM);wve=n(TRe,"STRONG",{});var D4t=s(wve);M4r=r(D4t,"electra"),D4t.forEach(t),E4r=r(TRe," \u2014 "),RW=n(TRe,"A",{href:!0});var G4t=s(RW);C4r=r(G4t,"TFElectraForQuestionAnswering"),G4t.forEach(t),w4r=r(TRe," (ELECTRA model)"),TRe.forEach(t),A4r=i(ae),xM=n(ae,"LI",{});var MRe=s(xM);Ave=n(MRe,"STRONG",{});var O4t=s(Ave);y4r=r(O4t,"flaubert"),O4t.forEach(t),L4r=r(MRe," \u2014 "),BW=n(MRe,"A",{href:!0});var V4t=s(BW);x4r=r(V4t,"TFFlaubertForQuestionAnsweringSimple"),V4t.forEach(t),k4r=r(MRe," (FlauBERT model)"),MRe.forEach(t),S4r=i(ae),kM=n(ae,"LI",{});var ERe=s(kM);yve=n(ERe,"STRONG",{});var X4t=s(yve);R4r=r(X4t,"funnel"),X4t.forEach(t),B4r=r(ERe," \u2014 "),PW=n(ERe,"A",{href:!0});var z4t=s(PW);P4r=r(z4t,"TFFunnelForQuestionAnswering"),z4t.forEach(t),$4r=r(ERe," (Funnel Transformer model)"),ERe.forEach(t),I4r=i(ae),SM=n(ae,"LI",{});var CRe=s(SM);Lve=n(CRe,"STRONG",{});var Q4t=s(Lve);q4r=r(Q4t,"gptj"),Q4t.forEach(t),N4r=r(CRe," \u2014 "),$W=n(CRe,"A",{href:!0});var W4t=s($W);j4r=r(W4t,"TFGPTJForQuestionAnswering"),W4t.forEach(t),D4r=r(CRe," (GPT-J model)"),CRe.forEach(t),G4r=i(ae),RM=n(ae,"LI",{});var wRe=s(RM);xve=n(wRe,"STRONG",{});var H4t=s(xve);O4r=r(H4t,"longformer"),H4t.forEach(t),V4r=r(wRe," \u2014 "),IW=n(wRe,"A",{href:!0});var U4t=s(IW);X4r=r(U4t,"TFLongformerForQuestionAnswering"),U4t.forEach(t),z4r=r(wRe," (Longformer model)"),wRe.forEach(t),Q4r=i(ae),BM=n(ae,"LI",{});var ARe=s(BM);kve=n(ARe,"STRONG",{});var J4t=s(kve);W4r=r(J4t,"mobilebert"),J4t.forEach(t),H4r=r(ARe," \u2014 "),qW=n(ARe,"A",{href:!0});var Y4t=s(qW);U4r=r(Y4t,"TFMobileBertForQuestionAnswering"),Y4t.forEach(t),J4r=r(ARe," (MobileBERT model)"),ARe.forEach(t),Y4r=i(ae),PM=n(ae,"LI",{});var yRe=s(PM);Sve=n(yRe,"STRONG",{});var K4t=s(Sve);K4r=r(K4t,"mpnet"),K4t.forEach(t),Z4r=r(yRe," \u2014 "),NW=n(yRe,"A",{href:!0});var Z4t=s(NW);eEr=r(Z4t,"TFMPNetForQuestionAnswering"),Z4t.forEach(t),oEr=r(yRe," (MPNet model)"),yRe.forEach(t),rEr=i(ae),$M=n(ae,"LI",{});var LRe=s($M);Rve=n(LRe,"STRONG",{});var eEt=s(Rve);tEr=r(eEt,"rembert"),eEt.forEach(t),aEr=r(LRe," \u2014 "),jW=n(LRe,"A",{href:!0});var oEt=s(jW);nEr=r(oEt,"TFRemBertForQuestionAnswering"),oEt.forEach(t),sEr=r(LRe," (RemBERT model)"),LRe.forEach(t),lEr=i(ae),IM=n(ae,"LI",{});var xRe=s(IM);Bve=n(xRe,"STRONG",{});var rEt=s(Bve);iEr=r(rEt,"roberta"),rEt.forEach(t),dEr=r(xRe," \u2014 "),DW=n(xRe,"A",{href:!0});var tEt=s(DW);cEr=r(tEt,"TFRobertaForQuestionAnswering"),tEt.forEach(t),fEr=r(xRe," (RoBERTa model)"),xRe.forEach(t),mEr=i(ae),qM=n(ae,"LI",{});var kRe=s(qM);Pve=n(kRe,"STRONG",{});var aEt=s(Pve);gEr=r(aEt,"roformer"),aEt.forEach(t),hEr=r(kRe," \u2014 "),GW=n(kRe,"A",{href:!0});var nEt=s(GW);pEr=r(nEt,"TFRoFormerForQuestionAnswering"),nEt.forEach(t),_Er=r(kRe," (RoFormer model)"),kRe.forEach(t),uEr=i(ae),NM=n(ae,"LI",{});var SRe=s(NM);$ve=n(SRe,"STRONG",{});var sEt=s($ve);bEr=r(sEt,"xlm"),sEt.forEach(t),vEr=r(SRe," \u2014 "),OW=n(SRe,"A",{href:!0});var lEt=s(OW);FEr=r(lEt,"TFXLMForQuestionAnsweringSimple"),lEt.forEach(t),TEr=r(SRe," (XLM model)"),SRe.forEach(t),MEr=i(ae),jM=n(ae,"LI",{});var RRe=s(jM);Ive=n(RRe,"STRONG",{});var iEt=s(Ive);EEr=r(iEt,"xlm-roberta"),iEt.forEach(t),CEr=r(RRe," \u2014 "),VW=n(RRe,"A",{href:!0});var dEt=s(VW);wEr=r(dEt,"TFXLMRobertaForQuestionAnswering"),dEt.forEach(t),AEr=r(RRe," (XLM-RoBERTa model)"),RRe.forEach(t),yEr=i(ae),DM=n(ae,"LI",{});var BRe=s(DM);qve=n(BRe,"STRONG",{});var cEt=s(qve);LEr=r(cEt,"xlnet"),cEt.forEach(t),xEr=r(BRe," \u2014 "),XW=n(BRe,"A",{href:!0});var fEt=s(XW);kEr=r(fEt,"TFXLNetForQuestionAnsweringSimple"),fEt.forEach(t),SEr=r(BRe," (XLNet model)"),BRe.forEach(t),ae.forEach(t),REr=i(wa),Nve=n(wa,"P",{});var mEt=s(Nve);BEr=r(mEt,"Examples:"),mEt.forEach(t),PEr=i(wa),m(ry.$$.fragment,wa),wa.forEach(t),pi.forEach(t),nIe=i(c),of=n(c,"H2",{class:!0});var _Ne=s(of);GM=n(_Ne,"A",{id:!0,class:!0,href:!0});var gEt=s(GM);jve=n(gEt,"SPAN",{});var hEt=s(jve);m(ty.$$.fragment,hEt),hEt.forEach(t),gEt.forEach(t),$Er=i(_Ne),Dve=n(_Ne,"SPAN",{});var pEt=s(Dve);IEr=r(pEt,"TFAutoModelForVision2Seq"),pEt.forEach(t),_Ne.forEach(t),sIe=i(c),kr=n(c,"DIV",{class:!0});var ui=s(kr);m(ay.$$.fragment,ui),qEr=i(ui),rf=n(ui,"P",{});var UY=s(rf);NEr=r(UY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),zW=n(UY,"A",{href:!0});var _Et=s(zW);jEr=r(_Et,"from_pretrained()"),_Et.forEach(t),DEr=r(UY," class method or the "),QW=n(UY,"A",{href:!0});var uEt=s(QW);GEr=r(uEt,"from_config()"),uEt.forEach(t),OEr=r(UY,` class
method.`),UY.forEach(t),VEr=i(ui),ny=n(ui,"P",{});var uNe=s(ny);XEr=r(uNe,"This class cannot be instantiated directly using "),Gve=n(uNe,"CODE",{});var bEt=s(Gve);zEr=r(bEt,"__init__()"),bEt.forEach(t),QEr=r(uNe," (throws an error)."),uNe.forEach(t),WEr=i(ui),Ct=n(ui,"DIV",{class:!0});var bi=s(Ct);m(sy.$$.fragment,bi),HEr=i(bi),Ove=n(bi,"P",{});var vEt=s(Ove);UEr=r(vEt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),vEt.forEach(t),JEr=i(bi),tf=n(bi,"P",{});var JY=s(tf);YEr=r(JY,`Note:
Loading a model from its configuration file does `),Vve=n(JY,"STRONG",{});var FEt=s(Vve);KEr=r(FEt,"not"),FEt.forEach(t),ZEr=r(JY,` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=n(JY,"A",{href:!0});var TEt=s(WW);e5r=r(TEt,"from_pretrained()"),TEt.forEach(t),o5r=r(JY," to load the model weights."),JY.forEach(t),r5r=i(bi),Xve=n(bi,"P",{});var MEt=s(Xve);t5r=r(MEt,"Examples:"),MEt.forEach(t),a5r=i(bi),m(ly.$$.fragment,bi),bi.forEach(t),n5r=i(ui),Ao=n(ui,"DIV",{class:!0});var Aa=s(Ao);m(iy.$$.fragment,Aa),s5r=i(Aa),zve=n(Aa,"P",{});var EEt=s(zve);l5r=r(EEt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),EEt.forEach(t),i5r=i(Aa),Ln=n(Aa,"P",{});var j5=s(Ln);d5r=r(j5,"The model class to instantiate is selected based on the "),Qve=n(j5,"CODE",{});var CEt=s(Qve);c5r=r(CEt,"model_type"),CEt.forEach(t),f5r=r(j5,` property of the config object (either
passed as an argument or loaded from `),Wve=n(j5,"CODE",{});var wEt=s(Wve);m5r=r(wEt,"pretrained_model_name_or_path"),wEt.forEach(t),g5r=r(j5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hve=n(j5,"CODE",{});var AEt=s(Hve);h5r=r(AEt,"pretrained_model_name_or_path"),AEt.forEach(t),p5r=r(j5,":"),j5.forEach(t),_5r=i(Aa),Uve=n(Aa,"UL",{});var yEt=s(Uve);OM=n(yEt,"LI",{});var PRe=s(OM);Jve=n(PRe,"STRONG",{});var LEt=s(Jve);u5r=r(LEt,"vision-encoder-decoder"),LEt.forEach(t),b5r=r(PRe," \u2014 "),HW=n(PRe,"A",{href:!0});var xEt=s(HW);v5r=r(xEt,"TFVisionEncoderDecoderModel"),xEt.forEach(t),F5r=r(PRe," (Vision Encoder decoder model)"),PRe.forEach(t),yEt.forEach(t),T5r=i(Aa),Yve=n(Aa,"P",{});var kEt=s(Yve);M5r=r(kEt,"Examples:"),kEt.forEach(t),E5r=i(Aa),m(dy.$$.fragment,Aa),Aa.forEach(t),ui.forEach(t),lIe=i(c),af=n(c,"H2",{class:!0});var bNe=s(af);VM=n(bNe,"A",{id:!0,class:!0,href:!0});var SEt=s(VM);Kve=n(SEt,"SPAN",{});var REt=s(Kve);m(cy.$$.fragment,REt),REt.forEach(t),SEt.forEach(t),C5r=i(bNe),Zve=n(bNe,"SPAN",{});var BEt=s(Zve);w5r=r(BEt,"TFAutoModelForSpeechSeq2Seq"),BEt.forEach(t),bNe.forEach(t),iIe=i(c),Sr=n(c,"DIV",{class:!0});var vi=s(Sr);m(fy.$$.fragment,vi),A5r=i(vi),nf=n(vi,"P",{});var YY=s(nf);y5r=r(YY,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),UW=n(YY,"A",{href:!0});var PEt=s(UW);L5r=r(PEt,"from_pretrained()"),PEt.forEach(t),x5r=r(YY," class method or the "),JW=n(YY,"A",{href:!0});var $Et=s(JW);k5r=r($Et,"from_config()"),$Et.forEach(t),S5r=r(YY,` class
method.`),YY.forEach(t),R5r=i(vi),my=n(vi,"P",{});var vNe=s(my);B5r=r(vNe,"This class cannot be instantiated directly using "),eFe=n(vNe,"CODE",{});var IEt=s(eFe);P5r=r(IEt,"__init__()"),IEt.forEach(t),$5r=r(vNe," (throws an error)."),vNe.forEach(t),I5r=i(vi),wt=n(vi,"DIV",{class:!0});var Fi=s(wt);m(gy.$$.fragment,Fi),q5r=i(Fi),oFe=n(Fi,"P",{});var qEt=s(oFe);N5r=r(qEt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),qEt.forEach(t),j5r=i(Fi),sf=n(Fi,"P",{});var KY=s(sf);D5r=r(KY,`Note:
Loading a model from its configuration file does `),rFe=n(KY,"STRONG",{});var NEt=s(rFe);G5r=r(NEt,"not"),NEt.forEach(t),O5r=r(KY,` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=n(KY,"A",{href:!0});var jEt=s(YW);V5r=r(jEt,"from_pretrained()"),jEt.forEach(t),X5r=r(KY," to load the model weights."),KY.forEach(t),z5r=i(Fi),tFe=n(Fi,"P",{});var DEt=s(tFe);Q5r=r(DEt,"Examples:"),DEt.forEach(t),W5r=i(Fi),m(hy.$$.fragment,Fi),Fi.forEach(t),H5r=i(vi),yo=n(vi,"DIV",{class:!0});var ya=s(yo);m(py.$$.fragment,ya),U5r=i(ya),aFe=n(ya,"P",{});var GEt=s(aFe);J5r=r(GEt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),GEt.forEach(t),Y5r=i(ya),xn=n(ya,"P",{});var D5=s(xn);K5r=r(D5,"The model class to instantiate is selected based on the "),nFe=n(D5,"CODE",{});var OEt=s(nFe);Z5r=r(OEt,"model_type"),OEt.forEach(t),e3r=r(D5,` property of the config object (either
passed as an argument or loaded from `),sFe=n(D5,"CODE",{});var VEt=s(sFe);o3r=r(VEt,"pretrained_model_name_or_path"),VEt.forEach(t),r3r=r(D5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lFe=n(D5,"CODE",{});var XEt=s(lFe);t3r=r(XEt,"pretrained_model_name_or_path"),XEt.forEach(t),a3r=r(D5,":"),D5.forEach(t),n3r=i(ya),iFe=n(ya,"UL",{});var zEt=s(iFe);XM=n(zEt,"LI",{});var $Re=s(XM);dFe=n($Re,"STRONG",{});var QEt=s(dFe);s3r=r(QEt,"speech_to_text"),QEt.forEach(t),l3r=r($Re," \u2014 "),KW=n($Re,"A",{href:!0});var WEt=s(KW);i3r=r(WEt,"TFSpeech2TextForConditionalGeneration"),WEt.forEach(t),d3r=r($Re," (Speech2Text model)"),$Re.forEach(t),zEt.forEach(t),c3r=i(ya),cFe=n(ya,"P",{});var HEt=s(cFe);f3r=r(HEt,"Examples:"),HEt.forEach(t),m3r=i(ya),m(_y.$$.fragment,ya),ya.forEach(t),vi.forEach(t),dIe=i(c),lf=n(c,"H2",{class:!0});var FNe=s(lf);zM=n(FNe,"A",{id:!0,class:!0,href:!0});var UEt=s(zM);fFe=n(UEt,"SPAN",{});var JEt=s(fFe);m(uy.$$.fragment,JEt),JEt.forEach(t),UEt.forEach(t),g3r=i(FNe),mFe=n(FNe,"SPAN",{});var YEt=s(mFe);h3r=r(YEt,"FlaxAutoModel"),YEt.forEach(t),FNe.forEach(t),cIe=i(c),Rr=n(c,"DIV",{class:!0});var Ti=s(Rr);m(by.$$.fragment,Ti),p3r=i(Ti),df=n(Ti,"P",{});var ZY=s(df);_3r=r(ZY,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),ZW=n(ZY,"A",{href:!0});var KEt=s(ZW);u3r=r(KEt,"from_pretrained()"),KEt.forEach(t),b3r=r(ZY," class method or the "),eH=n(ZY,"A",{href:!0});var ZEt=s(eH);v3r=r(ZEt,"from_config()"),ZEt.forEach(t),F3r=r(ZY,` class
method.`),ZY.forEach(t),T3r=i(Ti),vy=n(Ti,"P",{});var TNe=s(vy);M3r=r(TNe,"This class cannot be instantiated directly using "),gFe=n(TNe,"CODE",{});var e5t=s(gFe);E3r=r(e5t,"__init__()"),e5t.forEach(t),C3r=r(TNe," (throws an error)."),TNe.forEach(t),w3r=i(Ti),At=n(Ti,"DIV",{class:!0});var Mi=s(At);m(Fy.$$.fragment,Mi),A3r=i(Mi),hFe=n(Mi,"P",{});var o5t=s(hFe);y3r=r(o5t,"Instantiates one of the base model classes of the library from a configuration."),o5t.forEach(t),L3r=i(Mi),cf=n(Mi,"P",{});var eK=s(cf);x3r=r(eK,`Note:
Loading a model from its configuration file does `),pFe=n(eK,"STRONG",{});var r5t=s(pFe);k3r=r(r5t,"not"),r5t.forEach(t),S3r=r(eK,` load the model weights. It only affects the
model\u2019s configuration. Use `),oH=n(eK,"A",{href:!0});var t5t=s(oH);R3r=r(t5t,"from_pretrained()"),t5t.forEach(t),B3r=r(eK," to load the model weights."),eK.forEach(t),P3r=i(Mi),_Fe=n(Mi,"P",{});var a5t=s(_Fe);$3r=r(a5t,"Examples:"),a5t.forEach(t),I3r=i(Mi),m(Ty.$$.fragment,Mi),Mi.forEach(t),q3r=i(Ti),Lo=n(Ti,"DIV",{class:!0});var La=s(Lo);m(My.$$.fragment,La),N3r=i(La),uFe=n(La,"P",{});var n5t=s(uFe);j3r=r(n5t,"Instantiate one of the base model classes of the library from a pretrained model."),n5t.forEach(t),D3r=i(La),kn=n(La,"P",{});var G5=s(kn);G3r=r(G5,"The model class to instantiate is selected based on the "),bFe=n(G5,"CODE",{});var s5t=s(bFe);O3r=r(s5t,"model_type"),s5t.forEach(t),V3r=r(G5,` property of the config object (either
passed as an argument or loaded from `),vFe=n(G5,"CODE",{});var l5t=s(vFe);X3r=r(l5t,"pretrained_model_name_or_path"),l5t.forEach(t),z3r=r(G5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FFe=n(G5,"CODE",{});var i5t=s(FFe);Q3r=r(i5t,"pretrained_model_name_or_path"),i5t.forEach(t),W3r=r(G5,":"),G5.forEach(t),H3r=i(La),X=n(La,"UL",{});var W=s(X);QM=n(W,"LI",{});var IRe=s(QM);TFe=n(IRe,"STRONG",{});var d5t=s(TFe);U3r=r(d5t,"albert"),d5t.forEach(t),J3r=r(IRe," \u2014 "),rH=n(IRe,"A",{href:!0});var c5t=s(rH);Y3r=r(c5t,"FlaxAlbertModel"),c5t.forEach(t),K3r=r(IRe," (ALBERT model)"),IRe.forEach(t),Z3r=i(W),WM=n(W,"LI",{});var qRe=s(WM);MFe=n(qRe,"STRONG",{});var f5t=s(MFe);eCr=r(f5t,"bart"),f5t.forEach(t),oCr=r(qRe," \u2014 "),tH=n(qRe,"A",{href:!0});var m5t=s(tH);rCr=r(m5t,"FlaxBartModel"),m5t.forEach(t),tCr=r(qRe," (BART model)"),qRe.forEach(t),aCr=i(W),HM=n(W,"LI",{});var NRe=s(HM);EFe=n(NRe,"STRONG",{});var g5t=s(EFe);nCr=r(g5t,"beit"),g5t.forEach(t),sCr=r(NRe," \u2014 "),aH=n(NRe,"A",{href:!0});var h5t=s(aH);lCr=r(h5t,"FlaxBeitModel"),h5t.forEach(t),iCr=r(NRe," (BEiT model)"),NRe.forEach(t),dCr=i(W),UM=n(W,"LI",{});var jRe=s(UM);CFe=n(jRe,"STRONG",{});var p5t=s(CFe);cCr=r(p5t,"bert"),p5t.forEach(t),fCr=r(jRe," \u2014 "),nH=n(jRe,"A",{href:!0});var _5t=s(nH);mCr=r(_5t,"FlaxBertModel"),_5t.forEach(t),gCr=r(jRe," (BERT model)"),jRe.forEach(t),hCr=i(W),JM=n(W,"LI",{});var DRe=s(JM);wFe=n(DRe,"STRONG",{});var u5t=s(wFe);pCr=r(u5t,"big_bird"),u5t.forEach(t),_Cr=r(DRe," \u2014 "),sH=n(DRe,"A",{href:!0});var b5t=s(sH);uCr=r(b5t,"FlaxBigBirdModel"),b5t.forEach(t),bCr=r(DRe," (BigBird model)"),DRe.forEach(t),vCr=i(W),YM=n(W,"LI",{});var GRe=s(YM);AFe=n(GRe,"STRONG",{});var v5t=s(AFe);FCr=r(v5t,"blenderbot"),v5t.forEach(t),TCr=r(GRe," \u2014 "),lH=n(GRe,"A",{href:!0});var F5t=s(lH);MCr=r(F5t,"FlaxBlenderbotModel"),F5t.forEach(t),ECr=r(GRe," (Blenderbot model)"),GRe.forEach(t),CCr=i(W),KM=n(W,"LI",{});var ORe=s(KM);yFe=n(ORe,"STRONG",{});var T5t=s(yFe);wCr=r(T5t,"blenderbot-small"),T5t.forEach(t),ACr=r(ORe," \u2014 "),iH=n(ORe,"A",{href:!0});var M5t=s(iH);yCr=r(M5t,"FlaxBlenderbotSmallModel"),M5t.forEach(t),LCr=r(ORe," (BlenderbotSmall model)"),ORe.forEach(t),xCr=i(W),ZM=n(W,"LI",{});var VRe=s(ZM);LFe=n(VRe,"STRONG",{});var E5t=s(LFe);kCr=r(E5t,"clip"),E5t.forEach(t),SCr=r(VRe," \u2014 "),dH=n(VRe,"A",{href:!0});var C5t=s(dH);RCr=r(C5t,"FlaxCLIPModel"),C5t.forEach(t),BCr=r(VRe," (CLIP model)"),VRe.forEach(t),PCr=i(W),e4=n(W,"LI",{});var XRe=s(e4);xFe=n(XRe,"STRONG",{});var w5t=s(xFe);$Cr=r(w5t,"distilbert"),w5t.forEach(t),ICr=r(XRe," \u2014 "),cH=n(XRe,"A",{href:!0});var A5t=s(cH);qCr=r(A5t,"FlaxDistilBertModel"),A5t.forEach(t),NCr=r(XRe," (DistilBERT model)"),XRe.forEach(t),jCr=i(W),o4=n(W,"LI",{});var zRe=s(o4);kFe=n(zRe,"STRONG",{});var y5t=s(kFe);DCr=r(y5t,"electra"),y5t.forEach(t),GCr=r(zRe," \u2014 "),fH=n(zRe,"A",{href:!0});var L5t=s(fH);OCr=r(L5t,"FlaxElectraModel"),L5t.forEach(t),VCr=r(zRe," (ELECTRA model)"),zRe.forEach(t),XCr=i(W),r4=n(W,"LI",{});var QRe=s(r4);SFe=n(QRe,"STRONG",{});var x5t=s(SFe);zCr=r(x5t,"gpt2"),x5t.forEach(t),QCr=r(QRe," \u2014 "),mH=n(QRe,"A",{href:!0});var k5t=s(mH);WCr=r(k5t,"FlaxGPT2Model"),k5t.forEach(t),HCr=r(QRe," (OpenAI GPT-2 model)"),QRe.forEach(t),UCr=i(W),t4=n(W,"LI",{});var WRe=s(t4);RFe=n(WRe,"STRONG",{});var S5t=s(RFe);JCr=r(S5t,"gpt_neo"),S5t.forEach(t),YCr=r(WRe," \u2014 "),gH=n(WRe,"A",{href:!0});var R5t=s(gH);KCr=r(R5t,"FlaxGPTNeoModel"),R5t.forEach(t),ZCr=r(WRe," (GPT Neo model)"),WRe.forEach(t),ewr=i(W),a4=n(W,"LI",{});var HRe=s(a4);BFe=n(HRe,"STRONG",{});var B5t=s(BFe);owr=r(B5t,"gptj"),B5t.forEach(t),rwr=r(HRe," \u2014 "),hH=n(HRe,"A",{href:!0});var P5t=s(hH);twr=r(P5t,"FlaxGPTJModel"),P5t.forEach(t),awr=r(HRe," (GPT-J model)"),HRe.forEach(t),nwr=i(W),n4=n(W,"LI",{});var URe=s(n4);PFe=n(URe,"STRONG",{});var $5t=s(PFe);swr=r($5t,"longt5"),$5t.forEach(t),lwr=r(URe," \u2014 "),pH=n(URe,"A",{href:!0});var I5t=s(pH);iwr=r(I5t,"FlaxLongT5Model"),I5t.forEach(t),dwr=r(URe," (LongT5 model)"),URe.forEach(t),cwr=i(W),s4=n(W,"LI",{});var JRe=s(s4);$Fe=n(JRe,"STRONG",{});var q5t=s($Fe);fwr=r(q5t,"marian"),q5t.forEach(t),mwr=r(JRe," \u2014 "),_H=n(JRe,"A",{href:!0});var N5t=s(_H);gwr=r(N5t,"FlaxMarianModel"),N5t.forEach(t),hwr=r(JRe," (Marian model)"),JRe.forEach(t),pwr=i(W),l4=n(W,"LI",{});var YRe=s(l4);IFe=n(YRe,"STRONG",{});var j5t=s(IFe);_wr=r(j5t,"mbart"),j5t.forEach(t),uwr=r(YRe," \u2014 "),uH=n(YRe,"A",{href:!0});var D5t=s(uH);bwr=r(D5t,"FlaxMBartModel"),D5t.forEach(t),vwr=r(YRe," (mBART model)"),YRe.forEach(t),Fwr=i(W),i4=n(W,"LI",{});var KRe=s(i4);qFe=n(KRe,"STRONG",{});var G5t=s(qFe);Twr=r(G5t,"mt5"),G5t.forEach(t),Mwr=r(KRe," \u2014 "),bH=n(KRe,"A",{href:!0});var O5t=s(bH);Ewr=r(O5t,"FlaxMT5Model"),O5t.forEach(t),Cwr=r(KRe," (mT5 model)"),KRe.forEach(t),wwr=i(W),d4=n(W,"LI",{});var ZRe=s(d4);NFe=n(ZRe,"STRONG",{});var V5t=s(NFe);Awr=r(V5t,"pegasus"),V5t.forEach(t),ywr=r(ZRe," \u2014 "),vH=n(ZRe,"A",{href:!0});var X5t=s(vH);Lwr=r(X5t,"FlaxPegasusModel"),X5t.forEach(t),xwr=r(ZRe," (Pegasus model)"),ZRe.forEach(t),kwr=i(W),c4=n(W,"LI",{});var eBe=s(c4);jFe=n(eBe,"STRONG",{});var z5t=s(jFe);Swr=r(z5t,"roberta"),z5t.forEach(t),Rwr=r(eBe," \u2014 "),FH=n(eBe,"A",{href:!0});var Q5t=s(FH);Bwr=r(Q5t,"FlaxRobertaModel"),Q5t.forEach(t),Pwr=r(eBe," (RoBERTa model)"),eBe.forEach(t),$wr=i(W),f4=n(W,"LI",{});var oBe=s(f4);DFe=n(oBe,"STRONG",{});var W5t=s(DFe);Iwr=r(W5t,"roformer"),W5t.forEach(t),qwr=r(oBe," \u2014 "),TH=n(oBe,"A",{href:!0});var H5t=s(TH);Nwr=r(H5t,"FlaxRoFormerModel"),H5t.forEach(t),jwr=r(oBe," (RoFormer model)"),oBe.forEach(t),Dwr=i(W),m4=n(W,"LI",{});var rBe=s(m4);GFe=n(rBe,"STRONG",{});var U5t=s(GFe);Gwr=r(U5t,"t5"),U5t.forEach(t),Owr=r(rBe," \u2014 "),MH=n(rBe,"A",{href:!0});var J5t=s(MH);Vwr=r(J5t,"FlaxT5Model"),J5t.forEach(t),Xwr=r(rBe," (T5 model)"),rBe.forEach(t),zwr=i(W),g4=n(W,"LI",{});var tBe=s(g4);OFe=n(tBe,"STRONG",{});var Y5t=s(OFe);Qwr=r(Y5t,"vision-text-dual-encoder"),Y5t.forEach(t),Wwr=r(tBe," \u2014 "),EH=n(tBe,"A",{href:!0});var K5t=s(EH);Hwr=r(K5t,"FlaxVisionTextDualEncoderModel"),K5t.forEach(t),Uwr=r(tBe," (VisionTextDualEncoder model)"),tBe.forEach(t),Jwr=i(W),h4=n(W,"LI",{});var aBe=s(h4);VFe=n(aBe,"STRONG",{});var Z5t=s(VFe);Ywr=r(Z5t,"vit"),Z5t.forEach(t),Kwr=r(aBe," \u2014 "),CH=n(aBe,"A",{href:!0});var e3t=s(CH);Zwr=r(e3t,"FlaxViTModel"),e3t.forEach(t),e0r=r(aBe," (ViT model)"),aBe.forEach(t),o0r=i(W),p4=n(W,"LI",{});var nBe=s(p4);XFe=n(nBe,"STRONG",{});var o3t=s(XFe);r0r=r(o3t,"wav2vec2"),o3t.forEach(t),t0r=r(nBe," \u2014 "),wH=n(nBe,"A",{href:!0});var r3t=s(wH);a0r=r(r3t,"FlaxWav2Vec2Model"),r3t.forEach(t),n0r=r(nBe," (Wav2Vec2 model)"),nBe.forEach(t),s0r=i(W),_4=n(W,"LI",{});var sBe=s(_4);zFe=n(sBe,"STRONG",{});var t3t=s(zFe);l0r=r(t3t,"xglm"),t3t.forEach(t),i0r=r(sBe," \u2014 "),AH=n(sBe,"A",{href:!0});var a3t=s(AH);d0r=r(a3t,"FlaxXGLMModel"),a3t.forEach(t),c0r=r(sBe," (XGLM model)"),sBe.forEach(t),f0r=i(W),u4=n(W,"LI",{});var lBe=s(u4);QFe=n(lBe,"STRONG",{});var n3t=s(QFe);m0r=r(n3t,"xlm-roberta"),n3t.forEach(t),g0r=r(lBe," \u2014 "),yH=n(lBe,"A",{href:!0});var s3t=s(yH);h0r=r(s3t,"FlaxXLMRobertaModel"),s3t.forEach(t),p0r=r(lBe," (XLM-RoBERTa model)"),lBe.forEach(t),W.forEach(t),_0r=i(La),WFe=n(La,"P",{});var l3t=s(WFe);u0r=r(l3t,"Examples:"),l3t.forEach(t),b0r=i(La),m(Ey.$$.fragment,La),La.forEach(t),Ti.forEach(t),fIe=i(c),ff=n(c,"H2",{class:!0});var MNe=s(ff);b4=n(MNe,"A",{id:!0,class:!0,href:!0});var i3t=s(b4);HFe=n(i3t,"SPAN",{});var d3t=s(HFe);m(Cy.$$.fragment,d3t),d3t.forEach(t),i3t.forEach(t),v0r=i(MNe),UFe=n(MNe,"SPAN",{});var c3t=s(UFe);F0r=r(c3t,"FlaxAutoModelForCausalLM"),c3t.forEach(t),MNe.forEach(t),mIe=i(c),Br=n(c,"DIV",{class:!0});var Ei=s(Br);m(wy.$$.fragment,Ei),T0r=i(Ei),mf=n(Ei,"P",{});var oK=s(mf);M0r=r(oK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),LH=n(oK,"A",{href:!0});var f3t=s(LH);E0r=r(f3t,"from_pretrained()"),f3t.forEach(t),C0r=r(oK," class method or the "),xH=n(oK,"A",{href:!0});var m3t=s(xH);w0r=r(m3t,"from_config()"),m3t.forEach(t),A0r=r(oK,` class
method.`),oK.forEach(t),y0r=i(Ei),Ay=n(Ei,"P",{});var ENe=s(Ay);L0r=r(ENe,"This class cannot be instantiated directly using "),JFe=n(ENe,"CODE",{});var g3t=s(JFe);x0r=r(g3t,"__init__()"),g3t.forEach(t),k0r=r(ENe," (throws an error)."),ENe.forEach(t),S0r=i(Ei),yt=n(Ei,"DIV",{class:!0});var Ci=s(yt);m(yy.$$.fragment,Ci),R0r=i(Ci),YFe=n(Ci,"P",{});var h3t=s(YFe);B0r=r(h3t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),h3t.forEach(t),P0r=i(Ci),gf=n(Ci,"P",{});var rK=s(gf);$0r=r(rK,`Note:
Loading a model from its configuration file does `),KFe=n(rK,"STRONG",{});var p3t=s(KFe);I0r=r(p3t,"not"),p3t.forEach(t),q0r=r(rK,` load the model weights. It only affects the
model\u2019s configuration. Use `),kH=n(rK,"A",{href:!0});var _3t=s(kH);N0r=r(_3t,"from_pretrained()"),_3t.forEach(t),j0r=r(rK," to load the model weights."),rK.forEach(t),D0r=i(Ci),ZFe=n(Ci,"P",{});var u3t=s(ZFe);G0r=r(u3t,"Examples:"),u3t.forEach(t),O0r=i(Ci),m(Ly.$$.fragment,Ci),Ci.forEach(t),V0r=i(Ei),xo=n(Ei,"DIV",{class:!0});var xa=s(xo);m(xy.$$.fragment,xa),X0r=i(xa),eTe=n(xa,"P",{});var b3t=s(eTe);z0r=r(b3t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),b3t.forEach(t),Q0r=i(xa),Sn=n(xa,"P",{});var O5=s(Sn);W0r=r(O5,"The model class to instantiate is selected based on the "),oTe=n(O5,"CODE",{});var v3t=s(oTe);H0r=r(v3t,"model_type"),v3t.forEach(t),U0r=r(O5,` property of the config object (either
passed as an argument or loaded from `),rTe=n(O5,"CODE",{});var F3t=s(rTe);J0r=r(F3t,"pretrained_model_name_or_path"),F3t.forEach(t),Y0r=r(O5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tTe=n(O5,"CODE",{});var T3t=s(tTe);K0r=r(T3t,"pretrained_model_name_or_path"),T3t.forEach(t),Z0r=r(O5,":"),O5.forEach(t),eAr=i(xa),ca=n(xa,"UL",{});var wi=s(ca);v4=n(wi,"LI",{});var iBe=s(v4);aTe=n(iBe,"STRONG",{});var M3t=s(aTe);oAr=r(M3t,"bart"),M3t.forEach(t),rAr=r(iBe," \u2014 "),SH=n(iBe,"A",{href:!0});var E3t=s(SH);tAr=r(E3t,"FlaxBartForCausalLM"),E3t.forEach(t),aAr=r(iBe," (BART model)"),iBe.forEach(t),nAr=i(wi),F4=n(wi,"LI",{});var dBe=s(F4);nTe=n(dBe,"STRONG",{});var C3t=s(nTe);sAr=r(C3t,"gpt2"),C3t.forEach(t),lAr=r(dBe," \u2014 "),RH=n(dBe,"A",{href:!0});var w3t=s(RH);iAr=r(w3t,"FlaxGPT2LMHeadModel"),w3t.forEach(t),dAr=r(dBe," (OpenAI GPT-2 model)"),dBe.forEach(t),cAr=i(wi),T4=n(wi,"LI",{});var cBe=s(T4);sTe=n(cBe,"STRONG",{});var A3t=s(sTe);fAr=r(A3t,"gpt_neo"),A3t.forEach(t),mAr=r(cBe," \u2014 "),BH=n(cBe,"A",{href:!0});var y3t=s(BH);gAr=r(y3t,"FlaxGPTNeoForCausalLM"),y3t.forEach(t),hAr=r(cBe," (GPT Neo model)"),cBe.forEach(t),pAr=i(wi),M4=n(wi,"LI",{});var fBe=s(M4);lTe=n(fBe,"STRONG",{});var L3t=s(lTe);_Ar=r(L3t,"gptj"),L3t.forEach(t),uAr=r(fBe," \u2014 "),PH=n(fBe,"A",{href:!0});var x3t=s(PH);bAr=r(x3t,"FlaxGPTJForCausalLM"),x3t.forEach(t),vAr=r(fBe," (GPT-J model)"),fBe.forEach(t),FAr=i(wi),E4=n(wi,"LI",{});var mBe=s(E4);iTe=n(mBe,"STRONG",{});var k3t=s(iTe);TAr=r(k3t,"xglm"),k3t.forEach(t),MAr=r(mBe," \u2014 "),$H=n(mBe,"A",{href:!0});var S3t=s($H);EAr=r(S3t,"FlaxXGLMForCausalLM"),S3t.forEach(t),CAr=r(mBe," (XGLM model)"),mBe.forEach(t),wi.forEach(t),wAr=i(xa),dTe=n(xa,"P",{});var R3t=s(dTe);AAr=r(R3t,"Examples:"),R3t.forEach(t),yAr=i(xa),m(ky.$$.fragment,xa),xa.forEach(t),Ei.forEach(t),gIe=i(c),hf=n(c,"H2",{class:!0});var CNe=s(hf);C4=n(CNe,"A",{id:!0,class:!0,href:!0});var B3t=s(C4);cTe=n(B3t,"SPAN",{});var P3t=s(cTe);m(Sy.$$.fragment,P3t),P3t.forEach(t),B3t.forEach(t),LAr=i(CNe),fTe=n(CNe,"SPAN",{});var $3t=s(fTe);xAr=r($3t,"FlaxAutoModelForPreTraining"),$3t.forEach(t),CNe.forEach(t),hIe=i(c),Pr=n(c,"DIV",{class:!0});var Ai=s(Pr);m(Ry.$$.fragment,Ai),kAr=i(Ai),pf=n(Ai,"P",{});var tK=s(pf);SAr=r(tK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),IH=n(tK,"A",{href:!0});var I3t=s(IH);RAr=r(I3t,"from_pretrained()"),I3t.forEach(t),BAr=r(tK," class method or the "),qH=n(tK,"A",{href:!0});var q3t=s(qH);PAr=r(q3t,"from_config()"),q3t.forEach(t),$Ar=r(tK,` class
method.`),tK.forEach(t),IAr=i(Ai),By=n(Ai,"P",{});var wNe=s(By);qAr=r(wNe,"This class cannot be instantiated directly using "),mTe=n(wNe,"CODE",{});var N3t=s(mTe);NAr=r(N3t,"__init__()"),N3t.forEach(t),jAr=r(wNe," (throws an error)."),wNe.forEach(t),DAr=i(Ai),Lt=n(Ai,"DIV",{class:!0});var yi=s(Lt);m(Py.$$.fragment,yi),GAr=i(yi),gTe=n(yi,"P",{});var j3t=s(gTe);OAr=r(j3t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),j3t.forEach(t),VAr=i(yi),_f=n(yi,"P",{});var aK=s(_f);XAr=r(aK,`Note:
Loading a model from its configuration file does `),hTe=n(aK,"STRONG",{});var D3t=s(hTe);zAr=r(D3t,"not"),D3t.forEach(t),QAr=r(aK,` load the model weights. It only affects the
model\u2019s configuration. Use `),NH=n(aK,"A",{href:!0});var G3t=s(NH);WAr=r(G3t,"from_pretrained()"),G3t.forEach(t),HAr=r(aK," to load the model weights."),aK.forEach(t),UAr=i(yi),pTe=n(yi,"P",{});var O3t=s(pTe);JAr=r(O3t,"Examples:"),O3t.forEach(t),YAr=i(yi),m($y.$$.fragment,yi),yi.forEach(t),KAr=i(Ai),ko=n(Ai,"DIV",{class:!0});var ka=s(ko);m(Iy.$$.fragment,ka),ZAr=i(ka),_Te=n(ka,"P",{});var V3t=s(_Te);eyr=r(V3t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),V3t.forEach(t),oyr=i(ka),Rn=n(ka,"P",{});var V5=s(Rn);ryr=r(V5,"The model class to instantiate is selected based on the "),uTe=n(V5,"CODE",{});var X3t=s(uTe);tyr=r(X3t,"model_type"),X3t.forEach(t),ayr=r(V5,` property of the config object (either
passed as an argument or loaded from `),bTe=n(V5,"CODE",{});var z3t=s(bTe);nyr=r(z3t,"pretrained_model_name_or_path"),z3t.forEach(t),syr=r(V5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vTe=n(V5,"CODE",{});var Q3t=s(vTe);lyr=r(Q3t,"pretrained_model_name_or_path"),Q3t.forEach(t),iyr=r(V5,":"),V5.forEach(t),dyr=i(ka),fe=n(ka,"UL",{});var _e=s(fe);w4=n(_e,"LI",{});var gBe=s(w4);FTe=n(gBe,"STRONG",{});var W3t=s(FTe);cyr=r(W3t,"albert"),W3t.forEach(t),fyr=r(gBe," \u2014 "),jH=n(gBe,"A",{href:!0});var H3t=s(jH);myr=r(H3t,"FlaxAlbertForPreTraining"),H3t.forEach(t),gyr=r(gBe," (ALBERT model)"),gBe.forEach(t),hyr=i(_e),A4=n(_e,"LI",{});var hBe=s(A4);TTe=n(hBe,"STRONG",{});var U3t=s(TTe);pyr=r(U3t,"bart"),U3t.forEach(t),_yr=r(hBe," \u2014 "),DH=n(hBe,"A",{href:!0});var J3t=s(DH);uyr=r(J3t,"FlaxBartForConditionalGeneration"),J3t.forEach(t),byr=r(hBe," (BART model)"),hBe.forEach(t),vyr=i(_e),y4=n(_e,"LI",{});var pBe=s(y4);MTe=n(pBe,"STRONG",{});var Y3t=s(MTe);Fyr=r(Y3t,"bert"),Y3t.forEach(t),Tyr=r(pBe," \u2014 "),GH=n(pBe,"A",{href:!0});var K3t=s(GH);Myr=r(K3t,"FlaxBertForPreTraining"),K3t.forEach(t),Eyr=r(pBe," (BERT model)"),pBe.forEach(t),Cyr=i(_e),L4=n(_e,"LI",{});var _Be=s(L4);ETe=n(_Be,"STRONG",{});var Z3t=s(ETe);wyr=r(Z3t,"big_bird"),Z3t.forEach(t),Ayr=r(_Be," \u2014 "),OH=n(_Be,"A",{href:!0});var eCt=s(OH);yyr=r(eCt,"FlaxBigBirdForPreTraining"),eCt.forEach(t),Lyr=r(_Be," (BigBird model)"),_Be.forEach(t),xyr=i(_e),x4=n(_e,"LI",{});var uBe=s(x4);CTe=n(uBe,"STRONG",{});var oCt=s(CTe);kyr=r(oCt,"electra"),oCt.forEach(t),Syr=r(uBe," \u2014 "),VH=n(uBe,"A",{href:!0});var rCt=s(VH);Ryr=r(rCt,"FlaxElectraForPreTraining"),rCt.forEach(t),Byr=r(uBe," (ELECTRA model)"),uBe.forEach(t),Pyr=i(_e),k4=n(_e,"LI",{});var bBe=s(k4);wTe=n(bBe,"STRONG",{});var tCt=s(wTe);$yr=r(tCt,"longt5"),tCt.forEach(t),Iyr=r(bBe," \u2014 "),XH=n(bBe,"A",{href:!0});var aCt=s(XH);qyr=r(aCt,"FlaxLongT5ForConditionalGeneration"),aCt.forEach(t),Nyr=r(bBe," (LongT5 model)"),bBe.forEach(t),jyr=i(_e),S4=n(_e,"LI",{});var vBe=s(S4);ATe=n(vBe,"STRONG",{});var nCt=s(ATe);Dyr=r(nCt,"mbart"),nCt.forEach(t),Gyr=r(vBe," \u2014 "),zH=n(vBe,"A",{href:!0});var sCt=s(zH);Oyr=r(sCt,"FlaxMBartForConditionalGeneration"),sCt.forEach(t),Vyr=r(vBe," (mBART model)"),vBe.forEach(t),Xyr=i(_e),R4=n(_e,"LI",{});var FBe=s(R4);yTe=n(FBe,"STRONG",{});var lCt=s(yTe);zyr=r(lCt,"mt5"),lCt.forEach(t),Qyr=r(FBe," \u2014 "),QH=n(FBe,"A",{href:!0});var iCt=s(QH);Wyr=r(iCt,"FlaxMT5ForConditionalGeneration"),iCt.forEach(t),Hyr=r(FBe," (mT5 model)"),FBe.forEach(t),Uyr=i(_e),B4=n(_e,"LI",{});var TBe=s(B4);LTe=n(TBe,"STRONG",{});var dCt=s(LTe);Jyr=r(dCt,"roberta"),dCt.forEach(t),Yyr=r(TBe," \u2014 "),WH=n(TBe,"A",{href:!0});var cCt=s(WH);Kyr=r(cCt,"FlaxRobertaForMaskedLM"),cCt.forEach(t),Zyr=r(TBe," (RoBERTa model)"),TBe.forEach(t),eLr=i(_e),P4=n(_e,"LI",{});var MBe=s(P4);xTe=n(MBe,"STRONG",{});var fCt=s(xTe);oLr=r(fCt,"roformer"),fCt.forEach(t),rLr=r(MBe," \u2014 "),HH=n(MBe,"A",{href:!0});var mCt=s(HH);tLr=r(mCt,"FlaxRoFormerForMaskedLM"),mCt.forEach(t),aLr=r(MBe," (RoFormer model)"),MBe.forEach(t),nLr=i(_e),$4=n(_e,"LI",{});var EBe=s($4);kTe=n(EBe,"STRONG",{});var gCt=s(kTe);sLr=r(gCt,"t5"),gCt.forEach(t),lLr=r(EBe," \u2014 "),UH=n(EBe,"A",{href:!0});var hCt=s(UH);iLr=r(hCt,"FlaxT5ForConditionalGeneration"),hCt.forEach(t),dLr=r(EBe," (T5 model)"),EBe.forEach(t),cLr=i(_e),I4=n(_e,"LI",{});var CBe=s(I4);STe=n(CBe,"STRONG",{});var pCt=s(STe);fLr=r(pCt,"wav2vec2"),pCt.forEach(t),mLr=r(CBe," \u2014 "),JH=n(CBe,"A",{href:!0});var _Ct=s(JH);gLr=r(_Ct,"FlaxWav2Vec2ForPreTraining"),_Ct.forEach(t),hLr=r(CBe," (Wav2Vec2 model)"),CBe.forEach(t),pLr=i(_e),q4=n(_e,"LI",{});var wBe=s(q4);RTe=n(wBe,"STRONG",{});var uCt=s(RTe);_Lr=r(uCt,"xlm-roberta"),uCt.forEach(t),uLr=r(wBe," \u2014 "),YH=n(wBe,"A",{href:!0});var bCt=s(YH);bLr=r(bCt,"FlaxXLMRobertaForMaskedLM"),bCt.forEach(t),vLr=r(wBe," (XLM-RoBERTa model)"),wBe.forEach(t),_e.forEach(t),FLr=i(ka),BTe=n(ka,"P",{});var vCt=s(BTe);TLr=r(vCt,"Examples:"),vCt.forEach(t),MLr=i(ka),m(qy.$$.fragment,ka),ka.forEach(t),Ai.forEach(t),pIe=i(c),uf=n(c,"H2",{class:!0});var ANe=s(uf);N4=n(ANe,"A",{id:!0,class:!0,href:!0});var FCt=s(N4);PTe=n(FCt,"SPAN",{});var TCt=s(PTe);m(Ny.$$.fragment,TCt),TCt.forEach(t),FCt.forEach(t),ELr=i(ANe),$Te=n(ANe,"SPAN",{});var MCt=s($Te);CLr=r(MCt,"FlaxAutoModelForMaskedLM"),MCt.forEach(t),ANe.forEach(t),_Ie=i(c),$r=n(c,"DIV",{class:!0});var Li=s($r);m(jy.$$.fragment,Li),wLr=i(Li),bf=n(Li,"P",{});var nK=s(bf);ALr=r(nK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),KH=n(nK,"A",{href:!0});var ECt=s(KH);yLr=r(ECt,"from_pretrained()"),ECt.forEach(t),LLr=r(nK," class method or the "),ZH=n(nK,"A",{href:!0});var CCt=s(ZH);xLr=r(CCt,"from_config()"),CCt.forEach(t),kLr=r(nK,` class
method.`),nK.forEach(t),SLr=i(Li),Dy=n(Li,"P",{});var yNe=s(Dy);RLr=r(yNe,"This class cannot be instantiated directly using "),ITe=n(yNe,"CODE",{});var wCt=s(ITe);BLr=r(wCt,"__init__()"),wCt.forEach(t),PLr=r(yNe," (throws an error)."),yNe.forEach(t),$Lr=i(Li),xt=n(Li,"DIV",{class:!0});var xi=s(xt);m(Gy.$$.fragment,xi),ILr=i(xi),qTe=n(xi,"P",{});var ACt=s(qTe);qLr=r(ACt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),ACt.forEach(t),NLr=i(xi),vf=n(xi,"P",{});var sK=s(vf);jLr=r(sK,`Note:
Loading a model from its configuration file does `),NTe=n(sK,"STRONG",{});var yCt=s(NTe);DLr=r(yCt,"not"),yCt.forEach(t),GLr=r(sK,` load the model weights. It only affects the
model\u2019s configuration. Use `),eU=n(sK,"A",{href:!0});var LCt=s(eU);OLr=r(LCt,"from_pretrained()"),LCt.forEach(t),VLr=r(sK," to load the model weights."),sK.forEach(t),XLr=i(xi),jTe=n(xi,"P",{});var xCt=s(jTe);zLr=r(xCt,"Examples:"),xCt.forEach(t),QLr=i(xi),m(Oy.$$.fragment,xi),xi.forEach(t),WLr=i(Li),So=n(Li,"DIV",{class:!0});var Sa=s(So);m(Vy.$$.fragment,Sa),HLr=i(Sa),DTe=n(Sa,"P",{});var kCt=s(DTe);ULr=r(kCt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),kCt.forEach(t),JLr=i(Sa),Bn=n(Sa,"P",{});var X5=s(Bn);YLr=r(X5,"The model class to instantiate is selected based on the "),GTe=n(X5,"CODE",{});var SCt=s(GTe);KLr=r(SCt,"model_type"),SCt.forEach(t),ZLr=r(X5,` property of the config object (either
passed as an argument or loaded from `),OTe=n(X5,"CODE",{});var RCt=s(OTe);e8r=r(RCt,"pretrained_model_name_or_path"),RCt.forEach(t),o8r=r(X5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VTe=n(X5,"CODE",{});var BCt=s(VTe);r8r=r(BCt,"pretrained_model_name_or_path"),BCt.forEach(t),t8r=r(X5,":"),X5.forEach(t),a8r=i(Sa),Te=n(Sa,"UL",{});var Le=s(Te);j4=n(Le,"LI",{});var ABe=s(j4);XTe=n(ABe,"STRONG",{});var PCt=s(XTe);n8r=r(PCt,"albert"),PCt.forEach(t),s8r=r(ABe," \u2014 "),oU=n(ABe,"A",{href:!0});var $Ct=s(oU);l8r=r($Ct,"FlaxAlbertForMaskedLM"),$Ct.forEach(t),i8r=r(ABe," (ALBERT model)"),ABe.forEach(t),d8r=i(Le),D4=n(Le,"LI",{});var yBe=s(D4);zTe=n(yBe,"STRONG",{});var ICt=s(zTe);c8r=r(ICt,"bart"),ICt.forEach(t),f8r=r(yBe," \u2014 "),rU=n(yBe,"A",{href:!0});var qCt=s(rU);m8r=r(qCt,"FlaxBartForConditionalGeneration"),qCt.forEach(t),g8r=r(yBe," (BART model)"),yBe.forEach(t),h8r=i(Le),G4=n(Le,"LI",{});var LBe=s(G4);QTe=n(LBe,"STRONG",{});var NCt=s(QTe);p8r=r(NCt,"bert"),NCt.forEach(t),_8r=r(LBe," \u2014 "),tU=n(LBe,"A",{href:!0});var jCt=s(tU);u8r=r(jCt,"FlaxBertForMaskedLM"),jCt.forEach(t),b8r=r(LBe," (BERT model)"),LBe.forEach(t),v8r=i(Le),O4=n(Le,"LI",{});var xBe=s(O4);WTe=n(xBe,"STRONG",{});var DCt=s(WTe);F8r=r(DCt,"big_bird"),DCt.forEach(t),T8r=r(xBe," \u2014 "),aU=n(xBe,"A",{href:!0});var GCt=s(aU);M8r=r(GCt,"FlaxBigBirdForMaskedLM"),GCt.forEach(t),E8r=r(xBe," (BigBird model)"),xBe.forEach(t),C8r=i(Le),V4=n(Le,"LI",{});var kBe=s(V4);HTe=n(kBe,"STRONG",{});var OCt=s(HTe);w8r=r(OCt,"distilbert"),OCt.forEach(t),A8r=r(kBe," \u2014 "),nU=n(kBe,"A",{href:!0});var VCt=s(nU);y8r=r(VCt,"FlaxDistilBertForMaskedLM"),VCt.forEach(t),L8r=r(kBe," (DistilBERT model)"),kBe.forEach(t),x8r=i(Le),X4=n(Le,"LI",{});var SBe=s(X4);UTe=n(SBe,"STRONG",{});var XCt=s(UTe);k8r=r(XCt,"electra"),XCt.forEach(t),S8r=r(SBe," \u2014 "),sU=n(SBe,"A",{href:!0});var zCt=s(sU);R8r=r(zCt,"FlaxElectraForMaskedLM"),zCt.forEach(t),B8r=r(SBe," (ELECTRA model)"),SBe.forEach(t),P8r=i(Le),z4=n(Le,"LI",{});var RBe=s(z4);JTe=n(RBe,"STRONG",{});var QCt=s(JTe);$8r=r(QCt,"mbart"),QCt.forEach(t),I8r=r(RBe," \u2014 "),lU=n(RBe,"A",{href:!0});var WCt=s(lU);q8r=r(WCt,"FlaxMBartForConditionalGeneration"),WCt.forEach(t),N8r=r(RBe," (mBART model)"),RBe.forEach(t),j8r=i(Le),Q4=n(Le,"LI",{});var BBe=s(Q4);YTe=n(BBe,"STRONG",{});var HCt=s(YTe);D8r=r(HCt,"roberta"),HCt.forEach(t),G8r=r(BBe," \u2014 "),iU=n(BBe,"A",{href:!0});var UCt=s(iU);O8r=r(UCt,"FlaxRobertaForMaskedLM"),UCt.forEach(t),V8r=r(BBe," (RoBERTa model)"),BBe.forEach(t),X8r=i(Le),W4=n(Le,"LI",{});var PBe=s(W4);KTe=n(PBe,"STRONG",{});var JCt=s(KTe);z8r=r(JCt,"roformer"),JCt.forEach(t),Q8r=r(PBe," \u2014 "),dU=n(PBe,"A",{href:!0});var YCt=s(dU);W8r=r(YCt,"FlaxRoFormerForMaskedLM"),YCt.forEach(t),H8r=r(PBe," (RoFormer model)"),PBe.forEach(t),U8r=i(Le),H4=n(Le,"LI",{});var $Be=s(H4);ZTe=n($Be,"STRONG",{});var KCt=s(ZTe);J8r=r(KCt,"xlm-roberta"),KCt.forEach(t),Y8r=r($Be," \u2014 "),cU=n($Be,"A",{href:!0});var ZCt=s(cU);K8r=r(ZCt,"FlaxXLMRobertaForMaskedLM"),ZCt.forEach(t),Z8r=r($Be," (XLM-RoBERTa model)"),$Be.forEach(t),Le.forEach(t),exr=i(Sa),e7e=n(Sa,"P",{});var ewt=s(e7e);oxr=r(ewt,"Examples:"),ewt.forEach(t),rxr=i(Sa),m(Xy.$$.fragment,Sa),Sa.forEach(t),Li.forEach(t),uIe=i(c),Ff=n(c,"H2",{class:!0});var LNe=s(Ff);U4=n(LNe,"A",{id:!0,class:!0,href:!0});var owt=s(U4);o7e=n(owt,"SPAN",{});var rwt=s(o7e);m(zy.$$.fragment,rwt),rwt.forEach(t),owt.forEach(t),txr=i(LNe),r7e=n(LNe,"SPAN",{});var twt=s(r7e);axr=r(twt,"FlaxAutoModelForSeq2SeqLM"),twt.forEach(t),LNe.forEach(t),bIe=i(c),Ir=n(c,"DIV",{class:!0});var ki=s(Ir);m(Qy.$$.fragment,ki),nxr=i(ki),Tf=n(ki,"P",{});var lK=s(Tf);sxr=r(lK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),fU=n(lK,"A",{href:!0});var awt=s(fU);lxr=r(awt,"from_pretrained()"),awt.forEach(t),ixr=r(lK," class method or the "),mU=n(lK,"A",{href:!0});var nwt=s(mU);dxr=r(nwt,"from_config()"),nwt.forEach(t),cxr=r(lK,` class
method.`),lK.forEach(t),fxr=i(ki),Wy=n(ki,"P",{});var xNe=s(Wy);mxr=r(xNe,"This class cannot be instantiated directly using "),t7e=n(xNe,"CODE",{});var swt=s(t7e);gxr=r(swt,"__init__()"),swt.forEach(t),hxr=r(xNe," (throws an error)."),xNe.forEach(t),pxr=i(ki),kt=n(ki,"DIV",{class:!0});var Si=s(kt);m(Hy.$$.fragment,Si),_xr=i(Si),a7e=n(Si,"P",{});var lwt=s(a7e);uxr=r(lwt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),lwt.forEach(t),bxr=i(Si),Mf=n(Si,"P",{});var iK=s(Mf);vxr=r(iK,`Note:
Loading a model from its configuration file does `),n7e=n(iK,"STRONG",{});var iwt=s(n7e);Fxr=r(iwt,"not"),iwt.forEach(t),Txr=r(iK,` load the model weights. It only affects the
model\u2019s configuration. Use `),gU=n(iK,"A",{href:!0});var dwt=s(gU);Mxr=r(dwt,"from_pretrained()"),dwt.forEach(t),Exr=r(iK," to load the model weights."),iK.forEach(t),Cxr=i(Si),s7e=n(Si,"P",{});var cwt=s(s7e);wxr=r(cwt,"Examples:"),cwt.forEach(t),Axr=i(Si),m(Uy.$$.fragment,Si),Si.forEach(t),yxr=i(ki),Ro=n(ki,"DIV",{class:!0});var Ra=s(Ro);m(Jy.$$.fragment,Ra),Lxr=i(Ra),l7e=n(Ra,"P",{});var fwt=s(l7e);xxr=r(fwt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),fwt.forEach(t),kxr=i(Ra),Pn=n(Ra,"P",{});var z5=s(Pn);Sxr=r(z5,"The model class to instantiate is selected based on the "),i7e=n(z5,"CODE",{});var mwt=s(i7e);Rxr=r(mwt,"model_type"),mwt.forEach(t),Bxr=r(z5,` property of the config object (either
passed as an argument or loaded from `),d7e=n(z5,"CODE",{});var gwt=s(d7e);Pxr=r(gwt,"pretrained_model_name_or_path"),gwt.forEach(t),$xr=r(z5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c7e=n(z5,"CODE",{});var hwt=s(c7e);Ixr=r(hwt,"pretrained_model_name_or_path"),hwt.forEach(t),qxr=r(z5,":"),z5.forEach(t),Nxr=i(Ra),Me=n(Ra,"UL",{});var xe=s(Me);J4=n(xe,"LI",{});var IBe=s(J4);f7e=n(IBe,"STRONG",{});var pwt=s(f7e);jxr=r(pwt,"bart"),pwt.forEach(t),Dxr=r(IBe," \u2014 "),hU=n(IBe,"A",{href:!0});var _wt=s(hU);Gxr=r(_wt,"FlaxBartForConditionalGeneration"),_wt.forEach(t),Oxr=r(IBe," (BART model)"),IBe.forEach(t),Vxr=i(xe),Y4=n(xe,"LI",{});var qBe=s(Y4);m7e=n(qBe,"STRONG",{});var uwt=s(m7e);Xxr=r(uwt,"blenderbot"),uwt.forEach(t),zxr=r(qBe," \u2014 "),pU=n(qBe,"A",{href:!0});var bwt=s(pU);Qxr=r(bwt,"FlaxBlenderbotForConditionalGeneration"),bwt.forEach(t),Wxr=r(qBe," (Blenderbot model)"),qBe.forEach(t),Hxr=i(xe),K4=n(xe,"LI",{});var NBe=s(K4);g7e=n(NBe,"STRONG",{});var vwt=s(g7e);Uxr=r(vwt,"blenderbot-small"),vwt.forEach(t),Jxr=r(NBe," \u2014 "),_U=n(NBe,"A",{href:!0});var Fwt=s(_U);Yxr=r(Fwt,"FlaxBlenderbotSmallForConditionalGeneration"),Fwt.forEach(t),Kxr=r(NBe," (BlenderbotSmall model)"),NBe.forEach(t),Zxr=i(xe),Z4=n(xe,"LI",{});var jBe=s(Z4);h7e=n(jBe,"STRONG",{});var Twt=s(h7e);ekr=r(Twt,"encoder-decoder"),Twt.forEach(t),okr=r(jBe," \u2014 "),uU=n(jBe,"A",{href:!0});var Mwt=s(uU);rkr=r(Mwt,"FlaxEncoderDecoderModel"),Mwt.forEach(t),tkr=r(jBe," (Encoder decoder model)"),jBe.forEach(t),akr=i(xe),eE=n(xe,"LI",{});var DBe=s(eE);p7e=n(DBe,"STRONG",{});var Ewt=s(p7e);nkr=r(Ewt,"longt5"),Ewt.forEach(t),skr=r(DBe," \u2014 "),bU=n(DBe,"A",{href:!0});var Cwt=s(bU);lkr=r(Cwt,"FlaxLongT5ForConditionalGeneration"),Cwt.forEach(t),ikr=r(DBe," (LongT5 model)"),DBe.forEach(t),dkr=i(xe),oE=n(xe,"LI",{});var GBe=s(oE);_7e=n(GBe,"STRONG",{});var wwt=s(_7e);ckr=r(wwt,"marian"),wwt.forEach(t),fkr=r(GBe," \u2014 "),vU=n(GBe,"A",{href:!0});var Awt=s(vU);mkr=r(Awt,"FlaxMarianMTModel"),Awt.forEach(t),gkr=r(GBe," (Marian model)"),GBe.forEach(t),hkr=i(xe),rE=n(xe,"LI",{});var OBe=s(rE);u7e=n(OBe,"STRONG",{});var ywt=s(u7e);pkr=r(ywt,"mbart"),ywt.forEach(t),_kr=r(OBe," \u2014 "),FU=n(OBe,"A",{href:!0});var Lwt=s(FU);ukr=r(Lwt,"FlaxMBartForConditionalGeneration"),Lwt.forEach(t),bkr=r(OBe," (mBART model)"),OBe.forEach(t),vkr=i(xe),tE=n(xe,"LI",{});var VBe=s(tE);b7e=n(VBe,"STRONG",{});var xwt=s(b7e);Fkr=r(xwt,"mt5"),xwt.forEach(t),Tkr=r(VBe," \u2014 "),TU=n(VBe,"A",{href:!0});var kwt=s(TU);Mkr=r(kwt,"FlaxMT5ForConditionalGeneration"),kwt.forEach(t),Ekr=r(VBe," (mT5 model)"),VBe.forEach(t),Ckr=i(xe),aE=n(xe,"LI",{});var XBe=s(aE);v7e=n(XBe,"STRONG",{});var Swt=s(v7e);wkr=r(Swt,"pegasus"),Swt.forEach(t),Akr=r(XBe," \u2014 "),MU=n(XBe,"A",{href:!0});var Rwt=s(MU);ykr=r(Rwt,"FlaxPegasusForConditionalGeneration"),Rwt.forEach(t),Lkr=r(XBe," (Pegasus model)"),XBe.forEach(t),xkr=i(xe),nE=n(xe,"LI",{});var zBe=s(nE);F7e=n(zBe,"STRONG",{});var Bwt=s(F7e);kkr=r(Bwt,"t5"),Bwt.forEach(t),Skr=r(zBe," \u2014 "),EU=n(zBe,"A",{href:!0});var Pwt=s(EU);Rkr=r(Pwt,"FlaxT5ForConditionalGeneration"),Pwt.forEach(t),Bkr=r(zBe," (T5 model)"),zBe.forEach(t),xe.forEach(t),Pkr=i(Ra),T7e=n(Ra,"P",{});var $wt=s(T7e);$kr=r($wt,"Examples:"),$wt.forEach(t),Ikr=i(Ra),m(Yy.$$.fragment,Ra),Ra.forEach(t),ki.forEach(t),vIe=i(c),Ef=n(c,"H2",{class:!0});var kNe=s(Ef);sE=n(kNe,"A",{id:!0,class:!0,href:!0});var Iwt=s(sE);M7e=n(Iwt,"SPAN",{});var qwt=s(M7e);m(Ky.$$.fragment,qwt),qwt.forEach(t),Iwt.forEach(t),qkr=i(kNe),E7e=n(kNe,"SPAN",{});var Nwt=s(E7e);Nkr=r(Nwt,"FlaxAutoModelForSequenceClassification"),Nwt.forEach(t),kNe.forEach(t),FIe=i(c),qr=n(c,"DIV",{class:!0});var Ri=s(qr);m(Zy.$$.fragment,Ri),jkr=i(Ri),Cf=n(Ri,"P",{});var dK=s(Cf);Dkr=r(dK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),CU=n(dK,"A",{href:!0});var jwt=s(CU);Gkr=r(jwt,"from_pretrained()"),jwt.forEach(t),Okr=r(dK," class method or the "),wU=n(dK,"A",{href:!0});var Dwt=s(wU);Vkr=r(Dwt,"from_config()"),Dwt.forEach(t),Xkr=r(dK,` class
method.`),dK.forEach(t),zkr=i(Ri),eL=n(Ri,"P",{});var SNe=s(eL);Qkr=r(SNe,"This class cannot be instantiated directly using "),C7e=n(SNe,"CODE",{});var Gwt=s(C7e);Wkr=r(Gwt,"__init__()"),Gwt.forEach(t),Hkr=r(SNe," (throws an error)."),SNe.forEach(t),Ukr=i(Ri),St=n(Ri,"DIV",{class:!0});var Bi=s(St);m(oL.$$.fragment,Bi),Jkr=i(Bi),w7e=n(Bi,"P",{});var Owt=s(w7e);Ykr=r(Owt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Owt.forEach(t),Kkr=i(Bi),wf=n(Bi,"P",{});var cK=s(wf);Zkr=r(cK,`Note:
Loading a model from its configuration file does `),A7e=n(cK,"STRONG",{});var Vwt=s(A7e);eSr=r(Vwt,"not"),Vwt.forEach(t),oSr=r(cK,` load the model weights. It only affects the
model\u2019s configuration. Use `),AU=n(cK,"A",{href:!0});var Xwt=s(AU);rSr=r(Xwt,"from_pretrained()"),Xwt.forEach(t),tSr=r(cK," to load the model weights."),cK.forEach(t),aSr=i(Bi),y7e=n(Bi,"P",{});var zwt=s(y7e);nSr=r(zwt,"Examples:"),zwt.forEach(t),sSr=i(Bi),m(rL.$$.fragment,Bi),Bi.forEach(t),lSr=i(Ri),Bo=n(Ri,"DIV",{class:!0});var Ba=s(Bo);m(tL.$$.fragment,Ba),iSr=i(Ba),L7e=n(Ba,"P",{});var Qwt=s(L7e);dSr=r(Qwt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Qwt.forEach(t),cSr=i(Ba),$n=n(Ba,"P",{});var Q5=s($n);fSr=r(Q5,"The model class to instantiate is selected based on the "),x7e=n(Q5,"CODE",{});var Wwt=s(x7e);mSr=r(Wwt,"model_type"),Wwt.forEach(t),gSr=r(Q5,` property of the config object (either
passed as an argument or loaded from `),k7e=n(Q5,"CODE",{});var Hwt=s(k7e);hSr=r(Hwt,"pretrained_model_name_or_path"),Hwt.forEach(t),pSr=r(Q5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S7e=n(Q5,"CODE",{});var Uwt=s(S7e);_Sr=r(Uwt,"pretrained_model_name_or_path"),Uwt.forEach(t),uSr=r(Q5,":"),Q5.forEach(t),bSr=i(Ba),Ee=n(Ba,"UL",{});var ke=s(Ee);lE=n(ke,"LI",{});var QBe=s(lE);R7e=n(QBe,"STRONG",{});var Jwt=s(R7e);vSr=r(Jwt,"albert"),Jwt.forEach(t),FSr=r(QBe," \u2014 "),yU=n(QBe,"A",{href:!0});var Ywt=s(yU);TSr=r(Ywt,"FlaxAlbertForSequenceClassification"),Ywt.forEach(t),MSr=r(QBe," (ALBERT model)"),QBe.forEach(t),ESr=i(ke),iE=n(ke,"LI",{});var WBe=s(iE);B7e=n(WBe,"STRONG",{});var Kwt=s(B7e);CSr=r(Kwt,"bart"),Kwt.forEach(t),wSr=r(WBe," \u2014 "),LU=n(WBe,"A",{href:!0});var Zwt=s(LU);ASr=r(Zwt,"FlaxBartForSequenceClassification"),Zwt.forEach(t),ySr=r(WBe," (BART model)"),WBe.forEach(t),LSr=i(ke),dE=n(ke,"LI",{});var HBe=s(dE);P7e=n(HBe,"STRONG",{});var e0t=s(P7e);xSr=r(e0t,"bert"),e0t.forEach(t),kSr=r(HBe," \u2014 "),xU=n(HBe,"A",{href:!0});var o0t=s(xU);SSr=r(o0t,"FlaxBertForSequenceClassification"),o0t.forEach(t),RSr=r(HBe," (BERT model)"),HBe.forEach(t),BSr=i(ke),cE=n(ke,"LI",{});var UBe=s(cE);$7e=n(UBe,"STRONG",{});var r0t=s($7e);PSr=r(r0t,"big_bird"),r0t.forEach(t),$Sr=r(UBe," \u2014 "),kU=n(UBe,"A",{href:!0});var t0t=s(kU);ISr=r(t0t,"FlaxBigBirdForSequenceClassification"),t0t.forEach(t),qSr=r(UBe," (BigBird model)"),UBe.forEach(t),NSr=i(ke),fE=n(ke,"LI",{});var JBe=s(fE);I7e=n(JBe,"STRONG",{});var a0t=s(I7e);jSr=r(a0t,"distilbert"),a0t.forEach(t),DSr=r(JBe," \u2014 "),SU=n(JBe,"A",{href:!0});var n0t=s(SU);GSr=r(n0t,"FlaxDistilBertForSequenceClassification"),n0t.forEach(t),OSr=r(JBe," (DistilBERT model)"),JBe.forEach(t),VSr=i(ke),mE=n(ke,"LI",{});var YBe=s(mE);q7e=n(YBe,"STRONG",{});var s0t=s(q7e);XSr=r(s0t,"electra"),s0t.forEach(t),zSr=r(YBe," \u2014 "),RU=n(YBe,"A",{href:!0});var l0t=s(RU);QSr=r(l0t,"FlaxElectraForSequenceClassification"),l0t.forEach(t),WSr=r(YBe," (ELECTRA model)"),YBe.forEach(t),HSr=i(ke),gE=n(ke,"LI",{});var KBe=s(gE);N7e=n(KBe,"STRONG",{});var i0t=s(N7e);USr=r(i0t,"mbart"),i0t.forEach(t),JSr=r(KBe," \u2014 "),BU=n(KBe,"A",{href:!0});var d0t=s(BU);YSr=r(d0t,"FlaxMBartForSequenceClassification"),d0t.forEach(t),KSr=r(KBe," (mBART model)"),KBe.forEach(t),ZSr=i(ke),hE=n(ke,"LI",{});var ZBe=s(hE);j7e=n(ZBe,"STRONG",{});var c0t=s(j7e);eRr=r(c0t,"roberta"),c0t.forEach(t),oRr=r(ZBe," \u2014 "),PU=n(ZBe,"A",{href:!0});var f0t=s(PU);rRr=r(f0t,"FlaxRobertaForSequenceClassification"),f0t.forEach(t),tRr=r(ZBe," (RoBERTa model)"),ZBe.forEach(t),aRr=i(ke),pE=n(ke,"LI",{});var ePe=s(pE);D7e=n(ePe,"STRONG",{});var m0t=s(D7e);nRr=r(m0t,"roformer"),m0t.forEach(t),sRr=r(ePe," \u2014 "),$U=n(ePe,"A",{href:!0});var g0t=s($U);lRr=r(g0t,"FlaxRoFormerForSequenceClassification"),g0t.forEach(t),iRr=r(ePe," (RoFormer model)"),ePe.forEach(t),dRr=i(ke),_E=n(ke,"LI",{});var oPe=s(_E);G7e=n(oPe,"STRONG",{});var h0t=s(G7e);cRr=r(h0t,"xlm-roberta"),h0t.forEach(t),fRr=r(oPe," \u2014 "),IU=n(oPe,"A",{href:!0});var p0t=s(IU);mRr=r(p0t,"FlaxXLMRobertaForSequenceClassification"),p0t.forEach(t),gRr=r(oPe," (XLM-RoBERTa model)"),oPe.forEach(t),ke.forEach(t),hRr=i(Ba),O7e=n(Ba,"P",{});var _0t=s(O7e);pRr=r(_0t,"Examples:"),_0t.forEach(t),_Rr=i(Ba),m(aL.$$.fragment,Ba),Ba.forEach(t),Ri.forEach(t),TIe=i(c),Af=n(c,"H2",{class:!0});var RNe=s(Af);uE=n(RNe,"A",{id:!0,class:!0,href:!0});var u0t=s(uE);V7e=n(u0t,"SPAN",{});var b0t=s(V7e);m(nL.$$.fragment,b0t),b0t.forEach(t),u0t.forEach(t),uRr=i(RNe),X7e=n(RNe,"SPAN",{});var v0t=s(X7e);bRr=r(v0t,"FlaxAutoModelForQuestionAnswering"),v0t.forEach(t),RNe.forEach(t),MIe=i(c),Nr=n(c,"DIV",{class:!0});var Pi=s(Nr);m(sL.$$.fragment,Pi),vRr=i(Pi),yf=n(Pi,"P",{});var fK=s(yf);FRr=r(fK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),qU=n(fK,"A",{href:!0});var F0t=s(qU);TRr=r(F0t,"from_pretrained()"),F0t.forEach(t),MRr=r(fK," class method or the "),NU=n(fK,"A",{href:!0});var T0t=s(NU);ERr=r(T0t,"from_config()"),T0t.forEach(t),CRr=r(fK,` class
method.`),fK.forEach(t),wRr=i(Pi),lL=n(Pi,"P",{});var BNe=s(lL);ARr=r(BNe,"This class cannot be instantiated directly using "),z7e=n(BNe,"CODE",{});var M0t=s(z7e);yRr=r(M0t,"__init__()"),M0t.forEach(t),LRr=r(BNe," (throws an error)."),BNe.forEach(t),xRr=i(Pi),Rt=n(Pi,"DIV",{class:!0});var $i=s(Rt);m(iL.$$.fragment,$i),kRr=i($i),Q7e=n($i,"P",{});var E0t=s(Q7e);SRr=r(E0t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),E0t.forEach(t),RRr=i($i),Lf=n($i,"P",{});var mK=s(Lf);BRr=r(mK,`Note:
Loading a model from its configuration file does `),W7e=n(mK,"STRONG",{});var C0t=s(W7e);PRr=r(C0t,"not"),C0t.forEach(t),$Rr=r(mK,` load the model weights. It only affects the
model\u2019s configuration. Use `),jU=n(mK,"A",{href:!0});var w0t=s(jU);IRr=r(w0t,"from_pretrained()"),w0t.forEach(t),qRr=r(mK," to load the model weights."),mK.forEach(t),NRr=i($i),H7e=n($i,"P",{});var A0t=s(H7e);jRr=r(A0t,"Examples:"),A0t.forEach(t),DRr=i($i),m(dL.$$.fragment,$i),$i.forEach(t),GRr=i(Pi),Po=n(Pi,"DIV",{class:!0});var Pa=s(Po);m(cL.$$.fragment,Pa),ORr=i(Pa),U7e=n(Pa,"P",{});var y0t=s(U7e);VRr=r(y0t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),y0t.forEach(t),XRr=i(Pa),In=n(Pa,"P",{});var W5=s(In);zRr=r(W5,"The model class to instantiate is selected based on the "),J7e=n(W5,"CODE",{});var L0t=s(J7e);QRr=r(L0t,"model_type"),L0t.forEach(t),WRr=r(W5,` property of the config object (either
passed as an argument or loaded from `),Y7e=n(W5,"CODE",{});var x0t=s(Y7e);HRr=r(x0t,"pretrained_model_name_or_path"),x0t.forEach(t),URr=r(W5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K7e=n(W5,"CODE",{});var k0t=s(K7e);JRr=r(k0t,"pretrained_model_name_or_path"),k0t.forEach(t),YRr=r(W5,":"),W5.forEach(t),KRr=i(Pa),Ce=n(Pa,"UL",{});var Se=s(Ce);bE=n(Se,"LI",{});var rPe=s(bE);Z7e=n(rPe,"STRONG",{});var S0t=s(Z7e);ZRr=r(S0t,"albert"),S0t.forEach(t),eBr=r(rPe," \u2014 "),DU=n(rPe,"A",{href:!0});var R0t=s(DU);oBr=r(R0t,"FlaxAlbertForQuestionAnswering"),R0t.forEach(t),rBr=r(rPe," (ALBERT model)"),rPe.forEach(t),tBr=i(Se),vE=n(Se,"LI",{});var tPe=s(vE);e9e=n(tPe,"STRONG",{});var B0t=s(e9e);aBr=r(B0t,"bart"),B0t.forEach(t),nBr=r(tPe," \u2014 "),GU=n(tPe,"A",{href:!0});var P0t=s(GU);sBr=r(P0t,"FlaxBartForQuestionAnswering"),P0t.forEach(t),lBr=r(tPe," (BART model)"),tPe.forEach(t),iBr=i(Se),FE=n(Se,"LI",{});var aPe=s(FE);o9e=n(aPe,"STRONG",{});var $0t=s(o9e);dBr=r($0t,"bert"),$0t.forEach(t),cBr=r(aPe," \u2014 "),OU=n(aPe,"A",{href:!0});var I0t=s(OU);fBr=r(I0t,"FlaxBertForQuestionAnswering"),I0t.forEach(t),mBr=r(aPe," (BERT model)"),aPe.forEach(t),gBr=i(Se),TE=n(Se,"LI",{});var nPe=s(TE);r9e=n(nPe,"STRONG",{});var q0t=s(r9e);hBr=r(q0t,"big_bird"),q0t.forEach(t),pBr=r(nPe," \u2014 "),VU=n(nPe,"A",{href:!0});var N0t=s(VU);_Br=r(N0t,"FlaxBigBirdForQuestionAnswering"),N0t.forEach(t),uBr=r(nPe," (BigBird model)"),nPe.forEach(t),bBr=i(Se),ME=n(Se,"LI",{});var sPe=s(ME);t9e=n(sPe,"STRONG",{});var j0t=s(t9e);vBr=r(j0t,"distilbert"),j0t.forEach(t),FBr=r(sPe," \u2014 "),XU=n(sPe,"A",{href:!0});var D0t=s(XU);TBr=r(D0t,"FlaxDistilBertForQuestionAnswering"),D0t.forEach(t),MBr=r(sPe," (DistilBERT model)"),sPe.forEach(t),EBr=i(Se),EE=n(Se,"LI",{});var lPe=s(EE);a9e=n(lPe,"STRONG",{});var G0t=s(a9e);CBr=r(G0t,"electra"),G0t.forEach(t),wBr=r(lPe," \u2014 "),zU=n(lPe,"A",{href:!0});var O0t=s(zU);ABr=r(O0t,"FlaxElectraForQuestionAnswering"),O0t.forEach(t),yBr=r(lPe," (ELECTRA model)"),lPe.forEach(t),LBr=i(Se),CE=n(Se,"LI",{});var iPe=s(CE);n9e=n(iPe,"STRONG",{});var V0t=s(n9e);xBr=r(V0t,"mbart"),V0t.forEach(t),kBr=r(iPe," \u2014 "),QU=n(iPe,"A",{href:!0});var X0t=s(QU);SBr=r(X0t,"FlaxMBartForQuestionAnswering"),X0t.forEach(t),RBr=r(iPe," (mBART model)"),iPe.forEach(t),BBr=i(Se),wE=n(Se,"LI",{});var dPe=s(wE);s9e=n(dPe,"STRONG",{});var z0t=s(s9e);PBr=r(z0t,"roberta"),z0t.forEach(t),$Br=r(dPe," \u2014 "),WU=n(dPe,"A",{href:!0});var Q0t=s(WU);IBr=r(Q0t,"FlaxRobertaForQuestionAnswering"),Q0t.forEach(t),qBr=r(dPe," (RoBERTa model)"),dPe.forEach(t),NBr=i(Se),AE=n(Se,"LI",{});var cPe=s(AE);l9e=n(cPe,"STRONG",{});var W0t=s(l9e);jBr=r(W0t,"roformer"),W0t.forEach(t),DBr=r(cPe," \u2014 "),HU=n(cPe,"A",{href:!0});var H0t=s(HU);GBr=r(H0t,"FlaxRoFormerForQuestionAnswering"),H0t.forEach(t),OBr=r(cPe," (RoFormer model)"),cPe.forEach(t),VBr=i(Se),yE=n(Se,"LI",{});var fPe=s(yE);i9e=n(fPe,"STRONG",{});var U0t=s(i9e);XBr=r(U0t,"xlm-roberta"),U0t.forEach(t),zBr=r(fPe," \u2014 "),UU=n(fPe,"A",{href:!0});var J0t=s(UU);QBr=r(J0t,"FlaxXLMRobertaForQuestionAnswering"),J0t.forEach(t),WBr=r(fPe," (XLM-RoBERTa model)"),fPe.forEach(t),Se.forEach(t),HBr=i(Pa),d9e=n(Pa,"P",{});var Y0t=s(d9e);UBr=r(Y0t,"Examples:"),Y0t.forEach(t),JBr=i(Pa),m(fL.$$.fragment,Pa),Pa.forEach(t),Pi.forEach(t),EIe=i(c),xf=n(c,"H2",{class:!0});var PNe=s(xf);LE=n(PNe,"A",{id:!0,class:!0,href:!0});var K0t=s(LE);c9e=n(K0t,"SPAN",{});var Z0t=s(c9e);m(mL.$$.fragment,Z0t),Z0t.forEach(t),K0t.forEach(t),YBr=i(PNe),f9e=n(PNe,"SPAN",{});var eAt=s(f9e);KBr=r(eAt,"FlaxAutoModelForTokenClassification"),eAt.forEach(t),PNe.forEach(t),CIe=i(c),jr=n(c,"DIV",{class:!0});var Ii=s(jr);m(gL.$$.fragment,Ii),ZBr=i(Ii),kf=n(Ii,"P",{});var gK=s(kf);ePr=r(gK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),JU=n(gK,"A",{href:!0});var oAt=s(JU);oPr=r(oAt,"from_pretrained()"),oAt.forEach(t),rPr=r(gK," class method or the "),YU=n(gK,"A",{href:!0});var rAt=s(YU);tPr=r(rAt,"from_config()"),rAt.forEach(t),aPr=r(gK,` class
method.`),gK.forEach(t),nPr=i(Ii),hL=n(Ii,"P",{});var $Ne=s(hL);sPr=r($Ne,"This class cannot be instantiated directly using "),m9e=n($Ne,"CODE",{});var tAt=s(m9e);lPr=r(tAt,"__init__()"),tAt.forEach(t),iPr=r($Ne," (throws an error)."),$Ne.forEach(t),dPr=i(Ii),Bt=n(Ii,"DIV",{class:!0});var qi=s(Bt);m(pL.$$.fragment,qi),cPr=i(qi),g9e=n(qi,"P",{});var aAt=s(g9e);fPr=r(aAt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),aAt.forEach(t),mPr=i(qi),Sf=n(qi,"P",{});var hK=s(Sf);gPr=r(hK,`Note:
Loading a model from its configuration file does `),h9e=n(hK,"STRONG",{});var nAt=s(h9e);hPr=r(nAt,"not"),nAt.forEach(t),pPr=r(hK,` load the model weights. It only affects the
model\u2019s configuration. Use `),KU=n(hK,"A",{href:!0});var sAt=s(KU);_Pr=r(sAt,"from_pretrained()"),sAt.forEach(t),uPr=r(hK," to load the model weights."),hK.forEach(t),bPr=i(qi),p9e=n(qi,"P",{});var lAt=s(p9e);vPr=r(lAt,"Examples:"),lAt.forEach(t),FPr=i(qi),m(_L.$$.fragment,qi),qi.forEach(t),TPr=i(Ii),$o=n(Ii,"DIV",{class:!0});var $a=s($o);m(uL.$$.fragment,$a),MPr=i($a),_9e=n($a,"P",{});var iAt=s(_9e);EPr=r(iAt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),iAt.forEach(t),CPr=i($a),qn=n($a,"P",{});var H5=s(qn);wPr=r(H5,"The model class to instantiate is selected based on the "),u9e=n(H5,"CODE",{});var dAt=s(u9e);APr=r(dAt,"model_type"),dAt.forEach(t),yPr=r(H5,` property of the config object (either
passed as an argument or loaded from `),b9e=n(H5,"CODE",{});var cAt=s(b9e);LPr=r(cAt,"pretrained_model_name_or_path"),cAt.forEach(t),xPr=r(H5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v9e=n(H5,"CODE",{});var fAt=s(v9e);kPr=r(fAt,"pretrained_model_name_or_path"),fAt.forEach(t),SPr=r(H5,":"),H5.forEach(t),RPr=i($a),$e=n($a,"UL",{});var Oo=s($e);xE=n(Oo,"LI",{});var mPe=s(xE);F9e=n(mPe,"STRONG",{});var mAt=s(F9e);BPr=r(mAt,"albert"),mAt.forEach(t),PPr=r(mPe," \u2014 "),ZU=n(mPe,"A",{href:!0});var gAt=s(ZU);$Pr=r(gAt,"FlaxAlbertForTokenClassification"),gAt.forEach(t),IPr=r(mPe," (ALBERT model)"),mPe.forEach(t),qPr=i(Oo),kE=n(Oo,"LI",{});var gPe=s(kE);T9e=n(gPe,"STRONG",{});var hAt=s(T9e);NPr=r(hAt,"bert"),hAt.forEach(t),jPr=r(gPe," \u2014 "),eJ=n(gPe,"A",{href:!0});var pAt=s(eJ);DPr=r(pAt,"FlaxBertForTokenClassification"),pAt.forEach(t),GPr=r(gPe," (BERT model)"),gPe.forEach(t),OPr=i(Oo),SE=n(Oo,"LI",{});var hPe=s(SE);M9e=n(hPe,"STRONG",{});var _At=s(M9e);VPr=r(_At,"big_bird"),_At.forEach(t),XPr=r(hPe," \u2014 "),oJ=n(hPe,"A",{href:!0});var uAt=s(oJ);zPr=r(uAt,"FlaxBigBirdForTokenClassification"),uAt.forEach(t),QPr=r(hPe," (BigBird model)"),hPe.forEach(t),WPr=i(Oo),RE=n(Oo,"LI",{});var pPe=s(RE);E9e=n(pPe,"STRONG",{});var bAt=s(E9e);HPr=r(bAt,"distilbert"),bAt.forEach(t),UPr=r(pPe," \u2014 "),rJ=n(pPe,"A",{href:!0});var vAt=s(rJ);JPr=r(vAt,"FlaxDistilBertForTokenClassification"),vAt.forEach(t),YPr=r(pPe," (DistilBERT model)"),pPe.forEach(t),KPr=i(Oo),BE=n(Oo,"LI",{});var _Pe=s(BE);C9e=n(_Pe,"STRONG",{});var FAt=s(C9e);ZPr=r(FAt,"electra"),FAt.forEach(t),e$r=r(_Pe," \u2014 "),tJ=n(_Pe,"A",{href:!0});var TAt=s(tJ);o$r=r(TAt,"FlaxElectraForTokenClassification"),TAt.forEach(t),r$r=r(_Pe," (ELECTRA model)"),_Pe.forEach(t),t$r=i(Oo),PE=n(Oo,"LI",{});var uPe=s(PE);w9e=n(uPe,"STRONG",{});var MAt=s(w9e);a$r=r(MAt,"roberta"),MAt.forEach(t),n$r=r(uPe," \u2014 "),aJ=n(uPe,"A",{href:!0});var EAt=s(aJ);s$r=r(EAt,"FlaxRobertaForTokenClassification"),EAt.forEach(t),l$r=r(uPe," (RoBERTa model)"),uPe.forEach(t),i$r=i(Oo),$E=n(Oo,"LI",{});var bPe=s($E);A9e=n(bPe,"STRONG",{});var CAt=s(A9e);d$r=r(CAt,"roformer"),CAt.forEach(t),c$r=r(bPe," \u2014 "),nJ=n(bPe,"A",{href:!0});var wAt=s(nJ);f$r=r(wAt,"FlaxRoFormerForTokenClassification"),wAt.forEach(t),m$r=r(bPe," (RoFormer model)"),bPe.forEach(t),g$r=i(Oo),IE=n(Oo,"LI",{});var vPe=s(IE);y9e=n(vPe,"STRONG",{});var AAt=s(y9e);h$r=r(AAt,"xlm-roberta"),AAt.forEach(t),p$r=r(vPe," \u2014 "),sJ=n(vPe,"A",{href:!0});var yAt=s(sJ);_$r=r(yAt,"FlaxXLMRobertaForTokenClassification"),yAt.forEach(t),u$r=r(vPe," (XLM-RoBERTa model)"),vPe.forEach(t),Oo.forEach(t),b$r=i($a),L9e=n($a,"P",{});var LAt=s(L9e);v$r=r(LAt,"Examples:"),LAt.forEach(t),F$r=i($a),m(bL.$$.fragment,$a),$a.forEach(t),Ii.forEach(t),wIe=i(c),Rf=n(c,"H2",{class:!0});var INe=s(Rf);qE=n(INe,"A",{id:!0,class:!0,href:!0});var xAt=s(qE);x9e=n(xAt,"SPAN",{});var kAt=s(x9e);m(vL.$$.fragment,kAt),kAt.forEach(t),xAt.forEach(t),T$r=i(INe),k9e=n(INe,"SPAN",{});var SAt=s(k9e);M$r=r(SAt,"FlaxAutoModelForMultipleChoice"),SAt.forEach(t),INe.forEach(t),AIe=i(c),Dr=n(c,"DIV",{class:!0});var Ni=s(Dr);m(FL.$$.fragment,Ni),E$r=i(Ni),Bf=n(Ni,"P",{});var pK=s(Bf);C$r=r(pK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),lJ=n(pK,"A",{href:!0});var RAt=s(lJ);w$r=r(RAt,"from_pretrained()"),RAt.forEach(t),A$r=r(pK," class method or the "),iJ=n(pK,"A",{href:!0});var BAt=s(iJ);y$r=r(BAt,"from_config()"),BAt.forEach(t),L$r=r(pK,` class
method.`),pK.forEach(t),x$r=i(Ni),TL=n(Ni,"P",{});var qNe=s(TL);k$r=r(qNe,"This class cannot be instantiated directly using "),S9e=n(qNe,"CODE",{});var PAt=s(S9e);S$r=r(PAt,"__init__()"),PAt.forEach(t),R$r=r(qNe," (throws an error)."),qNe.forEach(t),B$r=i(Ni),Pt=n(Ni,"DIV",{class:!0});var ji=s(Pt);m(ML.$$.fragment,ji),P$r=i(ji),R9e=n(ji,"P",{});var $At=s(R9e);$$r=r($At,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),$At.forEach(t),I$r=i(ji),Pf=n(ji,"P",{});var _K=s(Pf);q$r=r(_K,`Note:
Loading a model from its configuration file does `),B9e=n(_K,"STRONG",{});var IAt=s(B9e);N$r=r(IAt,"not"),IAt.forEach(t),j$r=r(_K,` load the model weights. It only affects the
model\u2019s configuration. Use `),dJ=n(_K,"A",{href:!0});var qAt=s(dJ);D$r=r(qAt,"from_pretrained()"),qAt.forEach(t),G$r=r(_K," to load the model weights."),_K.forEach(t),O$r=i(ji),P9e=n(ji,"P",{});var NAt=s(P9e);V$r=r(NAt,"Examples:"),NAt.forEach(t),X$r=i(ji),m(EL.$$.fragment,ji),ji.forEach(t),z$r=i(Ni),Io=n(Ni,"DIV",{class:!0});var Ia=s(Io);m(CL.$$.fragment,Ia),Q$r=i(Ia),$9e=n(Ia,"P",{});var jAt=s($9e);W$r=r(jAt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),jAt.forEach(t),H$r=i(Ia),Nn=n(Ia,"P",{});var U5=s(Nn);U$r=r(U5,"The model class to instantiate is selected based on the "),I9e=n(U5,"CODE",{});var DAt=s(I9e);J$r=r(DAt,"model_type"),DAt.forEach(t),Y$r=r(U5,` property of the config object (either
passed as an argument or loaded from `),q9e=n(U5,"CODE",{});var GAt=s(q9e);K$r=r(GAt,"pretrained_model_name_or_path"),GAt.forEach(t),Z$r=r(U5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N9e=n(U5,"CODE",{});var OAt=s(N9e);eIr=r(OAt,"pretrained_model_name_or_path"),OAt.forEach(t),oIr=r(U5,":"),U5.forEach(t),rIr=i(Ia),Ie=n(Ia,"UL",{});var Vo=s(Ie);NE=n(Vo,"LI",{});var FPe=s(NE);j9e=n(FPe,"STRONG",{});var VAt=s(j9e);tIr=r(VAt,"albert"),VAt.forEach(t),aIr=r(FPe," \u2014 "),cJ=n(FPe,"A",{href:!0});var XAt=s(cJ);nIr=r(XAt,"FlaxAlbertForMultipleChoice"),XAt.forEach(t),sIr=r(FPe," (ALBERT model)"),FPe.forEach(t),lIr=i(Vo),jE=n(Vo,"LI",{});var TPe=s(jE);D9e=n(TPe,"STRONG",{});var zAt=s(D9e);iIr=r(zAt,"bert"),zAt.forEach(t),dIr=r(TPe," \u2014 "),fJ=n(TPe,"A",{href:!0});var QAt=s(fJ);cIr=r(QAt,"FlaxBertForMultipleChoice"),QAt.forEach(t),fIr=r(TPe," (BERT model)"),TPe.forEach(t),mIr=i(Vo),DE=n(Vo,"LI",{});var MPe=s(DE);G9e=n(MPe,"STRONG",{});var WAt=s(G9e);gIr=r(WAt,"big_bird"),WAt.forEach(t),hIr=r(MPe," \u2014 "),mJ=n(MPe,"A",{href:!0});var HAt=s(mJ);pIr=r(HAt,"FlaxBigBirdForMultipleChoice"),HAt.forEach(t),_Ir=r(MPe," (BigBird model)"),MPe.forEach(t),uIr=i(Vo),GE=n(Vo,"LI",{});var EPe=s(GE);O9e=n(EPe,"STRONG",{});var UAt=s(O9e);bIr=r(UAt,"distilbert"),UAt.forEach(t),vIr=r(EPe," \u2014 "),gJ=n(EPe,"A",{href:!0});var JAt=s(gJ);FIr=r(JAt,"FlaxDistilBertForMultipleChoice"),JAt.forEach(t),TIr=r(EPe," (DistilBERT model)"),EPe.forEach(t),MIr=i(Vo),OE=n(Vo,"LI",{});var CPe=s(OE);V9e=n(CPe,"STRONG",{});var YAt=s(V9e);EIr=r(YAt,"electra"),YAt.forEach(t),CIr=r(CPe," \u2014 "),hJ=n(CPe,"A",{href:!0});var KAt=s(hJ);wIr=r(KAt,"FlaxElectraForMultipleChoice"),KAt.forEach(t),AIr=r(CPe," (ELECTRA model)"),CPe.forEach(t),yIr=i(Vo),VE=n(Vo,"LI",{});var wPe=s(VE);X9e=n(wPe,"STRONG",{});var ZAt=s(X9e);LIr=r(ZAt,"roberta"),ZAt.forEach(t),xIr=r(wPe," \u2014 "),pJ=n(wPe,"A",{href:!0});var eyt=s(pJ);kIr=r(eyt,"FlaxRobertaForMultipleChoice"),eyt.forEach(t),SIr=r(wPe," (RoBERTa model)"),wPe.forEach(t),RIr=i(Vo),XE=n(Vo,"LI",{});var APe=s(XE);z9e=n(APe,"STRONG",{});var oyt=s(z9e);BIr=r(oyt,"roformer"),oyt.forEach(t),PIr=r(APe," \u2014 "),_J=n(APe,"A",{href:!0});var ryt=s(_J);$Ir=r(ryt,"FlaxRoFormerForMultipleChoice"),ryt.forEach(t),IIr=r(APe," (RoFormer model)"),APe.forEach(t),qIr=i(Vo),zE=n(Vo,"LI",{});var yPe=s(zE);Q9e=n(yPe,"STRONG",{});var tyt=s(Q9e);NIr=r(tyt,"xlm-roberta"),tyt.forEach(t),jIr=r(yPe," \u2014 "),uJ=n(yPe,"A",{href:!0});var ayt=s(uJ);DIr=r(ayt,"FlaxXLMRobertaForMultipleChoice"),ayt.forEach(t),GIr=r(yPe," (XLM-RoBERTa model)"),yPe.forEach(t),Vo.forEach(t),OIr=i(Ia),W9e=n(Ia,"P",{});var nyt=s(W9e);VIr=r(nyt,"Examples:"),nyt.forEach(t),XIr=i(Ia),m(wL.$$.fragment,Ia),Ia.forEach(t),Ni.forEach(t),yIe=i(c),$f=n(c,"H2",{class:!0});var NNe=s($f);QE=n(NNe,"A",{id:!0,class:!0,href:!0});var syt=s(QE);H9e=n(syt,"SPAN",{});var lyt=s(H9e);m(AL.$$.fragment,lyt),lyt.forEach(t),syt.forEach(t),zIr=i(NNe),U9e=n(NNe,"SPAN",{});var iyt=s(U9e);QIr=r(iyt,"FlaxAutoModelForNextSentencePrediction"),iyt.forEach(t),NNe.forEach(t),LIe=i(c),Gr=n(c,"DIV",{class:!0});var Di=s(Gr);m(yL.$$.fragment,Di),WIr=i(Di),If=n(Di,"P",{});var uK=s(If);HIr=r(uK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),bJ=n(uK,"A",{href:!0});var dyt=s(bJ);UIr=r(dyt,"from_pretrained()"),dyt.forEach(t),JIr=r(uK," class method or the "),vJ=n(uK,"A",{href:!0});var cyt=s(vJ);YIr=r(cyt,"from_config()"),cyt.forEach(t),KIr=r(uK,` class
method.`),uK.forEach(t),ZIr=i(Di),LL=n(Di,"P",{});var jNe=s(LL);eqr=r(jNe,"This class cannot be instantiated directly using "),J9e=n(jNe,"CODE",{});var fyt=s(J9e);oqr=r(fyt,"__init__()"),fyt.forEach(t),rqr=r(jNe," (throws an error)."),jNe.forEach(t),tqr=i(Di),$t=n(Di,"DIV",{class:!0});var Gi=s($t);m(xL.$$.fragment,Gi),aqr=i(Gi),Y9e=n(Gi,"P",{});var myt=s(Y9e);nqr=r(myt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),myt.forEach(t),sqr=i(Gi),qf=n(Gi,"P",{});var bK=s(qf);lqr=r(bK,`Note:
Loading a model from its configuration file does `),K9e=n(bK,"STRONG",{});var gyt=s(K9e);iqr=r(gyt,"not"),gyt.forEach(t),dqr=r(bK,` load the model weights. It only affects the
model\u2019s configuration. Use `),FJ=n(bK,"A",{href:!0});var hyt=s(FJ);cqr=r(hyt,"from_pretrained()"),hyt.forEach(t),fqr=r(bK," to load the model weights."),bK.forEach(t),mqr=i(Gi),Z9e=n(Gi,"P",{});var pyt=s(Z9e);gqr=r(pyt,"Examples:"),pyt.forEach(t),hqr=i(Gi),m(kL.$$.fragment,Gi),Gi.forEach(t),pqr=i(Di),qo=n(Di,"DIV",{class:!0});var qa=s(qo);m(SL.$$.fragment,qa),_qr=i(qa),eMe=n(qa,"P",{});var _yt=s(eMe);uqr=r(_yt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),_yt.forEach(t),bqr=i(qa),jn=n(qa,"P",{});var J5=s(jn);vqr=r(J5,"The model class to instantiate is selected based on the "),oMe=n(J5,"CODE",{});var uyt=s(oMe);Fqr=r(uyt,"model_type"),uyt.forEach(t),Tqr=r(J5,` property of the config object (either
passed as an argument or loaded from `),rMe=n(J5,"CODE",{});var byt=s(rMe);Mqr=r(byt,"pretrained_model_name_or_path"),byt.forEach(t),Eqr=r(J5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tMe=n(J5,"CODE",{});var vyt=s(tMe);Cqr=r(vyt,"pretrained_model_name_or_path"),vyt.forEach(t),wqr=r(J5,":"),J5.forEach(t),Aqr=i(qa),aMe=n(qa,"UL",{});var Fyt=s(aMe);WE=n(Fyt,"LI",{});var LPe=s(WE);nMe=n(LPe,"STRONG",{});var Tyt=s(nMe);yqr=r(Tyt,"bert"),Tyt.forEach(t),Lqr=r(LPe," \u2014 "),TJ=n(LPe,"A",{href:!0});var Myt=s(TJ);xqr=r(Myt,"FlaxBertForNextSentencePrediction"),Myt.forEach(t),kqr=r(LPe," (BERT model)"),LPe.forEach(t),Fyt.forEach(t),Sqr=i(qa),sMe=n(qa,"P",{});var Eyt=s(sMe);Rqr=r(Eyt,"Examples:"),Eyt.forEach(t),Bqr=i(qa),m(RL.$$.fragment,qa),qa.forEach(t),Di.forEach(t),xIe=i(c),Nf=n(c,"H2",{class:!0});var DNe=s(Nf);HE=n(DNe,"A",{id:!0,class:!0,href:!0});var Cyt=s(HE);lMe=n(Cyt,"SPAN",{});var wyt=s(lMe);m(BL.$$.fragment,wyt),wyt.forEach(t),Cyt.forEach(t),Pqr=i(DNe),iMe=n(DNe,"SPAN",{});var Ayt=s(iMe);$qr=r(Ayt,"FlaxAutoModelForImageClassification"),Ayt.forEach(t),DNe.forEach(t),kIe=i(c),Or=n(c,"DIV",{class:!0});var Oi=s(Or);m(PL.$$.fragment,Oi),Iqr=i(Oi),jf=n(Oi,"P",{});var vK=s(jf);qqr=r(vK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),MJ=n(vK,"A",{href:!0});var yyt=s(MJ);Nqr=r(yyt,"from_pretrained()"),yyt.forEach(t),jqr=r(vK," class method or the "),EJ=n(vK,"A",{href:!0});var Lyt=s(EJ);Dqr=r(Lyt,"from_config()"),Lyt.forEach(t),Gqr=r(vK,` class
method.`),vK.forEach(t),Oqr=i(Oi),$L=n(Oi,"P",{});var GNe=s($L);Vqr=r(GNe,"This class cannot be instantiated directly using "),dMe=n(GNe,"CODE",{});var xyt=s(dMe);Xqr=r(xyt,"__init__()"),xyt.forEach(t),zqr=r(GNe," (throws an error)."),GNe.forEach(t),Qqr=i(Oi),It=n(Oi,"DIV",{class:!0});var Vi=s(It);m(IL.$$.fragment,Vi),Wqr=i(Vi),cMe=n(Vi,"P",{});var kyt=s(cMe);Hqr=r(kyt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),kyt.forEach(t),Uqr=i(Vi),Df=n(Vi,"P",{});var FK=s(Df);Jqr=r(FK,`Note:
Loading a model from its configuration file does `),fMe=n(FK,"STRONG",{});var Syt=s(fMe);Yqr=r(Syt,"not"),Syt.forEach(t),Kqr=r(FK,` load the model weights. It only affects the
model\u2019s configuration. Use `),CJ=n(FK,"A",{href:!0});var Ryt=s(CJ);Zqr=r(Ryt,"from_pretrained()"),Ryt.forEach(t),eNr=r(FK," to load the model weights."),FK.forEach(t),oNr=i(Vi),mMe=n(Vi,"P",{});var Byt=s(mMe);rNr=r(Byt,"Examples:"),Byt.forEach(t),tNr=i(Vi),m(qL.$$.fragment,Vi),Vi.forEach(t),aNr=i(Oi),No=n(Oi,"DIV",{class:!0});var Na=s(No);m(NL.$$.fragment,Na),nNr=i(Na),gMe=n(Na,"P",{});var Pyt=s(gMe);sNr=r(Pyt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Pyt.forEach(t),lNr=i(Na),Dn=n(Na,"P",{});var Y5=s(Dn);iNr=r(Y5,"The model class to instantiate is selected based on the "),hMe=n(Y5,"CODE",{});var $yt=s(hMe);dNr=r($yt,"model_type"),$yt.forEach(t),cNr=r(Y5,` property of the config object (either
passed as an argument or loaded from `),pMe=n(Y5,"CODE",{});var Iyt=s(pMe);fNr=r(Iyt,"pretrained_model_name_or_path"),Iyt.forEach(t),mNr=r(Y5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Me=n(Y5,"CODE",{});var qyt=s(_Me);gNr=r(qyt,"pretrained_model_name_or_path"),qyt.forEach(t),hNr=r(Y5,":"),Y5.forEach(t),pNr=i(Na),jL=n(Na,"UL",{});var ONe=s(jL);UE=n(ONe,"LI",{});var xPe=s(UE);uMe=n(xPe,"STRONG",{});var Nyt=s(uMe);_Nr=r(Nyt,"beit"),Nyt.forEach(t),uNr=r(xPe," \u2014 "),wJ=n(xPe,"A",{href:!0});var jyt=s(wJ);bNr=r(jyt,"FlaxBeitForImageClassification"),jyt.forEach(t),vNr=r(xPe," (BEiT model)"),xPe.forEach(t),FNr=i(ONe),JE=n(ONe,"LI",{});var kPe=s(JE);bMe=n(kPe,"STRONG",{});var Dyt=s(bMe);TNr=r(Dyt,"vit"),Dyt.forEach(t),MNr=r(kPe," \u2014 "),AJ=n(kPe,"A",{href:!0});var Gyt=s(AJ);ENr=r(Gyt,"FlaxViTForImageClassification"),Gyt.forEach(t),CNr=r(kPe," (ViT model)"),kPe.forEach(t),ONe.forEach(t),wNr=i(Na),vMe=n(Na,"P",{});var Oyt=s(vMe);ANr=r(Oyt,"Examples:"),Oyt.forEach(t),yNr=i(Na),m(DL.$$.fragment,Na),Na.forEach(t),Oi.forEach(t),SIe=i(c),Gf=n(c,"H2",{class:!0});var VNe=s(Gf);YE=n(VNe,"A",{id:!0,class:!0,href:!0});var Vyt=s(YE);FMe=n(Vyt,"SPAN",{});var Xyt=s(FMe);m(GL.$$.fragment,Xyt),Xyt.forEach(t),Vyt.forEach(t),LNr=i(VNe),TMe=n(VNe,"SPAN",{});var zyt=s(TMe);xNr=r(zyt,"FlaxAutoModelForVision2Seq"),zyt.forEach(t),VNe.forEach(t),RIe=i(c),Vr=n(c,"DIV",{class:!0});var Xi=s(Vr);m(OL.$$.fragment,Xi),kNr=i(Xi),Of=n(Xi,"P",{});var TK=s(Of);SNr=r(TK,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),yJ=n(TK,"A",{href:!0});var Qyt=s(yJ);RNr=r(Qyt,"from_pretrained()"),Qyt.forEach(t),BNr=r(TK," class method or the "),LJ=n(TK,"A",{href:!0});var Wyt=s(LJ);PNr=r(Wyt,"from_config()"),Wyt.forEach(t),$Nr=r(TK,` class
method.`),TK.forEach(t),INr=i(Xi),VL=n(Xi,"P",{});var XNe=s(VL);qNr=r(XNe,"This class cannot be instantiated directly using "),MMe=n(XNe,"CODE",{});var Hyt=s(MMe);NNr=r(Hyt,"__init__()"),Hyt.forEach(t),jNr=r(XNe," (throws an error)."),XNe.forEach(t),DNr=i(Xi),qt=n(Xi,"DIV",{class:!0});var zi=s(qt);m(XL.$$.fragment,zi),GNr=i(zi),EMe=n(zi,"P",{});var Uyt=s(EMe);ONr=r(Uyt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Uyt.forEach(t),VNr=i(zi),Vf=n(zi,"P",{});var MK=s(Vf);XNr=r(MK,`Note:
Loading a model from its configuration file does `),CMe=n(MK,"STRONG",{});var Jyt=s(CMe);zNr=r(Jyt,"not"),Jyt.forEach(t),QNr=r(MK,` load the model weights. It only affects the
model\u2019s configuration. Use `),xJ=n(MK,"A",{href:!0});var Yyt=s(xJ);WNr=r(Yyt,"from_pretrained()"),Yyt.forEach(t),HNr=r(MK," to load the model weights."),MK.forEach(t),UNr=i(zi),wMe=n(zi,"P",{});var Kyt=s(wMe);JNr=r(Kyt,"Examples:"),Kyt.forEach(t),YNr=i(zi),m(zL.$$.fragment,zi),zi.forEach(t),KNr=i(Xi),jo=n(Xi,"DIV",{class:!0});var ja=s(jo);m(QL.$$.fragment,ja),ZNr=i(ja),AMe=n(ja,"P",{});var Zyt=s(AMe);ejr=r(Zyt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Zyt.forEach(t),ojr=i(ja),Gn=n(ja,"P",{});var K5=s(Gn);rjr=r(K5,"The model class to instantiate is selected based on the "),yMe=n(K5,"CODE",{});var eLt=s(yMe);tjr=r(eLt,"model_type"),eLt.forEach(t),ajr=r(K5,` property of the config object (either
passed as an argument or loaded from `),LMe=n(K5,"CODE",{});var oLt=s(LMe);njr=r(oLt,"pretrained_model_name_or_path"),oLt.forEach(t),sjr=r(K5,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=n(K5,"CODE",{});var rLt=s(xMe);ljr=r(rLt,"pretrained_model_name_or_path"),rLt.forEach(t),ijr=r(K5,":"),K5.forEach(t),djr=i(ja),kMe=n(ja,"UL",{});var tLt=s(kMe);KE=n(tLt,"LI",{});var SPe=s(KE);SMe=n(SPe,"STRONG",{});var aLt=s(SMe);cjr=r(aLt,"vision-encoder-decoder"),aLt.forEach(t),fjr=r(SPe," \u2014 "),kJ=n(SPe,"A",{href:!0});var nLt=s(kJ);mjr=r(nLt,"FlaxVisionEncoderDecoderModel"),nLt.forEach(t),gjr=r(SPe," (Vision Encoder decoder model)"),SPe.forEach(t),tLt.forEach(t),hjr=i(ja),RMe=n(ja,"P",{});var sLt=s(RMe);pjr=r(sLt,"Examples:"),sLt.forEach(t),_jr=i(ja),m(WL.$$.fragment,ja),ja.forEach(t),Xi.forEach(t),this.h()},h(){d(oe,"name","hf:doc:metadata"),d(oe,"content",JSON.stringify(_Lt)),d(Ae,"id","auto-classes"),d(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ae,"href","#auto-classes"),d(ge,"class","relative group"),d(On,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.AutoConfig"),d(Xn,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.AutoModel"),d(zn,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.AutoTokenizer"),d(Ki,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertModel"),d(Jf,"id","extending-the-auto-classes"),d(Jf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Jf,"href","#extending-the-auto-classes"),d(Zi,"class","relative group"),d(Kf,"id","transformers.AutoConfig"),d(Kf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Kf,"href","#transformers.AutoConfig"),d(ed,"class","relative group"),d(sx,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),d(lx,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertConfig"),d(ix,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig"),d(dx,"href","/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitConfig"),d(cx,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertConfig"),d(fx,"href","/docs/transformers/pr_16792/en/model_doc/bert-generation#transformers.BertGenerationConfig"),d(mx,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdConfig"),d(gx,"href","/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),d(hx,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotConfig"),d(px,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),d(_x,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertConfig"),d(ux,"href","/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineConfig"),d(bx,"href","/docs/transformers/pr_16792/en/model_doc/clip#transformers.CLIPConfig"),d(vx,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertConfig"),d(Fx,"href","/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextConfig"),d(Tx,"href","/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLConfig"),d(Mx,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),d(Ex,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextConfig"),d(Cx,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),d(wx,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaConfig"),d(Ax,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Config"),d(yx,"href","/docs/transformers/pr_16792/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),d(Lx,"href","/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTConfig"),d(xx,"href","/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrConfig"),d(kx,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertConfig"),d(Sx,"href","/docs/transformers/pr_16792/en/model_doc/dpr#transformers.DPRConfig"),d(Rx,"href","/docs/transformers/pr_16792/en/model_doc/dpt#transformers.DPTConfig"),d(Bx,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraConfig"),d(Px,"href","/docs/transformers/pr_16792/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),d($x,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertConfig"),d(Ix,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetConfig"),d(qx,"href","/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTConfig"),d(Nx,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelConfig"),d(jx,"href","/docs/transformers/pr_16792/en/model_doc/glpn#transformers.GLPNConfig"),d(Dx,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Config"),d(Gx,"href","/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),d(Ox,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJConfig"),d(Vx,"href","/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertConfig"),d(Xx,"href","/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertConfig"),d(zx,"href","/docs/transformers/pr_16792/en/model_doc/imagegpt#transformers.ImageGPTConfig"),d(Qx,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMConfig"),d(Wx,"href","/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),d(Hx,"href","/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDConfig"),d(Ux,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerConfig"),d(Jx,"href","/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5Config"),d(Yx,"href","/docs/transformers/pr_16792/en/model_doc/luke#transformers.LukeConfig"),d(Kx,"href","/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertConfig"),d(Zx,"href","/docs/transformers/pr_16792/en/model_doc/m2m_100#transformers.M2M100Config"),d(ek,"href","/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianConfig"),d(ok,"href","/docs/transformers/pr_16792/en/model_doc/maskformer#transformers.MaskFormerConfig"),d(rk,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartConfig"),d(tk,"href","/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),d(ak,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertConfig"),d(nk,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetConfig"),d(sk,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5Config"),d(lk,"href","/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerConfig"),d(ik,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),d(dk,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusConfig"),d(ck,"href","/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverConfig"),d(fk,"href","/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartConfig"),d(mk,"href","/docs/transformers/pr_16792/en/model_doc/poolformer#transformers.PoolFormerConfig"),d(gk,"href","/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetConfig"),d(hk,"href","/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertConfig"),d(pk,"href","/docs/transformers/pr_16792/en/model_doc/rag#transformers.RagConfig"),d(_k,"href","/docs/transformers/pr_16792/en/model_doc/realm#transformers.RealmConfig"),d(uk,"href","/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerConfig"),d(bk,"href","/docs/transformers/pr_16792/en/model_doc/regnet#transformers.RegNetConfig"),d(vk,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertConfig"),d(Fk,"href","/docs/transformers/pr_16792/en/model_doc/resnet#transformers.ResNetConfig"),d(Tk,"href","/docs/transformers/pr_16792/en/model_doc/retribert#transformers.RetriBertConfig"),d(Mk,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaConfig"),d(Ek,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerConfig"),d(Ck,"href","/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerConfig"),d(wk,"href","/docs/transformers/pr_16792/en/model_doc/sew#transformers.SEWConfig"),d(Ak,"href","/docs/transformers/pr_16792/en/model_doc/sew-d#transformers.SEWDConfig"),d(yk,"href","/docs/transformers/pr_16792/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),d(Lk,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),d(xk,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),d(kk,"href","/docs/transformers/pr_16792/en/model_doc/splinter#transformers.SplinterConfig"),d(Sk,"href","/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),d(Rk,"href","/docs/transformers/pr_16792/en/model_doc/swin#transformers.SwinConfig"),d(Bk,"href","/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Config"),d(Pk,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasConfig"),d($k,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartConfig"),d(Ik,"href","/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),d(qk,"href","/docs/transformers/pr_16792/en/model_doc/trocr#transformers.TrOCRConfig"),d(Nk,"href","/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechConfig"),d(jk,"href","/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),d(Dk,"href","/docs/transformers/pr_16792/en/model_doc/van#transformers.VanConfig"),d(Gk,"href","/docs/transformers/pr_16792/en/model_doc/vilt#transformers.ViltConfig"),d(Ok,"href","/docs/transformers/pr_16792/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),d(Vk,"href","/docs/transformers/pr_16792/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),d(Xk,"href","/docs/transformers/pr_16792/en/model_doc/visual_bert#transformers.VisualBertConfig"),d(zk,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTConfig"),d(Qk,"href","/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.ViTMAEConfig"),d(Wk,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),d(Hk,"href","/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMConfig"),d(Uk,"href","/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMConfig"),d(Jk,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMConfig"),d(Yk,"href","/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),d(Kk,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),d(Zk,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),d(eS,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetConfig"),d(oS,"href","/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoConfig"),d(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Hg,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ug,"id","transformers.AutoTokenizer"),d(Ug,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ug,"href","#transformers.AutoTokenizer"),d(rd,"class","relative group"),d(rS,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),d(tS,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertTokenizer"),d(aS,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(nS,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartTokenizer"),d(sS,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartTokenizerFast"),d(lS,"href","/docs/transformers/pr_16792/en/model_doc/barthez#transformers.BarthezTokenizer"),d(iS,"href","/docs/transformers/pr_16792/en/model_doc/barthez#transformers.BarthezTokenizerFast"),d(dS,"href","/docs/transformers/pr_16792/en/model_doc/bartpho#transformers.BartphoTokenizer"),d(cS,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertTokenizer"),d(fS,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertTokenizerFast"),d(mS,"href","/docs/transformers/pr_16792/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),d(gS,"href","/docs/transformers/pr_16792/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),d(hS,"href","/docs/transformers/pr_16792/en/model_doc/bertweet#transformers.BertweetTokenizer"),d(pS,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdTokenizer"),d(_S,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),d(uS,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(bS,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(vS,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),d(FS,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),d(TS,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),d(MS,"href","/docs/transformers/pr_16792/en/model_doc/byt5#transformers.ByT5Tokenizer"),d(ES,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertTokenizer"),d(CS,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertTokenizerFast"),d(wS,"href","/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineTokenizer"),d(AS,"href","/docs/transformers/pr_16792/en/model_doc/clip#transformers.CLIPTokenizer"),d(yS,"href","/docs/transformers/pr_16792/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(LS,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertTokenizer"),d(xS,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),d(kS,"href","/docs/transformers/pr_16792/en/model_doc/cpm#transformers.CpmTokenizer"),d(SS,"href","/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLTokenizer"),d(RS,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaTokenizer"),d(BS,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(PS,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaTokenizer"),d($S,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaTokenizerFast"),d(IS,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),d(qS,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),d(NS,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertTokenizer"),d(jS,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),d(DS,"href","/docs/transformers/pr_16792/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),d(GS,"href","/docs/transformers/pr_16792/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),d(OS,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraTokenizer"),d(VS,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraTokenizerFast"),d(XS,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertTokenizer"),d(zS,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetTokenizer"),d(QS,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetTokenizerFast"),d(WS,"href","/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTTokenizer"),d(HS,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelTokenizer"),d(US,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelTokenizerFast"),d(JS,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(YS,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(KS,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(ZS,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(eR,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(oR,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(rR,"href","/docs/transformers/pr_16792/en/model_doc/herbert#transformers.HerbertTokenizer"),d(tR,"href","/docs/transformers/pr_16792/en/model_doc/herbert#transformers.HerbertTokenizerFast"),d(aR,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(nR,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaTokenizer"),d(sR,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(lR,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),d(iR,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),d(dR,"href","/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),d(cR,"href","/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),d(fR,"href","/docs/transformers/pr_16792/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),d(mR,"href","/docs/transformers/pr_16792/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),d(gR,"href","/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDTokenizer"),d(hR,"href","/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDTokenizerFast"),d(pR,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerTokenizer"),d(_R,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerTokenizerFast"),d(uR,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.T5Tokenizer"),d(bR,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.T5TokenizerFast"),d(vR,"href","/docs/transformers/pr_16792/en/model_doc/luke#transformers.LukeTokenizer"),d(FR,"href","/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertTokenizer"),d(TR,"href","/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),d(MR,"href","/docs/transformers/pr_16792/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),d(ER,"href","/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianTokenizer"),d(CR,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartTokenizer"),d(wR,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartTokenizerFast"),d(AR,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBart50Tokenizer"),d(yR,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBart50TokenizerFast"),d(LR,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertTokenizer"),d(xR,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertTokenizerFast"),d(kR,"href","/docs/transformers/pr_16792/en/model_doc/mluke#transformers.MLukeTokenizer"),d(SR,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),d(RR,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),d(BR,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetTokenizer"),d(PR,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),d($R,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.T5Tokenizer"),d(IR,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.T5TokenizerFast"),d(qR,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertTokenizer"),d(NR,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(jR,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),d(DR,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),d(GR,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(OR,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(VR,"href","/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverTokenizer"),d(XR,"href","/docs/transformers/pr_16792/en/model_doc/phobert#transformers.PhobertTokenizer"),d(zR,"href","/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartTokenizer"),d(QR,"href","/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),d(WR,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertTokenizer"),d(HR,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertTokenizerFast"),d(UR,"href","/docs/transformers/pr_16792/en/model_doc/rag#transformers.RagTokenizer"),d(JR,"href","/docs/transformers/pr_16792/en/model_doc/realm#transformers.RealmTokenizer"),d(YR,"href","/docs/transformers/pr_16792/en/model_doc/realm#transformers.RealmTokenizerFast"),d(KR,"href","/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerTokenizer"),d(ZR,"href","/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerTokenizerFast"),d(eB,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertTokenizer"),d(oB,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertTokenizerFast"),d(rB,"href","/docs/transformers/pr_16792/en/model_doc/retribert#transformers.RetriBertTokenizer"),d(tB,"href","/docs/transformers/pr_16792/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),d(aB,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaTokenizer"),d(nB,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(sB,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerTokenizer"),d(lB,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),d(iB,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),d(dB,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),d(cB,"href","/docs/transformers/pr_16792/en/model_doc/splinter#transformers.SplinterTokenizer"),d(fB,"href","/docs/transformers/pr_16792/en/model_doc/splinter#transformers.SplinterTokenizerFast"),d(mB,"href","/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),d(gB,"href","/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),d(hB,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.T5Tokenizer"),d(pB,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.T5TokenizerFast"),d(_B,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasTokenizer"),d(uB,"href","/docs/transformers/pr_16792/en/model_doc/tapex#transformers.TapexTokenizer"),d(bB,"href","/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),d(vB,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertTokenizer"),d(FB,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertTokenizerFast"),d(TB,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(MB,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),d(EB,"href","/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMTokenizer"),d(CB,"href","/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMTokenizerFast"),d(wB,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMTokenizer"),d(AB,"href","/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),d(yB,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(LB,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(xB,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaTokenizer"),d(kB,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(SB,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetTokenizer"),d(RB,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),d(BB,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertTokenizer"),d(PB,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ah,"id","transformers.AutoFeatureExtractor"),d(Ah,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ah,"href","#transformers.AutoFeatureExtractor"),d(td,"class","relative group"),d($B,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),d(IB,"href","/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitFeatureExtractor"),d(qB,"href","/docs/transformers/pr_16792/en/model_doc/clip#transformers.CLIPFeatureExtractor"),d(NB,"href","/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(jB,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(DB,"href","/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitFeatureExtractor"),d(GB,"href","/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTFeatureExtractor"),d(OB,"href","/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(VB,"href","/docs/transformers/pr_16792/en/model_doc/dpt#transformers.DPTFeatureExtractor"),d(XB,"href","/docs/transformers/pr_16792/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),d(zB,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(QB,"href","/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),d(WB,"href","/docs/transformers/pr_16792/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),d(HB,"href","/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),d(UB,"href","/docs/transformers/pr_16792/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),d(JB,"href","/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(YB,"href","/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(KB,"href","/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),d(ZB,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),d(eP,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(oP,"href","/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),d(rP,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(tP,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTFeatureExtractor"),d(aP,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(qe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Kh,"id","transformers.AutoProcessor"),d(Kh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Kh,"href","#transformers.AutoProcessor"),d(ad,"class","relative group"),d(nP,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),d(sP,"href","/docs/transformers/pr_16792/en/model_doc/clip#transformers.CLIPProcessor"),d(lP,"href","/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),d(iP,"href","/docs/transformers/pr_16792/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),d(dP,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(cP,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(fP,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),d(mP,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),d(gP,"href","/docs/transformers/pr_16792/en/model_doc/trocr#transformers.TrOCRProcessor"),d(hP,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(pP,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(_P,"href","/docs/transformers/pr_16792/en/model_doc/vilt#transformers.ViltProcessor"),d(uP,"href","/docs/transformers/pr_16792/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),d(bP,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(vP,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(Ne,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pp,"id","transformers.AutoModel"),d(pp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(pp,"href","#transformers.AutoModel"),d(sd,"class","relative group"),d(FP,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(TP,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(MP,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(EP,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertModel"),d(CP,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartModel"),d(wP,"href","/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitModel"),d(AP,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertModel"),d(yP,"href","/docs/transformers/pr_16792/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),d(LP,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdModel"),d(xP,"href","/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),d(kP,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotModel"),d(SP,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),d(RP,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertModel"),d(BP,"href","/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineModel"),d(PP,"href","/docs/transformers/pr_16792/en/model_doc/clip#transformers.CLIPModel"),d($P,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertModel"),d(IP,"href","/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextModel"),d(qP,"href","/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLModel"),d(NP,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioModel"),d(jP,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextModel"),d(DP,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecVisionModel"),d(GP,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaModel"),d(OP,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2Model"),d(VP,"href","/docs/transformers/pr_16792/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),d(XP,"href","/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTModel"),d(zP,"href","/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrModel"),d(QP,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertModel"),d(WP,"href","/docs/transformers/pr_16792/en/model_doc/dpr#transformers.DPRQuestionEncoder"),d(HP,"href","/docs/transformers/pr_16792/en/model_doc/dpt#transformers.DPTModel"),d(UP,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraModel"),d(JP,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertModel"),d(YP,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetModel"),d(KP,"href","/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTModel"),d(ZP,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelModel"),d(e$,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelBaseModel"),d(o$,"href","/docs/transformers/pr_16792/en/model_doc/glpn#transformers.GLPNModel"),d(r$,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2Model"),d(t$,"href","/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoModel"),d(a$,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJModel"),d(n$,"href","/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertModel"),d(s$,"href","/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertModel"),d(l$,"href","/docs/transformers/pr_16792/en/model_doc/imagegpt#transformers.ImageGPTModel"),d(i$,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMModel"),d(d$,"href","/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),d(c$,"href","/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDModel"),d(f$,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerModel"),d(m$,"href","/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5Model"),d(g$,"href","/docs/transformers/pr_16792/en/model_doc/luke#transformers.LukeModel"),d(h$,"href","/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertModel"),d(p$,"href","/docs/transformers/pr_16792/en/model_doc/m2m_100#transformers.M2M100Model"),d(_$,"href","/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianModel"),d(u$,"href","/docs/transformers/pr_16792/en/model_doc/maskformer#transformers.MaskFormerModel"),d(b$,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartModel"),d(v$,"href","/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertModel"),d(F$,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertModel"),d(T$,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetModel"),d(M$,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5Model"),d(E$,"href","/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerModel"),d(C$,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),d(w$,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusModel"),d(A$,"href","/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverModel"),d(y$,"href","/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartModel"),d(L$,"href","/docs/transformers/pr_16792/en/model_doc/poolformer#transformers.PoolFormerModel"),d(x$,"href","/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetModel"),d(k$,"href","/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertModel"),d(S$,"href","/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerModel"),d(R$,"href","/docs/transformers/pr_16792/en/model_doc/regnet#transformers.RegNetModel"),d(B$,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertModel"),d(P$,"href","/docs/transformers/pr_16792/en/model_doc/resnet#transformers.ResNetModel"),d($$,"href","/docs/transformers/pr_16792/en/model_doc/retribert#transformers.RetriBertModel"),d(I$,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaModel"),d(q$,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerModel"),d(N$,"href","/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerModel"),d(j$,"href","/docs/transformers/pr_16792/en/model_doc/sew#transformers.SEWModel"),d(D$,"href","/docs/transformers/pr_16792/en/model_doc/sew-d#transformers.SEWDModel"),d(G$,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextModel"),d(O$,"href","/docs/transformers/pr_16792/en/model_doc/splinter#transformers.SplinterModel"),d(V$,"href","/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertModel"),d(X$,"href","/docs/transformers/pr_16792/en/model_doc/swin#transformers.SwinModel"),d(z$,"href","/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5Model"),d(Q$,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasModel"),d(W$,"href","/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLModel"),d(H$,"href","/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechModel"),d(U$,"href","/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),d(J$,"href","/docs/transformers/pr_16792/en/model_doc/van#transformers.VanModel"),d(Y$,"href","/docs/transformers/pr_16792/en/model_doc/vilt#transformers.ViltModel"),d(K$,"href","/docs/transformers/pr_16792/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),d(Z$,"href","/docs/transformers/pr_16792/en/model_doc/visual_bert#transformers.VisualBertModel"),d(eI,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTModel"),d(oI,"href","/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.ViTMAEModel"),d(rI,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),d(tI,"href","/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMModel"),d(aI,"href","/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMModel"),d(nI,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMModel"),d(sI,"href","/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),d(lI,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),d(iI,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),d(dI,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetModel"),d(cI,"href","/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoModel"),d(je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tu,"id","transformers.AutoModelForPreTraining"),d(tu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(tu,"href","#transformers.AutoModelForPreTraining"),d(dd,"class","relative group"),d(fI,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mI,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gI,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hI,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForPreTraining"),d(pI,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(_I,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForPreTraining"),d(uI,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),d(bI,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(vI,"href","/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(FI,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(TI,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(MI,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(EI,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(CI,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForPreTraining"),d(wI,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(AI,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForPreTraining"),d(yI,"href","/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(LI,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForPreTraining"),d(xI,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(kI,"href","/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(SI,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(RI,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(BI,"href","/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),d(PI,"href","/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertForPreTraining"),d($I,"href","/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),d(II,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),d(qI,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(NI,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(jI,"href","/docs/transformers/pr_16792/en/model_doc/retribert#transformers.RetriBertModel"),d(DI,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(GI,"href","/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(OI,"href","/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(VI,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(XI,"href","/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(zI,"href","/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),d(QI,"href","/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),d(WI,"href","/docs/transformers/pr_16792/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),d(HI,"href","/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),d(UI,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),d(JI,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(YI,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(KI,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(ZI,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(De,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zu,"id","transformers.AutoModelForCausalLM"),d(zu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(zu,"href","#transformers.AutoModelForCausalLM"),d(md,"class","relative group"),d(eq,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(oq,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(rq,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tq,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForCausalLM"),d(aq,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertLMHeadModel"),d(nq,"href","/docs/transformers/pr_16792/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),d(sq,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),d(lq,"href","/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),d(iq,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),d(dq,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),d(cq,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForCausalLM"),d(fq,"href","/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(mq,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),d(gq,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForCausalLM"),d(hq,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(pq,"href","/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),d(_q,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJForCausalLM"),d(uq,"href","/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianForCausalLM"),d(bq,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartForCausalLM"),d(vq,"href","/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),d(Fq,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(Tq,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusForCausalLM"),d(Mq,"href","/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartForCausalLM"),d(Eq,"href","/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),d(Cq,"href","/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),d(wq,"href","/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),d(Aq,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForCausalLM"),d(yq,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForCausalLM"),d(Lq,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForCausalLM"),d(xq,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),d(kq,"href","/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(Sq,"href","/docs/transformers/pr_16792/en/model_doc/trocr#transformers.TrOCRForCausalLM"),d(Rq,"href","/docs/transformers/pr_16792/en/model_doc/xglm#transformers.XGLMForCausalLM"),d(Bq,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(Pq,"href","/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),d($q,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),d(Iq,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),d(qq,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(Ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(L2,"id","transformers.AutoModelForMaskedLM"),d(L2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(L2,"href","#transformers.AutoModelForMaskedLM"),d(pd,"class","relative group"),d(Nq,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jq,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Dq,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gq,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForMaskedLM"),d(Oq,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(Vq,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForMaskedLM"),d(Xq,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),d(zq,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(Qq,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),d(Wq,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(Hq,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(Uq,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(Jq,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(Yq,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForMaskedLM"),d(Kq,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(Zq,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForMaskedLM"),d(eN,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForMaskedLM"),d(oN,"href","/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(rN,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(tN,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(aN,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(nN,"href","/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),d(sN,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),d(lN,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(iN,"href","/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),d(dN,"href","/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),d(cN,"href","/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),d(fN,"href","/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerForMaskedLM"),d(mN,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForMaskedLM"),d(gN,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(hN,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),d(pN,"href","/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(_N,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(uN,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(bN,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(vN,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(FN,"href","/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoForMaskedLM"),d(Oe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(f1,"id","transformers.AutoModelForSeq2SeqLM"),d(f1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f1,"href","#transformers.AutoModelForSeq2SeqLM"),d(bd,"class","relative group"),d(TN,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(MN,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(EN,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(CN,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(wN,"href","/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),d(AN,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),d(yN,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),d(LN,"href","/docs/transformers/pr_16792/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),d(xN,"href","/docs/transformers/pr_16792/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(kN,"href","/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDForConditionalGeneration"),d(SN,"href","/docs/transformers/pr_16792/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),d(RN,"href","/docs/transformers/pr_16792/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(BN,"href","/docs/transformers/pr_16792/en/model_doc/marian#transformers.MarianMTModel"),d(PN,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d($N,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),d(IN,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),d(qN,"href","/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),d(NN,"href","/docs/transformers/pr_16792/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),d(jN,"href","/docs/transformers/pr_16792/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(DN,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(GN,"href","/docs/transformers/pr_16792/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),d(Ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(S1,"id","transformers.AutoModelForSequenceClassification"),d(S1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(S1,"href","#transformers.AutoModelForSequenceClassification"),d(Td,"class","relative group"),d(ON,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(VN,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(XN,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zN,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForSequenceClassification"),d(QN,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForSequenceClassification"),d(WN,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForSequenceClassification"),d(HN,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),d(UN,"href","/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),d(JN,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),d(YN,"href","/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineForSequenceClassification"),d(KN,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),d(ZN,"href","/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),d(ej,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),d(oj,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),d(rj,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),d(tj,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),d(aj,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForSequenceClassification"),d(nj,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),d(sj,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForSequenceClassification"),d(lj,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),d(ij,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),d(dj,"href","/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),d(cj,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),d(fj,"href","/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForSequenceClassification"),d(mj,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),d(gj,"href","/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),d(hj,"href","/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDForSequenceClassification"),d(pj,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),d(_j,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartForSequenceClassification"),d(uj,"href","/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),d(bj,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),d(vj,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),d(Fj,"href","/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),d(Tj,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),d(Mj,"href","/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),d(Ej,"href","/docs/transformers/pr_16792/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),d(Cj,"href","/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),d(wj,"href","/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),d(Aj,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),d(yj,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),d(Lj,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),d(xj,"href","/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),d(kj,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasForSequenceClassification"),d(Sj,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForSequenceClassification"),d(Rj,"href","/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),d(Bj,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMForSequenceClassification"),d(Pj,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),d($j,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),d(Ij,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),d(qj,"href","/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoForSequenceClassification"),d(Xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ab,"id","transformers.AutoModelForMultipleChoice"),d(Ab,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ab,"href","#transformers.AutoModelForMultipleChoice"),d(Cd,"class","relative group"),d(Nj,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jj,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Dj,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gj,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForMultipleChoice"),d(Oj,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForMultipleChoice"),d(Vj,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),d(Xj,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),d(zj,"href","/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineForMultipleChoice"),d(Qj,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),d(Wj,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),d(Hj,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),d(Uj,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForMultipleChoice"),d(Jj,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),d(Yj,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForMultipleChoice"),d(Kj,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),d(Zj,"href","/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForMultipleChoice"),d(eD,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),d(oD,"href","/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),d(rD,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),d(tD,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),d(aD,"href","/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),d(nD,"href","/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),d(sD,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),d(lD,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),d(iD,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),d(dD,"href","/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),d(cD,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMForMultipleChoice"),d(fD,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),d(mD,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),d(gD,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),d(hD,"href","/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoForMultipleChoice"),d(ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(r6,"id","transformers.AutoModelForNextSentencePrediction"),d(r6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(r6,"href","#transformers.AutoModelForNextSentencePrediction"),d(yd,"class","relative group"),d(pD,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_D,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(uD,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bD,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForNextSentencePrediction"),d(vD,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),d(FD,"href","/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),d(TD,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),d(MD,"href","/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),d(Qe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(d6,"id","transformers.AutoModelForTokenClassification"),d(d6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(d6,"href","#transformers.AutoModelForTokenClassification"),d(kd,"class","relative group"),d(ED,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(CD,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(wD,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(AD,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForTokenClassification"),d(yD,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForTokenClassification"),d(LD,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),d(xD,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForTokenClassification"),d(kD,"href","/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineForTokenClassification"),d(SD,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),d(RD,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),d(BD,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaForTokenClassification"),d(PD,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),d($D,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),d(ID,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForTokenClassification"),d(qD,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),d(ND,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForTokenClassification"),d(jD,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForTokenClassification"),d(DD,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),d(GD,"href","/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForTokenClassification"),d(OD,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),d(VD,"href","/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),d(XD,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForTokenClassification"),d(zD,"href","/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),d(QD,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),d(WD,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),d(HD,"href","/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),d(UD,"href","/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),d(JD,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForTokenClassification"),d(YD,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForTokenClassification"),d(KD,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),d(ZD,"href","/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),d(eG,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMForTokenClassification"),d(oG,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),d(rG,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),d(tG,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),d(aG,"href","/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoForTokenClassification"),d(We,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(X6,"id","transformers.AutoModelForQuestionAnswering"),d(X6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(X6,"href","#transformers.AutoModelForQuestionAnswering"),d(Bd,"class","relative group"),d(nG,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sG,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lG,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iG,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),d(dG,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.BartForQuestionAnswering"),d(cG,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.BertForQuestionAnswering"),d(fG,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),d(mG,"href","/docs/transformers/pr_16792/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),d(gG,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),d(hG,"href","/docs/transformers/pr_16792/en/model_doc/canine#transformers.CanineForQuestionAnswering"),d(pG,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),d(_G,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),d(uG,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),d(bG,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),d(vG,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),d(FG,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),d(TG,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),d(MG,"href","/docs/transformers/pr_16792/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),d(EG,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),d(CG,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),d(wG,"href","/docs/transformers/pr_16792/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),d(AG,"href","/docs/transformers/pr_16792/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(yG,"href","/docs/transformers/pr_16792/en/model_doc/led#transformers.LEDForQuestionAnswering"),d(LG,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),d(xG,"href","/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),d(kG,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),d(SG,"href","/docs/transformers/pr_16792/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),d(RG,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),d(BG,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),d(PG,"href","/docs/transformers/pr_16792/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),d($G,"href","/docs/transformers/pr_16792/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),d(IG,"href","/docs/transformers/pr_16792/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),d(qG,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),d(NG,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),d(jG,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),d(DG,"href","/docs/transformers/pr_16792/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),d(GG,"href","/docs/transformers/pr_16792/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),d(OG,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),d(VG,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),d(XG,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),d(zG,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),d(QG,"href","/docs/transformers/pr_16792/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),d(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sv,"id","transformers.AutoModelForTableQuestionAnswering"),d(Sv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Sv,"href","#transformers.AutoModelForTableQuestionAnswering"),d(Id,"class","relative group"),d(WG,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(HG,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(UG,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(JG,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),d(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pv,"id","transformers.AutoModelForImageClassification"),d(Pv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Pv,"href","#transformers.AutoModelForImageClassification"),d(jd,"class","relative group"),d(YG,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(KG,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ZG,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(eO,"href","/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitForImageClassification"),d(oO,"href","/docs/transformers/pr_16792/en/model_doc/convnext#transformers.ConvNextForImageClassification"),d(rO,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),d(tO,"href","/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTForImageClassification"),d(aO,"href","/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),d(nO,"href","/docs/transformers/pr_16792/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),d(sO,"href","/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),d(lO,"href","/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),d(iO,"href","/docs/transformers/pr_16792/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),d(dO,"href","/docs/transformers/pr_16792/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),d(cO,"href","/docs/transformers/pr_16792/en/model_doc/regnet#transformers.RegNetForImageClassification"),d(fO,"href","/docs/transformers/pr_16792/en/model_doc/resnet#transformers.ResNetForImageClassification"),d(mO,"href","/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerForImageClassification"),d(gO,"href","/docs/transformers/pr_16792/en/model_doc/swin#transformers.SwinForImageClassification"),d(hO,"href","/docs/transformers/pr_16792/en/model_doc/van#transformers.VanForImageClassification"),d(pO,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTForImageClassification"),d(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wv,"id","transformers.AutoModelForVision2Seq"),d(Wv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Wv,"href","#transformers.AutoModelForVision2Seq"),d(Od,"class","relative group"),d(_O,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(uO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vO,"href","/docs/transformers/pr_16792/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),d(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jv,"id","transformers.AutoModelForAudioClassification"),d(Jv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Jv,"href","#transformers.AutoModelForAudioClassification"),d(zd,"class","relative group"),d(FO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(TO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(MO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(EO,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),d(CO,"href","/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertForSequenceClassification"),d(wO,"href","/docs/transformers/pr_16792/en/model_doc/sew#transformers.SEWForSequenceClassification"),d(AO,"href","/docs/transformers/pr_16792/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),d(yO,"href","/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),d(LO,"href","/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),d(xO,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),d(kO,"href","/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),d(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sF,"id","transformers.AutoModelForAudioFrameClassification"),d(sF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(sF,"href","#transformers.AutoModelForAudioFrameClassification"),d(Hd,"class","relative group"),d(SO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(RO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(BO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(PO,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),d($O,"href","/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),d(IO,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),d(qO,"href","/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),d(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mF,"id","transformers.AutoModelForCTC"),d(mF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(mF,"href","#transformers.AutoModelForCTC"),d(Yd,"class","relative group"),d(NO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(DO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(GO,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),d(OO,"href","/docs/transformers/pr_16792/en/model_doc/hubert#transformers.HubertForCTC"),d(VO,"href","/docs/transformers/pr_16792/en/model_doc/sew#transformers.SEWForCTC"),d(XO,"href","/docs/transformers/pr_16792/en/model_doc/sew-d#transformers.SEWDForCTC"),d(zO,"href","/docs/transformers/pr_16792/en/model_doc/unispeech#transformers.UniSpeechForCTC"),d(QO,"href","/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),d(WO,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),d(HO,"href","/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMForCTC"),d(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(MF,"id","transformers.AutoModelForSpeechSeq2Seq"),d(MF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(MF,"href","#transformers.AutoModelForSpeechSeq2Seq"),d(ec,"class","relative group"),d(UO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(JO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(YO,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(KO,"href","/docs/transformers/pr_16792/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),d(ZO,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),d(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(AF,"id","transformers.AutoModelForAudioXVector"),d(AF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(AF,"href","#transformers.AutoModelForAudioXVector"),d(tc,"class","relative group"),d(eV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(oV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(rV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tV,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),d(aV,"href","/docs/transformers/pr_16792/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),d(nV,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),d(sV,"href","/docs/transformers/pr_16792/en/model_doc/wavlm#transformers.WavLMForXVector"),d(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(RF,"id","transformers.AutoModelForMaskedImageModeling"),d(RF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(RF,"href","#transformers.AutoModelForMaskedImageModeling"),d(sc,"class","relative group"),d(lV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(iV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(dV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cV,"href","/docs/transformers/pr_16792/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),d(fV,"href","/docs/transformers/pr_16792/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),d(mV,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),d(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qF,"id","transformers.AutoModelForObjectDetection"),d(qF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qF,"href","#transformers.AutoModelForObjectDetection"),d(cc,"class","relative group"),d(gV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(hV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(pV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_V,"href","/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrForObjectDetection"),d(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(DF,"id","transformers.AutoModelForImageSegmentation"),d(DF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(DF,"href","#transformers.AutoModelForImageSegmentation"),d(gc,"class","relative group"),d(uV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(bV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(vV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(FV,"href","/docs/transformers/pr_16792/en/model_doc/detr#transformers.DetrForSegmentation"),d(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(VF,"id","transformers.AutoModelForSemanticSegmentation"),d(VF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(VF,"href","#transformers.AutoModelForSemanticSegmentation"),d(_c,"class","relative group"),d(TV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(MV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(EV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(CV,"href","/docs/transformers/pr_16792/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),d(wV,"href","/docs/transformers/pr_16792/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),d(AV,"href","/docs/transformers/pr_16792/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),d(yV,"href","/docs/transformers/pr_16792/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),d(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(UF,"id","transformers.AutoModelForInstanceSegmentation"),d(UF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(UF,"href","#transformers.AutoModelForInstanceSegmentation"),d(vc,"class","relative group"),d(LV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(kV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(SV,"href","/docs/transformers/pr_16792/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),d(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(KF,"id","transformers.TFAutoModel"),d(KF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(KF,"href","#transformers.TFAutoModel"),d(Mc,"class","relative group"),d(RV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(BV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(PV,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($V,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertModel"),d(IV,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.TFBartModel"),d(qV,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertModel"),d(NV,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),d(jV,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),d(DV,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertModel"),d(GV,"href","/docs/transformers/pr_16792/en/model_doc/clip#transformers.TFCLIPModel"),d(OV,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertModel"),d(VV,"href","/docs/transformers/pr_16792/en/model_doc/convnext#transformers.TFConvNextModel"),d(XV,"href","/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.TFCTRLModel"),d(zV,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.TFDebertaModel"),d(QV,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),d(WV,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertModel"),d(HV,"href","/docs/transformers/pr_16792/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),d(UV,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraModel"),d(JV,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertModel"),d(YV,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelModel"),d(KV,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelBaseModel"),d(ZV,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.TFGPT2Model"),d(eX,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.TFGPTJModel"),d(oX,"href","/docs/transformers/pr_16792/en/model_doc/hubert#transformers.TFHubertModel"),d(rX,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),d(tX,"href","/docs/transformers/pr_16792/en/model_doc/led#transformers.TFLEDModel"),d(aX,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerModel"),d(nX,"href","/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.TFLxmertModel"),d(sX,"href","/docs/transformers/pr_16792/en/model_doc/marian#transformers.TFMarianModel"),d(lX,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.TFMBartModel"),d(iX,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertModel"),d(dX,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetModel"),d(cX,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.TFMT5Model"),d(fX,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),d(mX,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.TFPegasusModel"),d(gX,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertModel"),d(hX,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaModel"),d(pX,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerModel"),d(_X,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),d(uX,"href","/docs/transformers/pr_16792/en/model_doc/t5#transformers.TFT5Model"),d(bX,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TFTapasModel"),d(vX,"href","/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),d(FX,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.TFViTModel"),d(TX,"href","/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.TFViTMAEModel"),d(MX,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),d(EX,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMModel"),d(CX,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),d(wX,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetModel"),d(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(OT,"id","transformers.TFAutoModelForPreTraining"),d(OT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(OT,"href","#transformers.TFAutoModelForPreTraining"),d(wc,"class","relative group"),d(AX,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yX,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(LX,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xX,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForPreTraining"),d(kX,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(SX,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForPreTraining"),d(RX,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(BX,"href","/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(PX,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d($X,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForPreTraining"),d(IX,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(qX,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),d(NX,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(jX,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(DX,"href","/docs/transformers/pr_16792/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),d(GX,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),d(OX,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(VX,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(XX,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(zX,"href","/docs/transformers/pr_16792/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(QX,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(WX,"href","/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(HX,"href","/docs/transformers/pr_16792/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),d(UX,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(JX,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(YX,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(m7,"id","transformers.TFAutoModelForCausalLM"),d(m7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(m7,"href","#transformers.TFAutoModelForCausalLM"),d(Lc,"class","relative group"),d(KX,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ZX,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ez,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(oz,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertLMHeadModel"),d(rz,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),d(tz,"href","/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(az,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(nz,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),d(sz,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(lz,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),d(iz,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),d(dz,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),d(cz,"href","/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(fz,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(mz,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w7,"id","transformers.TFAutoModelForImageClassification"),d(w7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w7,"href","#transformers.TFAutoModelForImageClassification"),d(Sc,"class","relative group"),d(gz,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(hz,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(pz,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_z,"href","/docs/transformers/pr_16792/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),d(uz,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.TFViTForImageClassification"),d(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(L7,"id","transformers.TFAutoModelForMaskedLM"),d(L7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(L7,"href","#transformers.TFAutoModelForMaskedLM"),d(Pc,"class","relative group"),d(bz,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vz,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Fz,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tz,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),d(Mz,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForMaskedLM"),d(Ez,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(Cz,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),d(wz,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),d(Az,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),d(yz,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(Lz,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForMaskedLM"),d(xz,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(kz,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),d(Sz,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(Rz,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),d(Bz,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),d(Pz,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d($z,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),d(Iz,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(qz,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),d(Nz,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(jz,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(Dz,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(U7,"id","transformers.TFAutoModelForSeq2SeqLM"),d(U7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(U7,"href","#transformers.TFAutoModelForSeq2SeqLM"),d(qc,"class","relative group"),d(Gz,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Oz,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Vz,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xz,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(zz,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),d(Qz,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),d(Wz,"href","/docs/transformers/pr_16792/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),d(Hz,"href","/docs/transformers/pr_16792/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),d(Uz,"href","/docs/transformers/pr_16792/en/model_doc/marian#transformers.TFMarianMTModel"),d(Jz,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),d(Yz,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),d(Kz,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),d(Zz,"href","/docs/transformers/pr_16792/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(s9,"id","transformers.TFAutoModelForSequenceClassification"),d(s9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(s9,"href","#transformers.TFAutoModelForSequenceClassification"),d(Dc,"class","relative group"),d(eQ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(oQ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(rQ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tQ,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),d(aQ,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForSequenceClassification"),d(nQ,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),d(sQ,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),d(lQ,"href","/docs/transformers/pr_16792/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),d(iQ,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),d(dQ,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),d(cQ,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),d(fQ,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),d(mQ,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),d(gQ,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),d(hQ,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),d(pQ,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),d(_Q,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),d(uQ,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),d(bQ,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),d(vQ,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),d(FQ,"href","/docs/transformers/pr_16792/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),d(TQ,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),d(MQ,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),d(EQ,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),d(CQ,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),d(wQ,"href","/docs/transformers/pr_16792/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),d(AQ,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),d(yQ,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),d(LQ,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),d(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(B9,"id","transformers.TFAutoModelForMultipleChoice"),d(B9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(B9,"href","#transformers.TFAutoModelForMultipleChoice"),d(Vc,"class","relative group"),d(xQ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kQ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(SQ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(RQ,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),d(BQ,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForMultipleChoice"),d(PQ,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),d($Q,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),d(IQ,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),d(qQ,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),d(NQ,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),d(jQ,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),d(DQ,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),d(GQ,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),d(OQ,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),d(VQ,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),d(XQ,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),d(zQ,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),d(QQ,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),d(WQ,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),d(HQ,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),d(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Y9,"id","transformers.TFAutoModelForTableQuestionAnswering"),d(Y9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Y9,"href","#transformers.TFAutoModelForTableQuestionAnswering"),d(Qc,"class","relative group"),d(UQ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(JQ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(YQ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(KQ,"href","/docs/transformers/pr_16792/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),d(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Z9,"id","transformers.TFAutoModelForTokenClassification"),d(Z9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Z9,"href","#transformers.TFAutoModelForTokenClassification"),d(Uc,"class","relative group"),d(ZQ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(eW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(oW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rW,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),d(tW,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForTokenClassification"),d(aW,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),d(nW,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),d(sW,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),d(lW,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),d(iW,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),d(dW,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForTokenClassification"),d(cW,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),d(fW,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),d(mW,"href","/docs/transformers/pr_16792/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),d(gW,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),d(hW,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),d(pW,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),d(_W,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),d(uW,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),d(bW,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),d(vW,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),d(FW,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),d(TW,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),d(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(FM,"id","transformers.TFAutoModelForQuestionAnswering"),d(FM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(FM,"href","#transformers.TFAutoModelForQuestionAnswering"),d(Kc,"class","relative group"),d(MW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(EW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(CW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wW,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),d(AW,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),d(yW,"href","/docs/transformers/pr_16792/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),d(LW,"href","/docs/transformers/pr_16792/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),d(xW,"href","/docs/transformers/pr_16792/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),d(kW,"href","/docs/transformers/pr_16792/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),d(SW,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),d(RW,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),d(BW,"href","/docs/transformers/pr_16792/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),d(PW,"href","/docs/transformers/pr_16792/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),d($W,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),d(IW,"href","/docs/transformers/pr_16792/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),d(qW,"href","/docs/transformers/pr_16792/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),d(NW,"href","/docs/transformers/pr_16792/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),d(jW,"href","/docs/transformers/pr_16792/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),d(DW,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),d(GW,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),d(OW,"href","/docs/transformers/pr_16792/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),d(VW,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),d(XW,"href","/docs/transformers/pr_16792/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),d(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(GM,"id","transformers.TFAutoModelForVision2Seq"),d(GM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(GM,"href","#transformers.TFAutoModelForVision2Seq"),d(of,"class","relative group"),d(zW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(QW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(WW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(HW,"href","/docs/transformers/pr_16792/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),d(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(VM,"id","transformers.TFAutoModelForSpeechSeq2Seq"),d(VM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(VM,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),d(af,"class","relative group"),d(UW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(JW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(YW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(KW,"href","/docs/transformers/pr_16792/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),d(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zM,"id","transformers.FlaxAutoModel"),d(zM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(zM,"href","#transformers.FlaxAutoModel"),d(lf,"class","relative group"),d(ZW,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(eH,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(oH,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rH,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertModel"),d(tH,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartModel"),d(aH,"href","/docs/transformers/pr_16792/en/model_doc/beit#transformers.FlaxBeitModel"),d(nH,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertModel"),d(sH,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),d(lH,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),d(iH,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),d(dH,"href","/docs/transformers/pr_16792/en/model_doc/clip#transformers.FlaxCLIPModel"),d(cH,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),d(fH,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraModel"),d(mH,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.FlaxGPT2Model"),d(gH,"href","/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),d(hH,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.FlaxGPTJModel"),d(pH,"href","/docs/transformers/pr_16792/en/model_doc/longt5#transformers.FlaxLongT5Model"),d(_H,"href","/docs/transformers/pr_16792/en/model_doc/marian#transformers.FlaxMarianModel"),d(uH,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartModel"),d(bH,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.FlaxMT5Model"),d(vH,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.FlaxPegasusModel"),d(FH,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaModel"),d(TH,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerModel"),d(MH,"href","/docs/transformers/pr_16792/en/model_doc/t5#transformers.FlaxT5Model"),d(EH,"href","/docs/transformers/pr_16792/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),d(CH,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.FlaxViTModel"),d(wH,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),d(AH,"href","/docs/transformers/pr_16792/en/model_doc/xglm#transformers.FlaxXGLMModel"),d(yH,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),d(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(b4,"id","transformers.FlaxAutoModelForCausalLM"),d(b4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(b4,"href","#transformers.FlaxAutoModelForCausalLM"),d(ff,"class","relative group"),d(LH,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xH,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(kH,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(SH,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForCausalLM"),d(RH,"href","/docs/transformers/pr_16792/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),d(BH,"href","/docs/transformers/pr_16792/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),d(PH,"href","/docs/transformers/pr_16792/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),d($H,"href","/docs/transformers/pr_16792/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),d(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(C4,"id","transformers.FlaxAutoModelForPreTraining"),d(C4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(C4,"href","#transformers.FlaxAutoModelForPreTraining"),d(hf,"class","relative group"),d(IH,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qH,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(NH,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jH,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),d(DH,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(GH,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForPreTraining"),d(OH,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),d(VH,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),d(XH,"href","/docs/transformers/pr_16792/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(zH,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(QH,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(WH,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(HH,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(UH,"href","/docs/transformers/pr_16792/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(JH,"href","/docs/transformers/pr_16792/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),d(YH,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N4,"id","transformers.FlaxAutoModelForMaskedLM"),d(N4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N4,"href","#transformers.FlaxAutoModelForMaskedLM"),d(uf,"class","relative group"),d(KH,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ZH,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(eU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(oU,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),d(rU,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(tU,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),d(aU,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),d(nU,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),d(sU,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),d(lU,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(iU,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(dU,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(cU,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(U4,"id","transformers.FlaxAutoModelForSeq2SeqLM"),d(U4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(U4,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),d(Ff,"class","relative group"),d(fU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hU,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(pU,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),d(_U,"href","/docs/transformers/pr_16792/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),d(uU,"href","/docs/transformers/pr_16792/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),d(bU,"href","/docs/transformers/pr_16792/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(vU,"href","/docs/transformers/pr_16792/en/model_doc/marian#transformers.FlaxMarianMTModel"),d(FU,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(TU,"href","/docs/transformers/pr_16792/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(MU,"href","/docs/transformers/pr_16792/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),d(EU,"href","/docs/transformers/pr_16792/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sE,"id","transformers.FlaxAutoModelForSequenceClassification"),d(sE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(sE,"href","#transformers.FlaxAutoModelForSequenceClassification"),d(Ef,"class","relative group"),d(CU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(AU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yU,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),d(LU,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),d(xU,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),d(kU,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),d(SU,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),d(RU,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),d(BU,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),d(PU,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),d($U,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),d(IU,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),d(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(uE,"id","transformers.FlaxAutoModelForQuestionAnswering"),d(uE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(uE,"href","#transformers.FlaxAutoModelForQuestionAnswering"),d(Af,"class","relative group"),d(qU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(NU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(jU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(DU,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),d(GU,"href","/docs/transformers/pr_16792/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),d(OU,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),d(VU,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),d(XU,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),d(zU,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),d(QU,"href","/docs/transformers/pr_16792/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),d(WU,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),d(HU,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),d(UU,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),d(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(LE,"id","transformers.FlaxAutoModelForTokenClassification"),d(LE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(LE,"href","#transformers.FlaxAutoModelForTokenClassification"),d(xf,"class","relative group"),d(JU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(YU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(KU,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ZU,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),d(eJ,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),d(oJ,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),d(rJ,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),d(tJ,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),d(aJ,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),d(nJ,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),d(sJ,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),d($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qE,"id","transformers.FlaxAutoModelForMultipleChoice"),d(qE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qE,"href","#transformers.FlaxAutoModelForMultipleChoice"),d(Rf,"class","relative group"),d(lJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(iJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(dJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cJ,"href","/docs/transformers/pr_16792/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),d(fJ,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),d(mJ,"href","/docs/transformers/pr_16792/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),d(gJ,"href","/docs/transformers/pr_16792/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),d(hJ,"href","/docs/transformers/pr_16792/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),d(pJ,"href","/docs/transformers/pr_16792/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),d(_J,"href","/docs/transformers/pr_16792/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),d(uJ,"href","/docs/transformers/pr_16792/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),d(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(QE,"id","transformers.FlaxAutoModelForNextSentencePrediction"),d(QE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(QE,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),d($f,"class","relative group"),d(bJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(FJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(TJ,"href","/docs/transformers/pr_16792/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),d(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(HE,"id","transformers.FlaxAutoModelForImageClassification"),d(HE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(HE,"href","#transformers.FlaxAutoModelForImageClassification"),d(Nf,"class","relative group"),d(MJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(EJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(CJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wJ,"href","/docs/transformers/pr_16792/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),d(AJ,"href","/docs/transformers/pr_16792/en/model_doc/vit#transformers.FlaxViTForImageClassification"),d(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(YE,"id","transformers.FlaxAutoModelForVision2Seq"),d(YE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(YE,"href","#transformers.FlaxAutoModelForVision2Seq"),d(Gf,"class","relative group"),d(yJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(LJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(xJ,"href","/docs/transformers/pr_16792/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kJ,"href","/docs/transformers/pr_16792/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),d(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,u){e(document.head,oe),b(c,co,u),b(c,ge,u),e(ge,Ae),e(Ae,io),g(ue,io,null),e(ge,we),e(ge,Xo),e(Xo,Qi),b(c,Qf,u),b(c,fa,u),e(fa,Wi),e(fa,Hi),e(Hi,Z5),e(fa,Wf),b(c,Re,u),b(c,fo,u),e(fo,Ui),e(fo,On),e(On,e3),e(fo,Vn),e(fo,Xn),e(Xn,o3),e(fo,Ji),e(fo,zn),e(zn,r3),e(fo,Yi),b(c,Hf,u),g(Da,c,u),b(c,mo,u),b(c,ve,u),e(ve,ex),e(ve,Ki),e(Ki,ox),e(ve,rx),b(c,zo,u),b(c,Ga,u),e(Ga,tx),e(Ga,Uf),e(Uf,ax),e(Ga,zNe),b(c,RPe,u),b(c,Zi,u),e(Zi,Jf),e(Jf,EK),g(t3,EK,null),e(Zi,QNe),e(Zi,CK),e(CK,WNe),b(c,BPe,u),b(c,Qn,u),e(Qn,HNe),e(Qn,wK),e(wK,UNe),e(Qn,JNe),e(Qn,AK),e(AK,YNe),e(Qn,KNe),b(c,PPe,u),g(a3,c,u),b(c,$Pe,u),b(c,nx,u),e(nx,ZNe),b(c,IPe,u),g(Yf,c,u),b(c,qPe,u),b(c,ed,u),e(ed,Kf),e(Kf,yK),g(n3,yK,null),e(ed,eje),e(ed,LK),e(LK,oje),b(c,NPe,u),b(c,Qo,u),g(s3,Qo,null),e(Qo,rje),e(Qo,l3),e(l3,tje),e(l3,sx),e(sx,aje),e(l3,nje),e(Qo,sje),e(Qo,i3),e(i3,lje),e(i3,xK),e(xK,ije),e(i3,dje),e(Qo,cje),e(Qo,go),g(d3,go,null),e(go,fje),e(go,kK),e(kK,mje),e(go,gje),e(go,od),e(od,hje),e(od,SK),e(SK,pje),e(od,_je),e(od,RK),e(RK,uje),e(od,bje),e(go,vje),e(go,v),e(v,Zf),e(Zf,BK),e(BK,Fje),e(Zf,Tje),e(Zf,lx),e(lx,Mje),e(Zf,Eje),e(v,Cje),e(v,em),e(em,PK),e(PK,wje),e(em,Aje),e(em,ix),e(ix,yje),e(em,Lje),e(v,xje),e(v,om),e(om,$K),e($K,kje),e(om,Sje),e(om,dx),e(dx,Rje),e(om,Bje),e(v,Pje),e(v,rm),e(rm,IK),e(IK,$je),e(rm,Ije),e(rm,cx),e(cx,qje),e(rm,Nje),e(v,jje),e(v,tm),e(tm,qK),e(qK,Dje),e(tm,Gje),e(tm,fx),e(fx,Oje),e(tm,Vje),e(v,Xje),e(v,am),e(am,NK),e(NK,zje),e(am,Qje),e(am,mx),e(mx,Wje),e(am,Hje),e(v,Uje),e(v,nm),e(nm,jK),e(jK,Jje),e(nm,Yje),e(nm,gx),e(gx,Kje),e(nm,Zje),e(v,eDe),e(v,sm),e(sm,DK),e(DK,oDe),e(sm,rDe),e(sm,hx),e(hx,tDe),e(sm,aDe),e(v,nDe),e(v,lm),e(lm,GK),e(GK,sDe),e(lm,lDe),e(lm,px),e(px,iDe),e(lm,dDe),e(v,cDe),e(v,im),e(im,OK),e(OK,fDe),e(im,mDe),e(im,_x),e(_x,gDe),e(im,hDe),e(v,pDe),e(v,dm),e(dm,VK),e(VK,_De),e(dm,uDe),e(dm,ux),e(ux,bDe),e(dm,vDe),e(v,FDe),e(v,cm),e(cm,XK),e(XK,TDe),e(cm,MDe),e(cm,bx),e(bx,EDe),e(cm,CDe),e(v,wDe),e(v,fm),e(fm,zK),e(zK,ADe),e(fm,yDe),e(fm,vx),e(vx,LDe),e(fm,xDe),e(v,kDe),e(v,mm),e(mm,QK),e(QK,SDe),e(mm,RDe),e(mm,Fx),e(Fx,BDe),e(mm,PDe),e(v,$De),e(v,gm),e(gm,WK),e(WK,IDe),e(gm,qDe),e(gm,Tx),e(Tx,NDe),e(gm,jDe),e(v,DDe),e(v,hm),e(hm,HK),e(HK,GDe),e(hm,ODe),e(hm,Mx),e(Mx,VDe),e(hm,XDe),e(v,zDe),e(v,pm),e(pm,UK),e(UK,QDe),e(pm,WDe),e(pm,Ex),e(Ex,HDe),e(pm,UDe),e(v,JDe),e(v,_m),e(_m,JK),e(JK,YDe),e(_m,KDe),e(_m,Cx),e(Cx,ZDe),e(_m,eGe),e(v,oGe),e(v,um),e(um,YK),e(YK,rGe),e(um,tGe),e(um,wx),e(wx,aGe),e(um,nGe),e(v,sGe),e(v,bm),e(bm,KK),e(KK,lGe),e(bm,iGe),e(bm,Ax),e(Ax,dGe),e(bm,cGe),e(v,fGe),e(v,vm),e(vm,ZK),e(ZK,mGe),e(vm,gGe),e(vm,yx),e(yx,hGe),e(vm,pGe),e(v,_Ge),e(v,Fm),e(Fm,eZ),e(eZ,uGe),e(Fm,bGe),e(Fm,Lx),e(Lx,vGe),e(Fm,FGe),e(v,TGe),e(v,Tm),e(Tm,oZ),e(oZ,MGe),e(Tm,EGe),e(Tm,xx),e(xx,CGe),e(Tm,wGe),e(v,AGe),e(v,Mm),e(Mm,rZ),e(rZ,yGe),e(Mm,LGe),e(Mm,kx),e(kx,xGe),e(Mm,kGe),e(v,SGe),e(v,Em),e(Em,tZ),e(tZ,RGe),e(Em,BGe),e(Em,Sx),e(Sx,PGe),e(Em,$Ge),e(v,IGe),e(v,Cm),e(Cm,aZ),e(aZ,qGe),e(Cm,NGe),e(Cm,Rx),e(Rx,jGe),e(Cm,DGe),e(v,GGe),e(v,wm),e(wm,nZ),e(nZ,OGe),e(wm,VGe),e(wm,Bx),e(Bx,XGe),e(wm,zGe),e(v,QGe),e(v,Am),e(Am,sZ),e(sZ,WGe),e(Am,HGe),e(Am,Px),e(Px,UGe),e(Am,JGe),e(v,YGe),e(v,ym),e(ym,lZ),e(lZ,KGe),e(ym,ZGe),e(ym,$x),e($x,eOe),e(ym,oOe),e(v,rOe),e(v,Lm),e(Lm,iZ),e(iZ,tOe),e(Lm,aOe),e(Lm,Ix),e(Ix,nOe),e(Lm,sOe),e(v,lOe),e(v,xm),e(xm,dZ),e(dZ,iOe),e(xm,dOe),e(xm,qx),e(qx,cOe),e(xm,fOe),e(v,mOe),e(v,km),e(km,cZ),e(cZ,gOe),e(km,hOe),e(km,Nx),e(Nx,pOe),e(km,_Oe),e(v,uOe),e(v,Sm),e(Sm,fZ),e(fZ,bOe),e(Sm,vOe),e(Sm,jx),e(jx,FOe),e(Sm,TOe),e(v,MOe),e(v,Rm),e(Rm,mZ),e(mZ,EOe),e(Rm,COe),e(Rm,Dx),e(Dx,wOe),e(Rm,AOe),e(v,yOe),e(v,Bm),e(Bm,gZ),e(gZ,LOe),e(Bm,xOe),e(Bm,Gx),e(Gx,kOe),e(Bm,SOe),e(v,ROe),e(v,Pm),e(Pm,hZ),e(hZ,BOe),e(Pm,POe),e(Pm,Ox),e(Ox,$Oe),e(Pm,IOe),e(v,qOe),e(v,$m),e($m,pZ),e(pZ,NOe),e($m,jOe),e($m,Vx),e(Vx,DOe),e($m,GOe),e(v,OOe),e(v,Im),e(Im,_Z),e(_Z,VOe),e(Im,XOe),e(Im,Xx),e(Xx,zOe),e(Im,QOe),e(v,WOe),e(v,qm),e(qm,uZ),e(uZ,HOe),e(qm,UOe),e(qm,zx),e(zx,JOe),e(qm,YOe),e(v,KOe),e(v,Nm),e(Nm,bZ),e(bZ,ZOe),e(Nm,eVe),e(Nm,Qx),e(Qx,oVe),e(Nm,rVe),e(v,tVe),e(v,jm),e(jm,vZ),e(vZ,aVe),e(jm,nVe),e(jm,Wx),e(Wx,sVe),e(jm,lVe),e(v,iVe),e(v,Dm),e(Dm,FZ),e(FZ,dVe),e(Dm,cVe),e(Dm,Hx),e(Hx,fVe),e(Dm,mVe),e(v,gVe),e(v,Gm),e(Gm,TZ),e(TZ,hVe),e(Gm,pVe),e(Gm,Ux),e(Ux,_Ve),e(Gm,uVe),e(v,bVe),e(v,Om),e(Om,MZ),e(MZ,vVe),e(Om,FVe),e(Om,Jx),e(Jx,TVe),e(Om,MVe),e(v,EVe),e(v,Vm),e(Vm,EZ),e(EZ,CVe),e(Vm,wVe),e(Vm,Yx),e(Yx,AVe),e(Vm,yVe),e(v,LVe),e(v,Xm),e(Xm,CZ),e(CZ,xVe),e(Xm,kVe),e(Xm,Kx),e(Kx,SVe),e(Xm,RVe),e(v,BVe),e(v,zm),e(zm,wZ),e(wZ,PVe),e(zm,$Ve),e(zm,Zx),e(Zx,IVe),e(zm,qVe),e(v,NVe),e(v,Qm),e(Qm,AZ),e(AZ,jVe),e(Qm,DVe),e(Qm,ek),e(ek,GVe),e(Qm,OVe),e(v,VVe),e(v,Wm),e(Wm,yZ),e(yZ,XVe),e(Wm,zVe),e(Wm,ok),e(ok,QVe),e(Wm,WVe),e(v,HVe),e(v,Hm),e(Hm,LZ),e(LZ,UVe),e(Hm,JVe),e(Hm,rk),e(rk,YVe),e(Hm,KVe),e(v,ZVe),e(v,Um),e(Um,xZ),e(xZ,eXe),e(Um,oXe),e(Um,tk),e(tk,rXe),e(Um,tXe),e(v,aXe),e(v,Jm),e(Jm,kZ),e(kZ,nXe),e(Jm,sXe),e(Jm,ak),e(ak,lXe),e(Jm,iXe),e(v,dXe),e(v,Ym),e(Ym,SZ),e(SZ,cXe),e(Ym,fXe),e(Ym,nk),e(nk,mXe),e(Ym,gXe),e(v,hXe),e(v,Km),e(Km,RZ),e(RZ,pXe),e(Km,_Xe),e(Km,sk),e(sk,uXe),e(Km,bXe),e(v,vXe),e(v,Zm),e(Zm,BZ),e(BZ,FXe),e(Zm,TXe),e(Zm,lk),e(lk,MXe),e(Zm,EXe),e(v,CXe),e(v,eg),e(eg,PZ),e(PZ,wXe),e(eg,AXe),e(eg,ik),e(ik,yXe),e(eg,LXe),e(v,xXe),e(v,og),e(og,$Z),e($Z,kXe),e(og,SXe),e(og,dk),e(dk,RXe),e(og,BXe),e(v,PXe),e(v,rg),e(rg,IZ),e(IZ,$Xe),e(rg,IXe),e(rg,ck),e(ck,qXe),e(rg,NXe),e(v,jXe),e(v,tg),e(tg,qZ),e(qZ,DXe),e(tg,GXe),e(tg,fk),e(fk,OXe),e(tg,VXe),e(v,XXe),e(v,ag),e(ag,NZ),e(NZ,zXe),e(ag,QXe),e(ag,mk),e(mk,WXe),e(ag,HXe),e(v,UXe),e(v,ng),e(ng,jZ),e(jZ,JXe),e(ng,YXe),e(ng,gk),e(gk,KXe),e(ng,ZXe),e(v,eze),e(v,sg),e(sg,DZ),e(DZ,oze),e(sg,rze),e(sg,hk),e(hk,tze),e(sg,aze),e(v,nze),e(v,lg),e(lg,GZ),e(GZ,sze),e(lg,lze),e(lg,pk),e(pk,ize),e(lg,dze),e(v,cze),e(v,ig),e(ig,OZ),e(OZ,fze),e(ig,mze),e(ig,_k),e(_k,gze),e(ig,hze),e(v,pze),e(v,dg),e(dg,VZ),e(VZ,_ze),e(dg,uze),e(dg,uk),e(uk,bze),e(dg,vze),e(v,Fze),e(v,cg),e(cg,XZ),e(XZ,Tze),e(cg,Mze),e(cg,bk),e(bk,Eze),e(cg,Cze),e(v,wze),e(v,fg),e(fg,zZ),e(zZ,Aze),e(fg,yze),e(fg,vk),e(vk,Lze),e(fg,xze),e(v,kze),e(v,mg),e(mg,QZ),e(QZ,Sze),e(mg,Rze),e(mg,Fk),e(Fk,Bze),e(mg,Pze),e(v,$ze),e(v,gg),e(gg,WZ),e(WZ,Ize),e(gg,qze),e(gg,Tk),e(Tk,Nze),e(gg,jze),e(v,Dze),e(v,hg),e(hg,HZ),e(HZ,Gze),e(hg,Oze),e(hg,Mk),e(Mk,Vze),e(hg,Xze),e(v,zze),e(v,pg),e(pg,UZ),e(UZ,Qze),e(pg,Wze),e(pg,Ek),e(Ek,Hze),e(pg,Uze),e(v,Jze),e(v,_g),e(_g,JZ),e(JZ,Yze),e(_g,Kze),e(_g,Ck),e(Ck,Zze),e(_g,eQe),e(v,oQe),e(v,ug),e(ug,YZ),e(YZ,rQe),e(ug,tQe),e(ug,wk),e(wk,aQe),e(ug,nQe),e(v,sQe),e(v,bg),e(bg,KZ),e(KZ,lQe),e(bg,iQe),e(bg,Ak),e(Ak,dQe),e(bg,cQe),e(v,fQe),e(v,vg),e(vg,ZZ),e(ZZ,mQe),e(vg,gQe),e(vg,yk),e(yk,hQe),e(vg,pQe),e(v,_Qe),e(v,Fg),e(Fg,eee),e(eee,uQe),e(Fg,bQe),e(Fg,Lk),e(Lk,vQe),e(Fg,FQe),e(v,TQe),e(v,Tg),e(Tg,oee),e(oee,MQe),e(Tg,EQe),e(Tg,xk),e(xk,CQe),e(Tg,wQe),e(v,AQe),e(v,Mg),e(Mg,ree),e(ree,yQe),e(Mg,LQe),e(Mg,kk),e(kk,xQe),e(Mg,kQe),e(v,SQe),e(v,Eg),e(Eg,tee),e(tee,RQe),e(Eg,BQe),e(Eg,Sk),e(Sk,PQe),e(Eg,$Qe),e(v,IQe),e(v,Cg),e(Cg,aee),e(aee,qQe),e(Cg,NQe),e(Cg,Rk),e(Rk,jQe),e(Cg,DQe),e(v,GQe),e(v,wg),e(wg,nee),e(nee,OQe),e(wg,VQe),e(wg,Bk),e(Bk,XQe),e(wg,zQe),e(v,QQe),e(v,Ag),e(Ag,see),e(see,WQe),e(Ag,HQe),e(Ag,Pk),e(Pk,UQe),e(Ag,JQe),e(v,YQe),e(v,yg),e(yg,lee),e(lee,KQe),e(yg,ZQe),e(yg,$k),e($k,eWe),e(yg,oWe),e(v,rWe),e(v,Lg),e(Lg,iee),e(iee,tWe),e(Lg,aWe),e(Lg,Ik),e(Ik,nWe),e(Lg,sWe),e(v,lWe),e(v,xg),e(xg,dee),e(dee,iWe),e(xg,dWe),e(xg,qk),e(qk,cWe),e(xg,fWe),e(v,mWe),e(v,kg),e(kg,cee),e(cee,gWe),e(kg,hWe),e(kg,Nk),e(Nk,pWe),e(kg,_We),e(v,uWe),e(v,Sg),e(Sg,fee),e(fee,bWe),e(Sg,vWe),e(Sg,jk),e(jk,FWe),e(Sg,TWe),e(v,MWe),e(v,Rg),e(Rg,mee),e(mee,EWe),e(Rg,CWe),e(Rg,Dk),e(Dk,wWe),e(Rg,AWe),e(v,yWe),e(v,Bg),e(Bg,gee),e(gee,LWe),e(Bg,xWe),e(Bg,Gk),e(Gk,kWe),e(Bg,SWe),e(v,RWe),e(v,Pg),e(Pg,hee),e(hee,BWe),e(Pg,PWe),e(Pg,Ok),e(Ok,$We),e(Pg,IWe),e(v,qWe),e(v,$g),e($g,pee),e(pee,NWe),e($g,jWe),e($g,Vk),e(Vk,DWe),e($g,GWe),e(v,OWe),e(v,Ig),e(Ig,_ee),e(_ee,VWe),e(Ig,XWe),e(Ig,Xk),e(Xk,zWe),e(Ig,QWe),e(v,WWe),e(v,qg),e(qg,uee),e(uee,HWe),e(qg,UWe),e(qg,zk),e(zk,JWe),e(qg,YWe),e(v,KWe),e(v,Ng),e(Ng,bee),e(bee,ZWe),e(Ng,eHe),e(Ng,Qk),e(Qk,oHe),e(Ng,rHe),e(v,tHe),e(v,jg),e(jg,vee),e(vee,aHe),e(jg,nHe),e(jg,Wk),e(Wk,sHe),e(jg,lHe),e(v,iHe),e(v,Dg),e(Dg,Fee),e(Fee,dHe),e(Dg,cHe),e(Dg,Hk),e(Hk,fHe),e(Dg,mHe),e(v,gHe),e(v,Gg),e(Gg,Tee),e(Tee,hHe),e(Gg,pHe),e(Gg,Uk),e(Uk,_He),e(Gg,uHe),e(v,bHe),e(v,Og),e(Og,Mee),e(Mee,vHe),e(Og,FHe),e(Og,Jk),e(Jk,THe),e(Og,MHe),e(v,EHe),e(v,Vg),e(Vg,Eee),e(Eee,CHe),e(Vg,wHe),e(Vg,Yk),e(Yk,AHe),e(Vg,yHe),e(v,LHe),e(v,Xg),e(Xg,Cee),e(Cee,xHe),e(Xg,kHe),e(Xg,Kk),e(Kk,SHe),e(Xg,RHe),e(v,BHe),e(v,zg),e(zg,wee),e(wee,PHe),e(zg,$He),e(zg,Zk),e(Zk,IHe),e(zg,qHe),e(v,NHe),e(v,Qg),e(Qg,Aee),e(Aee,jHe),e(Qg,DHe),e(Qg,eS),e(eS,GHe),e(Qg,OHe),e(v,VHe),e(v,Wg),e(Wg,yee),e(yee,XHe),e(Wg,zHe),e(Wg,oS),e(oS,QHe),e(Wg,WHe),e(go,HHe),e(go,Lee),e(Lee,UHe),e(go,JHe),g(c3,go,null),e(Qo,YHe),e(Qo,Hg),g(f3,Hg,null),e(Hg,KHe),e(Hg,xee),e(xee,ZHe),b(c,jPe,u),b(c,rd,u),e(rd,Ug),e(Ug,kee),g(m3,kee,null),e(rd,eUe),e(rd,See),e(See,oUe),b(c,DPe,u),b(c,Wo,u),g(g3,Wo,null),e(Wo,rUe),e(Wo,h3),e(h3,tUe),e(h3,rS),e(rS,aUe),e(h3,nUe),e(Wo,sUe),e(Wo,p3),e(p3,lUe),e(p3,Ree),e(Ree,iUe),e(p3,dUe),e(Wo,cUe),e(Wo,ho),g(_3,ho,null),e(ho,fUe),e(ho,Bee),e(Bee,mUe),e(ho,gUe),e(ho,Oa),e(Oa,hUe),e(Oa,Pee),e(Pee,pUe),e(Oa,_Ue),e(Oa,$ee),e($ee,uUe),e(Oa,bUe),e(Oa,Iee),e(Iee,vUe),e(Oa,FUe),e(ho,TUe),e(ho,E),e(E,Wn),e(Wn,qee),e(qee,MUe),e(Wn,EUe),e(Wn,tS),e(tS,CUe),e(Wn,wUe),e(Wn,aS),e(aS,AUe),e(Wn,yUe),e(E,LUe),e(E,Hn),e(Hn,Nee),e(Nee,xUe),e(Hn,kUe),e(Hn,nS),e(nS,SUe),e(Hn,RUe),e(Hn,sS),e(sS,BUe),e(Hn,PUe),e(E,$Ue),e(E,Un),e(Un,jee),e(jee,IUe),e(Un,qUe),e(Un,lS),e(lS,NUe),e(Un,jUe),e(Un,iS),e(iS,DUe),e(Un,GUe),e(E,OUe),e(E,Jg),e(Jg,Dee),e(Dee,VUe),e(Jg,XUe),e(Jg,dS),e(dS,zUe),e(Jg,QUe),e(E,WUe),e(E,Jn),e(Jn,Gee),e(Gee,HUe),e(Jn,UUe),e(Jn,cS),e(cS,JUe),e(Jn,YUe),e(Jn,fS),e(fS,KUe),e(Jn,ZUe),e(E,eJe),e(E,Yg),e(Yg,Oee),e(Oee,oJe),e(Yg,rJe),e(Yg,mS),e(mS,tJe),e(Yg,aJe),e(E,nJe),e(E,Kg),e(Kg,Vee),e(Vee,sJe),e(Kg,lJe),e(Kg,gS),e(gS,iJe),e(Kg,dJe),e(E,cJe),e(E,Zg),e(Zg,Xee),e(Xee,fJe),e(Zg,mJe),e(Zg,hS),e(hS,gJe),e(Zg,hJe),e(E,pJe),e(E,Yn),e(Yn,zee),e(zee,_Je),e(Yn,uJe),e(Yn,pS),e(pS,bJe),e(Yn,vJe),e(Yn,_S),e(_S,FJe),e(Yn,TJe),e(E,MJe),e(E,Kn),e(Kn,Qee),e(Qee,EJe),e(Kn,CJe),e(Kn,uS),e(uS,wJe),e(Kn,AJe),e(Kn,bS),e(bS,yJe),e(Kn,LJe),e(E,xJe),e(E,Zn),e(Zn,Wee),e(Wee,kJe),e(Zn,SJe),e(Zn,vS),e(vS,RJe),e(Zn,BJe),e(Zn,FS),e(FS,PJe),e(Zn,$Je),e(E,IJe),e(E,eh),e(eh,Hee),e(Hee,qJe),e(eh,NJe),e(eh,TS),e(TS,jJe),e(eh,DJe),e(E,GJe),e(E,oh),e(oh,Uee),e(Uee,OJe),e(oh,VJe),e(oh,MS),e(MS,XJe),e(oh,zJe),e(E,QJe),e(E,es),e(es,Jee),e(Jee,WJe),e(es,HJe),e(es,ES),e(ES,UJe),e(es,JJe),e(es,CS),e(CS,YJe),e(es,KJe),e(E,ZJe),e(E,rh),e(rh,Yee),e(Yee,eYe),e(rh,oYe),e(rh,wS),e(wS,rYe),e(rh,tYe),e(E,aYe),e(E,os),e(os,Kee),e(Kee,nYe),e(os,sYe),e(os,AS),e(AS,lYe),e(os,iYe),e(os,yS),e(yS,dYe),e(os,cYe),e(E,fYe),e(E,rs),e(rs,Zee),e(Zee,mYe),e(rs,gYe),e(rs,LS),e(LS,hYe),e(rs,pYe),e(rs,xS),e(xS,_Ye),e(rs,uYe),e(E,bYe),e(E,ts),e(ts,eoe),e(eoe,vYe),e(ts,FYe),e(ts,kS),e(kS,TYe),e(ts,MYe),e(ts,ooe),e(ooe,EYe),e(ts,CYe),e(E,wYe),e(E,th),e(th,roe),e(roe,AYe),e(th,yYe),e(th,SS),e(SS,LYe),e(th,xYe),e(E,kYe),e(E,as),e(as,toe),e(toe,SYe),e(as,RYe),e(as,RS),e(RS,BYe),e(as,PYe),e(as,BS),e(BS,$Ye),e(as,IYe),e(E,qYe),e(E,ns),e(ns,aoe),e(aoe,NYe),e(ns,jYe),e(ns,PS),e(PS,DYe),e(ns,GYe),e(ns,$S),e($S,OYe),e(ns,VYe),e(E,XYe),e(E,ss),e(ss,noe),e(noe,zYe),e(ss,QYe),e(ss,IS),e(IS,WYe),e(ss,HYe),e(ss,qS),e(qS,UYe),e(ss,JYe),e(E,YYe),e(E,ls),e(ls,soe),e(soe,KYe),e(ls,ZYe),e(ls,NS),e(NS,eKe),e(ls,oKe),e(ls,jS),e(jS,rKe),e(ls,tKe),e(E,aKe),e(E,is),e(is,loe),e(loe,nKe),e(is,sKe),e(is,DS),e(DS,lKe),e(is,iKe),e(is,GS),e(GS,dKe),e(is,cKe),e(E,fKe),e(E,ds),e(ds,ioe),e(ioe,mKe),e(ds,gKe),e(ds,OS),e(OS,hKe),e(ds,pKe),e(ds,VS),e(VS,_Ke),e(ds,uKe),e(E,bKe),e(E,ah),e(ah,doe),e(doe,vKe),e(ah,FKe),e(ah,XS),e(XS,TKe),e(ah,MKe),e(E,EKe),e(E,cs),e(cs,coe),e(coe,CKe),e(cs,wKe),e(cs,zS),e(zS,AKe),e(cs,yKe),e(cs,QS),e(QS,LKe),e(cs,xKe),e(E,kKe),e(E,nh),e(nh,foe),e(foe,SKe),e(nh,RKe),e(nh,WS),e(WS,BKe),e(nh,PKe),e(E,$Ke),e(E,fs),e(fs,moe),e(moe,IKe),e(fs,qKe),e(fs,HS),e(HS,NKe),e(fs,jKe),e(fs,US),e(US,DKe),e(fs,GKe),e(E,OKe),e(E,ms),e(ms,goe),e(goe,VKe),e(ms,XKe),e(ms,JS),e(JS,zKe),e(ms,QKe),e(ms,YS),e(YS,WKe),e(ms,HKe),e(E,UKe),e(E,gs),e(gs,hoe),e(hoe,JKe),e(gs,YKe),e(gs,KS),e(KS,KKe),e(gs,ZKe),e(gs,ZS),e(ZS,eZe),e(gs,oZe),e(E,rZe),e(E,hs),e(hs,poe),e(poe,tZe),e(hs,aZe),e(hs,eR),e(eR,nZe),e(hs,sZe),e(hs,oR),e(oR,lZe),e(hs,iZe),e(E,dZe),e(E,ps),e(ps,_oe),e(_oe,cZe),e(ps,fZe),e(ps,rR),e(rR,mZe),e(ps,gZe),e(ps,tR),e(tR,hZe),e(ps,pZe),e(E,_Ze),e(E,sh),e(sh,uoe),e(uoe,uZe),e(sh,bZe),e(sh,aR),e(aR,vZe),e(sh,FZe),e(E,TZe),e(E,_s),e(_s,boe),e(boe,MZe),e(_s,EZe),e(_s,nR),e(nR,CZe),e(_s,wZe),e(_s,sR),e(sR,AZe),e(_s,yZe),e(E,LZe),e(E,us),e(us,voe),e(voe,xZe),e(us,kZe),e(us,lR),e(lR,SZe),e(us,RZe),e(us,iR),e(iR,BZe),e(us,PZe),e(E,$Ze),e(E,bs),e(bs,Foe),e(Foe,IZe),e(bs,qZe),e(bs,dR),e(dR,NZe),e(bs,jZe),e(bs,cR),e(cR,DZe),e(bs,GZe),e(E,OZe),e(E,vs),e(vs,Toe),e(Toe,VZe),e(vs,XZe),e(vs,fR),e(fR,zZe),e(vs,QZe),e(vs,mR),e(mR,WZe),e(vs,HZe),e(E,UZe),e(E,Fs),e(Fs,Moe),e(Moe,JZe),e(Fs,YZe),e(Fs,gR),e(gR,KZe),e(Fs,ZZe),e(Fs,hR),e(hR,eeo),e(Fs,oeo),e(E,reo),e(E,Ts),e(Ts,Eoe),e(Eoe,teo),e(Ts,aeo),e(Ts,pR),e(pR,neo),e(Ts,seo),e(Ts,_R),e(_R,leo),e(Ts,ieo),e(E,deo),e(E,Ms),e(Ms,Coe),e(Coe,ceo),e(Ms,feo),e(Ms,uR),e(uR,meo),e(Ms,geo),e(Ms,bR),e(bR,heo),e(Ms,peo),e(E,_eo),e(E,lh),e(lh,woe),e(woe,ueo),e(lh,beo),e(lh,vR),e(vR,veo),e(lh,Feo),e(E,Teo),e(E,Es),e(Es,Aoe),e(Aoe,Meo),e(Es,Eeo),e(Es,FR),e(FR,Ceo),e(Es,weo),e(Es,TR),e(TR,Aeo),e(Es,yeo),e(E,Leo),e(E,ih),e(ih,yoe),e(yoe,xeo),e(ih,keo),e(ih,MR),e(MR,Seo),e(ih,Reo),e(E,Beo),e(E,dh),e(dh,Loe),e(Loe,Peo),e(dh,$eo),e(dh,ER),e(ER,Ieo),e(dh,qeo),e(E,Neo),e(E,Cs),e(Cs,xoe),e(xoe,jeo),e(Cs,Deo),e(Cs,CR),e(CR,Geo),e(Cs,Oeo),e(Cs,wR),e(wR,Veo),e(Cs,Xeo),e(E,zeo),e(E,ws),e(ws,koe),e(koe,Qeo),e(ws,Weo),e(ws,AR),e(AR,Heo),e(ws,Ueo),e(ws,yR),e(yR,Jeo),e(ws,Yeo),e(E,Keo),e(E,As),e(As,Soe),e(Soe,Zeo),e(As,eoo),e(As,LR),e(LR,ooo),e(As,roo),e(As,xR),e(xR,too),e(As,aoo),e(E,noo),e(E,ch),e(ch,Roe),e(Roe,soo),e(ch,loo),e(ch,kR),e(kR,ioo),e(ch,doo),e(E,coo),e(E,ys),e(ys,Boe),e(Boe,foo),e(ys,moo),e(ys,SR),e(SR,goo),e(ys,hoo),e(ys,RR),e(RR,poo),e(ys,_oo),e(E,uoo),e(E,Ls),e(Ls,Poe),e(Poe,boo),e(Ls,voo),e(Ls,BR),e(BR,Foo),e(Ls,Too),e(Ls,PR),e(PR,Moo),e(Ls,Eoo),e(E,Coo),e(E,xs),e(xs,$oe),e($oe,woo),e(xs,Aoo),e(xs,$R),e($R,yoo),e(xs,Loo),e(xs,IR),e(IR,xoo),e(xs,koo),e(E,Soo),e(E,ks),e(ks,Ioe),e(Ioe,Roo),e(ks,Boo),e(ks,qR),e(qR,Poo),e(ks,$oo),e(ks,NR),e(NR,Ioo),e(ks,qoo),e(E,Noo),e(E,Ss),e(Ss,qoe),e(qoe,joo),e(Ss,Doo),e(Ss,jR),e(jR,Goo),e(Ss,Ooo),e(Ss,DR),e(DR,Voo),e(Ss,Xoo),e(E,zoo),e(E,Rs),e(Rs,Noe),e(Noe,Qoo),e(Rs,Woo),e(Rs,GR),e(GR,Hoo),e(Rs,Uoo),e(Rs,OR),e(OR,Joo),e(Rs,Yoo),e(E,Koo),e(E,fh),e(fh,joe),e(joe,Zoo),e(fh,ero),e(fh,VR),e(VR,oro),e(fh,rro),e(E,tro),e(E,mh),e(mh,Doe),e(Doe,aro),e(mh,nro),e(mh,XR),e(XR,sro),e(mh,lro),e(E,iro),e(E,gh),e(gh,Goe),e(Goe,dro),e(gh,cro),e(gh,zR),e(zR,fro),e(gh,mro),e(E,gro),e(E,hh),e(hh,Ooe),e(Ooe,hro),e(hh,pro),e(hh,QR),e(QR,_ro),e(hh,uro),e(E,bro),e(E,Bs),e(Bs,Voe),e(Voe,vro),e(Bs,Fro),e(Bs,WR),e(WR,Tro),e(Bs,Mro),e(Bs,HR),e(HR,Ero),e(Bs,Cro),e(E,wro),e(E,ph),e(ph,Xoe),e(Xoe,Aro),e(ph,yro),e(ph,UR),e(UR,Lro),e(ph,xro),e(E,kro),e(E,Ps),e(Ps,zoe),e(zoe,Sro),e(Ps,Rro),e(Ps,JR),e(JR,Bro),e(Ps,Pro),e(Ps,YR),e(YR,$ro),e(Ps,Iro),e(E,qro),e(E,$s),e($s,Qoe),e(Qoe,Nro),e($s,jro),e($s,KR),e(KR,Dro),e($s,Gro),e($s,ZR),e(ZR,Oro),e($s,Vro),e(E,Xro),e(E,Is),e(Is,Woe),e(Woe,zro),e(Is,Qro),e(Is,eB),e(eB,Wro),e(Is,Hro),e(Is,oB),e(oB,Uro),e(Is,Jro),e(E,Yro),e(E,qs),e(qs,Hoe),e(Hoe,Kro),e(qs,Zro),e(qs,rB),e(rB,eto),e(qs,oto),e(qs,tB),e(tB,rto),e(qs,tto),e(E,ato),e(E,Ns),e(Ns,Uoe),e(Uoe,nto),e(Ns,sto),e(Ns,aB),e(aB,lto),e(Ns,ito),e(Ns,nB),e(nB,dto),e(Ns,cto),e(E,fto),e(E,js),e(js,Joe),e(Joe,mto),e(js,gto),e(js,sB),e(sB,hto),e(js,pto),e(js,lB),e(lB,_to),e(js,uto),e(E,bto),e(E,_h),e(_h,Yoe),e(Yoe,vto),e(_h,Fto),e(_h,iB),e(iB,Tto),e(_h,Mto),e(E,Eto),e(E,uh),e(uh,Koe),e(Koe,Cto),e(uh,wto),e(uh,dB),e(dB,Ato),e(uh,yto),e(E,Lto),e(E,Ds),e(Ds,Zoe),e(Zoe,xto),e(Ds,kto),e(Ds,cB),e(cB,Sto),e(Ds,Rto),e(Ds,fB),e(fB,Bto),e(Ds,Pto),e(E,$to),e(E,Gs),e(Gs,ere),e(ere,Ito),e(Gs,qto),e(Gs,mB),e(mB,Nto),e(Gs,jto),e(Gs,gB),e(gB,Dto),e(Gs,Gto),e(E,Oto),e(E,Os),e(Os,ore),e(ore,Vto),e(Os,Xto),e(Os,hB),e(hB,zto),e(Os,Qto),e(Os,pB),e(pB,Wto),e(Os,Hto),e(E,Uto),e(E,bh),e(bh,rre),e(rre,Jto),e(bh,Yto),e(bh,_B),e(_B,Kto),e(bh,Zto),e(E,eao),e(E,vh),e(vh,tre),e(tre,oao),e(vh,rao),e(vh,uB),e(uB,tao),e(vh,aao),e(E,nao),e(E,Fh),e(Fh,are),e(are,sao),e(Fh,lao),e(Fh,bB),e(bB,iao),e(Fh,dao),e(E,cao),e(E,Vs),e(Vs,nre),e(nre,fao),e(Vs,mao),e(Vs,vB),e(vB,gao),e(Vs,hao),e(Vs,FB),e(FB,pao),e(Vs,_ao),e(E,uao),e(E,Th),e(Th,sre),e(sre,bao),e(Th,vao),e(Th,TB),e(TB,Fao),e(Th,Tao),e(E,Mao),e(E,Mh),e(Mh,lre),e(lre,Eao),e(Mh,Cao),e(Mh,MB),e(MB,wao),e(Mh,Aao),e(E,yao),e(E,Xs),e(Xs,ire),e(ire,Lao),e(Xs,xao),e(Xs,EB),e(EB,kao),e(Xs,Sao),e(Xs,CB),e(CB,Rao),e(Xs,Bao),e(E,Pao),e(E,Eh),e(Eh,dre),e(dre,$ao),e(Eh,Iao),e(Eh,wB),e(wB,qao),e(Eh,Nao),e(E,jao),e(E,Ch),e(Ch,cre),e(cre,Dao),e(Ch,Gao),e(Ch,AB),e(AB,Oao),e(Ch,Vao),e(E,Xao),e(E,zs),e(zs,fre),e(fre,zao),e(zs,Qao),e(zs,yB),e(yB,Wao),e(zs,Hao),e(zs,LB),e(LB,Uao),e(zs,Jao),e(E,Yao),e(E,Qs),e(Qs,mre),e(mre,Kao),e(Qs,Zao),e(Qs,xB),e(xB,eno),e(Qs,ono),e(Qs,kB),e(kB,rno),e(Qs,tno),e(E,ano),e(E,Ws),e(Ws,gre),e(gre,nno),e(Ws,sno),e(Ws,SB),e(SB,lno),e(Ws,ino),e(Ws,RB),e(RB,dno),e(Ws,cno),e(E,fno),e(E,Hs),e(Hs,hre),e(hre,mno),e(Hs,gno),e(Hs,BB),e(BB,hno),e(Hs,pno),e(Hs,PB),e(PB,_no),e(Hs,uno),e(ho,bno),e(ho,pre),e(pre,vno),e(ho,Fno),g(u3,ho,null),e(Wo,Tno),e(Wo,wh),g(b3,wh,null),e(wh,Mno),e(wh,_re),e(_re,Eno),b(c,GPe,u),b(c,td,u),e(td,Ah),e(Ah,ure),g(v3,ure,null),e(td,Cno),e(td,bre),e(bre,wno),b(c,OPe,u),b(c,Ho,u),g(F3,Ho,null),e(Ho,Ano),e(Ho,T3),e(T3,yno),e(T3,$B),e($B,Lno),e(T3,xno),e(Ho,kno),e(Ho,M3),e(M3,Sno),e(M3,vre),e(vre,Rno),e(M3,Bno),e(Ho,Pno),e(Ho,qe),g(E3,qe,null),e(qe,$no),e(qe,Fre),e(Fre,Ino),e(qe,qno),e(qe,Va),e(Va,Nno),e(Va,Tre),e(Tre,jno),e(Va,Dno),e(Va,Mre),e(Mre,Gno),e(Va,Ono),e(Va,Ere),e(Ere,Vno),e(Va,Xno),e(qe,zno),e(qe,H),e(H,yh),e(yh,Cre),e(Cre,Qno),e(yh,Wno),e(yh,IB),e(IB,Hno),e(yh,Uno),e(H,Jno),e(H,Lh),e(Lh,wre),e(wre,Yno),e(Lh,Kno),e(Lh,qB),e(qB,Zno),e(Lh,eso),e(H,oso),e(H,xh),e(xh,Are),e(Are,rso),e(xh,tso),e(xh,NB),e(NB,aso),e(xh,nso),e(H,sso),e(H,kh),e(kh,yre),e(yre,lso),e(kh,iso),e(kh,jB),e(jB,dso),e(kh,cso),e(H,fso),e(H,Sh),e(Sh,Lre),e(Lre,mso),e(Sh,gso),e(Sh,DB),e(DB,hso),e(Sh,pso),e(H,_so),e(H,Rh),e(Rh,xre),e(xre,uso),e(Rh,bso),e(Rh,GB),e(GB,vso),e(Rh,Fso),e(H,Tso),e(H,Bh),e(Bh,kre),e(kre,Mso),e(Bh,Eso),e(Bh,OB),e(OB,Cso),e(Bh,wso),e(H,Aso),e(H,Ph),e(Ph,Sre),e(Sre,yso),e(Ph,Lso),e(Ph,VB),e(VB,xso),e(Ph,kso),e(H,Sso),e(H,$h),e($h,Rre),e(Rre,Rso),e($h,Bso),e($h,XB),e(XB,Pso),e($h,$so),e(H,Iso),e(H,Ih),e(Ih,Bre),e(Bre,qso),e(Ih,Nso),e(Ih,zB),e(zB,jso),e(Ih,Dso),e(H,Gso),e(H,qh),e(qh,Pre),e(Pre,Oso),e(qh,Vso),e(qh,QB),e(QB,Xso),e(qh,zso),e(H,Qso),e(H,Nh),e(Nh,$re),e($re,Wso),e(Nh,Hso),e(Nh,WB),e(WB,Uso),e(Nh,Jso),e(H,Yso),e(H,jh),e(jh,Ire),e(Ire,Kso),e(jh,Zso),e(jh,HB),e(HB,elo),e(jh,olo),e(H,rlo),e(H,Dh),e(Dh,qre),e(qre,tlo),e(Dh,alo),e(Dh,UB),e(UB,nlo),e(Dh,slo),e(H,llo),e(H,Gh),e(Gh,Nre),e(Nre,ilo),e(Gh,dlo),e(Gh,JB),e(JB,clo),e(Gh,flo),e(H,mlo),e(H,Oh),e(Oh,jre),e(jre,glo),e(Oh,hlo),e(Oh,YB),e(YB,plo),e(Oh,_lo),e(H,ulo),e(H,Vh),e(Vh,Dre),e(Dre,blo),e(Vh,vlo),e(Vh,KB),e(KB,Flo),e(Vh,Tlo),e(H,Mlo),e(H,Xh),e(Xh,Gre),e(Gre,Elo),e(Xh,Clo),e(Xh,ZB),e(ZB,wlo),e(Xh,Alo),e(H,ylo),e(H,zh),e(zh,Ore),e(Ore,Llo),e(zh,xlo),e(zh,eP),e(eP,klo),e(zh,Slo),e(H,Rlo),e(H,Qh),e(Qh,Vre),e(Vre,Blo),e(Qh,Plo),e(Qh,oP),e(oP,$lo),e(Qh,Ilo),e(H,qlo),e(H,Wh),e(Wh,Xre),e(Xre,Nlo),e(Wh,jlo),e(Wh,rP),e(rP,Dlo),e(Wh,Glo),e(H,Olo),e(H,Hh),e(Hh,zre),e(zre,Vlo),e(Hh,Xlo),e(Hh,tP),e(tP,zlo),e(Hh,Qlo),e(H,Wlo),e(H,Uh),e(Uh,Qre),e(Qre,Hlo),e(Uh,Ulo),e(Uh,aP),e(aP,Jlo),e(Uh,Ylo),e(qe,Klo),g(Jh,qe,null),e(qe,Zlo),e(qe,Wre),e(Wre,eio),e(qe,oio),g(C3,qe,null),e(Ho,rio),e(Ho,Yh),g(w3,Yh,null),e(Yh,tio),e(Yh,Hre),e(Hre,aio),b(c,VPe,u),b(c,ad,u),e(ad,Kh),e(Kh,Ure),g(A3,Ure,null),e(ad,nio),e(ad,Jre),e(Jre,sio),b(c,XPe,u),b(c,Uo,u),g(y3,Uo,null),e(Uo,lio),e(Uo,L3),e(L3,iio),e(L3,nP),e(nP,dio),e(L3,cio),e(Uo,fio),e(Uo,x3),e(x3,mio),e(x3,Yre),e(Yre,gio),e(x3,hio),e(Uo,pio),e(Uo,Ne),g(k3,Ne,null),e(Ne,_io),e(Ne,Kre),e(Kre,uio),e(Ne,bio),e(Ne,nd),e(nd,vio),e(nd,Zre),e(Zre,Fio),e(nd,Tio),e(nd,ete),e(ete,Mio),e(nd,Eio),e(Ne,Cio),e(Ne,de),e(de,Zh),e(Zh,ote),e(ote,wio),e(Zh,Aio),e(Zh,sP),e(sP,yio),e(Zh,Lio),e(de,xio),e(de,ep),e(ep,rte),e(rte,kio),e(ep,Sio),e(ep,lP),e(lP,Rio),e(ep,Bio),e(de,Pio),e(de,op),e(op,tte),e(tte,$io),e(op,Iio),e(op,iP),e(iP,qio),e(op,Nio),e(de,jio),e(de,rp),e(rp,ate),e(ate,Dio),e(rp,Gio),e(rp,dP),e(dP,Oio),e(rp,Vio),e(de,Xio),e(de,tp),e(tp,nte),e(nte,zio),e(tp,Qio),e(tp,cP),e(cP,Wio),e(tp,Hio),e(de,Uio),e(de,ap),e(ap,ste),e(ste,Jio),e(ap,Yio),e(ap,fP),e(fP,Kio),e(ap,Zio),e(de,edo),e(de,np),e(np,lte),e(lte,odo),e(np,rdo),e(np,mP),e(mP,tdo),e(np,ado),e(de,ndo),e(de,sp),e(sp,ite),e(ite,sdo),e(sp,ldo),e(sp,gP),e(gP,ido),e(sp,ddo),e(de,cdo),e(de,lp),e(lp,dte),e(dte,fdo),e(lp,mdo),e(lp,hP),e(hP,gdo),e(lp,hdo),e(de,pdo),e(de,ip),e(ip,cte),e(cte,_do),e(ip,udo),e(ip,pP),e(pP,bdo),e(ip,vdo),e(de,Fdo),e(de,dp),e(dp,fte),e(fte,Tdo),e(dp,Mdo),e(dp,_P),e(_P,Edo),e(dp,Cdo),e(de,wdo),e(de,cp),e(cp,mte),e(mte,Ado),e(cp,ydo),e(cp,uP),e(uP,Ldo),e(cp,xdo),e(de,kdo),e(de,fp),e(fp,gte),e(gte,Sdo),e(fp,Rdo),e(fp,bP),e(bP,Bdo),e(fp,Pdo),e(de,$do),e(de,mp),e(mp,hte),e(hte,Ido),e(mp,qdo),e(mp,vP),e(vP,Ndo),e(mp,jdo),e(Ne,Ddo),g(gp,Ne,null),e(Ne,Gdo),e(Ne,pte),e(pte,Odo),e(Ne,Vdo),g(S3,Ne,null),e(Uo,Xdo),e(Uo,hp),g(R3,hp,null),e(hp,zdo),e(hp,_te),e(_te,Qdo),b(c,zPe,u),b(c,sd,u),e(sd,pp),e(pp,ute),g(B3,ute,null),e(sd,Wdo),e(sd,bte),e(bte,Hdo),b(c,QPe,u),b(c,Jo,u),g(P3,Jo,null),e(Jo,Udo),e(Jo,ld),e(ld,Jdo),e(ld,FP),e(FP,Ydo),e(ld,Kdo),e(ld,TP),e(TP,Zdo),e(ld,eco),e(Jo,oco),e(Jo,$3),e($3,rco),e($3,vte),e(vte,tco),e($3,aco),e(Jo,nco),e(Jo,Xr),g(I3,Xr,null),e(Xr,sco),e(Xr,Fte),e(Fte,lco),e(Xr,ico),e(Xr,id),e(id,dco),e(id,Tte),e(Tte,cco),e(id,fco),e(id,MP),e(MP,mco),e(id,gco),e(Xr,hco),e(Xr,Mte),e(Mte,pco),e(Xr,_co),g(q3,Xr,null),e(Jo,uco),e(Jo,je),g(N3,je,null),e(je,bco),e(je,Ete),e(Ete,vco),e(je,Fco),e(je,Xa),e(Xa,Tco),e(Xa,Cte),e(Cte,Mco),e(Xa,Eco),e(Xa,wte),e(wte,Cco),e(Xa,wco),e(Xa,Ate),e(Ate,Aco),e(Xa,yco),e(je,Lco),e(je,T),e(T,_p),e(_p,yte),e(yte,xco),e(_p,kco),e(_p,EP),e(EP,Sco),e(_p,Rco),e(T,Bco),e(T,up),e(up,Lte),e(Lte,Pco),e(up,$co),e(up,CP),e(CP,Ico),e(up,qco),e(T,Nco),e(T,bp),e(bp,xte),e(xte,jco),e(bp,Dco),e(bp,wP),e(wP,Gco),e(bp,Oco),e(T,Vco),e(T,vp),e(vp,kte),e(kte,Xco),e(vp,zco),e(vp,AP),e(AP,Qco),e(vp,Wco),e(T,Hco),e(T,Fp),e(Fp,Ste),e(Ste,Uco),e(Fp,Jco),e(Fp,yP),e(yP,Yco),e(Fp,Kco),e(T,Zco),e(T,Tp),e(Tp,Rte),e(Rte,efo),e(Tp,ofo),e(Tp,LP),e(LP,rfo),e(Tp,tfo),e(T,afo),e(T,Mp),e(Mp,Bte),e(Bte,nfo),e(Mp,sfo),e(Mp,xP),e(xP,lfo),e(Mp,ifo),e(T,dfo),e(T,Ep),e(Ep,Pte),e(Pte,cfo),e(Ep,ffo),e(Ep,kP),e(kP,mfo),e(Ep,gfo),e(T,hfo),e(T,Cp),e(Cp,$te),e($te,pfo),e(Cp,_fo),e(Cp,SP),e(SP,ufo),e(Cp,bfo),e(T,vfo),e(T,wp),e(wp,Ite),e(Ite,Ffo),e(wp,Tfo),e(wp,RP),e(RP,Mfo),e(wp,Efo),e(T,Cfo),e(T,Ap),e(Ap,qte),e(qte,wfo),e(Ap,Afo),e(Ap,BP),e(BP,yfo),e(Ap,Lfo),e(T,xfo),e(T,yp),e(yp,Nte),e(Nte,kfo),e(yp,Sfo),e(yp,PP),e(PP,Rfo),e(yp,Bfo),e(T,Pfo),e(T,Lp),e(Lp,jte),e(jte,$fo),e(Lp,Ifo),e(Lp,$P),e($P,qfo),e(Lp,Nfo),e(T,jfo),e(T,xp),e(xp,Dte),e(Dte,Dfo),e(xp,Gfo),e(xp,IP),e(IP,Ofo),e(xp,Vfo),e(T,Xfo),e(T,kp),e(kp,Gte),e(Gte,zfo),e(kp,Qfo),e(kp,qP),e(qP,Wfo),e(kp,Hfo),e(T,Ufo),e(T,Sp),e(Sp,Ote),e(Ote,Jfo),e(Sp,Yfo),e(Sp,NP),e(NP,Kfo),e(Sp,Zfo),e(T,emo),e(T,Rp),e(Rp,Vte),e(Vte,omo),e(Rp,rmo),e(Rp,jP),e(jP,tmo),e(Rp,amo),e(T,nmo),e(T,Bp),e(Bp,Xte),e(Xte,smo),e(Bp,lmo),e(Bp,DP),e(DP,imo),e(Bp,dmo),e(T,cmo),e(T,Pp),e(Pp,zte),e(zte,fmo),e(Pp,mmo),e(Pp,GP),e(GP,gmo),e(Pp,hmo),e(T,pmo),e(T,$p),e($p,Qte),e(Qte,_mo),e($p,umo),e($p,OP),e(OP,bmo),e($p,vmo),e(T,Fmo),e(T,Ip),e(Ip,Wte),e(Wte,Tmo),e(Ip,Mmo),e(Ip,VP),e(VP,Emo),e(Ip,Cmo),e(T,wmo),e(T,qp),e(qp,Hte),e(Hte,Amo),e(qp,ymo),e(qp,XP),e(XP,Lmo),e(qp,xmo),e(T,kmo),e(T,Np),e(Np,Ute),e(Ute,Smo),e(Np,Rmo),e(Np,zP),e(zP,Bmo),e(Np,Pmo),e(T,$mo),e(T,jp),e(jp,Jte),e(Jte,Imo),e(jp,qmo),e(jp,QP),e(QP,Nmo),e(jp,jmo),e(T,Dmo),e(T,Dp),e(Dp,Yte),e(Yte,Gmo),e(Dp,Omo),e(Dp,WP),e(WP,Vmo),e(Dp,Xmo),e(T,zmo),e(T,Gp),e(Gp,Kte),e(Kte,Qmo),e(Gp,Wmo),e(Gp,HP),e(HP,Hmo),e(Gp,Umo),e(T,Jmo),e(T,Op),e(Op,Zte),e(Zte,Ymo),e(Op,Kmo),e(Op,UP),e(UP,Zmo),e(Op,ego),e(T,ogo),e(T,Vp),e(Vp,eae),e(eae,rgo),e(Vp,tgo),e(Vp,JP),e(JP,ago),e(Vp,ngo),e(T,sgo),e(T,Xp),e(Xp,oae),e(oae,lgo),e(Xp,igo),e(Xp,YP),e(YP,dgo),e(Xp,cgo),e(T,fgo),e(T,zp),e(zp,rae),e(rae,mgo),e(zp,ggo),e(zp,KP),e(KP,hgo),e(zp,pgo),e(T,_go),e(T,Us),e(Us,tae),e(tae,ugo),e(Us,bgo),e(Us,ZP),e(ZP,vgo),e(Us,Fgo),e(Us,e$),e(e$,Tgo),e(Us,Mgo),e(T,Ego),e(T,Qp),e(Qp,aae),e(aae,Cgo),e(Qp,wgo),e(Qp,o$),e(o$,Ago),e(Qp,ygo),e(T,Lgo),e(T,Wp),e(Wp,nae),e(nae,xgo),e(Wp,kgo),e(Wp,r$),e(r$,Sgo),e(Wp,Rgo),e(T,Bgo),e(T,Hp),e(Hp,sae),e(sae,Pgo),e(Hp,$go),e(Hp,t$),e(t$,Igo),e(Hp,qgo),e(T,Ngo),e(T,Up),e(Up,lae),e(lae,jgo),e(Up,Dgo),e(Up,a$),e(a$,Ggo),e(Up,Ogo),e(T,Vgo),e(T,Jp),e(Jp,iae),e(iae,Xgo),e(Jp,zgo),e(Jp,n$),e(n$,Qgo),e(Jp,Wgo),e(T,Hgo),e(T,Yp),e(Yp,dae),e(dae,Ugo),e(Yp,Jgo),e(Yp,s$),e(s$,Ygo),e(Yp,Kgo),e(T,Zgo),e(T,Kp),e(Kp,cae),e(cae,eho),e(Kp,oho),e(Kp,l$),e(l$,rho),e(Kp,tho),e(T,aho),e(T,Zp),e(Zp,fae),e(fae,nho),e(Zp,sho),e(Zp,i$),e(i$,lho),e(Zp,iho),e(T,dho),e(T,e_),e(e_,mae),e(mae,cho),e(e_,fho),e(e_,d$),e(d$,mho),e(e_,gho),e(T,hho),e(T,o_),e(o_,gae),e(gae,pho),e(o_,_ho),e(o_,c$),e(c$,uho),e(o_,bho),e(T,vho),e(T,r_),e(r_,hae),e(hae,Fho),e(r_,Tho),e(r_,f$),e(f$,Mho),e(r_,Eho),e(T,Cho),e(T,t_),e(t_,pae),e(pae,who),e(t_,Aho),e(t_,m$),e(m$,yho),e(t_,Lho),e(T,xho),e(T,a_),e(a_,_ae),e(_ae,kho),e(a_,Sho),e(a_,g$),e(g$,Rho),e(a_,Bho),e(T,Pho),e(T,n_),e(n_,uae),e(uae,$ho),e(n_,Iho),e(n_,h$),e(h$,qho),e(n_,Nho),e(T,jho),e(T,s_),e(s_,bae),e(bae,Dho),e(s_,Gho),e(s_,p$),e(p$,Oho),e(s_,Vho),e(T,Xho),e(T,l_),e(l_,vae),e(vae,zho),e(l_,Qho),e(l_,_$),e(_$,Who),e(l_,Hho),e(T,Uho),e(T,i_),e(i_,Fae),e(Fae,Jho),e(i_,Yho),e(i_,u$),e(u$,Kho),e(i_,Zho),e(T,epo),e(T,d_),e(d_,Tae),e(Tae,opo),e(d_,rpo),e(d_,b$),e(b$,tpo),e(d_,apo),e(T,npo),e(T,c_),e(c_,Mae),e(Mae,spo),e(c_,lpo),e(c_,v$),e(v$,ipo),e(c_,dpo),e(T,cpo),e(T,f_),e(f_,Eae),e(Eae,fpo),e(f_,mpo),e(f_,F$),e(F$,gpo),e(f_,hpo),e(T,ppo),e(T,m_),e(m_,Cae),e(Cae,_po),e(m_,upo),e(m_,T$),e(T$,bpo),e(m_,vpo),e(T,Fpo),e(T,g_),e(g_,wae),e(wae,Tpo),e(g_,Mpo),e(g_,M$),e(M$,Epo),e(g_,Cpo),e(T,wpo),e(T,h_),e(h_,Aae),e(Aae,Apo),e(h_,ypo),e(h_,E$),e(E$,Lpo),e(h_,xpo),e(T,kpo),e(T,p_),e(p_,yae),e(yae,Spo),e(p_,Rpo),e(p_,C$),e(C$,Bpo),e(p_,Ppo),e(T,$po),e(T,__),e(__,Lae),e(Lae,Ipo),e(__,qpo),e(__,w$),e(w$,Npo),e(__,jpo),e(T,Dpo),e(T,u_),e(u_,xae),e(xae,Gpo),e(u_,Opo),e(u_,A$),e(A$,Vpo),e(u_,Xpo),e(T,zpo),e(T,b_),e(b_,kae),e(kae,Qpo),e(b_,Wpo),e(b_,y$),e(y$,Hpo),e(b_,Upo),e(T,Jpo),e(T,v_),e(v_,Sae),e(Sae,Ypo),e(v_,Kpo),e(v_,L$),e(L$,Zpo),e(v_,e_o),e(T,o_o),e(T,F_),e(F_,Rae),e(Rae,r_o),e(F_,t_o),e(F_,x$),e(x$,a_o),e(F_,n_o),e(T,s_o),e(T,T_),e(T_,Bae),e(Bae,l_o),e(T_,i_o),e(T_,k$),e(k$,d_o),e(T_,c_o),e(T,f_o),e(T,M_),e(M_,Pae),e(Pae,m_o),e(M_,g_o),e(M_,S$),e(S$,h_o),e(M_,p_o),e(T,__o),e(T,E_),e(E_,$ae),e($ae,u_o),e(E_,b_o),e(E_,R$),e(R$,v_o),e(E_,F_o),e(T,T_o),e(T,C_),e(C_,Iae),e(Iae,M_o),e(C_,E_o),e(C_,B$),e(B$,C_o),e(C_,w_o),e(T,A_o),e(T,w_),e(w_,qae),e(qae,y_o),e(w_,L_o),e(w_,P$),e(P$,x_o),e(w_,k_o),e(T,S_o),e(T,A_),e(A_,Nae),e(Nae,R_o),e(A_,B_o),e(A_,$$),e($$,P_o),e(A_,$_o),e(T,I_o),e(T,y_),e(y_,jae),e(jae,q_o),e(y_,N_o),e(y_,I$),e(I$,j_o),e(y_,D_o),e(T,G_o),e(T,L_),e(L_,Dae),e(Dae,O_o),e(L_,V_o),e(L_,q$),e(q$,X_o),e(L_,z_o),e(T,Q_o),e(T,x_),e(x_,Gae),e(Gae,W_o),e(x_,H_o),e(x_,N$),e(N$,U_o),e(x_,J_o),e(T,Y_o),e(T,k_),e(k_,Oae),e(Oae,K_o),e(k_,Z_o),e(k_,j$),e(j$,euo),e(k_,ouo),e(T,ruo),e(T,S_),e(S_,Vae),e(Vae,tuo),e(S_,auo),e(S_,D$),e(D$,nuo),e(S_,suo),e(T,luo),e(T,R_),e(R_,Xae),e(Xae,iuo),e(R_,duo),e(R_,G$),e(G$,cuo),e(R_,fuo),e(T,muo),e(T,B_),e(B_,zae),e(zae,guo),e(B_,huo),e(B_,O$),e(O$,puo),e(B_,_uo),e(T,uuo),e(T,P_),e(P_,Qae),e(Qae,buo),e(P_,vuo),e(P_,V$),e(V$,Fuo),e(P_,Tuo),e(T,Muo),e(T,$_),e($_,Wae),e(Wae,Euo),e($_,Cuo),e($_,X$),e(X$,wuo),e($_,Auo),e(T,yuo),e(T,I_),e(I_,Hae),e(Hae,Luo),e(I_,xuo),e(I_,z$),e(z$,kuo),e(I_,Suo),e(T,Ruo),e(T,q_),e(q_,Uae),e(Uae,Buo),e(q_,Puo),e(q_,Q$),e(Q$,$uo),e(q_,Iuo),e(T,quo),e(T,N_),e(N_,Jae),e(Jae,Nuo),e(N_,juo),e(N_,W$),e(W$,Duo),e(N_,Guo),e(T,Ouo),e(T,j_),e(j_,Yae),e(Yae,Vuo),e(j_,Xuo),e(j_,H$),e(H$,zuo),e(j_,Quo),e(T,Wuo),e(T,D_),e(D_,Kae),e(Kae,Huo),e(D_,Uuo),e(D_,U$),e(U$,Juo),e(D_,Yuo),e(T,Kuo),e(T,G_),e(G_,Zae),e(Zae,Zuo),e(G_,e2o),e(G_,J$),e(J$,o2o),e(G_,r2o),e(T,t2o),e(T,O_),e(O_,ene),e(ene,a2o),e(O_,n2o),e(O_,Y$),e(Y$,s2o),e(O_,l2o),e(T,i2o),e(T,V_),e(V_,one),e(one,d2o),e(V_,c2o),e(V_,K$),e(K$,f2o),e(V_,m2o),e(T,g2o),e(T,X_),e(X_,rne),e(rne,h2o),e(X_,p2o),e(X_,Z$),e(Z$,_2o),e(X_,u2o),e(T,b2o),e(T,z_),e(z_,tne),e(tne,v2o),e(z_,F2o),e(z_,eI),e(eI,T2o),e(z_,M2o),e(T,E2o),e(T,Q_),e(Q_,ane),e(ane,C2o),e(Q_,w2o),e(Q_,oI),e(oI,A2o),e(Q_,y2o),e(T,L2o),e(T,W_),e(W_,nne),e(nne,x2o),e(W_,k2o),e(W_,rI),e(rI,S2o),e(W_,R2o),e(T,B2o),e(T,H_),e(H_,sne),e(sne,P2o),e(H_,$2o),e(H_,tI),e(tI,I2o),e(H_,q2o),e(T,N2o),e(T,U_),e(U_,lne),e(lne,j2o),e(U_,D2o),e(U_,aI),e(aI,G2o),e(U_,O2o),e(T,V2o),e(T,J_),e(J_,ine),e(ine,X2o),e(J_,z2o),e(J_,nI),e(nI,Q2o),e(J_,W2o),e(T,H2o),e(T,Y_),e(Y_,dne),e(dne,U2o),e(Y_,J2o),e(Y_,sI),e(sI,Y2o),e(Y_,K2o),e(T,Z2o),e(T,K_),e(K_,cne),e(cne,e1o),e(K_,o1o),e(K_,lI),e(lI,r1o),e(K_,t1o),e(T,a1o),e(T,Z_),e(Z_,fne),e(fne,n1o),e(Z_,s1o),e(Z_,iI),e(iI,l1o),e(Z_,i1o),e(T,d1o),e(T,eu),e(eu,mne),e(mne,c1o),e(eu,f1o),e(eu,dI),e(dI,m1o),e(eu,g1o),e(T,h1o),e(T,ou),e(ou,gne),e(gne,p1o),e(ou,_1o),e(ou,cI),e(cI,u1o),e(ou,b1o),e(je,v1o),e(je,ru),e(ru,F1o),e(ru,hne),e(hne,T1o),e(ru,M1o),e(ru,pne),e(pne,E1o),e(je,C1o),e(je,_ne),e(_ne,w1o),e(je,A1o),g(j3,je,null),b(c,WPe,u),b(c,dd,u),e(dd,tu),e(tu,une),g(D3,une,null),e(dd,y1o),e(dd,bne),e(bne,L1o),b(c,HPe,u),b(c,Yo,u),g(G3,Yo,null),e(Yo,x1o),e(Yo,cd),e(cd,k1o),e(cd,fI),e(fI,S1o),e(cd,R1o),e(cd,mI),e(mI,B1o),e(cd,P1o),e(Yo,$1o),e(Yo,O3),e(O3,I1o),e(O3,vne),e(vne,q1o),e(O3,N1o),e(Yo,j1o),e(Yo,zr),g(V3,zr,null),e(zr,D1o),e(zr,Fne),e(Fne,G1o),e(zr,O1o),e(zr,fd),e(fd,V1o),e(fd,Tne),e(Tne,X1o),e(fd,z1o),e(fd,gI),e(gI,Q1o),e(fd,W1o),e(zr,H1o),e(zr,Mne),e(Mne,U1o),e(zr,J1o),g(X3,zr,null),e(Yo,Y1o),e(Yo,De),g(z3,De,null),e(De,K1o),e(De,Ene),e(Ene,Z1o),e(De,ebo),e(De,za),e(za,obo),e(za,Cne),e(Cne,rbo),e(za,tbo),e(za,wne),e(wne,abo),e(za,nbo),e(za,Ane),e(Ane,sbo),e(za,lbo),e(De,ibo),e(De,S),e(S,au),e(au,yne),e(yne,dbo),e(au,cbo),e(au,hI),e(hI,fbo),e(au,mbo),e(S,gbo),e(S,nu),e(nu,Lne),e(Lne,hbo),e(nu,pbo),e(nu,pI),e(pI,_bo),e(nu,ubo),e(S,bbo),e(S,su),e(su,xne),e(xne,vbo),e(su,Fbo),e(su,_I),e(_I,Tbo),e(su,Mbo),e(S,Ebo),e(S,lu),e(lu,kne),e(kne,Cbo),e(lu,wbo),e(lu,uI),e(uI,Abo),e(lu,ybo),e(S,Lbo),e(S,iu),e(iu,Sne),e(Sne,xbo),e(iu,kbo),e(iu,bI),e(bI,Sbo),e(iu,Rbo),e(S,Bbo),e(S,du),e(du,Rne),e(Rne,Pbo),e(du,$bo),e(du,vI),e(vI,Ibo),e(du,qbo),e(S,Nbo),e(S,cu),e(cu,Bne),e(Bne,jbo),e(cu,Dbo),e(cu,FI),e(FI,Gbo),e(cu,Obo),e(S,Vbo),e(S,fu),e(fu,Pne),e(Pne,Xbo),e(fu,zbo),e(fu,TI),e(TI,Qbo),e(fu,Wbo),e(S,Hbo),e(S,mu),e(mu,$ne),e($ne,Ubo),e(mu,Jbo),e(mu,MI),e(MI,Ybo),e(mu,Kbo),e(S,Zbo),e(S,gu),e(gu,Ine),e(Ine,e6o),e(gu,o6o),e(gu,EI),e(EI,r6o),e(gu,t6o),e(S,a6o),e(S,hu),e(hu,qne),e(qne,n6o),e(hu,s6o),e(hu,CI),e(CI,l6o),e(hu,i6o),e(S,d6o),e(S,pu),e(pu,Nne),e(Nne,c6o),e(pu,f6o),e(pu,wI),e(wI,m6o),e(pu,g6o),e(S,h6o),e(S,_u),e(_u,jne),e(jne,p6o),e(_u,_6o),e(_u,AI),e(AI,u6o),e(_u,b6o),e(S,v6o),e(S,uu),e(uu,Dne),e(Dne,F6o),e(uu,T6o),e(uu,yI),e(yI,M6o),e(uu,E6o),e(S,C6o),e(S,bu),e(bu,Gne),e(Gne,w6o),e(bu,A6o),e(bu,LI),e(LI,y6o),e(bu,L6o),e(S,x6o),e(S,vu),e(vu,One),e(One,k6o),e(vu,S6o),e(vu,xI),e(xI,R6o),e(vu,B6o),e(S,P6o),e(S,Fu),e(Fu,Vne),e(Vne,$6o),e(Fu,I6o),e(Fu,kI),e(kI,q6o),e(Fu,N6o),e(S,j6o),e(S,Tu),e(Tu,Xne),e(Xne,D6o),e(Tu,G6o),e(Tu,SI),e(SI,O6o),e(Tu,V6o),e(S,X6o),e(S,Mu),e(Mu,zne),e(zne,z6o),e(Mu,Q6o),e(Mu,RI),e(RI,W6o),e(Mu,H6o),e(S,U6o),e(S,Eu),e(Eu,Qne),e(Qne,J6o),e(Eu,Y6o),e(Eu,BI),e(BI,K6o),e(Eu,Z6o),e(S,evo),e(S,Cu),e(Cu,Wne),e(Wne,ovo),e(Cu,rvo),e(Cu,PI),e(PI,tvo),e(Cu,avo),e(S,nvo),e(S,wu),e(wu,Hne),e(Hne,svo),e(wu,lvo),e(wu,$I),e($I,ivo),e(wu,dvo),e(S,cvo),e(S,Au),e(Au,Une),e(Une,fvo),e(Au,mvo),e(Au,II),e(II,gvo),e(Au,hvo),e(S,pvo),e(S,yu),e(yu,Jne),e(Jne,_vo),e(yu,uvo),e(yu,qI),e(qI,bvo),e(yu,vvo),e(S,Fvo),e(S,Lu),e(Lu,Yne),e(Yne,Tvo),e(Lu,Mvo),e(Lu,NI),e(NI,Evo),e(Lu,Cvo),e(S,wvo),e(S,xu),e(xu,Kne),e(Kne,Avo),e(xu,yvo),e(xu,jI),e(jI,Lvo),e(xu,xvo),e(S,kvo),e(S,ku),e(ku,Zne),e(Zne,Svo),e(ku,Rvo),e(ku,DI),e(DI,Bvo),e(ku,Pvo),e(S,$vo),e(S,Su),e(Su,ese),e(ese,Ivo),e(Su,qvo),e(Su,GI),e(GI,Nvo),e(Su,jvo),e(S,Dvo),e(S,Ru),e(Ru,ose),e(ose,Gvo),e(Ru,Ovo),e(Ru,OI),e(OI,Vvo),e(Ru,Xvo),e(S,zvo),e(S,Bu),e(Bu,rse),e(rse,Qvo),e(Bu,Wvo),e(Bu,VI),e(VI,Hvo),e(Bu,Uvo),e(S,Jvo),e(S,Pu),e(Pu,tse),e(tse,Yvo),e(Pu,Kvo),e(Pu,XI),e(XI,Zvo),e(Pu,eFo),e(S,oFo),e(S,$u),e($u,ase),e(ase,rFo),e($u,tFo),e($u,zI),e(zI,aFo),e($u,nFo),e(S,sFo),e(S,Iu),e(Iu,nse),e(nse,lFo),e(Iu,iFo),e(Iu,QI),e(QI,dFo),e(Iu,cFo),e(S,fFo),e(S,qu),e(qu,sse),e(sse,mFo),e(qu,gFo),e(qu,WI),e(WI,hFo),e(qu,pFo),e(S,_Fo),e(S,Nu),e(Nu,lse),e(lse,uFo),e(Nu,bFo),e(Nu,HI),e(HI,vFo),e(Nu,FFo),e(S,TFo),e(S,ju),e(ju,ise),e(ise,MFo),e(ju,EFo),e(ju,UI),e(UI,CFo),e(ju,wFo),e(S,AFo),e(S,Du),e(Du,dse),e(dse,yFo),e(Du,LFo),e(Du,JI),e(JI,xFo),e(Du,kFo),e(S,SFo),e(S,Gu),e(Gu,cse),e(cse,RFo),e(Gu,BFo),e(Gu,YI),e(YI,PFo),e(Gu,$Fo),e(S,IFo),e(S,Ou),e(Ou,fse),e(fse,qFo),e(Ou,NFo),e(Ou,KI),e(KI,jFo),e(Ou,DFo),e(S,GFo),e(S,Vu),e(Vu,mse),e(mse,OFo),e(Vu,VFo),e(Vu,ZI),e(ZI,XFo),e(Vu,zFo),e(De,QFo),e(De,Xu),e(Xu,WFo),e(Xu,gse),e(gse,HFo),e(Xu,UFo),e(Xu,hse),e(hse,JFo),e(De,YFo),e(De,pse),e(pse,KFo),e(De,ZFo),g(Q3,De,null),b(c,UPe,u),b(c,md,u),e(md,zu),e(zu,_se),g(W3,_se,null),e(md,eTo),e(md,use),e(use,oTo),b(c,JPe,u),b(c,Ko,u),g(H3,Ko,null),e(Ko,rTo),e(Ko,gd),e(gd,tTo),e(gd,eq),e(eq,aTo),e(gd,nTo),e(gd,oq),e(oq,sTo),e(gd,lTo),e(Ko,iTo),e(Ko,U3),e(U3,dTo),e(U3,bse),e(bse,cTo),e(U3,fTo),e(Ko,mTo),e(Ko,Qr),g(J3,Qr,null),e(Qr,gTo),e(Qr,vse),e(vse,hTo),e(Qr,pTo),e(Qr,hd),e(hd,_To),e(hd,Fse),e(Fse,uTo),e(hd,bTo),e(hd,rq),e(rq,vTo),e(hd,FTo),e(Qr,TTo),e(Qr,Tse),e(Tse,MTo),e(Qr,ETo),g(Y3,Qr,null),e(Ko,CTo),e(Ko,Ge),g(K3,Ge,null),e(Ge,wTo),e(Ge,Mse),e(Mse,ATo),e(Ge,yTo),e(Ge,Qa),e(Qa,LTo),e(Qa,Ese),e(Ese,xTo),e(Qa,kTo),e(Qa,Cse),e(Cse,STo),e(Qa,RTo),e(Qa,wse),e(wse,BTo),e(Qa,PTo),e(Ge,$To),e(Ge,$),e($,Qu),e(Qu,Ase),e(Ase,ITo),e(Qu,qTo),e(Qu,tq),e(tq,NTo),e(Qu,jTo),e($,DTo),e($,Wu),e(Wu,yse),e(yse,GTo),e(Wu,OTo),e(Wu,aq),e(aq,VTo),e(Wu,XTo),e($,zTo),e($,Hu),e(Hu,Lse),e(Lse,QTo),e(Hu,WTo),e(Hu,nq),e(nq,HTo),e(Hu,UTo),e($,JTo),e($,Uu),e(Uu,xse),e(xse,YTo),e(Uu,KTo),e(Uu,sq),e(sq,ZTo),e(Uu,e7o),e($,o7o),e($,Ju),e(Ju,kse),e(kse,r7o),e(Ju,t7o),e(Ju,lq),e(lq,a7o),e(Ju,n7o),e($,s7o),e($,Yu),e(Yu,Sse),e(Sse,l7o),e(Yu,i7o),e(Yu,iq),e(iq,d7o),e(Yu,c7o),e($,f7o),e($,Ku),e(Ku,Rse),e(Rse,m7o),e(Ku,g7o),e(Ku,dq),e(dq,h7o),e(Ku,p7o),e($,_7o),e($,Zu),e(Zu,Bse),e(Bse,u7o),e(Zu,b7o),e(Zu,cq),e(cq,v7o),e(Zu,F7o),e($,T7o),e($,e2),e(e2,Pse),e(Pse,M7o),e(e2,E7o),e(e2,fq),e(fq,C7o),e(e2,w7o),e($,A7o),e($,o2),e(o2,$se),e($se,y7o),e(o2,L7o),e(o2,mq),e(mq,x7o),e(o2,k7o),e($,S7o),e($,r2),e(r2,Ise),e(Ise,R7o),e(r2,B7o),e(r2,gq),e(gq,P7o),e(r2,$7o),e($,I7o),e($,t2),e(t2,qse),e(qse,q7o),e(t2,N7o),e(t2,hq),e(hq,j7o),e(t2,D7o),e($,G7o),e($,a2),e(a2,Nse),e(Nse,O7o),e(a2,V7o),e(a2,pq),e(pq,X7o),e(a2,z7o),e($,Q7o),e($,n2),e(n2,jse),e(jse,W7o),e(n2,H7o),e(n2,_q),e(_q,U7o),e(n2,J7o),e($,Y7o),e($,s2),e(s2,Dse),e(Dse,K7o),e(s2,Z7o),e(s2,uq),e(uq,e9o),e(s2,o9o),e($,r9o),e($,l2),e(l2,Gse),e(Gse,t9o),e(l2,a9o),e(l2,bq),e(bq,n9o),e(l2,s9o),e($,l9o),e($,i2),e(i2,Ose),e(Ose,i9o),e(i2,d9o),e(i2,vq),e(vq,c9o),e(i2,f9o),e($,m9o),e($,d2),e(d2,Vse),e(Vse,g9o),e(d2,h9o),e(d2,Fq),e(Fq,p9o),e(d2,_9o),e($,u9o),e($,c2),e(c2,Xse),e(Xse,b9o),e(c2,v9o),e(c2,Tq),e(Tq,F9o),e(c2,T9o),e($,M9o),e($,f2),e(f2,zse),e(zse,E9o),e(f2,C9o),e(f2,Mq),e(Mq,w9o),e(f2,A9o),e($,y9o),e($,m2),e(m2,Qse),e(Qse,L9o),e(m2,x9o),e(m2,Eq),e(Eq,k9o),e(m2,S9o),e($,R9o),e($,g2),e(g2,Wse),e(Wse,B9o),e(g2,P9o),e(g2,Cq),e(Cq,$9o),e(g2,I9o),e($,q9o),e($,h2),e(h2,Hse),e(Hse,N9o),e(h2,j9o),e(h2,wq),e(wq,D9o),e(h2,G9o),e($,O9o),e($,p2),e(p2,Use),e(Use,V9o),e(p2,X9o),e(p2,Aq),e(Aq,z9o),e(p2,Q9o),e($,W9o),e($,_2),e(_2,Jse),e(Jse,H9o),e(_2,U9o),e(_2,yq),e(yq,J9o),e(_2,Y9o),e($,K9o),e($,u2),e(u2,Yse),e(Yse,Z9o),e(u2,eMo),e(u2,Lq),e(Lq,oMo),e(u2,rMo),e($,tMo),e($,b2),e(b2,Kse),e(Kse,aMo),e(b2,nMo),e(b2,xq),e(xq,sMo),e(b2,lMo),e($,iMo),e($,v2),e(v2,Zse),e(Zse,dMo),e(v2,cMo),e(v2,kq),e(kq,fMo),e(v2,mMo),e($,gMo),e($,F2),e(F2,ele),e(ele,hMo),e(F2,pMo),e(F2,Sq),e(Sq,_Mo),e(F2,uMo),e($,bMo),e($,T2),e(T2,ole),e(ole,vMo),e(T2,FMo),e(T2,Rq),e(Rq,TMo),e(T2,MMo),e($,EMo),e($,M2),e(M2,rle),e(rle,CMo),e(M2,wMo),e(M2,Bq),e(Bq,AMo),e(M2,yMo),e($,LMo),e($,E2),e(E2,tle),e(tle,xMo),e(E2,kMo),e(E2,Pq),e(Pq,SMo),e(E2,RMo),e($,BMo),e($,C2),e(C2,ale),e(ale,PMo),e(C2,$Mo),e(C2,$q),e($q,IMo),e(C2,qMo),e($,NMo),e($,w2),e(w2,nle),e(nle,jMo),e(w2,DMo),e(w2,Iq),e(Iq,GMo),e(w2,OMo),e($,VMo),e($,A2),e(A2,sle),e(sle,XMo),e(A2,zMo),e(A2,qq),e(qq,QMo),e(A2,WMo),e(Ge,HMo),e(Ge,y2),e(y2,UMo),e(y2,lle),e(lle,JMo),e(y2,YMo),e(y2,ile),e(ile,KMo),e(Ge,ZMo),e(Ge,dle),e(dle,e4o),e(Ge,o4o),g(Z3,Ge,null),b(c,YPe,u),b(c,pd,u),e(pd,L2),e(L2,cle),g(eC,cle,null),e(pd,r4o),e(pd,fle),e(fle,t4o),b(c,KPe,u),b(c,Zo,u),g(oC,Zo,null),e(Zo,a4o),e(Zo,_d),e(_d,n4o),e(_d,Nq),e(Nq,s4o),e(_d,l4o),e(_d,jq),e(jq,i4o),e(_d,d4o),e(Zo,c4o),e(Zo,rC),e(rC,f4o),e(rC,mle),e(mle,m4o),e(rC,g4o),e(Zo,h4o),e(Zo,Wr),g(tC,Wr,null),e(Wr,p4o),e(Wr,gle),e(gle,_4o),e(Wr,u4o),e(Wr,ud),e(ud,b4o),e(ud,hle),e(hle,v4o),e(ud,F4o),e(ud,Dq),e(Dq,T4o),e(ud,M4o),e(Wr,E4o),e(Wr,ple),e(ple,C4o),e(Wr,w4o),g(aC,Wr,null),e(Zo,A4o),e(Zo,Oe),g(nC,Oe,null),e(Oe,y4o),e(Oe,_le),e(_le,L4o),e(Oe,x4o),e(Oe,Wa),e(Wa,k4o),e(Wa,ule),e(ule,S4o),e(Wa,R4o),e(Wa,ble),e(ble,B4o),e(Wa,P4o),e(Wa,vle),e(vle,$4o),e(Wa,I4o),e(Oe,q4o),e(Oe,I),e(I,x2),e(x2,Fle),e(Fle,N4o),e(x2,j4o),e(x2,Gq),e(Gq,D4o),e(x2,G4o),e(I,O4o),e(I,k2),e(k2,Tle),e(Tle,V4o),e(k2,X4o),e(k2,Oq),e(Oq,z4o),e(k2,Q4o),e(I,W4o),e(I,S2),e(S2,Mle),e(Mle,H4o),e(S2,U4o),e(S2,Vq),e(Vq,J4o),e(S2,Y4o),e(I,K4o),e(I,R2),e(R2,Ele),e(Ele,Z4o),e(R2,eEo),e(R2,Xq),e(Xq,oEo),e(R2,rEo),e(I,tEo),e(I,B2),e(B2,Cle),e(Cle,aEo),e(B2,nEo),e(B2,zq),e(zq,sEo),e(B2,lEo),e(I,iEo),e(I,P2),e(P2,wle),e(wle,dEo),e(P2,cEo),e(P2,Qq),e(Qq,fEo),e(P2,mEo),e(I,gEo),e(I,$2),e($2,Ale),e(Ale,hEo),e($2,pEo),e($2,Wq),e(Wq,_Eo),e($2,uEo),e(I,bEo),e(I,I2),e(I2,yle),e(yle,vEo),e(I2,FEo),e(I2,Hq),e(Hq,TEo),e(I2,MEo),e(I,EEo),e(I,q2),e(q2,Lle),e(Lle,CEo),e(q2,wEo),e(q2,Uq),e(Uq,AEo),e(q2,yEo),e(I,LEo),e(I,N2),e(N2,xle),e(xle,xEo),e(N2,kEo),e(N2,Jq),e(Jq,SEo),e(N2,REo),e(I,BEo),e(I,j2),e(j2,kle),e(kle,PEo),e(j2,$Eo),e(j2,Yq),e(Yq,IEo),e(j2,qEo),e(I,NEo),e(I,D2),e(D2,Sle),e(Sle,jEo),e(D2,DEo),e(D2,Kq),e(Kq,GEo),e(D2,OEo),e(I,VEo),e(I,G2),e(G2,Rle),e(Rle,XEo),e(G2,zEo),e(G2,Zq),e(Zq,QEo),e(G2,WEo),e(I,HEo),e(I,O2),e(O2,Ble),e(Ble,UEo),e(O2,JEo),e(O2,eN),e(eN,YEo),e(O2,KEo),e(I,ZEo),e(I,V2),e(V2,Ple),e(Ple,e5o),e(V2,o5o),e(V2,oN),e(oN,r5o),e(V2,t5o),e(I,a5o),e(I,X2),e(X2,$le),e($le,n5o),e(X2,s5o),e(X2,rN),e(rN,l5o),e(X2,i5o),e(I,d5o),e(I,z2),e(z2,Ile),e(Ile,c5o),e(z2,f5o),e(z2,tN),e(tN,m5o),e(z2,g5o),e(I,h5o),e(I,Q2),e(Q2,qle),e(qle,p5o),e(Q2,_5o),e(Q2,aN),e(aN,u5o),e(Q2,b5o),e(I,v5o),e(I,W2),e(W2,Nle),e(Nle,F5o),e(W2,T5o),e(W2,nN),e(nN,M5o),e(W2,E5o),e(I,C5o),e(I,H2),e(H2,jle),e(jle,w5o),e(H2,A5o),e(H2,sN),e(sN,y5o),e(H2,L5o),e(I,x5o),e(I,U2),e(U2,Dle),e(Dle,k5o),e(U2,S5o),e(U2,lN),e(lN,R5o),e(U2,B5o),e(I,P5o),e(I,J2),e(J2,Gle),e(Gle,$5o),e(J2,I5o),e(J2,iN),e(iN,q5o),e(J2,N5o),e(I,j5o),e(I,Y2),e(Y2,Ole),e(Ole,D5o),e(Y2,G5o),e(Y2,dN),e(dN,O5o),e(Y2,V5o),e(I,X5o),e(I,K2),e(K2,Vle),e(Vle,z5o),e(K2,Q5o),e(K2,cN),e(cN,W5o),e(K2,H5o),e(I,U5o),e(I,Z2),e(Z2,Xle),e(Xle,J5o),e(Z2,Y5o),e(Z2,fN),e(fN,K5o),e(Z2,Z5o),e(I,e3o),e(I,e1),e(e1,zle),e(zle,o3o),e(e1,r3o),e(e1,mN),e(mN,t3o),e(e1,a3o),e(I,n3o),e(I,o1),e(o1,Qle),e(Qle,s3o),e(o1,l3o),e(o1,gN),e(gN,i3o),e(o1,d3o),e(I,c3o),e(I,r1),e(r1,Wle),e(Wle,f3o),e(r1,m3o),e(r1,hN),e(hN,g3o),e(r1,h3o),e(I,p3o),e(I,t1),e(t1,Hle),e(Hle,_3o),e(t1,u3o),e(t1,pN),e(pN,b3o),e(t1,v3o),e(I,F3o),e(I,a1),e(a1,Ule),e(Ule,T3o),e(a1,M3o),e(a1,_N),e(_N,E3o),e(a1,C3o),e(I,w3o),e(I,n1),e(n1,Jle),e(Jle,A3o),e(n1,y3o),e(n1,Yle),e(Yle,L3o),e(n1,x3o),e(I,k3o),e(I,s1),e(s1,Kle),e(Kle,S3o),e(s1,R3o),e(s1,uN),e(uN,B3o),e(s1,P3o),e(I,$3o),e(I,l1),e(l1,Zle),e(Zle,I3o),e(l1,q3o),e(l1,bN),e(bN,N3o),e(l1,j3o),e(I,D3o),e(I,i1),e(i1,eie),e(eie,G3o),e(i1,O3o),e(i1,vN),e(vN,V3o),e(i1,X3o),e(I,z3o),e(I,d1),e(d1,oie),e(oie,Q3o),e(d1,W3o),e(d1,FN),e(FN,H3o),e(d1,U3o),e(Oe,J3o),e(Oe,c1),e(c1,Y3o),e(c1,rie),e(rie,K3o),e(c1,Z3o),e(c1,tie),e(tie,eCo),e(Oe,oCo),e(Oe,aie),e(aie,rCo),e(Oe,tCo),g(sC,Oe,null),b(c,ZPe,u),b(c,bd,u),e(bd,f1),e(f1,nie),g(lC,nie,null),e(bd,aCo),e(bd,sie),e(sie,nCo),b(c,e$e,u),b(c,er,u),g(iC,er,null),e(er,sCo),e(er,vd),e(vd,lCo),e(vd,TN),e(TN,iCo),e(vd,dCo),e(vd,MN),e(MN,cCo),e(vd,fCo),e(er,mCo),e(er,dC),e(dC,gCo),e(dC,lie),e(lie,hCo),e(dC,pCo),e(er,_Co),e(er,Hr),g(cC,Hr,null),e(Hr,uCo),e(Hr,iie),e(iie,bCo),e(Hr,vCo),e(Hr,Fd),e(Fd,FCo),e(Fd,die),e(die,TCo),e(Fd,MCo),e(Fd,EN),e(EN,ECo),e(Fd,CCo),e(Hr,wCo),e(Hr,cie),e(cie,ACo),e(Hr,yCo),g(fC,Hr,null),e(er,LCo),e(er,Ve),g(mC,Ve,null),e(Ve,xCo),e(Ve,fie),e(fie,kCo),e(Ve,SCo),e(Ve,Ha),e(Ha,RCo),e(Ha,mie),e(mie,BCo),e(Ha,PCo),e(Ha,gie),e(gie,$Co),e(Ha,ICo),e(Ha,hie),e(hie,qCo),e(Ha,NCo),e(Ve,jCo),e(Ve,ne),e(ne,m1),e(m1,pie),e(pie,DCo),e(m1,GCo),e(m1,CN),e(CN,OCo),e(m1,VCo),e(ne,XCo),e(ne,g1),e(g1,_ie),e(_ie,zCo),e(g1,QCo),e(g1,wN),e(wN,WCo),e(g1,HCo),e(ne,UCo),e(ne,h1),e(h1,uie),e(uie,JCo),e(h1,YCo),e(h1,AN),e(AN,KCo),e(h1,ZCo),e(ne,ewo),e(ne,p1),e(p1,bie),e(bie,owo),e(p1,rwo),e(p1,yN),e(yN,two),e(p1,awo),e(ne,nwo),e(ne,_1),e(_1,vie),e(vie,swo),e(_1,lwo),e(_1,LN),e(LN,iwo),e(_1,dwo),e(ne,cwo),e(ne,u1),e(u1,Fie),e(Fie,fwo),e(u1,mwo),e(u1,xN),e(xN,gwo),e(u1,hwo),e(ne,pwo),e(ne,b1),e(b1,Tie),e(Tie,_wo),e(b1,uwo),e(b1,kN),e(kN,bwo),e(b1,vwo),e(ne,Fwo),e(ne,v1),e(v1,Mie),e(Mie,Two),e(v1,Mwo),e(v1,SN),e(SN,Ewo),e(v1,Cwo),e(ne,wwo),e(ne,F1),e(F1,Eie),e(Eie,Awo),e(F1,ywo),e(F1,RN),e(RN,Lwo),e(F1,xwo),e(ne,kwo),e(ne,T1),e(T1,Cie),e(Cie,Swo),e(T1,Rwo),e(T1,BN),e(BN,Bwo),e(T1,Pwo),e(ne,$wo),e(ne,M1),e(M1,wie),e(wie,Iwo),e(M1,qwo),e(M1,PN),e(PN,Nwo),e(M1,jwo),e(ne,Dwo),e(ne,E1),e(E1,Aie),e(Aie,Gwo),e(E1,Owo),e(E1,$N),e($N,Vwo),e(E1,Xwo),e(ne,zwo),e(ne,C1),e(C1,yie),e(yie,Qwo),e(C1,Wwo),e(C1,IN),e(IN,Hwo),e(C1,Uwo),e(ne,Jwo),e(ne,w1),e(w1,Lie),e(Lie,Ywo),e(w1,Kwo),e(w1,qN),e(qN,Zwo),e(w1,e0o),e(ne,o0o),e(ne,A1),e(A1,xie),e(xie,r0o),e(A1,t0o),e(A1,NN),e(NN,a0o),e(A1,n0o),e(ne,s0o),e(ne,y1),e(y1,kie),e(kie,l0o),e(y1,i0o),e(y1,jN),e(jN,d0o),e(y1,c0o),e(ne,f0o),e(ne,L1),e(L1,Sie),e(Sie,m0o),e(L1,g0o),e(L1,DN),e(DN,h0o),e(L1,p0o),e(ne,_0o),e(ne,x1),e(x1,Rie),e(Rie,u0o),e(x1,b0o),e(x1,GN),e(GN,v0o),e(x1,F0o),e(Ve,T0o),e(Ve,k1),e(k1,M0o),e(k1,Bie),e(Bie,E0o),e(k1,C0o),e(k1,Pie),e(Pie,w0o),e(Ve,A0o),e(Ve,$ie),e($ie,y0o),e(Ve,L0o),g(gC,Ve,null),b(c,o$e,u),b(c,Td,u),e(Td,S1),e(S1,Iie),g(hC,Iie,null),e(Td,x0o),e(Td,qie),e(qie,k0o),b(c,r$e,u),b(c,or,u),g(pC,or,null),e(or,S0o),e(or,Md),e(Md,R0o),e(Md,ON),e(ON,B0o),e(Md,P0o),e(Md,VN),e(VN,$0o),e(Md,I0o),e(or,q0o),e(or,_C),e(_C,N0o),e(_C,Nie),e(Nie,j0o),e(_C,D0o),e(or,G0o),e(or,Ur),g(uC,Ur,null),e(Ur,O0o),e(Ur,jie),e(jie,V0o),e(Ur,X0o),e(Ur,Ed),e(Ed,z0o),e(Ed,Die),e(Die,Q0o),e(Ed,W0o),e(Ed,XN),e(XN,H0o),e(Ed,U0o),e(Ur,J0o),e(Ur,Gie),e(Gie,Y0o),e(Ur,K0o),g(bC,Ur,null),e(or,Z0o),e(or,Xe),g(vC,Xe,null),e(Xe,eAo),e(Xe,Oie),e(Oie,oAo),e(Xe,rAo),e(Xe,Ua),e(Ua,tAo),e(Ua,Vie),e(Vie,aAo),e(Ua,nAo),e(Ua,Xie),e(Xie,sAo),e(Ua,lAo),e(Ua,zie),e(zie,iAo),e(Ua,dAo),e(Xe,cAo),e(Xe,y),e(y,R1),e(R1,Qie),e(Qie,fAo),e(R1,mAo),e(R1,zN),e(zN,gAo),e(R1,hAo),e(y,pAo),e(y,B1),e(B1,Wie),e(Wie,_Ao),e(B1,uAo),e(B1,QN),e(QN,bAo),e(B1,vAo),e(y,FAo),e(y,P1),e(P1,Hie),e(Hie,TAo),e(P1,MAo),e(P1,WN),e(WN,EAo),e(P1,CAo),e(y,wAo),e(y,$1),e($1,Uie),e(Uie,AAo),e($1,yAo),e($1,HN),e(HN,LAo),e($1,xAo),e(y,kAo),e(y,I1),e(I1,Jie),e(Jie,SAo),e(I1,RAo),e(I1,UN),e(UN,BAo),e(I1,PAo),e(y,$Ao),e(y,q1),e(q1,Yie),e(Yie,IAo),e(q1,qAo),e(q1,JN),e(JN,NAo),e(q1,jAo),e(y,DAo),e(y,N1),e(N1,Kie),e(Kie,GAo),e(N1,OAo),e(N1,YN),e(YN,VAo),e(N1,XAo),e(y,zAo),e(y,j1),e(j1,Zie),e(Zie,QAo),e(j1,WAo),e(j1,KN),e(KN,HAo),e(j1,UAo),e(y,JAo),e(y,D1),e(D1,ede),e(ede,YAo),e(D1,KAo),e(D1,ZN),e(ZN,ZAo),e(D1,eyo),e(y,oyo),e(y,G1),e(G1,ode),e(ode,ryo),e(G1,tyo),e(G1,ej),e(ej,ayo),e(G1,nyo),e(y,syo),e(y,O1),e(O1,rde),e(rde,lyo),e(O1,iyo),e(O1,oj),e(oj,dyo),e(O1,cyo),e(y,fyo),e(y,V1),e(V1,tde),e(tde,myo),e(V1,gyo),e(V1,rj),e(rj,hyo),e(V1,pyo),e(y,_yo),e(y,X1),e(X1,ade),e(ade,uyo),e(X1,byo),e(X1,tj),e(tj,vyo),e(X1,Fyo),e(y,Tyo),e(y,z1),e(z1,nde),e(nde,Myo),e(z1,Eyo),e(z1,aj),e(aj,Cyo),e(z1,wyo),e(y,Ayo),e(y,Q1),e(Q1,sde),e(sde,yyo),e(Q1,Lyo),e(Q1,nj),e(nj,xyo),e(Q1,kyo),e(y,Syo),e(y,W1),e(W1,lde),e(lde,Ryo),e(W1,Byo),e(W1,sj),e(sj,Pyo),e(W1,$yo),e(y,Iyo),e(y,H1),e(H1,ide),e(ide,qyo),e(H1,Nyo),e(H1,lj),e(lj,jyo),e(H1,Dyo),e(y,Gyo),e(y,U1),e(U1,dde),e(dde,Oyo),e(U1,Vyo),e(U1,ij),e(ij,Xyo),e(U1,zyo),e(y,Qyo),e(y,J1),e(J1,cde),e(cde,Wyo),e(J1,Hyo),e(J1,dj),e(dj,Uyo),e(J1,Jyo),e(y,Yyo),e(y,Y1),e(Y1,fde),e(fde,Kyo),e(Y1,Zyo),e(Y1,cj),e(cj,eLo),e(Y1,oLo),e(y,rLo),e(y,K1),e(K1,mde),e(mde,tLo),e(K1,aLo),e(K1,fj),e(fj,nLo),e(K1,sLo),e(y,lLo),e(y,Z1),e(Z1,gde),e(gde,iLo),e(Z1,dLo),e(Z1,mj),e(mj,cLo),e(Z1,fLo),e(y,mLo),e(y,eb),e(eb,hde),e(hde,gLo),e(eb,hLo),e(eb,gj),e(gj,pLo),e(eb,_Lo),e(y,uLo),e(y,ob),e(ob,pde),e(pde,bLo),e(ob,vLo),e(ob,hj),e(hj,FLo),e(ob,TLo),e(y,MLo),e(y,rb),e(rb,_de),e(_de,ELo),e(rb,CLo),e(rb,pj),e(pj,wLo),e(rb,ALo),e(y,yLo),e(y,tb),e(tb,ude),e(ude,LLo),e(tb,xLo),e(tb,_j),e(_j,kLo),e(tb,SLo),e(y,RLo),e(y,ab),e(ab,bde),e(bde,BLo),e(ab,PLo),e(ab,uj),e(uj,$Lo),e(ab,ILo),e(y,qLo),e(y,nb),e(nb,vde),e(vde,NLo),e(nb,jLo),e(nb,bj),e(bj,DLo),e(nb,GLo),e(y,OLo),e(y,sb),e(sb,Fde),e(Fde,VLo),e(sb,XLo),e(sb,vj),e(vj,zLo),e(sb,QLo),e(y,WLo),e(y,lb),e(lb,Tde),e(Tde,HLo),e(lb,ULo),e(lb,Fj),e(Fj,JLo),e(lb,YLo),e(y,KLo),e(y,ib),e(ib,Mde),e(Mde,ZLo),e(ib,e8o),e(ib,Tj),e(Tj,o8o),e(ib,r8o),e(y,t8o),e(y,db),e(db,Ede),e(Ede,a8o),e(db,n8o),e(db,Mj),e(Mj,s8o),e(db,l8o),e(y,i8o),e(y,cb),e(cb,Cde),e(Cde,d8o),e(cb,c8o),e(cb,Ej),e(Ej,f8o),e(cb,m8o),e(y,g8o),e(y,fb),e(fb,wde),e(wde,h8o),e(fb,p8o),e(fb,Cj),e(Cj,_8o),e(fb,u8o),e(y,b8o),e(y,mb),e(mb,Ade),e(Ade,v8o),e(mb,F8o),e(mb,wj),e(wj,T8o),e(mb,M8o),e(y,E8o),e(y,gb),e(gb,yde),e(yde,C8o),e(gb,w8o),e(gb,Aj),e(Aj,A8o),e(gb,y8o),e(y,L8o),e(y,hb),e(hb,Lde),e(Lde,x8o),e(hb,k8o),e(hb,yj),e(yj,S8o),e(hb,R8o),e(y,B8o),e(y,pb),e(pb,xde),e(xde,P8o),e(pb,$8o),e(pb,Lj),e(Lj,I8o),e(pb,q8o),e(y,N8o),e(y,_b),e(_b,kde),e(kde,j8o),e(_b,D8o),e(_b,xj),e(xj,G8o),e(_b,O8o),e(y,V8o),e(y,ub),e(ub,Sde),e(Sde,X8o),e(ub,z8o),e(ub,kj),e(kj,Q8o),e(ub,W8o),e(y,H8o),e(y,bb),e(bb,Rde),e(Rde,U8o),e(bb,J8o),e(bb,Sj),e(Sj,Y8o),e(bb,K8o),e(y,Z8o),e(y,vb),e(vb,Bde),e(Bde,exo),e(vb,oxo),e(vb,Rj),e(Rj,rxo),e(vb,txo),e(y,axo),e(y,Fb),e(Fb,Pde),e(Pde,nxo),e(Fb,sxo),e(Fb,Bj),e(Bj,lxo),e(Fb,ixo),e(y,dxo),e(y,Tb),e(Tb,$de),e($de,cxo),e(Tb,fxo),e(Tb,Pj),e(Pj,mxo),e(Tb,gxo),e(y,hxo),e(y,Mb),e(Mb,Ide),e(Ide,pxo),e(Mb,_xo),e(Mb,$j),e($j,uxo),e(Mb,bxo),e(y,vxo),e(y,Eb),e(Eb,qde),e(qde,Fxo),e(Eb,Txo),e(Eb,Ij),e(Ij,Mxo),e(Eb,Exo),e(y,Cxo),e(y,Cb),e(Cb,Nde),e(Nde,wxo),e(Cb,Axo),e(Cb,qj),e(qj,yxo),e(Cb,Lxo),e(Xe,xxo),e(Xe,wb),e(wb,kxo),e(wb,jde),e(jde,Sxo),e(wb,Rxo),e(wb,Dde),e(Dde,Bxo),e(Xe,Pxo),e(Xe,Gde),e(Gde,$xo),e(Xe,Ixo),g(FC,Xe,null),b(c,t$e,u),b(c,Cd,u),e(Cd,Ab),e(Ab,Ode),g(TC,Ode,null),e(Cd,qxo),e(Cd,Vde),e(Vde,Nxo),b(c,a$e,u),b(c,rr,u),g(MC,rr,null),e(rr,jxo),e(rr,wd),e(wd,Dxo),e(wd,Nj),e(Nj,Gxo),e(wd,Oxo),e(wd,jj),e(jj,Vxo),e(wd,Xxo),e(rr,zxo),e(rr,EC),e(EC,Qxo),e(EC,Xde),e(Xde,Wxo),e(EC,Hxo),e(rr,Uxo),e(rr,Jr),g(CC,Jr,null),e(Jr,Jxo),e(Jr,zde),e(zde,Yxo),e(Jr,Kxo),e(Jr,Ad),e(Ad,Zxo),e(Ad,Qde),e(Qde,eko),e(Ad,oko),e(Ad,Dj),e(Dj,rko),e(Ad,tko),e(Jr,ako),e(Jr,Wde),e(Wde,nko),e(Jr,sko),g(wC,Jr,null),e(rr,lko),e(rr,ze),g(AC,ze,null),e(ze,iko),e(ze,Hde),e(Hde,dko),e(ze,cko),e(ze,Ja),e(Ja,fko),e(Ja,Ude),e(Ude,mko),e(Ja,gko),e(Ja,Jde),e(Jde,hko),e(Ja,pko),e(Ja,Yde),e(Yde,_ko),e(Ja,uko),e(ze,bko),e(ze,G),e(G,yb),e(yb,Kde),e(Kde,vko),e(yb,Fko),e(yb,Gj),e(Gj,Tko),e(yb,Mko),e(G,Eko),e(G,Lb),e(Lb,Zde),e(Zde,Cko),e(Lb,wko),e(Lb,Oj),e(Oj,Ako),e(Lb,yko),e(G,Lko),e(G,xb),e(xb,ece),e(ece,xko),e(xb,kko),e(xb,Vj),e(Vj,Sko),e(xb,Rko),e(G,Bko),e(G,kb),e(kb,oce),e(oce,Pko),e(kb,$ko),e(kb,Xj),e(Xj,Iko),e(kb,qko),e(G,Nko),e(G,Sb),e(Sb,rce),e(rce,jko),e(Sb,Dko),e(Sb,zj),e(zj,Gko),e(Sb,Oko),e(G,Vko),e(G,Rb),e(Rb,tce),e(tce,Xko),e(Rb,zko),e(Rb,Qj),e(Qj,Qko),e(Rb,Wko),e(G,Hko),e(G,Bb),e(Bb,ace),e(ace,Uko),e(Bb,Jko),e(Bb,Wj),e(Wj,Yko),e(Bb,Kko),e(G,Zko),e(G,Pb),e(Pb,nce),e(nce,eSo),e(Pb,oSo),e(Pb,Hj),e(Hj,rSo),e(Pb,tSo),e(G,aSo),e(G,$b),e($b,sce),e(sce,nSo),e($b,sSo),e($b,Uj),e(Uj,lSo),e($b,iSo),e(G,dSo),e(G,Ib),e(Ib,lce),e(lce,cSo),e(Ib,fSo),e(Ib,Jj),e(Jj,mSo),e(Ib,gSo),e(G,hSo),e(G,qb),e(qb,ice),e(ice,pSo),e(qb,_So),e(qb,Yj),e(Yj,uSo),e(qb,bSo),e(G,vSo),e(G,Nb),e(Nb,dce),e(dce,FSo),e(Nb,TSo),e(Nb,Kj),e(Kj,MSo),e(Nb,ESo),e(G,CSo),e(G,jb),e(jb,cce),e(cce,wSo),e(jb,ASo),e(jb,Zj),e(Zj,ySo),e(jb,LSo),e(G,xSo),e(G,Db),e(Db,fce),e(fce,kSo),e(Db,SSo),e(Db,eD),e(eD,RSo),e(Db,BSo),e(G,PSo),e(G,Gb),e(Gb,mce),e(mce,$So),e(Gb,ISo),e(Gb,oD),e(oD,qSo),e(Gb,NSo),e(G,jSo),e(G,Ob),e(Ob,gce),e(gce,DSo),e(Ob,GSo),e(Ob,rD),e(rD,OSo),e(Ob,VSo),e(G,XSo),e(G,Vb),e(Vb,hce),e(hce,zSo),e(Vb,QSo),e(Vb,tD),e(tD,WSo),e(Vb,HSo),e(G,USo),e(G,Xb),e(Xb,pce),e(pce,JSo),e(Xb,YSo),e(Xb,aD),e(aD,KSo),e(Xb,ZSo),e(G,eRo),e(G,zb),e(zb,_ce),e(_ce,oRo),e(zb,rRo),e(zb,nD),e(nD,tRo),e(zb,aRo),e(G,nRo),e(G,Qb),e(Qb,uce),e(uce,sRo),e(Qb,lRo),e(Qb,sD),e(sD,iRo),e(Qb,dRo),e(G,cRo),e(G,Wb),e(Wb,bce),e(bce,fRo),e(Wb,mRo),e(Wb,lD),e(lD,gRo),e(Wb,hRo),e(G,pRo),e(G,Hb),e(Hb,vce),e(vce,_Ro),e(Hb,uRo),e(Hb,iD),e(iD,bRo),e(Hb,vRo),e(G,FRo),e(G,Ub),e(Ub,Fce),e(Fce,TRo),e(Ub,MRo),e(Ub,dD),e(dD,ERo),e(Ub,CRo),e(G,wRo),e(G,Jb),e(Jb,Tce),e(Tce,ARo),e(Jb,yRo),e(Jb,cD),e(cD,LRo),e(Jb,xRo),e(G,kRo),e(G,Yb),e(Yb,Mce),e(Mce,SRo),e(Yb,RRo),e(Yb,fD),e(fD,BRo),e(Yb,PRo),e(G,$Ro),e(G,Kb),e(Kb,Ece),e(Ece,IRo),e(Kb,qRo),e(Kb,mD),e(mD,NRo),e(Kb,jRo),e(G,DRo),e(G,Zb),e(Zb,Cce),e(Cce,GRo),e(Zb,ORo),e(Zb,gD),e(gD,VRo),e(Zb,XRo),e(G,zRo),e(G,e6),e(e6,wce),e(wce,QRo),e(e6,WRo),e(e6,hD),e(hD,HRo),e(e6,URo),e(ze,JRo),e(ze,o6),e(o6,YRo),e(o6,Ace),e(Ace,KRo),e(o6,ZRo),e(o6,yce),e(yce,eBo),e(ze,oBo),e(ze,Lce),e(Lce,rBo),e(ze,tBo),g(yC,ze,null),b(c,n$e,u),b(c,yd,u),e(yd,r6),e(r6,xce),g(LC,xce,null),e(yd,aBo),e(yd,kce),e(kce,nBo),b(c,s$e,u),b(c,tr,u),g(xC,tr,null),e(tr,sBo),e(tr,Ld),e(Ld,lBo),e(Ld,pD),e(pD,iBo),e(Ld,dBo),e(Ld,_D),e(_D,cBo),e(Ld,fBo),e(tr,mBo),e(tr,kC),e(kC,gBo),e(kC,Sce),e(Sce,hBo),e(kC,pBo),e(tr,_Bo),e(tr,Yr),g(SC,Yr,null),e(Yr,uBo),e(Yr,Rce),e(Rce,bBo),e(Yr,vBo),e(Yr,xd),e(xd,FBo),e(xd,Bce),e(Bce,TBo),e(xd,MBo),e(xd,uD),e(uD,EBo),e(xd,CBo),e(Yr,wBo),e(Yr,Pce),e(Pce,ABo),e(Yr,yBo),g(RC,Yr,null),e(tr,LBo),e(tr,Qe),g(BC,Qe,null),e(Qe,xBo),e(Qe,$ce),e($ce,kBo),e(Qe,SBo),e(Qe,Ya),e(Ya,RBo),e(Ya,Ice),e(Ice,BBo),e(Ya,PBo),e(Ya,qce),e(qce,$Bo),e(Ya,IBo),e(Ya,Nce),e(Nce,qBo),e(Ya,NBo),e(Qe,jBo),e(Qe,da),e(da,t6),e(t6,jce),e(jce,DBo),e(t6,GBo),e(t6,bD),e(bD,OBo),e(t6,VBo),e(da,XBo),e(da,a6),e(a6,Dce),e(Dce,zBo),e(a6,QBo),e(a6,vD),e(vD,WBo),e(a6,HBo),e(da,UBo),e(da,n6),e(n6,Gce),e(Gce,JBo),e(n6,YBo),e(n6,FD),e(FD,KBo),e(n6,ZBo),e(da,ePo),e(da,s6),e(s6,Oce),e(Oce,oPo),e(s6,rPo),e(s6,TD),e(TD,tPo),e(s6,aPo),e(da,nPo),e(da,l6),e(l6,Vce),e(Vce,sPo),e(l6,lPo),e(l6,MD),e(MD,iPo),e(l6,dPo),e(Qe,cPo),e(Qe,i6),e(i6,fPo),e(i6,Xce),e(Xce,mPo),e(i6,gPo),e(i6,zce),e(zce,hPo),e(Qe,pPo),e(Qe,Qce),e(Qce,_Po),e(Qe,uPo),g(PC,Qe,null),b(c,l$e,u),b(c,kd,u),e(kd,d6),e(d6,Wce),g($C,Wce,null),e(kd,bPo),e(kd,Hce),e(Hce,vPo),b(c,i$e,u),b(c,ar,u),g(IC,ar,null),e(ar,FPo),e(ar,Sd),e(Sd,TPo),e(Sd,ED),e(ED,MPo),e(Sd,EPo),e(Sd,CD),e(CD,CPo),e(Sd,wPo),e(ar,APo),e(ar,qC),e(qC,yPo),e(qC,Uce),e(Uce,LPo),e(qC,xPo),e(ar,kPo),e(ar,Kr),g(NC,Kr,null),e(Kr,SPo),e(Kr,Jce),e(Jce,RPo),e(Kr,BPo),e(Kr,Rd),e(Rd,PPo),e(Rd,Yce),e(Yce,$Po),e(Rd,IPo),e(Rd,wD),e(wD,qPo),e(Rd,NPo),e(Kr,jPo),e(Kr,Kce),e(Kce,DPo),e(Kr,GPo),g(jC,Kr,null),e(ar,OPo),e(ar,We),g(DC,We,null),e(We,VPo),e(We,Zce),e(Zce,XPo),e(We,zPo),e(We,Ka),e(Ka,QPo),e(Ka,efe),e(efe,WPo),e(Ka,HPo),e(Ka,ofe),e(ofe,UPo),e(Ka,JPo),e(Ka,rfe),e(rfe,YPo),e(Ka,KPo),e(We,ZPo),e(We,j),e(j,c6),e(c6,tfe),e(tfe,e$o),e(c6,o$o),e(c6,AD),e(AD,r$o),e(c6,t$o),e(j,a$o),e(j,f6),e(f6,afe),e(afe,n$o),e(f6,s$o),e(f6,yD),e(yD,l$o),e(f6,i$o),e(j,d$o),e(j,m6),e(m6,nfe),e(nfe,c$o),e(m6,f$o),e(m6,LD),e(LD,m$o),e(m6,g$o),e(j,h$o),e(j,g6),e(g6,sfe),e(sfe,p$o),e(g6,_$o),e(g6,xD),e(xD,u$o),e(g6,b$o),e(j,v$o),e(j,h6),e(h6,lfe),e(lfe,F$o),e(h6,T$o),e(h6,kD),e(kD,M$o),e(h6,E$o),e(j,C$o),e(j,p6),e(p6,ife),e(ife,w$o),e(p6,A$o),e(p6,SD),e(SD,y$o),e(p6,L$o),e(j,x$o),e(j,_6),e(_6,dfe),e(dfe,k$o),e(_6,S$o),e(_6,RD),e(RD,R$o),e(_6,B$o),e(j,P$o),e(j,u6),e(u6,cfe),e(cfe,$$o),e(u6,I$o),e(u6,BD),e(BD,q$o),e(u6,N$o),e(j,j$o),e(j,b6),e(b6,ffe),e(ffe,D$o),e(b6,G$o),e(b6,PD),e(PD,O$o),e(b6,V$o),e(j,X$o),e(j,v6),e(v6,mfe),e(mfe,z$o),e(v6,Q$o),e(v6,$D),e($D,W$o),e(v6,H$o),e(j,U$o),e(j,F6),e(F6,gfe),e(gfe,J$o),e(F6,Y$o),e(F6,ID),e(ID,K$o),e(F6,Z$o),e(j,eIo),e(j,T6),e(T6,hfe),e(hfe,oIo),e(T6,rIo),e(T6,qD),e(qD,tIo),e(T6,aIo),e(j,nIo),e(j,M6),e(M6,pfe),e(pfe,sIo),e(M6,lIo),e(M6,ND),e(ND,iIo),e(M6,dIo),e(j,cIo),e(j,E6),e(E6,_fe),e(_fe,fIo),e(E6,mIo),e(E6,jD),e(jD,gIo),e(E6,hIo),e(j,pIo),e(j,C6),e(C6,ufe),e(ufe,_Io),e(C6,uIo),e(C6,DD),e(DD,bIo),e(C6,vIo),e(j,FIo),e(j,w6),e(w6,bfe),e(bfe,TIo),e(w6,MIo),e(w6,GD),e(GD,EIo),e(w6,CIo),e(j,wIo),e(j,A6),e(A6,vfe),e(vfe,AIo),e(A6,yIo),e(A6,OD),e(OD,LIo),e(A6,xIo),e(j,kIo),e(j,y6),e(y6,Ffe),e(Ffe,SIo),e(y6,RIo),e(y6,VD),e(VD,BIo),e(y6,PIo),e(j,$Io),e(j,L6),e(L6,Tfe),e(Tfe,IIo),e(L6,qIo),e(L6,XD),e(XD,NIo),e(L6,jIo),e(j,DIo),e(j,x6),e(x6,Mfe),e(Mfe,GIo),e(x6,OIo),e(x6,zD),e(zD,VIo),e(x6,XIo),e(j,zIo),e(j,k6),e(k6,Efe),e(Efe,QIo),e(k6,WIo),e(k6,QD),e(QD,HIo),e(k6,UIo),e(j,JIo),e(j,S6),e(S6,Cfe),e(Cfe,YIo),e(S6,KIo),e(S6,WD),e(WD,ZIo),e(S6,eqo),e(j,oqo),e(j,R6),e(R6,wfe),e(wfe,rqo),e(R6,tqo),e(R6,HD),e(HD,aqo),e(R6,nqo),e(j,sqo),e(j,B6),e(B6,Afe),e(Afe,lqo),e(B6,iqo),e(B6,UD),e(UD,dqo),e(B6,cqo),e(j,fqo),e(j,P6),e(P6,yfe),e(yfe,mqo),e(P6,gqo),e(P6,JD),e(JD,hqo),e(P6,pqo),e(j,_qo),e(j,$6),e($6,Lfe),e(Lfe,uqo),e($6,bqo),e($6,YD),e(YD,vqo),e($6,Fqo),e(j,Tqo),e(j,I6),e(I6,xfe),e(xfe,Mqo),e(I6,Eqo),e(I6,KD),e(KD,Cqo),e(I6,wqo),e(j,Aqo),e(j,q6),e(q6,kfe),e(kfe,yqo),e(q6,Lqo),e(q6,ZD),e(ZD,xqo),e(q6,kqo),e(j,Sqo),e(j,N6),e(N6,Sfe),e(Sfe,Rqo),e(N6,Bqo),e(N6,eG),e(eG,Pqo),e(N6,$qo),e(j,Iqo),e(j,j6),e(j6,Rfe),e(Rfe,qqo),e(j6,Nqo),e(j6,oG),e(oG,jqo),e(j6,Dqo),e(j,Gqo),e(j,D6),e(D6,Bfe),e(Bfe,Oqo),e(D6,Vqo),e(D6,rG),e(rG,Xqo),e(D6,zqo),e(j,Qqo),e(j,G6),e(G6,Pfe),e(Pfe,Wqo),e(G6,Hqo),e(G6,tG),e(tG,Uqo),e(G6,Jqo),e(j,Yqo),e(j,O6),e(O6,$fe),e($fe,Kqo),e(O6,Zqo),e(O6,aG),e(aG,eNo),e(O6,oNo),e(We,rNo),e(We,V6),e(V6,tNo),e(V6,Ife),e(Ife,aNo),e(V6,nNo),e(V6,qfe),e(qfe,sNo),e(We,lNo),e(We,Nfe),e(Nfe,iNo),e(We,dNo),g(GC,We,null),b(c,d$e,u),b(c,Bd,u),e(Bd,X6),e(X6,jfe),g(OC,jfe,null),e(Bd,cNo),e(Bd,Dfe),e(Dfe,fNo),b(c,c$e,u),b(c,nr,u),g(VC,nr,null),e(nr,mNo),e(nr,Pd),e(Pd,gNo),e(Pd,nG),e(nG,hNo),e(Pd,pNo),e(Pd,sG),e(sG,_No),e(Pd,uNo),e(nr,bNo),e(nr,XC),e(XC,vNo),e(XC,Gfe),e(Gfe,FNo),e(XC,TNo),e(nr,MNo),e(nr,Zr),g(zC,Zr,null),e(Zr,ENo),e(Zr,Ofe),e(Ofe,CNo),e(Zr,wNo),e(Zr,$d),e($d,ANo),e($d,Vfe),e(Vfe,yNo),e($d,LNo),e($d,lG),e(lG,xNo),e($d,kNo),e(Zr,SNo),e(Zr,Xfe),e(Xfe,RNo),e(Zr,BNo),g(QC,Zr,null),e(nr,PNo),e(nr,He),g(WC,He,null),e(He,$No),e(He,zfe),e(zfe,INo),e(He,qNo),e(He,Za),e(Za,NNo),e(Za,Qfe),e(Qfe,jNo),e(Za,DNo),e(Za,Wfe),e(Wfe,GNo),e(Za,ONo),e(Za,Hfe),e(Hfe,VNo),e(Za,XNo),e(He,zNo),e(He,R),e(R,z6),e(z6,Ufe),e(Ufe,QNo),e(z6,WNo),e(z6,iG),e(iG,HNo),e(z6,UNo),e(R,JNo),e(R,Q6),e(Q6,Jfe),e(Jfe,YNo),e(Q6,KNo),e(Q6,dG),e(dG,ZNo),e(Q6,ejo),e(R,ojo),e(R,W6),e(W6,Yfe),e(Yfe,rjo),e(W6,tjo),e(W6,cG),e(cG,ajo),e(W6,njo),e(R,sjo),e(R,H6),e(H6,Kfe),e(Kfe,ljo),e(H6,ijo),e(H6,fG),e(fG,djo),e(H6,cjo),e(R,fjo),e(R,U6),e(U6,Zfe),e(Zfe,mjo),e(U6,gjo),e(U6,mG),e(mG,hjo),e(U6,pjo),e(R,_jo),e(R,J6),e(J6,eme),e(eme,ujo),e(J6,bjo),e(J6,gG),e(gG,vjo),e(J6,Fjo),e(R,Tjo),e(R,Y6),e(Y6,ome),e(ome,Mjo),e(Y6,Ejo),e(Y6,hG),e(hG,Cjo),e(Y6,wjo),e(R,Ajo),e(R,K6),e(K6,rme),e(rme,yjo),e(K6,Ljo),e(K6,pG),e(pG,xjo),e(K6,kjo),e(R,Sjo),e(R,Z6),e(Z6,tme),e(tme,Rjo),e(Z6,Bjo),e(Z6,_G),e(_G,Pjo),e(Z6,$jo),e(R,Ijo),e(R,ev),e(ev,ame),e(ame,qjo),e(ev,Njo),e(ev,uG),e(uG,jjo),e(ev,Djo),e(R,Gjo),e(R,ov),e(ov,nme),e(nme,Ojo),e(ov,Vjo),e(ov,bG),e(bG,Xjo),e(ov,zjo),e(R,Qjo),e(R,rv),e(rv,sme),e(sme,Wjo),e(rv,Hjo),e(rv,vG),e(vG,Ujo),e(rv,Jjo),e(R,Yjo),e(R,tv),e(tv,lme),e(lme,Kjo),e(tv,Zjo),e(tv,FG),e(FG,eDo),e(tv,oDo),e(R,rDo),e(R,av),e(av,ime),e(ime,tDo),e(av,aDo),e(av,TG),e(TG,nDo),e(av,sDo),e(R,lDo),e(R,nv),e(nv,dme),e(dme,iDo),e(nv,dDo),e(nv,MG),e(MG,cDo),e(nv,fDo),e(R,mDo),e(R,sv),e(sv,cme),e(cme,gDo),e(sv,hDo),e(sv,EG),e(EG,pDo),e(sv,_Do),e(R,uDo),e(R,lv),e(lv,fme),e(fme,bDo),e(lv,vDo),e(lv,CG),e(CG,FDo),e(lv,TDo),e(R,MDo),e(R,iv),e(iv,mme),e(mme,EDo),e(iv,CDo),e(iv,wG),e(wG,wDo),e(iv,ADo),e(R,yDo),e(R,dv),e(dv,gme),e(gme,LDo),e(dv,xDo),e(dv,AG),e(AG,kDo),e(dv,SDo),e(R,RDo),e(R,cv),e(cv,hme),e(hme,BDo),e(cv,PDo),e(cv,yG),e(yG,$Do),e(cv,IDo),e(R,qDo),e(R,fv),e(fv,pme),e(pme,NDo),e(fv,jDo),e(fv,LG),e(LG,DDo),e(fv,GDo),e(R,ODo),e(R,mv),e(mv,_me),e(_me,VDo),e(mv,XDo),e(mv,xG),e(xG,zDo),e(mv,QDo),e(R,WDo),e(R,gv),e(gv,ume),e(ume,HDo),e(gv,UDo),e(gv,kG),e(kG,JDo),e(gv,YDo),e(R,KDo),e(R,hv),e(hv,bme),e(bme,ZDo),e(hv,eGo),e(hv,SG),e(SG,oGo),e(hv,rGo),e(R,tGo),e(R,pv),e(pv,vme),e(vme,aGo),e(pv,nGo),e(pv,RG),e(RG,sGo),e(pv,lGo),e(R,iGo),e(R,_v),e(_v,Fme),e(Fme,dGo),e(_v,cGo),e(_v,BG),e(BG,fGo),e(_v,mGo),e(R,gGo),e(R,uv),e(uv,Tme),e(Tme,hGo),e(uv,pGo),e(uv,PG),e(PG,_Go),e(uv,uGo),e(R,bGo),e(R,bv),e(bv,Mme),e(Mme,vGo),e(bv,FGo),e(bv,$G),e($G,TGo),e(bv,MGo),e(R,EGo),e(R,vv),e(vv,Eme),e(Eme,CGo),e(vv,wGo),e(vv,IG),e(IG,AGo),e(vv,yGo),e(R,LGo),e(R,Fv),e(Fv,Cme),e(Cme,xGo),e(Fv,kGo),e(Fv,qG),e(qG,SGo),e(Fv,RGo),e(R,BGo),e(R,Tv),e(Tv,wme),e(wme,PGo),e(Tv,$Go),e(Tv,NG),e(NG,IGo),e(Tv,qGo),e(R,NGo),e(R,Mv),e(Mv,Ame),e(Ame,jGo),e(Mv,DGo),e(Mv,jG),e(jG,GGo),e(Mv,OGo),e(R,VGo),e(R,Ev),e(Ev,yme),e(yme,XGo),e(Ev,zGo),e(Ev,DG),e(DG,QGo),e(Ev,WGo),e(R,HGo),e(R,Cv),e(Cv,Lme),e(Lme,UGo),e(Cv,JGo),e(Cv,GG),e(GG,YGo),e(Cv,KGo),e(R,ZGo),e(R,wv),e(wv,xme),e(xme,eOo),e(wv,oOo),e(wv,OG),e(OG,rOo),e(wv,tOo),e(R,aOo),e(R,Av),e(Av,kme),e(kme,nOo),e(Av,sOo),e(Av,VG),e(VG,lOo),e(Av,iOo),e(R,dOo),e(R,yv),e(yv,Sme),e(Sme,cOo),e(yv,fOo),e(yv,XG),e(XG,mOo),e(yv,gOo),e(R,hOo),e(R,Lv),e(Lv,Rme),e(Rme,pOo),e(Lv,_Oo),e(Lv,zG),e(zG,uOo),e(Lv,bOo),e(R,vOo),e(R,xv),e(xv,Bme),e(Bme,FOo),e(xv,TOo),e(xv,QG),e(QG,MOo),e(xv,EOo),e(He,COo),e(He,kv),e(kv,wOo),e(kv,Pme),e(Pme,AOo),e(kv,yOo),e(kv,$me),e($me,LOo),e(He,xOo),e(He,Ime),e(Ime,kOo),e(He,SOo),g(HC,He,null),b(c,f$e,u),b(c,Id,u),e(Id,Sv),e(Sv,qme),g(UC,qme,null),e(Id,ROo),e(Id,Nme),e(Nme,BOo),b(c,m$e,u),b(c,sr,u),g(JC,sr,null),e(sr,POo),e(sr,qd),e(qd,$Oo),e(qd,WG),e(WG,IOo),e(qd,qOo),e(qd,HG),e(HG,NOo),e(qd,jOo),e(sr,DOo),e(sr,YC),e(YC,GOo),e(YC,jme),e(jme,OOo),e(YC,VOo),e(sr,XOo),e(sr,et),g(KC,et,null),e(et,zOo),e(et,Dme),e(Dme,QOo),e(et,WOo),e(et,Nd),e(Nd,HOo),e(Nd,Gme),e(Gme,UOo),e(Nd,JOo),e(Nd,UG),e(UG,YOo),e(Nd,KOo),e(et,ZOo),e(et,Ome),e(Ome,eVo),e(et,oVo),g(ZC,et,null),e(sr,rVo),e(sr,Ue),g(ew,Ue,null),e(Ue,tVo),e(Ue,Vme),e(Vme,aVo),e(Ue,nVo),e(Ue,en),e(en,sVo),e(en,Xme),e(Xme,lVo),e(en,iVo),e(en,zme),e(zme,dVo),e(en,cVo),e(en,Qme),e(Qme,fVo),e(en,mVo),e(Ue,gVo),e(Ue,Wme),e(Wme,Rv),e(Rv,Hme),e(Hme,hVo),e(Rv,pVo),e(Rv,JG),e(JG,_Vo),e(Rv,uVo),e(Ue,bVo),e(Ue,Bv),e(Bv,vVo),e(Bv,Ume),e(Ume,FVo),e(Bv,TVo),e(Bv,Jme),e(Jme,MVo),e(Ue,EVo),e(Ue,Yme),e(Yme,CVo),e(Ue,wVo),g(ow,Ue,null),b(c,g$e,u),b(c,jd,u),e(jd,Pv),e(Pv,Kme),g(rw,Kme,null),e(jd,AVo),e(jd,Zme),e(Zme,yVo),b(c,h$e,u),b(c,lr,u),g(tw,lr,null),e(lr,LVo),e(lr,Dd),e(Dd,xVo),e(Dd,YG),e(YG,kVo),e(Dd,SVo),e(Dd,KG),e(KG,RVo),e(Dd,BVo),e(lr,PVo),e(lr,aw),e(aw,$Vo),e(aw,ege),e(ege,IVo),e(aw,qVo),e(lr,NVo),e(lr,ot),g(nw,ot,null),e(ot,jVo),e(ot,oge),e(oge,DVo),e(ot,GVo),e(ot,Gd),e(Gd,OVo),e(Gd,rge),e(rge,VVo),e(Gd,XVo),e(Gd,ZG),e(ZG,zVo),e(Gd,QVo),e(ot,WVo),e(ot,tge),e(tge,HVo),e(ot,UVo),g(sw,ot,null),e(lr,JVo),e(lr,Je),g(lw,Je,null),e(Je,YVo),e(Je,age),e(age,KVo),e(Je,ZVo),e(Je,on),e(on,eXo),e(on,nge),e(nge,oXo),e(on,rXo),e(on,sge),e(sge,tXo),e(on,aXo),e(on,lge),e(lge,nXo),e(on,sXo),e(Je,lXo),e(Je,ce),e(ce,$v),e($v,ige),e(ige,iXo),e($v,dXo),e($v,eO),e(eO,cXo),e($v,fXo),e(ce,mXo),e(ce,Iv),e(Iv,dge),e(dge,gXo),e(Iv,hXo),e(Iv,oO),e(oO,pXo),e(Iv,_Xo),e(ce,uXo),e(ce,qv),e(qv,cge),e(cge,bXo),e(qv,vXo),e(qv,rO),e(rO,FXo),e(qv,TXo),e(ce,MXo),e(ce,Js),e(Js,fge),e(fge,EXo),e(Js,CXo),e(Js,tO),e(tO,wXo),e(Js,AXo),e(Js,aO),e(aO,yXo),e(Js,LXo),e(ce,xXo),e(ce,Nv),e(Nv,mge),e(mge,kXo),e(Nv,SXo),e(Nv,nO),e(nO,RXo),e(Nv,BXo),e(ce,PXo),e(ce,ma),e(ma,gge),e(gge,$Xo),e(ma,IXo),e(ma,sO),e(sO,qXo),e(ma,NXo),e(ma,lO),e(lO,jXo),e(ma,DXo),e(ma,iO),e(iO,GXo),e(ma,OXo),e(ce,VXo),e(ce,jv),e(jv,hge),e(hge,XXo),e(jv,zXo),e(jv,dO),e(dO,QXo),e(jv,WXo),e(ce,HXo),e(ce,Dv),e(Dv,pge),e(pge,UXo),e(Dv,JXo),e(Dv,cO),e(cO,YXo),e(Dv,KXo),e(ce,ZXo),e(ce,Gv),e(Gv,_ge),e(_ge,ezo),e(Gv,ozo),e(Gv,fO),e(fO,rzo),e(Gv,tzo),e(ce,azo),e(ce,Ov),e(Ov,uge),e(uge,nzo),e(Ov,szo),e(Ov,mO),e(mO,lzo),e(Ov,izo),e(ce,dzo),e(ce,Vv),e(Vv,bge),e(bge,czo),e(Vv,fzo),e(Vv,gO),e(gO,mzo),e(Vv,gzo),e(ce,hzo),e(ce,Xv),e(Xv,vge),e(vge,pzo),e(Xv,_zo),e(Xv,hO),e(hO,uzo),e(Xv,bzo),e(ce,vzo),e(ce,zv),e(zv,Fge),e(Fge,Fzo),e(zv,Tzo),e(zv,pO),e(pO,Mzo),e(zv,Ezo),e(Je,Czo),e(Je,Qv),e(Qv,wzo),e(Qv,Tge),e(Tge,Azo),e(Qv,yzo),e(Qv,Mge),e(Mge,Lzo),e(Je,xzo),e(Je,Ege),e(Ege,kzo),e(Je,Szo),g(iw,Je,null),b(c,p$e,u),b(c,Od,u),e(Od,Wv),e(Wv,Cge),g(dw,Cge,null),e(Od,Rzo),e(Od,wge),e(wge,Bzo),b(c,_$e,u),b(c,ir,u),g(cw,ir,null),e(ir,Pzo),e(ir,Vd),e(Vd,$zo),e(Vd,_O),e(_O,Izo),e(Vd,qzo),e(Vd,uO),e(uO,Nzo),e(Vd,jzo),e(ir,Dzo),e(ir,fw),e(fw,Gzo),e(fw,Age),e(Age,Ozo),e(fw,Vzo),e(ir,Xzo),e(ir,rt),g(mw,rt,null),e(rt,zzo),e(rt,yge),e(yge,Qzo),e(rt,Wzo),e(rt,Xd),e(Xd,Hzo),e(Xd,Lge),e(Lge,Uzo),e(Xd,Jzo),e(Xd,bO),e(bO,Yzo),e(Xd,Kzo),e(rt,Zzo),e(rt,xge),e(xge,eQo),e(rt,oQo),g(gw,rt,null),e(ir,rQo),e(ir,Ye),g(hw,Ye,null),e(Ye,tQo),e(Ye,kge),e(kge,aQo),e(Ye,nQo),e(Ye,rn),e(rn,sQo),e(rn,Sge),e(Sge,lQo),e(rn,iQo),e(rn,Rge),e(Rge,dQo),e(rn,cQo),e(rn,Bge),e(Bge,fQo),e(rn,mQo),e(Ye,gQo),e(Ye,Pge),e(Pge,Hv),e(Hv,$ge),e($ge,hQo),e(Hv,pQo),e(Hv,vO),e(vO,_Qo),e(Hv,uQo),e(Ye,bQo),e(Ye,Uv),e(Uv,vQo),e(Uv,Ige),e(Ige,FQo),e(Uv,TQo),e(Uv,qge),e(qge,MQo),e(Ye,EQo),e(Ye,Nge),e(Nge,CQo),e(Ye,wQo),g(pw,Ye,null),b(c,u$e,u),b(c,zd,u),e(zd,Jv),e(Jv,jge),g(_w,jge,null),e(zd,AQo),e(zd,Dge),e(Dge,yQo),b(c,b$e,u),b(c,dr,u),g(uw,dr,null),e(dr,LQo),e(dr,Qd),e(Qd,xQo),e(Qd,FO),e(FO,kQo),e(Qd,SQo),e(Qd,TO),e(TO,RQo),e(Qd,BQo),e(dr,PQo),e(dr,bw),e(bw,$Qo),e(bw,Gge),e(Gge,IQo),e(bw,qQo),e(dr,NQo),e(dr,tt),g(vw,tt,null),e(tt,jQo),e(tt,Oge),e(Oge,DQo),e(tt,GQo),e(tt,Wd),e(Wd,OQo),e(Wd,Vge),e(Vge,VQo),e(Wd,XQo),e(Wd,MO),e(MO,zQo),e(Wd,QQo),e(tt,WQo),e(tt,Xge),e(Xge,HQo),e(tt,UQo),g(Fw,tt,null),e(dr,JQo),e(dr,Ke),g(Tw,Ke,null),e(Ke,YQo),e(Ke,zge),e(zge,KQo),e(Ke,ZQo),e(Ke,tn),e(tn,eWo),e(tn,Qge),e(Qge,oWo),e(tn,rWo),e(tn,Wge),e(Wge,tWo),e(tn,aWo),e(tn,Hge),e(Hge,nWo),e(tn,sWo),e(Ke,lWo),e(Ke,Be),e(Be,Yv),e(Yv,Uge),e(Uge,iWo),e(Yv,dWo),e(Yv,EO),e(EO,cWo),e(Yv,fWo),e(Be,mWo),e(Be,Kv),e(Kv,Jge),e(Jge,gWo),e(Kv,hWo),e(Kv,CO),e(CO,pWo),e(Kv,_Wo),e(Be,uWo),e(Be,Zv),e(Zv,Yge),e(Yge,bWo),e(Zv,vWo),e(Zv,wO),e(wO,FWo),e(Zv,TWo),e(Be,MWo),e(Be,eF),e(eF,Kge),e(Kge,EWo),e(eF,CWo),e(eF,AO),e(AO,wWo),e(eF,AWo),e(Be,yWo),e(Be,oF),e(oF,Zge),e(Zge,LWo),e(oF,xWo),e(oF,yO),e(yO,kWo),e(oF,SWo),e(Be,RWo),e(Be,rF),e(rF,ehe),e(ehe,BWo),e(rF,PWo),e(rF,LO),e(LO,$Wo),e(rF,IWo),e(Be,qWo),e(Be,tF),e(tF,ohe),e(ohe,NWo),e(tF,jWo),e(tF,xO),e(xO,DWo),e(tF,GWo),e(Be,OWo),e(Be,aF),e(aF,rhe),e(rhe,VWo),e(aF,XWo),e(aF,kO),e(kO,zWo),e(aF,QWo),e(Ke,WWo),e(Ke,nF),e(nF,HWo),e(nF,the),e(the,UWo),e(nF,JWo),e(nF,ahe),e(ahe,YWo),e(Ke,KWo),e(Ke,nhe),e(nhe,ZWo),e(Ke,eHo),g(Mw,Ke,null),b(c,v$e,u),b(c,Hd,u),e(Hd,sF),e(sF,she),g(Ew,she,null),e(Hd,oHo),e(Hd,lhe),e(lhe,rHo),b(c,F$e,u),b(c,cr,u),g(Cw,cr,null),e(cr,tHo),e(cr,Ud),e(Ud,aHo),e(Ud,SO),e(SO,nHo),e(Ud,sHo),e(Ud,RO),e(RO,lHo),e(Ud,iHo),e(cr,dHo),e(cr,ww),e(ww,cHo),e(ww,ihe),e(ihe,fHo),e(ww,mHo),e(cr,gHo),e(cr,at),g(Aw,at,null),e(at,hHo),e(at,dhe),e(dhe,pHo),e(at,_Ho),e(at,Jd),e(Jd,uHo),e(Jd,che),e(che,bHo),e(Jd,vHo),e(Jd,BO),e(BO,FHo),e(Jd,THo),e(at,MHo),e(at,fhe),e(fhe,EHo),e(at,CHo),g(yw,at,null),e(cr,wHo),e(cr,Ze),g(Lw,Ze,null),e(Ze,AHo),e(Ze,mhe),e(mhe,yHo),e(Ze,LHo),e(Ze,an),e(an,xHo),e(an,ghe),e(ghe,kHo),e(an,SHo),e(an,hhe),e(hhe,RHo),e(an,BHo),e(an,phe),e(phe,PHo),e(an,$Ho),e(Ze,IHo),e(Ze,nn),e(nn,lF),e(lF,_he),e(_he,qHo),e(lF,NHo),e(lF,PO),e(PO,jHo),e(lF,DHo),e(nn,GHo),e(nn,iF),e(iF,uhe),e(uhe,OHo),e(iF,VHo),e(iF,$O),e($O,XHo),e(iF,zHo),e(nn,QHo),e(nn,dF),e(dF,bhe),e(bhe,WHo),e(dF,HHo),e(dF,IO),e(IO,UHo),e(dF,JHo),e(nn,YHo),e(nn,cF),e(cF,vhe),e(vhe,KHo),e(cF,ZHo),e(cF,qO),e(qO,eUo),e(cF,oUo),e(Ze,rUo),e(Ze,fF),e(fF,tUo),e(fF,Fhe),e(Fhe,aUo),e(fF,nUo),e(fF,The),e(The,sUo),e(Ze,lUo),e(Ze,Mhe),e(Mhe,iUo),e(Ze,dUo),g(xw,Ze,null),b(c,T$e,u),b(c,Yd,u),e(Yd,mF),e(mF,Ehe),g(kw,Ehe,null),e(Yd,cUo),e(Yd,Che),e(Che,fUo),b(c,M$e,u),b(c,fr,u),g(Sw,fr,null),e(fr,mUo),e(fr,Kd),e(Kd,gUo),e(Kd,NO),e(NO,hUo),e(Kd,pUo),e(Kd,jO),e(jO,_Uo),e(Kd,uUo),e(fr,bUo),e(fr,Rw),e(Rw,vUo),e(Rw,whe),e(whe,FUo),e(Rw,TUo),e(fr,MUo),e(fr,nt),g(Bw,nt,null),e(nt,EUo),e(nt,Ahe),e(Ahe,CUo),e(nt,wUo),e(nt,Zd),e(Zd,AUo),e(Zd,yhe),e(yhe,yUo),e(Zd,LUo),e(Zd,DO),e(DO,xUo),e(Zd,kUo),e(nt,SUo),e(nt,Lhe),e(Lhe,RUo),e(nt,BUo),g(Pw,nt,null),e(fr,PUo),e(fr,eo),g($w,eo,null),e(eo,$Uo),e(eo,xhe),e(xhe,IUo),e(eo,qUo),e(eo,sn),e(sn,NUo),e(sn,khe),e(khe,jUo),e(sn,DUo),e(sn,She),e(She,GUo),e(sn,OUo),e(sn,Rhe),e(Rhe,VUo),e(sn,XUo),e(eo,zUo),e(eo,Pe),e(Pe,gF),e(gF,Bhe),e(Bhe,QUo),e(gF,WUo),e(gF,GO),e(GO,HUo),e(gF,UUo),e(Pe,JUo),e(Pe,hF),e(hF,Phe),e(Phe,YUo),e(hF,KUo),e(hF,OO),e(OO,ZUo),e(hF,eJo),e(Pe,oJo),e(Pe,pF),e(pF,$he),e($he,rJo),e(pF,tJo),e(pF,VO),e(VO,aJo),e(pF,nJo),e(Pe,sJo),e(Pe,_F),e(_F,Ihe),e(Ihe,lJo),e(_F,iJo),e(_F,XO),e(XO,dJo),e(_F,cJo),e(Pe,fJo),e(Pe,uF),e(uF,qhe),e(qhe,mJo),e(uF,gJo),e(uF,zO),e(zO,hJo),e(uF,pJo),e(Pe,_Jo),e(Pe,bF),e(bF,Nhe),e(Nhe,uJo),e(bF,bJo),e(bF,QO),e(QO,vJo),e(bF,FJo),e(Pe,TJo),e(Pe,vF),e(vF,jhe),e(jhe,MJo),e(vF,EJo),e(vF,WO),e(WO,CJo),e(vF,wJo),e(Pe,AJo),e(Pe,FF),e(FF,Dhe),e(Dhe,yJo),e(FF,LJo),e(FF,HO),e(HO,xJo),e(FF,kJo),e(eo,SJo),e(eo,TF),e(TF,RJo),e(TF,Ghe),e(Ghe,BJo),e(TF,PJo),e(TF,Ohe),e(Ohe,$Jo),e(eo,IJo),e(eo,Vhe),e(Vhe,qJo),e(eo,NJo),g(Iw,eo,null),b(c,E$e,u),b(c,ec,u),e(ec,MF),e(MF,Xhe),g(qw,Xhe,null),e(ec,jJo),e(ec,zhe),e(zhe,DJo),b(c,C$e,u),b(c,mr,u),g(Nw,mr,null),e(mr,GJo),e(mr,oc),e(oc,OJo),e(oc,UO),e(UO,VJo),e(oc,XJo),e(oc,JO),e(JO,zJo),e(oc,QJo),e(mr,WJo),e(mr,jw),e(jw,HJo),e(jw,Qhe),e(Qhe,UJo),e(jw,JJo),e(mr,YJo),e(mr,st),g(Dw,st,null),e(st,KJo),e(st,Whe),e(Whe,ZJo),e(st,eYo),e(st,rc),e(rc,oYo),e(rc,Hhe),e(Hhe,rYo),e(rc,tYo),e(rc,YO),e(YO,aYo),e(rc,nYo),e(st,sYo),e(st,Uhe),e(Uhe,lYo),e(st,iYo),g(Gw,st,null),e(mr,dYo),e(mr,oo),g(Ow,oo,null),e(oo,cYo),e(oo,Jhe),e(Jhe,fYo),e(oo,mYo),e(oo,ln),e(ln,gYo),e(ln,Yhe),e(Yhe,hYo),e(ln,pYo),e(ln,Khe),e(Khe,_Yo),e(ln,uYo),e(ln,Zhe),e(Zhe,bYo),e(ln,vYo),e(oo,FYo),e(oo,Vw),e(Vw,EF),e(EF,epe),e(epe,TYo),e(EF,MYo),e(EF,KO),e(KO,EYo),e(EF,CYo),e(Vw,wYo),e(Vw,CF),e(CF,ope),e(ope,AYo),e(CF,yYo),e(CF,ZO),e(ZO,LYo),e(CF,xYo),e(oo,kYo),e(oo,wF),e(wF,SYo),e(wF,rpe),e(rpe,RYo),e(wF,BYo),e(wF,tpe),e(tpe,PYo),e(oo,$Yo),e(oo,ape),e(ape,IYo),e(oo,qYo),g(Xw,oo,null),b(c,w$e,u),b(c,tc,u),e(tc,AF),e(AF,npe),g(zw,npe,null),e(tc,NYo),e(tc,spe),e(spe,jYo),b(c,A$e,u),b(c,gr,u),g(Qw,gr,null),e(gr,DYo),e(gr,ac),e(ac,GYo),e(ac,eV),e(eV,OYo),e(ac,VYo),e(ac,oV),e(oV,XYo),e(ac,zYo),e(gr,QYo),e(gr,Ww),e(Ww,WYo),e(Ww,lpe),e(lpe,HYo),e(Ww,UYo),e(gr,JYo),e(gr,lt),g(Hw,lt,null),e(lt,YYo),e(lt,ipe),e(ipe,KYo),e(lt,ZYo),e(lt,nc),e(nc,eKo),e(nc,dpe),e(dpe,oKo),e(nc,rKo),e(nc,rV),e(rV,tKo),e(nc,aKo),e(lt,nKo),e(lt,cpe),e(cpe,sKo),e(lt,lKo),g(Uw,lt,null),e(gr,iKo),e(gr,ro),g(Jw,ro,null),e(ro,dKo),e(ro,fpe),e(fpe,cKo),e(ro,fKo),e(ro,dn),e(dn,mKo),e(dn,mpe),e(mpe,gKo),e(dn,hKo),e(dn,gpe),e(gpe,pKo),e(dn,_Ko),e(dn,hpe),e(hpe,uKo),e(dn,bKo),e(ro,vKo),e(ro,cn),e(cn,yF),e(yF,ppe),e(ppe,FKo),e(yF,TKo),e(yF,tV),e(tV,MKo),e(yF,EKo),e(cn,CKo),e(cn,LF),e(LF,_pe),e(_pe,wKo),e(LF,AKo),e(LF,aV),e(aV,yKo),e(LF,LKo),e(cn,xKo),e(cn,xF),e(xF,upe),e(upe,kKo),e(xF,SKo),e(xF,nV),e(nV,RKo),e(xF,BKo),e(cn,PKo),e(cn,kF),e(kF,bpe),e(bpe,$Ko),e(kF,IKo),e(kF,sV),e(sV,qKo),e(kF,NKo),e(ro,jKo),e(ro,SF),e(SF,DKo),e(SF,vpe),e(vpe,GKo),e(SF,OKo),e(SF,Fpe),e(Fpe,VKo),e(ro,XKo),e(ro,Tpe),e(Tpe,zKo),e(ro,QKo),g(Yw,ro,null),b(c,y$e,u),b(c,sc,u),e(sc,RF),e(RF,Mpe),g(Kw,Mpe,null),e(sc,WKo),e(sc,Epe),e(Epe,HKo),b(c,L$e,u),b(c,hr,u),g(Zw,hr,null),e(hr,UKo),e(hr,lc),e(lc,JKo),e(lc,lV),e(lV,YKo),e(lc,KKo),e(lc,iV),e(iV,ZKo),e(lc,eZo),e(hr,oZo),e(hr,e0),e(e0,rZo),e(e0,Cpe),e(Cpe,tZo),e(e0,aZo),e(hr,nZo),e(hr,it),g(o0,it,null),e(it,sZo),e(it,wpe),e(wpe,lZo),e(it,iZo),e(it,ic),e(ic,dZo),e(ic,Ape),e(Ape,cZo),e(ic,fZo),e(ic,dV),e(dV,mZo),e(ic,gZo),e(it,hZo),e(it,ype),e(ype,pZo),e(it,_Zo),g(r0,it,null),e(hr,uZo),e(hr,to),g(t0,to,null),e(to,bZo),e(to,Lpe),e(Lpe,vZo),e(to,FZo),e(to,fn),e(fn,TZo),e(fn,xpe),e(xpe,MZo),e(fn,EZo),e(fn,kpe),e(kpe,CZo),e(fn,wZo),e(fn,Spe),e(Spe,AZo),e(fn,yZo),e(to,LZo),e(to,dc),e(dc,BF),e(BF,Rpe),e(Rpe,xZo),e(BF,kZo),e(BF,cV),e(cV,SZo),e(BF,RZo),e(dc,BZo),e(dc,PF),e(PF,Bpe),e(Bpe,PZo),e(PF,$Zo),e(PF,fV),e(fV,IZo),e(PF,qZo),e(dc,NZo),e(dc,$F),e($F,Ppe),e(Ppe,jZo),e($F,DZo),e($F,mV),e(mV,GZo),e($F,OZo),e(to,VZo),e(to,IF),e(IF,XZo),e(IF,$pe),e($pe,zZo),e(IF,QZo),e(IF,Ipe),e(Ipe,WZo),e(to,HZo),e(to,qpe),e(qpe,UZo),e(to,JZo),g(a0,to,null),b(c,x$e,u),b(c,cc,u),e(cc,qF),e(qF,Npe),g(n0,Npe,null),e(cc,YZo),e(cc,jpe),e(jpe,KZo),b(c,k$e,u),b(c,pr,u),g(s0,pr,null),e(pr,ZZo),e(pr,fc),e(fc,eer),e(fc,gV),e(gV,oer),e(fc,rer),e(fc,hV),e(hV,ter),e(fc,aer),e(pr,ner),e(pr,l0),e(l0,ser),e(l0,Dpe),e(Dpe,ler),e(l0,ier),e(pr,der),e(pr,dt),g(i0,dt,null),e(dt,cer),e(dt,Gpe),e(Gpe,fer),e(dt,mer),e(dt,mc),e(mc,ger),e(mc,Ope),e(Ope,her),e(mc,per),e(mc,pV),e(pV,_er),e(mc,uer),e(dt,ber),e(dt,Vpe),e(Vpe,ver),e(dt,Fer),g(d0,dt,null),e(pr,Ter),e(pr,ao),g(c0,ao,null),e(ao,Mer),e(ao,Xpe),e(Xpe,Eer),e(ao,Cer),e(ao,mn),e(mn,wer),e(mn,zpe),e(zpe,Aer),e(mn,yer),e(mn,Qpe),e(Qpe,Ler),e(mn,xer),e(mn,Wpe),e(Wpe,ker),e(mn,Ser),e(ao,Rer),e(ao,Hpe),e(Hpe,NF),e(NF,Upe),e(Upe,Ber),e(NF,Per),e(NF,_V),e(_V,$er),e(NF,Ier),e(ao,qer),e(ao,jF),e(jF,Ner),e(jF,Jpe),e(Jpe,jer),e(jF,Der),e(jF,Ype),e(Ype,Ger),e(ao,Oer),e(ao,Kpe),e(Kpe,Ver),e(ao,Xer),g(f0,ao,null),b(c,S$e,u),b(c,gc,u),e(gc,DF),e(DF,Zpe),g(m0,Zpe,null),e(gc,zer),e(gc,e_e),e(e_e,Qer),b(c,R$e,u),b(c,_r,u),g(g0,_r,null),e(_r,Wer),e(_r,hc),e(hc,Her),e(hc,uV),e(uV,Uer),e(hc,Jer),e(hc,bV),e(bV,Yer),e(hc,Ker),e(_r,Zer),e(_r,h0),e(h0,eor),e(h0,o_e),e(o_e,oor),e(h0,ror),e(_r,tor),e(_r,ct),g(p0,ct,null),e(ct,aor),e(ct,r_e),e(r_e,nor),e(ct,sor),e(ct,pc),e(pc,lor),e(pc,t_e),e(t_e,ior),e(pc,dor),e(pc,vV),e(vV,cor),e(pc,mor),e(ct,gor),e(ct,a_e),e(a_e,hor),e(ct,por),g(_0,ct,null),e(_r,_or),e(_r,no),g(u0,no,null),e(no,uor),e(no,n_e),e(n_e,bor),e(no,vor),e(no,gn),e(gn,For),e(gn,s_e),e(s_e,Tor),e(gn,Mor),e(gn,l_e),e(l_e,Eor),e(gn,Cor),e(gn,i_e),e(i_e,wor),e(gn,Aor),e(no,yor),e(no,d_e),e(d_e,GF),e(GF,c_e),e(c_e,Lor),e(GF,xor),e(GF,FV),e(FV,kor),e(GF,Sor),e(no,Ror),e(no,OF),e(OF,Bor),e(OF,f_e),e(f_e,Por),e(OF,$or),e(OF,m_e),e(m_e,Ior),e(no,qor),e(no,g_e),e(g_e,Nor),e(no,jor),g(b0,no,null),b(c,B$e,u),b(c,_c,u),e(_c,VF),e(VF,h_e),g(v0,h_e,null),e(_c,Dor),e(_c,p_e),e(p_e,Gor),b(c,P$e,u),b(c,ur,u),g(F0,ur,null),e(ur,Oor),e(ur,uc),e(uc,Vor),e(uc,TV),e(TV,Xor),e(uc,zor),e(uc,MV),e(MV,Qor),e(uc,Wor),e(ur,Hor),e(ur,T0),e(T0,Uor),e(T0,__e),e(__e,Jor),e(T0,Yor),e(ur,Kor),e(ur,ft),g(M0,ft,null),e(ft,Zor),e(ft,u_e),e(u_e,err),e(ft,orr),e(ft,bc),e(bc,rrr),e(bc,b_e),e(b_e,trr),e(bc,arr),e(bc,EV),e(EV,nrr),e(bc,srr),e(ft,lrr),e(ft,v_e),e(v_e,irr),e(ft,drr),g(E0,ft,null),e(ur,crr),e(ur,so),g(C0,so,null),e(so,frr),e(so,F_e),e(F_e,mrr),e(so,grr),e(so,hn),e(hn,hrr),e(hn,T_e),e(T_e,prr),e(hn,_rr),e(hn,M_e),e(M_e,urr),e(hn,brr),e(hn,E_e),e(E_e,vrr),e(hn,Frr),e(so,Trr),e(so,pn),e(pn,XF),e(XF,C_e),e(C_e,Mrr),e(XF,Err),e(XF,CV),e(CV,Crr),e(XF,wrr),e(pn,Arr),e(pn,zF),e(zF,w_e),e(w_e,yrr),e(zF,Lrr),e(zF,wV),e(wV,xrr),e(zF,krr),e(pn,Srr),e(pn,QF),e(QF,A_e),e(A_e,Rrr),e(QF,Brr),e(QF,AV),e(AV,Prr),e(QF,$rr),e(pn,Irr),e(pn,WF),e(WF,y_e),e(y_e,qrr),e(WF,Nrr),e(WF,yV),e(yV,jrr),e(WF,Drr),e(so,Grr),e(so,HF),e(HF,Orr),e(HF,L_e),e(L_e,Vrr),e(HF,Xrr),e(HF,x_e),e(x_e,zrr),e(so,Qrr),e(so,k_e),e(k_e,Wrr),e(so,Hrr),g(w0,so,null),b(c,$$e,u),b(c,vc,u),e(vc,UF),e(UF,S_e),g(A0,S_e,null),e(vc,Urr),e(vc,R_e),e(R_e,Jrr),b(c,I$e,u),b(c,br,u),g(y0,br,null),e(br,Yrr),e(br,Fc),e(Fc,Krr),e(Fc,LV),e(LV,Zrr),e(Fc,etr),e(Fc,xV),e(xV,otr),e(Fc,rtr),e(br,ttr),e(br,L0),e(L0,atr),e(L0,B_e),e(B_e,ntr),e(L0,str),e(br,ltr),e(br,mt),g(x0,mt,null),e(mt,itr),e(mt,P_e),e(P_e,dtr),e(mt,ctr),e(mt,Tc),e(Tc,ftr),e(Tc,$_e),e($_e,mtr),e(Tc,gtr),e(Tc,kV),e(kV,htr),e(Tc,ptr),e(mt,_tr),e(mt,I_e),e(I_e,utr),e(mt,btr),g(k0,mt,null),e(br,vtr),e(br,lo),g(S0,lo,null),e(lo,Ftr),e(lo,q_e),e(q_e,Ttr),e(lo,Mtr),e(lo,_n),e(_n,Etr),e(_n,N_e),e(N_e,Ctr),e(_n,wtr),e(_n,j_e),e(j_e,Atr),e(_n,ytr),e(_n,D_e),e(D_e,Ltr),e(_n,xtr),e(lo,ktr),e(lo,G_e),e(G_e,JF),e(JF,O_e),e(O_e,Str),e(JF,Rtr),e(JF,SV),e(SV,Btr),e(JF,Ptr),e(lo,$tr),e(lo,YF),e(YF,Itr),e(YF,V_e),e(V_e,qtr),e(YF,Ntr),e(YF,X_e),e(X_e,jtr),e(lo,Dtr),e(lo,z_e),e(z_e,Gtr),e(lo,Otr),g(R0,lo,null),b(c,q$e,u),b(c,Mc,u),e(Mc,KF),e(KF,Q_e),g(B0,Q_e,null),e(Mc,Vtr),e(Mc,W_e),e(W_e,Xtr),b(c,N$e,u),b(c,vr,u),g(P0,vr,null),e(vr,ztr),e(vr,Ec),e(Ec,Qtr),e(Ec,RV),e(RV,Wtr),e(Ec,Htr),e(Ec,BV),e(BV,Utr),e(Ec,Jtr),e(vr,Ytr),e(vr,$0),e($0,Ktr),e($0,H_e),e(H_e,Ztr),e($0,ear),e(vr,oar),e(vr,gt),g(I0,gt,null),e(gt,rar),e(gt,U_e),e(U_e,tar),e(gt,aar),e(gt,Cc),e(Cc,nar),e(Cc,J_e),e(J_e,sar),e(Cc,lar),e(Cc,PV),e(PV,iar),e(Cc,dar),e(gt,car),e(gt,Y_e),e(Y_e,far),e(gt,mar),g(q0,gt,null),e(vr,gar),e(vr,po),g(N0,po,null),e(po,har),e(po,K_e),e(K_e,par),e(po,_ar),e(po,un),e(un,uar),e(un,Z_e),e(Z_e,bar),e(un,Far),e(un,eue),e(eue,Tar),e(un,Mar),e(un,oue),e(oue,Ear),e(un,Car),e(po,war),e(po,x),e(x,ZF),e(ZF,rue),e(rue,Aar),e(ZF,yar),e(ZF,$V),e($V,Lar),e(ZF,xar),e(x,kar),e(x,eT),e(eT,tue),e(tue,Sar),e(eT,Rar),e(eT,IV),e(IV,Bar),e(eT,Par),e(x,$ar),e(x,oT),e(oT,aue),e(aue,Iar),e(oT,qar),e(oT,qV),e(qV,Nar),e(oT,jar),e(x,Dar),e(x,rT),e(rT,nue),e(nue,Gar),e(rT,Oar),e(rT,NV),e(NV,Var),e(rT,Xar),e(x,zar),e(x,tT),e(tT,sue),e(sue,Qar),e(tT,War),e(tT,jV),e(jV,Har),e(tT,Uar),e(x,Jar),e(x,aT),e(aT,lue),e(lue,Yar),e(aT,Kar),e(aT,DV),e(DV,Zar),e(aT,enr),e(x,onr),e(x,nT),e(nT,iue),e(iue,rnr),e(nT,tnr),e(nT,GV),e(GV,anr),e(nT,nnr),e(x,snr),e(x,sT),e(sT,due),e(due,lnr),e(sT,inr),e(sT,OV),e(OV,dnr),e(sT,cnr),e(x,fnr),e(x,lT),e(lT,cue),e(cue,mnr),e(lT,gnr),e(lT,VV),e(VV,hnr),e(lT,pnr),e(x,_nr),e(x,iT),e(iT,fue),e(fue,unr),e(iT,bnr),e(iT,XV),e(XV,vnr),e(iT,Fnr),e(x,Tnr),e(x,dT),e(dT,mue),e(mue,Mnr),e(dT,Enr),e(dT,zV),e(zV,Cnr),e(dT,wnr),e(x,Anr),e(x,cT),e(cT,gue),e(gue,ynr),e(cT,Lnr),e(cT,QV),e(QV,xnr),e(cT,knr),e(x,Snr),e(x,fT),e(fT,hue),e(hue,Rnr),e(fT,Bnr),e(fT,WV),e(WV,Pnr),e(fT,$nr),e(x,Inr),e(x,mT),e(mT,pue),e(pue,qnr),e(mT,Nnr),e(mT,HV),e(HV,jnr),e(mT,Dnr),e(x,Gnr),e(x,gT),e(gT,_ue),e(_ue,Onr),e(gT,Vnr),e(gT,UV),e(UV,Xnr),e(gT,znr),e(x,Qnr),e(x,hT),e(hT,uue),e(uue,Wnr),e(hT,Hnr),e(hT,JV),e(JV,Unr),e(hT,Jnr),e(x,Ynr),e(x,Ys),e(Ys,bue),e(bue,Knr),e(Ys,Znr),e(Ys,YV),e(YV,esr),e(Ys,osr),e(Ys,KV),e(KV,rsr),e(Ys,tsr),e(x,asr),e(x,pT),e(pT,vue),e(vue,nsr),e(pT,ssr),e(pT,ZV),e(ZV,lsr),e(pT,isr),e(x,dsr),e(x,_T),e(_T,Fue),e(Fue,csr),e(_T,fsr),e(_T,eX),e(eX,msr),e(_T,gsr),e(x,hsr),e(x,uT),e(uT,Tue),e(Tue,psr),e(uT,_sr),e(uT,oX),e(oX,usr),e(uT,bsr),e(x,vsr),e(x,bT),e(bT,Mue),e(Mue,Fsr),e(bT,Tsr),e(bT,rX),e(rX,Msr),e(bT,Esr),e(x,Csr),e(x,vT),e(vT,Eue),e(Eue,wsr),e(vT,Asr),e(vT,tX),e(tX,ysr),e(vT,Lsr),e(x,xsr),e(x,FT),e(FT,Cue),e(Cue,ksr),e(FT,Ssr),e(FT,aX),e(aX,Rsr),e(FT,Bsr),e(x,Psr),e(x,TT),e(TT,wue),e(wue,$sr),e(TT,Isr),e(TT,nX),e(nX,qsr),e(TT,Nsr),e(x,jsr),e(x,MT),e(MT,Aue),e(Aue,Dsr),e(MT,Gsr),e(MT,sX),e(sX,Osr),e(MT,Vsr),e(x,Xsr),e(x,ET),e(ET,yue),e(yue,zsr),e(ET,Qsr),e(ET,lX),e(lX,Wsr),e(ET,Hsr),e(x,Usr),e(x,CT),e(CT,Lue),e(Lue,Jsr),e(CT,Ysr),e(CT,iX),e(iX,Ksr),e(CT,Zsr),e(x,elr),e(x,wT),e(wT,xue),e(xue,olr),e(wT,rlr),e(wT,dX),e(dX,tlr),e(wT,alr),e(x,nlr),e(x,AT),e(AT,kue),e(kue,slr),e(AT,llr),e(AT,cX),e(cX,ilr),e(AT,dlr),e(x,clr),e(x,yT),e(yT,Sue),e(Sue,flr),e(yT,mlr),e(yT,fX),e(fX,glr),e(yT,hlr),e(x,plr),e(x,LT),e(LT,Rue),e(Rue,_lr),e(LT,ulr),e(LT,mX),e(mX,blr),e(LT,vlr),e(x,Flr),e(x,xT),e(xT,Bue),e(Bue,Tlr),e(xT,Mlr),e(xT,gX),e(gX,Elr),e(xT,Clr),e(x,wlr),e(x,kT),e(kT,Pue),e(Pue,Alr),e(kT,ylr),e(kT,hX),e(hX,Llr),e(kT,xlr),e(x,klr),e(x,ST),e(ST,$ue),e($ue,Slr),e(ST,Rlr),e(ST,pX),e(pX,Blr),e(ST,Plr),e(x,$lr),e(x,RT),e(RT,Iue),e(Iue,Ilr),e(RT,qlr),e(RT,_X),e(_X,Nlr),e(RT,jlr),e(x,Dlr),e(x,BT),e(BT,que),e(que,Glr),e(BT,Olr),e(BT,uX),e(uX,Vlr),e(BT,Xlr),e(x,zlr),e(x,PT),e(PT,Nue),e(Nue,Qlr),e(PT,Wlr),e(PT,bX),e(bX,Hlr),e(PT,Ulr),e(x,Jlr),e(x,$T),e($T,jue),e(jue,Ylr),e($T,Klr),e($T,vX),e(vX,Zlr),e($T,eir),e(x,oir),e(x,IT),e(IT,Due),e(Due,rir),e(IT,tir),e(IT,FX),e(FX,air),e(IT,nir),e(x,sir),e(x,qT),e(qT,Gue),e(Gue,lir),e(qT,iir),e(qT,TX),e(TX,dir),e(qT,cir),e(x,fir),e(x,NT),e(NT,Oue),e(Oue,mir),e(NT,gir),e(NT,MX),e(MX,hir),e(NT,pir),e(x,_ir),e(x,jT),e(jT,Vue),e(Vue,uir),e(jT,bir),e(jT,EX),e(EX,vir),e(jT,Fir),e(x,Tir),e(x,DT),e(DT,Xue),e(Xue,Mir),e(DT,Eir),e(DT,CX),e(CX,Cir),e(DT,wir),e(x,Air),e(x,GT),e(GT,zue),e(zue,yir),e(GT,Lir),e(GT,wX),e(wX,xir),e(GT,kir),e(po,Sir),e(po,Que),e(Que,Rir),e(po,Bir),g(j0,po,null),b(c,j$e,u),b(c,wc,u),e(wc,OT),e(OT,Wue),g(D0,Wue,null),e(wc,Pir),e(wc,Hue),e(Hue,$ir),b(c,D$e,u),b(c,Fr,u),g(G0,Fr,null),e(Fr,Iir),e(Fr,Ac),e(Ac,qir),e(Ac,AX),e(AX,Nir),e(Ac,jir),e(Ac,yX),e(yX,Dir),e(Ac,Gir),e(Fr,Oir),e(Fr,O0),e(O0,Vir),e(O0,Uue),e(Uue,Xir),e(O0,zir),e(Fr,Qir),e(Fr,ht),g(V0,ht,null),e(ht,Wir),e(ht,Jue),e(Jue,Hir),e(ht,Uir),e(ht,yc),e(yc,Jir),e(yc,Yue),e(Yue,Yir),e(yc,Kir),e(yc,LX),e(LX,Zir),e(yc,edr),e(ht,odr),e(ht,Kue),e(Kue,rdr),e(ht,tdr),g(X0,ht,null),e(Fr,adr),e(Fr,_o),g(z0,_o,null),e(_o,ndr),e(_o,Zue),e(Zue,sdr),e(_o,ldr),e(_o,bn),e(bn,idr),e(bn,e2e),e(e2e,ddr),e(bn,cdr),e(bn,o2e),e(o2e,fdr),e(bn,mdr),e(bn,r2e),e(r2e,gdr),e(bn,hdr),e(_o,pdr),e(_o,U),e(U,VT),e(VT,t2e),e(t2e,_dr),e(VT,udr),e(VT,xX),e(xX,bdr),e(VT,vdr),e(U,Fdr),e(U,XT),e(XT,a2e),e(a2e,Tdr),e(XT,Mdr),e(XT,kX),e(kX,Edr),e(XT,Cdr),e(U,wdr),e(U,zT),e(zT,n2e),e(n2e,Adr),e(zT,ydr),e(zT,SX),e(SX,Ldr),e(zT,xdr),e(U,kdr),e(U,QT),e(QT,s2e),e(s2e,Sdr),e(QT,Rdr),e(QT,RX),e(RX,Bdr),e(QT,Pdr),e(U,$dr),e(U,WT),e(WT,l2e),e(l2e,Idr),e(WT,qdr),e(WT,BX),e(BX,Ndr),e(WT,jdr),e(U,Ddr),e(U,HT),e(HT,i2e),e(i2e,Gdr),e(HT,Odr),e(HT,PX),e(PX,Vdr),e(HT,Xdr),e(U,zdr),e(U,UT),e(UT,d2e),e(d2e,Qdr),e(UT,Wdr),e(UT,$X),e($X,Hdr),e(UT,Udr),e(U,Jdr),e(U,JT),e(JT,c2e),e(c2e,Ydr),e(JT,Kdr),e(JT,IX),e(IX,Zdr),e(JT,ecr),e(U,ocr),e(U,YT),e(YT,f2e),e(f2e,rcr),e(YT,tcr),e(YT,qX),e(qX,acr),e(YT,ncr),e(U,scr),e(U,KT),e(KT,m2e),e(m2e,lcr),e(KT,icr),e(KT,NX),e(NX,dcr),e(KT,ccr),e(U,fcr),e(U,ZT),e(ZT,g2e),e(g2e,mcr),e(ZT,gcr),e(ZT,jX),e(jX,hcr),e(ZT,pcr),e(U,_cr),e(U,e7),e(e7,h2e),e(h2e,ucr),e(e7,bcr),e(e7,DX),e(DX,vcr),e(e7,Fcr),e(U,Tcr),e(U,o7),e(o7,p2e),e(p2e,Mcr),e(o7,Ecr),e(o7,GX),e(GX,Ccr),e(o7,wcr),e(U,Acr),e(U,r7),e(r7,_2e),e(_2e,ycr),e(r7,Lcr),e(r7,OX),e(OX,xcr),e(r7,kcr),e(U,Scr),e(U,t7),e(t7,u2e),e(u2e,Rcr),e(t7,Bcr),e(t7,VX),e(VX,Pcr),e(t7,$cr),e(U,Icr),e(U,a7),e(a7,b2e),e(b2e,qcr),e(a7,Ncr),e(a7,XX),e(XX,jcr),e(a7,Dcr),e(U,Gcr),e(U,n7),e(n7,v2e),e(v2e,Ocr),e(n7,Vcr),e(n7,zX),e(zX,Xcr),e(n7,zcr),e(U,Qcr),e(U,s7),e(s7,F2e),e(F2e,Wcr),e(s7,Hcr),e(s7,QX),e(QX,Ucr),e(s7,Jcr),e(U,Ycr),e(U,l7),e(l7,T2e),e(T2e,Kcr),e(l7,Zcr),e(l7,WX),e(WX,efr),e(l7,ofr),e(U,rfr),e(U,i7),e(i7,M2e),e(M2e,tfr),e(i7,afr),e(i7,HX),e(HX,nfr),e(i7,sfr),e(U,lfr),e(U,d7),e(d7,E2e),e(E2e,ifr),e(d7,dfr),e(d7,UX),e(UX,cfr),e(d7,ffr),e(U,mfr),e(U,c7),e(c7,C2e),e(C2e,gfr),e(c7,hfr),e(c7,JX),e(JX,pfr),e(c7,_fr),e(U,ufr),e(U,f7),e(f7,w2e),e(w2e,bfr),e(f7,vfr),e(f7,YX),e(YX,Ffr),e(f7,Tfr),e(_o,Mfr),e(_o,A2e),e(A2e,Efr),e(_o,Cfr),g(Q0,_o,null),b(c,G$e,u),b(c,Lc,u),e(Lc,m7),e(m7,y2e),g(W0,y2e,null),e(Lc,wfr),e(Lc,L2e),e(L2e,Afr),b(c,O$e,u),b(c,Tr,u),g(H0,Tr,null),e(Tr,yfr),e(Tr,xc),e(xc,Lfr),e(xc,KX),e(KX,xfr),e(xc,kfr),e(xc,ZX),e(ZX,Sfr),e(xc,Rfr),e(Tr,Bfr),e(Tr,U0),e(U0,Pfr),e(U0,x2e),e(x2e,$fr),e(U0,Ifr),e(Tr,qfr),e(Tr,pt),g(J0,pt,null),e(pt,Nfr),e(pt,k2e),e(k2e,jfr),e(pt,Dfr),e(pt,kc),e(kc,Gfr),e(kc,S2e),e(S2e,Ofr),e(kc,Vfr),e(kc,ez),e(ez,Xfr),e(kc,zfr),e(pt,Qfr),e(pt,R2e),e(R2e,Wfr),e(pt,Hfr),g(Y0,pt,null),e(Tr,Ufr),e(Tr,uo),g(K0,uo,null),e(uo,Jfr),e(uo,B2e),e(B2e,Yfr),e(uo,Kfr),e(uo,vn),e(vn,Zfr),e(vn,P2e),e(P2e,emr),e(vn,omr),e(vn,$2e),e($2e,rmr),e(vn,tmr),e(vn,I2e),e(I2e,amr),e(vn,nmr),e(uo,smr),e(uo,he),e(he,g7),e(g7,q2e),e(q2e,lmr),e(g7,imr),e(g7,oz),e(oz,dmr),e(g7,cmr),e(he,fmr),e(he,h7),e(h7,N2e),e(N2e,mmr),e(h7,gmr),e(h7,rz),e(rz,hmr),e(h7,pmr),e(he,_mr),e(he,p7),e(p7,j2e),e(j2e,umr),e(p7,bmr),e(p7,tz),e(tz,vmr),e(p7,Fmr),e(he,Tmr),e(he,_7),e(_7,D2e),e(D2e,Mmr),e(_7,Emr),e(_7,az),e(az,Cmr),e(_7,wmr),e(he,Amr),e(he,u7),e(u7,G2e),e(G2e,ymr),e(u7,Lmr),e(u7,nz),e(nz,xmr),e(u7,kmr),e(he,Smr),e(he,b7),e(b7,O2e),e(O2e,Rmr),e(b7,Bmr),e(b7,sz),e(sz,Pmr),e(b7,$mr),e(he,Imr),e(he,v7),e(v7,V2e),e(V2e,qmr),e(v7,Nmr),e(v7,lz),e(lz,jmr),e(v7,Dmr),e(he,Gmr),e(he,F7),e(F7,X2e),e(X2e,Omr),e(F7,Vmr),e(F7,iz),e(iz,Xmr),e(F7,zmr),e(he,Qmr),e(he,T7),e(T7,z2e),e(z2e,Wmr),e(T7,Hmr),e(T7,dz),e(dz,Umr),e(T7,Jmr),e(he,Ymr),e(he,M7),e(M7,Q2e),e(Q2e,Kmr),e(M7,Zmr),e(M7,cz),e(cz,egr),e(M7,ogr),e(he,rgr),e(he,E7),e(E7,W2e),e(W2e,tgr),e(E7,agr),e(E7,fz),e(fz,ngr),e(E7,sgr),e(he,lgr),e(he,C7),e(C7,H2e),e(H2e,igr),e(C7,dgr),e(C7,mz),e(mz,cgr),e(C7,fgr),e(uo,mgr),e(uo,U2e),e(U2e,ggr),e(uo,hgr),g(Z0,uo,null),b(c,V$e,u),b(c,Sc,u),e(Sc,w7),e(w7,J2e),g(eA,J2e,null),e(Sc,pgr),e(Sc,Y2e),e(Y2e,_gr),b(c,X$e,u),b(c,Mr,u),g(oA,Mr,null),e(Mr,ugr),e(Mr,Rc),e(Rc,bgr),e(Rc,gz),e(gz,vgr),e(Rc,Fgr),e(Rc,hz),e(hz,Tgr),e(Rc,Mgr),e(Mr,Egr),e(Mr,rA),e(rA,Cgr),e(rA,K2e),e(K2e,wgr),e(rA,Agr),e(Mr,ygr),e(Mr,_t),g(tA,_t,null),e(_t,Lgr),e(_t,Z2e),e(Z2e,xgr),e(_t,kgr),e(_t,Bc),e(Bc,Sgr),e(Bc,e1e),e(e1e,Rgr),e(Bc,Bgr),e(Bc,pz),e(pz,Pgr),e(Bc,$gr),e(_t,Igr),e(_t,o1e),e(o1e,qgr),e(_t,Ngr),g(aA,_t,null),e(Mr,jgr),e(Mr,bo),g(nA,bo,null),e(bo,Dgr),e(bo,r1e),e(r1e,Ggr),e(bo,Ogr),e(bo,Fn),e(Fn,Vgr),e(Fn,t1e),e(t1e,Xgr),e(Fn,zgr),e(Fn,a1e),e(a1e,Qgr),e(Fn,Wgr),e(Fn,n1e),e(n1e,Hgr),e(Fn,Ugr),e(bo,Jgr),e(bo,sA),e(sA,A7),e(A7,s1e),e(s1e,Ygr),e(A7,Kgr),e(A7,_z),e(_z,Zgr),e(A7,ehr),e(sA,ohr),e(sA,y7),e(y7,l1e),e(l1e,rhr),e(y7,thr),e(y7,uz),e(uz,ahr),e(y7,nhr),e(bo,shr),e(bo,i1e),e(i1e,lhr),e(bo,ihr),g(lA,bo,null),b(c,z$e,u),b(c,Pc,u),e(Pc,L7),e(L7,d1e),g(iA,d1e,null),e(Pc,dhr),e(Pc,c1e),e(c1e,chr),b(c,Q$e,u),b(c,Er,u),g(dA,Er,null),e(Er,fhr),e(Er,$c),e($c,mhr),e($c,bz),e(bz,ghr),e($c,hhr),e($c,vz),e(vz,phr),e($c,_hr),e(Er,uhr),e(Er,cA),e(cA,bhr),e(cA,f1e),e(f1e,vhr),e(cA,Fhr),e(Er,Thr),e(Er,ut),g(fA,ut,null),e(ut,Mhr),e(ut,m1e),e(m1e,Ehr),e(ut,Chr),e(ut,Ic),e(Ic,whr),e(Ic,g1e),e(g1e,Ahr),e(Ic,yhr),e(Ic,Fz),e(Fz,Lhr),e(Ic,xhr),e(ut,khr),e(ut,h1e),e(h1e,Shr),e(ut,Rhr),g(mA,ut,null),e(Er,Bhr),e(Er,vo),g(gA,vo,null),e(vo,Phr),e(vo,p1e),e(p1e,$hr),e(vo,Ihr),e(vo,Tn),e(Tn,qhr),e(Tn,_1e),e(_1e,Nhr),e(Tn,jhr),e(Tn,u1e),e(u1e,Dhr),e(Tn,Ghr),e(Tn,b1e),e(b1e,Ohr),e(Tn,Vhr),e(vo,Xhr),e(vo,K),e(K,x7),e(x7,v1e),e(v1e,zhr),e(x7,Qhr),e(x7,Tz),e(Tz,Whr),e(x7,Hhr),e(K,Uhr),e(K,k7),e(k7,F1e),e(F1e,Jhr),e(k7,Yhr),e(k7,Mz),e(Mz,Khr),e(k7,Zhr),e(K,epr),e(K,S7),e(S7,T1e),e(T1e,opr),e(S7,rpr),e(S7,Ez),e(Ez,tpr),e(S7,apr),e(K,npr),e(K,R7),e(R7,M1e),e(M1e,spr),e(R7,lpr),e(R7,Cz),e(Cz,ipr),e(R7,dpr),e(K,cpr),e(K,B7),e(B7,E1e),e(E1e,fpr),e(B7,mpr),e(B7,wz),e(wz,gpr),e(B7,hpr),e(K,ppr),e(K,P7),e(P7,C1e),e(C1e,_pr),e(P7,upr),e(P7,Az),e(Az,bpr),e(P7,vpr),e(K,Fpr),e(K,$7),e($7,w1e),e(w1e,Tpr),e($7,Mpr),e($7,yz),e(yz,Epr),e($7,Cpr),e(K,wpr),e(K,I7),e(I7,A1e),e(A1e,Apr),e(I7,ypr),e(I7,Lz),e(Lz,Lpr),e(I7,xpr),e(K,kpr),e(K,q7),e(q7,y1e),e(y1e,Spr),e(q7,Rpr),e(q7,xz),e(xz,Bpr),e(q7,Ppr),e(K,$pr),e(K,N7),e(N7,L1e),e(L1e,Ipr),e(N7,qpr),e(N7,kz),e(kz,Npr),e(N7,jpr),e(K,Dpr),e(K,j7),e(j7,x1e),e(x1e,Gpr),e(j7,Opr),e(j7,Sz),e(Sz,Vpr),e(j7,Xpr),e(K,zpr),e(K,D7),e(D7,k1e),e(k1e,Qpr),e(D7,Wpr),e(D7,Rz),e(Rz,Hpr),e(D7,Upr),e(K,Jpr),e(K,G7),e(G7,S1e),e(S1e,Ypr),e(G7,Kpr),e(G7,Bz),e(Bz,Zpr),e(G7,e_r),e(K,o_r),e(K,O7),e(O7,R1e),e(R1e,r_r),e(O7,t_r),e(O7,Pz),e(Pz,a_r),e(O7,n_r),e(K,s_r),e(K,V7),e(V7,B1e),e(B1e,l_r),e(V7,i_r),e(V7,$z),e($z,d_r),e(V7,c_r),e(K,f_r),e(K,X7),e(X7,P1e),e(P1e,m_r),e(X7,g_r),e(X7,Iz),e(Iz,h_r),e(X7,p_r),e(K,__r),e(K,z7),e(z7,$1e),e($1e,u_r),e(z7,b_r),e(z7,qz),e(qz,v_r),e(z7,F_r),e(K,T_r),e(K,Q7),e(Q7,I1e),e(I1e,M_r),e(Q7,E_r),e(Q7,Nz),e(Nz,C_r),e(Q7,w_r),e(K,A_r),e(K,W7),e(W7,q1e),e(q1e,y_r),e(W7,L_r),e(W7,jz),e(jz,x_r),e(W7,k_r),e(K,S_r),e(K,H7),e(H7,N1e),e(N1e,R_r),e(H7,B_r),e(H7,Dz),e(Dz,P_r),e(H7,$_r),e(vo,I_r),e(vo,j1e),e(j1e,q_r),e(vo,N_r),g(hA,vo,null),b(c,W$e,u),b(c,qc,u),e(qc,U7),e(U7,D1e),g(pA,D1e,null),e(qc,j_r),e(qc,G1e),e(G1e,D_r),b(c,H$e,u),b(c,Cr,u),g(_A,Cr,null),e(Cr,G_r),e(Cr,Nc),e(Nc,O_r),e(Nc,Gz),e(Gz,V_r),e(Nc,X_r),e(Nc,Oz),e(Oz,z_r),e(Nc,Q_r),e(Cr,W_r),e(Cr,uA),e(uA,H_r),e(uA,O1e),e(O1e,U_r),e(uA,J_r),e(Cr,Y_r),e(Cr,bt),g(bA,bt,null),e(bt,K_r),e(bt,V1e),e(V1e,Z_r),e(bt,eur),e(bt,jc),e(jc,our),e(jc,X1e),e(X1e,rur),e(jc,tur),e(jc,Vz),e(Vz,aur),e(jc,nur),e(bt,sur),e(bt,z1e),e(z1e,lur),e(bt,iur),g(vA,bt,null),e(Cr,dur),e(Cr,Fo),g(FA,Fo,null),e(Fo,cur),e(Fo,Q1e),e(Q1e,fur),e(Fo,mur),e(Fo,Mn),e(Mn,gur),e(Mn,W1e),e(W1e,hur),e(Mn,pur),e(Mn,H1e),e(H1e,_ur),e(Mn,uur),e(Mn,U1e),e(U1e,bur),e(Mn,vur),e(Fo,Fur),e(Fo,Fe),e(Fe,J7),e(J7,J1e),e(J1e,Tur),e(J7,Mur),e(J7,Xz),e(Xz,Eur),e(J7,Cur),e(Fe,wur),e(Fe,Y7),e(Y7,Y1e),e(Y1e,Aur),e(Y7,yur),e(Y7,zz),e(zz,Lur),e(Y7,xur),e(Fe,kur),e(Fe,K7),e(K7,K1e),e(K1e,Sur),e(K7,Rur),e(K7,Qz),e(Qz,Bur),e(K7,Pur),e(Fe,$ur),e(Fe,Z7),e(Z7,Z1e),e(Z1e,Iur),e(Z7,qur),e(Z7,Wz),e(Wz,Nur),e(Z7,jur),e(Fe,Dur),e(Fe,e9),e(e9,ebe),e(ebe,Gur),e(e9,Our),e(e9,Hz),e(Hz,Vur),e(e9,Xur),e(Fe,zur),e(Fe,o9),e(o9,obe),e(obe,Qur),e(o9,Wur),e(o9,Uz),e(Uz,Hur),e(o9,Uur),e(Fe,Jur),e(Fe,r9),e(r9,rbe),e(rbe,Yur),e(r9,Kur),e(r9,Jz),e(Jz,Zur),e(r9,e2r),e(Fe,o2r),e(Fe,t9),e(t9,tbe),e(tbe,r2r),e(t9,t2r),e(t9,Yz),e(Yz,a2r),e(t9,n2r),e(Fe,s2r),e(Fe,a9),e(a9,abe),e(abe,l2r),e(a9,i2r),e(a9,Kz),e(Kz,d2r),e(a9,c2r),e(Fe,f2r),e(Fe,n9),e(n9,nbe),e(nbe,m2r),e(n9,g2r),e(n9,Zz),e(Zz,h2r),e(n9,p2r),e(Fo,_2r),e(Fo,sbe),e(sbe,u2r),e(Fo,b2r),g(TA,Fo,null),b(c,U$e,u),b(c,Dc,u),e(Dc,s9),e(s9,lbe),g(MA,lbe,null),e(Dc,v2r),e(Dc,ibe),e(ibe,F2r),b(c,J$e,u),b(c,wr,u),g(EA,wr,null),e(wr,T2r),e(wr,Gc),e(Gc,M2r),e(Gc,eQ),e(eQ,E2r),e(Gc,C2r),e(Gc,oQ),e(oQ,w2r),e(Gc,A2r),e(wr,y2r),e(wr,CA),e(CA,L2r),e(CA,dbe),e(dbe,x2r),e(CA,k2r),e(wr,S2r),e(wr,vt),g(wA,vt,null),e(vt,R2r),e(vt,cbe),e(cbe,B2r),e(vt,P2r),e(vt,Oc),e(Oc,$2r),e(Oc,fbe),e(fbe,I2r),e(Oc,q2r),e(Oc,rQ),e(rQ,N2r),e(Oc,j2r),e(vt,D2r),e(vt,mbe),e(mbe,G2r),e(vt,O2r),g(AA,vt,null),e(wr,V2r),e(wr,To),g(yA,To,null),e(To,X2r),e(To,gbe),e(gbe,z2r),e(To,Q2r),e(To,En),e(En,W2r),e(En,hbe),e(hbe,H2r),e(En,U2r),e(En,pbe),e(pbe,J2r),e(En,Y2r),e(En,_be),e(_be,K2r),e(En,Z2r),e(To,e1r),e(To,V),e(V,l9),e(l9,ube),e(ube,o1r),e(l9,r1r),e(l9,tQ),e(tQ,t1r),e(l9,a1r),e(V,n1r),e(V,i9),e(i9,bbe),e(bbe,s1r),e(i9,l1r),e(i9,aQ),e(aQ,i1r),e(i9,d1r),e(V,c1r),e(V,d9),e(d9,vbe),e(vbe,f1r),e(d9,m1r),e(d9,nQ),e(nQ,g1r),e(d9,h1r),e(V,p1r),e(V,c9),e(c9,Fbe),e(Fbe,_1r),e(c9,u1r),e(c9,sQ),e(sQ,b1r),e(c9,v1r),e(V,F1r),e(V,f9),e(f9,Tbe),e(Tbe,T1r),e(f9,M1r),e(f9,lQ),e(lQ,E1r),e(f9,C1r),e(V,w1r),e(V,m9),e(m9,Mbe),e(Mbe,A1r),e(m9,y1r),e(m9,iQ),e(iQ,L1r),e(m9,x1r),e(V,k1r),e(V,g9),e(g9,Ebe),e(Ebe,S1r),e(g9,R1r),e(g9,dQ),e(dQ,B1r),e(g9,P1r),e(V,$1r),e(V,h9),e(h9,Cbe),e(Cbe,I1r),e(h9,q1r),e(h9,cQ),e(cQ,N1r),e(h9,j1r),e(V,D1r),e(V,p9),e(p9,wbe),e(wbe,G1r),e(p9,O1r),e(p9,fQ),e(fQ,V1r),e(p9,X1r),e(V,z1r),e(V,_9),e(_9,Abe),e(Abe,Q1r),e(_9,W1r),e(_9,mQ),e(mQ,H1r),e(_9,U1r),e(V,J1r),e(V,u9),e(u9,ybe),e(ybe,Y1r),e(u9,K1r),e(u9,gQ),e(gQ,Z1r),e(u9,ebr),e(V,obr),e(V,b9),e(b9,Lbe),e(Lbe,rbr),e(b9,tbr),e(b9,hQ),e(hQ,abr),e(b9,nbr),e(V,sbr),e(V,v9),e(v9,xbe),e(xbe,lbr),e(v9,ibr),e(v9,pQ),e(pQ,dbr),e(v9,cbr),e(V,fbr),e(V,F9),e(F9,kbe),e(kbe,mbr),e(F9,gbr),e(F9,_Q),e(_Q,hbr),e(F9,pbr),e(V,_br),e(V,T9),e(T9,Sbe),e(Sbe,ubr),e(T9,bbr),e(T9,uQ),e(uQ,vbr),e(T9,Fbr),e(V,Tbr),e(V,M9),e(M9,Rbe),e(Rbe,Mbr),e(M9,Ebr),e(M9,bQ),e(bQ,Cbr),e(M9,wbr),e(V,Abr),e(V,E9),e(E9,Bbe),e(Bbe,ybr),e(E9,Lbr),e(E9,vQ),e(vQ,xbr),e(E9,kbr),e(V,Sbr),e(V,C9),e(C9,Pbe),e(Pbe,Rbr),e(C9,Bbr),e(C9,FQ),e(FQ,Pbr),e(C9,$br),e(V,Ibr),e(V,w9),e(w9,$be),e($be,qbr),e(w9,Nbr),e(w9,TQ),e(TQ,jbr),e(w9,Dbr),e(V,Gbr),e(V,A9),e(A9,Ibe),e(Ibe,Obr),e(A9,Vbr),e(A9,MQ),e(MQ,Xbr),e(A9,zbr),e(V,Qbr),e(V,y9),e(y9,qbe),e(qbe,Wbr),e(y9,Hbr),e(y9,EQ),e(EQ,Ubr),e(y9,Jbr),e(V,Ybr),e(V,L9),e(L9,Nbe),e(Nbe,Kbr),e(L9,Zbr),e(L9,CQ),e(CQ,e6r),e(L9,o6r),e(V,r6r),e(V,x9),e(x9,jbe),e(jbe,t6r),e(x9,a6r),e(x9,wQ),e(wQ,n6r),e(x9,s6r),e(V,l6r),e(V,k9),e(k9,Dbe),e(Dbe,i6r),e(k9,d6r),e(k9,AQ),e(AQ,c6r),e(k9,f6r),e(V,m6r),e(V,S9),e(S9,Gbe),e(Gbe,g6r),e(S9,h6r),e(S9,yQ),e(yQ,p6r),e(S9,_6r),e(V,u6r),e(V,R9),e(R9,Obe),e(Obe,b6r),e(R9,v6r),e(R9,LQ),e(LQ,F6r),e(R9,T6r),e(To,M6r),e(To,Vbe),e(Vbe,E6r),e(To,C6r),g(LA,To,null),b(c,Y$e,u),b(c,Vc,u),e(Vc,B9),e(B9,Xbe),g(xA,Xbe,null),e(Vc,w6r),e(Vc,zbe),e(zbe,A6r),b(c,K$e,u),b(c,Ar,u),g(kA,Ar,null),e(Ar,y6r),e(Ar,Xc),e(Xc,L6r),e(Xc,xQ),e(xQ,x6r),e(Xc,k6r),e(Xc,kQ),e(kQ,S6r),e(Xc,R6r),e(Ar,B6r),e(Ar,SA),e(SA,P6r),e(SA,Qbe),e(Qbe,$6r),e(SA,I6r),e(Ar,q6r),e(Ar,Ft),g(RA,Ft,null),e(Ft,N6r),e(Ft,Wbe),e(Wbe,j6r),e(Ft,D6r),e(Ft,zc),e(zc,G6r),e(zc,Hbe),e(Hbe,O6r),e(zc,V6r),e(zc,SQ),e(SQ,X6r),e(zc,z6r),e(Ft,Q6r),e(Ft,Ube),e(Ube,W6r),e(Ft,H6r),g(BA,Ft,null),e(Ar,U6r),e(Ar,Mo),g(PA,Mo,null),e(Mo,J6r),e(Mo,Jbe),e(Jbe,Y6r),e(Mo,K6r),e(Mo,Cn),e(Cn,Z6r),e(Cn,Ybe),e(Ybe,evr),e(Cn,ovr),e(Cn,Kbe),e(Kbe,rvr),e(Cn,tvr),e(Cn,Zbe),e(Zbe,avr),e(Cn,nvr),e(Mo,svr),e(Mo,se),e(se,P9),e(P9,e6e),e(e6e,lvr),e(P9,ivr),e(P9,RQ),e(RQ,dvr),e(P9,cvr),e(se,fvr),e(se,$9),e($9,o6e),e(o6e,mvr),e($9,gvr),e($9,BQ),e(BQ,hvr),e($9,pvr),e(se,_vr),e(se,I9),e(I9,r6e),e(r6e,uvr),e(I9,bvr),e(I9,PQ),e(PQ,vvr),e(I9,Fvr),e(se,Tvr),e(se,q9),e(q9,t6e),e(t6e,Mvr),e(q9,Evr),e(q9,$Q),e($Q,Cvr),e(q9,wvr),e(se,Avr),e(se,N9),e(N9,a6e),e(a6e,yvr),e(N9,Lvr),e(N9,IQ),e(IQ,xvr),e(N9,kvr),e(se,Svr),e(se,j9),e(j9,n6e),e(n6e,Rvr),e(j9,Bvr),e(j9,qQ),e(qQ,Pvr),e(j9,$vr),e(se,Ivr),e(se,D9),e(D9,s6e),e(s6e,qvr),e(D9,Nvr),e(D9,NQ),e(NQ,jvr),e(D9,Dvr),e(se,Gvr),e(se,G9),e(G9,l6e),e(l6e,Ovr),e(G9,Vvr),e(G9,jQ),e(jQ,Xvr),e(G9,zvr),e(se,Qvr),e(se,O9),e(O9,i6e),e(i6e,Wvr),e(O9,Hvr),e(O9,DQ),e(DQ,Uvr),e(O9,Jvr),e(se,Yvr),e(se,V9),e(V9,d6e),e(d6e,Kvr),e(V9,Zvr),e(V9,GQ),e(GQ,eFr),e(V9,oFr),e(se,rFr),e(se,X9),e(X9,c6e),e(c6e,tFr),e(X9,aFr),e(X9,OQ),e(OQ,nFr),e(X9,sFr),e(se,lFr),e(se,z9),e(z9,f6e),e(f6e,iFr),e(z9,dFr),e(z9,VQ),e(VQ,cFr),e(z9,fFr),e(se,mFr),e(se,Q9),e(Q9,m6e),e(m6e,gFr),e(Q9,hFr),e(Q9,XQ),e(XQ,pFr),e(Q9,_Fr),e(se,uFr),e(se,W9),e(W9,g6e),e(g6e,bFr),e(W9,vFr),e(W9,zQ),e(zQ,FFr),e(W9,TFr),e(se,MFr),e(se,H9),e(H9,h6e),e(h6e,EFr),e(H9,CFr),e(H9,QQ),e(QQ,wFr),e(H9,AFr),e(se,yFr),e(se,U9),e(U9,p6e),e(p6e,LFr),e(U9,xFr),e(U9,WQ),e(WQ,kFr),e(U9,SFr),e(se,RFr),e(se,J9),e(J9,_6e),e(_6e,BFr),e(J9,PFr),e(J9,HQ),e(HQ,$Fr),e(J9,IFr),e(Mo,qFr),e(Mo,u6e),e(u6e,NFr),e(Mo,jFr),g($A,Mo,null),b(c,Z$e,u),b(c,Qc,u),e(Qc,Y9),e(Y9,b6e),g(IA,b6e,null),e(Qc,DFr),e(Qc,v6e),e(v6e,GFr),b(c,eIe,u),b(c,yr,u),g(qA,yr,null),e(yr,OFr),e(yr,Wc),e(Wc,VFr),e(Wc,UQ),e(UQ,XFr),e(Wc,zFr),e(Wc,JQ),e(JQ,QFr),e(Wc,WFr),e(yr,HFr),e(yr,NA),e(NA,UFr),e(NA,F6e),e(F6e,JFr),e(NA,YFr),e(yr,KFr),e(yr,Tt),g(jA,Tt,null),e(Tt,ZFr),e(Tt,T6e),e(T6e,eTr),e(Tt,oTr),e(Tt,Hc),e(Hc,rTr),e(Hc,M6e),e(M6e,tTr),e(Hc,aTr),e(Hc,YQ),e(YQ,nTr),e(Hc,sTr),e(Tt,lTr),e(Tt,E6e),e(E6e,iTr),e(Tt,dTr),g(DA,Tt,null),e(yr,cTr),e(yr,Eo),g(GA,Eo,null),e(Eo,fTr),e(Eo,C6e),e(C6e,mTr),e(Eo,gTr),e(Eo,wn),e(wn,hTr),e(wn,w6e),e(w6e,pTr),e(wn,_Tr),e(wn,A6e),e(A6e,uTr),e(wn,bTr),e(wn,y6e),e(y6e,vTr),e(wn,FTr),e(Eo,TTr),e(Eo,L6e),e(L6e,K9),e(K9,x6e),e(x6e,MTr),e(K9,ETr),e(K9,KQ),e(KQ,CTr),e(K9,wTr),e(Eo,ATr),e(Eo,k6e),e(k6e,yTr),e(Eo,LTr),g(OA,Eo,null),b(c,oIe,u),b(c,Uc,u),e(Uc,Z9),e(Z9,S6e),g(VA,S6e,null),e(Uc,xTr),e(Uc,R6e),e(R6e,kTr),b(c,rIe,u),b(c,Lr,u),g(XA,Lr,null),e(Lr,STr),e(Lr,Jc),e(Jc,RTr),e(Jc,ZQ),e(ZQ,BTr),e(Jc,PTr),e(Jc,eW),e(eW,$Tr),e(Jc,ITr),e(Lr,qTr),e(Lr,zA),e(zA,NTr),e(zA,B6e),e(B6e,jTr),e(zA,DTr),e(Lr,GTr),e(Lr,Mt),g(QA,Mt,null),e(Mt,OTr),e(Mt,P6e),e(P6e,VTr),e(Mt,XTr),e(Mt,Yc),e(Yc,zTr),e(Yc,$6e),e($6e,QTr),e(Yc,WTr),e(Yc,oW),e(oW,HTr),e(Yc,UTr),e(Mt,JTr),e(Mt,I6e),e(I6e,YTr),e(Mt,KTr),g(WA,Mt,null),e(Lr,ZTr),e(Lr,Co),g(HA,Co,null),e(Co,e7r),e(Co,q6e),e(q6e,o7r),e(Co,r7r),e(Co,An),e(An,t7r),e(An,N6e),e(N6e,a7r),e(An,n7r),e(An,j6e),e(j6e,s7r),e(An,l7r),e(An,D6e),e(D6e,i7r),e(An,d7r),e(Co,c7r),e(Co,Z),e(Z,eM),e(eM,G6e),e(G6e,f7r),e(eM,m7r),e(eM,rW),e(rW,g7r),e(eM,h7r),e(Z,p7r),e(Z,oM),e(oM,O6e),e(O6e,_7r),e(oM,u7r),e(oM,tW),e(tW,b7r),e(oM,v7r),e(Z,F7r),e(Z,rM),e(rM,V6e),e(V6e,T7r),e(rM,M7r),e(rM,aW),e(aW,E7r),e(rM,C7r),e(Z,w7r),e(Z,tM),e(tM,X6e),e(X6e,A7r),e(tM,y7r),e(tM,nW),e(nW,L7r),e(tM,x7r),e(Z,k7r),e(Z,aM),e(aM,z6e),e(z6e,S7r),e(aM,R7r),e(aM,sW),e(sW,B7r),e(aM,P7r),e(Z,$7r),e(Z,nM),e(nM,Q6e),e(Q6e,I7r),e(nM,q7r),e(nM,lW),e(lW,N7r),e(nM,j7r),e(Z,D7r),e(Z,sM),e(sM,W6e),e(W6e,G7r),e(sM,O7r),e(sM,iW),e(iW,V7r),e(sM,X7r),e(Z,z7r),e(Z,lM),e(lM,H6e),e(H6e,Q7r),e(lM,W7r),e(lM,dW),e(dW,H7r),e(lM,U7r),e(Z,J7r),e(Z,iM),e(iM,U6e),e(U6e,Y7r),e(iM,K7r),e(iM,cW),e(cW,Z7r),e(iM,e9r),e(Z,o9r),e(Z,dM),e(dM,J6e),e(J6e,r9r),e(dM,t9r),e(dM,fW),e(fW,a9r),e(dM,n9r),e(Z,s9r),e(Z,cM),e(cM,Y6e),e(Y6e,l9r),e(cM,i9r),e(cM,mW),e(mW,d9r),e(cM,c9r),e(Z,f9r),e(Z,fM),e(fM,K6e),e(K6e,m9r),e(fM,g9r),e(fM,gW),e(gW,h9r),e(fM,p9r),e(Z,_9r),e(Z,mM),e(mM,Z6e),e(Z6e,u9r),e(mM,b9r),e(mM,hW),e(hW,v9r),e(mM,F9r),e(Z,T9r),e(Z,gM),e(gM,eve),e(eve,M9r),e(gM,E9r),e(gM,pW),e(pW,C9r),e(gM,w9r),e(Z,A9r),e(Z,hM),e(hM,ove),e(ove,y9r),e(hM,L9r),e(hM,_W),e(_W,x9r),e(hM,k9r),e(Z,S9r),e(Z,pM),e(pM,rve),e(rve,R9r),e(pM,B9r),e(pM,uW),e(uW,P9r),e(pM,$9r),e(Z,I9r),e(Z,_M),e(_M,tve),e(tve,q9r),e(_M,N9r),e(_M,bW),e(bW,j9r),e(_M,D9r),e(Z,G9r),e(Z,uM),e(uM,ave),e(ave,O9r),e(uM,V9r),e(uM,vW),e(vW,X9r),e(uM,z9r),e(Z,Q9r),e(Z,bM),e(bM,nve),e(nve,W9r),e(bM,H9r),e(bM,FW),e(FW,U9r),e(bM,J9r),e(Z,Y9r),e(Z,vM),e(vM,sve),e(sve,K9r),e(vM,Z9r),e(vM,TW),e(TW,eMr),e(vM,oMr),e(Co,rMr),e(Co,lve),e(lve,tMr),e(Co,aMr),g(UA,Co,null),b(c,tIe,u),b(c,Kc,u),e(Kc,FM),e(FM,ive),g(JA,ive,null),e(Kc,nMr),e(Kc,dve),e(dve,sMr),b(c,aIe,u),b(c,xr,u),g(YA,xr,null),e(xr,lMr),e(xr,Zc),e(Zc,iMr),e(Zc,MW),e(MW,dMr),e(Zc,cMr),e(Zc,EW),e(EW,fMr),e(Zc,mMr),e(xr,gMr),e(xr,KA),e(KA,hMr),e(KA,cve),e(cve,pMr),e(KA,_Mr),e(xr,uMr),e(xr,Et),g(ZA,Et,null),e(Et,bMr),e(Et,fve),e(fve,vMr),e(Et,FMr),e(Et,ef),e(ef,TMr),e(ef,mve),e(mve,MMr),e(ef,EMr),e(ef,CW),e(CW,CMr),e(ef,wMr),e(Et,AMr),e(Et,gve),e(gve,yMr),e(Et,LMr),g(ey,Et,null),e(xr,xMr),e(xr,wo),g(oy,wo,null),e(wo,kMr),e(wo,hve),e(hve,SMr),e(wo,RMr),e(wo,yn),e(yn,BMr),e(yn,pve),e(pve,PMr),e(yn,$Mr),e(yn,_ve),e(_ve,IMr),e(yn,qMr),e(yn,uve),e(uve,NMr),e(yn,jMr),e(wo,DMr),e(wo,ee),e(ee,TM),e(TM,bve),e(bve,GMr),e(TM,OMr),e(TM,wW),e(wW,VMr),e(TM,XMr),e(ee,zMr),e(ee,MM),e(MM,vve),e(vve,QMr),e(MM,WMr),e(MM,AW),e(AW,HMr),e(MM,UMr),e(ee,JMr),e(ee,EM),e(EM,Fve),e(Fve,YMr),e(EM,KMr),e(EM,yW),e(yW,ZMr),e(EM,e4r),e(ee,o4r),e(ee,CM),e(CM,Tve),e(Tve,r4r),e(CM,t4r),e(CM,LW),e(LW,a4r),e(CM,n4r),e(ee,s4r),e(ee,wM),e(wM,Mve),e(Mve,l4r),e(wM,i4r),e(wM,xW),e(xW,d4r),e(wM,c4r),e(ee,f4r),e(ee,AM),e(AM,Eve),e(Eve,m4r),e(AM,g4r),e(AM,kW),e(kW,h4r),e(AM,p4r),e(ee,_4r),e(ee,yM),e(yM,Cve),e(Cve,u4r),e(yM,b4r),e(yM,SW),e(SW,v4r),e(yM,F4r),e(ee,T4r),e(ee,LM),e(LM,wve),e(wve,M4r),e(LM,E4r),e(LM,RW),e(RW,C4r),e(LM,w4r),e(ee,A4r),e(ee,xM),e(xM,Ave),e(Ave,y4r),e(xM,L4r),e(xM,BW),e(BW,x4r),e(xM,k4r),e(ee,S4r),e(ee,kM),e(kM,yve),e(yve,R4r),e(kM,B4r),e(kM,PW),e(PW,P4r),e(kM,$4r),e(ee,I4r),e(ee,SM),e(SM,Lve),e(Lve,q4r),e(SM,N4r),e(SM,$W),e($W,j4r),e(SM,D4r),e(ee,G4r),e(ee,RM),e(RM,xve),e(xve,O4r),e(RM,V4r),e(RM,IW),e(IW,X4r),e(RM,z4r),e(ee,Q4r),e(ee,BM),e(BM,kve),e(kve,W4r),e(BM,H4r),e(BM,qW),e(qW,U4r),e(BM,J4r),e(ee,Y4r),e(ee,PM),e(PM,Sve),e(Sve,K4r),e(PM,Z4r),e(PM,NW),e(NW,eEr),e(PM,oEr),e(ee,rEr),e(ee,$M),e($M,Rve),e(Rve,tEr),e($M,aEr),e($M,jW),e(jW,nEr),e($M,sEr),e(ee,lEr),e(ee,IM),e(IM,Bve),e(Bve,iEr),e(IM,dEr),e(IM,DW),e(DW,cEr),e(IM,fEr),e(ee,mEr),e(ee,qM),e(qM,Pve),e(Pve,gEr),e(qM,hEr),e(qM,GW),e(GW,pEr),e(qM,_Er),e(ee,uEr),e(ee,NM),e(NM,$ve),e($ve,bEr),e(NM,vEr),e(NM,OW),e(OW,FEr),e(NM,TEr),e(ee,MEr),e(ee,jM),e(jM,Ive),e(Ive,EEr),e(jM,CEr),e(jM,VW),e(VW,wEr),e(jM,AEr),e(ee,yEr),e(ee,DM),e(DM,qve),e(qve,LEr),e(DM,xEr),e(DM,XW),e(XW,kEr),e(DM,SEr),e(wo,REr),e(wo,Nve),e(Nve,BEr),e(wo,PEr),g(ry,wo,null),b(c,nIe,u),b(c,of,u),e(of,GM),e(GM,jve),g(ty,jve,null),e(of,$Er),e(of,Dve),e(Dve,IEr),b(c,sIe,u),b(c,kr,u),g(ay,kr,null),e(kr,qEr),e(kr,rf),e(rf,NEr),e(rf,zW),e(zW,jEr),e(rf,DEr),e(rf,QW),e(QW,GEr),e(rf,OEr),e(kr,VEr),e(kr,ny),e(ny,XEr),e(ny,Gve),e(Gve,zEr),e(ny,QEr),e(kr,WEr),e(kr,Ct),g(sy,Ct,null),e(Ct,HEr),e(Ct,Ove),e(Ove,UEr),e(Ct,JEr),e(Ct,tf),e(tf,YEr),e(tf,Vve),e(Vve,KEr),e(tf,ZEr),e(tf,WW),e(WW,e5r),e(tf,o5r),e(Ct,r5r),e(Ct,Xve),e(Xve,t5r),e(Ct,a5r),g(ly,Ct,null),e(kr,n5r),e(kr,Ao),g(iy,Ao,null),e(Ao,s5r),e(Ao,zve),e(zve,l5r),e(Ao,i5r),e(Ao,Ln),e(Ln,d5r),e(Ln,Qve),e(Qve,c5r),e(Ln,f5r),e(Ln,Wve),e(Wve,m5r),e(Ln,g5r),e(Ln,Hve),e(Hve,h5r),e(Ln,p5r),e(Ao,_5r),e(Ao,Uve),e(Uve,OM),e(OM,Jve),e(Jve,u5r),e(OM,b5r),e(OM,HW),e(HW,v5r),e(OM,F5r),e(Ao,T5r),e(Ao,Yve),e(Yve,M5r),e(Ao,E5r),g(dy,Ao,null),b(c,lIe,u),b(c,af,u),e(af,VM),e(VM,Kve),g(cy,Kve,null),e(af,C5r),e(af,Zve),e(Zve,w5r),b(c,iIe,u),b(c,Sr,u),g(fy,Sr,null),e(Sr,A5r),e(Sr,nf),e(nf,y5r),e(nf,UW),e(UW,L5r),e(nf,x5r),e(nf,JW),e(JW,k5r),e(nf,S5r),e(Sr,R5r),e(Sr,my),e(my,B5r),e(my,eFe),e(eFe,P5r),e(my,$5r),e(Sr,I5r),e(Sr,wt),g(gy,wt,null),e(wt,q5r),e(wt,oFe),e(oFe,N5r),e(wt,j5r),e(wt,sf),e(sf,D5r),e(sf,rFe),e(rFe,G5r),e(sf,O5r),e(sf,YW),e(YW,V5r),e(sf,X5r),e(wt,z5r),e(wt,tFe),e(tFe,Q5r),e(wt,W5r),g(hy,wt,null),e(Sr,H5r),e(Sr,yo),g(py,yo,null),e(yo,U5r),e(yo,aFe),e(aFe,J5r),e(yo,Y5r),e(yo,xn),e(xn,K5r),e(xn,nFe),e(nFe,Z5r),e(xn,e3r),e(xn,sFe),e(sFe,o3r),e(xn,r3r),e(xn,lFe),e(lFe,t3r),e(xn,a3r),e(yo,n3r),e(yo,iFe),e(iFe,XM),e(XM,dFe),e(dFe,s3r),e(XM,l3r),e(XM,KW),e(KW,i3r),e(XM,d3r),e(yo,c3r),e(yo,cFe),e(cFe,f3r),e(yo,m3r),g(_y,yo,null),b(c,dIe,u),b(c,lf,u),e(lf,zM),e(zM,fFe),g(uy,fFe,null),e(lf,g3r),e(lf,mFe),e(mFe,h3r),b(c,cIe,u),b(c,Rr,u),g(by,Rr,null),e(Rr,p3r),e(Rr,df),e(df,_3r),e(df,ZW),e(ZW,u3r),e(df,b3r),e(df,eH),e(eH,v3r),e(df,F3r),e(Rr,T3r),e(Rr,vy),e(vy,M3r),e(vy,gFe),e(gFe,E3r),e(vy,C3r),e(Rr,w3r),e(Rr,At),g(Fy,At,null),e(At,A3r),e(At,hFe),e(hFe,y3r),e(At,L3r),e(At,cf),e(cf,x3r),e(cf,pFe),e(pFe,k3r),e(cf,S3r),e(cf,oH),e(oH,R3r),e(cf,B3r),e(At,P3r),e(At,_Fe),e(_Fe,$3r),e(At,I3r),g(Ty,At,null),e(Rr,q3r),e(Rr,Lo),g(My,Lo,null),e(Lo,N3r),e(Lo,uFe),e(uFe,j3r),e(Lo,D3r),e(Lo,kn),e(kn,G3r),e(kn,bFe),e(bFe,O3r),e(kn,V3r),e(kn,vFe),e(vFe,X3r),e(kn,z3r),e(kn,FFe),e(FFe,Q3r),e(kn,W3r),e(Lo,H3r),e(Lo,X),e(X,QM),e(QM,TFe),e(TFe,U3r),e(QM,J3r),e(QM,rH),e(rH,Y3r),e(QM,K3r),e(X,Z3r),e(X,WM),e(WM,MFe),e(MFe,eCr),e(WM,oCr),e(WM,tH),e(tH,rCr),e(WM,tCr),e(X,aCr),e(X,HM),e(HM,EFe),e(EFe,nCr),e(HM,sCr),e(HM,aH),e(aH,lCr),e(HM,iCr),e(X,dCr),e(X,UM),e(UM,CFe),e(CFe,cCr),e(UM,fCr),e(UM,nH),e(nH,mCr),e(UM,gCr),e(X,hCr),e(X,JM),e(JM,wFe),e(wFe,pCr),e(JM,_Cr),e(JM,sH),e(sH,uCr),e(JM,bCr),e(X,vCr),e(X,YM),e(YM,AFe),e(AFe,FCr),e(YM,TCr),e(YM,lH),e(lH,MCr),e(YM,ECr),e(X,CCr),e(X,KM),e(KM,yFe),e(yFe,wCr),e(KM,ACr),e(KM,iH),e(iH,yCr),e(KM,LCr),e(X,xCr),e(X,ZM),e(ZM,LFe),e(LFe,kCr),e(ZM,SCr),e(ZM,dH),e(dH,RCr),e(ZM,BCr),e(X,PCr),e(X,e4),e(e4,xFe),e(xFe,$Cr),e(e4,ICr),e(e4,cH),e(cH,qCr),e(e4,NCr),e(X,jCr),e(X,o4),e(o4,kFe),e(kFe,DCr),e(o4,GCr),e(o4,fH),e(fH,OCr),e(o4,VCr),e(X,XCr),e(X,r4),e(r4,SFe),e(SFe,zCr),e(r4,QCr),e(r4,mH),e(mH,WCr),e(r4,HCr),e(X,UCr),e(X,t4),e(t4,RFe),e(RFe,JCr),e(t4,YCr),e(t4,gH),e(gH,KCr),e(t4,ZCr),e(X,ewr),e(X,a4),e(a4,BFe),e(BFe,owr),e(a4,rwr),e(a4,hH),e(hH,twr),e(a4,awr),e(X,nwr),e(X,n4),e(n4,PFe),e(PFe,swr),e(n4,lwr),e(n4,pH),e(pH,iwr),e(n4,dwr),e(X,cwr),e(X,s4),e(s4,$Fe),e($Fe,fwr),e(s4,mwr),e(s4,_H),e(_H,gwr),e(s4,hwr),e(X,pwr),e(X,l4),e(l4,IFe),e(IFe,_wr),e(l4,uwr),e(l4,uH),e(uH,bwr),e(l4,vwr),e(X,Fwr),e(X,i4),e(i4,qFe),e(qFe,Twr),e(i4,Mwr),e(i4,bH),e(bH,Ewr),e(i4,Cwr),e(X,wwr),e(X,d4),e(d4,NFe),e(NFe,Awr),e(d4,ywr),e(d4,vH),e(vH,Lwr),e(d4,xwr),e(X,kwr),e(X,c4),e(c4,jFe),e(jFe,Swr),e(c4,Rwr),e(c4,FH),e(FH,Bwr),e(c4,Pwr),e(X,$wr),e(X,f4),e(f4,DFe),e(DFe,Iwr),e(f4,qwr),e(f4,TH),e(TH,Nwr),e(f4,jwr),e(X,Dwr),e(X,m4),e(m4,GFe),e(GFe,Gwr),e(m4,Owr),e(m4,MH),e(MH,Vwr),e(m4,Xwr),e(X,zwr),e(X,g4),e(g4,OFe),e(OFe,Qwr),e(g4,Wwr),e(g4,EH),e(EH,Hwr),e(g4,Uwr),e(X,Jwr),e(X,h4),e(h4,VFe),e(VFe,Ywr),e(h4,Kwr),e(h4,CH),e(CH,Zwr),e(h4,e0r),e(X,o0r),e(X,p4),e(p4,XFe),e(XFe,r0r),e(p4,t0r),e(p4,wH),e(wH,a0r),e(p4,n0r),e(X,s0r),e(X,_4),e(_4,zFe),e(zFe,l0r),e(_4,i0r),e(_4,AH),e(AH,d0r),e(_4,c0r),e(X,f0r),e(X,u4),e(u4,QFe),e(QFe,m0r),e(u4,g0r),e(u4,yH),e(yH,h0r),e(u4,p0r),e(Lo,_0r),e(Lo,WFe),e(WFe,u0r),e(Lo,b0r),g(Ey,Lo,null),b(c,fIe,u),b(c,ff,u),e(ff,b4),e(b4,HFe),g(Cy,HFe,null),e(ff,v0r),e(ff,UFe),e(UFe,F0r),b(c,mIe,u),b(c,Br,u),g(wy,Br,null),e(Br,T0r),e(Br,mf),e(mf,M0r),e(mf,LH),e(LH,E0r),e(mf,C0r),e(mf,xH),e(xH,w0r),e(mf,A0r),e(Br,y0r),e(Br,Ay),e(Ay,L0r),e(Ay,JFe),e(JFe,x0r),e(Ay,k0r),e(Br,S0r),e(Br,yt),g(yy,yt,null),e(yt,R0r),e(yt,YFe),e(YFe,B0r),e(yt,P0r),e(yt,gf),e(gf,$0r),e(gf,KFe),e(KFe,I0r),e(gf,q0r),e(gf,kH),e(kH,N0r),e(gf,j0r),e(yt,D0r),e(yt,ZFe),e(ZFe,G0r),e(yt,O0r),g(Ly,yt,null),e(Br,V0r),e(Br,xo),g(xy,xo,null),e(xo,X0r),e(xo,eTe),e(eTe,z0r),e(xo,Q0r),e(xo,Sn),e(Sn,W0r),e(Sn,oTe),e(oTe,H0r),e(Sn,U0r),e(Sn,rTe),e(rTe,J0r),e(Sn,Y0r),e(Sn,tTe),e(tTe,K0r),e(Sn,Z0r),e(xo,eAr),e(xo,ca),e(ca,v4),e(v4,aTe),e(aTe,oAr),e(v4,rAr),e(v4,SH),e(SH,tAr),e(v4,aAr),e(ca,nAr),e(ca,F4),e(F4,nTe),e(nTe,sAr),e(F4,lAr),e(F4,RH),e(RH,iAr),e(F4,dAr),e(ca,cAr),e(ca,T4),e(T4,sTe),e(sTe,fAr),e(T4,mAr),e(T4,BH),e(BH,gAr),e(T4,hAr),e(ca,pAr),e(ca,M4),e(M4,lTe),e(lTe,_Ar),e(M4,uAr),e(M4,PH),e(PH,bAr),e(M4,vAr),e(ca,FAr),e(ca,E4),e(E4,iTe),e(iTe,TAr),e(E4,MAr),e(E4,$H),e($H,EAr),e(E4,CAr),e(xo,wAr),e(xo,dTe),e(dTe,AAr),e(xo,yAr),g(ky,xo,null),b(c,gIe,u),b(c,hf,u),e(hf,C4),e(C4,cTe),g(Sy,cTe,null),e(hf,LAr),e(hf,fTe),e(fTe,xAr),b(c,hIe,u),b(c,Pr,u),g(Ry,Pr,null),e(Pr,kAr),e(Pr,pf),e(pf,SAr),e(pf,IH),e(IH,RAr),e(pf,BAr),e(pf,qH),e(qH,PAr),e(pf,$Ar),e(Pr,IAr),e(Pr,By),e(By,qAr),e(By,mTe),e(mTe,NAr),e(By,jAr),e(Pr,DAr),e(Pr,Lt),g(Py,Lt,null),e(Lt,GAr),e(Lt,gTe),e(gTe,OAr),e(Lt,VAr),e(Lt,_f),e(_f,XAr),e(_f,hTe),e(hTe,zAr),e(_f,QAr),e(_f,NH),e(NH,WAr),e(_f,HAr),e(Lt,UAr),e(Lt,pTe),e(pTe,JAr),e(Lt,YAr),g($y,Lt,null),e(Pr,KAr),e(Pr,ko),g(Iy,ko,null),e(ko,ZAr),e(ko,_Te),e(_Te,eyr),e(ko,oyr),e(ko,Rn),e(Rn,ryr),e(Rn,uTe),e(uTe,tyr),e(Rn,ayr),e(Rn,bTe),e(bTe,nyr),e(Rn,syr),e(Rn,vTe),e(vTe,lyr),e(Rn,iyr),e(ko,dyr),e(ko,fe),e(fe,w4),e(w4,FTe),e(FTe,cyr),e(w4,fyr),e(w4,jH),e(jH,myr),e(w4,gyr),e(fe,hyr),e(fe,A4),e(A4,TTe),e(TTe,pyr),e(A4,_yr),e(A4,DH),e(DH,uyr),e(A4,byr),e(fe,vyr),e(fe,y4),e(y4,MTe),e(MTe,Fyr),e(y4,Tyr),e(y4,GH),e(GH,Myr),e(y4,Eyr),e(fe,Cyr),e(fe,L4),e(L4,ETe),e(ETe,wyr),e(L4,Ayr),e(L4,OH),e(OH,yyr),e(L4,Lyr),e(fe,xyr),e(fe,x4),e(x4,CTe),e(CTe,kyr),e(x4,Syr),e(x4,VH),e(VH,Ryr),e(x4,Byr),e(fe,Pyr),e(fe,k4),e(k4,wTe),e(wTe,$yr),e(k4,Iyr),e(k4,XH),e(XH,qyr),e(k4,Nyr),e(fe,jyr),e(fe,S4),e(S4,ATe),e(ATe,Dyr),e(S4,Gyr),e(S4,zH),e(zH,Oyr),e(S4,Vyr),e(fe,Xyr),e(fe,R4),e(R4,yTe),e(yTe,zyr),e(R4,Qyr),e(R4,QH),e(QH,Wyr),e(R4,Hyr),e(fe,Uyr),e(fe,B4),e(B4,LTe),e(LTe,Jyr),e(B4,Yyr),e(B4,WH),e(WH,Kyr),e(B4,Zyr),e(fe,eLr),e(fe,P4),e(P4,xTe),e(xTe,oLr),e(P4,rLr),e(P4,HH),e(HH,tLr),e(P4,aLr),e(fe,nLr),e(fe,$4),e($4,kTe),e(kTe,sLr),e($4,lLr),e($4,UH),e(UH,iLr),e($4,dLr),e(fe,cLr),e(fe,I4),e(I4,STe),e(STe,fLr),e(I4,mLr),e(I4,JH),e(JH,gLr),e(I4,hLr),e(fe,pLr),e(fe,q4),e(q4,RTe),e(RTe,_Lr),e(q4,uLr),e(q4,YH),e(YH,bLr),e(q4,vLr),e(ko,FLr),e(ko,BTe),e(BTe,TLr),e(ko,MLr),g(qy,ko,null),b(c,pIe,u),b(c,uf,u),e(uf,N4),e(N4,PTe),g(Ny,PTe,null),e(uf,ELr),e(uf,$Te),e($Te,CLr),b(c,_Ie,u),b(c,$r,u),g(jy,$r,null),e($r,wLr),e($r,bf),e(bf,ALr),e(bf,KH),e(KH,yLr),e(bf,LLr),e(bf,ZH),e(ZH,xLr),e(bf,kLr),e($r,SLr),e($r,Dy),e(Dy,RLr),e(Dy,ITe),e(ITe,BLr),e(Dy,PLr),e($r,$Lr),e($r,xt),g(Gy,xt,null),e(xt,ILr),e(xt,qTe),e(qTe,qLr),e(xt,NLr),e(xt,vf),e(vf,jLr),e(vf,NTe),e(NTe,DLr),e(vf,GLr),e(vf,eU),e(eU,OLr),e(vf,VLr),e(xt,XLr),e(xt,jTe),e(jTe,zLr),e(xt,QLr),g(Oy,xt,null),e($r,WLr),e($r,So),g(Vy,So,null),e(So,HLr),e(So,DTe),e(DTe,ULr),e(So,JLr),e(So,Bn),e(Bn,YLr),e(Bn,GTe),e(GTe,KLr),e(Bn,ZLr),e(Bn,OTe),e(OTe,e8r),e(Bn,o8r),e(Bn,VTe),e(VTe,r8r),e(Bn,t8r),e(So,a8r),e(So,Te),e(Te,j4),e(j4,XTe),e(XTe,n8r),e(j4,s8r),e(j4,oU),e(oU,l8r),e(j4,i8r),e(Te,d8r),e(Te,D4),e(D4,zTe),e(zTe,c8r),e(D4,f8r),e(D4,rU),e(rU,m8r),e(D4,g8r),e(Te,h8r),e(Te,G4),e(G4,QTe),e(QTe,p8r),e(G4,_8r),e(G4,tU),e(tU,u8r),e(G4,b8r),e(Te,v8r),e(Te,O4),e(O4,WTe),e(WTe,F8r),e(O4,T8r),e(O4,aU),e(aU,M8r),e(O4,E8r),e(Te,C8r),e(Te,V4),e(V4,HTe),e(HTe,w8r),e(V4,A8r),e(V4,nU),e(nU,y8r),e(V4,L8r),e(Te,x8r),e(Te,X4),e(X4,UTe),e(UTe,k8r),e(X4,S8r),e(X4,sU),e(sU,R8r),e(X4,B8r),e(Te,P8r),e(Te,z4),e(z4,JTe),e(JTe,$8r),e(z4,I8r),e(z4,lU),e(lU,q8r),e(z4,N8r),e(Te,j8r),e(Te,Q4),e(Q4,YTe),e(YTe,D8r),e(Q4,G8r),e(Q4,iU),e(iU,O8r),e(Q4,V8r),e(Te,X8r),e(Te,W4),e(W4,KTe),e(KTe,z8r),e(W4,Q8r),e(W4,dU),e(dU,W8r),e(W4,H8r),e(Te,U8r),e(Te,H4),e(H4,ZTe),e(ZTe,J8r),e(H4,Y8r),e(H4,cU),e(cU,K8r),e(H4,Z8r),e(So,exr),e(So,e7e),e(e7e,oxr),e(So,rxr),g(Xy,So,null),b(c,uIe,u),b(c,Ff,u),e(Ff,U4),e(U4,o7e),g(zy,o7e,null),e(Ff,txr),e(Ff,r7e),e(r7e,axr),b(c,bIe,u),b(c,Ir,u),g(Qy,Ir,null),e(Ir,nxr),e(Ir,Tf),e(Tf,sxr),e(Tf,fU),e(fU,lxr),e(Tf,ixr),e(Tf,mU),e(mU,dxr),e(Tf,cxr),e(Ir,fxr),e(Ir,Wy),e(Wy,mxr),e(Wy,t7e),e(t7e,gxr),e(Wy,hxr),e(Ir,pxr),e(Ir,kt),g(Hy,kt,null),e(kt,_xr),e(kt,a7e),e(a7e,uxr),e(kt,bxr),e(kt,Mf),e(Mf,vxr),e(Mf,n7e),e(n7e,Fxr),e(Mf,Txr),e(Mf,gU),e(gU,Mxr),e(Mf,Exr),e(kt,Cxr),e(kt,s7e),e(s7e,wxr),e(kt,Axr),g(Uy,kt,null),e(Ir,yxr),e(Ir,Ro),g(Jy,Ro,null),e(Ro,Lxr),e(Ro,l7e),e(l7e,xxr),e(Ro,kxr),e(Ro,Pn),e(Pn,Sxr),e(Pn,i7e),e(i7e,Rxr),e(Pn,Bxr),e(Pn,d7e),e(d7e,Pxr),e(Pn,$xr),e(Pn,c7e),e(c7e,Ixr),e(Pn,qxr),e(Ro,Nxr),e(Ro,Me),e(Me,J4),e(J4,f7e),e(f7e,jxr),e(J4,Dxr),e(J4,hU),e(hU,Gxr),e(J4,Oxr),e(Me,Vxr),e(Me,Y4),e(Y4,m7e),e(m7e,Xxr),e(Y4,zxr),e(Y4,pU),e(pU,Qxr),e(Y4,Wxr),e(Me,Hxr),e(Me,K4),e(K4,g7e),e(g7e,Uxr),e(K4,Jxr),e(K4,_U),e(_U,Yxr),e(K4,Kxr),e(Me,Zxr),e(Me,Z4),e(Z4,h7e),e(h7e,ekr),e(Z4,okr),e(Z4,uU),e(uU,rkr),e(Z4,tkr),e(Me,akr),e(Me,eE),e(eE,p7e),e(p7e,nkr),e(eE,skr),e(eE,bU),e(bU,lkr),e(eE,ikr),e(Me,dkr),e(Me,oE),e(oE,_7e),e(_7e,ckr),e(oE,fkr),e(oE,vU),e(vU,mkr),e(oE,gkr),e(Me,hkr),e(Me,rE),e(rE,u7e),e(u7e,pkr),e(rE,_kr),e(rE,FU),e(FU,ukr),e(rE,bkr),e(Me,vkr),e(Me,tE),e(tE,b7e),e(b7e,Fkr),e(tE,Tkr),e(tE,TU),e(TU,Mkr),e(tE,Ekr),e(Me,Ckr),e(Me,aE),e(aE,v7e),e(v7e,wkr),e(aE,Akr),e(aE,MU),e(MU,ykr),e(aE,Lkr),e(Me,xkr),e(Me,nE),e(nE,F7e),e(F7e,kkr),e(nE,Skr),e(nE,EU),e(EU,Rkr),e(nE,Bkr),e(Ro,Pkr),e(Ro,T7e),e(T7e,$kr),e(Ro,Ikr),g(Yy,Ro,null),b(c,vIe,u),b(c,Ef,u),e(Ef,sE),e(sE,M7e),g(Ky,M7e,null),e(Ef,qkr),e(Ef,E7e),e(E7e,Nkr),b(c,FIe,u),b(c,qr,u),g(Zy,qr,null),e(qr,jkr),e(qr,Cf),e(Cf,Dkr),e(Cf,CU),e(CU,Gkr),e(Cf,Okr),e(Cf,wU),e(wU,Vkr),e(Cf,Xkr),e(qr,zkr),e(qr,eL),e(eL,Qkr),e(eL,C7e),e(C7e,Wkr),e(eL,Hkr),e(qr,Ukr),e(qr,St),g(oL,St,null),e(St,Jkr),e(St,w7e),e(w7e,Ykr),e(St,Kkr),e(St,wf),e(wf,Zkr),e(wf,A7e),e(A7e,eSr),e(wf,oSr),e(wf,AU),e(AU,rSr),e(wf,tSr),e(St,aSr),e(St,y7e),e(y7e,nSr),e(St,sSr),g(rL,St,null),e(qr,lSr),e(qr,Bo),g(tL,Bo,null),e(Bo,iSr),e(Bo,L7e),e(L7e,dSr),e(Bo,cSr),e(Bo,$n),e($n,fSr),e($n,x7e),e(x7e,mSr),e($n,gSr),e($n,k7e),e(k7e,hSr),e($n,pSr),e($n,S7e),e(S7e,_Sr),e($n,uSr),e(Bo,bSr),e(Bo,Ee),e(Ee,lE),e(lE,R7e),e(R7e,vSr),e(lE,FSr),e(lE,yU),e(yU,TSr),e(lE,MSr),e(Ee,ESr),e(Ee,iE),e(iE,B7e),e(B7e,CSr),e(iE,wSr),e(iE,LU),e(LU,ASr),e(iE,ySr),e(Ee,LSr),e(Ee,dE),e(dE,P7e),e(P7e,xSr),e(dE,kSr),e(dE,xU),e(xU,SSr),e(dE,RSr),e(Ee,BSr),e(Ee,cE),e(cE,$7e),e($7e,PSr),e(cE,$Sr),e(cE,kU),e(kU,ISr),e(cE,qSr),e(Ee,NSr),e(Ee,fE),e(fE,I7e),e(I7e,jSr),e(fE,DSr),e(fE,SU),e(SU,GSr),e(fE,OSr),e(Ee,VSr),e(Ee,mE),e(mE,q7e),e(q7e,XSr),e(mE,zSr),e(mE,RU),e(RU,QSr),e(mE,WSr),e(Ee,HSr),e(Ee,gE),e(gE,N7e),e(N7e,USr),e(gE,JSr),e(gE,BU),e(BU,YSr),e(gE,KSr),e(Ee,ZSr),e(Ee,hE),e(hE,j7e),e(j7e,eRr),e(hE,oRr),e(hE,PU),e(PU,rRr),e(hE,tRr),e(Ee,aRr),e(Ee,pE),e(pE,D7e),e(D7e,nRr),e(pE,sRr),e(pE,$U),e($U,lRr),e(pE,iRr),e(Ee,dRr),e(Ee,_E),e(_E,G7e),e(G7e,cRr),e(_E,fRr),e(_E,IU),e(IU,mRr),e(_E,gRr),e(Bo,hRr),e(Bo,O7e),e(O7e,pRr),e(Bo,_Rr),g(aL,Bo,null),b(c,TIe,u),b(c,Af,u),e(Af,uE),e(uE,V7e),g(nL,V7e,null),e(Af,uRr),e(Af,X7e),e(X7e,bRr),b(c,MIe,u),b(c,Nr,u),g(sL,Nr,null),e(Nr,vRr),e(Nr,yf),e(yf,FRr),e(yf,qU),e(qU,TRr),e(yf,MRr),e(yf,NU),e(NU,ERr),e(yf,CRr),e(Nr,wRr),e(Nr,lL),e(lL,ARr),e(lL,z7e),e(z7e,yRr),e(lL,LRr),e(Nr,xRr),e(Nr,Rt),g(iL,Rt,null),e(Rt,kRr),e(Rt,Q7e),e(Q7e,SRr),e(Rt,RRr),e(Rt,Lf),e(Lf,BRr),e(Lf,W7e),e(W7e,PRr),e(Lf,$Rr),e(Lf,jU),e(jU,IRr),e(Lf,qRr),e(Rt,NRr),e(Rt,H7e),e(H7e,jRr),e(Rt,DRr),g(dL,Rt,null),e(Nr,GRr),e(Nr,Po),g(cL,Po,null),e(Po,ORr),e(Po,U7e),e(U7e,VRr),e(Po,XRr),e(Po,In),e(In,zRr),e(In,J7e),e(J7e,QRr),e(In,WRr),e(In,Y7e),e(Y7e,HRr),e(In,URr),e(In,K7e),e(K7e,JRr),e(In,YRr),e(Po,KRr),e(Po,Ce),e(Ce,bE),e(bE,Z7e),e(Z7e,ZRr),e(bE,eBr),e(bE,DU),e(DU,oBr),e(bE,rBr),e(Ce,tBr),e(Ce,vE),e(vE,e9e),e(e9e,aBr),e(vE,nBr),e(vE,GU),e(GU,sBr),e(vE,lBr),e(Ce,iBr),e(Ce,FE),e(FE,o9e),e(o9e,dBr),e(FE,cBr),e(FE,OU),e(OU,fBr),e(FE,mBr),e(Ce,gBr),e(Ce,TE),e(TE,r9e),e(r9e,hBr),e(TE,pBr),e(TE,VU),e(VU,_Br),e(TE,uBr),e(Ce,bBr),e(Ce,ME),e(ME,t9e),e(t9e,vBr),e(ME,FBr),e(ME,XU),e(XU,TBr),e(ME,MBr),e(Ce,EBr),e(Ce,EE),e(EE,a9e),e(a9e,CBr),e(EE,wBr),e(EE,zU),e(zU,ABr),e(EE,yBr),e(Ce,LBr),e(Ce,CE),e(CE,n9e),e(n9e,xBr),e(CE,kBr),e(CE,QU),e(QU,SBr),e(CE,RBr),e(Ce,BBr),e(Ce,wE),e(wE,s9e),e(s9e,PBr),e(wE,$Br),e(wE,WU),e(WU,IBr),e(wE,qBr),e(Ce,NBr),e(Ce,AE),e(AE,l9e),e(l9e,jBr),e(AE,DBr),e(AE,HU),e(HU,GBr),e(AE,OBr),e(Ce,VBr),e(Ce,yE),e(yE,i9e),e(i9e,XBr),e(yE,zBr),e(yE,UU),e(UU,QBr),e(yE,WBr),e(Po,HBr),e(Po,d9e),e(d9e,UBr),e(Po,JBr),g(fL,Po,null),b(c,EIe,u),b(c,xf,u),e(xf,LE),e(LE,c9e),g(mL,c9e,null),e(xf,YBr),e(xf,f9e),e(f9e,KBr),b(c,CIe,u),b(c,jr,u),g(gL,jr,null),e(jr,ZBr),e(jr,kf),e(kf,ePr),e(kf,JU),e(JU,oPr),e(kf,rPr),e(kf,YU),e(YU,tPr),e(kf,aPr),e(jr,nPr),e(jr,hL),e(hL,sPr),e(hL,m9e),e(m9e,lPr),e(hL,iPr),e(jr,dPr),e(jr,Bt),g(pL,Bt,null),e(Bt,cPr),e(Bt,g9e),e(g9e,fPr),e(Bt,mPr),e(Bt,Sf),e(Sf,gPr),e(Sf,h9e),e(h9e,hPr),e(Sf,pPr),e(Sf,KU),e(KU,_Pr),e(Sf,uPr),e(Bt,bPr),e(Bt,p9e),e(p9e,vPr),e(Bt,FPr),g(_L,Bt,null),e(jr,TPr),e(jr,$o),g(uL,$o,null),e($o,MPr),e($o,_9e),e(_9e,EPr),e($o,CPr),e($o,qn),e(qn,wPr),e(qn,u9e),e(u9e,APr),e(qn,yPr),e(qn,b9e),e(b9e,LPr),e(qn,xPr),e(qn,v9e),e(v9e,kPr),e(qn,SPr),e($o,RPr),e($o,$e),e($e,xE),e(xE,F9e),e(F9e,BPr),e(xE,PPr),e(xE,ZU),e(ZU,$Pr),e(xE,IPr),e($e,qPr),e($e,kE),e(kE,T9e),e(T9e,NPr),e(kE,jPr),e(kE,eJ),e(eJ,DPr),e(kE,GPr),e($e,OPr),e($e,SE),e(SE,M9e),e(M9e,VPr),e(SE,XPr),e(SE,oJ),e(oJ,zPr),e(SE,QPr),e($e,WPr),e($e,RE),e(RE,E9e),e(E9e,HPr),e(RE,UPr),e(RE,rJ),e(rJ,JPr),e(RE,YPr),e($e,KPr),e($e,BE),e(BE,C9e),e(C9e,ZPr),e(BE,e$r),e(BE,tJ),e(tJ,o$r),e(BE,r$r),e($e,t$r),e($e,PE),e(PE,w9e),e(w9e,a$r),e(PE,n$r),e(PE,aJ),e(aJ,s$r),e(PE,l$r),e($e,i$r),e($e,$E),e($E,A9e),e(A9e,d$r),e($E,c$r),e($E,nJ),e(nJ,f$r),e($E,m$r),e($e,g$r),e($e,IE),e(IE,y9e),e(y9e,h$r),e(IE,p$r),e(IE,sJ),e(sJ,_$r),e(IE,u$r),e($o,b$r),e($o,L9e),e(L9e,v$r),e($o,F$r),g(bL,$o,null),b(c,wIe,u),b(c,Rf,u),e(Rf,qE),e(qE,x9e),g(vL,x9e,null),e(Rf,T$r),e(Rf,k9e),e(k9e,M$r),b(c,AIe,u),b(c,Dr,u),g(FL,Dr,null),e(Dr,E$r),e(Dr,Bf),e(Bf,C$r),e(Bf,lJ),e(lJ,w$r),e(Bf,A$r),e(Bf,iJ),e(iJ,y$r),e(Bf,L$r),e(Dr,x$r),e(Dr,TL),e(TL,k$r),e(TL,S9e),e(S9e,S$r),e(TL,R$r),e(Dr,B$r),e(Dr,Pt),g(ML,Pt,null),e(Pt,P$r),e(Pt,R9e),e(R9e,$$r),e(Pt,I$r),e(Pt,Pf),e(Pf,q$r),e(Pf,B9e),e(B9e,N$r),e(Pf,j$r),e(Pf,dJ),e(dJ,D$r),e(Pf,G$r),e(Pt,O$r),e(Pt,P9e),e(P9e,V$r),e(Pt,X$r),g(EL,Pt,null),e(Dr,z$r),e(Dr,Io),g(CL,Io,null),e(Io,Q$r),e(Io,$9e),e($9e,W$r),e(Io,H$r),e(Io,Nn),e(Nn,U$r),e(Nn,I9e),e(I9e,J$r),e(Nn,Y$r),e(Nn,q9e),e(q9e,K$r),e(Nn,Z$r),e(Nn,N9e),e(N9e,eIr),e(Nn,oIr),e(Io,rIr),e(Io,Ie),e(Ie,NE),e(NE,j9e),e(j9e,tIr),e(NE,aIr),e(NE,cJ),e(cJ,nIr),e(NE,sIr),e(Ie,lIr),e(Ie,jE),e(jE,D9e),e(D9e,iIr),e(jE,dIr),e(jE,fJ),e(fJ,cIr),e(jE,fIr),e(Ie,mIr),e(Ie,DE),e(DE,G9e),e(G9e,gIr),e(DE,hIr),e(DE,mJ),e(mJ,pIr),e(DE,_Ir),e(Ie,uIr),e(Ie,GE),e(GE,O9e),e(O9e,bIr),e(GE,vIr),e(GE,gJ),e(gJ,FIr),e(GE,TIr),e(Ie,MIr),e(Ie,OE),e(OE,V9e),e(V9e,EIr),e(OE,CIr),e(OE,hJ),e(hJ,wIr),e(OE,AIr),e(Ie,yIr),e(Ie,VE),e(VE,X9e),e(X9e,LIr),e(VE,xIr),e(VE,pJ),e(pJ,kIr),e(VE,SIr),e(Ie,RIr),e(Ie,XE),e(XE,z9e),e(z9e,BIr),e(XE,PIr),e(XE,_J),e(_J,$Ir),e(XE,IIr),e(Ie,qIr),e(Ie,zE),e(zE,Q9e),e(Q9e,NIr),e(zE,jIr),e(zE,uJ),e(uJ,DIr),e(zE,GIr),e(Io,OIr),e(Io,W9e),e(W9e,VIr),e(Io,XIr),g(wL,Io,null),b(c,yIe,u),b(c,$f,u),e($f,QE),e(QE,H9e),g(AL,H9e,null),e($f,zIr),e($f,U9e),e(U9e,QIr),b(c,LIe,u),b(c,Gr,u),g(yL,Gr,null),e(Gr,WIr),e(Gr,If),e(If,HIr),e(If,bJ),e(bJ,UIr),e(If,JIr),e(If,vJ),e(vJ,YIr),e(If,KIr),e(Gr,ZIr),e(Gr,LL),e(LL,eqr),e(LL,J9e),e(J9e,oqr),e(LL,rqr),e(Gr,tqr),e(Gr,$t),g(xL,$t,null),e($t,aqr),e($t,Y9e),e(Y9e,nqr),e($t,sqr),e($t,qf),e(qf,lqr),e(qf,K9e),e(K9e,iqr),e(qf,dqr),e(qf,FJ),e(FJ,cqr),e(qf,fqr),e($t,mqr),e($t,Z9e),e(Z9e,gqr),e($t,hqr),g(kL,$t,null),e(Gr,pqr),e(Gr,qo),g(SL,qo,null),e(qo,_qr),e(qo,eMe),e(eMe,uqr),e(qo,bqr),e(qo,jn),e(jn,vqr),e(jn,oMe),e(oMe,Fqr),e(jn,Tqr),e(jn,rMe),e(rMe,Mqr),e(jn,Eqr),e(jn,tMe),e(tMe,Cqr),e(jn,wqr),e(qo,Aqr),e(qo,aMe),e(aMe,WE),e(WE,nMe),e(nMe,yqr),e(WE,Lqr),e(WE,TJ),e(TJ,xqr),e(WE,kqr),e(qo,Sqr),e(qo,sMe),e(sMe,Rqr),e(qo,Bqr),g(RL,qo,null),b(c,xIe,u),b(c,Nf,u),e(Nf,HE),e(HE,lMe),g(BL,lMe,null),e(Nf,Pqr),e(Nf,iMe),e(iMe,$qr),b(c,kIe,u),b(c,Or,u),g(PL,Or,null),e(Or,Iqr),e(Or,jf),e(jf,qqr),e(jf,MJ),e(MJ,Nqr),e(jf,jqr),e(jf,EJ),e(EJ,Dqr),e(jf,Gqr),e(Or,Oqr),e(Or,$L),e($L,Vqr),e($L,dMe),e(dMe,Xqr),e($L,zqr),e(Or,Qqr),e(Or,It),g(IL,It,null),e(It,Wqr),e(It,cMe),e(cMe,Hqr),e(It,Uqr),e(It,Df),e(Df,Jqr),e(Df,fMe),e(fMe,Yqr),e(Df,Kqr),e(Df,CJ),e(CJ,Zqr),e(Df,eNr),e(It,oNr),e(It,mMe),e(mMe,rNr),e(It,tNr),g(qL,It,null),e(Or,aNr),e(Or,No),g(NL,No,null),e(No,nNr),e(No,gMe),e(gMe,sNr),e(No,lNr),e(No,Dn),e(Dn,iNr),e(Dn,hMe),e(hMe,dNr),e(Dn,cNr),e(Dn,pMe),e(pMe,fNr),e(Dn,mNr),e(Dn,_Me),e(_Me,gNr),e(Dn,hNr),e(No,pNr),e(No,jL),e(jL,UE),e(UE,uMe),e(uMe,_Nr),e(UE,uNr),e(UE,wJ),e(wJ,bNr),e(UE,vNr),e(jL,FNr),e(jL,JE),e(JE,bMe),e(bMe,TNr),e(JE,MNr),e(JE,AJ),e(AJ,ENr),e(JE,CNr),e(No,wNr),e(No,vMe),e(vMe,ANr),e(No,yNr),g(DL,No,null),b(c,SIe,u),b(c,Gf,u),e(Gf,YE),e(YE,FMe),g(GL,FMe,null),e(Gf,LNr),e(Gf,TMe),e(TMe,xNr),b(c,RIe,u),b(c,Vr,u),g(OL,Vr,null),e(Vr,kNr),e(Vr,Of),e(Of,SNr),e(Of,yJ),e(yJ,RNr),e(Of,BNr),e(Of,LJ),e(LJ,PNr),e(Of,$Nr),e(Vr,INr),e(Vr,VL),e(VL,qNr),e(VL,MMe),e(MMe,NNr),e(VL,jNr),e(Vr,DNr),e(Vr,qt),g(XL,qt,null),e(qt,GNr),e(qt,EMe),e(EMe,ONr),e(qt,VNr),e(qt,Vf),e(Vf,XNr),e(Vf,CMe),e(CMe,zNr),e(Vf,QNr),e(Vf,xJ),e(xJ,WNr),e(Vf,HNr),e(qt,UNr),e(qt,wMe),e(wMe,JNr),e(qt,YNr),g(zL,qt,null),e(Vr,KNr),e(Vr,jo),g(QL,jo,null),e(jo,ZNr),e(jo,AMe),e(AMe,ejr),e(jo,ojr),e(jo,Gn),e(Gn,rjr),e(Gn,yMe),e(yMe,tjr),e(Gn,ajr),e(Gn,LMe),e(LMe,njr),e(Gn,sjr),e(Gn,xMe),e(xMe,ljr),e(Gn,ijr),e(jo,djr),e(jo,kMe),e(kMe,KE),e(KE,SMe),e(SMe,cjr),e(KE,fjr),e(KE,kJ),e(kJ,mjr),e(KE,gjr),e(jo,hjr),e(jo,RMe),e(RMe,pjr),e(jo,_jr),g(WL,jo,null),BIe=!0},p(c,[u]){const HL={};u&2&&(HL.$$scope={dirty:u,ctx:c}),Yf.$set(HL);const BMe={};u&2&&(BMe.$$scope={dirty:u,ctx:c}),Jh.$set(BMe);const PMe={};u&2&&(PMe.$$scope={dirty:u,ctx:c}),gp.$set(PMe)},i(c){BIe||(h(ue.$$.fragment,c),h(Da.$$.fragment,c),h(t3.$$.fragment,c),h(a3.$$.fragment,c),h(Yf.$$.fragment,c),h(n3.$$.fragment,c),h(s3.$$.fragment,c),h(d3.$$.fragment,c),h(c3.$$.fragment,c),h(f3.$$.fragment,c),h(m3.$$.fragment,c),h(g3.$$.fragment,c),h(_3.$$.fragment,c),h(u3.$$.fragment,c),h(b3.$$.fragment,c),h(v3.$$.fragment,c),h(F3.$$.fragment,c),h(E3.$$.fragment,c),h(Jh.$$.fragment,c),h(C3.$$.fragment,c),h(w3.$$.fragment,c),h(A3.$$.fragment,c),h(y3.$$.fragment,c),h(k3.$$.fragment,c),h(gp.$$.fragment,c),h(S3.$$.fragment,c),h(R3.$$.fragment,c),h(B3.$$.fragment,c),h(P3.$$.fragment,c),h(I3.$$.fragment,c),h(q3.$$.fragment,c),h(N3.$$.fragment,c),h(j3.$$.fragment,c),h(D3.$$.fragment,c),h(G3.$$.fragment,c),h(V3.$$.fragment,c),h(X3.$$.fragment,c),h(z3.$$.fragment,c),h(Q3.$$.fragment,c),h(W3.$$.fragment,c),h(H3.$$.fragment,c),h(J3.$$.fragment,c),h(Y3.$$.fragment,c),h(K3.$$.fragment,c),h(Z3.$$.fragment,c),h(eC.$$.fragment,c),h(oC.$$.fragment,c),h(tC.$$.fragment,c),h(aC.$$.fragment,c),h(nC.$$.fragment,c),h(sC.$$.fragment,c),h(lC.$$.fragment,c),h(iC.$$.fragment,c),h(cC.$$.fragment,c),h(fC.$$.fragment,c),h(mC.$$.fragment,c),h(gC.$$.fragment,c),h(hC.$$.fragment,c),h(pC.$$.fragment,c),h(uC.$$.fragment,c),h(bC.$$.fragment,c),h(vC.$$.fragment,c),h(FC.$$.fragment,c),h(TC.$$.fragment,c),h(MC.$$.fragment,c),h(CC.$$.fragment,c),h(wC.$$.fragment,c),h(AC.$$.fragment,c),h(yC.$$.fragment,c),h(LC.$$.fragment,c),h(xC.$$.fragment,c),h(SC.$$.fragment,c),h(RC.$$.fragment,c),h(BC.$$.fragment,c),h(PC.$$.fragment,c),h($C.$$.fragment,c),h(IC.$$.fragment,c),h(NC.$$.fragment,c),h(jC.$$.fragment,c),h(DC.$$.fragment,c),h(GC.$$.fragment,c),h(OC.$$.fragment,c),h(VC.$$.fragment,c),h(zC.$$.fragment,c),h(QC.$$.fragment,c),h(WC.$$.fragment,c),h(HC.$$.fragment,c),h(UC.$$.fragment,c),h(JC.$$.fragment,c),h(KC.$$.fragment,c),h(ZC.$$.fragment,c),h(ew.$$.fragment,c),h(ow.$$.fragment,c),h(rw.$$.fragment,c),h(tw.$$.fragment,c),h(nw.$$.fragment,c),h(sw.$$.fragment,c),h(lw.$$.fragment,c),h(iw.$$.fragment,c),h(dw.$$.fragment,c),h(cw.$$.fragment,c),h(mw.$$.fragment,c),h(gw.$$.fragment,c),h(hw.$$.fragment,c),h(pw.$$.fragment,c),h(_w.$$.fragment,c),h(uw.$$.fragment,c),h(vw.$$.fragment,c),h(Fw.$$.fragment,c),h(Tw.$$.fragment,c),h(Mw.$$.fragment,c),h(Ew.$$.fragment,c),h(Cw.$$.fragment,c),h(Aw.$$.fragment,c),h(yw.$$.fragment,c),h(Lw.$$.fragment,c),h(xw.$$.fragment,c),h(kw.$$.fragment,c),h(Sw.$$.fragment,c),h(Bw.$$.fragment,c),h(Pw.$$.fragment,c),h($w.$$.fragment,c),h(Iw.$$.fragment,c),h(qw.$$.fragment,c),h(Nw.$$.fragment,c),h(Dw.$$.fragment,c),h(Gw.$$.fragment,c),h(Ow.$$.fragment,c),h(Xw.$$.fragment,c),h(zw.$$.fragment,c),h(Qw.$$.fragment,c),h(Hw.$$.fragment,c),h(Uw.$$.fragment,c),h(Jw.$$.fragment,c),h(Yw.$$.fragment,c),h(Kw.$$.fragment,c),h(Zw.$$.fragment,c),h(o0.$$.fragment,c),h(r0.$$.fragment,c),h(t0.$$.fragment,c),h(a0.$$.fragment,c),h(n0.$$.fragment,c),h(s0.$$.fragment,c),h(i0.$$.fragment,c),h(d0.$$.fragment,c),h(c0.$$.fragment,c),h(f0.$$.fragment,c),h(m0.$$.fragment,c),h(g0.$$.fragment,c),h(p0.$$.fragment,c),h(_0.$$.fragment,c),h(u0.$$.fragment,c),h(b0.$$.fragment,c),h(v0.$$.fragment,c),h(F0.$$.fragment,c),h(M0.$$.fragment,c),h(E0.$$.fragment,c),h(C0.$$.fragment,c),h(w0.$$.fragment,c),h(A0.$$.fragment,c),h(y0.$$.fragment,c),h(x0.$$.fragment,c),h(k0.$$.fragment,c),h(S0.$$.fragment,c),h(R0.$$.fragment,c),h(B0.$$.fragment,c),h(P0.$$.fragment,c),h(I0.$$.fragment,c),h(q0.$$.fragment,c),h(N0.$$.fragment,c),h(j0.$$.fragment,c),h(D0.$$.fragment,c),h(G0.$$.fragment,c),h(V0.$$.fragment,c),h(X0.$$.fragment,c),h(z0.$$.fragment,c),h(Q0.$$.fragment,c),h(W0.$$.fragment,c),h(H0.$$.fragment,c),h(J0.$$.fragment,c),h(Y0.$$.fragment,c),h(K0.$$.fragment,c),h(Z0.$$.fragment,c),h(eA.$$.fragment,c),h(oA.$$.fragment,c),h(tA.$$.fragment,c),h(aA.$$.fragment,c),h(nA.$$.fragment,c),h(lA.$$.fragment,c),h(iA.$$.fragment,c),h(dA.$$.fragment,c),h(fA.$$.fragment,c),h(mA.$$.fragment,c),h(gA.$$.fragment,c),h(hA.$$.fragment,c),h(pA.$$.fragment,c),h(_A.$$.fragment,c),h(bA.$$.fragment,c),h(vA.$$.fragment,c),h(FA.$$.fragment,c),h(TA.$$.fragment,c),h(MA.$$.fragment,c),h(EA.$$.fragment,c),h(wA.$$.fragment,c),h(AA.$$.fragment,c),h(yA.$$.fragment,c),h(LA.$$.fragment,c),h(xA.$$.fragment,c),h(kA.$$.fragment,c),h(RA.$$.fragment,c),h(BA.$$.fragment,c),h(PA.$$.fragment,c),h($A.$$.fragment,c),h(IA.$$.fragment,c),h(qA.$$.fragment,c),h(jA.$$.fragment,c),h(DA.$$.fragment,c),h(GA.$$.fragment,c),h(OA.$$.fragment,c),h(VA.$$.fragment,c),h(XA.$$.fragment,c),h(QA.$$.fragment,c),h(WA.$$.fragment,c),h(HA.$$.fragment,c),h(UA.$$.fragment,c),h(JA.$$.fragment,c),h(YA.$$.fragment,c),h(ZA.$$.fragment,c),h(ey.$$.fragment,c),h(oy.$$.fragment,c),h(ry.$$.fragment,c),h(ty.$$.fragment,c),h(ay.$$.fragment,c),h(sy.$$.fragment,c),h(ly.$$.fragment,c),h(iy.$$.fragment,c),h(dy.$$.fragment,c),h(cy.$$.fragment,c),h(fy.$$.fragment,c),h(gy.$$.fragment,c),h(hy.$$.fragment,c),h(py.$$.fragment,c),h(_y.$$.fragment,c),h(uy.$$.fragment,c),h(by.$$.fragment,c),h(Fy.$$.fragment,c),h(Ty.$$.fragment,c),h(My.$$.fragment,c),h(Ey.$$.fragment,c),h(Cy.$$.fragment,c),h(wy.$$.fragment,c),h(yy.$$.fragment,c),h(Ly.$$.fragment,c),h(xy.$$.fragment,c),h(ky.$$.fragment,c),h(Sy.$$.fragment,c),h(Ry.$$.fragment,c),h(Py.$$.fragment,c),h($y.$$.fragment,c),h(Iy.$$.fragment,c),h(qy.$$.fragment,c),h(Ny.$$.fragment,c),h(jy.$$.fragment,c),h(Gy.$$.fragment,c),h(Oy.$$.fragment,c),h(Vy.$$.fragment,c),h(Xy.$$.fragment,c),h(zy.$$.fragment,c),h(Qy.$$.fragment,c),h(Hy.$$.fragment,c),h(Uy.$$.fragment,c),h(Jy.$$.fragment,c),h(Yy.$$.fragment,c),h(Ky.$$.fragment,c),h(Zy.$$.fragment,c),h(oL.$$.fragment,c),h(rL.$$.fragment,c),h(tL.$$.fragment,c),h(aL.$$.fragment,c),h(nL.$$.fragment,c),h(sL.$$.fragment,c),h(iL.$$.fragment,c),h(dL.$$.fragment,c),h(cL.$$.fragment,c),h(fL.$$.fragment,c),h(mL.$$.fragment,c),h(gL.$$.fragment,c),h(pL.$$.fragment,c),h(_L.$$.fragment,c),h(uL.$$.fragment,c),h(bL.$$.fragment,c),h(vL.$$.fragment,c),h(FL.$$.fragment,c),h(ML.$$.fragment,c),h(EL.$$.fragment,c),h(CL.$$.fragment,c),h(wL.$$.fragment,c),h(AL.$$.fragment,c),h(yL.$$.fragment,c),h(xL.$$.fragment,c),h(kL.$$.fragment,c),h(SL.$$.fragment,c),h(RL.$$.fragment,c),h(BL.$$.fragment,c),h(PL.$$.fragment,c),h(IL.$$.fragment,c),h(qL.$$.fragment,c),h(NL.$$.fragment,c),h(DL.$$.fragment,c),h(GL.$$.fragment,c),h(OL.$$.fragment,c),h(XL.$$.fragment,c),h(zL.$$.fragment,c),h(QL.$$.fragment,c),h(WL.$$.fragment,c),BIe=!0)},o(c){p(ue.$$.fragment,c),p(Da.$$.fragment,c),p(t3.$$.fragment,c),p(a3.$$.fragment,c),p(Yf.$$.fragment,c),p(n3.$$.fragment,c),p(s3.$$.fragment,c),p(d3.$$.fragment,c),p(c3.$$.fragment,c),p(f3.$$.fragment,c),p(m3.$$.fragment,c),p(g3.$$.fragment,c),p(_3.$$.fragment,c),p(u3.$$.fragment,c),p(b3.$$.fragment,c),p(v3.$$.fragment,c),p(F3.$$.fragment,c),p(E3.$$.fragment,c),p(Jh.$$.fragment,c),p(C3.$$.fragment,c),p(w3.$$.fragment,c),p(A3.$$.fragment,c),p(y3.$$.fragment,c),p(k3.$$.fragment,c),p(gp.$$.fragment,c),p(S3.$$.fragment,c),p(R3.$$.fragment,c),p(B3.$$.fragment,c),p(P3.$$.fragment,c),p(I3.$$.fragment,c),p(q3.$$.fragment,c),p(N3.$$.fragment,c),p(j3.$$.fragment,c),p(D3.$$.fragment,c),p(G3.$$.fragment,c),p(V3.$$.fragment,c),p(X3.$$.fragment,c),p(z3.$$.fragment,c),p(Q3.$$.fragment,c),p(W3.$$.fragment,c),p(H3.$$.fragment,c),p(J3.$$.fragment,c),p(Y3.$$.fragment,c),p(K3.$$.fragment,c),p(Z3.$$.fragment,c),p(eC.$$.fragment,c),p(oC.$$.fragment,c),p(tC.$$.fragment,c),p(aC.$$.fragment,c),p(nC.$$.fragment,c),p(sC.$$.fragment,c),p(lC.$$.fragment,c),p(iC.$$.fragment,c),p(cC.$$.fragment,c),p(fC.$$.fragment,c),p(mC.$$.fragment,c),p(gC.$$.fragment,c),p(hC.$$.fragment,c),p(pC.$$.fragment,c),p(uC.$$.fragment,c),p(bC.$$.fragment,c),p(vC.$$.fragment,c),p(FC.$$.fragment,c),p(TC.$$.fragment,c),p(MC.$$.fragment,c),p(CC.$$.fragment,c),p(wC.$$.fragment,c),p(AC.$$.fragment,c),p(yC.$$.fragment,c),p(LC.$$.fragment,c),p(xC.$$.fragment,c),p(SC.$$.fragment,c),p(RC.$$.fragment,c),p(BC.$$.fragment,c),p(PC.$$.fragment,c),p($C.$$.fragment,c),p(IC.$$.fragment,c),p(NC.$$.fragment,c),p(jC.$$.fragment,c),p(DC.$$.fragment,c),p(GC.$$.fragment,c),p(OC.$$.fragment,c),p(VC.$$.fragment,c),p(zC.$$.fragment,c),p(QC.$$.fragment,c),p(WC.$$.fragment,c),p(HC.$$.fragment,c),p(UC.$$.fragment,c),p(JC.$$.fragment,c),p(KC.$$.fragment,c),p(ZC.$$.fragment,c),p(ew.$$.fragment,c),p(ow.$$.fragment,c),p(rw.$$.fragment,c),p(tw.$$.fragment,c),p(nw.$$.fragment,c),p(sw.$$.fragment,c),p(lw.$$.fragment,c),p(iw.$$.fragment,c),p(dw.$$.fragment,c),p(cw.$$.fragment,c),p(mw.$$.fragment,c),p(gw.$$.fragment,c),p(hw.$$.fragment,c),p(pw.$$.fragment,c),p(_w.$$.fragment,c),p(uw.$$.fragment,c),p(vw.$$.fragment,c),p(Fw.$$.fragment,c),p(Tw.$$.fragment,c),p(Mw.$$.fragment,c),p(Ew.$$.fragment,c),p(Cw.$$.fragment,c),p(Aw.$$.fragment,c),p(yw.$$.fragment,c),p(Lw.$$.fragment,c),p(xw.$$.fragment,c),p(kw.$$.fragment,c),p(Sw.$$.fragment,c),p(Bw.$$.fragment,c),p(Pw.$$.fragment,c),p($w.$$.fragment,c),p(Iw.$$.fragment,c),p(qw.$$.fragment,c),p(Nw.$$.fragment,c),p(Dw.$$.fragment,c),p(Gw.$$.fragment,c),p(Ow.$$.fragment,c),p(Xw.$$.fragment,c),p(zw.$$.fragment,c),p(Qw.$$.fragment,c),p(Hw.$$.fragment,c),p(Uw.$$.fragment,c),p(Jw.$$.fragment,c),p(Yw.$$.fragment,c),p(Kw.$$.fragment,c),p(Zw.$$.fragment,c),p(o0.$$.fragment,c),p(r0.$$.fragment,c),p(t0.$$.fragment,c),p(a0.$$.fragment,c),p(n0.$$.fragment,c),p(s0.$$.fragment,c),p(i0.$$.fragment,c),p(d0.$$.fragment,c),p(c0.$$.fragment,c),p(f0.$$.fragment,c),p(m0.$$.fragment,c),p(g0.$$.fragment,c),p(p0.$$.fragment,c),p(_0.$$.fragment,c),p(u0.$$.fragment,c),p(b0.$$.fragment,c),p(v0.$$.fragment,c),p(F0.$$.fragment,c),p(M0.$$.fragment,c),p(E0.$$.fragment,c),p(C0.$$.fragment,c),p(w0.$$.fragment,c),p(A0.$$.fragment,c),p(y0.$$.fragment,c),p(x0.$$.fragment,c),p(k0.$$.fragment,c),p(S0.$$.fragment,c),p(R0.$$.fragment,c),p(B0.$$.fragment,c),p(P0.$$.fragment,c),p(I0.$$.fragment,c),p(q0.$$.fragment,c),p(N0.$$.fragment,c),p(j0.$$.fragment,c),p(D0.$$.fragment,c),p(G0.$$.fragment,c),p(V0.$$.fragment,c),p(X0.$$.fragment,c),p(z0.$$.fragment,c),p(Q0.$$.fragment,c),p(W0.$$.fragment,c),p(H0.$$.fragment,c),p(J0.$$.fragment,c),p(Y0.$$.fragment,c),p(K0.$$.fragment,c),p(Z0.$$.fragment,c),p(eA.$$.fragment,c),p(oA.$$.fragment,c),p(tA.$$.fragment,c),p(aA.$$.fragment,c),p(nA.$$.fragment,c),p(lA.$$.fragment,c),p(iA.$$.fragment,c),p(dA.$$.fragment,c),p(fA.$$.fragment,c),p(mA.$$.fragment,c),p(gA.$$.fragment,c),p(hA.$$.fragment,c),p(pA.$$.fragment,c),p(_A.$$.fragment,c),p(bA.$$.fragment,c),p(vA.$$.fragment,c),p(FA.$$.fragment,c),p(TA.$$.fragment,c),p(MA.$$.fragment,c),p(EA.$$.fragment,c),p(wA.$$.fragment,c),p(AA.$$.fragment,c),p(yA.$$.fragment,c),p(LA.$$.fragment,c),p(xA.$$.fragment,c),p(kA.$$.fragment,c),p(RA.$$.fragment,c),p(BA.$$.fragment,c),p(PA.$$.fragment,c),p($A.$$.fragment,c),p(IA.$$.fragment,c),p(qA.$$.fragment,c),p(jA.$$.fragment,c),p(DA.$$.fragment,c),p(GA.$$.fragment,c),p(OA.$$.fragment,c),p(VA.$$.fragment,c),p(XA.$$.fragment,c),p(QA.$$.fragment,c),p(WA.$$.fragment,c),p(HA.$$.fragment,c),p(UA.$$.fragment,c),p(JA.$$.fragment,c),p(YA.$$.fragment,c),p(ZA.$$.fragment,c),p(ey.$$.fragment,c),p(oy.$$.fragment,c),p(ry.$$.fragment,c),p(ty.$$.fragment,c),p(ay.$$.fragment,c),p(sy.$$.fragment,c),p(ly.$$.fragment,c),p(iy.$$.fragment,c),p(dy.$$.fragment,c),p(cy.$$.fragment,c),p(fy.$$.fragment,c),p(gy.$$.fragment,c),p(hy.$$.fragment,c),p(py.$$.fragment,c),p(_y.$$.fragment,c),p(uy.$$.fragment,c),p(by.$$.fragment,c),p(Fy.$$.fragment,c),p(Ty.$$.fragment,c),p(My.$$.fragment,c),p(Ey.$$.fragment,c),p(Cy.$$.fragment,c),p(wy.$$.fragment,c),p(yy.$$.fragment,c),p(Ly.$$.fragment,c),p(xy.$$.fragment,c),p(ky.$$.fragment,c),p(Sy.$$.fragment,c),p(Ry.$$.fragment,c),p(Py.$$.fragment,c),p($y.$$.fragment,c),p(Iy.$$.fragment,c),p(qy.$$.fragment,c),p(Ny.$$.fragment,c),p(jy.$$.fragment,c),p(Gy.$$.fragment,c),p(Oy.$$.fragment,c),p(Vy.$$.fragment,c),p(Xy.$$.fragment,c),p(zy.$$.fragment,c),p(Qy.$$.fragment,c),p(Hy.$$.fragment,c),p(Uy.$$.fragment,c),p(Jy.$$.fragment,c),p(Yy.$$.fragment,c),p(Ky.$$.fragment,c),p(Zy.$$.fragment,c),p(oL.$$.fragment,c),p(rL.$$.fragment,c),p(tL.$$.fragment,c),p(aL.$$.fragment,c),p(nL.$$.fragment,c),p(sL.$$.fragment,c),p(iL.$$.fragment,c),p(dL.$$.fragment,c),p(cL.$$.fragment,c),p(fL.$$.fragment,c),p(mL.$$.fragment,c),p(gL.$$.fragment,c),p(pL.$$.fragment,c),p(_L.$$.fragment,c),p(uL.$$.fragment,c),p(bL.$$.fragment,c),p(vL.$$.fragment,c),p(FL.$$.fragment,c),p(ML.$$.fragment,c),p(EL.$$.fragment,c),p(CL.$$.fragment,c),p(wL.$$.fragment,c),p(AL.$$.fragment,c),p(yL.$$.fragment,c),p(xL.$$.fragment,c),p(kL.$$.fragment,c),p(SL.$$.fragment,c),p(RL.$$.fragment,c),p(BL.$$.fragment,c),p(PL.$$.fragment,c),p(IL.$$.fragment,c),p(qL.$$.fragment,c),p(NL.$$.fragment,c),p(DL.$$.fragment,c),p(GL.$$.fragment,c),p(OL.$$.fragment,c),p(XL.$$.fragment,c),p(zL.$$.fragment,c),p(QL.$$.fragment,c),p(WL.$$.fragment,c),BIe=!1},d(c){t(oe),c&&t(co),c&&t(ge),_(ue),c&&t(Qf),c&&t(fa),c&&t(Re),c&&t(fo),c&&t(Hf),_(Da,c),c&&t(mo),c&&t(ve),c&&t(zo),c&&t(Ga),c&&t(RPe),c&&t(Zi),_(t3),c&&t(BPe),c&&t(Qn),c&&t(PPe),_(a3,c),c&&t($Pe),c&&t(nx),c&&t(IPe),_(Yf,c),c&&t(qPe),c&&t(ed),_(n3),c&&t(NPe),c&&t(Qo),_(s3),_(d3),_(c3),_(f3),c&&t(jPe),c&&t(rd),_(m3),c&&t(DPe),c&&t(Wo),_(g3),_(_3),_(u3),_(b3),c&&t(GPe),c&&t(td),_(v3),c&&t(OPe),c&&t(Ho),_(F3),_(E3),_(Jh),_(C3),_(w3),c&&t(VPe),c&&t(ad),_(A3),c&&t(XPe),c&&t(Uo),_(y3),_(k3),_(gp),_(S3),_(R3),c&&t(zPe),c&&t(sd),_(B3),c&&t(QPe),c&&t(Jo),_(P3),_(I3),_(q3),_(N3),_(j3),c&&t(WPe),c&&t(dd),_(D3),c&&t(HPe),c&&t(Yo),_(G3),_(V3),_(X3),_(z3),_(Q3),c&&t(UPe),c&&t(md),_(W3),c&&t(JPe),c&&t(Ko),_(H3),_(J3),_(Y3),_(K3),_(Z3),c&&t(YPe),c&&t(pd),_(eC),c&&t(KPe),c&&t(Zo),_(oC),_(tC),_(aC),_(nC),_(sC),c&&t(ZPe),c&&t(bd),_(lC),c&&t(e$e),c&&t(er),_(iC),_(cC),_(fC),_(mC),_(gC),c&&t(o$e),c&&t(Td),_(hC),c&&t(r$e),c&&t(or),_(pC),_(uC),_(bC),_(vC),_(FC),c&&t(t$e),c&&t(Cd),_(TC),c&&t(a$e),c&&t(rr),_(MC),_(CC),_(wC),_(AC),_(yC),c&&t(n$e),c&&t(yd),_(LC),c&&t(s$e),c&&t(tr),_(xC),_(SC),_(RC),_(BC),_(PC),c&&t(l$e),c&&t(kd),_($C),c&&t(i$e),c&&t(ar),_(IC),_(NC),_(jC),_(DC),_(GC),c&&t(d$e),c&&t(Bd),_(OC),c&&t(c$e),c&&t(nr),_(VC),_(zC),_(QC),_(WC),_(HC),c&&t(f$e),c&&t(Id),_(UC),c&&t(m$e),c&&t(sr),_(JC),_(KC),_(ZC),_(ew),_(ow),c&&t(g$e),c&&t(jd),_(rw),c&&t(h$e),c&&t(lr),_(tw),_(nw),_(sw),_(lw),_(iw),c&&t(p$e),c&&t(Od),_(dw),c&&t(_$e),c&&t(ir),_(cw),_(mw),_(gw),_(hw),_(pw),c&&t(u$e),c&&t(zd),_(_w),c&&t(b$e),c&&t(dr),_(uw),_(vw),_(Fw),_(Tw),_(Mw),c&&t(v$e),c&&t(Hd),_(Ew),c&&t(F$e),c&&t(cr),_(Cw),_(Aw),_(yw),_(Lw),_(xw),c&&t(T$e),c&&t(Yd),_(kw),c&&t(M$e),c&&t(fr),_(Sw),_(Bw),_(Pw),_($w),_(Iw),c&&t(E$e),c&&t(ec),_(qw),c&&t(C$e),c&&t(mr),_(Nw),_(Dw),_(Gw),_(Ow),_(Xw),c&&t(w$e),c&&t(tc),_(zw),c&&t(A$e),c&&t(gr),_(Qw),_(Hw),_(Uw),_(Jw),_(Yw),c&&t(y$e),c&&t(sc),_(Kw),c&&t(L$e),c&&t(hr),_(Zw),_(o0),_(r0),_(t0),_(a0),c&&t(x$e),c&&t(cc),_(n0),c&&t(k$e),c&&t(pr),_(s0),_(i0),_(d0),_(c0),_(f0),c&&t(S$e),c&&t(gc),_(m0),c&&t(R$e),c&&t(_r),_(g0),_(p0),_(_0),_(u0),_(b0),c&&t(B$e),c&&t(_c),_(v0),c&&t(P$e),c&&t(ur),_(F0),_(M0),_(E0),_(C0),_(w0),c&&t($$e),c&&t(vc),_(A0),c&&t(I$e),c&&t(br),_(y0),_(x0),_(k0),_(S0),_(R0),c&&t(q$e),c&&t(Mc),_(B0),c&&t(N$e),c&&t(vr),_(P0),_(I0),_(q0),_(N0),_(j0),c&&t(j$e),c&&t(wc),_(D0),c&&t(D$e),c&&t(Fr),_(G0),_(V0),_(X0),_(z0),_(Q0),c&&t(G$e),c&&t(Lc),_(W0),c&&t(O$e),c&&t(Tr),_(H0),_(J0),_(Y0),_(K0),_(Z0),c&&t(V$e),c&&t(Sc),_(eA),c&&t(X$e),c&&t(Mr),_(oA),_(tA),_(aA),_(nA),_(lA),c&&t(z$e),c&&t(Pc),_(iA),c&&t(Q$e),c&&t(Er),_(dA),_(fA),_(mA),_(gA),_(hA),c&&t(W$e),c&&t(qc),_(pA),c&&t(H$e),c&&t(Cr),_(_A),_(bA),_(vA),_(FA),_(TA),c&&t(U$e),c&&t(Dc),_(MA),c&&t(J$e),c&&t(wr),_(EA),_(wA),_(AA),_(yA),_(LA),c&&t(Y$e),c&&t(Vc),_(xA),c&&t(K$e),c&&t(Ar),_(kA),_(RA),_(BA),_(PA),_($A),c&&t(Z$e),c&&t(Qc),_(IA),c&&t(eIe),c&&t(yr),_(qA),_(jA),_(DA),_(GA),_(OA),c&&t(oIe),c&&t(Uc),_(VA),c&&t(rIe),c&&t(Lr),_(XA),_(QA),_(WA),_(HA),_(UA),c&&t(tIe),c&&t(Kc),_(JA),c&&t(aIe),c&&t(xr),_(YA),_(ZA),_(ey),_(oy),_(ry),c&&t(nIe),c&&t(of),_(ty),c&&t(sIe),c&&t(kr),_(ay),_(sy),_(ly),_(iy),_(dy),c&&t(lIe),c&&t(af),_(cy),c&&t(iIe),c&&t(Sr),_(fy),_(gy),_(hy),_(py),_(_y),c&&t(dIe),c&&t(lf),_(uy),c&&t(cIe),c&&t(Rr),_(by),_(Fy),_(Ty),_(My),_(Ey),c&&t(fIe),c&&t(ff),_(Cy),c&&t(mIe),c&&t(Br),_(wy),_(yy),_(Ly),_(xy),_(ky),c&&t(gIe),c&&t(hf),_(Sy),c&&t(hIe),c&&t(Pr),_(Ry),_(Py),_($y),_(Iy),_(qy),c&&t(pIe),c&&t(uf),_(Ny),c&&t(_Ie),c&&t($r),_(jy),_(Gy),_(Oy),_(Vy),_(Xy),c&&t(uIe),c&&t(Ff),_(zy),c&&t(bIe),c&&t(Ir),_(Qy),_(Hy),_(Uy),_(Jy),_(Yy),c&&t(vIe),c&&t(Ef),_(Ky),c&&t(FIe),c&&t(qr),_(Zy),_(oL),_(rL),_(tL),_(aL),c&&t(TIe),c&&t(Af),_(nL),c&&t(MIe),c&&t(Nr),_(sL),_(iL),_(dL),_(cL),_(fL),c&&t(EIe),c&&t(xf),_(mL),c&&t(CIe),c&&t(jr),_(gL),_(pL),_(_L),_(uL),_(bL),c&&t(wIe),c&&t(Rf),_(vL),c&&t(AIe),c&&t(Dr),_(FL),_(ML),_(EL),_(CL),_(wL),c&&t(yIe),c&&t($f),_(AL),c&&t(LIe),c&&t(Gr),_(yL),_(xL),_(kL),_(SL),_(RL),c&&t(xIe),c&&t(Nf),_(BL),c&&t(kIe),c&&t(Or),_(PL),_(IL),_(qL),_(NL),_(DL),c&&t(SIe),c&&t(Gf),_(GL),c&&t(RIe),c&&t(Vr),_(OL),_(XL),_(zL),_(QL),_(WL)}}}const _Lt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function uLt(zf){return fLt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ELt extends lLt{constructor(oe){super();iLt(this,oe,uLt,pLt,dLt,{})}}export{ELt as default,_Lt as metadata};
