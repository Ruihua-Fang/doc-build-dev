import{S as R8t,i as S8t,s as P8t,e as a,k as l,w as f,t as o,M as $8t,c as n,d as t,m as i,a as s,x as m,h as r,b as c,F as e,g as b,y as g,q as h,o as p,B as _}from"../../chunks/vendor-4833417e.js";import{T as Oxr}from"../../chunks/Tip-fffd6df1.js";import{D as M}from"../../chunks/Docstring-4f315ed9.js";import{C as w}from"../../chunks/CodeBlock-6a3d1b46.js";import{I as X}from"../../chunks/IconCopyLink-4b81c553.js";import"../../chunks/CopyButton-dacfbfaf.js";function I8t(Xi){let J,Pe,de,he,io,fe,Fe,zo,Vi,Wf,ha,zi,Wi,s4,Qf,Le,co,Qi,Wn,l4,Qn,Hn,i4,Hi,Un,d4,Ui,Hf,Va;return{c(){J=a("p"),Pe=o("If your "),de=a("code"),he=o("NewModelConfig"),io=o(" is a subclass of "),fe=a("code"),Fe=o("PretrainedConfig"),zo=o(`, make sure its
`),Vi=a("code"),Wf=o("model_type"),ha=o(" attribute is set to the same key you use when registering the config (here "),zi=a("code"),Wi=o('"new-model"'),s4=o(")."),Qf=l(),Le=a("p"),co=o("Likewise, if your "),Qi=a("code"),Wn=o("NewModel"),l4=o(" is a subclass of "),Qn=a("a"),Hn=o("PreTrainedModel"),i4=o(`, make sure its
`),Hi=a("code"),Un=o("config_class"),d4=o(` attribute is set to the same class you use when registering the model (here
`),Ui=a("code"),Hf=o("NewModelConfig"),Va=o(")."),this.h()},l(fo){J=n(fo,"P",{});var pe=s(J);Pe=r(pe,"If your "),de=n(pe,"CODE",{});var s9=s(de);he=r(s9,"NewModelConfig"),s9.forEach(t),io=r(pe," is a subclass of "),fe=n(pe,"CODE",{});var Ji=s(fe);Fe=r(Ji,"PretrainedConfig"),Ji.forEach(t),zo=r(pe,`, make sure its
`),Vi=n(pe,"CODE",{});var l9=s(Vi);Wf=r(l9,"model_type"),l9.forEach(t),ha=r(pe," attribute is set to the same key you use when registering the config (here "),zi=n(pe,"CODE",{});var i9=s(zi);Wi=r(i9,'"new-model"'),i9.forEach(t),s4=r(pe,")."),pe.forEach(t),Qf=i(fo),Le=n(fo,"P",{});var Wo=s(Le);co=r(Wo,"Likewise, if your "),Qi=n(Wo,"CODE",{});var za=s(Qi);Wn=r(za,"NewModel"),za.forEach(t),l4=r(Wo," is a subclass of "),Qn=n(Wo,"A",{href:!0});var d9=s(Qn);Hn=r(d9,"PreTrainedModel"),d9.forEach(t),i4=r(Wo,`, make sure its
`),Hi=n(Wo,"CODE",{});var Uf=s(Hi);Un=r(Uf,"config_class"),Uf.forEach(t),d4=r(Wo,` attribute is set to the same class you use when registering the model (here
`),Ui=n(Wo,"CODE",{});var c9=s(Ui);Hf=r(c9,"NewModelConfig"),c9.forEach(t),Va=r(Wo,")."),Wo.forEach(t),this.h()},h(){c(Qn,"href","/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel")},m(fo,pe){b(fo,J,pe),e(J,Pe),e(J,de),e(de,he),e(J,io),e(J,fe),e(fe,Fe),e(J,zo),e(J,Vi),e(Vi,Wf),e(J,ha),e(J,zi),e(zi,Wi),e(J,s4),b(fo,Qf,pe),b(fo,Le,pe),e(Le,co),e(Le,Qi),e(Qi,Wn),e(Le,l4),e(Le,Qn),e(Qn,Hn),e(Le,i4),e(Le,Hi),e(Hi,Un),e(Le,d4),e(Le,Ui),e(Ui,Hf),e(Le,Va)},d(fo){fo&&t(J),fo&&t(Qf),fo&&t(Le)}}}function j8t(Xi){let J,Pe,de,he,io;return{c(){J=a("p"),Pe=o("Passing "),de=a("code"),he=o("use_auth_token=True"),io=o(" is required when you want to use a private model.")},l(fe){J=n(fe,"P",{});var Fe=s(J);Pe=r(Fe,"Passing "),de=n(Fe,"CODE",{});var zo=s(de);he=r(zo,"use_auth_token=True"),zo.forEach(t),io=r(Fe," is required when you want to use a private model."),Fe.forEach(t)},m(fe,Fe){b(fe,J,Fe),e(J,Pe),e(J,de),e(de,he),e(J,io)},d(fe){fe&&t(J)}}}function D8t(Xi){let J,Pe,de,he,io;return{c(){J=a("p"),Pe=o("Passing "),de=a("code"),he=o("use_auth_token=True"),io=o(" is required when you want to use a private model.")},l(fe){J=n(fe,"P",{});var Fe=s(J);Pe=r(Fe,"Passing "),de=n(Fe,"CODE",{});var zo=s(de);he=r(zo,"use_auth_token=True"),zo.forEach(t),io=r(Fe," is required when you want to use a private model."),Fe.forEach(t)},m(fe,Fe){b(fe,J,Fe),e(J,Pe),e(J,de),e(de,he),e(J,io)},d(fe){fe&&t(J)}}}function N8t(Xi){let J,Pe,de,he,io,fe,Fe,zo,Vi,Wf,ha,zi,Wi,s4,Qf,Le,co,Qi,Wn,l4,Qn,Hn,i4,Hi,Un,d4,Ui,Hf,Va,fo,pe,s9,Ji,l9,i9,Wo,za,d9,Uf,c9,c$e,Wxe,Yi,Jf,jQ,c4,f$e,DQ,m$e,Qxe,Jn,g$e,NQ,h$e,p$e,qQ,_$e,u$e,Hxe,f4,Uxe,f9,b$e,Jxe,Yf,Yxe,Ki,Kf,OQ,m4,v$e,GQ,T$e,Kxe,Qo,g4,F$e,h4,C$e,m9,M$e,E$e,y$e,p4,w$e,XQ,A$e,L$e,B$e,mo,_4,x$e,VQ,k$e,R$e,Zi,S$e,zQ,P$e,$$e,WQ,I$e,j$e,D$e,v,Zf,QQ,N$e,q$e,g9,O$e,G$e,X$e,em,HQ,V$e,z$e,h9,W$e,Q$e,H$e,om,UQ,U$e,J$e,p9,Y$e,K$e,Z$e,rm,JQ,eIe,oIe,_9,rIe,tIe,aIe,tm,YQ,nIe,sIe,u9,lIe,iIe,dIe,am,KQ,cIe,fIe,b9,mIe,gIe,hIe,nm,ZQ,pIe,_Ie,v9,uIe,bIe,vIe,sm,eH,TIe,FIe,T9,CIe,MIe,EIe,lm,oH,yIe,wIe,F9,AIe,LIe,BIe,im,rH,xIe,kIe,C9,RIe,SIe,PIe,dm,tH,$Ie,IIe,M9,jIe,DIe,NIe,cm,aH,qIe,OIe,E9,GIe,XIe,VIe,fm,nH,zIe,WIe,y9,QIe,HIe,UIe,mm,sH,JIe,YIe,w9,KIe,ZIe,eje,gm,lH,oje,rje,A9,tje,aje,nje,hm,iH,sje,lje,L9,ije,dje,cje,pm,dH,fje,mje,B9,gje,hje,pje,_m,cH,_je,uje,x9,bje,vje,Tje,um,fH,Fje,Cje,k9,Mje,Eje,yje,bm,mH,wje,Aje,R9,Lje,Bje,xje,vm,gH,kje,Rje,S9,Sje,Pje,$je,Tm,hH,Ije,jje,P9,Dje,Nje,qje,Fm,pH,Oje,Gje,$9,Xje,Vje,zje,Cm,_H,Wje,Qje,I9,Hje,Uje,Jje,Mm,uH,Yje,Kje,j9,Zje,eDe,oDe,Em,bH,rDe,tDe,D9,aDe,nDe,sDe,ym,vH,lDe,iDe,N9,dDe,cDe,fDe,wm,TH,mDe,gDe,q9,hDe,pDe,_De,Am,FH,uDe,bDe,O9,vDe,TDe,FDe,Lm,CH,CDe,MDe,G9,EDe,yDe,wDe,Bm,MH,ADe,LDe,X9,BDe,xDe,kDe,xm,EH,RDe,SDe,V9,PDe,$De,IDe,km,yH,jDe,DDe,z9,NDe,qDe,ODe,Rm,wH,GDe,XDe,W9,VDe,zDe,WDe,Sm,AH,QDe,HDe,Q9,UDe,JDe,YDe,Pm,LH,KDe,ZDe,H9,eNe,oNe,rNe,$m,BH,tNe,aNe,U9,nNe,sNe,lNe,Im,xH,iNe,dNe,J9,cNe,fNe,mNe,jm,kH,gNe,hNe,Y9,pNe,_Ne,uNe,Dm,RH,bNe,vNe,K9,TNe,FNe,CNe,Nm,SH,MNe,ENe,Z9,yNe,wNe,ANe,qm,PH,LNe,BNe,eB,xNe,kNe,RNe,Om,$H,SNe,PNe,oB,$Ne,INe,jNe,Gm,IH,DNe,NNe,rB,qNe,ONe,GNe,Xm,jH,XNe,VNe,tB,zNe,WNe,QNe,Vm,DH,HNe,UNe,aB,JNe,YNe,KNe,zm,NH,ZNe,eqe,nB,oqe,rqe,tqe,Wm,qH,aqe,nqe,sB,sqe,lqe,iqe,Qm,OH,dqe,cqe,lB,fqe,mqe,gqe,Hm,GH,hqe,pqe,iB,_qe,uqe,bqe,Um,XH,vqe,Tqe,dB,Fqe,Cqe,Mqe,Jm,VH,Eqe,yqe,cB,wqe,Aqe,Lqe,Ym,zH,Bqe,xqe,fB,kqe,Rqe,Sqe,Km,WH,Pqe,$qe,mB,Iqe,jqe,Dqe,Zm,QH,Nqe,qqe,gB,Oqe,Gqe,Xqe,eg,HH,Vqe,zqe,hB,Wqe,Qqe,Hqe,og,UH,Uqe,Jqe,pB,Yqe,Kqe,Zqe,rg,JH,eOe,oOe,_B,rOe,tOe,aOe,tg,YH,nOe,sOe,uB,lOe,iOe,dOe,ag,KH,cOe,fOe,bB,mOe,gOe,hOe,ng,ZH,pOe,_Oe,vB,uOe,bOe,vOe,sg,eU,TOe,FOe,TB,COe,MOe,EOe,lg,oU,yOe,wOe,FB,AOe,LOe,BOe,ig,rU,xOe,kOe,CB,ROe,SOe,POe,dg,tU,$Oe,IOe,MB,jOe,DOe,NOe,cg,aU,qOe,OOe,EB,GOe,XOe,VOe,fg,nU,zOe,WOe,yB,QOe,HOe,UOe,mg,sU,JOe,YOe,wB,KOe,ZOe,eGe,gg,lU,oGe,rGe,AB,tGe,aGe,nGe,hg,iU,sGe,lGe,LB,iGe,dGe,cGe,pg,dU,fGe,mGe,BB,gGe,hGe,pGe,_g,cU,_Ge,uGe,xB,bGe,vGe,TGe,ug,fU,FGe,CGe,kB,MGe,EGe,yGe,bg,mU,wGe,AGe,RB,LGe,BGe,xGe,vg,gU,kGe,RGe,SB,SGe,PGe,$Ge,Tg,hU,IGe,jGe,PB,DGe,NGe,qGe,Fg,pU,OGe,GGe,$B,XGe,VGe,zGe,Cg,_U,WGe,QGe,IB,HGe,UGe,JGe,Mg,uU,YGe,KGe,jB,ZGe,eXe,oXe,Eg,bU,rXe,tXe,DB,aXe,nXe,sXe,yg,vU,lXe,iXe,NB,dXe,cXe,fXe,wg,TU,mXe,gXe,qB,hXe,pXe,_Xe,Ag,FU,uXe,bXe,OB,vXe,TXe,FXe,Lg,CU,CXe,MXe,GB,EXe,yXe,wXe,Bg,MU,AXe,LXe,XB,BXe,xXe,kXe,xg,EU,RXe,SXe,VB,PXe,$Xe,IXe,kg,yU,jXe,DXe,zB,NXe,qXe,OXe,Rg,wU,GXe,XXe,WB,VXe,zXe,WXe,Sg,AU,QXe,HXe,QB,UXe,JXe,YXe,Pg,LU,KXe,ZXe,HB,eVe,oVe,rVe,$g,BU,tVe,aVe,UB,nVe,sVe,lVe,Ig,xU,iVe,dVe,JB,cVe,fVe,mVe,jg,kU,gVe,hVe,YB,pVe,_Ve,uVe,Dg,RU,bVe,vVe,KB,TVe,FVe,CVe,SU,MVe,EVe,u4,yVe,Ng,b4,wVe,PU,AVe,Zxe,ed,qg,$U,v4,LVe,IU,BVe,eke,Ho,T4,xVe,F4,kVe,ZB,RVe,SVe,PVe,C4,$Ve,jU,IVe,jVe,DVe,go,M4,NVe,DU,qVe,OVe,Wa,GVe,NU,XVe,VVe,qU,zVe,WVe,OU,QVe,HVe,UVe,E,Yn,GU,JVe,YVe,ex,KVe,ZVe,ox,eze,oze,rze,Kn,XU,tze,aze,rx,nze,sze,tx,lze,ize,dze,Zn,VU,cze,fze,ax,mze,gze,nx,hze,pze,_ze,Og,zU,uze,bze,sx,vze,Tze,Fze,es,WU,Cze,Mze,lx,Eze,yze,ix,wze,Aze,Lze,Gg,QU,Bze,xze,dx,kze,Rze,Sze,Xg,HU,Pze,$ze,cx,Ize,jze,Dze,Vg,UU,Nze,qze,fx,Oze,Gze,Xze,os,JU,Vze,zze,mx,Wze,Qze,gx,Hze,Uze,Jze,rs,YU,Yze,Kze,hx,Zze,eWe,px,oWe,rWe,tWe,ts,KU,aWe,nWe,_x,sWe,lWe,ux,iWe,dWe,cWe,zg,ZU,fWe,mWe,bx,gWe,hWe,pWe,Wg,eJ,_We,uWe,vx,bWe,vWe,TWe,as,oJ,FWe,CWe,Tx,MWe,EWe,Fx,yWe,wWe,AWe,Qg,rJ,LWe,BWe,Cx,xWe,kWe,RWe,ns,tJ,SWe,PWe,Mx,$We,IWe,Ex,jWe,DWe,NWe,ss,aJ,qWe,OWe,yx,GWe,XWe,wx,VWe,zWe,WWe,ls,nJ,QWe,HWe,Ax,UWe,JWe,sJ,YWe,KWe,ZWe,Hg,lJ,eQe,oQe,Lx,rQe,tQe,aQe,is,iJ,nQe,sQe,Bx,lQe,iQe,xx,dQe,cQe,fQe,Ug,dJ,mQe,gQe,kx,hQe,pQe,_Qe,ds,cJ,uQe,bQe,Rx,vQe,TQe,Sx,FQe,CQe,MQe,cs,fJ,EQe,yQe,Px,wQe,AQe,$x,LQe,BQe,xQe,fs,mJ,kQe,RQe,Ix,SQe,PQe,jx,$Qe,IQe,jQe,Jg,gJ,DQe,NQe,Dx,qQe,OQe,GQe,ms,hJ,XQe,VQe,Nx,zQe,WQe,qx,QQe,HQe,UQe,Yg,pJ,JQe,YQe,Ox,KQe,ZQe,eHe,gs,_J,oHe,rHe,Gx,tHe,aHe,Xx,nHe,sHe,lHe,hs,uJ,iHe,dHe,Vx,cHe,fHe,zx,mHe,gHe,hHe,ps,bJ,pHe,_He,Wx,uHe,bHe,Qx,vHe,THe,FHe,_s,vJ,CHe,MHe,Hx,EHe,yHe,Ux,wHe,AHe,LHe,Kg,TJ,BHe,xHe,Jx,kHe,RHe,SHe,us,FJ,PHe,$He,Yx,IHe,jHe,Kx,DHe,NHe,qHe,bs,CJ,OHe,GHe,Zx,XHe,VHe,ek,zHe,WHe,QHe,vs,MJ,HHe,UHe,ok,JHe,YHe,rk,KHe,ZHe,eUe,Ts,EJ,oUe,rUe,tk,tUe,aUe,ak,nUe,sUe,lUe,Fs,yJ,iUe,dUe,nk,cUe,fUe,sk,mUe,gUe,hUe,Cs,wJ,pUe,_Ue,lk,uUe,bUe,ik,vUe,TUe,FUe,Zg,AJ,CUe,MUe,dk,EUe,yUe,wUe,Ms,LJ,AUe,LUe,ck,BUe,xUe,fk,kUe,RUe,SUe,eh,BJ,PUe,$Ue,mk,IUe,jUe,DUe,oh,xJ,NUe,qUe,gk,OUe,GUe,XUe,Es,kJ,VUe,zUe,hk,WUe,QUe,pk,HUe,UUe,JUe,ys,RJ,YUe,KUe,_k,ZUe,eJe,uk,oJe,rJe,tJe,rh,SJ,aJe,nJe,bk,sJe,lJe,iJe,ws,PJ,dJe,cJe,vk,fJe,mJe,Tk,gJe,hJe,pJe,As,$J,_Je,uJe,Fk,bJe,vJe,Ck,TJe,FJe,CJe,Ls,IJ,MJe,EJe,Mk,yJe,wJe,Ek,AJe,LJe,BJe,Bs,jJ,xJe,kJe,yk,RJe,SJe,wk,PJe,$Je,IJe,xs,DJ,jJe,DJe,Ak,NJe,qJe,Lk,OJe,GJe,XJe,th,NJ,VJe,zJe,Bk,WJe,QJe,HJe,ah,qJ,UJe,JJe,xk,YJe,KJe,ZJe,nh,OJ,eYe,oYe,kk,rYe,tYe,aYe,sh,GJ,nYe,sYe,Rk,lYe,iYe,dYe,ks,XJ,cYe,fYe,Sk,mYe,gYe,Pk,hYe,pYe,_Ye,lh,VJ,uYe,bYe,$k,vYe,TYe,FYe,Rs,zJ,CYe,MYe,Ik,EYe,yYe,jk,wYe,AYe,LYe,Ss,WJ,BYe,xYe,Dk,kYe,RYe,Nk,SYe,PYe,$Ye,Ps,QJ,IYe,jYe,qk,DYe,NYe,Ok,qYe,OYe,GYe,$s,HJ,XYe,VYe,Gk,zYe,WYe,Xk,QYe,HYe,UYe,Is,UJ,JYe,YYe,Vk,KYe,ZYe,zk,eKe,oKe,rKe,js,JJ,tKe,aKe,Wk,nKe,sKe,Qk,lKe,iKe,dKe,ih,YJ,cKe,fKe,Hk,mKe,gKe,hKe,dh,KJ,pKe,_Ke,Uk,uKe,bKe,vKe,Ds,ZJ,TKe,FKe,Jk,CKe,MKe,Yk,EKe,yKe,wKe,Ns,eY,AKe,LKe,Kk,BKe,xKe,Zk,kKe,RKe,SKe,qs,oY,PKe,$Ke,eR,IKe,jKe,oR,DKe,NKe,qKe,ch,rY,OKe,GKe,rR,XKe,VKe,zKe,fh,tY,WKe,QKe,tR,HKe,UKe,JKe,mh,aY,YKe,KKe,aR,ZKe,eZe,oZe,gh,nY,rZe,tZe,nR,aZe,nZe,sZe,Os,sY,lZe,iZe,sR,dZe,cZe,lR,fZe,mZe,gZe,hh,lY,hZe,pZe,iR,_Ze,uZe,bZe,ph,iY,vZe,TZe,dR,FZe,CZe,MZe,Gs,dY,EZe,yZe,cR,wZe,AZe,fR,LZe,BZe,xZe,Xs,cY,kZe,RZe,mR,SZe,PZe,gR,$Ze,IZe,jZe,fY,DZe,NZe,E4,qZe,_h,y4,OZe,mY,GZe,oke,od,uh,gY,w4,XZe,hY,VZe,rke,Uo,A4,zZe,L4,WZe,hR,QZe,HZe,UZe,B4,JZe,pY,YZe,KZe,ZZe,$e,x4,eeo,_Y,oeo,reo,Qa,teo,uY,aeo,neo,bY,seo,leo,vY,ieo,deo,ceo,ae,bh,TY,feo,meo,pR,geo,heo,peo,vh,FY,_eo,ueo,_R,beo,veo,Teo,Th,CY,Feo,Ceo,uR,Meo,Eeo,yeo,Fh,MY,weo,Aeo,bR,Leo,Beo,xeo,Ch,EY,keo,Reo,vR,Seo,Peo,$eo,Mh,yY,Ieo,jeo,TR,Deo,Neo,qeo,Eh,wY,Oeo,Geo,FR,Xeo,Veo,zeo,yh,AY,Weo,Qeo,CR,Heo,Ueo,Jeo,wh,LY,Yeo,Keo,MR,Zeo,eoo,ooo,Ah,BY,roo,too,ER,aoo,noo,soo,Lh,xY,loo,ioo,yR,doo,coo,foo,Bh,kY,moo,goo,wR,hoo,poo,_oo,xh,RY,uoo,boo,AR,voo,Too,Foo,kh,SY,Coo,Moo,LR,Eoo,yoo,woo,Rh,PY,Aoo,Loo,BR,Boo,xoo,koo,Sh,$Y,Roo,Soo,xR,Poo,$oo,Ioo,Ph,joo,IY,Doo,Noo,k4,qoo,$h,R4,Ooo,jY,Goo,tke,rd,Ih,DY,S4,Xoo,NY,Voo,ake,Jo,P4,zoo,$4,Woo,kR,Qoo,Hoo,Uoo,I4,Joo,qY,Yoo,Koo,Zoo,Ie,j4,ero,OY,oro,rro,td,tro,GY,aro,nro,XY,sro,lro,iro,Be,jh,VY,dro,cro,RR,fro,mro,gro,Dh,zY,hro,pro,SR,_ro,uro,bro,Nh,WY,vro,Tro,PR,Fro,Cro,Mro,qh,QY,Ero,yro,$R,wro,Aro,Lro,Oh,HY,Bro,xro,IR,kro,Rro,Sro,Gh,UY,Pro,$ro,jR,Iro,jro,Dro,Xh,JY,Nro,qro,DR,Oro,Gro,Xro,Vh,YY,Vro,zro,NR,Wro,Qro,Hro,zh,Uro,KY,Jro,Yro,D4,Kro,Wh,N4,Zro,ZY,eto,nke,ad,Qh,eK,q4,oto,oK,rto,ske,Yo,O4,tto,nd,ato,rK,nto,sto,tK,lto,ito,dto,G4,cto,aK,fto,mto,gto,Wr,X4,hto,nK,pto,_to,sd,uto,sK,bto,vto,lK,Tto,Fto,Cto,iK,Mto,Eto,V4,yto,je,z4,wto,dK,Ato,Lto,Ha,Bto,cK,xto,kto,fK,Rto,Sto,mK,Pto,$to,Ito,F,Hh,gK,jto,Dto,qR,Nto,qto,Oto,Uh,hK,Gto,Xto,OR,Vto,zto,Wto,Jh,pK,Qto,Hto,GR,Uto,Jto,Yto,Yh,_K,Kto,Zto,XR,eao,oao,rao,Kh,uK,tao,aao,VR,nao,sao,lao,Zh,bK,iao,dao,zR,cao,fao,mao,ep,vK,gao,hao,WR,pao,_ao,uao,op,TK,bao,vao,QR,Tao,Fao,Cao,rp,FK,Mao,Eao,HR,yao,wao,Aao,tp,CK,Lao,Bao,UR,xao,kao,Rao,ap,MK,Sao,Pao,JR,$ao,Iao,jao,np,EK,Dao,Nao,YR,qao,Oao,Gao,sp,yK,Xao,Vao,KR,zao,Wao,Qao,lp,wK,Hao,Uao,ZR,Jao,Yao,Kao,ip,AK,Zao,eno,eS,ono,rno,tno,dp,LK,ano,nno,oS,sno,lno,ino,cp,BK,dno,cno,rS,fno,mno,gno,fp,xK,hno,pno,tS,_no,uno,bno,mp,kK,vno,Tno,aS,Fno,Cno,Mno,gp,RK,Eno,yno,nS,wno,Ano,Lno,hp,SK,Bno,xno,sS,kno,Rno,Sno,pp,PK,Pno,$no,lS,Ino,jno,Dno,_p,$K,Nno,qno,iS,Ono,Gno,Xno,up,IK,Vno,zno,dS,Wno,Qno,Hno,bp,jK,Uno,Jno,cS,Yno,Kno,Zno,vp,DK,eso,oso,fS,rso,tso,aso,Tp,NK,nso,sso,mS,lso,iso,dso,Vs,qK,cso,fso,gS,mso,gso,hS,hso,pso,_so,Fp,OK,uso,bso,pS,vso,Tso,Fso,Cp,GK,Cso,Mso,_S,Eso,yso,wso,Mp,XK,Aso,Lso,uS,Bso,xso,kso,Ep,VK,Rso,Sso,bS,Pso,$so,Iso,yp,zK,jso,Dso,vS,Nso,qso,Oso,wp,WK,Gso,Xso,TS,Vso,zso,Wso,Ap,QK,Qso,Hso,FS,Uso,Jso,Yso,Lp,HK,Kso,Zso,CS,elo,olo,rlo,Bp,UK,tlo,alo,MS,nlo,slo,llo,xp,JK,ilo,dlo,ES,clo,flo,mlo,kp,YK,glo,hlo,yS,plo,_lo,ulo,Rp,KK,blo,vlo,wS,Tlo,Flo,Clo,Sp,ZK,Mlo,Elo,AS,ylo,wlo,Alo,Pp,eZ,Llo,Blo,LS,xlo,klo,Rlo,$p,oZ,Slo,Plo,BS,$lo,Ilo,jlo,Ip,rZ,Dlo,Nlo,xS,qlo,Olo,Glo,jp,tZ,Xlo,Vlo,kS,zlo,Wlo,Qlo,Dp,aZ,Hlo,Ulo,RS,Jlo,Ylo,Klo,Np,nZ,Zlo,eio,SS,oio,rio,tio,qp,sZ,aio,nio,PS,sio,lio,iio,Op,lZ,dio,cio,$S,fio,mio,gio,Gp,iZ,hio,pio,IS,_io,uio,bio,Xp,dZ,vio,Tio,jS,Fio,Cio,Mio,Vp,cZ,Eio,yio,DS,wio,Aio,Lio,zp,fZ,Bio,xio,NS,kio,Rio,Sio,Wp,mZ,Pio,$io,qS,Iio,jio,Dio,Qp,gZ,Nio,qio,OS,Oio,Gio,Xio,Hp,hZ,Vio,zio,GS,Wio,Qio,Hio,Up,pZ,Uio,Jio,XS,Yio,Kio,Zio,Jp,_Z,edo,odo,VS,rdo,tdo,ado,Yp,uZ,ndo,sdo,zS,ldo,ido,ddo,Kp,bZ,cdo,fdo,WS,mdo,gdo,hdo,Zp,vZ,pdo,_do,QS,udo,bdo,vdo,e_,TZ,Tdo,Fdo,HS,Cdo,Mdo,Edo,o_,FZ,ydo,wdo,US,Ado,Ldo,Bdo,r_,CZ,xdo,kdo,JS,Rdo,Sdo,Pdo,t_,MZ,$do,Ido,YS,jdo,Ddo,Ndo,a_,EZ,qdo,Odo,KS,Gdo,Xdo,Vdo,n_,yZ,zdo,Wdo,ZS,Qdo,Hdo,Udo,s_,wZ,Jdo,Ydo,eP,Kdo,Zdo,eco,l_,AZ,oco,rco,oP,tco,aco,nco,i_,LZ,sco,lco,rP,ico,dco,cco,d_,BZ,fco,mco,tP,gco,hco,pco,c_,xZ,_co,uco,aP,bco,vco,Tco,f_,kZ,Fco,Cco,nP,Mco,Eco,yco,m_,RZ,wco,Aco,sP,Lco,Bco,xco,g_,SZ,kco,Rco,lP,Sco,Pco,$co,h_,PZ,Ico,jco,iP,Dco,Nco,qco,p_,$Z,Oco,Gco,dP,Xco,Vco,zco,__,IZ,Wco,Qco,cP,Hco,Uco,Jco,u_,jZ,Yco,Kco,fP,Zco,efo,ofo,b_,DZ,rfo,tfo,mP,afo,nfo,sfo,v_,NZ,lfo,ifo,gP,dfo,cfo,ffo,T_,qZ,mfo,gfo,hP,hfo,pfo,_fo,F_,OZ,ufo,bfo,pP,vfo,Tfo,Ffo,C_,GZ,Cfo,Mfo,_P,Efo,yfo,wfo,M_,XZ,Afo,Lfo,uP,Bfo,xfo,kfo,E_,VZ,Rfo,Sfo,bP,Pfo,$fo,Ifo,y_,zZ,jfo,Dfo,vP,Nfo,qfo,Ofo,w_,Gfo,WZ,Xfo,Vfo,QZ,zfo,Wfo,HZ,Qfo,Hfo,W4,lke,ld,A_,UZ,Q4,Ufo,JZ,Jfo,ike,Ko,H4,Yfo,id,Kfo,YZ,Zfo,emo,KZ,omo,rmo,tmo,U4,amo,ZZ,nmo,smo,lmo,Qr,J4,imo,eee,dmo,cmo,dd,fmo,oee,mmo,gmo,ree,hmo,pmo,_mo,tee,umo,bmo,Y4,vmo,De,K4,Tmo,aee,Fmo,Cmo,Ua,Mmo,nee,Emo,ymo,see,wmo,Amo,lee,Lmo,Bmo,xmo,k,L_,iee,kmo,Rmo,TP,Smo,Pmo,$mo,B_,dee,Imo,jmo,FP,Dmo,Nmo,qmo,x_,cee,Omo,Gmo,CP,Xmo,Vmo,zmo,k_,fee,Wmo,Qmo,MP,Hmo,Umo,Jmo,R_,mee,Ymo,Kmo,EP,Zmo,ego,ogo,S_,gee,rgo,tgo,yP,ago,ngo,sgo,P_,hee,lgo,igo,wP,dgo,cgo,fgo,$_,pee,mgo,ggo,AP,hgo,pgo,_go,I_,_ee,ugo,bgo,LP,vgo,Tgo,Fgo,j_,uee,Cgo,Mgo,BP,Ego,ygo,wgo,D_,bee,Ago,Lgo,xP,Bgo,xgo,kgo,N_,vee,Rgo,Sgo,kP,Pgo,$go,Igo,q_,Tee,jgo,Dgo,RP,Ngo,qgo,Ogo,O_,Fee,Ggo,Xgo,SP,Vgo,zgo,Wgo,G_,Cee,Qgo,Hgo,PP,Ugo,Jgo,Ygo,X_,Mee,Kgo,Zgo,$P,eho,oho,rho,V_,Eee,tho,aho,IP,nho,sho,lho,z_,yee,iho,dho,jP,cho,fho,mho,W_,wee,gho,hho,DP,pho,_ho,uho,Q_,Aee,bho,vho,NP,Tho,Fho,Cho,H_,Lee,Mho,Eho,qP,yho,who,Aho,U_,Bee,Lho,Bho,OP,xho,kho,Rho,J_,xee,Sho,Pho,GP,$ho,Iho,jho,Y_,kee,Dho,Nho,XP,qho,Oho,Gho,K_,Ree,Xho,Vho,VP,zho,Who,Qho,Z_,See,Hho,Uho,zP,Jho,Yho,Kho,eu,Pee,Zho,epo,WP,opo,rpo,tpo,ou,$ee,apo,npo,QP,spo,lpo,ipo,ru,Iee,dpo,cpo,HP,fpo,mpo,gpo,tu,jee,hpo,ppo,UP,_po,upo,bpo,au,Dee,vpo,Tpo,JP,Fpo,Cpo,Mpo,nu,Nee,Epo,ypo,YP,wpo,Apo,Lpo,su,qee,Bpo,xpo,KP,kpo,Rpo,Spo,lu,Oee,Ppo,$po,ZP,Ipo,jpo,Dpo,iu,Gee,Npo,qpo,e$,Opo,Gpo,Xpo,du,Xee,Vpo,zpo,o$,Wpo,Qpo,Hpo,cu,Vee,Upo,Jpo,r$,Ypo,Kpo,Zpo,fu,zee,e_o,o_o,t$,r_o,t_o,a_o,mu,Wee,n_o,s_o,a$,l_o,i_o,d_o,gu,c_o,Qee,f_o,m_o,Hee,g_o,h_o,Uee,p_o,__o,Z4,dke,cd,hu,Jee,eE,u_o,Yee,b_o,cke,Zo,oE,v_o,fd,T_o,Kee,F_o,C_o,Zee,M_o,E_o,y_o,rE,w_o,eoe,A_o,L_o,B_o,Hr,tE,x_o,ooe,k_o,R_o,md,S_o,roe,P_o,$_o,toe,I_o,j_o,D_o,aoe,N_o,q_o,aE,O_o,Ne,nE,G_o,noe,X_o,V_o,Ja,z_o,soe,W_o,Q_o,loe,H_o,U_o,ioe,J_o,Y_o,K_o,$,pu,doe,Z_o,euo,n$,ouo,ruo,tuo,_u,coe,auo,nuo,s$,suo,luo,iuo,uu,foe,duo,cuo,l$,fuo,muo,guo,bu,moe,huo,puo,i$,_uo,uuo,buo,vu,goe,vuo,Tuo,d$,Fuo,Cuo,Muo,Tu,hoe,Euo,yuo,c$,wuo,Auo,Luo,Fu,poe,Buo,xuo,f$,kuo,Ruo,Suo,Cu,_oe,Puo,$uo,m$,Iuo,juo,Duo,Mu,uoe,Nuo,quo,g$,Ouo,Guo,Xuo,Eu,boe,Vuo,zuo,h$,Wuo,Quo,Huo,yu,voe,Uuo,Juo,p$,Yuo,Kuo,Zuo,wu,Toe,e1o,o1o,_$,r1o,t1o,a1o,Au,Foe,n1o,s1o,u$,l1o,i1o,d1o,Lu,Coe,c1o,f1o,b$,m1o,g1o,h1o,Bu,Moe,p1o,_1o,v$,u1o,b1o,v1o,xu,Eoe,T1o,F1o,T$,C1o,M1o,E1o,ku,yoe,y1o,w1o,F$,A1o,L1o,B1o,Ru,woe,x1o,k1o,C$,R1o,S1o,P1o,Su,Aoe,$1o,I1o,M$,j1o,D1o,N1o,Pu,Loe,q1o,O1o,E$,G1o,X1o,V1o,$u,Boe,z1o,W1o,y$,Q1o,H1o,U1o,Iu,xoe,J1o,Y1o,w$,K1o,Z1o,ebo,ju,koe,obo,rbo,A$,tbo,abo,nbo,Du,Roe,sbo,lbo,L$,ibo,dbo,cbo,Nu,Soe,fbo,mbo,B$,gbo,hbo,pbo,qu,Poe,_bo,ubo,x$,bbo,vbo,Tbo,Ou,$oe,Fbo,Cbo,k$,Mbo,Ebo,ybo,Gu,Ioe,wbo,Abo,R$,Lbo,Bbo,xbo,Xu,joe,kbo,Rbo,S$,Sbo,Pbo,$bo,Vu,Doe,Ibo,jbo,P$,Dbo,Nbo,qbo,zu,Noe,Obo,Gbo,$$,Xbo,Vbo,zbo,Wu,qoe,Wbo,Qbo,I$,Hbo,Ubo,Jbo,Qu,Ooe,Ybo,Kbo,j$,Zbo,e5o,o5o,Hu,Goe,r5o,t5o,D$,a5o,n5o,s5o,Uu,Xoe,l5o,i5o,N$,d5o,c5o,f5o,Ju,m5o,Voe,g5o,h5o,zoe,p5o,_5o,Woe,u5o,b5o,sE,fke,gd,Yu,Qoe,lE,v5o,Hoe,T5o,mke,er,iE,F5o,hd,C5o,Uoe,M5o,E5o,Joe,y5o,w5o,A5o,dE,L5o,Yoe,B5o,x5o,k5o,Ur,cE,R5o,Koe,S5o,P5o,pd,$5o,Zoe,I5o,j5o,ere,D5o,N5o,q5o,ore,O5o,G5o,fE,X5o,qe,mE,V5o,rre,z5o,W5o,Ya,Q5o,tre,H5o,U5o,are,J5o,Y5o,nre,K5o,Z5o,e2o,I,Ku,sre,o2o,r2o,q$,t2o,a2o,n2o,Zu,lre,s2o,l2o,O$,i2o,d2o,c2o,e1,ire,f2o,m2o,G$,g2o,h2o,p2o,o1,dre,_2o,u2o,X$,b2o,v2o,T2o,r1,cre,F2o,C2o,V$,M2o,E2o,y2o,t1,fre,w2o,A2o,z$,L2o,B2o,x2o,a1,mre,k2o,R2o,W$,S2o,P2o,$2o,n1,gre,I2o,j2o,Q$,D2o,N2o,q2o,s1,hre,O2o,G2o,H$,X2o,V2o,z2o,l1,pre,W2o,Q2o,U$,H2o,U2o,J2o,i1,_re,Y2o,K2o,J$,Z2o,evo,ovo,d1,ure,rvo,tvo,Y$,avo,nvo,svo,c1,bre,lvo,ivo,K$,dvo,cvo,fvo,f1,vre,mvo,gvo,Z$,hvo,pvo,_vo,m1,Tre,uvo,bvo,eI,vvo,Tvo,Fvo,g1,Fre,Cvo,Mvo,oI,Evo,yvo,wvo,h1,Cre,Avo,Lvo,rI,Bvo,xvo,kvo,p1,Mre,Rvo,Svo,tI,Pvo,$vo,Ivo,_1,Ere,jvo,Dvo,aI,Nvo,qvo,Ovo,u1,yre,Gvo,Xvo,nI,Vvo,zvo,Wvo,b1,wre,Qvo,Hvo,sI,Uvo,Jvo,Yvo,v1,Are,Kvo,Zvo,lI,e6o,o6o,r6o,T1,Lre,t6o,a6o,iI,n6o,s6o,l6o,F1,Bre,i6o,d6o,dI,c6o,f6o,m6o,C1,xre,g6o,h6o,cI,p6o,_6o,u6o,M1,kre,b6o,v6o,fI,T6o,F6o,C6o,E1,Rre,M6o,E6o,mI,y6o,w6o,A6o,y1,Sre,L6o,B6o,gI,x6o,k6o,R6o,w1,Pre,S6o,P6o,hI,$6o,I6o,j6o,A1,$re,D6o,N6o,pI,q6o,O6o,G6o,L1,Ire,X6o,V6o,jre,z6o,W6o,Q6o,B1,Dre,H6o,U6o,_I,J6o,Y6o,K6o,x1,Nre,Z6o,e0o,uI,o0o,r0o,t0o,k1,qre,a0o,n0o,bI,s0o,l0o,i0o,R1,Ore,d0o,c0o,vI,f0o,m0o,g0o,S1,h0o,Gre,p0o,_0o,Xre,u0o,b0o,Vre,v0o,T0o,gE,gke,_d,P1,zre,hE,F0o,Wre,C0o,hke,or,pE,M0o,ud,E0o,Qre,y0o,w0o,Hre,A0o,L0o,B0o,_E,x0o,Ure,k0o,R0o,S0o,Jr,uE,P0o,Jre,$0o,I0o,bd,j0o,Yre,D0o,N0o,Kre,q0o,O0o,G0o,Zre,X0o,V0o,bE,z0o,Oe,vE,W0o,ete,Q0o,H0o,Ka,U0o,ote,J0o,Y0o,rte,K0o,Z0o,tte,eTo,oTo,rTo,ne,$1,ate,tTo,aTo,TI,nTo,sTo,lTo,I1,nte,iTo,dTo,FI,cTo,fTo,mTo,j1,ste,gTo,hTo,CI,pTo,_To,uTo,D1,lte,bTo,vTo,MI,TTo,FTo,CTo,N1,ite,MTo,ETo,EI,yTo,wTo,ATo,q1,dte,LTo,BTo,yI,xTo,kTo,RTo,O1,cte,STo,PTo,wI,$To,ITo,jTo,G1,fte,DTo,NTo,AI,qTo,OTo,GTo,X1,mte,XTo,VTo,LI,zTo,WTo,QTo,V1,gte,HTo,UTo,BI,JTo,YTo,KTo,z1,hte,ZTo,e8o,xI,o8o,r8o,t8o,W1,pte,a8o,n8o,kI,s8o,l8o,i8o,Q1,_te,d8o,c8o,RI,f8o,m8o,g8o,H1,ute,h8o,p8o,SI,_8o,u8o,b8o,U1,bte,v8o,T8o,PI,F8o,C8o,M8o,J1,vte,E8o,y8o,$I,w8o,A8o,L8o,Y1,B8o,Tte,x8o,k8o,Fte,R8o,S8o,Cte,P8o,$8o,TE,pke,vd,K1,Mte,FE,I8o,Ete,j8o,_ke,rr,CE,D8o,Td,N8o,yte,q8o,O8o,wte,G8o,X8o,V8o,ME,z8o,Ate,W8o,Q8o,H8o,Yr,EE,U8o,Lte,J8o,Y8o,Fd,K8o,Bte,Z8o,eFo,xte,oFo,rFo,tFo,kte,aFo,nFo,yE,sFo,Ge,wE,lFo,Rte,iFo,dFo,Za,cFo,Ste,fFo,mFo,Pte,gFo,hFo,$te,pFo,_Fo,uFo,A,Z1,Ite,bFo,vFo,II,TFo,FFo,CFo,eb,jte,MFo,EFo,jI,yFo,wFo,AFo,ob,Dte,LFo,BFo,DI,xFo,kFo,RFo,rb,Nte,SFo,PFo,NI,$Fo,IFo,jFo,tb,qte,DFo,NFo,qI,qFo,OFo,GFo,ab,Ote,XFo,VFo,OI,zFo,WFo,QFo,nb,Gte,HFo,UFo,GI,JFo,YFo,KFo,sb,Xte,ZFo,eCo,XI,oCo,rCo,tCo,lb,Vte,aCo,nCo,VI,sCo,lCo,iCo,ib,zte,dCo,cCo,zI,fCo,mCo,gCo,db,Wte,hCo,pCo,WI,_Co,uCo,bCo,cb,Qte,vCo,TCo,QI,FCo,CCo,MCo,fb,Hte,ECo,yCo,HI,wCo,ACo,LCo,mb,Ute,BCo,xCo,UI,kCo,RCo,SCo,gb,Jte,PCo,$Co,JI,ICo,jCo,DCo,hb,Yte,NCo,qCo,YI,OCo,GCo,XCo,pb,Kte,VCo,zCo,KI,WCo,QCo,HCo,_b,Zte,UCo,JCo,ZI,YCo,KCo,ZCo,ub,eae,eMo,oMo,ej,rMo,tMo,aMo,bb,oae,nMo,sMo,oj,lMo,iMo,dMo,vb,rae,cMo,fMo,rj,mMo,gMo,hMo,Tb,tae,pMo,_Mo,tj,uMo,bMo,vMo,Fb,aae,TMo,FMo,aj,CMo,MMo,EMo,Cb,nae,yMo,wMo,nj,AMo,LMo,BMo,Mb,sae,xMo,kMo,sj,RMo,SMo,PMo,Eb,lae,$Mo,IMo,lj,jMo,DMo,NMo,yb,iae,qMo,OMo,ij,GMo,XMo,VMo,wb,dae,zMo,WMo,dj,QMo,HMo,UMo,Ab,cae,JMo,YMo,cj,KMo,ZMo,e4o,Lb,fae,o4o,r4o,fj,t4o,a4o,n4o,Bb,mae,s4o,l4o,mj,i4o,d4o,c4o,xb,gae,f4o,m4o,gj,g4o,h4o,p4o,kb,hae,_4o,u4o,hj,b4o,v4o,T4o,Rb,pae,F4o,C4o,pj,M4o,E4o,y4o,Sb,_ae,w4o,A4o,_j,L4o,B4o,x4o,Pb,uae,k4o,R4o,uj,S4o,P4o,$4o,$b,bae,I4o,j4o,bj,D4o,N4o,q4o,Ib,vae,O4o,G4o,vj,X4o,V4o,z4o,jb,Tae,W4o,Q4o,Tj,H4o,U4o,J4o,Db,Fae,Y4o,K4o,Fj,Z4o,eEo,oEo,Nb,Cae,rEo,tEo,Cj,aEo,nEo,sEo,qb,Mae,lEo,iEo,Mj,dEo,cEo,fEo,Ob,Eae,mEo,gEo,Ej,hEo,pEo,_Eo,Gb,yae,uEo,bEo,yj,vEo,TEo,FEo,Xb,wae,CEo,MEo,wj,EEo,yEo,wEo,Vb,Aae,AEo,LEo,Aj,BEo,xEo,kEo,zb,REo,Lae,SEo,PEo,Bae,$Eo,IEo,xae,jEo,DEo,AE,uke,Cd,Wb,kae,LE,NEo,Rae,qEo,bke,tr,BE,OEo,Md,GEo,Sae,XEo,VEo,Pae,zEo,WEo,QEo,xE,HEo,$ae,UEo,JEo,YEo,Kr,kE,KEo,Iae,ZEo,e3o,Ed,o3o,jae,r3o,t3o,Dae,a3o,n3o,s3o,Nae,l3o,i3o,RE,d3o,Xe,SE,c3o,qae,f3o,m3o,en,g3o,Oae,h3o,p3o,Gae,_3o,u3o,Xae,b3o,v3o,T3o,O,Qb,Vae,F3o,C3o,Lj,M3o,E3o,y3o,Hb,zae,w3o,A3o,Bj,L3o,B3o,x3o,Ub,Wae,k3o,R3o,xj,S3o,P3o,$3o,Jb,Qae,I3o,j3o,kj,D3o,N3o,q3o,Yb,Hae,O3o,G3o,Rj,X3o,V3o,z3o,Kb,Uae,W3o,Q3o,Sj,H3o,U3o,J3o,Zb,Jae,Y3o,K3o,Pj,Z3o,eyo,oyo,e5,Yae,ryo,tyo,$j,ayo,nyo,syo,o5,Kae,lyo,iyo,Ij,dyo,cyo,fyo,r5,Zae,myo,gyo,jj,hyo,pyo,_yo,t5,ene,uyo,byo,Dj,vyo,Tyo,Fyo,a5,one,Cyo,Myo,Nj,Eyo,yyo,wyo,n5,rne,Ayo,Lyo,qj,Byo,xyo,kyo,s5,tne,Ryo,Syo,Oj,Pyo,$yo,Iyo,l5,ane,jyo,Dyo,Gj,Nyo,qyo,Oyo,i5,nne,Gyo,Xyo,Xj,Vyo,zyo,Wyo,d5,sne,Qyo,Hyo,Vj,Uyo,Jyo,Yyo,c5,lne,Kyo,Zyo,zj,ewo,owo,rwo,f5,ine,two,awo,Wj,nwo,swo,lwo,m5,dne,iwo,dwo,Qj,cwo,fwo,mwo,g5,cne,gwo,hwo,Hj,pwo,_wo,uwo,h5,fne,bwo,vwo,Uj,Two,Fwo,Cwo,p5,mne,Mwo,Ewo,Jj,ywo,wwo,Awo,_5,gne,Lwo,Bwo,Yj,xwo,kwo,Rwo,u5,hne,Swo,Pwo,Kj,$wo,Iwo,jwo,b5,pne,Dwo,Nwo,Zj,qwo,Owo,Gwo,v5,_ne,Xwo,Vwo,eD,zwo,Wwo,Qwo,T5,une,Hwo,Uwo,oD,Jwo,Ywo,Kwo,F5,Zwo,bne,eAo,oAo,vne,rAo,tAo,Tne,aAo,nAo,PE,vke,yd,C5,Fne,$E,sAo,Cne,lAo,Tke,ar,IE,iAo,wd,dAo,Mne,cAo,fAo,Ene,mAo,gAo,hAo,jE,pAo,yne,_Ao,uAo,bAo,Zr,DE,vAo,wne,TAo,FAo,Ad,CAo,Ane,MAo,EAo,Lne,yAo,wAo,AAo,Bne,LAo,BAo,NE,xAo,Ve,qE,kAo,xne,RAo,SAo,on,PAo,kne,$Ao,IAo,Rne,jAo,DAo,Sne,NAo,qAo,OAo,ma,M5,Pne,GAo,XAo,rD,VAo,zAo,WAo,E5,$ne,QAo,HAo,tD,UAo,JAo,YAo,y5,Ine,KAo,ZAo,aD,eLo,oLo,rLo,w5,jne,tLo,aLo,nD,nLo,sLo,lLo,A5,Dne,iLo,dLo,sD,cLo,fLo,mLo,L5,gLo,Nne,hLo,pLo,qne,_Lo,uLo,One,bLo,vLo,OE,Fke,Ld,B5,Gne,GE,TLo,Xne,FLo,Cke,nr,XE,CLo,Bd,MLo,Vne,ELo,yLo,zne,wLo,ALo,LLo,VE,BLo,Wne,xLo,kLo,RLo,et,zE,SLo,Qne,PLo,$Lo,xd,ILo,Hne,jLo,DLo,Une,NLo,qLo,OLo,Jne,GLo,XLo,WE,VLo,ze,QE,zLo,Yne,WLo,QLo,rn,HLo,Kne,ULo,JLo,Zne,YLo,KLo,ese,ZLo,e7o,o7o,N,x5,ose,r7o,t7o,lD,a7o,n7o,s7o,k5,rse,l7o,i7o,iD,d7o,c7o,f7o,R5,tse,m7o,g7o,dD,h7o,p7o,_7o,S5,ase,u7o,b7o,cD,v7o,T7o,F7o,P5,nse,C7o,M7o,fD,E7o,y7o,w7o,$5,sse,A7o,L7o,mD,B7o,x7o,k7o,I5,lse,R7o,S7o,gD,P7o,$7o,I7o,j5,ise,j7o,D7o,hD,N7o,q7o,O7o,D5,dse,G7o,X7o,pD,V7o,z7o,W7o,N5,cse,Q7o,H7o,_D,U7o,J7o,Y7o,q5,fse,K7o,Z7o,uD,e9o,o9o,r9o,O5,mse,t9o,a9o,bD,n9o,s9o,l9o,G5,gse,i9o,d9o,vD,c9o,f9o,m9o,X5,hse,g9o,h9o,TD,p9o,_9o,u9o,V5,pse,b9o,v9o,FD,T9o,F9o,C9o,z5,_se,M9o,E9o,CD,y9o,w9o,A9o,W5,use,L9o,B9o,MD,x9o,k9o,R9o,Q5,bse,S9o,P9o,ED,$9o,I9o,j9o,H5,vse,D9o,N9o,yD,q9o,O9o,G9o,U5,Tse,X9o,V9o,wD,z9o,W9o,Q9o,J5,Fse,H9o,U9o,AD,J9o,Y9o,K9o,Y5,Cse,Z9o,eBo,LD,oBo,rBo,tBo,K5,Mse,aBo,nBo,BD,sBo,lBo,iBo,Z5,Ese,dBo,cBo,xD,fBo,mBo,gBo,e2,yse,hBo,pBo,kD,_Bo,uBo,bBo,o2,wse,vBo,TBo,RD,FBo,CBo,MBo,r2,Ase,EBo,yBo,SD,wBo,ABo,LBo,t2,Lse,BBo,xBo,PD,kBo,RBo,SBo,a2,Bse,PBo,$Bo,$D,IBo,jBo,DBo,n2,xse,NBo,qBo,ID,OBo,GBo,XBo,s2,kse,VBo,zBo,jD,WBo,QBo,HBo,l2,Rse,UBo,JBo,DD,YBo,KBo,ZBo,i2,Sse,exo,oxo,ND,rxo,txo,axo,d2,nxo,Pse,sxo,lxo,$se,ixo,dxo,Ise,cxo,fxo,HE,Mke,kd,c2,jse,UE,mxo,Dse,gxo,Eke,sr,JE,hxo,Rd,pxo,Nse,_xo,uxo,qse,bxo,vxo,Txo,YE,Fxo,Ose,Cxo,Mxo,Exo,ot,KE,yxo,Gse,wxo,Axo,Sd,Lxo,Xse,Bxo,xxo,Vse,kxo,Rxo,Sxo,zse,Pxo,$xo,ZE,Ixo,We,e3,jxo,Wse,Dxo,Nxo,tn,qxo,Qse,Oxo,Gxo,Hse,Xxo,Vxo,Use,zxo,Wxo,Qxo,R,f2,Jse,Hxo,Uxo,qD,Jxo,Yxo,Kxo,m2,Yse,Zxo,eko,OD,oko,rko,tko,g2,Kse,ako,nko,GD,sko,lko,iko,h2,Zse,dko,cko,XD,fko,mko,gko,p2,ele,hko,pko,VD,_ko,uko,bko,_2,ole,vko,Tko,zD,Fko,Cko,Mko,u2,rle,Eko,yko,WD,wko,Ako,Lko,b2,tle,Bko,xko,QD,kko,Rko,Sko,v2,ale,Pko,$ko,HD,Iko,jko,Dko,T2,nle,Nko,qko,UD,Oko,Gko,Xko,F2,sle,Vko,zko,JD,Wko,Qko,Hko,C2,lle,Uko,Jko,YD,Yko,Kko,Zko,M2,ile,eRo,oRo,KD,rRo,tRo,aRo,E2,dle,nRo,sRo,ZD,lRo,iRo,dRo,y2,cle,cRo,fRo,eN,mRo,gRo,hRo,w2,fle,pRo,_Ro,oN,uRo,bRo,vRo,A2,mle,TRo,FRo,rN,CRo,MRo,ERo,L2,gle,yRo,wRo,tN,ARo,LRo,BRo,B2,hle,xRo,kRo,aN,RRo,SRo,PRo,x2,ple,$Ro,IRo,nN,jRo,DRo,NRo,k2,_le,qRo,ORo,sN,GRo,XRo,VRo,R2,ule,zRo,WRo,lN,QRo,HRo,URo,S2,ble,JRo,YRo,iN,KRo,ZRo,eSo,P2,vle,oSo,rSo,dN,tSo,aSo,nSo,$2,Tle,sSo,lSo,cN,iSo,dSo,cSo,I2,Fle,fSo,mSo,fN,gSo,hSo,pSo,j2,Cle,_So,uSo,mN,bSo,vSo,TSo,D2,Mle,FSo,CSo,gN,MSo,ESo,ySo,N2,Ele,wSo,ASo,hN,LSo,BSo,xSo,q2,yle,kSo,RSo,pN,SSo,PSo,$So,O2,wle,ISo,jSo,_N,DSo,NSo,qSo,G2,Ale,OSo,GSo,uN,XSo,VSo,zSo,X2,Lle,WSo,QSo,bN,HSo,USo,JSo,V2,Ble,YSo,KSo,vN,ZSo,ePo,oPo,z2,xle,rPo,tPo,TN,aPo,nPo,sPo,W2,kle,lPo,iPo,FN,dPo,cPo,fPo,Q2,Rle,mPo,gPo,CN,hPo,pPo,_Po,H2,Sle,uPo,bPo,MN,vPo,TPo,FPo,U2,Ple,CPo,MPo,EN,EPo,yPo,wPo,J2,APo,$le,LPo,BPo,Ile,xPo,kPo,jle,RPo,SPo,o3,yke,Pd,Y2,Dle,r3,PPo,Nle,$Po,wke,lr,t3,IPo,$d,jPo,qle,DPo,NPo,Ole,qPo,OPo,GPo,a3,XPo,Gle,VPo,zPo,WPo,rt,n3,QPo,Xle,HPo,UPo,Id,JPo,Vle,YPo,KPo,zle,ZPo,e$o,o$o,Wle,r$o,t$o,s3,a$o,Qe,l3,n$o,Qle,s$o,l$o,an,i$o,Hle,d$o,c$o,Ule,f$o,m$o,Jle,g$o,h$o,p$o,Yle,K2,Kle,_$o,u$o,yN,b$o,v$o,T$o,Z2,F$o,Zle,C$o,M$o,eie,E$o,y$o,oie,w$o,A$o,i3,Ake,jd,ev,rie,d3,L$o,tie,B$o,Lke,ir,c3,x$o,Dd,k$o,aie,R$o,S$o,nie,P$o,$$o,I$o,f3,j$o,sie,D$o,N$o,q$o,tt,m3,O$o,lie,G$o,X$o,Nd,V$o,iie,z$o,W$o,die,Q$o,H$o,U$o,cie,J$o,Y$o,g3,K$o,He,h3,Z$o,fie,eIo,oIo,nn,rIo,mie,tIo,aIo,gie,nIo,sIo,hie,lIo,iIo,dIo,Ce,ov,pie,cIo,fIo,wN,mIo,gIo,hIo,rv,_ie,pIo,_Io,AN,uIo,bIo,vIo,zs,uie,TIo,FIo,LN,CIo,MIo,BN,EIo,yIo,wIo,tv,bie,AIo,LIo,xN,BIo,xIo,kIo,pa,vie,RIo,SIo,kN,PIo,$Io,RN,IIo,jIo,SN,DIo,NIo,qIo,av,Tie,OIo,GIo,PN,XIo,VIo,zIo,nv,Fie,WIo,QIo,$N,HIo,UIo,JIo,sv,Cie,YIo,KIo,IN,ZIo,ejo,ojo,lv,Mie,rjo,tjo,jN,ajo,njo,sjo,iv,ljo,Eie,ijo,djo,yie,cjo,fjo,wie,mjo,gjo,p3,Bke,qd,dv,Aie,_3,hjo,Lie,pjo,xke,dr,u3,_jo,Od,ujo,Bie,bjo,vjo,xie,Tjo,Fjo,Cjo,b3,Mjo,kie,Ejo,yjo,wjo,at,v3,Ajo,Rie,Ljo,Bjo,Gd,xjo,Sie,kjo,Rjo,Pie,Sjo,Pjo,$jo,$ie,Ijo,jjo,T3,Djo,Ue,F3,Njo,Iie,qjo,Ojo,sn,Gjo,jie,Xjo,Vjo,Die,zjo,Wjo,Nie,Qjo,Hjo,Ujo,qie,cv,Oie,Jjo,Yjo,DN,Kjo,Zjo,eDo,fv,oDo,Gie,rDo,tDo,Xie,aDo,nDo,Vie,sDo,lDo,C3,kke,Xd,mv,zie,M3,iDo,Wie,dDo,Rke,cr,E3,cDo,Vd,fDo,Qie,mDo,gDo,Hie,hDo,pDo,_Do,y3,uDo,Uie,bDo,vDo,TDo,nt,w3,FDo,Jie,CDo,MDo,zd,EDo,Yie,yDo,wDo,Kie,ADo,LDo,BDo,Zie,xDo,kDo,A3,RDo,Je,L3,SDo,ede,PDo,$Do,ln,IDo,ode,jDo,DDo,rde,NDo,qDo,tde,ODo,GDo,XDo,xe,gv,ade,VDo,zDo,NN,WDo,QDo,HDo,hv,nde,UDo,JDo,qN,YDo,KDo,ZDo,pv,sde,eNo,oNo,ON,rNo,tNo,aNo,_v,lde,nNo,sNo,GN,lNo,iNo,dNo,uv,ide,cNo,fNo,XN,mNo,gNo,hNo,bv,dde,pNo,_No,VN,uNo,bNo,vNo,vv,cde,TNo,FNo,zN,CNo,MNo,ENo,Tv,fde,yNo,wNo,WN,ANo,LNo,BNo,Fv,xNo,mde,kNo,RNo,gde,SNo,PNo,hde,$No,INo,B3,Ske,Wd,Cv,pde,x3,jNo,_de,DNo,Pke,fr,k3,NNo,Qd,qNo,ude,ONo,GNo,bde,XNo,VNo,zNo,R3,WNo,vde,QNo,HNo,UNo,st,S3,JNo,Tde,YNo,KNo,Hd,ZNo,Fde,eqo,oqo,Cde,rqo,tqo,aqo,Mde,nqo,sqo,P3,lqo,Ye,$3,iqo,Ede,dqo,cqo,dn,fqo,yde,mqo,gqo,wde,hqo,pqo,Ade,_qo,uqo,bqo,cn,Mv,Lde,vqo,Tqo,QN,Fqo,Cqo,Mqo,Ev,Bde,Eqo,yqo,HN,wqo,Aqo,Lqo,yv,xde,Bqo,xqo,UN,kqo,Rqo,Sqo,wv,kde,Pqo,$qo,JN,Iqo,jqo,Dqo,Av,Nqo,Rde,qqo,Oqo,Sde,Gqo,Xqo,Pde,Vqo,zqo,I3,$ke,Ud,Lv,$de,j3,Wqo,Ide,Qqo,Ike,mr,D3,Hqo,Jd,Uqo,jde,Jqo,Yqo,Dde,Kqo,Zqo,eOo,N3,oOo,Nde,rOo,tOo,aOo,lt,q3,nOo,qde,sOo,lOo,Yd,iOo,Ode,dOo,cOo,Gde,fOo,mOo,gOo,Xde,hOo,pOo,O3,_Oo,Ke,G3,uOo,Vde,bOo,vOo,fn,TOo,zde,FOo,COo,Wde,MOo,EOo,Qde,yOo,wOo,AOo,ke,Bv,Hde,LOo,BOo,YN,xOo,kOo,ROo,xv,Ude,SOo,POo,KN,$Oo,IOo,jOo,kv,Jde,DOo,NOo,ZN,qOo,OOo,GOo,Rv,Yde,XOo,VOo,eq,zOo,WOo,QOo,Sv,Kde,HOo,UOo,oq,JOo,YOo,KOo,Pv,Zde,ZOo,eGo,rq,oGo,rGo,tGo,$v,ece,aGo,nGo,tq,sGo,lGo,iGo,Iv,oce,dGo,cGo,aq,fGo,mGo,gGo,jv,hGo,rce,pGo,_Go,tce,uGo,bGo,ace,vGo,TGo,X3,jke,Kd,Dv,nce,V3,FGo,sce,CGo,Dke,gr,z3,MGo,Zd,EGo,lce,yGo,wGo,ice,AGo,LGo,BGo,W3,xGo,dce,kGo,RGo,SGo,it,Q3,PGo,cce,$Go,IGo,ec,jGo,fce,DGo,NGo,mce,qGo,OGo,GGo,gce,XGo,VGo,H3,zGo,Ze,U3,WGo,hce,QGo,HGo,mn,UGo,pce,JGo,YGo,_ce,KGo,ZGo,uce,eXo,oXo,rXo,J3,Nv,bce,tXo,aXo,nq,nXo,sXo,lXo,qv,vce,iXo,dXo,sq,cXo,fXo,mXo,Ov,gXo,Tce,hXo,pXo,Fce,_Xo,uXo,Cce,bXo,vXo,Y3,Nke,oc,Gv,Mce,K3,TXo,Ece,FXo,qke,hr,Z3,CXo,rc,MXo,yce,EXo,yXo,wce,wXo,AXo,LXo,ey,BXo,Ace,xXo,kXo,RXo,dt,oy,SXo,Lce,PXo,$Xo,tc,IXo,Bce,jXo,DXo,xce,NXo,qXo,OXo,kce,GXo,XXo,ry,VXo,eo,ty,zXo,Rce,WXo,QXo,gn,HXo,Sce,UXo,JXo,Pce,YXo,KXo,$ce,ZXo,eVo,oVo,hn,Xv,Ice,rVo,tVo,lq,aVo,nVo,sVo,Vv,jce,lVo,iVo,iq,dVo,cVo,fVo,zv,Dce,mVo,gVo,dq,hVo,pVo,_Vo,Wv,Nce,uVo,bVo,cq,vVo,TVo,FVo,Qv,CVo,qce,MVo,EVo,Oce,yVo,wVo,Gce,AVo,LVo,ay,Oke,ac,Hv,Xce,ny,BVo,Vce,xVo,Gke,pr,sy,kVo,nc,RVo,zce,SVo,PVo,Wce,$Vo,IVo,jVo,ly,DVo,Qce,NVo,qVo,OVo,ct,iy,GVo,Hce,XVo,VVo,sc,zVo,Uce,WVo,QVo,Jce,HVo,UVo,JVo,Yce,YVo,KVo,dy,ZVo,oo,cy,ezo,Kce,ozo,rzo,pn,tzo,Zce,azo,nzo,efe,szo,lzo,ofe,izo,dzo,czo,lc,Uv,rfe,fzo,mzo,fq,gzo,hzo,pzo,Jv,tfe,_zo,uzo,mq,bzo,vzo,Tzo,Yv,afe,Fzo,Czo,gq,Mzo,Ezo,yzo,Kv,wzo,nfe,Azo,Lzo,sfe,Bzo,xzo,lfe,kzo,Rzo,fy,Xke,ic,Zv,ife,my,Szo,dfe,Pzo,Vke,_r,gy,$zo,dc,Izo,cfe,jzo,Dzo,ffe,Nzo,qzo,Ozo,hy,Gzo,mfe,Xzo,Vzo,zzo,ft,py,Wzo,gfe,Qzo,Hzo,cc,Uzo,hfe,Jzo,Yzo,pfe,Kzo,Zzo,eWo,_fe,oWo,rWo,_y,tWo,ro,uy,aWo,ufe,nWo,sWo,_n,lWo,bfe,iWo,dWo,vfe,cWo,fWo,Tfe,mWo,gWo,hWo,Ffe,e6,Cfe,pWo,_Wo,hq,uWo,bWo,vWo,o6,TWo,Mfe,FWo,CWo,Efe,MWo,EWo,yfe,yWo,wWo,by,zke,fc,r6,wfe,vy,AWo,Afe,LWo,Wke,ur,Ty,BWo,mc,xWo,Lfe,kWo,RWo,Bfe,SWo,PWo,$Wo,Fy,IWo,xfe,jWo,DWo,NWo,mt,Cy,qWo,kfe,OWo,GWo,gc,XWo,Rfe,VWo,zWo,Sfe,WWo,QWo,HWo,Pfe,UWo,JWo,My,YWo,to,Ey,KWo,$fe,ZWo,eQo,un,oQo,Ife,rQo,tQo,jfe,aQo,nQo,Dfe,sQo,lQo,iQo,Nfe,t6,qfe,dQo,cQo,pq,fQo,mQo,gQo,a6,hQo,Ofe,pQo,_Qo,Gfe,uQo,bQo,Xfe,vQo,TQo,yy,Qke,hc,n6,Vfe,wy,FQo,zfe,CQo,Hke,br,Ay,MQo,pc,EQo,Wfe,yQo,wQo,Qfe,AQo,LQo,BQo,Ly,xQo,Hfe,kQo,RQo,SQo,gt,By,PQo,Ufe,$Qo,IQo,_c,jQo,Jfe,DQo,NQo,Yfe,qQo,OQo,GQo,Kfe,XQo,VQo,xy,zQo,ao,ky,WQo,Zfe,QQo,HQo,bn,UQo,eme,JQo,YQo,ome,KQo,ZQo,rme,eHo,oHo,rHo,Ry,s6,tme,tHo,aHo,_q,nHo,sHo,lHo,l6,ame,iHo,dHo,uq,cHo,fHo,mHo,i6,gHo,nme,hHo,pHo,sme,_Ho,uHo,lme,bHo,vHo,Sy,Uke,uc,d6,ime,Py,THo,dme,FHo,Jke,vr,$y,CHo,bc,MHo,cme,EHo,yHo,fme,wHo,AHo,LHo,Iy,BHo,mme,xHo,kHo,RHo,ht,jy,SHo,gme,PHo,$Ho,vc,IHo,hme,jHo,DHo,pme,NHo,qHo,OHo,_me,GHo,XHo,Dy,VHo,no,Ny,zHo,ume,WHo,QHo,vn,HHo,bme,UHo,JHo,vme,YHo,KHo,Tme,ZHo,eUo,oUo,Fme,c6,Cme,rUo,tUo,bq,aUo,nUo,sUo,f6,lUo,Mme,iUo,dUo,Eme,cUo,fUo,yme,mUo,gUo,qy,Yke,Tc,m6,wme,Oy,hUo,Ame,pUo,Kke,Tr,Gy,_Uo,Fc,uUo,Lme,bUo,vUo,Bme,TUo,FUo,CUo,Xy,MUo,xme,EUo,yUo,wUo,pt,Vy,AUo,kme,LUo,BUo,Cc,xUo,Rme,kUo,RUo,Sme,SUo,PUo,$Uo,Pme,IUo,jUo,zy,DUo,ho,Wy,NUo,$me,qUo,OUo,Tn,GUo,Ime,XUo,VUo,jme,zUo,WUo,Dme,QUo,HUo,UUo,B,g6,Nme,JUo,YUo,vq,KUo,ZUo,eJo,h6,qme,oJo,rJo,Tq,tJo,aJo,nJo,p6,Ome,sJo,lJo,Fq,iJo,dJo,cJo,_6,Gme,fJo,mJo,Cq,gJo,hJo,pJo,u6,Xme,_Jo,uJo,Mq,bJo,vJo,TJo,b6,Vme,FJo,CJo,Eq,MJo,EJo,yJo,v6,zme,wJo,AJo,yq,LJo,BJo,xJo,T6,Wme,kJo,RJo,wq,SJo,PJo,$Jo,F6,Qme,IJo,jJo,Aq,DJo,NJo,qJo,C6,Hme,OJo,GJo,Lq,XJo,VJo,zJo,M6,Ume,WJo,QJo,Bq,HJo,UJo,JJo,E6,Jme,YJo,KJo,xq,ZJo,eYo,oYo,y6,Yme,rYo,tYo,kq,aYo,nYo,sYo,w6,Kme,lYo,iYo,Rq,dYo,cYo,fYo,A6,Zme,mYo,gYo,Sq,hYo,pYo,_Yo,L6,ege,uYo,bYo,Pq,vYo,TYo,FYo,Ws,oge,CYo,MYo,$q,EYo,yYo,Iq,wYo,AYo,LYo,B6,rge,BYo,xYo,jq,kYo,RYo,SYo,x6,tge,PYo,$Yo,Dq,IYo,jYo,DYo,k6,age,NYo,qYo,Nq,OYo,GYo,XYo,R6,nge,VYo,zYo,qq,WYo,QYo,HYo,S6,sge,UYo,JYo,Oq,YYo,KYo,ZYo,P6,lge,eKo,oKo,Gq,rKo,tKo,aKo,$6,ige,nKo,sKo,Xq,lKo,iKo,dKo,I6,dge,cKo,fKo,Vq,mKo,gKo,hKo,j6,cge,pKo,_Ko,zq,uKo,bKo,vKo,D6,fge,TKo,FKo,Wq,CKo,MKo,EKo,N6,mge,yKo,wKo,Qq,AKo,LKo,BKo,q6,gge,xKo,kKo,Hq,RKo,SKo,PKo,O6,hge,$Ko,IKo,Uq,jKo,DKo,NKo,G6,pge,qKo,OKo,Jq,GKo,XKo,VKo,X6,_ge,zKo,WKo,Yq,QKo,HKo,UKo,V6,uge,JKo,YKo,Kq,KKo,ZKo,eZo,z6,bge,oZo,rZo,Zq,tZo,aZo,nZo,W6,vge,sZo,lZo,eO,iZo,dZo,cZo,Q6,Tge,fZo,mZo,oO,gZo,hZo,pZo,H6,Fge,_Zo,uZo,rO,bZo,vZo,TZo,U6,Cge,FZo,CZo,tO,MZo,EZo,yZo,J6,Mge,wZo,AZo,aO,LZo,BZo,xZo,Y6,Ege,kZo,RZo,nO,SZo,PZo,$Zo,K6,yge,IZo,jZo,sO,DZo,NZo,qZo,Z6,wge,OZo,GZo,lO,XZo,VZo,zZo,Age,WZo,QZo,Qy,Zke,Mc,e0,Lge,Hy,HZo,Bge,UZo,eRe,Fr,Uy,JZo,Ec,YZo,xge,KZo,ZZo,kge,eer,oer,rer,Jy,ter,Rge,aer,ner,ser,_t,Yy,ler,Sge,ier,der,yc,cer,Pge,fer,mer,$ge,ger,her,per,Ige,_er,uer,Ky,ber,po,Zy,ver,jge,Ter,Fer,Fn,Cer,Dge,Mer,Eer,Nge,yer,wer,qge,Aer,Ler,Ber,H,o0,Oge,xer,ker,iO,Rer,Ser,Per,r0,Gge,$er,Ier,dO,jer,Der,Ner,t0,Xge,qer,Oer,cO,Ger,Xer,Ver,a0,Vge,zer,Wer,fO,Qer,Her,Uer,n0,zge,Jer,Yer,mO,Ker,Zer,eor,s0,Wge,oor,ror,gO,tor,aor,nor,l0,Qge,sor,lor,hO,ior,dor,cor,i0,Hge,mor,gor,pO,hor,por,_or,d0,Uge,uor,bor,_O,vor,Tor,For,c0,Jge,Cor,Mor,uO,Eor,yor,wor,f0,Yge,Aor,Lor,bO,Bor,xor,kor,m0,Kge,Ror,Sor,vO,Por,$or,Ior,g0,Zge,jor,Dor,TO,Nor,qor,Oor,h0,ehe,Gor,Xor,FO,Vor,zor,Wor,p0,ohe,Qor,Hor,CO,Uor,Jor,Yor,_0,rhe,Kor,Zor,MO,err,orr,rrr,u0,the,trr,arr,EO,nrr,srr,lrr,b0,ahe,irr,drr,yO,crr,frr,mrr,v0,nhe,grr,hrr,wO,prr,_rr,urr,T0,she,brr,vrr,AO,Trr,Frr,Crr,F0,lhe,Mrr,Err,LO,yrr,wrr,Arr,C0,ihe,Lrr,Brr,BO,xrr,krr,Rrr,dhe,Srr,Prr,ew,oRe,wc,M0,che,ow,$rr,fhe,Irr,rRe,Cr,rw,jrr,Ac,Drr,mhe,Nrr,qrr,ghe,Orr,Grr,Xrr,tw,Vrr,hhe,zrr,Wrr,Qrr,ut,aw,Hrr,phe,Urr,Jrr,Lc,Yrr,_he,Krr,Zrr,uhe,etr,otr,rtr,bhe,ttr,atr,nw,ntr,_o,sw,str,vhe,ltr,itr,Cn,dtr,The,ctr,ftr,Fhe,mtr,gtr,Che,htr,ptr,_tr,me,E0,Mhe,utr,btr,xO,vtr,Ttr,Ftr,y0,Ehe,Ctr,Mtr,kO,Etr,ytr,wtr,w0,yhe,Atr,Ltr,RO,Btr,xtr,ktr,A0,whe,Rtr,Str,SO,Ptr,$tr,Itr,L0,Ahe,jtr,Dtr,PO,Ntr,qtr,Otr,B0,Lhe,Gtr,Xtr,$O,Vtr,ztr,Wtr,x0,Bhe,Qtr,Htr,IO,Utr,Jtr,Ytr,k0,xhe,Ktr,Ztr,jO,ear,oar,rar,R0,khe,tar,aar,DO,nar,sar,lar,S0,Rhe,iar,dar,NO,car,far,mar,P0,She,gar,har,qO,par,_ar,uar,Phe,bar,Tar,lw,tRe,Bc,$0,$he,iw,Far,Ihe,Car,aRe,Mr,dw,Mar,xc,Ear,jhe,yar,war,Dhe,Aar,Lar,Bar,cw,xar,Nhe,kar,Rar,Sar,bt,fw,Par,qhe,$ar,Iar,kc,jar,Ohe,Dar,Nar,Ghe,qar,Oar,Gar,Xhe,Xar,Var,mw,zar,uo,gw,War,Vhe,Qar,Har,Mn,Uar,zhe,Jar,Yar,Whe,Kar,Zar,Qhe,enr,onr,rnr,hw,I0,Hhe,tnr,anr,OO,nnr,snr,lnr,j0,Uhe,inr,dnr,GO,cnr,fnr,mnr,Jhe,gnr,hnr,pw,nRe,Rc,D0,Yhe,_w,pnr,Khe,_nr,sRe,Er,uw,unr,Sc,bnr,Zhe,vnr,Tnr,epe,Fnr,Cnr,Mnr,bw,Enr,ope,ynr,wnr,Anr,vt,vw,Lnr,rpe,Bnr,xnr,Pc,knr,tpe,Rnr,Snr,ape,Pnr,$nr,Inr,npe,jnr,Dnr,Tw,Nnr,bo,Fw,qnr,spe,Onr,Gnr,En,Xnr,lpe,Vnr,znr,ipe,Wnr,Qnr,dpe,Hnr,Unr,Jnr,Y,N0,cpe,Ynr,Knr,XO,Znr,esr,osr,q0,fpe,rsr,tsr,VO,asr,nsr,ssr,O0,mpe,lsr,isr,zO,dsr,csr,fsr,G0,gpe,msr,gsr,WO,hsr,psr,_sr,X0,hpe,usr,bsr,QO,vsr,Tsr,Fsr,V0,ppe,Csr,Msr,HO,Esr,ysr,wsr,z0,_pe,Asr,Lsr,UO,Bsr,xsr,ksr,W0,upe,Rsr,Ssr,JO,Psr,$sr,Isr,Q0,bpe,jsr,Dsr,YO,Nsr,qsr,Osr,H0,vpe,Gsr,Xsr,KO,Vsr,zsr,Wsr,U0,Tpe,Qsr,Hsr,ZO,Usr,Jsr,Ysr,J0,Fpe,Ksr,Zsr,eG,elr,olr,rlr,Y0,Cpe,tlr,alr,oG,nlr,slr,llr,K0,Mpe,ilr,dlr,rG,clr,flr,mlr,Z0,Epe,glr,hlr,tG,plr,_lr,ulr,eT,ype,blr,vlr,aG,Tlr,Flr,Clr,oT,wpe,Mlr,Elr,nG,ylr,wlr,Alr,rT,Ape,Llr,Blr,sG,xlr,klr,Rlr,tT,Lpe,Slr,Plr,lG,$lr,Ilr,jlr,aT,Bpe,Dlr,Nlr,iG,qlr,Olr,Glr,xpe,Xlr,Vlr,Cw,lRe,$c,nT,kpe,Mw,zlr,Rpe,Wlr,iRe,yr,Ew,Qlr,Ic,Hlr,Spe,Ulr,Jlr,Ppe,Ylr,Klr,Zlr,yw,eir,$pe,oir,rir,tir,Tt,ww,air,Ipe,nir,sir,jc,lir,jpe,iir,dir,Dpe,cir,fir,mir,Npe,gir,hir,Aw,pir,vo,Lw,_ir,qpe,uir,bir,yn,vir,Ope,Tir,Fir,Gpe,Cir,Mir,Xpe,Eir,yir,wir,_e,sT,Vpe,Air,Lir,dG,Bir,xir,kir,lT,zpe,Rir,Sir,cG,Pir,$ir,Iir,iT,Wpe,jir,Dir,fG,Nir,qir,Oir,dT,Qpe,Gir,Xir,mG,Vir,zir,Wir,cT,Hpe,Qir,Hir,gG,Uir,Jir,Yir,fT,Upe,Kir,Zir,hG,edr,odr,rdr,mT,Jpe,tdr,adr,pG,ndr,sdr,ldr,gT,Ype,idr,ddr,_G,cdr,fdr,mdr,hT,Kpe,gdr,hdr,uG,pdr,_dr,udr,pT,Zpe,bdr,vdr,bG,Tdr,Fdr,Cdr,e_e,Mdr,Edr,Bw,dRe,Dc,_T,o_e,xw,ydr,r_e,wdr,cRe,wr,kw,Adr,Nc,Ldr,t_e,Bdr,xdr,a_e,kdr,Rdr,Sdr,Rw,Pdr,n_e,$dr,Idr,jdr,Ft,Sw,Ddr,s_e,Ndr,qdr,qc,Odr,l_e,Gdr,Xdr,i_e,Vdr,zdr,Wdr,d_e,Qdr,Hdr,Pw,Udr,To,$w,Jdr,c_e,Ydr,Kdr,wn,Zdr,f_e,ecr,ocr,m_e,rcr,tcr,g_e,acr,ncr,scr,V,uT,h_e,lcr,icr,vG,dcr,ccr,fcr,bT,p_e,mcr,gcr,TG,hcr,pcr,_cr,vT,__e,ucr,bcr,FG,vcr,Tcr,Fcr,TT,u_e,Ccr,Mcr,CG,Ecr,ycr,wcr,FT,b_e,Acr,Lcr,MG,Bcr,xcr,kcr,CT,v_e,Rcr,Scr,EG,Pcr,$cr,Icr,MT,T_e,jcr,Dcr,yG,Ncr,qcr,Ocr,ET,F_e,Gcr,Xcr,wG,Vcr,zcr,Wcr,yT,C_e,Qcr,Hcr,AG,Ucr,Jcr,Ycr,wT,M_e,Kcr,Zcr,LG,efr,ofr,rfr,AT,E_e,tfr,afr,BG,nfr,sfr,lfr,LT,y_e,ifr,dfr,xG,cfr,ffr,mfr,BT,w_e,gfr,hfr,kG,pfr,_fr,ufr,xT,A_e,bfr,vfr,RG,Tfr,Ffr,Cfr,kT,L_e,Mfr,Efr,SG,yfr,wfr,Afr,RT,B_e,Lfr,Bfr,PG,xfr,kfr,Rfr,ST,x_e,Sfr,Pfr,$G,$fr,Ifr,jfr,PT,k_e,Dfr,Nfr,IG,qfr,Ofr,Gfr,$T,R_e,Xfr,Vfr,jG,zfr,Wfr,Qfr,IT,S_e,Hfr,Ufr,DG,Jfr,Yfr,Kfr,jT,P_e,Zfr,emr,NG,omr,rmr,tmr,DT,$_e,amr,nmr,qG,smr,lmr,imr,NT,I_e,dmr,cmr,OG,fmr,mmr,gmr,qT,j_e,hmr,pmr,GG,_mr,umr,bmr,OT,D_e,vmr,Tmr,XG,Fmr,Cmr,Mmr,N_e,Emr,ymr,Iw,fRe,Oc,GT,q_e,jw,wmr,O_e,Amr,mRe,Ar,Dw,Lmr,Gc,Bmr,G_e,xmr,kmr,X_e,Rmr,Smr,Pmr,Nw,$mr,V_e,Imr,jmr,Dmr,Ct,qw,Nmr,z_e,qmr,Omr,Xc,Gmr,W_e,Xmr,Vmr,Q_e,zmr,Wmr,Qmr,H_e,Hmr,Umr,Ow,Jmr,Fo,Gw,Ymr,U_e,Kmr,Zmr,An,egr,J_e,ogr,rgr,Y_e,tgr,agr,K_e,ngr,sgr,lgr,te,XT,Z_e,igr,dgr,VG,cgr,fgr,mgr,VT,eue,ggr,hgr,zG,pgr,_gr,ugr,zT,oue,bgr,vgr,WG,Tgr,Fgr,Cgr,WT,rue,Mgr,Egr,QG,ygr,wgr,Agr,QT,tue,Lgr,Bgr,HG,xgr,kgr,Rgr,HT,aue,Sgr,Pgr,UG,$gr,Igr,jgr,UT,nue,Dgr,Ngr,JG,qgr,Ogr,Ggr,JT,sue,Xgr,Vgr,YG,zgr,Wgr,Qgr,YT,lue,Hgr,Ugr,KG,Jgr,Ygr,Kgr,KT,iue,Zgr,ehr,ZG,ohr,rhr,thr,ZT,due,ahr,nhr,eX,shr,lhr,ihr,e8,cue,dhr,chr,oX,fhr,mhr,ghr,o8,fue,hhr,phr,rX,_hr,uhr,bhr,r8,mue,vhr,Thr,tX,Fhr,Chr,Mhr,t8,gue,Ehr,yhr,aX,whr,Ahr,Lhr,a8,hue,Bhr,xhr,nX,khr,Rhr,Shr,n8,pue,Phr,$hr,sX,Ihr,jhr,Dhr,_ue,Nhr,qhr,Xw,gRe,Vc,s8,uue,Vw,Ohr,bue,Ghr,hRe,Lr,zw,Xhr,zc,Vhr,vue,zhr,Whr,Tue,Qhr,Hhr,Uhr,Ww,Jhr,Fue,Yhr,Khr,Zhr,Mt,Qw,epr,Cue,opr,rpr,Wc,tpr,Mue,apr,npr,Eue,spr,lpr,ipr,yue,dpr,cpr,Hw,fpr,Co,Uw,mpr,wue,gpr,hpr,Ln,ppr,Aue,_pr,upr,Lue,bpr,vpr,Bue,Tpr,Fpr,Cpr,xue,l8,kue,Mpr,Epr,lX,ypr,wpr,Apr,Rue,Lpr,Bpr,Jw,pRe,Qc,i8,Sue,Yw,xpr,Pue,kpr,_Re,Br,Kw,Rpr,Hc,Spr,$ue,Ppr,$pr,Iue,Ipr,jpr,Dpr,Zw,Npr,jue,qpr,Opr,Gpr,Et,eA,Xpr,Due,Vpr,zpr,Uc,Wpr,Nue,Qpr,Hpr,que,Upr,Jpr,Ypr,Oue,Kpr,Zpr,oA,e_r,Mo,rA,o_r,Gue,r_r,t_r,Bn,a_r,Xue,n_r,s_r,Vue,l_r,i_r,zue,d_r,c_r,f_r,K,d8,Wue,m_r,g_r,iX,h_r,p_r,__r,c8,Que,u_r,b_r,dX,v_r,T_r,F_r,f8,Hue,C_r,M_r,cX,E_r,y_r,w_r,m8,Uue,A_r,L_r,fX,B_r,x_r,k_r,g8,Jue,R_r,S_r,mX,P_r,$_r,I_r,h8,Yue,j_r,D_r,gX,N_r,q_r,O_r,p8,Kue,G_r,X_r,hX,V_r,z_r,W_r,_8,Zue,Q_r,H_r,pX,U_r,J_r,Y_r,u8,e1e,K_r,Z_r,_X,eur,our,rur,b8,o1e,tur,aur,uX,nur,sur,lur,v8,r1e,iur,dur,bX,cur,fur,mur,T8,t1e,gur,hur,vX,pur,_ur,uur,F8,a1e,bur,vur,TX,Tur,Fur,Cur,C8,n1e,Mur,Eur,FX,yur,wur,Aur,M8,s1e,Lur,Bur,CX,xur,kur,Rur,E8,l1e,Sur,Pur,MX,$ur,Iur,jur,y8,i1e,Dur,Nur,EX,qur,Our,Gur,w8,d1e,Xur,Vur,yX,zur,Wur,Qur,A8,c1e,Hur,Uur,wX,Jur,Yur,Kur,L8,f1e,Zur,e1r,AX,o1r,r1r,t1r,m1e,a1r,n1r,tA,uRe,Jc,B8,g1e,aA,s1r,h1e,l1r,bRe,xr,nA,i1r,Yc,d1r,p1e,c1r,f1r,_1e,m1r,g1r,h1r,sA,p1r,u1e,_1r,u1r,b1r,yt,lA,v1r,b1e,T1r,F1r,Kc,C1r,v1e,M1r,E1r,T1e,y1r,w1r,A1r,F1e,L1r,B1r,iA,x1r,Eo,dA,k1r,C1e,R1r,S1r,xn,P1r,M1e,$1r,I1r,E1e,j1r,D1r,y1e,N1r,q1r,O1r,Z,x8,w1e,G1r,X1r,LX,V1r,z1r,W1r,k8,A1e,Q1r,H1r,BX,U1r,J1r,Y1r,R8,L1e,K1r,Z1r,xX,ebr,obr,rbr,S8,B1e,tbr,abr,kX,nbr,sbr,lbr,P8,x1e,ibr,dbr,RX,cbr,fbr,mbr,$8,k1e,gbr,hbr,SX,pbr,_br,ubr,I8,R1e,bbr,vbr,PX,Tbr,Fbr,Cbr,j8,S1e,Mbr,Ebr,$X,ybr,wbr,Abr,D8,P1e,Lbr,Bbr,IX,xbr,kbr,Rbr,N8,$1e,Sbr,Pbr,jX,$br,Ibr,jbr,q8,I1e,Dbr,Nbr,DX,qbr,Obr,Gbr,O8,j1e,Xbr,Vbr,NX,zbr,Wbr,Qbr,G8,D1e,Hbr,Ubr,qX,Jbr,Ybr,Kbr,X8,N1e,Zbr,e5r,OX,o5r,r5r,t5r,V8,q1e,a5r,n5r,GX,s5r,l5r,i5r,z8,O1e,d5r,c5r,XX,f5r,m5r,g5r,W8,G1e,h5r,p5r,VX,_5r,u5r,b5r,Q8,X1e,v5r,T5r,zX,F5r,C5r,M5r,H8,V1e,E5r,y5r,WX,w5r,A5r,L5r,z1e,B5r,x5r,cA,vRe,Zc,U8,W1e,fA,k5r,Q1e,R5r,TRe,kr,mA,S5r,ef,P5r,H1e,$5r,I5r,U1e,j5r,D5r,N5r,gA,q5r,J1e,O5r,G5r,X5r,wt,hA,V5r,Y1e,z5r,W5r,of,Q5r,K1e,H5r,U5r,Z1e,J5r,Y5r,K5r,ebe,Z5r,e2r,pA,o2r,yo,_A,r2r,obe,t2r,a2r,kn,n2r,rbe,s2r,l2r,tbe,i2r,d2r,abe,c2r,f2r,m2r,nbe,J8,sbe,g2r,h2r,QX,p2r,_2r,u2r,lbe,b2r,v2r,uA,FRe,rf,Y8,ibe,bA,T2r,dbe,F2r,CRe,Rr,vA,C2r,tf,M2r,cbe,E2r,y2r,fbe,w2r,A2r,L2r,TA,B2r,mbe,x2r,k2r,R2r,At,FA,S2r,gbe,P2r,$2r,af,I2r,hbe,j2r,D2r,pbe,N2r,q2r,O2r,_be,G2r,X2r,CA,V2r,wo,MA,z2r,ube,W2r,Q2r,Rn,H2r,bbe,U2r,J2r,vbe,Y2r,K2r,Tbe,Z2r,evr,ovr,Fbe,K8,Cbe,rvr,tvr,HX,avr,nvr,svr,Mbe,lvr,ivr,EA,MRe,nf,Z8,Ebe,yA,dvr,ybe,cvr,ERe,Sr,wA,fvr,sf,mvr,wbe,gvr,hvr,Abe,pvr,_vr,uvr,AA,bvr,Lbe,vvr,Tvr,Fvr,Lt,LA,Cvr,Bbe,Mvr,Evr,lf,yvr,xbe,wvr,Avr,kbe,Lvr,Bvr,xvr,Rbe,kvr,Rvr,BA,Svr,Ao,xA,Pvr,Sbe,$vr,Ivr,Sn,jvr,Pbe,Dvr,Nvr,$be,qvr,Ovr,Ibe,Gvr,Xvr,Vvr,z,eF,jbe,zvr,Wvr,UX,Qvr,Hvr,Uvr,oF,Dbe,Jvr,Yvr,JX,Kvr,Zvr,e6r,rF,Nbe,o6r,r6r,YX,t6r,a6r,n6r,tF,qbe,s6r,l6r,KX,i6r,d6r,c6r,aF,Obe,f6r,m6r,ZX,g6r,h6r,p6r,nF,Gbe,_6r,u6r,eV,b6r,v6r,T6r,sF,Xbe,F6r,C6r,oV,M6r,E6r,y6r,lF,Vbe,w6r,A6r,rV,L6r,B6r,x6r,iF,zbe,k6r,R6r,tV,S6r,P6r,$6r,dF,Wbe,I6r,j6r,aV,D6r,N6r,q6r,cF,Qbe,O6r,G6r,nV,X6r,V6r,z6r,fF,Hbe,W6r,Q6r,sV,H6r,U6r,J6r,mF,Ube,Y6r,K6r,lV,Z6r,e0r,o0r,gF,Jbe,r0r,t0r,iV,a0r,n0r,s0r,hF,Ybe,l0r,i0r,dV,d0r,c0r,f0r,pF,Kbe,m0r,g0r,cV,h0r,p0r,_0r,_F,Zbe,u0r,b0r,fV,v0r,T0r,F0r,uF,e5e,C0r,M0r,mV,E0r,y0r,w0r,bF,o5e,A0r,L0r,gV,B0r,x0r,k0r,vF,r5e,R0r,S0r,hV,P0r,$0r,I0r,TF,t5e,j0r,D0r,pV,N0r,q0r,O0r,FF,a5e,G0r,X0r,_V,V0r,z0r,W0r,CF,n5e,Q0r,H0r,uV,U0r,J0r,Y0r,MF,s5e,K0r,Z0r,bV,eTr,oTr,rTr,EF,l5e,tTr,aTr,vV,nTr,sTr,lTr,i5e,iTr,dTr,kA,yRe,df,yF,d5e,RA,cTr,c5e,fTr,wRe,Pr,SA,mTr,cf,gTr,f5e,hTr,pTr,m5e,_Tr,uTr,bTr,PA,vTr,g5e,TTr,FTr,CTr,Bt,$A,MTr,h5e,ETr,yTr,ff,wTr,p5e,ATr,LTr,_5e,BTr,xTr,kTr,u5e,RTr,STr,IA,PTr,Lo,jA,$Tr,b5e,ITr,jTr,Pn,DTr,v5e,NTr,qTr,T5e,OTr,GTr,F5e,XTr,VTr,zTr,ga,wF,C5e,WTr,QTr,TV,HTr,UTr,JTr,AF,M5e,YTr,KTr,FV,ZTr,e8r,o8r,LF,E5e,r8r,t8r,CV,a8r,n8r,s8r,BF,y5e,l8r,i8r,MV,d8r,c8r,f8r,xF,w5e,m8r,g8r,EV,h8r,p8r,_8r,A5e,u8r,b8r,DA,ARe,mf,kF,L5e,NA,v8r,B5e,T8r,LRe,$r,qA,F8r,gf,C8r,x5e,M8r,E8r,k5e,y8r,w8r,A8r,OA,L8r,R5e,B8r,x8r,k8r,xt,GA,R8r,S5e,S8r,P8r,hf,$8r,P5e,I8r,j8r,$5e,D8r,N8r,q8r,I5e,O8r,G8r,XA,X8r,Bo,VA,V8r,j5e,z8r,W8r,$n,Q8r,D5e,H8r,U8r,N5e,J8r,Y8r,q5e,K8r,Z8r,eFr,ce,RF,O5e,oFr,rFr,yV,tFr,aFr,nFr,SF,G5e,sFr,lFr,wV,iFr,dFr,cFr,PF,X5e,fFr,mFr,AV,gFr,hFr,pFr,$F,V5e,_Fr,uFr,LV,bFr,vFr,TFr,IF,z5e,FFr,CFr,BV,MFr,EFr,yFr,jF,W5e,wFr,AFr,xV,LFr,BFr,xFr,DF,Q5e,kFr,RFr,kV,SFr,PFr,$Fr,NF,H5e,IFr,jFr,RV,DFr,NFr,qFr,qF,U5e,OFr,GFr,SV,XFr,VFr,zFr,OF,J5e,WFr,QFr,PV,HFr,UFr,JFr,GF,Y5e,YFr,KFr,$V,ZFr,eCr,oCr,XF,K5e,rCr,tCr,IV,aCr,nCr,sCr,Z5e,lCr,iCr,zA,BRe,pf,VF,e2e,WA,dCr,o2e,cCr,xRe,Ir,QA,fCr,_f,mCr,r2e,gCr,hCr,t2e,pCr,_Cr,uCr,HA,bCr,a2e,vCr,TCr,FCr,kt,UA,CCr,n2e,MCr,ECr,uf,yCr,s2e,wCr,ACr,l2e,LCr,BCr,xCr,i2e,kCr,RCr,JA,SCr,xo,YA,PCr,d2e,$Cr,ICr,In,jCr,c2e,DCr,NCr,f2e,qCr,OCr,m2e,GCr,XCr,VCr,ue,zF,g2e,zCr,WCr,jV,QCr,HCr,UCr,WF,h2e,JCr,YCr,DV,KCr,ZCr,eMr,QF,p2e,oMr,rMr,NV,tMr,aMr,nMr,HF,_2e,sMr,lMr,qV,iMr,dMr,cMr,UF,u2e,fMr,mMr,OV,gMr,hMr,pMr,JF,b2e,_Mr,uMr,GV,bMr,vMr,TMr,YF,v2e,FMr,CMr,XV,MMr,EMr,yMr,KF,T2e,wMr,AMr,VV,LMr,BMr,xMr,ZF,F2e,kMr,RMr,zV,SMr,PMr,$Mr,eC,C2e,IMr,jMr,WV,DMr,NMr,qMr,M2e,OMr,GMr,KA,kRe,bf,oC,E2e,ZA,XMr,y2e,VMr,RRe,jr,eL,zMr,vf,WMr,w2e,QMr,HMr,A2e,UMr,JMr,YMr,oL,KMr,L2e,ZMr,e4r,o4r,Rt,rL,r4r,B2e,t4r,a4r,Tf,n4r,x2e,s4r,l4r,k2e,i4r,d4r,c4r,R2e,f4r,m4r,tL,g4r,ko,aL,h4r,S2e,p4r,_4r,jn,u4r,P2e,b4r,v4r,$2e,T4r,F4r,I2e,C4r,M4r,E4r,Me,rC,j2e,y4r,w4r,QV,A4r,L4r,B4r,tC,D2e,x4r,k4r,HV,R4r,S4r,P4r,aC,N2e,$4r,I4r,UV,j4r,D4r,N4r,nC,q2e,q4r,O4r,JV,G4r,X4r,V4r,sC,O2e,z4r,W4r,YV,Q4r,H4r,U4r,lC,G2e,J4r,Y4r,KV,K4r,Z4r,eEr,iC,X2e,oEr,rEr,ZV,tEr,aEr,nEr,dC,V2e,sEr,lEr,ez,iEr,dEr,cEr,cC,z2e,fEr,mEr,oz,gEr,hEr,pEr,W2e,_Er,uEr,nL,SRe,Ff,fC,Q2e,sL,bEr,H2e,vEr,PRe,Dr,lL,TEr,Cf,FEr,U2e,CEr,MEr,J2e,EEr,yEr,wEr,iL,AEr,Y2e,LEr,BEr,xEr,St,dL,kEr,K2e,REr,SEr,Mf,PEr,Z2e,$Er,IEr,eve,jEr,DEr,NEr,ove,qEr,OEr,cL,GEr,Ro,fL,XEr,rve,VEr,zEr,Dn,WEr,tve,QEr,HEr,ave,UEr,JEr,nve,YEr,KEr,ZEr,be,mC,sve,e3r,o3r,rz,r3r,t3r,a3r,gC,lve,n3r,s3r,tz,l3r,i3r,d3r,hC,ive,c3r,f3r,az,m3r,g3r,h3r,pC,dve,p3r,_3r,nz,u3r,b3r,v3r,_C,cve,T3r,F3r,sz,C3r,M3r,E3r,uC,fve,y3r,w3r,lz,A3r,L3r,B3r,bC,mve,x3r,k3r,iz,R3r,S3r,P3r,vC,gve,$3r,I3r,dz,j3r,D3r,N3r,TC,hve,q3r,O3r,cz,G3r,X3r,V3r,FC,pve,z3r,W3r,fz,Q3r,H3r,U3r,_ve,J3r,Y3r,mL,$Re,Ef,CC,uve,gL,K3r,bve,Z3r,IRe,Nr,hL,eyr,yf,oyr,vve,ryr,tyr,Tve,ayr,nyr,syr,pL,lyr,Fve,iyr,dyr,cyr,Pt,_L,fyr,Cve,myr,gyr,wf,hyr,Mve,pyr,_yr,Eve,uyr,byr,vyr,yve,Tyr,Fyr,uL,Cyr,So,bL,Myr,wve,Eyr,yyr,Nn,wyr,Ave,Ayr,Lyr,Lve,Byr,xyr,Bve,kyr,Ryr,Syr,xve,MC,kve,Pyr,$yr,mz,Iyr,jyr,Dyr,Rve,Nyr,qyr,vL,jRe,Af,EC,Sve,TL,Oyr,Pve,Gyr,DRe,qr,FL,Xyr,Lf,Vyr,$ve,zyr,Wyr,Ive,Qyr,Hyr,Uyr,CL,Jyr,jve,Yyr,Kyr,Zyr,$t,ML,ewr,Dve,owr,rwr,Bf,twr,Nve,awr,nwr,qve,swr,lwr,iwr,Ove,dwr,cwr,EL,fwr,Po,yL,mwr,Gve,gwr,hwr,qn,pwr,Xve,_wr,uwr,Vve,bwr,vwr,zve,Twr,Fwr,Cwr,ve,yC,Wve,Mwr,Ewr,gz,ywr,wwr,Awr,wC,Qve,Lwr,Bwr,hz,xwr,kwr,Rwr,AC,Hve,Swr,Pwr,pz,$wr,Iwr,jwr,LC,Uve,Dwr,Nwr,_z,qwr,Owr,Gwr,BC,Jve,Xwr,Vwr,uz,zwr,Wwr,Qwr,xC,Yve,Hwr,Uwr,bz,Jwr,Ywr,Kwr,kC,Kve,Zwr,eAr,vz,oAr,rAr,tAr,RC,Zve,aAr,nAr,Tz,sAr,lAr,iAr,SC,e6e,dAr,cAr,Fz,fAr,mAr,gAr,PC,o6e,hAr,pAr,Cz,_Ar,uAr,bAr,r6e,vAr,TAr,wL,NRe,xf,$C,t6e,AL,FAr,a6e,CAr,qRe,Or,LL,MAr,kf,EAr,n6e,yAr,wAr,s6e,AAr,LAr,BAr,BL,xAr,l6e,kAr,RAr,SAr,It,xL,PAr,i6e,$Ar,IAr,Rf,jAr,d6e,DAr,NAr,c6e,qAr,OAr,GAr,f6e,XAr,VAr,kL,zAr,$o,RL,WAr,m6e,QAr,HAr,On,UAr,g6e,JAr,YAr,h6e,KAr,ZAr,p6e,eLr,oLr,rLr,Re,IC,_6e,tLr,aLr,Mz,nLr,sLr,lLr,jC,u6e,iLr,dLr,Ez,cLr,fLr,mLr,DC,b6e,gLr,hLr,yz,pLr,_Lr,uLr,NC,v6e,bLr,vLr,wz,TLr,FLr,CLr,qC,T6e,MLr,ELr,Az,yLr,wLr,ALr,OC,F6e,LLr,BLr,Lz,xLr,kLr,RLr,GC,C6e,SLr,PLr,Bz,$Lr,ILr,jLr,XC,M6e,DLr,NLr,xz,qLr,OLr,GLr,E6e,XLr,VLr,SL,ORe,Sf,VC,y6e,PL,zLr,w6e,WLr,GRe,Gr,$L,QLr,Pf,HLr,A6e,ULr,JLr,L6e,YLr,KLr,ZLr,IL,e7r,B6e,o7r,r7r,t7r,jt,jL,a7r,x6e,n7r,s7r,$f,l7r,k6e,i7r,d7r,R6e,c7r,f7r,m7r,S6e,g7r,h7r,DL,p7r,Io,NL,_7r,P6e,u7r,b7r,Gn,v7r,$6e,T7r,F7r,I6e,C7r,M7r,j6e,E7r,y7r,w7r,Se,zC,D6e,A7r,L7r,kz,B7r,x7r,k7r,WC,N6e,R7r,S7r,Rz,P7r,$7r,I7r,QC,q6e,j7r,D7r,Sz,N7r,q7r,O7r,HC,O6e,G7r,X7r,Pz,V7r,z7r,W7r,UC,G6e,Q7r,H7r,$z,U7r,J7r,Y7r,JC,X6e,K7r,Z7r,Iz,e9r,o9r,r9r,YC,V6e,t9r,a9r,jz,n9r,s9r,l9r,KC,z6e,i9r,d9r,Dz,c9r,f9r,m9r,W6e,g9r,h9r,qL,XRe,If,ZC,Q6e,OL,p9r,H6e,_9r,VRe,Xr,GL,u9r,jf,b9r,U6e,v9r,T9r,J6e,F9r,C9r,M9r,XL,E9r,Y6e,y9r,w9r,A9r,Dt,VL,L9r,K6e,B9r,x9r,Df,k9r,Z6e,R9r,S9r,e0e,P9r,$9r,I9r,o0e,j9r,D9r,zL,N9r,jo,WL,q9r,r0e,O9r,G9r,Xn,X9r,t0e,V9r,z9r,a0e,W9r,Q9r,n0e,H9r,U9r,J9r,s0e,eM,l0e,Y9r,K9r,Nz,Z9r,eBr,oBr,i0e,rBr,tBr,QL,zRe,Nf,oM,d0e,HL,aBr,c0e,nBr,WRe,Vr,UL,sBr,qf,lBr,f0e,iBr,dBr,m0e,cBr,fBr,mBr,JL,gBr,g0e,hBr,pBr,_Br,Nt,YL,uBr,h0e,bBr,vBr,Of,TBr,p0e,FBr,CBr,_0e,MBr,EBr,yBr,u0e,wBr,ABr,KL,LBr,Do,ZL,BBr,b0e,xBr,kBr,Vn,RBr,v0e,SBr,PBr,T0e,$Br,IBr,F0e,jBr,DBr,NBr,e7,rM,C0e,qBr,OBr,qz,GBr,XBr,VBr,tM,M0e,zBr,WBr,Oz,QBr,HBr,UBr,E0e,JBr,YBr,o7,QRe,Gf,aM,y0e,r7,KBr,w0e,ZBr,HRe,zr,t7,exr,Xf,oxr,A0e,rxr,txr,L0e,axr,nxr,sxr,a7,lxr,B0e,ixr,dxr,cxr,qt,n7,fxr,x0e,mxr,gxr,Vf,hxr,k0e,pxr,_xr,R0e,uxr,bxr,vxr,S0e,Txr,Fxr,s7,Cxr,No,l7,Mxr,P0e,Exr,yxr,zn,wxr,$0e,Axr,Lxr,I0e,Bxr,xxr,j0e,kxr,Rxr,Sxr,D0e,nM,N0e,Pxr,$xr,Gz,Ixr,jxr,Dxr,q0e,Nxr,qxr,i7,URe;return fe=new X({}),Va=new w({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),c4=new X({}),f4=new w({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Yf=new Oxr({props:{warning:"&lcub;true}",$$slots:{default:[I8t]},$$scope:{ctx:Xi}}}),m4=new X({}),g4=new M({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/configuration_auto.py#L527"}}),_4=new M({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/configuration_auto.py#L550",parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}]}}),u4=new w({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

config.unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config.unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),b4=new M({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/configuration_auto.py#L672",parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}]}}),v4=new X({}),T4=new M({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/tokenization_auto.py#L352"}}),M4=new M({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/tokenization_auto.py#L366",parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_16058/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}]}}),E4=new w({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)`}}),y4=new M({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/tokenization_auto.py#L562",parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}]}}),w4=new X({}),A4=new M({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/feature_extraction_auto.py#L170"}}),x4=new M({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/feature_extraction_auto.py#L184",parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_16058/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}]}}),Ph=new Oxr({props:{$$slots:{default:[j8t]},$$scope:{ctx:Xi}}}),k4=new w({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),R4=new M({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/feature_extraction_auto.py#L311",parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}]}}),S4=new X({}),P4=new M({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/processing_auto.py#L71"}}),j4=new M({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/processing_auto.py#L85",parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}]}}),zh=new Oxr({props:{$$slots:{default:[D8t]},$$scope:{ctx:Xi}}}),D4=new w({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),N4=new M({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/processing_auto.py#L238",parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}]}}),q4=new X({}),O4=new M({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L697"}}),X4=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),V4=new w({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),z4=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),W4=new w({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Q4=new X({}),H4=new M({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L704"}}),J4=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),Y4=new w({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),K4=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Z4=new w({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),eE=new X({}),oE=new M({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L719"}}),tE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLMProphetNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),aE=new w({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),nE=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),sE=new w({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),lE=new X({}),iE=new M({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L726"}}),cE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code>(Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),fE=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),mE=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),gE=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),hE=new X({}),pE=new M({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L733"}}),uE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLMProphetNet model)</li>
</ul>`,name:"config"}]}}),bE=new w({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),vE=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),TE=new w({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),FE=new X({}),CE=new M({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L742"}}),EE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),yE=new w({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),wE=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),AE=new w({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),LE=new X({}),BE=new M({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L776"}}),kE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),RE=new w({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),SE=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),PE=new w({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),$E=new X({}),IE=new M({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L783"}}),DE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}]}}),NE=new w({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),qE=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),OE=new w({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),GE=new X({}),XE=new M({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L769"}}),zE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),WE=new w({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),QE=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),HE=new w({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),UE=new X({}),JE=new M({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L751"}}),KE=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBirdPegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (Canine model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (MegatronBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystromformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}]}}),ZE=new w({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),e3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),o3=new w({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),r3=new X({}),t3=new M({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L758"}}),n3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}]}}),s3=new w({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),l3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),i3=new w({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),d3=new X({}),c3=new M({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L792"}}),m3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),g3=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),h3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),p3=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),_3=new X({}),u3=new M({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L831"}}),v3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),T3=new w({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),F3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),C3=new w({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),M3=new X({}),E3=new M({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L838"}}),w3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),A3=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),L3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),B3=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),x3=new X({}),k3=new M({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L861"}}),S3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),P3=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),$3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),I3=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),j3=new X({}),D3=new M({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L845"}}),q3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),O3=new w({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),G3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),X3=new w({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),V3=new X({}),z3=new M({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L852"}}),Q3=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}]}}),H3=new w({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),U3=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Y3=new w({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),K3=new X({}),Z3=new M({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L870"}}),oy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}]}}),ry=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),ty=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),ay=new w({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),ny=new X({}),sy=new M({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L877"}}),iy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}]}}),dy=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),cy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),fy=new w({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),my=new X({}),gy=new M({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L824"}}),py=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
</ul>`,name:"config"}]}}),_y=new w({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),uy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),by=new w({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),vy=new X({}),Ty=new M({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L799"}}),Cy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}]}}),My=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),Ey=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),yy=new w({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),wy=new X({}),Ay=new M({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L806"}}),By=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}]}}),xy=new w({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),ky=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Sy=new w({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Py=new X({}),$y=new M({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_auto.py#L815"}}),jy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}]}}),Dy=new w({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),Ny=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),qy=new w({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Oy=new X({}),Gy=new M({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L374"}}),Vy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),zy=new w({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),Wy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Qy=new w({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Hy=new X({}),Uy=new M({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L381"}}),Yy=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),Ky=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),Zy=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),ew=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),ow=new X({}),rw=new M({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L396"}}),aw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),nw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),sw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),lw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),iw=new X({}),dw=new M({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L403"}}),fw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNext model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),mw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),gw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),pw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),_w=new X({}),uw=new M({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L417"}}),vw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),Tw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),Fw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Cw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Mw=new X({}),Ew=new M({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L424"}}),ww=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}]}}),Aw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),Lw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Bw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),xw=new X({}),kw=new M({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L433"}}),Sw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),Pw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),$w=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Iw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),jw=new X({}),Dw=new M({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L469"}}),qw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),Ow=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),Gw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Xw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Vw=new X({}),zw=new M({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L449"}}),Qw=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}]}}),Hw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),Uw=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),Jw=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),Yw=new X({}),Kw=new M({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L460"}}),eA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),oA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),rA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),tA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),aA=new X({}),nA=new M({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L442"}}),lA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}]}}),iA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),dA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),cA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),fA=new X({}),mA=new M({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L410"}}),hA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),pA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),_A=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),uA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),bA=new X({}),vA=new M({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_tf_auto.py#L485"}}),FA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}]}}),CA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),MA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),EA=new w({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),yA=new X({}),wA=new M({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L237"}}),LA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),BA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),xA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),kA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),RA=new X({}),SA=new M({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L251"}}),$A=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}]}}),IA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),jA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),DA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),NA=new X({}),qA=new M({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L244"}}),GA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),XA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),VA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),zA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),WA=new X({}),QA=new M({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L258"}}),UA=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),JA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),YA=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),KA=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),ZA=new X({}),eL=new M({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L265"}}),rL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (mT5 model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}]}}),tL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),aL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),nL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),sL=new X({}),lL=new M({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),dL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),cL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),fL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),mL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),gL=new X({}),hL=new M({props:{name:"class transformers.FlaxAutoModelForSpeechSeq2Seq",anchor:"transformers.FlaxAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L331"}}),_L=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/speech-encoder-decoder#transformers.FlaxSpeechEncoderDecoderModel">FlaxSpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}]}}),uL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSpeechSeq2Seq.from_config(config)`}}),bL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),vL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),TL=new X({}),FL=new M({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),ML=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),EL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),yL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),wL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),AL=new X({}),LL=new M({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L290"}}),xL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),kL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),RL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),SL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),PL=new X({}),$L=new M({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),jL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}]}}),DL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),NL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),qL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),OL=new X({}),GL=new M({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L306"}}),VL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}]}}),zL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),WL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),QL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),HL=new X({}),UL=new M({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),YL=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}]}}),KL=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),ZL=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),o7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),r7=new X({}),t7=new M({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),n7=new M({props:{name:"from_config",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L390",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_16058/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_16058/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}]}}),s7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),l7=new M({props:{name:"from_pretrained",anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_16058/src/transformers/models/auto/auto_factory.py#L418",parametersDescription:[{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_16058/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.revision(str,",description:`<strong>revision(<code>str</code>,</strong> <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_16058/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}]}}),i7=new w({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){J=a("meta"),Pe=l(),de=a("h1"),he=a("a"),io=a("span"),f(fe.$$.fragment),Fe=l(),zo=a("span"),Vi=o("Auto Classes"),Wf=l(),ha=a("p"),zi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Wi=a("code"),s4=o("from_pretrained()"),Qf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Le=l(),co=a("p"),Qi=o("Instantiating one of "),Wn=a("a"),l4=o("AutoConfig"),Qn=o(", "),Hn=a("a"),i4=o("AutoModel"),Hi=o(`, and
`),Un=a("a"),d4=o("AutoTokenizer"),Ui=o(" will directly create a class of the relevant architecture. For instance"),Hf=l(),f(Va.$$.fragment),fo=l(),pe=a("p"),s9=o("will create a model that is an instance of "),Ji=a("a"),l9=o("BertModel"),i9=o("."),Wo=l(),za=a("p"),d9=o("There is one class of "),Uf=a("code"),c9=o("AutoModel"),c$e=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),Wxe=l(),Yi=a("h2"),Jf=a("a"),jQ=a("span"),f(c4.$$.fragment),f$e=l(),DQ=a("span"),m$e=o("Extending the Auto Classes"),Qxe=l(),Jn=a("p"),g$e=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),NQ=a("code"),h$e=o("NewModel"),p$e=o(", make sure you have a "),qQ=a("code"),_$e=o("NewModelConfig"),u$e=o(` then you can add those to the auto
classes like this:`),Hxe=l(),f(f4.$$.fragment),Uxe=l(),f9=a("p"),b$e=o("You will then be able to use the auto classes like you would usually do!"),Jxe=l(),f(Yf.$$.fragment),Yxe=l(),Ki=a("h2"),Kf=a("a"),OQ=a("span"),f(m4.$$.fragment),v$e=l(),GQ=a("span"),T$e=o("AutoConfig"),Kxe=l(),Qo=a("div"),f(g4.$$.fragment),F$e=l(),h4=a("p"),C$e=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),m9=a("a"),M$e=o("from_pretrained()"),E$e=o(" class method."),y$e=l(),p4=a("p"),w$e=o("This class cannot be instantiated directly using "),XQ=a("code"),A$e=o("__init__()"),L$e=o(" (throws an error)."),B$e=l(),mo=a("div"),f(_4.$$.fragment),x$e=l(),VQ=a("p"),k$e=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),R$e=l(),Zi=a("p"),S$e=o("The configuration class to instantiate is selected based on the "),zQ=a("code"),P$e=o("model_type"),$$e=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),WQ=a("code"),I$e=o("pretrained_model_name_or_path"),j$e=o(":"),D$e=l(),v=a("ul"),Zf=a("li"),QQ=a("strong"),N$e=o("albert"),q$e=o(" \u2014 "),g9=a("a"),O$e=o("AlbertConfig"),G$e=o(" (ALBERT model)"),X$e=l(),em=a("li"),HQ=a("strong"),V$e=o("bart"),z$e=o(" \u2014 "),h9=a("a"),W$e=o("BartConfig"),Q$e=o(" (BART model)"),H$e=l(),om=a("li"),UQ=a("strong"),U$e=o("beit"),J$e=o(" \u2014 "),p9=a("a"),Y$e=o("BeitConfig"),K$e=o(" (BEiT model)"),Z$e=l(),rm=a("li"),JQ=a("strong"),eIe=o("bert"),oIe=o(" \u2014 "),_9=a("a"),rIe=o("BertConfig"),tIe=o(" (BERT model)"),aIe=l(),tm=a("li"),YQ=a("strong"),nIe=o("bert-generation"),sIe=o(" \u2014 "),u9=a("a"),lIe=o("BertGenerationConfig"),iIe=o(" (Bert Generation model)"),dIe=l(),am=a("li"),KQ=a("strong"),cIe=o("big_bird"),fIe=o(" \u2014 "),b9=a("a"),mIe=o("BigBirdConfig"),gIe=o(" (BigBird model)"),hIe=l(),nm=a("li"),ZQ=a("strong"),pIe=o("bigbird_pegasus"),_Ie=o(" \u2014 "),v9=a("a"),uIe=o("BigBirdPegasusConfig"),bIe=o(" (BigBirdPegasus model)"),vIe=l(),sm=a("li"),eH=a("strong"),TIe=o("blenderbot"),FIe=o(" \u2014 "),T9=a("a"),CIe=o("BlenderbotConfig"),MIe=o(" (Blenderbot model)"),EIe=l(),lm=a("li"),oH=a("strong"),yIe=o("blenderbot-small"),wIe=o(" \u2014 "),F9=a("a"),AIe=o("BlenderbotSmallConfig"),LIe=o(" (BlenderbotSmall model)"),BIe=l(),im=a("li"),rH=a("strong"),xIe=o("camembert"),kIe=o(" \u2014 "),C9=a("a"),RIe=o("CamembertConfig"),SIe=o(" (CamemBERT model)"),PIe=l(),dm=a("li"),tH=a("strong"),$Ie=o("canine"),IIe=o(" \u2014 "),M9=a("a"),jIe=o("CanineConfig"),DIe=o(" (Canine model)"),NIe=l(),cm=a("li"),aH=a("strong"),qIe=o("clip"),OIe=o(" \u2014 "),E9=a("a"),GIe=o("CLIPConfig"),XIe=o(" (CLIP model)"),VIe=l(),fm=a("li"),nH=a("strong"),zIe=o("convbert"),WIe=o(" \u2014 "),y9=a("a"),QIe=o("ConvBertConfig"),HIe=o(" (ConvBERT model)"),UIe=l(),mm=a("li"),sH=a("strong"),JIe=o("convnext"),YIe=o(" \u2014 "),w9=a("a"),KIe=o("ConvNextConfig"),ZIe=o(" (ConvNext model)"),eje=l(),gm=a("li"),lH=a("strong"),oje=o("ctrl"),rje=o(" \u2014 "),A9=a("a"),tje=o("CTRLConfig"),aje=o(" (CTRL model)"),nje=l(),hm=a("li"),iH=a("strong"),sje=o("data2vec-audio"),lje=o(" \u2014 "),L9=a("a"),ije=o("Data2VecAudioConfig"),dje=o(" (Data2VecAudio model)"),cje=l(),pm=a("li"),dH=a("strong"),fje=o("data2vec-text"),mje=o(" \u2014 "),B9=a("a"),gje=o("Data2VecTextConfig"),hje=o(" (Data2VecText model)"),pje=l(),_m=a("li"),cH=a("strong"),_je=o("deberta"),uje=o(" \u2014 "),x9=a("a"),bje=o("DebertaConfig"),vje=o(" (DeBERTa model)"),Tje=l(),um=a("li"),fH=a("strong"),Fje=o("deberta-v2"),Cje=o(" \u2014 "),k9=a("a"),Mje=o("DebertaV2Config"),Eje=o(" (DeBERTa-v2 model)"),yje=l(),bm=a("li"),mH=a("strong"),wje=o("deit"),Aje=o(" \u2014 "),R9=a("a"),Lje=o("DeiTConfig"),Bje=o(" (DeiT model)"),xje=l(),vm=a("li"),gH=a("strong"),kje=o("detr"),Rje=o(" \u2014 "),S9=a("a"),Sje=o("DetrConfig"),Pje=o(" (DETR model)"),$je=l(),Tm=a("li"),hH=a("strong"),Ije=o("distilbert"),jje=o(" \u2014 "),P9=a("a"),Dje=o("DistilBertConfig"),Nje=o(" (DistilBERT model)"),qje=l(),Fm=a("li"),pH=a("strong"),Oje=o("dpr"),Gje=o(" \u2014 "),$9=a("a"),Xje=o("DPRConfig"),Vje=o(" (DPR model)"),zje=l(),Cm=a("li"),_H=a("strong"),Wje=o("electra"),Qje=o(" \u2014 "),I9=a("a"),Hje=o("ElectraConfig"),Uje=o(" (ELECTRA model)"),Jje=l(),Mm=a("li"),uH=a("strong"),Yje=o("encoder-decoder"),Kje=o(" \u2014 "),j9=a("a"),Zje=o("EncoderDecoderConfig"),eDe=o(" (Encoder decoder model)"),oDe=l(),Em=a("li"),bH=a("strong"),rDe=o("flaubert"),tDe=o(" \u2014 "),D9=a("a"),aDe=o("FlaubertConfig"),nDe=o(" (FlauBERT model)"),sDe=l(),ym=a("li"),vH=a("strong"),lDe=o("fnet"),iDe=o(" \u2014 "),N9=a("a"),dDe=o("FNetConfig"),cDe=o(" (FNet model)"),fDe=l(),wm=a("li"),TH=a("strong"),mDe=o("fsmt"),gDe=o(" \u2014 "),q9=a("a"),hDe=o("FSMTConfig"),pDe=o(" (FairSeq Machine-Translation model)"),_De=l(),Am=a("li"),FH=a("strong"),uDe=o("funnel"),bDe=o(" \u2014 "),O9=a("a"),vDe=o("FunnelConfig"),TDe=o(" (Funnel Transformer model)"),FDe=l(),Lm=a("li"),CH=a("strong"),CDe=o("gpt2"),MDe=o(" \u2014 "),G9=a("a"),EDe=o("GPT2Config"),yDe=o(" (OpenAI GPT-2 model)"),wDe=l(),Bm=a("li"),MH=a("strong"),ADe=o("gpt_neo"),LDe=o(" \u2014 "),X9=a("a"),BDe=o("GPTNeoConfig"),xDe=o(" (GPT Neo model)"),kDe=l(),xm=a("li"),EH=a("strong"),RDe=o("gptj"),SDe=o(" \u2014 "),V9=a("a"),PDe=o("GPTJConfig"),$De=o(" (GPT-J model)"),IDe=l(),km=a("li"),yH=a("strong"),jDe=o("hubert"),DDe=o(" \u2014 "),z9=a("a"),NDe=o("HubertConfig"),qDe=o(" (Hubert model)"),ODe=l(),Rm=a("li"),wH=a("strong"),GDe=o("ibert"),XDe=o(" \u2014 "),W9=a("a"),VDe=o("IBertConfig"),zDe=o(" (I-BERT model)"),WDe=l(),Sm=a("li"),AH=a("strong"),QDe=o("imagegpt"),HDe=o(" \u2014 "),Q9=a("a"),UDe=o("ImageGPTConfig"),JDe=o(" (ImageGPT model)"),YDe=l(),Pm=a("li"),LH=a("strong"),KDe=o("layoutlm"),ZDe=o(" \u2014 "),H9=a("a"),eNe=o("LayoutLMConfig"),oNe=o(" (LayoutLM model)"),rNe=l(),$m=a("li"),BH=a("strong"),tNe=o("layoutlmv2"),aNe=o(" \u2014 "),U9=a("a"),nNe=o("LayoutLMv2Config"),sNe=o(" (LayoutLMv2 model)"),lNe=l(),Im=a("li"),xH=a("strong"),iNe=o("led"),dNe=o(" \u2014 "),J9=a("a"),cNe=o("LEDConfig"),fNe=o(" (LED model)"),mNe=l(),jm=a("li"),kH=a("strong"),gNe=o("longformer"),hNe=o(" \u2014 "),Y9=a("a"),pNe=o("LongformerConfig"),_Ne=o(" (Longformer model)"),uNe=l(),Dm=a("li"),RH=a("strong"),bNe=o("luke"),vNe=o(" \u2014 "),K9=a("a"),TNe=o("LukeConfig"),FNe=o(" (LUKE model)"),CNe=l(),Nm=a("li"),SH=a("strong"),MNe=o("lxmert"),ENe=o(" \u2014 "),Z9=a("a"),yNe=o("LxmertConfig"),wNe=o(" (LXMERT model)"),ANe=l(),qm=a("li"),PH=a("strong"),LNe=o("m2m_100"),BNe=o(" \u2014 "),eB=a("a"),xNe=o("M2M100Config"),kNe=o(" (M2M100 model)"),RNe=l(),Om=a("li"),$H=a("strong"),SNe=o("marian"),PNe=o(" \u2014 "),oB=a("a"),$Ne=o("MarianConfig"),INe=o(" (Marian model)"),jNe=l(),Gm=a("li"),IH=a("strong"),DNe=o("maskformer"),NNe=o(" \u2014 "),rB=a("a"),qNe=o("MaskFormerConfig"),ONe=o(" (MaskFormer model)"),GNe=l(),Xm=a("li"),jH=a("strong"),XNe=o("mbart"),VNe=o(" \u2014 "),tB=a("a"),zNe=o("MBartConfig"),WNe=o(" (mBART model)"),QNe=l(),Vm=a("li"),DH=a("strong"),HNe=o("megatron-bert"),UNe=o(" \u2014 "),aB=a("a"),JNe=o("MegatronBertConfig"),YNe=o(" (MegatronBert model)"),KNe=l(),zm=a("li"),NH=a("strong"),ZNe=o("mobilebert"),eqe=o(" \u2014 "),nB=a("a"),oqe=o("MobileBertConfig"),rqe=o(" (MobileBERT model)"),tqe=l(),Wm=a("li"),qH=a("strong"),aqe=o("mpnet"),nqe=o(" \u2014 "),sB=a("a"),sqe=o("MPNetConfig"),lqe=o(" (MPNet model)"),iqe=l(),Qm=a("li"),OH=a("strong"),dqe=o("mt5"),cqe=o(" \u2014 "),lB=a("a"),fqe=o("MT5Config"),mqe=o(" (mT5 model)"),gqe=l(),Hm=a("li"),GH=a("strong"),hqe=o("nystromformer"),pqe=o(" \u2014 "),iB=a("a"),_qe=o("NystromformerConfig"),uqe=o(" (Nystromformer model)"),bqe=l(),Um=a("li"),XH=a("strong"),vqe=o("openai-gpt"),Tqe=o(" \u2014 "),dB=a("a"),Fqe=o("OpenAIGPTConfig"),Cqe=o(" (OpenAI GPT model)"),Mqe=l(),Jm=a("li"),VH=a("strong"),Eqe=o("pegasus"),yqe=o(" \u2014 "),cB=a("a"),wqe=o("PegasusConfig"),Aqe=o(" (Pegasus model)"),Lqe=l(),Ym=a("li"),zH=a("strong"),Bqe=o("perceiver"),xqe=o(" \u2014 "),fB=a("a"),kqe=o("PerceiverConfig"),Rqe=o(" (Perceiver model)"),Sqe=l(),Km=a("li"),WH=a("strong"),Pqe=o("plbart"),$qe=o(" \u2014 "),mB=a("a"),Iqe=o("PLBartConfig"),jqe=o(" (PLBart model)"),Dqe=l(),Zm=a("li"),QH=a("strong"),Nqe=o("poolformer"),qqe=o(" \u2014 "),gB=a("a"),Oqe=o("PoolFormerConfig"),Gqe=o(" (PoolFormer model)"),Xqe=l(),eg=a("li"),HH=a("strong"),Vqe=o("prophetnet"),zqe=o(" \u2014 "),hB=a("a"),Wqe=o("ProphetNetConfig"),Qqe=o(" (ProphetNet model)"),Hqe=l(),og=a("li"),UH=a("strong"),Uqe=o("qdqbert"),Jqe=o(" \u2014 "),pB=a("a"),Yqe=o("QDQBertConfig"),Kqe=o(" (QDQBert model)"),Zqe=l(),rg=a("li"),JH=a("strong"),eOe=o("rag"),oOe=o(" \u2014 "),_B=a("a"),rOe=o("RagConfig"),tOe=o(" (RAG model)"),aOe=l(),tg=a("li"),YH=a("strong"),nOe=o("realm"),sOe=o(" \u2014 "),uB=a("a"),lOe=o("RealmConfig"),iOe=o(" (Realm model)"),dOe=l(),ag=a("li"),KH=a("strong"),cOe=o("reformer"),fOe=o(" \u2014 "),bB=a("a"),mOe=o("ReformerConfig"),gOe=o(" (Reformer model)"),hOe=l(),ng=a("li"),ZH=a("strong"),pOe=o("rembert"),_Oe=o(" \u2014 "),vB=a("a"),uOe=o("RemBertConfig"),bOe=o(" (RemBERT model)"),vOe=l(),sg=a("li"),eU=a("strong"),TOe=o("retribert"),FOe=o(" \u2014 "),TB=a("a"),COe=o("RetriBertConfig"),MOe=o(" (RetriBERT model)"),EOe=l(),lg=a("li"),oU=a("strong"),yOe=o("roberta"),wOe=o(" \u2014 "),FB=a("a"),AOe=o("RobertaConfig"),LOe=o(" (RoBERTa model)"),BOe=l(),ig=a("li"),rU=a("strong"),xOe=o("roformer"),kOe=o(" \u2014 "),CB=a("a"),ROe=o("RoFormerConfig"),SOe=o(" (RoFormer model)"),POe=l(),dg=a("li"),tU=a("strong"),$Oe=o("segformer"),IOe=o(" \u2014 "),MB=a("a"),jOe=o("SegformerConfig"),DOe=o(" (SegFormer model)"),NOe=l(),cg=a("li"),aU=a("strong"),qOe=o("sew"),OOe=o(" \u2014 "),EB=a("a"),GOe=o("SEWConfig"),XOe=o(" (SEW model)"),VOe=l(),fg=a("li"),nU=a("strong"),zOe=o("sew-d"),WOe=o(" \u2014 "),yB=a("a"),QOe=o("SEWDConfig"),HOe=o(" (SEW-D model)"),UOe=l(),mg=a("li"),sU=a("strong"),JOe=o("speech-encoder-decoder"),YOe=o(" \u2014 "),wB=a("a"),KOe=o("SpeechEncoderDecoderConfig"),ZOe=o(" (Speech Encoder decoder model)"),eGe=l(),gg=a("li"),lU=a("strong"),oGe=o("speech_to_text"),rGe=o(" \u2014 "),AB=a("a"),tGe=o("Speech2TextConfig"),aGe=o(" (Speech2Text model)"),nGe=l(),hg=a("li"),iU=a("strong"),sGe=o("speech_to_text_2"),lGe=o(" \u2014 "),LB=a("a"),iGe=o("Speech2Text2Config"),dGe=o(" (Speech2Text2 model)"),cGe=l(),pg=a("li"),dU=a("strong"),fGe=o("splinter"),mGe=o(" \u2014 "),BB=a("a"),gGe=o("SplinterConfig"),hGe=o(" (Splinter model)"),pGe=l(),_g=a("li"),cU=a("strong"),_Ge=o("squeezebert"),uGe=o(" \u2014 "),xB=a("a"),bGe=o("SqueezeBertConfig"),vGe=o(" (SqueezeBERT model)"),TGe=l(),ug=a("li"),fU=a("strong"),FGe=o("swin"),CGe=o(" \u2014 "),kB=a("a"),MGe=o("SwinConfig"),EGe=o(" (Swin model)"),yGe=l(),bg=a("li"),mU=a("strong"),wGe=o("t5"),AGe=o(" \u2014 "),RB=a("a"),LGe=o("T5Config"),BGe=o(" (T5 model)"),xGe=l(),vg=a("li"),gU=a("strong"),kGe=o("tapas"),RGe=o(" \u2014 "),SB=a("a"),SGe=o("TapasConfig"),PGe=o(" (TAPAS model)"),$Ge=l(),Tg=a("li"),hU=a("strong"),IGe=o("transfo-xl"),jGe=o(" \u2014 "),PB=a("a"),DGe=o("TransfoXLConfig"),NGe=o(" (Transformer-XL model)"),qGe=l(),Fg=a("li"),pU=a("strong"),OGe=o("trocr"),GGe=o(" \u2014 "),$B=a("a"),XGe=o("TrOCRConfig"),VGe=o(" (TrOCR model)"),zGe=l(),Cg=a("li"),_U=a("strong"),WGe=o("unispeech"),QGe=o(" \u2014 "),IB=a("a"),HGe=o("UniSpeechConfig"),UGe=o(" (UniSpeech model)"),JGe=l(),Mg=a("li"),uU=a("strong"),YGe=o("unispeech-sat"),KGe=o(" \u2014 "),jB=a("a"),ZGe=o("UniSpeechSatConfig"),eXe=o(" (UniSpeechSat model)"),oXe=l(),Eg=a("li"),bU=a("strong"),rXe=o("vilt"),tXe=o(" \u2014 "),DB=a("a"),aXe=o("ViltConfig"),nXe=o(" (ViLT model)"),sXe=l(),yg=a("li"),vU=a("strong"),lXe=o("vision-encoder-decoder"),iXe=o(" \u2014 "),NB=a("a"),dXe=o("VisionEncoderDecoderConfig"),cXe=o(" (Vision Encoder decoder model)"),fXe=l(),wg=a("li"),TU=a("strong"),mXe=o("vision-text-dual-encoder"),gXe=o(" \u2014 "),qB=a("a"),hXe=o("VisionTextDualEncoderConfig"),pXe=o(" (VisionTextDualEncoder model)"),_Xe=l(),Ag=a("li"),FU=a("strong"),uXe=o("visual_bert"),bXe=o(" \u2014 "),OB=a("a"),vXe=o("VisualBertConfig"),TXe=o(" (VisualBert model)"),FXe=l(),Lg=a("li"),CU=a("strong"),CXe=o("vit"),MXe=o(" \u2014 "),GB=a("a"),EXe=o("ViTConfig"),yXe=o(" (ViT model)"),wXe=l(),Bg=a("li"),MU=a("strong"),AXe=o("vit_mae"),LXe=o(" \u2014 "),XB=a("a"),BXe=o("ViTMAEConfig"),xXe=o(" (ViTMAE model)"),kXe=l(),xg=a("li"),EU=a("strong"),RXe=o("wav2vec2"),SXe=o(" \u2014 "),VB=a("a"),PXe=o("Wav2Vec2Config"),$Xe=o(" (Wav2Vec2 model)"),IXe=l(),kg=a("li"),yU=a("strong"),jXe=o("wavlm"),DXe=o(" \u2014 "),zB=a("a"),NXe=o("WavLMConfig"),qXe=o(" (WavLM model)"),OXe=l(),Rg=a("li"),wU=a("strong"),GXe=o("xglm"),XXe=o(" \u2014 "),WB=a("a"),VXe=o("XGLMConfig"),zXe=o(" (XGLM model)"),WXe=l(),Sg=a("li"),AU=a("strong"),QXe=o("xlm"),HXe=o(" \u2014 "),QB=a("a"),UXe=o("XLMConfig"),JXe=o(" (XLM model)"),YXe=l(),Pg=a("li"),LU=a("strong"),KXe=o("xlm-prophetnet"),ZXe=o(" \u2014 "),HB=a("a"),eVe=o("XLMProphetNetConfig"),oVe=o(" (XLMProphetNet model)"),rVe=l(),$g=a("li"),BU=a("strong"),tVe=o("xlm-roberta"),aVe=o(" \u2014 "),UB=a("a"),nVe=o("XLMRobertaConfig"),sVe=o(" (XLM-RoBERTa model)"),lVe=l(),Ig=a("li"),xU=a("strong"),iVe=o("xlm-roberta-xl"),dVe=o(" \u2014 "),JB=a("a"),cVe=o("XLMRobertaXLConfig"),fVe=o(" (XLM-RoBERTa-XL model)"),mVe=l(),jg=a("li"),kU=a("strong"),gVe=o("xlnet"),hVe=o(" \u2014 "),YB=a("a"),pVe=o("XLNetConfig"),_Ve=o(" (XLNet model)"),uVe=l(),Dg=a("li"),RU=a("strong"),bVe=o("yoso"),vVe=o(" \u2014 "),KB=a("a"),TVe=o("YosoConfig"),FVe=o(" (YOSO model)"),CVe=l(),SU=a("p"),MVe=o("Examples:"),EVe=l(),f(u4.$$.fragment),yVe=l(),Ng=a("div"),f(b4.$$.fragment),wVe=l(),PU=a("p"),AVe=o("Register a new configuration for this class."),Zxe=l(),ed=a("h2"),qg=a("a"),$U=a("span"),f(v4.$$.fragment),LVe=l(),IU=a("span"),BVe=o("AutoTokenizer"),eke=l(),Ho=a("div"),f(T4.$$.fragment),xVe=l(),F4=a("p"),kVe=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),ZB=a("a"),RVe=o("AutoTokenizer.from_pretrained()"),SVe=o(" class method."),PVe=l(),C4=a("p"),$Ve=o("This class cannot be instantiated directly using "),jU=a("code"),IVe=o("__init__()"),jVe=o(" (throws an error)."),DVe=l(),go=a("div"),f(M4.$$.fragment),NVe=l(),DU=a("p"),qVe=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),OVe=l(),Wa=a("p"),GVe=o("The tokenizer class to instantiate is selected based on the "),NU=a("code"),XVe=o("model_type"),VVe=o(` property of the config object (either
passed as an argument or loaded from `),qU=a("code"),zVe=o("pretrained_model_name_or_path"),WVe=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OU=a("code"),QVe=o("pretrained_model_name_or_path"),HVe=o(":"),UVe=l(),E=a("ul"),Yn=a("li"),GU=a("strong"),JVe=o("albert"),YVe=o(" \u2014 "),ex=a("a"),KVe=o("AlbertTokenizer"),ZVe=o(" or "),ox=a("a"),eze=o("AlbertTokenizerFast"),oze=o(" (ALBERT model)"),rze=l(),Kn=a("li"),XU=a("strong"),tze=o("bart"),aze=o(" \u2014 "),rx=a("a"),nze=o("BartTokenizer"),sze=o(" or "),tx=a("a"),lze=o("BartTokenizerFast"),ize=o(" (BART model)"),dze=l(),Zn=a("li"),VU=a("strong"),cze=o("barthez"),fze=o(" \u2014 "),ax=a("a"),mze=o("BarthezTokenizer"),gze=o(" or "),nx=a("a"),hze=o("BarthezTokenizerFast"),pze=o(" (BARThez model)"),_ze=l(),Og=a("li"),zU=a("strong"),uze=o("bartpho"),bze=o(" \u2014 "),sx=a("a"),vze=o("BartphoTokenizer"),Tze=o(" (BARTpho model)"),Fze=l(),es=a("li"),WU=a("strong"),Cze=o("bert"),Mze=o(" \u2014 "),lx=a("a"),Eze=o("BertTokenizer"),yze=o(" or "),ix=a("a"),wze=o("BertTokenizerFast"),Aze=o(" (BERT model)"),Lze=l(),Gg=a("li"),QU=a("strong"),Bze=o("bert-generation"),xze=o(" \u2014 "),dx=a("a"),kze=o("BertGenerationTokenizer"),Rze=o(" (Bert Generation model)"),Sze=l(),Xg=a("li"),HU=a("strong"),Pze=o("bert-japanese"),$ze=o(" \u2014 "),cx=a("a"),Ize=o("BertJapaneseTokenizer"),jze=o(" (BertJapanese model)"),Dze=l(),Vg=a("li"),UU=a("strong"),Nze=o("bertweet"),qze=o(" \u2014 "),fx=a("a"),Oze=o("BertweetTokenizer"),Gze=o(" (Bertweet model)"),Xze=l(),os=a("li"),JU=a("strong"),Vze=o("big_bird"),zze=o(" \u2014 "),mx=a("a"),Wze=o("BigBirdTokenizer"),Qze=o(" or "),gx=a("a"),Hze=o("BigBirdTokenizerFast"),Uze=o(" (BigBird model)"),Jze=l(),rs=a("li"),YU=a("strong"),Yze=o("bigbird_pegasus"),Kze=o(" \u2014 "),hx=a("a"),Zze=o("PegasusTokenizer"),eWe=o(" or "),px=a("a"),oWe=o("PegasusTokenizerFast"),rWe=o(" (BigBirdPegasus model)"),tWe=l(),ts=a("li"),KU=a("strong"),aWe=o("blenderbot"),nWe=o(" \u2014 "),_x=a("a"),sWe=o("BlenderbotTokenizer"),lWe=o(" or "),ux=a("a"),iWe=o("BlenderbotTokenizerFast"),dWe=o(" (Blenderbot model)"),cWe=l(),zg=a("li"),ZU=a("strong"),fWe=o("blenderbot-small"),mWe=o(" \u2014 "),bx=a("a"),gWe=o("BlenderbotSmallTokenizer"),hWe=o(" (BlenderbotSmall model)"),pWe=l(),Wg=a("li"),eJ=a("strong"),_We=o("byt5"),uWe=o(" \u2014 "),vx=a("a"),bWe=o("ByT5Tokenizer"),vWe=o(" (ByT5 model)"),TWe=l(),as=a("li"),oJ=a("strong"),FWe=o("camembert"),CWe=o(" \u2014 "),Tx=a("a"),MWe=o("CamembertTokenizer"),EWe=o(" or "),Fx=a("a"),yWe=o("CamembertTokenizerFast"),wWe=o(" (CamemBERT model)"),AWe=l(),Qg=a("li"),rJ=a("strong"),LWe=o("canine"),BWe=o(" \u2014 "),Cx=a("a"),xWe=o("CanineTokenizer"),kWe=o(" (Canine model)"),RWe=l(),ns=a("li"),tJ=a("strong"),SWe=o("clip"),PWe=o(" \u2014 "),Mx=a("a"),$We=o("CLIPTokenizer"),IWe=o(" or "),Ex=a("a"),jWe=o("CLIPTokenizerFast"),DWe=o(" (CLIP model)"),NWe=l(),ss=a("li"),aJ=a("strong"),qWe=o("convbert"),OWe=o(" \u2014 "),yx=a("a"),GWe=o("ConvBertTokenizer"),XWe=o(" or "),wx=a("a"),VWe=o("ConvBertTokenizerFast"),zWe=o(" (ConvBERT model)"),WWe=l(),ls=a("li"),nJ=a("strong"),QWe=o("cpm"),HWe=o(" \u2014 "),Ax=a("a"),UWe=o("CpmTokenizer"),JWe=o(" or "),sJ=a("code"),YWe=o("CpmTokenizerFast"),KWe=o(" (CPM model)"),ZWe=l(),Hg=a("li"),lJ=a("strong"),eQe=o("ctrl"),oQe=o(" \u2014 "),Lx=a("a"),rQe=o("CTRLTokenizer"),tQe=o(" (CTRL model)"),aQe=l(),is=a("li"),iJ=a("strong"),nQe=o("deberta"),sQe=o(" \u2014 "),Bx=a("a"),lQe=o("DebertaTokenizer"),iQe=o(" or "),xx=a("a"),dQe=o("DebertaTokenizerFast"),cQe=o(" (DeBERTa model)"),fQe=l(),Ug=a("li"),dJ=a("strong"),mQe=o("deberta-v2"),gQe=o(" \u2014 "),kx=a("a"),hQe=o("DebertaV2Tokenizer"),pQe=o(" (DeBERTa-v2 model)"),_Qe=l(),ds=a("li"),cJ=a("strong"),uQe=o("distilbert"),bQe=o(" \u2014 "),Rx=a("a"),vQe=o("DistilBertTokenizer"),TQe=o(" or "),Sx=a("a"),FQe=o("DistilBertTokenizerFast"),CQe=o(" (DistilBERT model)"),MQe=l(),cs=a("li"),fJ=a("strong"),EQe=o("dpr"),yQe=o(" \u2014 "),Px=a("a"),wQe=o("DPRQuestionEncoderTokenizer"),AQe=o(" or "),$x=a("a"),LQe=o("DPRQuestionEncoderTokenizerFast"),BQe=o(" (DPR model)"),xQe=l(),fs=a("li"),mJ=a("strong"),kQe=o("electra"),RQe=o(" \u2014 "),Ix=a("a"),SQe=o("ElectraTokenizer"),PQe=o(" or "),jx=a("a"),$Qe=o("ElectraTokenizerFast"),IQe=o(" (ELECTRA model)"),jQe=l(),Jg=a("li"),gJ=a("strong"),DQe=o("flaubert"),NQe=o(" \u2014 "),Dx=a("a"),qQe=o("FlaubertTokenizer"),OQe=o(" (FlauBERT model)"),GQe=l(),ms=a("li"),hJ=a("strong"),XQe=o("fnet"),VQe=o(" \u2014 "),Nx=a("a"),zQe=o("FNetTokenizer"),WQe=o(" or "),qx=a("a"),QQe=o("FNetTokenizerFast"),HQe=o(" (FNet model)"),UQe=l(),Yg=a("li"),pJ=a("strong"),JQe=o("fsmt"),YQe=o(" \u2014 "),Ox=a("a"),KQe=o("FSMTTokenizer"),ZQe=o(" (FairSeq Machine-Translation model)"),eHe=l(),gs=a("li"),_J=a("strong"),oHe=o("funnel"),rHe=o(" \u2014 "),Gx=a("a"),tHe=o("FunnelTokenizer"),aHe=o(" or "),Xx=a("a"),nHe=o("FunnelTokenizerFast"),sHe=o(" (Funnel Transformer model)"),lHe=l(),hs=a("li"),uJ=a("strong"),iHe=o("gpt2"),dHe=o(" \u2014 "),Vx=a("a"),cHe=o("GPT2Tokenizer"),fHe=o(" or "),zx=a("a"),mHe=o("GPT2TokenizerFast"),gHe=o(" (OpenAI GPT-2 model)"),hHe=l(),ps=a("li"),bJ=a("strong"),pHe=o("gpt_neo"),_He=o(" \u2014 "),Wx=a("a"),uHe=o("GPT2Tokenizer"),bHe=o(" or "),Qx=a("a"),vHe=o("GPT2TokenizerFast"),THe=o(" (GPT Neo model)"),FHe=l(),_s=a("li"),vJ=a("strong"),CHe=o("herbert"),MHe=o(" \u2014 "),Hx=a("a"),EHe=o("HerbertTokenizer"),yHe=o(" or "),Ux=a("a"),wHe=o("HerbertTokenizerFast"),AHe=o(" (HerBERT model)"),LHe=l(),Kg=a("li"),TJ=a("strong"),BHe=o("hubert"),xHe=o(" \u2014 "),Jx=a("a"),kHe=o("Wav2Vec2CTCTokenizer"),RHe=o(" (Hubert model)"),SHe=l(),us=a("li"),FJ=a("strong"),PHe=o("ibert"),$He=o(" \u2014 "),Yx=a("a"),IHe=o("RobertaTokenizer"),jHe=o(" or "),Kx=a("a"),DHe=o("RobertaTokenizerFast"),NHe=o(" (I-BERT model)"),qHe=l(),bs=a("li"),CJ=a("strong"),OHe=o("layoutlm"),GHe=o(" \u2014 "),Zx=a("a"),XHe=o("LayoutLMTokenizer"),VHe=o(" or "),ek=a("a"),zHe=o("LayoutLMTokenizerFast"),WHe=o(" (LayoutLM model)"),QHe=l(),vs=a("li"),MJ=a("strong"),HHe=o("layoutlmv2"),UHe=o(" \u2014 "),ok=a("a"),JHe=o("LayoutLMv2Tokenizer"),YHe=o(" or "),rk=a("a"),KHe=o("LayoutLMv2TokenizerFast"),ZHe=o(" (LayoutLMv2 model)"),eUe=l(),Ts=a("li"),EJ=a("strong"),oUe=o("layoutxlm"),rUe=o(" \u2014 "),tk=a("a"),tUe=o("LayoutXLMTokenizer"),aUe=o(" or "),ak=a("a"),nUe=o("LayoutXLMTokenizerFast"),sUe=o(" (LayoutXLM model)"),lUe=l(),Fs=a("li"),yJ=a("strong"),iUe=o("led"),dUe=o(" \u2014 "),nk=a("a"),cUe=o("LEDTokenizer"),fUe=o(" or "),sk=a("a"),mUe=o("LEDTokenizerFast"),gUe=o(" (LED model)"),hUe=l(),Cs=a("li"),wJ=a("strong"),pUe=o("longformer"),_Ue=o(" \u2014 "),lk=a("a"),uUe=o("LongformerTokenizer"),bUe=o(" or "),ik=a("a"),vUe=o("LongformerTokenizerFast"),TUe=o(" (Longformer model)"),FUe=l(),Zg=a("li"),AJ=a("strong"),CUe=o("luke"),MUe=o(" \u2014 "),dk=a("a"),EUe=o("LukeTokenizer"),yUe=o(" (LUKE model)"),wUe=l(),Ms=a("li"),LJ=a("strong"),AUe=o("lxmert"),LUe=o(" \u2014 "),ck=a("a"),BUe=o("LxmertTokenizer"),xUe=o(" or "),fk=a("a"),kUe=o("LxmertTokenizerFast"),RUe=o(" (LXMERT model)"),SUe=l(),eh=a("li"),BJ=a("strong"),PUe=o("m2m_100"),$Ue=o(" \u2014 "),mk=a("a"),IUe=o("M2M100Tokenizer"),jUe=o(" (M2M100 model)"),DUe=l(),oh=a("li"),xJ=a("strong"),NUe=o("marian"),qUe=o(" \u2014 "),gk=a("a"),OUe=o("MarianTokenizer"),GUe=o(" (Marian model)"),XUe=l(),Es=a("li"),kJ=a("strong"),VUe=o("mbart"),zUe=o(" \u2014 "),hk=a("a"),WUe=o("MBartTokenizer"),QUe=o(" or "),pk=a("a"),HUe=o("MBartTokenizerFast"),UUe=o(" (mBART model)"),JUe=l(),ys=a("li"),RJ=a("strong"),YUe=o("mbart50"),KUe=o(" \u2014 "),_k=a("a"),ZUe=o("MBart50Tokenizer"),eJe=o(" or "),uk=a("a"),oJe=o("MBart50TokenizerFast"),rJe=o(" (mBART-50 model)"),tJe=l(),rh=a("li"),SJ=a("strong"),aJe=o("mluke"),nJe=o(" \u2014 "),bk=a("a"),sJe=o("MLukeTokenizer"),lJe=o(" (mLUKE model)"),iJe=l(),ws=a("li"),PJ=a("strong"),dJe=o("mobilebert"),cJe=o(" \u2014 "),vk=a("a"),fJe=o("MobileBertTokenizer"),mJe=o(" or "),Tk=a("a"),gJe=o("MobileBertTokenizerFast"),hJe=o(" (MobileBERT model)"),pJe=l(),As=a("li"),$J=a("strong"),_Je=o("mpnet"),uJe=o(" \u2014 "),Fk=a("a"),bJe=o("MPNetTokenizer"),vJe=o(" or "),Ck=a("a"),TJe=o("MPNetTokenizerFast"),FJe=o(" (MPNet model)"),CJe=l(),Ls=a("li"),IJ=a("strong"),MJe=o("mt5"),EJe=o(" \u2014 "),Mk=a("a"),yJe=o("MT5Tokenizer"),wJe=o(" or "),Ek=a("a"),AJe=o("MT5TokenizerFast"),LJe=o(" (mT5 model)"),BJe=l(),Bs=a("li"),jJ=a("strong"),xJe=o("openai-gpt"),kJe=o(" \u2014 "),yk=a("a"),RJe=o("OpenAIGPTTokenizer"),SJe=o(" or "),wk=a("a"),PJe=o("OpenAIGPTTokenizerFast"),$Je=o(" (OpenAI GPT model)"),IJe=l(),xs=a("li"),DJ=a("strong"),jJe=o("pegasus"),DJe=o(" \u2014 "),Ak=a("a"),NJe=o("PegasusTokenizer"),qJe=o(" or "),Lk=a("a"),OJe=o("PegasusTokenizerFast"),GJe=o(" (Pegasus model)"),XJe=l(),th=a("li"),NJ=a("strong"),VJe=o("perceiver"),zJe=o(" \u2014 "),Bk=a("a"),WJe=o("PerceiverTokenizer"),QJe=o(" (Perceiver model)"),HJe=l(),ah=a("li"),qJ=a("strong"),UJe=o("phobert"),JJe=o(" \u2014 "),xk=a("a"),YJe=o("PhobertTokenizer"),KJe=o(" (PhoBERT model)"),ZJe=l(),nh=a("li"),OJ=a("strong"),eYe=o("plbart"),oYe=o(" \u2014 "),kk=a("a"),rYe=o("PLBartTokenizer"),tYe=o(" (PLBart model)"),aYe=l(),sh=a("li"),GJ=a("strong"),nYe=o("prophetnet"),sYe=o(" \u2014 "),Rk=a("a"),lYe=o("ProphetNetTokenizer"),iYe=o(" (ProphetNet model)"),dYe=l(),ks=a("li"),XJ=a("strong"),cYe=o("qdqbert"),fYe=o(" \u2014 "),Sk=a("a"),mYe=o("BertTokenizer"),gYe=o(" or "),Pk=a("a"),hYe=o("BertTokenizerFast"),pYe=o(" (QDQBert model)"),_Ye=l(),lh=a("li"),VJ=a("strong"),uYe=o("rag"),bYe=o(" \u2014 "),$k=a("a"),vYe=o("RagTokenizer"),TYe=o(" (RAG model)"),FYe=l(),Rs=a("li"),zJ=a("strong"),CYe=o("realm"),MYe=o(" \u2014 "),Ik=a("a"),EYe=o("RealmTokenizer"),yYe=o(" or "),jk=a("a"),wYe=o("RealmTokenizerFast"),AYe=o(" (Realm model)"),LYe=l(),Ss=a("li"),WJ=a("strong"),BYe=o("reformer"),xYe=o(" \u2014 "),Dk=a("a"),kYe=o("ReformerTokenizer"),RYe=o(" or "),Nk=a("a"),SYe=o("ReformerTokenizerFast"),PYe=o(" (Reformer model)"),$Ye=l(),Ps=a("li"),QJ=a("strong"),IYe=o("rembert"),jYe=o(" \u2014 "),qk=a("a"),DYe=o("RemBertTokenizer"),NYe=o(" or "),Ok=a("a"),qYe=o("RemBertTokenizerFast"),OYe=o(" (RemBERT model)"),GYe=l(),$s=a("li"),HJ=a("strong"),XYe=o("retribert"),VYe=o(" \u2014 "),Gk=a("a"),zYe=o("RetriBertTokenizer"),WYe=o(" or "),Xk=a("a"),QYe=o("RetriBertTokenizerFast"),HYe=o(" (RetriBERT model)"),UYe=l(),Is=a("li"),UJ=a("strong"),JYe=o("roberta"),YYe=o(" \u2014 "),Vk=a("a"),KYe=o("RobertaTokenizer"),ZYe=o(" or "),zk=a("a"),eKe=o("RobertaTokenizerFast"),oKe=o(" (RoBERTa model)"),rKe=l(),js=a("li"),JJ=a("strong"),tKe=o("roformer"),aKe=o(" \u2014 "),Wk=a("a"),nKe=o("RoFormerTokenizer"),sKe=o(" or "),Qk=a("a"),lKe=o("RoFormerTokenizerFast"),iKe=o(" (RoFormer model)"),dKe=l(),ih=a("li"),YJ=a("strong"),cKe=o("speech_to_text"),fKe=o(" \u2014 "),Hk=a("a"),mKe=o("Speech2TextTokenizer"),gKe=o(" (Speech2Text model)"),hKe=l(),dh=a("li"),KJ=a("strong"),pKe=o("speech_to_text_2"),_Ke=o(" \u2014 "),Uk=a("a"),uKe=o("Speech2Text2Tokenizer"),bKe=o(" (Speech2Text2 model)"),vKe=l(),Ds=a("li"),ZJ=a("strong"),TKe=o("splinter"),FKe=o(" \u2014 "),Jk=a("a"),CKe=o("SplinterTokenizer"),MKe=o(" or "),Yk=a("a"),EKe=o("SplinterTokenizerFast"),yKe=o(" (Splinter model)"),wKe=l(),Ns=a("li"),eY=a("strong"),AKe=o("squeezebert"),LKe=o(" \u2014 "),Kk=a("a"),BKe=o("SqueezeBertTokenizer"),xKe=o(" or "),Zk=a("a"),kKe=o("SqueezeBertTokenizerFast"),RKe=o(" (SqueezeBERT model)"),SKe=l(),qs=a("li"),oY=a("strong"),PKe=o("t5"),$Ke=o(" \u2014 "),eR=a("a"),IKe=o("T5Tokenizer"),jKe=o(" or "),oR=a("a"),DKe=o("T5TokenizerFast"),NKe=o(" (T5 model)"),qKe=l(),ch=a("li"),rY=a("strong"),OKe=o("tapas"),GKe=o(" \u2014 "),rR=a("a"),XKe=o("TapasTokenizer"),VKe=o(" (TAPAS model)"),zKe=l(),fh=a("li"),tY=a("strong"),WKe=o("transfo-xl"),QKe=o(" \u2014 "),tR=a("a"),HKe=o("TransfoXLTokenizer"),UKe=o(" (Transformer-XL model)"),JKe=l(),mh=a("li"),aY=a("strong"),YKe=o("wav2vec2"),KKe=o(" \u2014 "),aR=a("a"),ZKe=o("Wav2Vec2CTCTokenizer"),eZe=o(" (Wav2Vec2 model)"),oZe=l(),gh=a("li"),nY=a("strong"),rZe=o("wav2vec2_phoneme"),tZe=o(" \u2014 "),nR=a("a"),aZe=o("Wav2Vec2PhonemeCTCTokenizer"),nZe=o(" (Wav2Vec2Phoneme model)"),sZe=l(),Os=a("li"),sY=a("strong"),lZe=o("xglm"),iZe=o(" \u2014 "),sR=a("a"),dZe=o("XGLMTokenizer"),cZe=o(" or "),lR=a("a"),fZe=o("XGLMTokenizerFast"),mZe=o(" (XGLM model)"),gZe=l(),hh=a("li"),lY=a("strong"),hZe=o("xlm"),pZe=o(" \u2014 "),iR=a("a"),_Ze=o("XLMTokenizer"),uZe=o(" (XLM model)"),bZe=l(),ph=a("li"),iY=a("strong"),vZe=o("xlm-prophetnet"),TZe=o(" \u2014 "),dR=a("a"),FZe=o("XLMProphetNetTokenizer"),CZe=o(" (XLMProphetNet model)"),MZe=l(),Gs=a("li"),dY=a("strong"),EZe=o("xlm-roberta"),yZe=o(" \u2014 "),cR=a("a"),wZe=o("XLMRobertaTokenizer"),AZe=o(" or "),fR=a("a"),LZe=o("XLMRobertaTokenizerFast"),BZe=o(" (XLM-RoBERTa model)"),xZe=l(),Xs=a("li"),cY=a("strong"),kZe=o("xlnet"),RZe=o(" \u2014 "),mR=a("a"),SZe=o("XLNetTokenizer"),PZe=o(" or "),gR=a("a"),$Ze=o("XLNetTokenizerFast"),IZe=o(" (XLNet model)"),jZe=l(),fY=a("p"),DZe=o("Examples:"),NZe=l(),f(E4.$$.fragment),qZe=l(),_h=a("div"),f(y4.$$.fragment),OZe=l(),mY=a("p"),GZe=o("Register a new tokenizer in this mapping."),oke=l(),od=a("h2"),uh=a("a"),gY=a("span"),f(w4.$$.fragment),XZe=l(),hY=a("span"),VZe=o("AutoFeatureExtractor"),rke=l(),Uo=a("div"),f(A4.$$.fragment),zZe=l(),L4=a("p"),WZe=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),hR=a("a"),QZe=o("AutoFeatureExtractor.from_pretrained()"),HZe=o(" class method."),UZe=l(),B4=a("p"),JZe=o("This class cannot be instantiated directly using "),pY=a("code"),YZe=o("__init__()"),KZe=o(" (throws an error)."),ZZe=l(),$e=a("div"),f(x4.$$.fragment),eeo=l(),_Y=a("p"),oeo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),reo=l(),Qa=a("p"),teo=o("The feature extractor class to instantiate is selected based on the "),uY=a("code"),aeo=o("model_type"),neo=o(` property of the config object
(either passed as an argument or loaded from `),bY=a("code"),seo=o("pretrained_model_name_or_path"),leo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),vY=a("code"),ieo=o("pretrained_model_name_or_path"),deo=o(":"),ceo=l(),ae=a("ul"),bh=a("li"),TY=a("strong"),feo=o("beit"),meo=o(" \u2014 "),pR=a("a"),geo=o("BeitFeatureExtractor"),heo=o(" (BEiT model)"),peo=l(),vh=a("li"),FY=a("strong"),_eo=o("clip"),ueo=o(" \u2014 "),_R=a("a"),beo=o("CLIPFeatureExtractor"),veo=o(" (CLIP model)"),Teo=l(),Th=a("li"),CY=a("strong"),Feo=o("convnext"),Ceo=o(" \u2014 "),uR=a("a"),Meo=o("ConvNextFeatureExtractor"),Eeo=o(" (ConvNext model)"),yeo=l(),Fh=a("li"),MY=a("strong"),weo=o("deit"),Aeo=o(" \u2014 "),bR=a("a"),Leo=o("DeiTFeatureExtractor"),Beo=o(" (DeiT model)"),xeo=l(),Ch=a("li"),EY=a("strong"),keo=o("detr"),Reo=o(" \u2014 "),vR=a("a"),Seo=o("DetrFeatureExtractor"),Peo=o(" (DETR model)"),$eo=l(),Mh=a("li"),yY=a("strong"),Ieo=o("hubert"),jeo=o(" \u2014 "),TR=a("a"),Deo=o("Wav2Vec2FeatureExtractor"),Neo=o(" (Hubert model)"),qeo=l(),Eh=a("li"),wY=a("strong"),Oeo=o("layoutlmv2"),Geo=o(" \u2014 "),FR=a("a"),Xeo=o("LayoutLMv2FeatureExtractor"),Veo=o(" (LayoutLMv2 model)"),zeo=l(),yh=a("li"),AY=a("strong"),Weo=o("maskformer"),Qeo=o(" \u2014 "),CR=a("a"),Heo=o("MaskFormerFeatureExtractor"),Ueo=o(" (MaskFormer model)"),Jeo=l(),wh=a("li"),LY=a("strong"),Yeo=o("perceiver"),Keo=o(" \u2014 "),MR=a("a"),Zeo=o("PerceiverFeatureExtractor"),eoo=o(" (Perceiver model)"),ooo=l(),Ah=a("li"),BY=a("strong"),roo=o("poolformer"),too=o(" \u2014 "),ER=a("a"),aoo=o("PoolFormerFeatureExtractor"),noo=o(" (PoolFormer model)"),soo=l(),Lh=a("li"),xY=a("strong"),loo=o("segformer"),ioo=o(" \u2014 "),yR=a("a"),doo=o("SegformerFeatureExtractor"),coo=o(" (SegFormer model)"),foo=l(),Bh=a("li"),kY=a("strong"),moo=o("speech_to_text"),goo=o(" \u2014 "),wR=a("a"),hoo=o("Speech2TextFeatureExtractor"),poo=o(" (Speech2Text model)"),_oo=l(),xh=a("li"),RY=a("strong"),uoo=o("swin"),boo=o(" \u2014 "),AR=a("a"),voo=o("ViTFeatureExtractor"),Too=o(" (Swin model)"),Foo=l(),kh=a("li"),SY=a("strong"),Coo=o("vit"),Moo=o(" \u2014 "),LR=a("a"),Eoo=o("ViTFeatureExtractor"),yoo=o(" (ViT model)"),woo=l(),Rh=a("li"),PY=a("strong"),Aoo=o("vit_mae"),Loo=o(" \u2014 "),BR=a("a"),Boo=o("ViTFeatureExtractor"),xoo=o(" (ViTMAE model)"),koo=l(),Sh=a("li"),$Y=a("strong"),Roo=o("wav2vec2"),Soo=o(" \u2014 "),xR=a("a"),Poo=o("Wav2Vec2FeatureExtractor"),$oo=o(" (Wav2Vec2 model)"),Ioo=l(),f(Ph.$$.fragment),joo=l(),IY=a("p"),Doo=o("Examples:"),Noo=l(),f(k4.$$.fragment),qoo=l(),$h=a("div"),f(R4.$$.fragment),Ooo=l(),jY=a("p"),Goo=o("Register a new feature extractor for this class."),tke=l(),rd=a("h2"),Ih=a("a"),DY=a("span"),f(S4.$$.fragment),Xoo=l(),NY=a("span"),Voo=o("AutoProcessor"),ake=l(),Jo=a("div"),f(P4.$$.fragment),zoo=l(),$4=a("p"),Woo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),kR=a("a"),Qoo=o("AutoProcessor.from_pretrained()"),Hoo=o(" class method."),Uoo=l(),I4=a("p"),Joo=o("This class cannot be instantiated directly using "),qY=a("code"),Yoo=o("__init__()"),Koo=o(" (throws an error)."),Zoo=l(),Ie=a("div"),f(j4.$$.fragment),ero=l(),OY=a("p"),oro=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),rro=l(),td=a("p"),tro=o("The processor class to instantiate is selected based on the "),GY=a("code"),aro=o("model_type"),nro=o(` property of the config object (either
passed as an argument or loaded from `),XY=a("code"),sro=o("pretrained_model_name_or_path"),lro=o(" if possible):"),iro=l(),Be=a("ul"),jh=a("li"),VY=a("strong"),dro=o("clip"),cro=o(" \u2014 "),RR=a("a"),fro=o("CLIPProcessor"),mro=o(" (CLIP model)"),gro=l(),Dh=a("li"),zY=a("strong"),hro=o("layoutlmv2"),pro=o(" \u2014 "),SR=a("a"),_ro=o("LayoutLMv2Processor"),uro=o(" (LayoutLMv2 model)"),bro=l(),Nh=a("li"),WY=a("strong"),vro=o("layoutxlm"),Tro=o(" \u2014 "),PR=a("a"),Fro=o("LayoutXLMProcessor"),Cro=o(" (LayoutXLM model)"),Mro=l(),qh=a("li"),QY=a("strong"),Ero=o("speech_to_text"),yro=o(" \u2014 "),$R=a("a"),wro=o("Speech2TextProcessor"),Aro=o(" (Speech2Text model)"),Lro=l(),Oh=a("li"),HY=a("strong"),Bro=o("speech_to_text_2"),xro=o(" \u2014 "),IR=a("a"),kro=o("Speech2Text2Processor"),Rro=o(" (Speech2Text2 model)"),Sro=l(),Gh=a("li"),UY=a("strong"),Pro=o("trocr"),$ro=o(" \u2014 "),jR=a("a"),Iro=o("TrOCRProcessor"),jro=o(" (TrOCR model)"),Dro=l(),Xh=a("li"),JY=a("strong"),Nro=o("vision-text-dual-encoder"),qro=o(" \u2014 "),DR=a("a"),Oro=o("VisionTextDualEncoderProcessor"),Gro=o(" (VisionTextDualEncoder model)"),Xro=l(),Vh=a("li"),YY=a("strong"),Vro=o("wav2vec2"),zro=o(" \u2014 "),NR=a("a"),Wro=o("Wav2Vec2Processor"),Qro=o(" (Wav2Vec2 model)"),Hro=l(),f(zh.$$.fragment),Uro=l(),KY=a("p"),Jro=o("Examples:"),Yro=l(),f(D4.$$.fragment),Kro=l(),Wh=a("div"),f(N4.$$.fragment),Zro=l(),ZY=a("p"),eto=o("Register a new processor for this class."),nke=l(),ad=a("h2"),Qh=a("a"),eK=a("span"),f(q4.$$.fragment),oto=l(),oK=a("span"),rto=o("AutoModel"),ske=l(),Yo=a("div"),f(O4.$$.fragment),tto=l(),nd=a("p"),ato=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rK=a("code"),nto=o("from_pretrained()"),sto=o("class method or the "),tK=a("code"),lto=o("from_config()"),ito=o(`class
method.`),dto=l(),G4=a("p"),cto=o("This class cannot be instantiated directly using "),aK=a("code"),fto=o("__init__()"),mto=o(" (throws an error)."),gto=l(),Wr=a("div"),f(X4.$$.fragment),hto=l(),nK=a("p"),pto=o("Instantiates one of the base model classes of the library from a configuration."),_to=l(),sd=a("p"),uto=o(`Note:
Loading a model from its configuration file does `),sK=a("strong"),bto=o("not"),vto=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lK=a("code"),Tto=o("from_pretrained()"),Fto=o("to load the model weights."),Cto=l(),iK=a("p"),Mto=o("Examples:"),Eto=l(),f(V4.$$.fragment),yto=l(),je=a("div"),f(z4.$$.fragment),wto=l(),dK=a("p"),Ato=o("Instantiate one of the base model classes of the library from a pretrained model."),Lto=l(),Ha=a("p"),Bto=o("The model class to instantiate is selected based on the "),cK=a("code"),xto=o("model_type"),kto=o(` property of the config object (either
passed as an argument or loaded from `),fK=a("code"),Rto=o("pretrained_model_name_or_path"),Sto=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mK=a("code"),Pto=o("pretrained_model_name_or_path"),$to=o(":"),Ito=l(),F=a("ul"),Hh=a("li"),gK=a("strong"),jto=o("albert"),Dto=o(" \u2014 "),qR=a("a"),Nto=o("AlbertModel"),qto=o(" (ALBERT model)"),Oto=l(),Uh=a("li"),hK=a("strong"),Gto=o("bart"),Xto=o(" \u2014 "),OR=a("a"),Vto=o("BartModel"),zto=o(" (BART model)"),Wto=l(),Jh=a("li"),pK=a("strong"),Qto=o("beit"),Hto=o(" \u2014 "),GR=a("a"),Uto=o("BeitModel"),Jto=o(" (BEiT model)"),Yto=l(),Yh=a("li"),_K=a("strong"),Kto=o("bert"),Zto=o(" \u2014 "),XR=a("a"),eao=o("BertModel"),oao=o(" (BERT model)"),rao=l(),Kh=a("li"),uK=a("strong"),tao=o("bert-generation"),aao=o(" \u2014 "),VR=a("a"),nao=o("BertGenerationEncoder"),sao=o(" (Bert Generation model)"),lao=l(),Zh=a("li"),bK=a("strong"),iao=o("big_bird"),dao=o(" \u2014 "),zR=a("a"),cao=o("BigBirdModel"),fao=o(" (BigBird model)"),mao=l(),ep=a("li"),vK=a("strong"),gao=o("bigbird_pegasus"),hao=o(" \u2014 "),WR=a("a"),pao=o("BigBirdPegasusModel"),_ao=o(" (BigBirdPegasus model)"),uao=l(),op=a("li"),TK=a("strong"),bao=o("blenderbot"),vao=o(" \u2014 "),QR=a("a"),Tao=o("BlenderbotModel"),Fao=o(" (Blenderbot model)"),Cao=l(),rp=a("li"),FK=a("strong"),Mao=o("blenderbot-small"),Eao=o(" \u2014 "),HR=a("a"),yao=o("BlenderbotSmallModel"),wao=o(" (BlenderbotSmall model)"),Aao=l(),tp=a("li"),CK=a("strong"),Lao=o("camembert"),Bao=o(" \u2014 "),UR=a("a"),xao=o("CamembertModel"),kao=o(" (CamemBERT model)"),Rao=l(),ap=a("li"),MK=a("strong"),Sao=o("canine"),Pao=o(" \u2014 "),JR=a("a"),$ao=o("CanineModel"),Iao=o(" (Canine model)"),jao=l(),np=a("li"),EK=a("strong"),Dao=o("clip"),Nao=o(" \u2014 "),YR=a("a"),qao=o("CLIPModel"),Oao=o(" (CLIP model)"),Gao=l(),sp=a("li"),yK=a("strong"),Xao=o("convbert"),Vao=o(" \u2014 "),KR=a("a"),zao=o("ConvBertModel"),Wao=o(" (ConvBERT model)"),Qao=l(),lp=a("li"),wK=a("strong"),Hao=o("convnext"),Uao=o(" \u2014 "),ZR=a("a"),Jao=o("ConvNextModel"),Yao=o(" (ConvNext model)"),Kao=l(),ip=a("li"),AK=a("strong"),Zao=o("ctrl"),eno=o(" \u2014 "),eS=a("a"),ono=o("CTRLModel"),rno=o(" (CTRL model)"),tno=l(),dp=a("li"),LK=a("strong"),ano=o("data2vec-audio"),nno=o(" \u2014 "),oS=a("a"),sno=o("Data2VecAudioModel"),lno=o(" (Data2VecAudio model)"),ino=l(),cp=a("li"),BK=a("strong"),dno=o("data2vec-text"),cno=o(" \u2014 "),rS=a("a"),fno=o("Data2VecTextModel"),mno=o(" (Data2VecText model)"),gno=l(),fp=a("li"),xK=a("strong"),hno=o("deberta"),pno=o(" \u2014 "),tS=a("a"),_no=o("DebertaModel"),uno=o(" (DeBERTa model)"),bno=l(),mp=a("li"),kK=a("strong"),vno=o("deberta-v2"),Tno=o(" \u2014 "),aS=a("a"),Fno=o("DebertaV2Model"),Cno=o(" (DeBERTa-v2 model)"),Mno=l(),gp=a("li"),RK=a("strong"),Eno=o("deit"),yno=o(" \u2014 "),nS=a("a"),wno=o("DeiTModel"),Ano=o(" (DeiT model)"),Lno=l(),hp=a("li"),SK=a("strong"),Bno=o("detr"),xno=o(" \u2014 "),sS=a("a"),kno=o("DetrModel"),Rno=o(" (DETR model)"),Sno=l(),pp=a("li"),PK=a("strong"),Pno=o("distilbert"),$no=o(" \u2014 "),lS=a("a"),Ino=o("DistilBertModel"),jno=o(" (DistilBERT model)"),Dno=l(),_p=a("li"),$K=a("strong"),Nno=o("dpr"),qno=o(" \u2014 "),iS=a("a"),Ono=o("DPRQuestionEncoder"),Gno=o(" (DPR model)"),Xno=l(),up=a("li"),IK=a("strong"),Vno=o("electra"),zno=o(" \u2014 "),dS=a("a"),Wno=o("ElectraModel"),Qno=o(" (ELECTRA model)"),Hno=l(),bp=a("li"),jK=a("strong"),Uno=o("flaubert"),Jno=o(" \u2014 "),cS=a("a"),Yno=o("FlaubertModel"),Kno=o(" (FlauBERT model)"),Zno=l(),vp=a("li"),DK=a("strong"),eso=o("fnet"),oso=o(" \u2014 "),fS=a("a"),rso=o("FNetModel"),tso=o(" (FNet model)"),aso=l(),Tp=a("li"),NK=a("strong"),nso=o("fsmt"),sso=o(" \u2014 "),mS=a("a"),lso=o("FSMTModel"),iso=o(" (FairSeq Machine-Translation model)"),dso=l(),Vs=a("li"),qK=a("strong"),cso=o("funnel"),fso=o(" \u2014 "),gS=a("a"),mso=o("FunnelModel"),gso=o(" or "),hS=a("a"),hso=o("FunnelBaseModel"),pso=o(" (Funnel Transformer model)"),_so=l(),Fp=a("li"),OK=a("strong"),uso=o("gpt2"),bso=o(" \u2014 "),pS=a("a"),vso=o("GPT2Model"),Tso=o(" (OpenAI GPT-2 model)"),Fso=l(),Cp=a("li"),GK=a("strong"),Cso=o("gpt_neo"),Mso=o(" \u2014 "),_S=a("a"),Eso=o("GPTNeoModel"),yso=o(" (GPT Neo model)"),wso=l(),Mp=a("li"),XK=a("strong"),Aso=o("gptj"),Lso=o(" \u2014 "),uS=a("a"),Bso=o("GPTJModel"),xso=o(" (GPT-J model)"),kso=l(),Ep=a("li"),VK=a("strong"),Rso=o("hubert"),Sso=o(" \u2014 "),bS=a("a"),Pso=o("HubertModel"),$so=o(" (Hubert model)"),Iso=l(),yp=a("li"),zK=a("strong"),jso=o("ibert"),Dso=o(" \u2014 "),vS=a("a"),Nso=o("IBertModel"),qso=o(" (I-BERT model)"),Oso=l(),wp=a("li"),WK=a("strong"),Gso=o("imagegpt"),Xso=o(" \u2014 "),TS=a("a"),Vso=o("ImageGPTModel"),zso=o(" (ImageGPT model)"),Wso=l(),Ap=a("li"),QK=a("strong"),Qso=o("layoutlm"),Hso=o(" \u2014 "),FS=a("a"),Uso=o("LayoutLMModel"),Jso=o(" (LayoutLM model)"),Yso=l(),Lp=a("li"),HK=a("strong"),Kso=o("layoutlmv2"),Zso=o(" \u2014 "),CS=a("a"),elo=o("LayoutLMv2Model"),olo=o(" (LayoutLMv2 model)"),rlo=l(),Bp=a("li"),UK=a("strong"),tlo=o("led"),alo=o(" \u2014 "),MS=a("a"),nlo=o("LEDModel"),slo=o(" (LED model)"),llo=l(),xp=a("li"),JK=a("strong"),ilo=o("longformer"),dlo=o(" \u2014 "),ES=a("a"),clo=o("LongformerModel"),flo=o(" (Longformer model)"),mlo=l(),kp=a("li"),YK=a("strong"),glo=o("luke"),hlo=o(" \u2014 "),yS=a("a"),plo=o("LukeModel"),_lo=o(" (LUKE model)"),ulo=l(),Rp=a("li"),KK=a("strong"),blo=o("lxmert"),vlo=o(" \u2014 "),wS=a("a"),Tlo=o("LxmertModel"),Flo=o(" (LXMERT model)"),Clo=l(),Sp=a("li"),ZK=a("strong"),Mlo=o("m2m_100"),Elo=o(" \u2014 "),AS=a("a"),ylo=o("M2M100Model"),wlo=o(" (M2M100 model)"),Alo=l(),Pp=a("li"),eZ=a("strong"),Llo=o("marian"),Blo=o(" \u2014 "),LS=a("a"),xlo=o("MarianModel"),klo=o(" (Marian model)"),Rlo=l(),$p=a("li"),oZ=a("strong"),Slo=o("maskformer"),Plo=o(" \u2014 "),BS=a("a"),$lo=o("MaskFormerModel"),Ilo=o(" (MaskFormer model)"),jlo=l(),Ip=a("li"),rZ=a("strong"),Dlo=o("mbart"),Nlo=o(" \u2014 "),xS=a("a"),qlo=o("MBartModel"),Olo=o(" (mBART model)"),Glo=l(),jp=a("li"),tZ=a("strong"),Xlo=o("megatron-bert"),Vlo=o(" \u2014 "),kS=a("a"),zlo=o("MegatronBertModel"),Wlo=o(" (MegatronBert model)"),Qlo=l(),Dp=a("li"),aZ=a("strong"),Hlo=o("mobilebert"),Ulo=o(" \u2014 "),RS=a("a"),Jlo=o("MobileBertModel"),Ylo=o(" (MobileBERT model)"),Klo=l(),Np=a("li"),nZ=a("strong"),Zlo=o("mpnet"),eio=o(" \u2014 "),SS=a("a"),oio=o("MPNetModel"),rio=o(" (MPNet model)"),tio=l(),qp=a("li"),sZ=a("strong"),aio=o("mt5"),nio=o(" \u2014 "),PS=a("a"),sio=o("MT5Model"),lio=o(" (mT5 model)"),iio=l(),Op=a("li"),lZ=a("strong"),dio=o("nystromformer"),cio=o(" \u2014 "),$S=a("a"),fio=o("NystromformerModel"),mio=o(" (Nystromformer model)"),gio=l(),Gp=a("li"),iZ=a("strong"),hio=o("openai-gpt"),pio=o(" \u2014 "),IS=a("a"),_io=o("OpenAIGPTModel"),uio=o(" (OpenAI GPT model)"),bio=l(),Xp=a("li"),dZ=a("strong"),vio=o("pegasus"),Tio=o(" \u2014 "),jS=a("a"),Fio=o("PegasusModel"),Cio=o(" (Pegasus model)"),Mio=l(),Vp=a("li"),cZ=a("strong"),Eio=o("perceiver"),yio=o(" \u2014 "),DS=a("a"),wio=o("PerceiverModel"),Aio=o(" (Perceiver model)"),Lio=l(),zp=a("li"),fZ=a("strong"),Bio=o("plbart"),xio=o(" \u2014 "),NS=a("a"),kio=o("PLBartModel"),Rio=o(" (PLBart model)"),Sio=l(),Wp=a("li"),mZ=a("strong"),Pio=o("poolformer"),$io=o(" \u2014 "),qS=a("a"),Iio=o("PoolFormerModel"),jio=o(" (PoolFormer model)"),Dio=l(),Qp=a("li"),gZ=a("strong"),Nio=o("prophetnet"),qio=o(" \u2014 "),OS=a("a"),Oio=o("ProphetNetModel"),Gio=o(" (ProphetNet model)"),Xio=l(),Hp=a("li"),hZ=a("strong"),Vio=o("qdqbert"),zio=o(" \u2014 "),GS=a("a"),Wio=o("QDQBertModel"),Qio=o(" (QDQBert model)"),Hio=l(),Up=a("li"),pZ=a("strong"),Uio=o("reformer"),Jio=o(" \u2014 "),XS=a("a"),Yio=o("ReformerModel"),Kio=o(" (Reformer model)"),Zio=l(),Jp=a("li"),_Z=a("strong"),edo=o("rembert"),odo=o(" \u2014 "),VS=a("a"),rdo=o("RemBertModel"),tdo=o(" (RemBERT model)"),ado=l(),Yp=a("li"),uZ=a("strong"),ndo=o("retribert"),sdo=o(" \u2014 "),zS=a("a"),ldo=o("RetriBertModel"),ido=o(" (RetriBERT model)"),ddo=l(),Kp=a("li"),bZ=a("strong"),cdo=o("roberta"),fdo=o(" \u2014 "),WS=a("a"),mdo=o("RobertaModel"),gdo=o(" (RoBERTa model)"),hdo=l(),Zp=a("li"),vZ=a("strong"),pdo=o("roformer"),_do=o(" \u2014 "),QS=a("a"),udo=o("RoFormerModel"),bdo=o(" (RoFormer model)"),vdo=l(),e_=a("li"),TZ=a("strong"),Tdo=o("segformer"),Fdo=o(" \u2014 "),HS=a("a"),Cdo=o("SegformerModel"),Mdo=o(" (SegFormer model)"),Edo=l(),o_=a("li"),FZ=a("strong"),ydo=o("sew"),wdo=o(" \u2014 "),US=a("a"),Ado=o("SEWModel"),Ldo=o(" (SEW model)"),Bdo=l(),r_=a("li"),CZ=a("strong"),xdo=o("sew-d"),kdo=o(" \u2014 "),JS=a("a"),Rdo=o("SEWDModel"),Sdo=o(" (SEW-D model)"),Pdo=l(),t_=a("li"),MZ=a("strong"),$do=o("speech_to_text"),Ido=o(" \u2014 "),YS=a("a"),jdo=o("Speech2TextModel"),Ddo=o(" (Speech2Text model)"),Ndo=l(),a_=a("li"),EZ=a("strong"),qdo=o("splinter"),Odo=o(" \u2014 "),KS=a("a"),Gdo=o("SplinterModel"),Xdo=o(" (Splinter model)"),Vdo=l(),n_=a("li"),yZ=a("strong"),zdo=o("squeezebert"),Wdo=o(" \u2014 "),ZS=a("a"),Qdo=o("SqueezeBertModel"),Hdo=o(" (SqueezeBERT model)"),Udo=l(),s_=a("li"),wZ=a("strong"),Jdo=o("swin"),Ydo=o(" \u2014 "),eP=a("a"),Kdo=o("SwinModel"),Zdo=o(" (Swin model)"),eco=l(),l_=a("li"),AZ=a("strong"),oco=o("t5"),rco=o(" \u2014 "),oP=a("a"),tco=o("T5Model"),aco=o(" (T5 model)"),nco=l(),i_=a("li"),LZ=a("strong"),sco=o("tapas"),lco=o(" \u2014 "),rP=a("a"),ico=o("TapasModel"),dco=o(" (TAPAS model)"),cco=l(),d_=a("li"),BZ=a("strong"),fco=o("transfo-xl"),mco=o(" \u2014 "),tP=a("a"),gco=o("TransfoXLModel"),hco=o(" (Transformer-XL model)"),pco=l(),c_=a("li"),xZ=a("strong"),_co=o("unispeech"),uco=o(" \u2014 "),aP=a("a"),bco=o("UniSpeechModel"),vco=o(" (UniSpeech model)"),Tco=l(),f_=a("li"),kZ=a("strong"),Fco=o("unispeech-sat"),Cco=o(" \u2014 "),nP=a("a"),Mco=o("UniSpeechSatModel"),Eco=o(" (UniSpeechSat model)"),yco=l(),m_=a("li"),RZ=a("strong"),wco=o("vilt"),Aco=o(" \u2014 "),sP=a("a"),Lco=o("ViltModel"),Bco=o(" (ViLT model)"),xco=l(),g_=a("li"),SZ=a("strong"),kco=o("vision-text-dual-encoder"),Rco=o(" \u2014 "),lP=a("a"),Sco=o("VisionTextDualEncoderModel"),Pco=o(" (VisionTextDualEncoder model)"),$co=l(),h_=a("li"),PZ=a("strong"),Ico=o("visual_bert"),jco=o(" \u2014 "),iP=a("a"),Dco=o("VisualBertModel"),Nco=o(" (VisualBert model)"),qco=l(),p_=a("li"),$Z=a("strong"),Oco=o("vit"),Gco=o(" \u2014 "),dP=a("a"),Xco=o("ViTModel"),Vco=o(" (ViT model)"),zco=l(),__=a("li"),IZ=a("strong"),Wco=o("vit_mae"),Qco=o(" \u2014 "),cP=a("a"),Hco=o("ViTMAEModel"),Uco=o(" (ViTMAE model)"),Jco=l(),u_=a("li"),jZ=a("strong"),Yco=o("wav2vec2"),Kco=o(" \u2014 "),fP=a("a"),Zco=o("Wav2Vec2Model"),efo=o(" (Wav2Vec2 model)"),ofo=l(),b_=a("li"),DZ=a("strong"),rfo=o("wavlm"),tfo=o(" \u2014 "),mP=a("a"),afo=o("WavLMModel"),nfo=o(" (WavLM model)"),sfo=l(),v_=a("li"),NZ=a("strong"),lfo=o("xglm"),ifo=o(" \u2014 "),gP=a("a"),dfo=o("XGLMModel"),cfo=o(" (XGLM model)"),ffo=l(),T_=a("li"),qZ=a("strong"),mfo=o("xlm"),gfo=o(" \u2014 "),hP=a("a"),hfo=o("XLMModel"),pfo=o(" (XLM model)"),_fo=l(),F_=a("li"),OZ=a("strong"),ufo=o("xlm-prophetnet"),bfo=o(" \u2014 "),pP=a("a"),vfo=o("XLMProphetNetModel"),Tfo=o(" (XLMProphetNet model)"),Ffo=l(),C_=a("li"),GZ=a("strong"),Cfo=o("xlm-roberta"),Mfo=o(" \u2014 "),_P=a("a"),Efo=o("XLMRobertaModel"),yfo=o(" (XLM-RoBERTa model)"),wfo=l(),M_=a("li"),XZ=a("strong"),Afo=o("xlm-roberta-xl"),Lfo=o(" \u2014 "),uP=a("a"),Bfo=o("XLMRobertaXLModel"),xfo=o(" (XLM-RoBERTa-XL model)"),kfo=l(),E_=a("li"),VZ=a("strong"),Rfo=o("xlnet"),Sfo=o(" \u2014 "),bP=a("a"),Pfo=o("XLNetModel"),$fo=o(" (XLNet model)"),Ifo=l(),y_=a("li"),zZ=a("strong"),jfo=o("yoso"),Dfo=o(" \u2014 "),vP=a("a"),Nfo=o("YosoModel"),qfo=o(" (YOSO model)"),Ofo=l(),w_=a("p"),Gfo=o("The model is set in evaluation mode by default using "),WZ=a("code"),Xfo=o("model.eval()"),Vfo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),QZ=a("code"),zfo=o("model.train()"),Wfo=l(),HZ=a("p"),Qfo=o("Examples:"),Hfo=l(),f(W4.$$.fragment),lke=l(),ld=a("h2"),A_=a("a"),UZ=a("span"),f(Q4.$$.fragment),Ufo=l(),JZ=a("span"),Jfo=o("AutoModelForPreTraining"),ike=l(),Ko=a("div"),f(H4.$$.fragment),Yfo=l(),id=a("p"),Kfo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),YZ=a("code"),Zfo=o("from_pretrained()"),emo=o("class method or the "),KZ=a("code"),omo=o("from_config()"),rmo=o(`class
method.`),tmo=l(),U4=a("p"),amo=o("This class cannot be instantiated directly using "),ZZ=a("code"),nmo=o("__init__()"),smo=o(" (throws an error)."),lmo=l(),Qr=a("div"),f(J4.$$.fragment),imo=l(),eee=a("p"),dmo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),cmo=l(),dd=a("p"),fmo=o(`Note:
Loading a model from its configuration file does `),oee=a("strong"),mmo=o("not"),gmo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ree=a("code"),hmo=o("from_pretrained()"),pmo=o("to load the model weights."),_mo=l(),tee=a("p"),umo=o("Examples:"),bmo=l(),f(Y4.$$.fragment),vmo=l(),De=a("div"),f(K4.$$.fragment),Tmo=l(),aee=a("p"),Fmo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Cmo=l(),Ua=a("p"),Mmo=o("The model class to instantiate is selected based on the "),nee=a("code"),Emo=o("model_type"),ymo=o(` property of the config object (either
passed as an argument or loaded from `),see=a("code"),wmo=o("pretrained_model_name_or_path"),Amo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lee=a("code"),Lmo=o("pretrained_model_name_or_path"),Bmo=o(":"),xmo=l(),k=a("ul"),L_=a("li"),iee=a("strong"),kmo=o("albert"),Rmo=o(" \u2014 "),TP=a("a"),Smo=o("AlbertForPreTraining"),Pmo=o(" (ALBERT model)"),$mo=l(),B_=a("li"),dee=a("strong"),Imo=o("bart"),jmo=o(" \u2014 "),FP=a("a"),Dmo=o("BartForConditionalGeneration"),Nmo=o(" (BART model)"),qmo=l(),x_=a("li"),cee=a("strong"),Omo=o("bert"),Gmo=o(" \u2014 "),CP=a("a"),Xmo=o("BertForPreTraining"),Vmo=o(" (BERT model)"),zmo=l(),k_=a("li"),fee=a("strong"),Wmo=o("big_bird"),Qmo=o(" \u2014 "),MP=a("a"),Hmo=o("BigBirdForPreTraining"),Umo=o(" (BigBird model)"),Jmo=l(),R_=a("li"),mee=a("strong"),Ymo=o("camembert"),Kmo=o(" \u2014 "),EP=a("a"),Zmo=o("CamembertForMaskedLM"),ego=o(" (CamemBERT model)"),ogo=l(),S_=a("li"),gee=a("strong"),rgo=o("ctrl"),tgo=o(" \u2014 "),yP=a("a"),ago=o("CTRLLMHeadModel"),ngo=o(" (CTRL model)"),sgo=l(),P_=a("li"),hee=a("strong"),lgo=o("data2vec-text"),igo=o(" \u2014 "),wP=a("a"),dgo=o("Data2VecTextForMaskedLM"),cgo=o(" (Data2VecText model)"),fgo=l(),$_=a("li"),pee=a("strong"),mgo=o("deberta"),ggo=o(" \u2014 "),AP=a("a"),hgo=o("DebertaForMaskedLM"),pgo=o(" (DeBERTa model)"),_go=l(),I_=a("li"),_ee=a("strong"),ugo=o("deberta-v2"),bgo=o(" \u2014 "),LP=a("a"),vgo=o("DebertaV2ForMaskedLM"),Tgo=o(" (DeBERTa-v2 model)"),Fgo=l(),j_=a("li"),uee=a("strong"),Cgo=o("distilbert"),Mgo=o(" \u2014 "),BP=a("a"),Ego=o("DistilBertForMaskedLM"),ygo=o(" (DistilBERT model)"),wgo=l(),D_=a("li"),bee=a("strong"),Ago=o("electra"),Lgo=o(" \u2014 "),xP=a("a"),Bgo=o("ElectraForPreTraining"),xgo=o(" (ELECTRA model)"),kgo=l(),N_=a("li"),vee=a("strong"),Rgo=o("flaubert"),Sgo=o(" \u2014 "),kP=a("a"),Pgo=o("FlaubertWithLMHeadModel"),$go=o(" (FlauBERT model)"),Igo=l(),q_=a("li"),Tee=a("strong"),jgo=o("fnet"),Dgo=o(" \u2014 "),RP=a("a"),Ngo=o("FNetForPreTraining"),qgo=o(" (FNet model)"),Ogo=l(),O_=a("li"),Fee=a("strong"),Ggo=o("fsmt"),Xgo=o(" \u2014 "),SP=a("a"),Vgo=o("FSMTForConditionalGeneration"),zgo=o(" (FairSeq Machine-Translation model)"),Wgo=l(),G_=a("li"),Cee=a("strong"),Qgo=o("funnel"),Hgo=o(" \u2014 "),PP=a("a"),Ugo=o("FunnelForPreTraining"),Jgo=o(" (Funnel Transformer model)"),Ygo=l(),X_=a("li"),Mee=a("strong"),Kgo=o("gpt2"),Zgo=o(" \u2014 "),$P=a("a"),eho=o("GPT2LMHeadModel"),oho=o(" (OpenAI GPT-2 model)"),rho=l(),V_=a("li"),Eee=a("strong"),tho=o("ibert"),aho=o(" \u2014 "),IP=a("a"),nho=o("IBertForMaskedLM"),sho=o(" (I-BERT model)"),lho=l(),z_=a("li"),yee=a("strong"),iho=o("layoutlm"),dho=o(" \u2014 "),jP=a("a"),cho=o("LayoutLMForMaskedLM"),fho=o(" (LayoutLM model)"),mho=l(),W_=a("li"),wee=a("strong"),gho=o("longformer"),hho=o(" \u2014 "),DP=a("a"),pho=o("LongformerForMaskedLM"),_ho=o(" (Longformer model)"),uho=l(),Q_=a("li"),Aee=a("strong"),bho=o("lxmert"),vho=o(" \u2014 "),NP=a("a"),Tho=o("LxmertForPreTraining"),Fho=o(" (LXMERT model)"),Cho=l(),H_=a("li"),Lee=a("strong"),Mho=o("megatron-bert"),Eho=o(" \u2014 "),qP=a("a"),yho=o("MegatronBertForPreTraining"),who=o(" (MegatronBert model)"),Aho=l(),U_=a("li"),Bee=a("strong"),Lho=o("mobilebert"),Bho=o(" \u2014 "),OP=a("a"),xho=o("MobileBertForPreTraining"),kho=o(" (MobileBERT model)"),Rho=l(),J_=a("li"),xee=a("strong"),Sho=o("mpnet"),Pho=o(" \u2014 "),GP=a("a"),$ho=o("MPNetForMaskedLM"),Iho=o(" (MPNet model)"),jho=l(),Y_=a("li"),kee=a("strong"),Dho=o("openai-gpt"),Nho=o(" \u2014 "),XP=a("a"),qho=o("OpenAIGPTLMHeadModel"),Oho=o(" (OpenAI GPT model)"),Gho=l(),K_=a("li"),Ree=a("strong"),Xho=o("retribert"),Vho=o(" \u2014 "),VP=a("a"),zho=o("RetriBertModel"),Who=o(" (RetriBERT model)"),Qho=l(),Z_=a("li"),See=a("strong"),Hho=o("roberta"),Uho=o(" \u2014 "),zP=a("a"),Jho=o("RobertaForMaskedLM"),Yho=o(" (RoBERTa model)"),Kho=l(),eu=a("li"),Pee=a("strong"),Zho=o("squeezebert"),epo=o(" \u2014 "),WP=a("a"),opo=o("SqueezeBertForMaskedLM"),rpo=o(" (SqueezeBERT model)"),tpo=l(),ou=a("li"),$ee=a("strong"),apo=o("t5"),npo=o(" \u2014 "),QP=a("a"),spo=o("T5ForConditionalGeneration"),lpo=o(" (T5 model)"),ipo=l(),ru=a("li"),Iee=a("strong"),dpo=o("tapas"),cpo=o(" \u2014 "),HP=a("a"),fpo=o("TapasForMaskedLM"),mpo=o(" (TAPAS model)"),gpo=l(),tu=a("li"),jee=a("strong"),hpo=o("transfo-xl"),ppo=o(" \u2014 "),UP=a("a"),_po=o("TransfoXLLMHeadModel"),upo=o(" (Transformer-XL model)"),bpo=l(),au=a("li"),Dee=a("strong"),vpo=o("unispeech"),Tpo=o(" \u2014 "),JP=a("a"),Fpo=o("UniSpeechForPreTraining"),Cpo=o(" (UniSpeech model)"),Mpo=l(),nu=a("li"),Nee=a("strong"),Epo=o("unispeech-sat"),ypo=o(" \u2014 "),YP=a("a"),wpo=o("UniSpeechSatForPreTraining"),Apo=o(" (UniSpeechSat model)"),Lpo=l(),su=a("li"),qee=a("strong"),Bpo=o("visual_bert"),xpo=o(" \u2014 "),KP=a("a"),kpo=o("VisualBertForPreTraining"),Rpo=o(" (VisualBert model)"),Spo=l(),lu=a("li"),Oee=a("strong"),Ppo=o("vit_mae"),$po=o(" \u2014 "),ZP=a("a"),Ipo=o("ViTMAEForPreTraining"),jpo=o(" (ViTMAE model)"),Dpo=l(),iu=a("li"),Gee=a("strong"),Npo=o("wav2vec2"),qpo=o(" \u2014 "),e$=a("a"),Opo=o("Wav2Vec2ForPreTraining"),Gpo=o(" (Wav2Vec2 model)"),Xpo=l(),du=a("li"),Xee=a("strong"),Vpo=o("xlm"),zpo=o(" \u2014 "),o$=a("a"),Wpo=o("XLMWithLMHeadModel"),Qpo=o(" (XLM model)"),Hpo=l(),cu=a("li"),Vee=a("strong"),Upo=o("xlm-roberta"),Jpo=o(" \u2014 "),r$=a("a"),Ypo=o("XLMRobertaForMaskedLM"),Kpo=o(" (XLM-RoBERTa model)"),Zpo=l(),fu=a("li"),zee=a("strong"),e_o=o("xlm-roberta-xl"),o_o=o(" \u2014 "),t$=a("a"),r_o=o("XLMRobertaXLForMaskedLM"),t_o=o(" (XLM-RoBERTa-XL model)"),a_o=l(),mu=a("li"),Wee=a("strong"),n_o=o("xlnet"),s_o=o(" \u2014 "),a$=a("a"),l_o=o("XLNetLMHeadModel"),i_o=o(" (XLNet model)"),d_o=l(),gu=a("p"),c_o=o("The model is set in evaluation mode by default using "),Qee=a("code"),f_o=o("model.eval()"),m_o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hee=a("code"),g_o=o("model.train()"),h_o=l(),Uee=a("p"),p_o=o("Examples:"),__o=l(),f(Z4.$$.fragment),dke=l(),cd=a("h2"),hu=a("a"),Jee=a("span"),f(eE.$$.fragment),u_o=l(),Yee=a("span"),b_o=o("AutoModelForCausalLM"),cke=l(),Zo=a("div"),f(oE.$$.fragment),v_o=l(),fd=a("p"),T_o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Kee=a("code"),F_o=o("from_pretrained()"),C_o=o("class method or the "),Zee=a("code"),M_o=o("from_config()"),E_o=o(`class
method.`),y_o=l(),rE=a("p"),w_o=o("This class cannot be instantiated directly using "),eoe=a("code"),A_o=o("__init__()"),L_o=o(" (throws an error)."),B_o=l(),Hr=a("div"),f(tE.$$.fragment),x_o=l(),ooe=a("p"),k_o=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),R_o=l(),md=a("p"),S_o=o(`Note:
Loading a model from its configuration file does `),roe=a("strong"),P_o=o("not"),$_o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),toe=a("code"),I_o=o("from_pretrained()"),j_o=o("to load the model weights."),D_o=l(),aoe=a("p"),N_o=o("Examples:"),q_o=l(),f(aE.$$.fragment),O_o=l(),Ne=a("div"),f(nE.$$.fragment),G_o=l(),noe=a("p"),X_o=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),V_o=l(),Ja=a("p"),z_o=o("The model class to instantiate is selected based on the "),soe=a("code"),W_o=o("model_type"),Q_o=o(` property of the config object (either
passed as an argument or loaded from `),loe=a("code"),H_o=o("pretrained_model_name_or_path"),U_o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ioe=a("code"),J_o=o("pretrained_model_name_or_path"),Y_o=o(":"),K_o=l(),$=a("ul"),pu=a("li"),doe=a("strong"),Z_o=o("bart"),euo=o(" \u2014 "),n$=a("a"),ouo=o("BartForCausalLM"),ruo=o(" (BART model)"),tuo=l(),_u=a("li"),coe=a("strong"),auo=o("bert"),nuo=o(" \u2014 "),s$=a("a"),suo=o("BertLMHeadModel"),luo=o(" (BERT model)"),iuo=l(),uu=a("li"),foe=a("strong"),duo=o("bert-generation"),cuo=o(" \u2014 "),l$=a("a"),fuo=o("BertGenerationDecoder"),muo=o(" (Bert Generation model)"),guo=l(),bu=a("li"),moe=a("strong"),huo=o("big_bird"),puo=o(" \u2014 "),i$=a("a"),_uo=o("BigBirdForCausalLM"),uuo=o(" (BigBird model)"),buo=l(),vu=a("li"),goe=a("strong"),vuo=o("bigbird_pegasus"),Tuo=o(" \u2014 "),d$=a("a"),Fuo=o("BigBirdPegasusForCausalLM"),Cuo=o(" (BigBirdPegasus model)"),Muo=l(),Tu=a("li"),hoe=a("strong"),Euo=o("blenderbot"),yuo=o(" \u2014 "),c$=a("a"),wuo=o("BlenderbotForCausalLM"),Auo=o(" (Blenderbot model)"),Luo=l(),Fu=a("li"),poe=a("strong"),Buo=o("blenderbot-small"),xuo=o(" \u2014 "),f$=a("a"),kuo=o("BlenderbotSmallForCausalLM"),Ruo=o(" (BlenderbotSmall model)"),Suo=l(),Cu=a("li"),_oe=a("strong"),Puo=o("camembert"),$uo=o(" \u2014 "),m$=a("a"),Iuo=o("CamembertForCausalLM"),juo=o(" (CamemBERT model)"),Duo=l(),Mu=a("li"),uoe=a("strong"),Nuo=o("ctrl"),quo=o(" \u2014 "),g$=a("a"),Ouo=o("CTRLLMHeadModel"),Guo=o(" (CTRL model)"),Xuo=l(),Eu=a("li"),boe=a("strong"),Vuo=o("data2vec-text"),zuo=o(" \u2014 "),h$=a("a"),Wuo=o("Data2VecTextForCausalLM"),Quo=o(" (Data2VecText model)"),Huo=l(),yu=a("li"),voe=a("strong"),Uuo=o("electra"),Juo=o(" \u2014 "),p$=a("a"),Yuo=o("ElectraForCausalLM"),Kuo=o(" (ELECTRA model)"),Zuo=l(),wu=a("li"),Toe=a("strong"),e1o=o("gpt2"),o1o=o(" \u2014 "),_$=a("a"),r1o=o("GPT2LMHeadModel"),t1o=o(" (OpenAI GPT-2 model)"),a1o=l(),Au=a("li"),Foe=a("strong"),n1o=o("gpt_neo"),s1o=o(" \u2014 "),u$=a("a"),l1o=o("GPTNeoForCausalLM"),i1o=o(" (GPT Neo model)"),d1o=l(),Lu=a("li"),Coe=a("strong"),c1o=o("gptj"),f1o=o(" \u2014 "),b$=a("a"),m1o=o("GPTJForCausalLM"),g1o=o(" (GPT-J model)"),h1o=l(),Bu=a("li"),Moe=a("strong"),p1o=o("marian"),_1o=o(" \u2014 "),v$=a("a"),u1o=o("MarianForCausalLM"),b1o=o(" (Marian model)"),v1o=l(),xu=a("li"),Eoe=a("strong"),T1o=o("mbart"),F1o=o(" \u2014 "),T$=a("a"),C1o=o("MBartForCausalLM"),M1o=o(" (mBART model)"),E1o=l(),ku=a("li"),yoe=a("strong"),y1o=o("megatron-bert"),w1o=o(" \u2014 "),F$=a("a"),A1o=o("MegatronBertForCausalLM"),L1o=o(" (MegatronBert model)"),B1o=l(),Ru=a("li"),woe=a("strong"),x1o=o("openai-gpt"),k1o=o(" \u2014 "),C$=a("a"),R1o=o("OpenAIGPTLMHeadModel"),S1o=o(" (OpenAI GPT model)"),P1o=l(),Su=a("li"),Aoe=a("strong"),$1o=o("pegasus"),I1o=o(" \u2014 "),M$=a("a"),j1o=o("PegasusForCausalLM"),D1o=o(" (Pegasus model)"),N1o=l(),Pu=a("li"),Loe=a("strong"),q1o=o("plbart"),O1o=o(" \u2014 "),E$=a("a"),G1o=o("PLBartForCausalLM"),X1o=o(" (PLBart model)"),V1o=l(),$u=a("li"),Boe=a("strong"),z1o=o("prophetnet"),W1o=o(" \u2014 "),y$=a("a"),Q1o=o("ProphetNetForCausalLM"),H1o=o(" (ProphetNet model)"),U1o=l(),Iu=a("li"),xoe=a("strong"),J1o=o("qdqbert"),Y1o=o(" \u2014 "),w$=a("a"),K1o=o("QDQBertLMHeadModel"),Z1o=o(" (QDQBert model)"),ebo=l(),ju=a("li"),koe=a("strong"),obo=o("reformer"),rbo=o(" \u2014 "),A$=a("a"),tbo=o("ReformerModelWithLMHead"),abo=o(" (Reformer model)"),nbo=l(),Du=a("li"),Roe=a("strong"),sbo=o("rembert"),lbo=o(" \u2014 "),L$=a("a"),ibo=o("RemBertForCausalLM"),dbo=o(" (RemBERT model)"),cbo=l(),Nu=a("li"),Soe=a("strong"),fbo=o("roberta"),mbo=o(" \u2014 "),B$=a("a"),gbo=o("RobertaForCausalLM"),hbo=o(" (RoBERTa model)"),pbo=l(),qu=a("li"),Poe=a("strong"),_bo=o("roformer"),ubo=o(" \u2014 "),x$=a("a"),bbo=o("RoFormerForCausalLM"),vbo=o(" (RoFormer model)"),Tbo=l(),Ou=a("li"),$oe=a("strong"),Fbo=o("speech_to_text_2"),Cbo=o(" \u2014 "),k$=a("a"),Mbo=o("Speech2Text2ForCausalLM"),Ebo=o(" (Speech2Text2 model)"),ybo=l(),Gu=a("li"),Ioe=a("strong"),wbo=o("transfo-xl"),Abo=o(" \u2014 "),R$=a("a"),Lbo=o("TransfoXLLMHeadModel"),Bbo=o(" (Transformer-XL model)"),xbo=l(),Xu=a("li"),joe=a("strong"),kbo=o("trocr"),Rbo=o(" \u2014 "),S$=a("a"),Sbo=o("TrOCRForCausalLM"),Pbo=o(" (TrOCR model)"),$bo=l(),Vu=a("li"),Doe=a("strong"),Ibo=o("xglm"),jbo=o(" \u2014 "),P$=a("a"),Dbo=o("XGLMForCausalLM"),Nbo=o(" (XGLM model)"),qbo=l(),zu=a("li"),Noe=a("strong"),Obo=o("xlm"),Gbo=o(" \u2014 "),$$=a("a"),Xbo=o("XLMWithLMHeadModel"),Vbo=o(" (XLM model)"),zbo=l(),Wu=a("li"),qoe=a("strong"),Wbo=o("xlm-prophetnet"),Qbo=o(" \u2014 "),I$=a("a"),Hbo=o("XLMProphetNetForCausalLM"),Ubo=o(" (XLMProphetNet model)"),Jbo=l(),Qu=a("li"),Ooe=a("strong"),Ybo=o("xlm-roberta"),Kbo=o(" \u2014 "),j$=a("a"),Zbo=o("XLMRobertaForCausalLM"),e5o=o(" (XLM-RoBERTa model)"),o5o=l(),Hu=a("li"),Goe=a("strong"),r5o=o("xlm-roberta-xl"),t5o=o(" \u2014 "),D$=a("a"),a5o=o("XLMRobertaXLForCausalLM"),n5o=o(" (XLM-RoBERTa-XL model)"),s5o=l(),Uu=a("li"),Xoe=a("strong"),l5o=o("xlnet"),i5o=o(" \u2014 "),N$=a("a"),d5o=o("XLNetLMHeadModel"),c5o=o(" (XLNet model)"),f5o=l(),Ju=a("p"),m5o=o("The model is set in evaluation mode by default using "),Voe=a("code"),g5o=o("model.eval()"),h5o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zoe=a("code"),p5o=o("model.train()"),_5o=l(),Woe=a("p"),u5o=o("Examples:"),b5o=l(),f(sE.$$.fragment),fke=l(),gd=a("h2"),Yu=a("a"),Qoe=a("span"),f(lE.$$.fragment),v5o=l(),Hoe=a("span"),T5o=o("AutoModelForMaskedLM"),mke=l(),er=a("div"),f(iE.$$.fragment),F5o=l(),hd=a("p"),C5o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Uoe=a("code"),M5o=o("from_pretrained()"),E5o=o("class method or the "),Joe=a("code"),y5o=o("from_config()"),w5o=o(`class
method.`),A5o=l(),dE=a("p"),L5o=o("This class cannot be instantiated directly using "),Yoe=a("code"),B5o=o("__init__()"),x5o=o(" (throws an error)."),k5o=l(),Ur=a("div"),f(cE.$$.fragment),R5o=l(),Koe=a("p"),S5o=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),P5o=l(),pd=a("p"),$5o=o(`Note:
Loading a model from its configuration file does `),Zoe=a("strong"),I5o=o("not"),j5o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ere=a("code"),D5o=o("from_pretrained()"),N5o=o("to load the model weights."),q5o=l(),ore=a("p"),O5o=o("Examples:"),G5o=l(),f(fE.$$.fragment),X5o=l(),qe=a("div"),f(mE.$$.fragment),V5o=l(),rre=a("p"),z5o=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),W5o=l(),Ya=a("p"),Q5o=o("The model class to instantiate is selected based on the "),tre=a("code"),H5o=o("model_type"),U5o=o(` property of the config object (either
passed as an argument or loaded from `),are=a("code"),J5o=o("pretrained_model_name_or_path"),Y5o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nre=a("code"),K5o=o("pretrained_model_name_or_path"),Z5o=o(":"),e2o=l(),I=a("ul"),Ku=a("li"),sre=a("strong"),o2o=o("albert"),r2o=o(" \u2014 "),q$=a("a"),t2o=o("AlbertForMaskedLM"),a2o=o(" (ALBERT model)"),n2o=l(),Zu=a("li"),lre=a("strong"),s2o=o("bart"),l2o=o(" \u2014 "),O$=a("a"),i2o=o("BartForConditionalGeneration"),d2o=o(" (BART model)"),c2o=l(),e1=a("li"),ire=a("strong"),f2o=o("bert"),m2o=o(" \u2014 "),G$=a("a"),g2o=o("BertForMaskedLM"),h2o=o(" (BERT model)"),p2o=l(),o1=a("li"),dre=a("strong"),_2o=o("big_bird"),u2o=o(" \u2014 "),X$=a("a"),b2o=o("BigBirdForMaskedLM"),v2o=o(" (BigBird model)"),T2o=l(),r1=a("li"),cre=a("strong"),F2o=o("camembert"),C2o=o(" \u2014 "),V$=a("a"),M2o=o("CamembertForMaskedLM"),E2o=o(" (CamemBERT model)"),y2o=l(),t1=a("li"),fre=a("strong"),w2o=o("convbert"),A2o=o(" \u2014 "),z$=a("a"),L2o=o("ConvBertForMaskedLM"),B2o=o(" (ConvBERT model)"),x2o=l(),a1=a("li"),mre=a("strong"),k2o=o("data2vec-text"),R2o=o(" \u2014 "),W$=a("a"),S2o=o("Data2VecTextForMaskedLM"),P2o=o(" (Data2VecText model)"),$2o=l(),n1=a("li"),gre=a("strong"),I2o=o("deberta"),j2o=o(" \u2014 "),Q$=a("a"),D2o=o("DebertaForMaskedLM"),N2o=o(" (DeBERTa model)"),q2o=l(),s1=a("li"),hre=a("strong"),O2o=o("deberta-v2"),G2o=o(" \u2014 "),H$=a("a"),X2o=o("DebertaV2ForMaskedLM"),V2o=o(" (DeBERTa-v2 model)"),z2o=l(),l1=a("li"),pre=a("strong"),W2o=o("distilbert"),Q2o=o(" \u2014 "),U$=a("a"),H2o=o("DistilBertForMaskedLM"),U2o=o(" (DistilBERT model)"),J2o=l(),i1=a("li"),_re=a("strong"),Y2o=o("electra"),K2o=o(" \u2014 "),J$=a("a"),Z2o=o("ElectraForMaskedLM"),evo=o(" (ELECTRA model)"),ovo=l(),d1=a("li"),ure=a("strong"),rvo=o("flaubert"),tvo=o(" \u2014 "),Y$=a("a"),avo=o("FlaubertWithLMHeadModel"),nvo=o(" (FlauBERT model)"),svo=l(),c1=a("li"),bre=a("strong"),lvo=o("fnet"),ivo=o(" \u2014 "),K$=a("a"),dvo=o("FNetForMaskedLM"),cvo=o(" (FNet model)"),fvo=l(),f1=a("li"),vre=a("strong"),mvo=o("funnel"),gvo=o(" \u2014 "),Z$=a("a"),hvo=o("FunnelForMaskedLM"),pvo=o(" (Funnel Transformer model)"),_vo=l(),m1=a("li"),Tre=a("strong"),uvo=o("ibert"),bvo=o(" \u2014 "),eI=a("a"),vvo=o("IBertForMaskedLM"),Tvo=o(" (I-BERT model)"),Fvo=l(),g1=a("li"),Fre=a("strong"),Cvo=o("layoutlm"),Mvo=o(" \u2014 "),oI=a("a"),Evo=o("LayoutLMForMaskedLM"),yvo=o(" (LayoutLM model)"),wvo=l(),h1=a("li"),Cre=a("strong"),Avo=o("longformer"),Lvo=o(" \u2014 "),rI=a("a"),Bvo=o("LongformerForMaskedLM"),xvo=o(" (Longformer model)"),kvo=l(),p1=a("li"),Mre=a("strong"),Rvo=o("mbart"),Svo=o(" \u2014 "),tI=a("a"),Pvo=o("MBartForConditionalGeneration"),$vo=o(" (mBART model)"),Ivo=l(),_1=a("li"),Ere=a("strong"),jvo=o("megatron-bert"),Dvo=o(" \u2014 "),aI=a("a"),Nvo=o("MegatronBertForMaskedLM"),qvo=o(" (MegatronBert model)"),Ovo=l(),u1=a("li"),yre=a("strong"),Gvo=o("mobilebert"),Xvo=o(" \u2014 "),nI=a("a"),Vvo=o("MobileBertForMaskedLM"),zvo=o(" (MobileBERT model)"),Wvo=l(),b1=a("li"),wre=a("strong"),Qvo=o("mpnet"),Hvo=o(" \u2014 "),sI=a("a"),Uvo=o("MPNetForMaskedLM"),Jvo=o(" (MPNet model)"),Yvo=l(),v1=a("li"),Are=a("strong"),Kvo=o("nystromformer"),Zvo=o(" \u2014 "),lI=a("a"),e6o=o("NystromformerForMaskedLM"),o6o=o(" (Nystromformer model)"),r6o=l(),T1=a("li"),Lre=a("strong"),t6o=o("perceiver"),a6o=o(" \u2014 "),iI=a("a"),n6o=o("PerceiverForMaskedLM"),s6o=o(" (Perceiver model)"),l6o=l(),F1=a("li"),Bre=a("strong"),i6o=o("qdqbert"),d6o=o(" \u2014 "),dI=a("a"),c6o=o("QDQBertForMaskedLM"),f6o=o(" (QDQBert model)"),m6o=l(),C1=a("li"),xre=a("strong"),g6o=o("reformer"),h6o=o(" \u2014 "),cI=a("a"),p6o=o("ReformerForMaskedLM"),_6o=o(" (Reformer model)"),u6o=l(),M1=a("li"),kre=a("strong"),b6o=o("rembert"),v6o=o(" \u2014 "),fI=a("a"),T6o=o("RemBertForMaskedLM"),F6o=o(" (RemBERT model)"),C6o=l(),E1=a("li"),Rre=a("strong"),M6o=o("roberta"),E6o=o(" \u2014 "),mI=a("a"),y6o=o("RobertaForMaskedLM"),w6o=o(" (RoBERTa model)"),A6o=l(),y1=a("li"),Sre=a("strong"),L6o=o("roformer"),B6o=o(" \u2014 "),gI=a("a"),x6o=o("RoFormerForMaskedLM"),k6o=o(" (RoFormer model)"),R6o=l(),w1=a("li"),Pre=a("strong"),S6o=o("squeezebert"),P6o=o(" \u2014 "),hI=a("a"),$6o=o("SqueezeBertForMaskedLM"),I6o=o(" (SqueezeBERT model)"),j6o=l(),A1=a("li"),$re=a("strong"),D6o=o("tapas"),N6o=o(" \u2014 "),pI=a("a"),q6o=o("TapasForMaskedLM"),O6o=o(" (TAPAS model)"),G6o=l(),L1=a("li"),Ire=a("strong"),X6o=o("wav2vec2"),V6o=o(" \u2014 "),jre=a("code"),z6o=o("Wav2Vec2ForMaskedLM"),W6o=o("(Wav2Vec2 model)"),Q6o=l(),B1=a("li"),Dre=a("strong"),H6o=o("xlm"),U6o=o(" \u2014 "),_I=a("a"),J6o=o("XLMWithLMHeadModel"),Y6o=o(" (XLM model)"),K6o=l(),x1=a("li"),Nre=a("strong"),Z6o=o("xlm-roberta"),e0o=o(" \u2014 "),uI=a("a"),o0o=o("XLMRobertaForMaskedLM"),r0o=o(" (XLM-RoBERTa model)"),t0o=l(),k1=a("li"),qre=a("strong"),a0o=o("xlm-roberta-xl"),n0o=o(" \u2014 "),bI=a("a"),s0o=o("XLMRobertaXLForMaskedLM"),l0o=o(" (XLM-RoBERTa-XL model)"),i0o=l(),R1=a("li"),Ore=a("strong"),d0o=o("yoso"),c0o=o(" \u2014 "),vI=a("a"),f0o=o("YosoForMaskedLM"),m0o=o(" (YOSO model)"),g0o=l(),S1=a("p"),h0o=o("The model is set in evaluation mode by default using "),Gre=a("code"),p0o=o("model.eval()"),_0o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xre=a("code"),u0o=o("model.train()"),b0o=l(),Vre=a("p"),v0o=o("Examples:"),T0o=l(),f(gE.$$.fragment),gke=l(),_d=a("h2"),P1=a("a"),zre=a("span"),f(hE.$$.fragment),F0o=l(),Wre=a("span"),C0o=o("AutoModelForSeq2SeqLM"),hke=l(),or=a("div"),f(pE.$$.fragment),M0o=l(),ud=a("p"),E0o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Qre=a("code"),y0o=o("from_pretrained()"),w0o=o("class method or the "),Hre=a("code"),A0o=o("from_config()"),L0o=o(`class
method.`),B0o=l(),_E=a("p"),x0o=o("This class cannot be instantiated directly using "),Ure=a("code"),k0o=o("__init__()"),R0o=o(" (throws an error)."),S0o=l(),Jr=a("div"),f(uE.$$.fragment),P0o=l(),Jre=a("p"),$0o=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),I0o=l(),bd=a("p"),j0o=o(`Note:
Loading a model from its configuration file does `),Yre=a("strong"),D0o=o("not"),N0o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kre=a("code"),q0o=o("from_pretrained()"),O0o=o("to load the model weights."),G0o=l(),Zre=a("p"),X0o=o("Examples:"),V0o=l(),f(bE.$$.fragment),z0o=l(),Oe=a("div"),f(vE.$$.fragment),W0o=l(),ete=a("p"),Q0o=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),H0o=l(),Ka=a("p"),U0o=o("The model class to instantiate is selected based on the "),ote=a("code"),J0o=o("model_type"),Y0o=o(` property of the config object (either
passed as an argument or loaded from `),rte=a("code"),K0o=o("pretrained_model_name_or_path"),Z0o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tte=a("code"),eTo=o("pretrained_model_name_or_path"),oTo=o(":"),rTo=l(),ne=a("ul"),$1=a("li"),ate=a("strong"),tTo=o("bart"),aTo=o(" \u2014 "),TI=a("a"),nTo=o("BartForConditionalGeneration"),sTo=o(" (BART model)"),lTo=l(),I1=a("li"),nte=a("strong"),iTo=o("bigbird_pegasus"),dTo=o(" \u2014 "),FI=a("a"),cTo=o("BigBirdPegasusForConditionalGeneration"),fTo=o(" (BigBirdPegasus model)"),mTo=l(),j1=a("li"),ste=a("strong"),gTo=o("blenderbot"),hTo=o(" \u2014 "),CI=a("a"),pTo=o("BlenderbotForConditionalGeneration"),_To=o(" (Blenderbot model)"),uTo=l(),D1=a("li"),lte=a("strong"),bTo=o("blenderbot-small"),vTo=o(" \u2014 "),MI=a("a"),TTo=o("BlenderbotSmallForConditionalGeneration"),FTo=o(" (BlenderbotSmall model)"),CTo=l(),N1=a("li"),ite=a("strong"),MTo=o("encoder-decoder"),ETo=o(" \u2014 "),EI=a("a"),yTo=o("EncoderDecoderModel"),wTo=o(" (Encoder decoder model)"),ATo=l(),q1=a("li"),dte=a("strong"),LTo=o("fsmt"),BTo=o(" \u2014 "),yI=a("a"),xTo=o("FSMTForConditionalGeneration"),kTo=o(" (FairSeq Machine-Translation model)"),RTo=l(),O1=a("li"),cte=a("strong"),STo=o("led"),PTo=o(" \u2014 "),wI=a("a"),$To=o("LEDForConditionalGeneration"),ITo=o(" (LED model)"),jTo=l(),G1=a("li"),fte=a("strong"),DTo=o("m2m_100"),NTo=o(" \u2014 "),AI=a("a"),qTo=o("M2M100ForConditionalGeneration"),OTo=o(" (M2M100 model)"),GTo=l(),X1=a("li"),mte=a("strong"),XTo=o("marian"),VTo=o(" \u2014 "),LI=a("a"),zTo=o("MarianMTModel"),WTo=o(" (Marian model)"),QTo=l(),V1=a("li"),gte=a("strong"),HTo=o("mbart"),UTo=o(" \u2014 "),BI=a("a"),JTo=o("MBartForConditionalGeneration"),YTo=o(" (mBART model)"),KTo=l(),z1=a("li"),hte=a("strong"),ZTo=o("mt5"),e8o=o(" \u2014 "),xI=a("a"),o8o=o("MT5ForConditionalGeneration"),r8o=o(" (mT5 model)"),t8o=l(),W1=a("li"),pte=a("strong"),a8o=o("pegasus"),n8o=o(" \u2014 "),kI=a("a"),s8o=o("PegasusForConditionalGeneration"),l8o=o(" (Pegasus model)"),i8o=l(),Q1=a("li"),_te=a("strong"),d8o=o("plbart"),c8o=o(" \u2014 "),RI=a("a"),f8o=o("PLBartForConditionalGeneration"),m8o=o(" (PLBart model)"),g8o=l(),H1=a("li"),ute=a("strong"),h8o=o("prophetnet"),p8o=o(" \u2014 "),SI=a("a"),_8o=o("ProphetNetForConditionalGeneration"),u8o=o(" (ProphetNet model)"),b8o=l(),U1=a("li"),bte=a("strong"),v8o=o("t5"),T8o=o(" \u2014 "),PI=a("a"),F8o=o("T5ForConditionalGeneration"),C8o=o(" (T5 model)"),M8o=l(),J1=a("li"),vte=a("strong"),E8o=o("xlm-prophetnet"),y8o=o(" \u2014 "),$I=a("a"),w8o=o("XLMProphetNetForConditionalGeneration"),A8o=o(" (XLMProphetNet model)"),L8o=l(),Y1=a("p"),B8o=o("The model is set in evaluation mode by default using "),Tte=a("code"),x8o=o("model.eval()"),k8o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fte=a("code"),R8o=o("model.train()"),S8o=l(),Cte=a("p"),P8o=o("Examples:"),$8o=l(),f(TE.$$.fragment),pke=l(),vd=a("h2"),K1=a("a"),Mte=a("span"),f(FE.$$.fragment),I8o=l(),Ete=a("span"),j8o=o("AutoModelForSequenceClassification"),_ke=l(),rr=a("div"),f(CE.$$.fragment),D8o=l(),Td=a("p"),N8o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),yte=a("code"),q8o=o("from_pretrained()"),O8o=o("class method or the "),wte=a("code"),G8o=o("from_config()"),X8o=o(`class
method.`),V8o=l(),ME=a("p"),z8o=o("This class cannot be instantiated directly using "),Ate=a("code"),W8o=o("__init__()"),Q8o=o(" (throws an error)."),H8o=l(),Yr=a("div"),f(EE.$$.fragment),U8o=l(),Lte=a("p"),J8o=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Y8o=l(),Fd=a("p"),K8o=o(`Note:
Loading a model from its configuration file does `),Bte=a("strong"),Z8o=o("not"),eFo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xte=a("code"),oFo=o("from_pretrained()"),rFo=o("to load the model weights."),tFo=l(),kte=a("p"),aFo=o("Examples:"),nFo=l(),f(yE.$$.fragment),sFo=l(),Ge=a("div"),f(wE.$$.fragment),lFo=l(),Rte=a("p"),iFo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),dFo=l(),Za=a("p"),cFo=o("The model class to instantiate is selected based on the "),Ste=a("code"),fFo=o("model_type"),mFo=o(` property of the config object (either
passed as an argument or loaded from `),Pte=a("code"),gFo=o("pretrained_model_name_or_path"),hFo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$te=a("code"),pFo=o("pretrained_model_name_or_path"),_Fo=o(":"),uFo=l(),A=a("ul"),Z1=a("li"),Ite=a("strong"),bFo=o("albert"),vFo=o(" \u2014 "),II=a("a"),TFo=o("AlbertForSequenceClassification"),FFo=o(" (ALBERT model)"),CFo=l(),eb=a("li"),jte=a("strong"),MFo=o("bart"),EFo=o(" \u2014 "),jI=a("a"),yFo=o("BartForSequenceClassification"),wFo=o(" (BART model)"),AFo=l(),ob=a("li"),Dte=a("strong"),LFo=o("bert"),BFo=o(" \u2014 "),DI=a("a"),xFo=o("BertForSequenceClassification"),kFo=o(" (BERT model)"),RFo=l(),rb=a("li"),Nte=a("strong"),SFo=o("big_bird"),PFo=o(" \u2014 "),NI=a("a"),$Fo=o("BigBirdForSequenceClassification"),IFo=o(" (BigBird model)"),jFo=l(),tb=a("li"),qte=a("strong"),DFo=o("bigbird_pegasus"),NFo=o(" \u2014 "),qI=a("a"),qFo=o("BigBirdPegasusForSequenceClassification"),OFo=o(" (BigBirdPegasus model)"),GFo=l(),ab=a("li"),Ote=a("strong"),XFo=o("camembert"),VFo=o(" \u2014 "),OI=a("a"),zFo=o("CamembertForSequenceClassification"),WFo=o(" (CamemBERT model)"),QFo=l(),nb=a("li"),Gte=a("strong"),HFo=o("canine"),UFo=o(" \u2014 "),GI=a("a"),JFo=o("CanineForSequenceClassification"),YFo=o(" (Canine model)"),KFo=l(),sb=a("li"),Xte=a("strong"),ZFo=o("convbert"),eCo=o(" \u2014 "),XI=a("a"),oCo=o("ConvBertForSequenceClassification"),rCo=o(" (ConvBERT model)"),tCo=l(),lb=a("li"),Vte=a("strong"),aCo=o("ctrl"),nCo=o(" \u2014 "),VI=a("a"),sCo=o("CTRLForSequenceClassification"),lCo=o(" (CTRL model)"),iCo=l(),ib=a("li"),zte=a("strong"),dCo=o("data2vec-text"),cCo=o(" \u2014 "),zI=a("a"),fCo=o("Data2VecTextForSequenceClassification"),mCo=o(" (Data2VecText model)"),gCo=l(),db=a("li"),Wte=a("strong"),hCo=o("deberta"),pCo=o(" \u2014 "),WI=a("a"),_Co=o("DebertaForSequenceClassification"),uCo=o(" (DeBERTa model)"),bCo=l(),cb=a("li"),Qte=a("strong"),vCo=o("deberta-v2"),TCo=o(" \u2014 "),QI=a("a"),FCo=o("DebertaV2ForSequenceClassification"),CCo=o(" (DeBERTa-v2 model)"),MCo=l(),fb=a("li"),Hte=a("strong"),ECo=o("distilbert"),yCo=o(" \u2014 "),HI=a("a"),wCo=o("DistilBertForSequenceClassification"),ACo=o(" (DistilBERT model)"),LCo=l(),mb=a("li"),Ute=a("strong"),BCo=o("electra"),xCo=o(" \u2014 "),UI=a("a"),kCo=o("ElectraForSequenceClassification"),RCo=o(" (ELECTRA model)"),SCo=l(),gb=a("li"),Jte=a("strong"),PCo=o("flaubert"),$Co=o(" \u2014 "),JI=a("a"),ICo=o("FlaubertForSequenceClassification"),jCo=o(" (FlauBERT model)"),DCo=l(),hb=a("li"),Yte=a("strong"),NCo=o("fnet"),qCo=o(" \u2014 "),YI=a("a"),OCo=o("FNetForSequenceClassification"),GCo=o(" (FNet model)"),XCo=l(),pb=a("li"),Kte=a("strong"),VCo=o("funnel"),zCo=o(" \u2014 "),KI=a("a"),WCo=o("FunnelForSequenceClassification"),QCo=o(" (Funnel Transformer model)"),HCo=l(),_b=a("li"),Zte=a("strong"),UCo=o("gpt2"),JCo=o(" \u2014 "),ZI=a("a"),YCo=o("GPT2ForSequenceClassification"),KCo=o(" (OpenAI GPT-2 model)"),ZCo=l(),ub=a("li"),eae=a("strong"),eMo=o("gpt_neo"),oMo=o(" \u2014 "),ej=a("a"),rMo=o("GPTNeoForSequenceClassification"),tMo=o(" (GPT Neo model)"),aMo=l(),bb=a("li"),oae=a("strong"),nMo=o("gptj"),sMo=o(" \u2014 "),oj=a("a"),lMo=o("GPTJForSequenceClassification"),iMo=o(" (GPT-J model)"),dMo=l(),vb=a("li"),rae=a("strong"),cMo=o("ibert"),fMo=o(" \u2014 "),rj=a("a"),mMo=o("IBertForSequenceClassification"),gMo=o(" (I-BERT model)"),hMo=l(),Tb=a("li"),tae=a("strong"),pMo=o("layoutlm"),_Mo=o(" \u2014 "),tj=a("a"),uMo=o("LayoutLMForSequenceClassification"),bMo=o(" (LayoutLM model)"),vMo=l(),Fb=a("li"),aae=a("strong"),TMo=o("layoutlmv2"),FMo=o(" \u2014 "),aj=a("a"),CMo=o("LayoutLMv2ForSequenceClassification"),MMo=o(" (LayoutLMv2 model)"),EMo=l(),Cb=a("li"),nae=a("strong"),yMo=o("led"),wMo=o(" \u2014 "),nj=a("a"),AMo=o("LEDForSequenceClassification"),LMo=o(" (LED model)"),BMo=l(),Mb=a("li"),sae=a("strong"),xMo=o("longformer"),kMo=o(" \u2014 "),sj=a("a"),RMo=o("LongformerForSequenceClassification"),SMo=o(" (Longformer model)"),PMo=l(),Eb=a("li"),lae=a("strong"),$Mo=o("mbart"),IMo=o(" \u2014 "),lj=a("a"),jMo=o("MBartForSequenceClassification"),DMo=o(" (mBART model)"),NMo=l(),yb=a("li"),iae=a("strong"),qMo=o("megatron-bert"),OMo=o(" \u2014 "),ij=a("a"),GMo=o("MegatronBertForSequenceClassification"),XMo=o(" (MegatronBert model)"),VMo=l(),wb=a("li"),dae=a("strong"),zMo=o("mobilebert"),WMo=o(" \u2014 "),dj=a("a"),QMo=o("MobileBertForSequenceClassification"),HMo=o(" (MobileBERT model)"),UMo=l(),Ab=a("li"),cae=a("strong"),JMo=o("mpnet"),YMo=o(" \u2014 "),cj=a("a"),KMo=o("MPNetForSequenceClassification"),ZMo=o(" (MPNet model)"),e4o=l(),Lb=a("li"),fae=a("strong"),o4o=o("nystromformer"),r4o=o(" \u2014 "),fj=a("a"),t4o=o("NystromformerForSequenceClassification"),a4o=o(" (Nystromformer model)"),n4o=l(),Bb=a("li"),mae=a("strong"),s4o=o("openai-gpt"),l4o=o(" \u2014 "),mj=a("a"),i4o=o("OpenAIGPTForSequenceClassification"),d4o=o(" (OpenAI GPT model)"),c4o=l(),xb=a("li"),gae=a("strong"),f4o=o("perceiver"),m4o=o(" \u2014 "),gj=a("a"),g4o=o("PerceiverForSequenceClassification"),h4o=o(" (Perceiver model)"),p4o=l(),kb=a("li"),hae=a("strong"),_4o=o("plbart"),u4o=o(" \u2014 "),hj=a("a"),b4o=o("PLBartForSequenceClassification"),v4o=o(" (PLBart model)"),T4o=l(),Rb=a("li"),pae=a("strong"),F4o=o("qdqbert"),C4o=o(" \u2014 "),pj=a("a"),M4o=o("QDQBertForSequenceClassification"),E4o=o(" (QDQBert model)"),y4o=l(),Sb=a("li"),_ae=a("strong"),w4o=o("reformer"),A4o=o(" \u2014 "),_j=a("a"),L4o=o("ReformerForSequenceClassification"),B4o=o(" (Reformer model)"),x4o=l(),Pb=a("li"),uae=a("strong"),k4o=o("rembert"),R4o=o(" \u2014 "),uj=a("a"),S4o=o("RemBertForSequenceClassification"),P4o=o(" (RemBERT model)"),$4o=l(),$b=a("li"),bae=a("strong"),I4o=o("roberta"),j4o=o(" \u2014 "),bj=a("a"),D4o=o("RobertaForSequenceClassification"),N4o=o(" (RoBERTa model)"),q4o=l(),Ib=a("li"),vae=a("strong"),O4o=o("roformer"),G4o=o(" \u2014 "),vj=a("a"),X4o=o("RoFormerForSequenceClassification"),V4o=o(" (RoFormer model)"),z4o=l(),jb=a("li"),Tae=a("strong"),W4o=o("squeezebert"),Q4o=o(" \u2014 "),Tj=a("a"),H4o=o("SqueezeBertForSequenceClassification"),U4o=o(" (SqueezeBERT model)"),J4o=l(),Db=a("li"),Fae=a("strong"),Y4o=o("tapas"),K4o=o(" \u2014 "),Fj=a("a"),Z4o=o("TapasForSequenceClassification"),eEo=o(" (TAPAS model)"),oEo=l(),Nb=a("li"),Cae=a("strong"),rEo=o("transfo-xl"),tEo=o(" \u2014 "),Cj=a("a"),aEo=o("TransfoXLForSequenceClassification"),nEo=o(" (Transformer-XL model)"),sEo=l(),qb=a("li"),Mae=a("strong"),lEo=o("xlm"),iEo=o(" \u2014 "),Mj=a("a"),dEo=o("XLMForSequenceClassification"),cEo=o(" (XLM model)"),fEo=l(),Ob=a("li"),Eae=a("strong"),mEo=o("xlm-roberta"),gEo=o(" \u2014 "),Ej=a("a"),hEo=o("XLMRobertaForSequenceClassification"),pEo=o(" (XLM-RoBERTa model)"),_Eo=l(),Gb=a("li"),yae=a("strong"),uEo=o("xlm-roberta-xl"),bEo=o(" \u2014 "),yj=a("a"),vEo=o("XLMRobertaXLForSequenceClassification"),TEo=o(" (XLM-RoBERTa-XL model)"),FEo=l(),Xb=a("li"),wae=a("strong"),CEo=o("xlnet"),MEo=o(" \u2014 "),wj=a("a"),EEo=o("XLNetForSequenceClassification"),yEo=o(" (XLNet model)"),wEo=l(),Vb=a("li"),Aae=a("strong"),AEo=o("yoso"),LEo=o(" \u2014 "),Aj=a("a"),BEo=o("YosoForSequenceClassification"),xEo=o(" (YOSO model)"),kEo=l(),zb=a("p"),REo=o("The model is set in evaluation mode by default using "),Lae=a("code"),SEo=o("model.eval()"),PEo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bae=a("code"),$Eo=o("model.train()"),IEo=l(),xae=a("p"),jEo=o("Examples:"),DEo=l(),f(AE.$$.fragment),uke=l(),Cd=a("h2"),Wb=a("a"),kae=a("span"),f(LE.$$.fragment),NEo=l(),Rae=a("span"),qEo=o("AutoModelForMultipleChoice"),bke=l(),tr=a("div"),f(BE.$$.fragment),OEo=l(),Md=a("p"),GEo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Sae=a("code"),XEo=o("from_pretrained()"),VEo=o("class method or the "),Pae=a("code"),zEo=o("from_config()"),WEo=o(`class
method.`),QEo=l(),xE=a("p"),HEo=o("This class cannot be instantiated directly using "),$ae=a("code"),UEo=o("__init__()"),JEo=o(" (throws an error)."),YEo=l(),Kr=a("div"),f(kE.$$.fragment),KEo=l(),Iae=a("p"),ZEo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),e3o=l(),Ed=a("p"),o3o=o(`Note:
Loading a model from its configuration file does `),jae=a("strong"),r3o=o("not"),t3o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dae=a("code"),a3o=o("from_pretrained()"),n3o=o("to load the model weights."),s3o=l(),Nae=a("p"),l3o=o("Examples:"),i3o=l(),f(RE.$$.fragment),d3o=l(),Xe=a("div"),f(SE.$$.fragment),c3o=l(),qae=a("p"),f3o=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),m3o=l(),en=a("p"),g3o=o("The model class to instantiate is selected based on the "),Oae=a("code"),h3o=o("model_type"),p3o=o(` property of the config object (either
passed as an argument or loaded from `),Gae=a("code"),_3o=o("pretrained_model_name_or_path"),u3o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xae=a("code"),b3o=o("pretrained_model_name_or_path"),v3o=o(":"),T3o=l(),O=a("ul"),Qb=a("li"),Vae=a("strong"),F3o=o("albert"),C3o=o(" \u2014 "),Lj=a("a"),M3o=o("AlbertForMultipleChoice"),E3o=o(" (ALBERT model)"),y3o=l(),Hb=a("li"),zae=a("strong"),w3o=o("bert"),A3o=o(" \u2014 "),Bj=a("a"),L3o=o("BertForMultipleChoice"),B3o=o(" (BERT model)"),x3o=l(),Ub=a("li"),Wae=a("strong"),k3o=o("big_bird"),R3o=o(" \u2014 "),xj=a("a"),S3o=o("BigBirdForMultipleChoice"),P3o=o(" (BigBird model)"),$3o=l(),Jb=a("li"),Qae=a("strong"),I3o=o("camembert"),j3o=o(" \u2014 "),kj=a("a"),D3o=o("CamembertForMultipleChoice"),N3o=o(" (CamemBERT model)"),q3o=l(),Yb=a("li"),Hae=a("strong"),O3o=o("canine"),G3o=o(" \u2014 "),Rj=a("a"),X3o=o("CanineForMultipleChoice"),V3o=o(" (Canine model)"),z3o=l(),Kb=a("li"),Uae=a("strong"),W3o=o("convbert"),Q3o=o(" \u2014 "),Sj=a("a"),H3o=o("ConvBertForMultipleChoice"),U3o=o(" (ConvBERT model)"),J3o=l(),Zb=a("li"),Jae=a("strong"),Y3o=o("data2vec-text"),K3o=o(" \u2014 "),Pj=a("a"),Z3o=o("Data2VecTextForMultipleChoice"),eyo=o(" (Data2VecText model)"),oyo=l(),e5=a("li"),Yae=a("strong"),ryo=o("distilbert"),tyo=o(" \u2014 "),$j=a("a"),ayo=o("DistilBertForMultipleChoice"),nyo=o(" (DistilBERT model)"),syo=l(),o5=a("li"),Kae=a("strong"),lyo=o("electra"),iyo=o(" \u2014 "),Ij=a("a"),dyo=o("ElectraForMultipleChoice"),cyo=o(" (ELECTRA model)"),fyo=l(),r5=a("li"),Zae=a("strong"),myo=o("flaubert"),gyo=o(" \u2014 "),jj=a("a"),hyo=o("FlaubertForMultipleChoice"),pyo=o(" (FlauBERT model)"),_yo=l(),t5=a("li"),ene=a("strong"),uyo=o("fnet"),byo=o(" \u2014 "),Dj=a("a"),vyo=o("FNetForMultipleChoice"),Tyo=o(" (FNet model)"),Fyo=l(),a5=a("li"),one=a("strong"),Cyo=o("funnel"),Myo=o(" \u2014 "),Nj=a("a"),Eyo=o("FunnelForMultipleChoice"),yyo=o(" (Funnel Transformer model)"),wyo=l(),n5=a("li"),rne=a("strong"),Ayo=o("ibert"),Lyo=o(" \u2014 "),qj=a("a"),Byo=o("IBertForMultipleChoice"),xyo=o(" (I-BERT model)"),kyo=l(),s5=a("li"),tne=a("strong"),Ryo=o("longformer"),Syo=o(" \u2014 "),Oj=a("a"),Pyo=o("LongformerForMultipleChoice"),$yo=o(" (Longformer model)"),Iyo=l(),l5=a("li"),ane=a("strong"),jyo=o("megatron-bert"),Dyo=o(" \u2014 "),Gj=a("a"),Nyo=o("MegatronBertForMultipleChoice"),qyo=o(" (MegatronBert model)"),Oyo=l(),i5=a("li"),nne=a("strong"),Gyo=o("mobilebert"),Xyo=o(" \u2014 "),Xj=a("a"),Vyo=o("MobileBertForMultipleChoice"),zyo=o(" (MobileBERT model)"),Wyo=l(),d5=a("li"),sne=a("strong"),Qyo=o("mpnet"),Hyo=o(" \u2014 "),Vj=a("a"),Uyo=o("MPNetForMultipleChoice"),Jyo=o(" (MPNet model)"),Yyo=l(),c5=a("li"),lne=a("strong"),Kyo=o("nystromformer"),Zyo=o(" \u2014 "),zj=a("a"),ewo=o("NystromformerForMultipleChoice"),owo=o(" (Nystromformer model)"),rwo=l(),f5=a("li"),ine=a("strong"),two=o("qdqbert"),awo=o(" \u2014 "),Wj=a("a"),nwo=o("QDQBertForMultipleChoice"),swo=o(" (QDQBert model)"),lwo=l(),m5=a("li"),dne=a("strong"),iwo=o("rembert"),dwo=o(" \u2014 "),Qj=a("a"),cwo=o("RemBertForMultipleChoice"),fwo=o(" (RemBERT model)"),mwo=l(),g5=a("li"),cne=a("strong"),gwo=o("roberta"),hwo=o(" \u2014 "),Hj=a("a"),pwo=o("RobertaForMultipleChoice"),_wo=o(" (RoBERTa model)"),uwo=l(),h5=a("li"),fne=a("strong"),bwo=o("roformer"),vwo=o(" \u2014 "),Uj=a("a"),Two=o("RoFormerForMultipleChoice"),Fwo=o(" (RoFormer model)"),Cwo=l(),p5=a("li"),mne=a("strong"),Mwo=o("squeezebert"),Ewo=o(" \u2014 "),Jj=a("a"),ywo=o("SqueezeBertForMultipleChoice"),wwo=o(" (SqueezeBERT model)"),Awo=l(),_5=a("li"),gne=a("strong"),Lwo=o("xlm"),Bwo=o(" \u2014 "),Yj=a("a"),xwo=o("XLMForMultipleChoice"),kwo=o(" (XLM model)"),Rwo=l(),u5=a("li"),hne=a("strong"),Swo=o("xlm-roberta"),Pwo=o(" \u2014 "),Kj=a("a"),$wo=o("XLMRobertaForMultipleChoice"),Iwo=o(" (XLM-RoBERTa model)"),jwo=l(),b5=a("li"),pne=a("strong"),Dwo=o("xlm-roberta-xl"),Nwo=o(" \u2014 "),Zj=a("a"),qwo=o("XLMRobertaXLForMultipleChoice"),Owo=o(" (XLM-RoBERTa-XL model)"),Gwo=l(),v5=a("li"),_ne=a("strong"),Xwo=o("xlnet"),Vwo=o(" \u2014 "),eD=a("a"),zwo=o("XLNetForMultipleChoice"),Wwo=o(" (XLNet model)"),Qwo=l(),T5=a("li"),une=a("strong"),Hwo=o("yoso"),Uwo=o(" \u2014 "),oD=a("a"),Jwo=o("YosoForMultipleChoice"),Ywo=o(" (YOSO model)"),Kwo=l(),F5=a("p"),Zwo=o("The model is set in evaluation mode by default using "),bne=a("code"),eAo=o("model.eval()"),oAo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vne=a("code"),rAo=o("model.train()"),tAo=l(),Tne=a("p"),aAo=o("Examples:"),nAo=l(),f(PE.$$.fragment),vke=l(),yd=a("h2"),C5=a("a"),Fne=a("span"),f($E.$$.fragment),sAo=l(),Cne=a("span"),lAo=o("AutoModelForNextSentencePrediction"),Tke=l(),ar=a("div"),f(IE.$$.fragment),iAo=l(),wd=a("p"),dAo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Mne=a("code"),cAo=o("from_pretrained()"),fAo=o("class method or the "),Ene=a("code"),mAo=o("from_config()"),gAo=o(`class
method.`),hAo=l(),jE=a("p"),pAo=o("This class cannot be instantiated directly using "),yne=a("code"),_Ao=o("__init__()"),uAo=o(" (throws an error)."),bAo=l(),Zr=a("div"),f(DE.$$.fragment),vAo=l(),wne=a("p"),TAo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),FAo=l(),Ad=a("p"),CAo=o(`Note:
Loading a model from its configuration file does `),Ane=a("strong"),MAo=o("not"),EAo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lne=a("code"),yAo=o("from_pretrained()"),wAo=o("to load the model weights."),AAo=l(),Bne=a("p"),LAo=o("Examples:"),BAo=l(),f(NE.$$.fragment),xAo=l(),Ve=a("div"),f(qE.$$.fragment),kAo=l(),xne=a("p"),RAo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),SAo=l(),on=a("p"),PAo=o("The model class to instantiate is selected based on the "),kne=a("code"),$Ao=o("model_type"),IAo=o(` property of the config object (either
passed as an argument or loaded from `),Rne=a("code"),jAo=o("pretrained_model_name_or_path"),DAo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sne=a("code"),NAo=o("pretrained_model_name_or_path"),qAo=o(":"),OAo=l(),ma=a("ul"),M5=a("li"),Pne=a("strong"),GAo=o("bert"),XAo=o(" \u2014 "),rD=a("a"),VAo=o("BertForNextSentencePrediction"),zAo=o(" (BERT model)"),WAo=l(),E5=a("li"),$ne=a("strong"),QAo=o("fnet"),HAo=o(" \u2014 "),tD=a("a"),UAo=o("FNetForNextSentencePrediction"),JAo=o(" (FNet model)"),YAo=l(),y5=a("li"),Ine=a("strong"),KAo=o("megatron-bert"),ZAo=o(" \u2014 "),aD=a("a"),eLo=o("MegatronBertForNextSentencePrediction"),oLo=o(" (MegatronBert model)"),rLo=l(),w5=a("li"),jne=a("strong"),tLo=o("mobilebert"),aLo=o(" \u2014 "),nD=a("a"),nLo=o("MobileBertForNextSentencePrediction"),sLo=o(" (MobileBERT model)"),lLo=l(),A5=a("li"),Dne=a("strong"),iLo=o("qdqbert"),dLo=o(" \u2014 "),sD=a("a"),cLo=o("QDQBertForNextSentencePrediction"),fLo=o(" (QDQBert model)"),mLo=l(),L5=a("p"),gLo=o("The model is set in evaluation mode by default using "),Nne=a("code"),hLo=o("model.eval()"),pLo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qne=a("code"),_Lo=o("model.train()"),uLo=l(),One=a("p"),bLo=o("Examples:"),vLo=l(),f(OE.$$.fragment),Fke=l(),Ld=a("h2"),B5=a("a"),Gne=a("span"),f(GE.$$.fragment),TLo=l(),Xne=a("span"),FLo=o("AutoModelForTokenClassification"),Cke=l(),nr=a("div"),f(XE.$$.fragment),CLo=l(),Bd=a("p"),MLo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Vne=a("code"),ELo=o("from_pretrained()"),yLo=o("class method or the "),zne=a("code"),wLo=o("from_config()"),ALo=o(`class
method.`),LLo=l(),VE=a("p"),BLo=o("This class cannot be instantiated directly using "),Wne=a("code"),xLo=o("__init__()"),kLo=o(" (throws an error)."),RLo=l(),et=a("div"),f(zE.$$.fragment),SLo=l(),Qne=a("p"),PLo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),$Lo=l(),xd=a("p"),ILo=o(`Note:
Loading a model from its configuration file does `),Hne=a("strong"),jLo=o("not"),DLo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Une=a("code"),NLo=o("from_pretrained()"),qLo=o("to load the model weights."),OLo=l(),Jne=a("p"),GLo=o("Examples:"),XLo=l(),f(WE.$$.fragment),VLo=l(),ze=a("div"),f(QE.$$.fragment),zLo=l(),Yne=a("p"),WLo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),QLo=l(),rn=a("p"),HLo=o("The model class to instantiate is selected based on the "),Kne=a("code"),ULo=o("model_type"),JLo=o(` property of the config object (either
passed as an argument or loaded from `),Zne=a("code"),YLo=o("pretrained_model_name_or_path"),KLo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ese=a("code"),ZLo=o("pretrained_model_name_or_path"),e7o=o(":"),o7o=l(),N=a("ul"),x5=a("li"),ose=a("strong"),r7o=o("albert"),t7o=o(" \u2014 "),lD=a("a"),a7o=o("AlbertForTokenClassification"),n7o=o(" (ALBERT model)"),s7o=l(),k5=a("li"),rse=a("strong"),l7o=o("bert"),i7o=o(" \u2014 "),iD=a("a"),d7o=o("BertForTokenClassification"),c7o=o(" (BERT model)"),f7o=l(),R5=a("li"),tse=a("strong"),m7o=o("big_bird"),g7o=o(" \u2014 "),dD=a("a"),h7o=o("BigBirdForTokenClassification"),p7o=o(" (BigBird model)"),_7o=l(),S5=a("li"),ase=a("strong"),u7o=o("camembert"),b7o=o(" \u2014 "),cD=a("a"),v7o=o("CamembertForTokenClassification"),T7o=o(" (CamemBERT model)"),F7o=l(),P5=a("li"),nse=a("strong"),C7o=o("canine"),M7o=o(" \u2014 "),fD=a("a"),E7o=o("CanineForTokenClassification"),y7o=o(" (Canine model)"),w7o=l(),$5=a("li"),sse=a("strong"),A7o=o("convbert"),L7o=o(" \u2014 "),mD=a("a"),B7o=o("ConvBertForTokenClassification"),x7o=o(" (ConvBERT model)"),k7o=l(),I5=a("li"),lse=a("strong"),R7o=o("data2vec-text"),S7o=o(" \u2014 "),gD=a("a"),P7o=o("Data2VecTextForTokenClassification"),$7o=o(" (Data2VecText model)"),I7o=l(),j5=a("li"),ise=a("strong"),j7o=o("deberta"),D7o=o(" \u2014 "),hD=a("a"),N7o=o("DebertaForTokenClassification"),q7o=o(" (DeBERTa model)"),O7o=l(),D5=a("li"),dse=a("strong"),G7o=o("deberta-v2"),X7o=o(" \u2014 "),pD=a("a"),V7o=o("DebertaV2ForTokenClassification"),z7o=o(" (DeBERTa-v2 model)"),W7o=l(),N5=a("li"),cse=a("strong"),Q7o=o("distilbert"),H7o=o(" \u2014 "),_D=a("a"),U7o=o("DistilBertForTokenClassification"),J7o=o(" (DistilBERT model)"),Y7o=l(),q5=a("li"),fse=a("strong"),K7o=o("electra"),Z7o=o(" \u2014 "),uD=a("a"),e9o=o("ElectraForTokenClassification"),o9o=o(" (ELECTRA model)"),r9o=l(),O5=a("li"),mse=a("strong"),t9o=o("flaubert"),a9o=o(" \u2014 "),bD=a("a"),n9o=o("FlaubertForTokenClassification"),s9o=o(" (FlauBERT model)"),l9o=l(),G5=a("li"),gse=a("strong"),i9o=o("fnet"),d9o=o(" \u2014 "),vD=a("a"),c9o=o("FNetForTokenClassification"),f9o=o(" (FNet model)"),m9o=l(),X5=a("li"),hse=a("strong"),g9o=o("funnel"),h9o=o(" \u2014 "),TD=a("a"),p9o=o("FunnelForTokenClassification"),_9o=o(" (Funnel Transformer model)"),u9o=l(),V5=a("li"),pse=a("strong"),b9o=o("gpt2"),v9o=o(" \u2014 "),FD=a("a"),T9o=o("GPT2ForTokenClassification"),F9o=o(" (OpenAI GPT-2 model)"),C9o=l(),z5=a("li"),_se=a("strong"),M9o=o("ibert"),E9o=o(" \u2014 "),CD=a("a"),y9o=o("IBertForTokenClassification"),w9o=o(" (I-BERT model)"),A9o=l(),W5=a("li"),use=a("strong"),L9o=o("layoutlm"),B9o=o(" \u2014 "),MD=a("a"),x9o=o("LayoutLMForTokenClassification"),k9o=o(" (LayoutLM model)"),R9o=l(),Q5=a("li"),bse=a("strong"),S9o=o("layoutlmv2"),P9o=o(" \u2014 "),ED=a("a"),$9o=o("LayoutLMv2ForTokenClassification"),I9o=o(" (LayoutLMv2 model)"),j9o=l(),H5=a("li"),vse=a("strong"),D9o=o("longformer"),N9o=o(" \u2014 "),yD=a("a"),q9o=o("LongformerForTokenClassification"),O9o=o(" (Longformer model)"),G9o=l(),U5=a("li"),Tse=a("strong"),X9o=o("megatron-bert"),V9o=o(" \u2014 "),wD=a("a"),z9o=o("MegatronBertForTokenClassification"),W9o=o(" (MegatronBert model)"),Q9o=l(),J5=a("li"),Fse=a("strong"),H9o=o("mobilebert"),U9o=o(" \u2014 "),AD=a("a"),J9o=o("MobileBertForTokenClassification"),Y9o=o(" (MobileBERT model)"),K9o=l(),Y5=a("li"),Cse=a("strong"),Z9o=o("mpnet"),eBo=o(" \u2014 "),LD=a("a"),oBo=o("MPNetForTokenClassification"),rBo=o(" (MPNet model)"),tBo=l(),K5=a("li"),Mse=a("strong"),aBo=o("nystromformer"),nBo=o(" \u2014 "),BD=a("a"),sBo=o("NystromformerForTokenClassification"),lBo=o(" (Nystromformer model)"),iBo=l(),Z5=a("li"),Ese=a("strong"),dBo=o("qdqbert"),cBo=o(" \u2014 "),xD=a("a"),fBo=o("QDQBertForTokenClassification"),mBo=o(" (QDQBert model)"),gBo=l(),e2=a("li"),yse=a("strong"),hBo=o("rembert"),pBo=o(" \u2014 "),kD=a("a"),_Bo=o("RemBertForTokenClassification"),uBo=o(" (RemBERT model)"),bBo=l(),o2=a("li"),wse=a("strong"),vBo=o("roberta"),TBo=o(" \u2014 "),RD=a("a"),FBo=o("RobertaForTokenClassification"),CBo=o(" (RoBERTa model)"),MBo=l(),r2=a("li"),Ase=a("strong"),EBo=o("roformer"),yBo=o(" \u2014 "),SD=a("a"),wBo=o("RoFormerForTokenClassification"),ABo=o(" (RoFormer model)"),LBo=l(),t2=a("li"),Lse=a("strong"),BBo=o("squeezebert"),xBo=o(" \u2014 "),PD=a("a"),kBo=o("SqueezeBertForTokenClassification"),RBo=o(" (SqueezeBERT model)"),SBo=l(),a2=a("li"),Bse=a("strong"),PBo=o("xlm"),$Bo=o(" \u2014 "),$D=a("a"),IBo=o("XLMForTokenClassification"),jBo=o(" (XLM model)"),DBo=l(),n2=a("li"),xse=a("strong"),NBo=o("xlm-roberta"),qBo=o(" \u2014 "),ID=a("a"),OBo=o("XLMRobertaForTokenClassification"),GBo=o(" (XLM-RoBERTa model)"),XBo=l(),s2=a("li"),kse=a("strong"),VBo=o("xlm-roberta-xl"),zBo=o(" \u2014 "),jD=a("a"),WBo=o("XLMRobertaXLForTokenClassification"),QBo=o(" (XLM-RoBERTa-XL model)"),HBo=l(),l2=a("li"),Rse=a("strong"),UBo=o("xlnet"),JBo=o(" \u2014 "),DD=a("a"),YBo=o("XLNetForTokenClassification"),KBo=o(" (XLNet model)"),ZBo=l(),i2=a("li"),Sse=a("strong"),exo=o("yoso"),oxo=o(" \u2014 "),ND=a("a"),rxo=o("YosoForTokenClassification"),txo=o(" (YOSO model)"),axo=l(),d2=a("p"),nxo=o("The model is set in evaluation mode by default using "),Pse=a("code"),sxo=o("model.eval()"),lxo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$se=a("code"),ixo=o("model.train()"),dxo=l(),Ise=a("p"),cxo=o("Examples:"),fxo=l(),f(HE.$$.fragment),Mke=l(),kd=a("h2"),c2=a("a"),jse=a("span"),f(UE.$$.fragment),mxo=l(),Dse=a("span"),gxo=o("AutoModelForQuestionAnswering"),Eke=l(),sr=a("div"),f(JE.$$.fragment),hxo=l(),Rd=a("p"),pxo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Nse=a("code"),_xo=o("from_pretrained()"),uxo=o("class method or the "),qse=a("code"),bxo=o("from_config()"),vxo=o(`class
method.`),Txo=l(),YE=a("p"),Fxo=o("This class cannot be instantiated directly using "),Ose=a("code"),Cxo=o("__init__()"),Mxo=o(" (throws an error)."),Exo=l(),ot=a("div"),f(KE.$$.fragment),yxo=l(),Gse=a("p"),wxo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Axo=l(),Sd=a("p"),Lxo=o(`Note:
Loading a model from its configuration file does `),Xse=a("strong"),Bxo=o("not"),xxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vse=a("code"),kxo=o("from_pretrained()"),Rxo=o("to load the model weights."),Sxo=l(),zse=a("p"),Pxo=o("Examples:"),$xo=l(),f(ZE.$$.fragment),Ixo=l(),We=a("div"),f(e3.$$.fragment),jxo=l(),Wse=a("p"),Dxo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Nxo=l(),tn=a("p"),qxo=o("The model class to instantiate is selected based on the "),Qse=a("code"),Oxo=o("model_type"),Gxo=o(` property of the config object (either
passed as an argument or loaded from `),Hse=a("code"),Xxo=o("pretrained_model_name_or_path"),Vxo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Use=a("code"),zxo=o("pretrained_model_name_or_path"),Wxo=o(":"),Qxo=l(),R=a("ul"),f2=a("li"),Jse=a("strong"),Hxo=o("albert"),Uxo=o(" \u2014 "),qD=a("a"),Jxo=o("AlbertForQuestionAnswering"),Yxo=o(" (ALBERT model)"),Kxo=l(),m2=a("li"),Yse=a("strong"),Zxo=o("bart"),eko=o(" \u2014 "),OD=a("a"),oko=o("BartForQuestionAnswering"),rko=o(" (BART model)"),tko=l(),g2=a("li"),Kse=a("strong"),ako=o("bert"),nko=o(" \u2014 "),GD=a("a"),sko=o("BertForQuestionAnswering"),lko=o(" (BERT model)"),iko=l(),h2=a("li"),Zse=a("strong"),dko=o("big_bird"),cko=o(" \u2014 "),XD=a("a"),fko=o("BigBirdForQuestionAnswering"),mko=o(" (BigBird model)"),gko=l(),p2=a("li"),ele=a("strong"),hko=o("bigbird_pegasus"),pko=o(" \u2014 "),VD=a("a"),_ko=o("BigBirdPegasusForQuestionAnswering"),uko=o(" (BigBirdPegasus model)"),bko=l(),_2=a("li"),ole=a("strong"),vko=o("camembert"),Tko=o(" \u2014 "),zD=a("a"),Fko=o("CamembertForQuestionAnswering"),Cko=o(" (CamemBERT model)"),Mko=l(),u2=a("li"),rle=a("strong"),Eko=o("canine"),yko=o(" \u2014 "),WD=a("a"),wko=o("CanineForQuestionAnswering"),Ako=o(" (Canine model)"),Lko=l(),b2=a("li"),tle=a("strong"),Bko=o("convbert"),xko=o(" \u2014 "),QD=a("a"),kko=o("ConvBertForQuestionAnswering"),Rko=o(" (ConvBERT model)"),Sko=l(),v2=a("li"),ale=a("strong"),Pko=o("data2vec-text"),$ko=o(" \u2014 "),HD=a("a"),Iko=o("Data2VecTextForQuestionAnswering"),jko=o(" (Data2VecText model)"),Dko=l(),T2=a("li"),nle=a("strong"),Nko=o("deberta"),qko=o(" \u2014 "),UD=a("a"),Oko=o("DebertaForQuestionAnswering"),Gko=o(" (DeBERTa model)"),Xko=l(),F2=a("li"),sle=a("strong"),Vko=o("deberta-v2"),zko=o(" \u2014 "),JD=a("a"),Wko=o("DebertaV2ForQuestionAnswering"),Qko=o(" (DeBERTa-v2 model)"),Hko=l(),C2=a("li"),lle=a("strong"),Uko=o("distilbert"),Jko=o(" \u2014 "),YD=a("a"),Yko=o("DistilBertForQuestionAnswering"),Kko=o(" (DistilBERT model)"),Zko=l(),M2=a("li"),ile=a("strong"),eRo=o("electra"),oRo=o(" \u2014 "),KD=a("a"),rRo=o("ElectraForQuestionAnswering"),tRo=o(" (ELECTRA model)"),aRo=l(),E2=a("li"),dle=a("strong"),nRo=o("flaubert"),sRo=o(" \u2014 "),ZD=a("a"),lRo=o("FlaubertForQuestionAnsweringSimple"),iRo=o(" (FlauBERT model)"),dRo=l(),y2=a("li"),cle=a("strong"),cRo=o("fnet"),fRo=o(" \u2014 "),eN=a("a"),mRo=o("FNetForQuestionAnswering"),gRo=o(" (FNet model)"),hRo=l(),w2=a("li"),fle=a("strong"),pRo=o("funnel"),_Ro=o(" \u2014 "),oN=a("a"),uRo=o("FunnelForQuestionAnswering"),bRo=o(" (Funnel Transformer model)"),vRo=l(),A2=a("li"),mle=a("strong"),TRo=o("gptj"),FRo=o(" \u2014 "),rN=a("a"),CRo=o("GPTJForQuestionAnswering"),MRo=o(" (GPT-J model)"),ERo=l(),L2=a("li"),gle=a("strong"),yRo=o("ibert"),wRo=o(" \u2014 "),tN=a("a"),ARo=o("IBertForQuestionAnswering"),LRo=o(" (I-BERT model)"),BRo=l(),B2=a("li"),hle=a("strong"),xRo=o("layoutlmv2"),kRo=o(" \u2014 "),aN=a("a"),RRo=o("LayoutLMv2ForQuestionAnswering"),SRo=o(" (LayoutLMv2 model)"),PRo=l(),x2=a("li"),ple=a("strong"),$Ro=o("led"),IRo=o(" \u2014 "),nN=a("a"),jRo=o("LEDForQuestionAnswering"),DRo=o(" (LED model)"),NRo=l(),k2=a("li"),_le=a("strong"),qRo=o("longformer"),ORo=o(" \u2014 "),sN=a("a"),GRo=o("LongformerForQuestionAnswering"),XRo=o(" (Longformer model)"),VRo=l(),R2=a("li"),ule=a("strong"),zRo=o("lxmert"),WRo=o(" \u2014 "),lN=a("a"),QRo=o("LxmertForQuestionAnswering"),HRo=o(" (LXMERT model)"),URo=l(),S2=a("li"),ble=a("strong"),JRo=o("mbart"),YRo=o(" \u2014 "),iN=a("a"),KRo=o("MBartForQuestionAnswering"),ZRo=o(" (mBART model)"),eSo=l(),P2=a("li"),vle=a("strong"),oSo=o("megatron-bert"),rSo=o(" \u2014 "),dN=a("a"),tSo=o("MegatronBertForQuestionAnswering"),aSo=o(" (MegatronBert model)"),nSo=l(),$2=a("li"),Tle=a("strong"),sSo=o("mobilebert"),lSo=o(" \u2014 "),cN=a("a"),iSo=o("MobileBertForQuestionAnswering"),dSo=o(" (MobileBERT model)"),cSo=l(),I2=a("li"),Fle=a("strong"),fSo=o("mpnet"),mSo=o(" \u2014 "),fN=a("a"),gSo=o("MPNetForQuestionAnswering"),hSo=o(" (MPNet model)"),pSo=l(),j2=a("li"),Cle=a("strong"),_So=o("nystromformer"),uSo=o(" \u2014 "),mN=a("a"),bSo=o("NystromformerForQuestionAnswering"),vSo=o(" (Nystromformer model)"),TSo=l(),D2=a("li"),Mle=a("strong"),FSo=o("qdqbert"),CSo=o(" \u2014 "),gN=a("a"),MSo=o("QDQBertForQuestionAnswering"),ESo=o(" (QDQBert model)"),ySo=l(),N2=a("li"),Ele=a("strong"),wSo=o("reformer"),ASo=o(" \u2014 "),hN=a("a"),LSo=o("ReformerForQuestionAnswering"),BSo=o(" (Reformer model)"),xSo=l(),q2=a("li"),yle=a("strong"),kSo=o("rembert"),RSo=o(" \u2014 "),pN=a("a"),SSo=o("RemBertForQuestionAnswering"),PSo=o(" (RemBERT model)"),$So=l(),O2=a("li"),wle=a("strong"),ISo=o("roberta"),jSo=o(" \u2014 "),_N=a("a"),DSo=o("RobertaForQuestionAnswering"),NSo=o(" (RoBERTa model)"),qSo=l(),G2=a("li"),Ale=a("strong"),OSo=o("roformer"),GSo=o(" \u2014 "),uN=a("a"),XSo=o("RoFormerForQuestionAnswering"),VSo=o(" (RoFormer model)"),zSo=l(),X2=a("li"),Lle=a("strong"),WSo=o("splinter"),QSo=o(" \u2014 "),bN=a("a"),HSo=o("SplinterForQuestionAnswering"),USo=o(" (Splinter model)"),JSo=l(),V2=a("li"),Ble=a("strong"),YSo=o("squeezebert"),KSo=o(" \u2014 "),vN=a("a"),ZSo=o("SqueezeBertForQuestionAnswering"),ePo=o(" (SqueezeBERT model)"),oPo=l(),z2=a("li"),xle=a("strong"),rPo=o("xlm"),tPo=o(" \u2014 "),TN=a("a"),aPo=o("XLMForQuestionAnsweringSimple"),nPo=o(" (XLM model)"),sPo=l(),W2=a("li"),kle=a("strong"),lPo=o("xlm-roberta"),iPo=o(" \u2014 "),FN=a("a"),dPo=o("XLMRobertaForQuestionAnswering"),cPo=o(" (XLM-RoBERTa model)"),fPo=l(),Q2=a("li"),Rle=a("strong"),mPo=o("xlm-roberta-xl"),gPo=o(" \u2014 "),CN=a("a"),hPo=o("XLMRobertaXLForQuestionAnswering"),pPo=o(" (XLM-RoBERTa-XL model)"),_Po=l(),H2=a("li"),Sle=a("strong"),uPo=o("xlnet"),bPo=o(" \u2014 "),MN=a("a"),vPo=o("XLNetForQuestionAnsweringSimple"),TPo=o(" (XLNet model)"),FPo=l(),U2=a("li"),Ple=a("strong"),CPo=o("yoso"),MPo=o(" \u2014 "),EN=a("a"),EPo=o("YosoForQuestionAnswering"),yPo=o(" (YOSO model)"),wPo=l(),J2=a("p"),APo=o("The model is set in evaluation mode by default using "),$le=a("code"),LPo=o("model.eval()"),BPo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ile=a("code"),xPo=o("model.train()"),kPo=l(),jle=a("p"),RPo=o("Examples:"),SPo=l(),f(o3.$$.fragment),yke=l(),Pd=a("h2"),Y2=a("a"),Dle=a("span"),f(r3.$$.fragment),PPo=l(),Nle=a("span"),$Po=o("AutoModelForTableQuestionAnswering"),wke=l(),lr=a("div"),f(t3.$$.fragment),IPo=l(),$d=a("p"),jPo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),qle=a("code"),DPo=o("from_pretrained()"),NPo=o("class method or the "),Ole=a("code"),qPo=o("from_config()"),OPo=o(`class
method.`),GPo=l(),a3=a("p"),XPo=o("This class cannot be instantiated directly using "),Gle=a("code"),VPo=o("__init__()"),zPo=o(" (throws an error)."),WPo=l(),rt=a("div"),f(n3.$$.fragment),QPo=l(),Xle=a("p"),HPo=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),UPo=l(),Id=a("p"),JPo=o(`Note:
Loading a model from its configuration file does `),Vle=a("strong"),YPo=o("not"),KPo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zle=a("code"),ZPo=o("from_pretrained()"),e$o=o("to load the model weights."),o$o=l(),Wle=a("p"),r$o=o("Examples:"),t$o=l(),f(s3.$$.fragment),a$o=l(),Qe=a("div"),f(l3.$$.fragment),n$o=l(),Qle=a("p"),s$o=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),l$o=l(),an=a("p"),i$o=o("The model class to instantiate is selected based on the "),Hle=a("code"),d$o=o("model_type"),c$o=o(` property of the config object (either
passed as an argument or loaded from `),Ule=a("code"),f$o=o("pretrained_model_name_or_path"),m$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jle=a("code"),g$o=o("pretrained_model_name_or_path"),h$o=o(":"),p$o=l(),Yle=a("ul"),K2=a("li"),Kle=a("strong"),_$o=o("tapas"),u$o=o(" \u2014 "),yN=a("a"),b$o=o("TapasForQuestionAnswering"),v$o=o(" (TAPAS model)"),T$o=l(),Z2=a("p"),F$o=o("The model is set in evaluation mode by default using "),Zle=a("code"),C$o=o("model.eval()"),M$o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eie=a("code"),E$o=o("model.train()"),y$o=l(),oie=a("p"),w$o=o("Examples:"),A$o=l(),f(i3.$$.fragment),Ake=l(),jd=a("h2"),ev=a("a"),rie=a("span"),f(d3.$$.fragment),L$o=l(),tie=a("span"),B$o=o("AutoModelForImageClassification"),Lke=l(),ir=a("div"),f(c3.$$.fragment),x$o=l(),Dd=a("p"),k$o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),aie=a("code"),R$o=o("from_pretrained()"),S$o=o("class method or the "),nie=a("code"),P$o=o("from_config()"),$$o=o(`class
method.`),I$o=l(),f3=a("p"),j$o=o("This class cannot be instantiated directly using "),sie=a("code"),D$o=o("__init__()"),N$o=o(" (throws an error)."),q$o=l(),tt=a("div"),f(m3.$$.fragment),O$o=l(),lie=a("p"),G$o=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),X$o=l(),Nd=a("p"),V$o=o(`Note:
Loading a model from its configuration file does `),iie=a("strong"),z$o=o("not"),W$o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),die=a("code"),Q$o=o("from_pretrained()"),H$o=o("to load the model weights."),U$o=l(),cie=a("p"),J$o=o("Examples:"),Y$o=l(),f(g3.$$.fragment),K$o=l(),He=a("div"),f(h3.$$.fragment),Z$o=l(),fie=a("p"),eIo=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),oIo=l(),nn=a("p"),rIo=o("The model class to instantiate is selected based on the "),mie=a("code"),tIo=o("model_type"),aIo=o(` property of the config object (either
passed as an argument or loaded from `),gie=a("code"),nIo=o("pretrained_model_name_or_path"),sIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hie=a("code"),lIo=o("pretrained_model_name_or_path"),iIo=o(":"),dIo=l(),Ce=a("ul"),ov=a("li"),pie=a("strong"),cIo=o("beit"),fIo=o(" \u2014 "),wN=a("a"),mIo=o("BeitForImageClassification"),gIo=o(" (BEiT model)"),hIo=l(),rv=a("li"),_ie=a("strong"),pIo=o("convnext"),_Io=o(" \u2014 "),AN=a("a"),uIo=o("ConvNextForImageClassification"),bIo=o(" (ConvNext model)"),vIo=l(),zs=a("li"),uie=a("strong"),TIo=o("deit"),FIo=o(" \u2014 "),LN=a("a"),CIo=o("DeiTForImageClassification"),MIo=o(" or "),BN=a("a"),EIo=o("DeiTForImageClassificationWithTeacher"),yIo=o(" (DeiT model)"),wIo=l(),tv=a("li"),bie=a("strong"),AIo=o("imagegpt"),LIo=o(" \u2014 "),xN=a("a"),BIo=o("ImageGPTForImageClassification"),xIo=o(" (ImageGPT model)"),kIo=l(),pa=a("li"),vie=a("strong"),RIo=o("perceiver"),SIo=o(" \u2014 "),kN=a("a"),PIo=o("PerceiverForImageClassificationLearned"),$Io=o(" or "),RN=a("a"),IIo=o("PerceiverForImageClassificationFourier"),jIo=o(" or "),SN=a("a"),DIo=o("PerceiverForImageClassificationConvProcessing"),NIo=o(" (Perceiver model)"),qIo=l(),av=a("li"),Tie=a("strong"),OIo=o("poolformer"),GIo=o(" \u2014 "),PN=a("a"),XIo=o("PoolFormerForImageClassification"),VIo=o(" (PoolFormer model)"),zIo=l(),nv=a("li"),Fie=a("strong"),WIo=o("segformer"),QIo=o(" \u2014 "),$N=a("a"),HIo=o("SegformerForImageClassification"),UIo=o(" (SegFormer model)"),JIo=l(),sv=a("li"),Cie=a("strong"),YIo=o("swin"),KIo=o(" \u2014 "),IN=a("a"),ZIo=o("SwinForImageClassification"),ejo=o(" (Swin model)"),ojo=l(),lv=a("li"),Mie=a("strong"),rjo=o("vit"),tjo=o(" \u2014 "),jN=a("a"),ajo=o("ViTForImageClassification"),njo=o(" (ViT model)"),sjo=l(),iv=a("p"),ljo=o("The model is set in evaluation mode by default using "),Eie=a("code"),ijo=o("model.eval()"),djo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yie=a("code"),cjo=o("model.train()"),fjo=l(),wie=a("p"),mjo=o("Examples:"),gjo=l(),f(p3.$$.fragment),Bke=l(),qd=a("h2"),dv=a("a"),Aie=a("span"),f(_3.$$.fragment),hjo=l(),Lie=a("span"),pjo=o("AutoModelForVision2Seq"),xke=l(),dr=a("div"),f(u3.$$.fragment),_jo=l(),Od=a("p"),ujo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Bie=a("code"),bjo=o("from_pretrained()"),vjo=o("class method or the "),xie=a("code"),Tjo=o("from_config()"),Fjo=o(`class
method.`),Cjo=l(),b3=a("p"),Mjo=o("This class cannot be instantiated directly using "),kie=a("code"),Ejo=o("__init__()"),yjo=o(" (throws an error)."),wjo=l(),at=a("div"),f(v3.$$.fragment),Ajo=l(),Rie=a("p"),Ljo=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Bjo=l(),Gd=a("p"),xjo=o(`Note:
Loading a model from its configuration file does `),Sie=a("strong"),kjo=o("not"),Rjo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Pie=a("code"),Sjo=o("from_pretrained()"),Pjo=o("to load the model weights."),$jo=l(),$ie=a("p"),Ijo=o("Examples:"),jjo=l(),f(T3.$$.fragment),Djo=l(),Ue=a("div"),f(F3.$$.fragment),Njo=l(),Iie=a("p"),qjo=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Ojo=l(),sn=a("p"),Gjo=o("The model class to instantiate is selected based on the "),jie=a("code"),Xjo=o("model_type"),Vjo=o(` property of the config object (either
passed as an argument or loaded from `),Die=a("code"),zjo=o("pretrained_model_name_or_path"),Wjo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nie=a("code"),Qjo=o("pretrained_model_name_or_path"),Hjo=o(":"),Ujo=l(),qie=a("ul"),cv=a("li"),Oie=a("strong"),Jjo=o("vision-encoder-decoder"),Yjo=o(" \u2014 "),DN=a("a"),Kjo=o("VisionEncoderDecoderModel"),Zjo=o(" (Vision Encoder decoder model)"),eDo=l(),fv=a("p"),oDo=o("The model is set in evaluation mode by default using "),Gie=a("code"),rDo=o("model.eval()"),tDo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xie=a("code"),aDo=o("model.train()"),nDo=l(),Vie=a("p"),sDo=o("Examples:"),lDo=l(),f(C3.$$.fragment),kke=l(),Xd=a("h2"),mv=a("a"),zie=a("span"),f(M3.$$.fragment),iDo=l(),Wie=a("span"),dDo=o("AutoModelForAudioClassification"),Rke=l(),cr=a("div"),f(E3.$$.fragment),cDo=l(),Vd=a("p"),fDo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Qie=a("code"),mDo=o("from_pretrained()"),gDo=o("class method or the "),Hie=a("code"),hDo=o("from_config()"),pDo=o(`class
method.`),_Do=l(),y3=a("p"),uDo=o("This class cannot be instantiated directly using "),Uie=a("code"),bDo=o("__init__()"),vDo=o(" (throws an error)."),TDo=l(),nt=a("div"),f(w3.$$.fragment),FDo=l(),Jie=a("p"),CDo=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),MDo=l(),zd=a("p"),EDo=o(`Note:
Loading a model from its configuration file does `),Yie=a("strong"),yDo=o("not"),wDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kie=a("code"),ADo=o("from_pretrained()"),LDo=o("to load the model weights."),BDo=l(),Zie=a("p"),xDo=o("Examples:"),kDo=l(),f(A3.$$.fragment),RDo=l(),Je=a("div"),f(L3.$$.fragment),SDo=l(),ede=a("p"),PDo=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),$Do=l(),ln=a("p"),IDo=o("The model class to instantiate is selected based on the "),ode=a("code"),jDo=o("model_type"),DDo=o(` property of the config object (either
passed as an argument or loaded from `),rde=a("code"),NDo=o("pretrained_model_name_or_path"),qDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tde=a("code"),ODo=o("pretrained_model_name_or_path"),GDo=o(":"),XDo=l(),xe=a("ul"),gv=a("li"),ade=a("strong"),VDo=o("data2vec-audio"),zDo=o(" \u2014 "),NN=a("a"),WDo=o("Data2VecAudioForSequenceClassification"),QDo=o(" (Data2VecAudio model)"),HDo=l(),hv=a("li"),nde=a("strong"),UDo=o("hubert"),JDo=o(" \u2014 "),qN=a("a"),YDo=o("HubertForSequenceClassification"),KDo=o(" (Hubert model)"),ZDo=l(),pv=a("li"),sde=a("strong"),eNo=o("sew"),oNo=o(" \u2014 "),ON=a("a"),rNo=o("SEWForSequenceClassification"),tNo=o(" (SEW model)"),aNo=l(),_v=a("li"),lde=a("strong"),nNo=o("sew-d"),sNo=o(" \u2014 "),GN=a("a"),lNo=o("SEWDForSequenceClassification"),iNo=o(" (SEW-D model)"),dNo=l(),uv=a("li"),ide=a("strong"),cNo=o("unispeech"),fNo=o(" \u2014 "),XN=a("a"),mNo=o("UniSpeechForSequenceClassification"),gNo=o(" (UniSpeech model)"),hNo=l(),bv=a("li"),dde=a("strong"),pNo=o("unispeech-sat"),_No=o(" \u2014 "),VN=a("a"),uNo=o("UniSpeechSatForSequenceClassification"),bNo=o(" (UniSpeechSat model)"),vNo=l(),vv=a("li"),cde=a("strong"),TNo=o("wav2vec2"),FNo=o(" \u2014 "),zN=a("a"),CNo=o("Wav2Vec2ForSequenceClassification"),MNo=o(" (Wav2Vec2 model)"),ENo=l(),Tv=a("li"),fde=a("strong"),yNo=o("wavlm"),wNo=o(" \u2014 "),WN=a("a"),ANo=o("WavLMForSequenceClassification"),LNo=o(" (WavLM model)"),BNo=l(),Fv=a("p"),xNo=o("The model is set in evaluation mode by default using "),mde=a("code"),kNo=o("model.eval()"),RNo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gde=a("code"),SNo=o("model.train()"),PNo=l(),hde=a("p"),$No=o("Examples:"),INo=l(),f(B3.$$.fragment),Ske=l(),Wd=a("h2"),Cv=a("a"),pde=a("span"),f(x3.$$.fragment),jNo=l(),_de=a("span"),DNo=o("AutoModelForAudioFrameClassification"),Pke=l(),fr=a("div"),f(k3.$$.fragment),NNo=l(),Qd=a("p"),qNo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),ude=a("code"),ONo=o("from_pretrained()"),GNo=o("class method or the "),bde=a("code"),XNo=o("from_config()"),VNo=o(`class
method.`),zNo=l(),R3=a("p"),WNo=o("This class cannot be instantiated directly using "),vde=a("code"),QNo=o("__init__()"),HNo=o(" (throws an error)."),UNo=l(),st=a("div"),f(S3.$$.fragment),JNo=l(),Tde=a("p"),YNo=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),KNo=l(),Hd=a("p"),ZNo=o(`Note:
Loading a model from its configuration file does `),Fde=a("strong"),eqo=o("not"),oqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cde=a("code"),rqo=o("from_pretrained()"),tqo=o("to load the model weights."),aqo=l(),Mde=a("p"),nqo=o("Examples:"),sqo=l(),f(P3.$$.fragment),lqo=l(),Ye=a("div"),f($3.$$.fragment),iqo=l(),Ede=a("p"),dqo=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),cqo=l(),dn=a("p"),fqo=o("The model class to instantiate is selected based on the "),yde=a("code"),mqo=o("model_type"),gqo=o(` property of the config object (either
passed as an argument or loaded from `),wde=a("code"),hqo=o("pretrained_model_name_or_path"),pqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ade=a("code"),_qo=o("pretrained_model_name_or_path"),uqo=o(":"),bqo=l(),cn=a("ul"),Mv=a("li"),Lde=a("strong"),vqo=o("data2vec-audio"),Tqo=o(" \u2014 "),QN=a("a"),Fqo=o("Data2VecAudioForAudioFrameClassification"),Cqo=o(" (Data2VecAudio model)"),Mqo=l(),Ev=a("li"),Bde=a("strong"),Eqo=o("unispeech-sat"),yqo=o(" \u2014 "),HN=a("a"),wqo=o("UniSpeechSatForAudioFrameClassification"),Aqo=o(" (UniSpeechSat model)"),Lqo=l(),yv=a("li"),xde=a("strong"),Bqo=o("wav2vec2"),xqo=o(" \u2014 "),UN=a("a"),kqo=o("Wav2Vec2ForAudioFrameClassification"),Rqo=o(" (Wav2Vec2 model)"),Sqo=l(),wv=a("li"),kde=a("strong"),Pqo=o("wavlm"),$qo=o(" \u2014 "),JN=a("a"),Iqo=o("WavLMForAudioFrameClassification"),jqo=o(" (WavLM model)"),Dqo=l(),Av=a("p"),Nqo=o("The model is set in evaluation mode by default using "),Rde=a("code"),qqo=o("model.eval()"),Oqo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sde=a("code"),Gqo=o("model.train()"),Xqo=l(),Pde=a("p"),Vqo=o("Examples:"),zqo=l(),f(I3.$$.fragment),$ke=l(),Ud=a("h2"),Lv=a("a"),$de=a("span"),f(j3.$$.fragment),Wqo=l(),Ide=a("span"),Qqo=o("AutoModelForCTC"),Ike=l(),mr=a("div"),f(D3.$$.fragment),Hqo=l(),Jd=a("p"),Uqo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),jde=a("code"),Jqo=o("from_pretrained()"),Yqo=o("class method or the "),Dde=a("code"),Kqo=o("from_config()"),Zqo=o(`class
method.`),eOo=l(),N3=a("p"),oOo=o("This class cannot be instantiated directly using "),Nde=a("code"),rOo=o("__init__()"),tOo=o(" (throws an error)."),aOo=l(),lt=a("div"),f(q3.$$.fragment),nOo=l(),qde=a("p"),sOo=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),lOo=l(),Yd=a("p"),iOo=o(`Note:
Loading a model from its configuration file does `),Ode=a("strong"),dOo=o("not"),cOo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gde=a("code"),fOo=o("from_pretrained()"),mOo=o("to load the model weights."),gOo=l(),Xde=a("p"),hOo=o("Examples:"),pOo=l(),f(O3.$$.fragment),_Oo=l(),Ke=a("div"),f(G3.$$.fragment),uOo=l(),Vde=a("p"),bOo=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),vOo=l(),fn=a("p"),TOo=o("The model class to instantiate is selected based on the "),zde=a("code"),FOo=o("model_type"),COo=o(` property of the config object (either
passed as an argument or loaded from `),Wde=a("code"),MOo=o("pretrained_model_name_or_path"),EOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qde=a("code"),yOo=o("pretrained_model_name_or_path"),wOo=o(":"),AOo=l(),ke=a("ul"),Bv=a("li"),Hde=a("strong"),LOo=o("data2vec-audio"),BOo=o(" \u2014 "),YN=a("a"),xOo=o("Data2VecAudioForCTC"),kOo=o(" (Data2VecAudio model)"),ROo=l(),xv=a("li"),Ude=a("strong"),SOo=o("hubert"),POo=o(" \u2014 "),KN=a("a"),$Oo=o("HubertForCTC"),IOo=o(" (Hubert model)"),jOo=l(),kv=a("li"),Jde=a("strong"),DOo=o("sew"),NOo=o(" \u2014 "),ZN=a("a"),qOo=o("SEWForCTC"),OOo=o(" (SEW model)"),GOo=l(),Rv=a("li"),Yde=a("strong"),XOo=o("sew-d"),VOo=o(" \u2014 "),eq=a("a"),zOo=o("SEWDForCTC"),WOo=o(" (SEW-D model)"),QOo=l(),Sv=a("li"),Kde=a("strong"),HOo=o("unispeech"),UOo=o(" \u2014 "),oq=a("a"),JOo=o("UniSpeechForCTC"),YOo=o(" (UniSpeech model)"),KOo=l(),Pv=a("li"),Zde=a("strong"),ZOo=o("unispeech-sat"),eGo=o(" \u2014 "),rq=a("a"),oGo=o("UniSpeechSatForCTC"),rGo=o(" (UniSpeechSat model)"),tGo=l(),$v=a("li"),ece=a("strong"),aGo=o("wav2vec2"),nGo=o(" \u2014 "),tq=a("a"),sGo=o("Wav2Vec2ForCTC"),lGo=o(" (Wav2Vec2 model)"),iGo=l(),Iv=a("li"),oce=a("strong"),dGo=o("wavlm"),cGo=o(" \u2014 "),aq=a("a"),fGo=o("WavLMForCTC"),mGo=o(" (WavLM model)"),gGo=l(),jv=a("p"),hGo=o("The model is set in evaluation mode by default using "),rce=a("code"),pGo=o("model.eval()"),_Go=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tce=a("code"),uGo=o("model.train()"),bGo=l(),ace=a("p"),vGo=o("Examples:"),TGo=l(),f(X3.$$.fragment),jke=l(),Kd=a("h2"),Dv=a("a"),nce=a("span"),f(V3.$$.fragment),FGo=l(),sce=a("span"),CGo=o("AutoModelForSpeechSeq2Seq"),Dke=l(),gr=a("div"),f(z3.$$.fragment),MGo=l(),Zd=a("p"),EGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),lce=a("code"),yGo=o("from_pretrained()"),wGo=o("class method or the "),ice=a("code"),AGo=o("from_config()"),LGo=o(`class
method.`),BGo=l(),W3=a("p"),xGo=o("This class cannot be instantiated directly using "),dce=a("code"),kGo=o("__init__()"),RGo=o(" (throws an error)."),SGo=l(),it=a("div"),f(Q3.$$.fragment),PGo=l(),cce=a("p"),$Go=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),IGo=l(),ec=a("p"),jGo=o(`Note:
Loading a model from its configuration file does `),fce=a("strong"),DGo=o("not"),NGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mce=a("code"),qGo=o("from_pretrained()"),OGo=o("to load the model weights."),GGo=l(),gce=a("p"),XGo=o("Examples:"),VGo=l(),f(H3.$$.fragment),zGo=l(),Ze=a("div"),f(U3.$$.fragment),WGo=l(),hce=a("p"),QGo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),HGo=l(),mn=a("p"),UGo=o("The model class to instantiate is selected based on the "),pce=a("code"),JGo=o("model_type"),YGo=o(` property of the config object (either
passed as an argument or loaded from `),_ce=a("code"),KGo=o("pretrained_model_name_or_path"),ZGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uce=a("code"),eXo=o("pretrained_model_name_or_path"),oXo=o(":"),rXo=l(),J3=a("ul"),Nv=a("li"),bce=a("strong"),tXo=o("speech-encoder-decoder"),aXo=o(" \u2014 "),nq=a("a"),nXo=o("SpeechEncoderDecoderModel"),sXo=o(" (Speech Encoder decoder model)"),lXo=l(),qv=a("li"),vce=a("strong"),iXo=o("speech_to_text"),dXo=o(" \u2014 "),sq=a("a"),cXo=o("Speech2TextForConditionalGeneration"),fXo=o(" (Speech2Text model)"),mXo=l(),Ov=a("p"),gXo=o("The model is set in evaluation mode by default using "),Tce=a("code"),hXo=o("model.eval()"),pXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fce=a("code"),_Xo=o("model.train()"),uXo=l(),Cce=a("p"),bXo=o("Examples:"),vXo=l(),f(Y3.$$.fragment),Nke=l(),oc=a("h2"),Gv=a("a"),Mce=a("span"),f(K3.$$.fragment),TXo=l(),Ece=a("span"),FXo=o("AutoModelForAudioXVector"),qke=l(),hr=a("div"),f(Z3.$$.fragment),CXo=l(),rc=a("p"),MXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),yce=a("code"),EXo=o("from_pretrained()"),yXo=o("class method or the "),wce=a("code"),wXo=o("from_config()"),AXo=o(`class
method.`),LXo=l(),ey=a("p"),BXo=o("This class cannot be instantiated directly using "),Ace=a("code"),xXo=o("__init__()"),kXo=o(" (throws an error)."),RXo=l(),dt=a("div"),f(oy.$$.fragment),SXo=l(),Lce=a("p"),PXo=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),$Xo=l(),tc=a("p"),IXo=o(`Note:
Loading a model from its configuration file does `),Bce=a("strong"),jXo=o("not"),DXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xce=a("code"),NXo=o("from_pretrained()"),qXo=o("to load the model weights."),OXo=l(),kce=a("p"),GXo=o("Examples:"),XXo=l(),f(ry.$$.fragment),VXo=l(),eo=a("div"),f(ty.$$.fragment),zXo=l(),Rce=a("p"),WXo=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),QXo=l(),gn=a("p"),HXo=o("The model class to instantiate is selected based on the "),Sce=a("code"),UXo=o("model_type"),JXo=o(` property of the config object (either
passed as an argument or loaded from `),Pce=a("code"),YXo=o("pretrained_model_name_or_path"),KXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ce=a("code"),ZXo=o("pretrained_model_name_or_path"),eVo=o(":"),oVo=l(),hn=a("ul"),Xv=a("li"),Ice=a("strong"),rVo=o("data2vec-audio"),tVo=o(" \u2014 "),lq=a("a"),aVo=o("Data2VecAudioForXVector"),nVo=o(" (Data2VecAudio model)"),sVo=l(),Vv=a("li"),jce=a("strong"),lVo=o("unispeech-sat"),iVo=o(" \u2014 "),iq=a("a"),dVo=o("UniSpeechSatForXVector"),cVo=o(" (UniSpeechSat model)"),fVo=l(),zv=a("li"),Dce=a("strong"),mVo=o("wav2vec2"),gVo=o(" \u2014 "),dq=a("a"),hVo=o("Wav2Vec2ForXVector"),pVo=o(" (Wav2Vec2 model)"),_Vo=l(),Wv=a("li"),Nce=a("strong"),uVo=o("wavlm"),bVo=o(" \u2014 "),cq=a("a"),vVo=o("WavLMForXVector"),TVo=o(" (WavLM model)"),FVo=l(),Qv=a("p"),CVo=o("The model is set in evaluation mode by default using "),qce=a("code"),MVo=o("model.eval()"),EVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Oce=a("code"),yVo=o("model.train()"),wVo=l(),Gce=a("p"),AVo=o("Examples:"),LVo=l(),f(ay.$$.fragment),Oke=l(),ac=a("h2"),Hv=a("a"),Xce=a("span"),f(ny.$$.fragment),BVo=l(),Vce=a("span"),xVo=o("AutoModelForMaskedImageModeling"),Gke=l(),pr=a("div"),f(sy.$$.fragment),kVo=l(),nc=a("p"),RVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),zce=a("code"),SVo=o("from_pretrained()"),PVo=o("class method or the "),Wce=a("code"),$Vo=o("from_config()"),IVo=o(`class
method.`),jVo=l(),ly=a("p"),DVo=o("This class cannot be instantiated directly using "),Qce=a("code"),NVo=o("__init__()"),qVo=o(" (throws an error)."),OVo=l(),ct=a("div"),f(iy.$$.fragment),GVo=l(),Hce=a("p"),XVo=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),VVo=l(),sc=a("p"),zVo=o(`Note:
Loading a model from its configuration file does `),Uce=a("strong"),WVo=o("not"),QVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jce=a("code"),HVo=o("from_pretrained()"),UVo=o("to load the model weights."),JVo=l(),Yce=a("p"),YVo=o("Examples:"),KVo=l(),f(dy.$$.fragment),ZVo=l(),oo=a("div"),f(cy.$$.fragment),ezo=l(),Kce=a("p"),ozo=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),rzo=l(),pn=a("p"),tzo=o("The model class to instantiate is selected based on the "),Zce=a("code"),azo=o("model_type"),nzo=o(` property of the config object (either
passed as an argument or loaded from `),efe=a("code"),szo=o("pretrained_model_name_or_path"),lzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ofe=a("code"),izo=o("pretrained_model_name_or_path"),dzo=o(":"),czo=l(),lc=a("ul"),Uv=a("li"),rfe=a("strong"),fzo=o("deit"),mzo=o(" \u2014 "),fq=a("a"),gzo=o("DeiTForMaskedImageModeling"),hzo=o(" (DeiT model)"),pzo=l(),Jv=a("li"),tfe=a("strong"),_zo=o("swin"),uzo=o(" \u2014 "),mq=a("a"),bzo=o("SwinForMaskedImageModeling"),vzo=o(" (Swin model)"),Tzo=l(),Yv=a("li"),afe=a("strong"),Fzo=o("vit"),Czo=o(" \u2014 "),gq=a("a"),Mzo=o("ViTForMaskedImageModeling"),Ezo=o(" (ViT model)"),yzo=l(),Kv=a("p"),wzo=o("The model is set in evaluation mode by default using "),nfe=a("code"),Azo=o("model.eval()"),Lzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sfe=a("code"),Bzo=o("model.train()"),xzo=l(),lfe=a("p"),kzo=o("Examples:"),Rzo=l(),f(fy.$$.fragment),Xke=l(),ic=a("h2"),Zv=a("a"),ife=a("span"),f(my.$$.fragment),Szo=l(),dfe=a("span"),Pzo=o("AutoModelForObjectDetection"),Vke=l(),_r=a("div"),f(gy.$$.fragment),$zo=l(),dc=a("p"),Izo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),cfe=a("code"),jzo=o("from_pretrained()"),Dzo=o("class method or the "),ffe=a("code"),Nzo=o("from_config()"),qzo=o(`class
method.`),Ozo=l(),hy=a("p"),Gzo=o("This class cannot be instantiated directly using "),mfe=a("code"),Xzo=o("__init__()"),Vzo=o(" (throws an error)."),zzo=l(),ft=a("div"),f(py.$$.fragment),Wzo=l(),gfe=a("p"),Qzo=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Hzo=l(),cc=a("p"),Uzo=o(`Note:
Loading a model from its configuration file does `),hfe=a("strong"),Jzo=o("not"),Yzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pfe=a("code"),Kzo=o("from_pretrained()"),Zzo=o("to load the model weights."),eWo=l(),_fe=a("p"),oWo=o("Examples:"),rWo=l(),f(_y.$$.fragment),tWo=l(),ro=a("div"),f(uy.$$.fragment),aWo=l(),ufe=a("p"),nWo=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),sWo=l(),_n=a("p"),lWo=o("The model class to instantiate is selected based on the "),bfe=a("code"),iWo=o("model_type"),dWo=o(` property of the config object (either
passed as an argument or loaded from `),vfe=a("code"),cWo=o("pretrained_model_name_or_path"),fWo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tfe=a("code"),mWo=o("pretrained_model_name_or_path"),gWo=o(":"),hWo=l(),Ffe=a("ul"),e6=a("li"),Cfe=a("strong"),pWo=o("detr"),_Wo=o(" \u2014 "),hq=a("a"),uWo=o("DetrForObjectDetection"),bWo=o(" (DETR model)"),vWo=l(),o6=a("p"),TWo=o("The model is set in evaluation mode by default using "),Mfe=a("code"),FWo=o("model.eval()"),CWo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Efe=a("code"),MWo=o("model.train()"),EWo=l(),yfe=a("p"),yWo=o("Examples:"),wWo=l(),f(by.$$.fragment),zke=l(),fc=a("h2"),r6=a("a"),wfe=a("span"),f(vy.$$.fragment),AWo=l(),Afe=a("span"),LWo=o("AutoModelForImageSegmentation"),Wke=l(),ur=a("div"),f(Ty.$$.fragment),BWo=l(),mc=a("p"),xWo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Lfe=a("code"),kWo=o("from_pretrained()"),RWo=o("class method or the "),Bfe=a("code"),SWo=o("from_config()"),PWo=o(`class
method.`),$Wo=l(),Fy=a("p"),IWo=o("This class cannot be instantiated directly using "),xfe=a("code"),jWo=o("__init__()"),DWo=o(" (throws an error)."),NWo=l(),mt=a("div"),f(Cy.$$.fragment),qWo=l(),kfe=a("p"),OWo=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),GWo=l(),gc=a("p"),XWo=o(`Note:
Loading a model from its configuration file does `),Rfe=a("strong"),VWo=o("not"),zWo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sfe=a("code"),WWo=o("from_pretrained()"),QWo=o("to load the model weights."),HWo=l(),Pfe=a("p"),UWo=o("Examples:"),JWo=l(),f(My.$$.fragment),YWo=l(),to=a("div"),f(Ey.$$.fragment),KWo=l(),$fe=a("p"),ZWo=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),eQo=l(),un=a("p"),oQo=o("The model class to instantiate is selected based on the "),Ife=a("code"),rQo=o("model_type"),tQo=o(` property of the config object (either
passed as an argument or loaded from `),jfe=a("code"),aQo=o("pretrained_model_name_or_path"),nQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dfe=a("code"),sQo=o("pretrained_model_name_or_path"),lQo=o(":"),iQo=l(),Nfe=a("ul"),t6=a("li"),qfe=a("strong"),dQo=o("detr"),cQo=o(" \u2014 "),pq=a("a"),fQo=o("DetrForSegmentation"),mQo=o(" (DETR model)"),gQo=l(),a6=a("p"),hQo=o("The model is set in evaluation mode by default using "),Ofe=a("code"),pQo=o("model.eval()"),_Qo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gfe=a("code"),uQo=o("model.train()"),bQo=l(),Xfe=a("p"),vQo=o("Examples:"),TQo=l(),f(yy.$$.fragment),Qke=l(),hc=a("h2"),n6=a("a"),Vfe=a("span"),f(wy.$$.fragment),FQo=l(),zfe=a("span"),CQo=o("AutoModelForSemanticSegmentation"),Hke=l(),br=a("div"),f(Ay.$$.fragment),MQo=l(),pc=a("p"),EQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Wfe=a("code"),yQo=o("from_pretrained()"),wQo=o("class method or the "),Qfe=a("code"),AQo=o("from_config()"),LQo=o(`class
method.`),BQo=l(),Ly=a("p"),xQo=o("This class cannot be instantiated directly using "),Hfe=a("code"),kQo=o("__init__()"),RQo=o(" (throws an error)."),SQo=l(),gt=a("div"),f(By.$$.fragment),PQo=l(),Ufe=a("p"),$Qo=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),IQo=l(),_c=a("p"),jQo=o(`Note:
Loading a model from its configuration file does `),Jfe=a("strong"),DQo=o("not"),NQo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yfe=a("code"),qQo=o("from_pretrained()"),OQo=o("to load the model weights."),GQo=l(),Kfe=a("p"),XQo=o("Examples:"),VQo=l(),f(xy.$$.fragment),zQo=l(),ao=a("div"),f(ky.$$.fragment),WQo=l(),Zfe=a("p"),QQo=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),HQo=l(),bn=a("p"),UQo=o("The model class to instantiate is selected based on the "),eme=a("code"),JQo=o("model_type"),YQo=o(` property of the config object (either
passed as an argument or loaded from `),ome=a("code"),KQo=o("pretrained_model_name_or_path"),ZQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rme=a("code"),eHo=o("pretrained_model_name_or_path"),oHo=o(":"),rHo=l(),Ry=a("ul"),s6=a("li"),tme=a("strong"),tHo=o("beit"),aHo=o(" \u2014 "),_q=a("a"),nHo=o("BeitForSemanticSegmentation"),sHo=o(" (BEiT model)"),lHo=l(),l6=a("li"),ame=a("strong"),iHo=o("segformer"),dHo=o(" \u2014 "),uq=a("a"),cHo=o("SegformerForSemanticSegmentation"),fHo=o(" (SegFormer model)"),mHo=l(),i6=a("p"),gHo=o("The model is set in evaluation mode by default using "),nme=a("code"),hHo=o("model.eval()"),pHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sme=a("code"),_Ho=o("model.train()"),uHo=l(),lme=a("p"),bHo=o("Examples:"),vHo=l(),f(Sy.$$.fragment),Uke=l(),uc=a("h2"),d6=a("a"),ime=a("span"),f(Py.$$.fragment),THo=l(),dme=a("span"),FHo=o("AutoModelForInstanceSegmentation"),Jke=l(),vr=a("div"),f($y.$$.fragment),CHo=l(),bc=a("p"),MHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),cme=a("code"),EHo=o("from_pretrained()"),yHo=o("class method or the "),fme=a("code"),wHo=o("from_config()"),AHo=o(`class
method.`),LHo=l(),Iy=a("p"),BHo=o("This class cannot be instantiated directly using "),mme=a("code"),xHo=o("__init__()"),kHo=o(" (throws an error)."),RHo=l(),ht=a("div"),f(jy.$$.fragment),SHo=l(),gme=a("p"),PHo=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),$Ho=l(),vc=a("p"),IHo=o(`Note:
Loading a model from its configuration file does `),hme=a("strong"),jHo=o("not"),DHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pme=a("code"),NHo=o("from_pretrained()"),qHo=o("to load the model weights."),OHo=l(),_me=a("p"),GHo=o("Examples:"),XHo=l(),f(Dy.$$.fragment),VHo=l(),no=a("div"),f(Ny.$$.fragment),zHo=l(),ume=a("p"),WHo=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),QHo=l(),vn=a("p"),HHo=o("The model class to instantiate is selected based on the "),bme=a("code"),UHo=o("model_type"),JHo=o(` property of the config object (either
passed as an argument or loaded from `),vme=a("code"),YHo=o("pretrained_model_name_or_path"),KHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tme=a("code"),ZHo=o("pretrained_model_name_or_path"),eUo=o(":"),oUo=l(),Fme=a("ul"),c6=a("li"),Cme=a("strong"),rUo=o("maskformer"),tUo=o(" \u2014 "),bq=a("a"),aUo=o("MaskFormerForInstanceSegmentation"),nUo=o(" (MaskFormer model)"),sUo=l(),f6=a("p"),lUo=o("The model is set in evaluation mode by default using "),Mme=a("code"),iUo=o("model.eval()"),dUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Eme=a("code"),cUo=o("model.train()"),fUo=l(),yme=a("p"),mUo=o("Examples:"),gUo=l(),f(qy.$$.fragment),Yke=l(),Tc=a("h2"),m6=a("a"),wme=a("span"),f(Oy.$$.fragment),hUo=l(),Ame=a("span"),pUo=o("TFAutoModel"),Kke=l(),Tr=a("div"),f(Gy.$$.fragment),_Uo=l(),Fc=a("p"),uUo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Lme=a("code"),bUo=o("from_pretrained()"),vUo=o("class method or the "),Bme=a("code"),TUo=o("from_config()"),FUo=o(`class
method.`),CUo=l(),Xy=a("p"),MUo=o("This class cannot be instantiated directly using "),xme=a("code"),EUo=o("__init__()"),yUo=o(" (throws an error)."),wUo=l(),pt=a("div"),f(Vy.$$.fragment),AUo=l(),kme=a("p"),LUo=o("Instantiates one of the base model classes of the library from a configuration."),BUo=l(),Cc=a("p"),xUo=o(`Note:
Loading a model from its configuration file does `),Rme=a("strong"),kUo=o("not"),RUo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sme=a("code"),SUo=o("from_pretrained()"),PUo=o("to load the model weights."),$Uo=l(),Pme=a("p"),IUo=o("Examples:"),jUo=l(),f(zy.$$.fragment),DUo=l(),ho=a("div"),f(Wy.$$.fragment),NUo=l(),$me=a("p"),qUo=o("Instantiate one of the base model classes of the library from a pretrained model."),OUo=l(),Tn=a("p"),GUo=o("The model class to instantiate is selected based on the "),Ime=a("code"),XUo=o("model_type"),VUo=o(` property of the config object (either
passed as an argument or loaded from `),jme=a("code"),zUo=o("pretrained_model_name_or_path"),WUo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dme=a("code"),QUo=o("pretrained_model_name_or_path"),HUo=o(":"),UUo=l(),B=a("ul"),g6=a("li"),Nme=a("strong"),JUo=o("albert"),YUo=o(" \u2014 "),vq=a("a"),KUo=o("TFAlbertModel"),ZUo=o(" (ALBERT model)"),eJo=l(),h6=a("li"),qme=a("strong"),oJo=o("bart"),rJo=o(" \u2014 "),Tq=a("a"),tJo=o("TFBartModel"),aJo=o(" (BART model)"),nJo=l(),p6=a("li"),Ome=a("strong"),sJo=o("bert"),lJo=o(" \u2014 "),Fq=a("a"),iJo=o("TFBertModel"),dJo=o(" (BERT model)"),cJo=l(),_6=a("li"),Gme=a("strong"),fJo=o("blenderbot"),mJo=o(" \u2014 "),Cq=a("a"),gJo=o("TFBlenderbotModel"),hJo=o(" (Blenderbot model)"),pJo=l(),u6=a("li"),Xme=a("strong"),_Jo=o("blenderbot-small"),uJo=o(" \u2014 "),Mq=a("a"),bJo=o("TFBlenderbotSmallModel"),vJo=o(" (BlenderbotSmall model)"),TJo=l(),b6=a("li"),Vme=a("strong"),FJo=o("camembert"),CJo=o(" \u2014 "),Eq=a("a"),MJo=o("TFCamembertModel"),EJo=o(" (CamemBERT model)"),yJo=l(),v6=a("li"),zme=a("strong"),wJo=o("clip"),AJo=o(" \u2014 "),yq=a("a"),LJo=o("TFCLIPModel"),BJo=o(" (CLIP model)"),xJo=l(),T6=a("li"),Wme=a("strong"),kJo=o("convbert"),RJo=o(" \u2014 "),wq=a("a"),SJo=o("TFConvBertModel"),PJo=o(" (ConvBERT model)"),$Jo=l(),F6=a("li"),Qme=a("strong"),IJo=o("convnext"),jJo=o(" \u2014 "),Aq=a("a"),DJo=o("TFConvNextModel"),NJo=o(" (ConvNext model)"),qJo=l(),C6=a("li"),Hme=a("strong"),OJo=o("ctrl"),GJo=o(" \u2014 "),Lq=a("a"),XJo=o("TFCTRLModel"),VJo=o(" (CTRL model)"),zJo=l(),M6=a("li"),Ume=a("strong"),WJo=o("deberta"),QJo=o(" \u2014 "),Bq=a("a"),HJo=o("TFDebertaModel"),UJo=o(" (DeBERTa model)"),JJo=l(),E6=a("li"),Jme=a("strong"),YJo=o("deberta-v2"),KJo=o(" \u2014 "),xq=a("a"),ZJo=o("TFDebertaV2Model"),eYo=o(" (DeBERTa-v2 model)"),oYo=l(),y6=a("li"),Yme=a("strong"),rYo=o("distilbert"),tYo=o(" \u2014 "),kq=a("a"),aYo=o("TFDistilBertModel"),nYo=o(" (DistilBERT model)"),sYo=l(),w6=a("li"),Kme=a("strong"),lYo=o("dpr"),iYo=o(" \u2014 "),Rq=a("a"),dYo=o("TFDPRQuestionEncoder"),cYo=o(" (DPR model)"),fYo=l(),A6=a("li"),Zme=a("strong"),mYo=o("electra"),gYo=o(" \u2014 "),Sq=a("a"),hYo=o("TFElectraModel"),pYo=o(" (ELECTRA model)"),_Yo=l(),L6=a("li"),ege=a("strong"),uYo=o("flaubert"),bYo=o(" \u2014 "),Pq=a("a"),vYo=o("TFFlaubertModel"),TYo=o(" (FlauBERT model)"),FYo=l(),Ws=a("li"),oge=a("strong"),CYo=o("funnel"),MYo=o(" \u2014 "),$q=a("a"),EYo=o("TFFunnelModel"),yYo=o(" or "),Iq=a("a"),wYo=o("TFFunnelBaseModel"),AYo=o(" (Funnel Transformer model)"),LYo=l(),B6=a("li"),rge=a("strong"),BYo=o("gpt2"),xYo=o(" \u2014 "),jq=a("a"),kYo=o("TFGPT2Model"),RYo=o(" (OpenAI GPT-2 model)"),SYo=l(),x6=a("li"),tge=a("strong"),PYo=o("hubert"),$Yo=o(" \u2014 "),Dq=a("a"),IYo=o("TFHubertModel"),jYo=o(" (Hubert model)"),DYo=l(),k6=a("li"),age=a("strong"),NYo=o("layoutlm"),qYo=o(" \u2014 "),Nq=a("a"),OYo=o("TFLayoutLMModel"),GYo=o(" (LayoutLM model)"),XYo=l(),R6=a("li"),nge=a("strong"),VYo=o("led"),zYo=o(" \u2014 "),qq=a("a"),WYo=o("TFLEDModel"),QYo=o(" (LED model)"),HYo=l(),S6=a("li"),sge=a("strong"),UYo=o("longformer"),JYo=o(" \u2014 "),Oq=a("a"),YYo=o("TFLongformerModel"),KYo=o(" (Longformer model)"),ZYo=l(),P6=a("li"),lge=a("strong"),eKo=o("lxmert"),oKo=o(" \u2014 "),Gq=a("a"),rKo=o("TFLxmertModel"),tKo=o(" (LXMERT model)"),aKo=l(),$6=a("li"),ige=a("strong"),nKo=o("marian"),sKo=o(" \u2014 "),Xq=a("a"),lKo=o("TFMarianModel"),iKo=o(" (Marian model)"),dKo=l(),I6=a("li"),dge=a("strong"),cKo=o("mbart"),fKo=o(" \u2014 "),Vq=a("a"),mKo=o("TFMBartModel"),gKo=o(" (mBART model)"),hKo=l(),j6=a("li"),cge=a("strong"),pKo=o("mobilebert"),_Ko=o(" \u2014 "),zq=a("a"),uKo=o("TFMobileBertModel"),bKo=o(" (MobileBERT model)"),vKo=l(),D6=a("li"),fge=a("strong"),TKo=o("mpnet"),FKo=o(" \u2014 "),Wq=a("a"),CKo=o("TFMPNetModel"),MKo=o(" (MPNet model)"),EKo=l(),N6=a("li"),mge=a("strong"),yKo=o("mt5"),wKo=o(" \u2014 "),Qq=a("a"),AKo=o("TFMT5Model"),LKo=o(" (mT5 model)"),BKo=l(),q6=a("li"),gge=a("strong"),xKo=o("openai-gpt"),kKo=o(" \u2014 "),Hq=a("a"),RKo=o("TFOpenAIGPTModel"),SKo=o(" (OpenAI GPT model)"),PKo=l(),O6=a("li"),hge=a("strong"),$Ko=o("pegasus"),IKo=o(" \u2014 "),Uq=a("a"),jKo=o("TFPegasusModel"),DKo=o(" (Pegasus model)"),NKo=l(),G6=a("li"),pge=a("strong"),qKo=o("rembert"),OKo=o(" \u2014 "),Jq=a("a"),GKo=o("TFRemBertModel"),XKo=o(" (RemBERT model)"),VKo=l(),X6=a("li"),_ge=a("strong"),zKo=o("roberta"),WKo=o(" \u2014 "),Yq=a("a"),QKo=o("TFRobertaModel"),HKo=o(" (RoBERTa model)"),UKo=l(),V6=a("li"),uge=a("strong"),JKo=o("roformer"),YKo=o(" \u2014 "),Kq=a("a"),KKo=o("TFRoFormerModel"),ZKo=o(" (RoFormer model)"),eZo=l(),z6=a("li"),bge=a("strong"),oZo=o("speech_to_text"),rZo=o(" \u2014 "),Zq=a("a"),tZo=o("TFSpeech2TextModel"),aZo=o(" (Speech2Text model)"),nZo=l(),W6=a("li"),vge=a("strong"),sZo=o("t5"),lZo=o(" \u2014 "),eO=a("a"),iZo=o("TFT5Model"),dZo=o(" (T5 model)"),cZo=l(),Q6=a("li"),Tge=a("strong"),fZo=o("tapas"),mZo=o(" \u2014 "),oO=a("a"),gZo=o("TFTapasModel"),hZo=o(" (TAPAS model)"),pZo=l(),H6=a("li"),Fge=a("strong"),_Zo=o("transfo-xl"),uZo=o(" \u2014 "),rO=a("a"),bZo=o("TFTransfoXLModel"),vZo=o(" (Transformer-XL model)"),TZo=l(),U6=a("li"),Cge=a("strong"),FZo=o("vit"),CZo=o(" \u2014 "),tO=a("a"),MZo=o("TFViTModel"),EZo=o(" (ViT model)"),yZo=l(),J6=a("li"),Mge=a("strong"),wZo=o("wav2vec2"),AZo=o(" \u2014 "),aO=a("a"),LZo=o("TFWav2Vec2Model"),BZo=o(" (Wav2Vec2 model)"),xZo=l(),Y6=a("li"),Ege=a("strong"),kZo=o("xlm"),RZo=o(" \u2014 "),nO=a("a"),SZo=o("TFXLMModel"),PZo=o(" (XLM model)"),$Zo=l(),K6=a("li"),yge=a("strong"),IZo=o("xlm-roberta"),jZo=o(" \u2014 "),sO=a("a"),DZo=o("TFXLMRobertaModel"),NZo=o(" (XLM-RoBERTa model)"),qZo=l(),Z6=a("li"),wge=a("strong"),OZo=o("xlnet"),GZo=o(" \u2014 "),lO=a("a"),XZo=o("TFXLNetModel"),VZo=o(" (XLNet model)"),zZo=l(),Age=a("p"),WZo=o("Examples:"),QZo=l(),f(Qy.$$.fragment),Zke=l(),Mc=a("h2"),e0=a("a"),Lge=a("span"),f(Hy.$$.fragment),HZo=l(),Bge=a("span"),UZo=o("TFAutoModelForPreTraining"),eRe=l(),Fr=a("div"),f(Uy.$$.fragment),JZo=l(),Ec=a("p"),YZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),xge=a("code"),KZo=o("from_pretrained()"),ZZo=o("class method or the "),kge=a("code"),eer=o("from_config()"),oer=o(`class
method.`),rer=l(),Jy=a("p"),ter=o("This class cannot be instantiated directly using "),Rge=a("code"),aer=o("__init__()"),ner=o(" (throws an error)."),ser=l(),_t=a("div"),f(Yy.$$.fragment),ler=l(),Sge=a("p"),ier=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),der=l(),yc=a("p"),cer=o(`Note:
Loading a model from its configuration file does `),Pge=a("strong"),fer=o("not"),mer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$ge=a("code"),ger=o("from_pretrained()"),her=o("to load the model weights."),per=l(),Ige=a("p"),_er=o("Examples:"),uer=l(),f(Ky.$$.fragment),ber=l(),po=a("div"),f(Zy.$$.fragment),ver=l(),jge=a("p"),Ter=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Fer=l(),Fn=a("p"),Cer=o("The model class to instantiate is selected based on the "),Dge=a("code"),Mer=o("model_type"),Eer=o(` property of the config object (either
passed as an argument or loaded from `),Nge=a("code"),yer=o("pretrained_model_name_or_path"),wer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qge=a("code"),Aer=o("pretrained_model_name_or_path"),Ler=o(":"),Ber=l(),H=a("ul"),o0=a("li"),Oge=a("strong"),xer=o("albert"),ker=o(" \u2014 "),iO=a("a"),Rer=o("TFAlbertForPreTraining"),Ser=o(" (ALBERT model)"),Per=l(),r0=a("li"),Gge=a("strong"),$er=o("bart"),Ier=o(" \u2014 "),dO=a("a"),jer=o("TFBartForConditionalGeneration"),Der=o(" (BART model)"),Ner=l(),t0=a("li"),Xge=a("strong"),qer=o("bert"),Oer=o(" \u2014 "),cO=a("a"),Ger=o("TFBertForPreTraining"),Xer=o(" (BERT model)"),Ver=l(),a0=a("li"),Vge=a("strong"),zer=o("camembert"),Wer=o(" \u2014 "),fO=a("a"),Qer=o("TFCamembertForMaskedLM"),Her=o(" (CamemBERT model)"),Uer=l(),n0=a("li"),zge=a("strong"),Jer=o("ctrl"),Yer=o(" \u2014 "),mO=a("a"),Ker=o("TFCTRLLMHeadModel"),Zer=o(" (CTRL model)"),eor=l(),s0=a("li"),Wge=a("strong"),oor=o("distilbert"),ror=o(" \u2014 "),gO=a("a"),tor=o("TFDistilBertForMaskedLM"),aor=o(" (DistilBERT model)"),nor=l(),l0=a("li"),Qge=a("strong"),sor=o("electra"),lor=o(" \u2014 "),hO=a("a"),ior=o("TFElectraForPreTraining"),dor=o(" (ELECTRA model)"),cor=l(),i0=a("li"),Hge=a("strong"),mor=o("flaubert"),gor=o(" \u2014 "),pO=a("a"),hor=o("TFFlaubertWithLMHeadModel"),por=o(" (FlauBERT model)"),_or=l(),d0=a("li"),Uge=a("strong"),uor=o("funnel"),bor=o(" \u2014 "),_O=a("a"),vor=o("TFFunnelForPreTraining"),Tor=o(" (Funnel Transformer model)"),For=l(),c0=a("li"),Jge=a("strong"),Cor=o("gpt2"),Mor=o(" \u2014 "),uO=a("a"),Eor=o("TFGPT2LMHeadModel"),yor=o(" (OpenAI GPT-2 model)"),wor=l(),f0=a("li"),Yge=a("strong"),Aor=o("layoutlm"),Lor=o(" \u2014 "),bO=a("a"),Bor=o("TFLayoutLMForMaskedLM"),xor=o(" (LayoutLM model)"),kor=l(),m0=a("li"),Kge=a("strong"),Ror=o("lxmert"),Sor=o(" \u2014 "),vO=a("a"),Por=o("TFLxmertForPreTraining"),$or=o(" (LXMERT model)"),Ior=l(),g0=a("li"),Zge=a("strong"),jor=o("mobilebert"),Dor=o(" \u2014 "),TO=a("a"),Nor=o("TFMobileBertForPreTraining"),qor=o(" (MobileBERT model)"),Oor=l(),h0=a("li"),ehe=a("strong"),Gor=o("mpnet"),Xor=o(" \u2014 "),FO=a("a"),Vor=o("TFMPNetForMaskedLM"),zor=o(" (MPNet model)"),Wor=l(),p0=a("li"),ohe=a("strong"),Qor=o("openai-gpt"),Hor=o(" \u2014 "),CO=a("a"),Uor=o("TFOpenAIGPTLMHeadModel"),Jor=o(" (OpenAI GPT model)"),Yor=l(),_0=a("li"),rhe=a("strong"),Kor=o("roberta"),Zor=o(" \u2014 "),MO=a("a"),err=o("TFRobertaForMaskedLM"),orr=o(" (RoBERTa model)"),rrr=l(),u0=a("li"),the=a("strong"),trr=o("t5"),arr=o(" \u2014 "),EO=a("a"),nrr=o("TFT5ForConditionalGeneration"),srr=o(" (T5 model)"),lrr=l(),b0=a("li"),ahe=a("strong"),irr=o("tapas"),drr=o(" \u2014 "),yO=a("a"),crr=o("TFTapasForMaskedLM"),frr=o(" (TAPAS model)"),mrr=l(),v0=a("li"),nhe=a("strong"),grr=o("transfo-xl"),hrr=o(" \u2014 "),wO=a("a"),prr=o("TFTransfoXLLMHeadModel"),_rr=o(" (Transformer-XL model)"),urr=l(),T0=a("li"),she=a("strong"),brr=o("xlm"),vrr=o(" \u2014 "),AO=a("a"),Trr=o("TFXLMWithLMHeadModel"),Frr=o(" (XLM model)"),Crr=l(),F0=a("li"),lhe=a("strong"),Mrr=o("xlm-roberta"),Err=o(" \u2014 "),LO=a("a"),yrr=o("TFXLMRobertaForMaskedLM"),wrr=o(" (XLM-RoBERTa model)"),Arr=l(),C0=a("li"),ihe=a("strong"),Lrr=o("xlnet"),Brr=o(" \u2014 "),BO=a("a"),xrr=o("TFXLNetLMHeadModel"),krr=o(" (XLNet model)"),Rrr=l(),dhe=a("p"),Srr=o("Examples:"),Prr=l(),f(ew.$$.fragment),oRe=l(),wc=a("h2"),M0=a("a"),che=a("span"),f(ow.$$.fragment),$rr=l(),fhe=a("span"),Irr=o("TFAutoModelForCausalLM"),rRe=l(),Cr=a("div"),f(rw.$$.fragment),jrr=l(),Ac=a("p"),Drr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),mhe=a("code"),Nrr=o("from_pretrained()"),qrr=o("class method or the "),ghe=a("code"),Orr=o("from_config()"),Grr=o(`class
method.`),Xrr=l(),tw=a("p"),Vrr=o("This class cannot be instantiated directly using "),hhe=a("code"),zrr=o("__init__()"),Wrr=o(" (throws an error)."),Qrr=l(),ut=a("div"),f(aw.$$.fragment),Hrr=l(),phe=a("p"),Urr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Jrr=l(),Lc=a("p"),Yrr=o(`Note:
Loading a model from its configuration file does `),_he=a("strong"),Krr=o("not"),Zrr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uhe=a("code"),etr=o("from_pretrained()"),otr=o("to load the model weights."),rtr=l(),bhe=a("p"),ttr=o("Examples:"),atr=l(),f(nw.$$.fragment),ntr=l(),_o=a("div"),f(sw.$$.fragment),str=l(),vhe=a("p"),ltr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),itr=l(),Cn=a("p"),dtr=o("The model class to instantiate is selected based on the "),The=a("code"),ctr=o("model_type"),ftr=o(` property of the config object (either
passed as an argument or loaded from `),Fhe=a("code"),mtr=o("pretrained_model_name_or_path"),gtr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Che=a("code"),htr=o("pretrained_model_name_or_path"),ptr=o(":"),_tr=l(),me=a("ul"),E0=a("li"),Mhe=a("strong"),utr=o("bert"),btr=o(" \u2014 "),xO=a("a"),vtr=o("TFBertLMHeadModel"),Ttr=o(" (BERT model)"),Ftr=l(),y0=a("li"),Ehe=a("strong"),Ctr=o("camembert"),Mtr=o(" \u2014 "),kO=a("a"),Etr=o("TFCamembertForCausalLM"),ytr=o(" (CamemBERT model)"),wtr=l(),w0=a("li"),yhe=a("strong"),Atr=o("ctrl"),Ltr=o(" \u2014 "),RO=a("a"),Btr=o("TFCTRLLMHeadModel"),xtr=o(" (CTRL model)"),ktr=l(),A0=a("li"),whe=a("strong"),Rtr=o("gpt2"),Str=o(" \u2014 "),SO=a("a"),Ptr=o("TFGPT2LMHeadModel"),$tr=o(" (OpenAI GPT-2 model)"),Itr=l(),L0=a("li"),Ahe=a("strong"),jtr=o("openai-gpt"),Dtr=o(" \u2014 "),PO=a("a"),Ntr=o("TFOpenAIGPTLMHeadModel"),qtr=o(" (OpenAI GPT model)"),Otr=l(),B0=a("li"),Lhe=a("strong"),Gtr=o("rembert"),Xtr=o(" \u2014 "),$O=a("a"),Vtr=o("TFRemBertForCausalLM"),ztr=o(" (RemBERT model)"),Wtr=l(),x0=a("li"),Bhe=a("strong"),Qtr=o("roberta"),Htr=o(" \u2014 "),IO=a("a"),Utr=o("TFRobertaForCausalLM"),Jtr=o(" (RoBERTa model)"),Ytr=l(),k0=a("li"),xhe=a("strong"),Ktr=o("roformer"),Ztr=o(" \u2014 "),jO=a("a"),ear=o("TFRoFormerForCausalLM"),oar=o(" (RoFormer model)"),rar=l(),R0=a("li"),khe=a("strong"),tar=o("transfo-xl"),aar=o(" \u2014 "),DO=a("a"),nar=o("TFTransfoXLLMHeadModel"),sar=o(" (Transformer-XL model)"),lar=l(),S0=a("li"),Rhe=a("strong"),iar=o("xlm"),dar=o(" \u2014 "),NO=a("a"),car=o("TFXLMWithLMHeadModel"),far=o(" (XLM model)"),mar=l(),P0=a("li"),She=a("strong"),gar=o("xlnet"),har=o(" \u2014 "),qO=a("a"),par=o("TFXLNetLMHeadModel"),_ar=o(" (XLNet model)"),uar=l(),Phe=a("p"),bar=o("Examples:"),Tar=l(),f(lw.$$.fragment),tRe=l(),Bc=a("h2"),$0=a("a"),$he=a("span"),f(iw.$$.fragment),Far=l(),Ihe=a("span"),Car=o("TFAutoModelForImageClassification"),aRe=l(),Mr=a("div"),f(dw.$$.fragment),Mar=l(),xc=a("p"),Ear=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),jhe=a("code"),yar=o("from_pretrained()"),war=o("class method or the "),Dhe=a("code"),Aar=o("from_config()"),Lar=o(`class
method.`),Bar=l(),cw=a("p"),xar=o("This class cannot be instantiated directly using "),Nhe=a("code"),kar=o("__init__()"),Rar=o(" (throws an error)."),Sar=l(),bt=a("div"),f(fw.$$.fragment),Par=l(),qhe=a("p"),$ar=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Iar=l(),kc=a("p"),jar=o(`Note:
Loading a model from its configuration file does `),Ohe=a("strong"),Dar=o("not"),Nar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ghe=a("code"),qar=o("from_pretrained()"),Oar=o("to load the model weights."),Gar=l(),Xhe=a("p"),Xar=o("Examples:"),Var=l(),f(mw.$$.fragment),zar=l(),uo=a("div"),f(gw.$$.fragment),War=l(),Vhe=a("p"),Qar=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Har=l(),Mn=a("p"),Uar=o("The model class to instantiate is selected based on the "),zhe=a("code"),Jar=o("model_type"),Yar=o(` property of the config object (either
passed as an argument or loaded from `),Whe=a("code"),Kar=o("pretrained_model_name_or_path"),Zar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qhe=a("code"),enr=o("pretrained_model_name_or_path"),onr=o(":"),rnr=l(),hw=a("ul"),I0=a("li"),Hhe=a("strong"),tnr=o("convnext"),anr=o(" \u2014 "),OO=a("a"),nnr=o("TFConvNextForImageClassification"),snr=o(" (ConvNext model)"),lnr=l(),j0=a("li"),Uhe=a("strong"),inr=o("vit"),dnr=o(" \u2014 "),GO=a("a"),cnr=o("TFViTForImageClassification"),fnr=o(" (ViT model)"),mnr=l(),Jhe=a("p"),gnr=o("Examples:"),hnr=l(),f(pw.$$.fragment),nRe=l(),Rc=a("h2"),D0=a("a"),Yhe=a("span"),f(_w.$$.fragment),pnr=l(),Khe=a("span"),_nr=o("TFAutoModelForMaskedLM"),sRe=l(),Er=a("div"),f(uw.$$.fragment),unr=l(),Sc=a("p"),bnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Zhe=a("code"),vnr=o("from_pretrained()"),Tnr=o("class method or the "),epe=a("code"),Fnr=o("from_config()"),Cnr=o(`class
method.`),Mnr=l(),bw=a("p"),Enr=o("This class cannot be instantiated directly using "),ope=a("code"),ynr=o("__init__()"),wnr=o(" (throws an error)."),Anr=l(),vt=a("div"),f(vw.$$.fragment),Lnr=l(),rpe=a("p"),Bnr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),xnr=l(),Pc=a("p"),knr=o(`Note:
Loading a model from its configuration file does `),tpe=a("strong"),Rnr=o("not"),Snr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ape=a("code"),Pnr=o("from_pretrained()"),$nr=o("to load the model weights."),Inr=l(),npe=a("p"),jnr=o("Examples:"),Dnr=l(),f(Tw.$$.fragment),Nnr=l(),bo=a("div"),f(Fw.$$.fragment),qnr=l(),spe=a("p"),Onr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Gnr=l(),En=a("p"),Xnr=o("The model class to instantiate is selected based on the "),lpe=a("code"),Vnr=o("model_type"),znr=o(` property of the config object (either
passed as an argument or loaded from `),ipe=a("code"),Wnr=o("pretrained_model_name_or_path"),Qnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dpe=a("code"),Hnr=o("pretrained_model_name_or_path"),Unr=o(":"),Jnr=l(),Y=a("ul"),N0=a("li"),cpe=a("strong"),Ynr=o("albert"),Knr=o(" \u2014 "),XO=a("a"),Znr=o("TFAlbertForMaskedLM"),esr=o(" (ALBERT model)"),osr=l(),q0=a("li"),fpe=a("strong"),rsr=o("bert"),tsr=o(" \u2014 "),VO=a("a"),asr=o("TFBertForMaskedLM"),nsr=o(" (BERT model)"),ssr=l(),O0=a("li"),mpe=a("strong"),lsr=o("camembert"),isr=o(" \u2014 "),zO=a("a"),dsr=o("TFCamembertForMaskedLM"),csr=o(" (CamemBERT model)"),fsr=l(),G0=a("li"),gpe=a("strong"),msr=o("convbert"),gsr=o(" \u2014 "),WO=a("a"),hsr=o("TFConvBertForMaskedLM"),psr=o(" (ConvBERT model)"),_sr=l(),X0=a("li"),hpe=a("strong"),usr=o("deberta"),bsr=o(" \u2014 "),QO=a("a"),vsr=o("TFDebertaForMaskedLM"),Tsr=o(" (DeBERTa model)"),Fsr=l(),V0=a("li"),ppe=a("strong"),Csr=o("deberta-v2"),Msr=o(" \u2014 "),HO=a("a"),Esr=o("TFDebertaV2ForMaskedLM"),ysr=o(" (DeBERTa-v2 model)"),wsr=l(),z0=a("li"),_pe=a("strong"),Asr=o("distilbert"),Lsr=o(" \u2014 "),UO=a("a"),Bsr=o("TFDistilBertForMaskedLM"),xsr=o(" (DistilBERT model)"),ksr=l(),W0=a("li"),upe=a("strong"),Rsr=o("electra"),Ssr=o(" \u2014 "),JO=a("a"),Psr=o("TFElectraForMaskedLM"),$sr=o(" (ELECTRA model)"),Isr=l(),Q0=a("li"),bpe=a("strong"),jsr=o("flaubert"),Dsr=o(" \u2014 "),YO=a("a"),Nsr=o("TFFlaubertWithLMHeadModel"),qsr=o(" (FlauBERT model)"),Osr=l(),H0=a("li"),vpe=a("strong"),Gsr=o("funnel"),Xsr=o(" \u2014 "),KO=a("a"),Vsr=o("TFFunnelForMaskedLM"),zsr=o(" (Funnel Transformer model)"),Wsr=l(),U0=a("li"),Tpe=a("strong"),Qsr=o("layoutlm"),Hsr=o(" \u2014 "),ZO=a("a"),Usr=o("TFLayoutLMForMaskedLM"),Jsr=o(" (LayoutLM model)"),Ysr=l(),J0=a("li"),Fpe=a("strong"),Ksr=o("longformer"),Zsr=o(" \u2014 "),eG=a("a"),elr=o("TFLongformerForMaskedLM"),olr=o(" (Longformer model)"),rlr=l(),Y0=a("li"),Cpe=a("strong"),tlr=o("mobilebert"),alr=o(" \u2014 "),oG=a("a"),nlr=o("TFMobileBertForMaskedLM"),slr=o(" (MobileBERT model)"),llr=l(),K0=a("li"),Mpe=a("strong"),ilr=o("mpnet"),dlr=o(" \u2014 "),rG=a("a"),clr=o("TFMPNetForMaskedLM"),flr=o(" (MPNet model)"),mlr=l(),Z0=a("li"),Epe=a("strong"),glr=o("rembert"),hlr=o(" \u2014 "),tG=a("a"),plr=o("TFRemBertForMaskedLM"),_lr=o(" (RemBERT model)"),ulr=l(),eT=a("li"),ype=a("strong"),blr=o("roberta"),vlr=o(" \u2014 "),aG=a("a"),Tlr=o("TFRobertaForMaskedLM"),Flr=o(" (RoBERTa model)"),Clr=l(),oT=a("li"),wpe=a("strong"),Mlr=o("roformer"),Elr=o(" \u2014 "),nG=a("a"),ylr=o("TFRoFormerForMaskedLM"),wlr=o(" (RoFormer model)"),Alr=l(),rT=a("li"),Ape=a("strong"),Llr=o("tapas"),Blr=o(" \u2014 "),sG=a("a"),xlr=o("TFTapasForMaskedLM"),klr=o(" (TAPAS model)"),Rlr=l(),tT=a("li"),Lpe=a("strong"),Slr=o("xlm"),Plr=o(" \u2014 "),lG=a("a"),$lr=o("TFXLMWithLMHeadModel"),Ilr=o(" (XLM model)"),jlr=l(),aT=a("li"),Bpe=a("strong"),Dlr=o("xlm-roberta"),Nlr=o(" \u2014 "),iG=a("a"),qlr=o("TFXLMRobertaForMaskedLM"),Olr=o(" (XLM-RoBERTa model)"),Glr=l(),xpe=a("p"),Xlr=o("Examples:"),Vlr=l(),f(Cw.$$.fragment),lRe=l(),$c=a("h2"),nT=a("a"),kpe=a("span"),f(Mw.$$.fragment),zlr=l(),Rpe=a("span"),Wlr=o("TFAutoModelForSeq2SeqLM"),iRe=l(),yr=a("div"),f(Ew.$$.fragment),Qlr=l(),Ic=a("p"),Hlr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Spe=a("code"),Ulr=o("from_pretrained()"),Jlr=o("class method or the "),Ppe=a("code"),Ylr=o("from_config()"),Klr=o(`class
method.`),Zlr=l(),yw=a("p"),eir=o("This class cannot be instantiated directly using "),$pe=a("code"),oir=o("__init__()"),rir=o(" (throws an error)."),tir=l(),Tt=a("div"),f(ww.$$.fragment),air=l(),Ipe=a("p"),nir=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),sir=l(),jc=a("p"),lir=o(`Note:
Loading a model from its configuration file does `),jpe=a("strong"),iir=o("not"),dir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dpe=a("code"),cir=o("from_pretrained()"),fir=o("to load the model weights."),mir=l(),Npe=a("p"),gir=o("Examples:"),hir=l(),f(Aw.$$.fragment),pir=l(),vo=a("div"),f(Lw.$$.fragment),_ir=l(),qpe=a("p"),uir=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),bir=l(),yn=a("p"),vir=o("The model class to instantiate is selected based on the "),Ope=a("code"),Tir=o("model_type"),Fir=o(` property of the config object (either
passed as an argument or loaded from `),Gpe=a("code"),Cir=o("pretrained_model_name_or_path"),Mir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xpe=a("code"),Eir=o("pretrained_model_name_or_path"),yir=o(":"),wir=l(),_e=a("ul"),sT=a("li"),Vpe=a("strong"),Air=o("bart"),Lir=o(" \u2014 "),dG=a("a"),Bir=o("TFBartForConditionalGeneration"),xir=o(" (BART model)"),kir=l(),lT=a("li"),zpe=a("strong"),Rir=o("blenderbot"),Sir=o(" \u2014 "),cG=a("a"),Pir=o("TFBlenderbotForConditionalGeneration"),$ir=o(" (Blenderbot model)"),Iir=l(),iT=a("li"),Wpe=a("strong"),jir=o("blenderbot-small"),Dir=o(" \u2014 "),fG=a("a"),Nir=o("TFBlenderbotSmallForConditionalGeneration"),qir=o(" (BlenderbotSmall model)"),Oir=l(),dT=a("li"),Qpe=a("strong"),Gir=o("encoder-decoder"),Xir=o(" \u2014 "),mG=a("a"),Vir=o("TFEncoderDecoderModel"),zir=o(" (Encoder decoder model)"),Wir=l(),cT=a("li"),Hpe=a("strong"),Qir=o("led"),Hir=o(" \u2014 "),gG=a("a"),Uir=o("TFLEDForConditionalGeneration"),Jir=o(" (LED model)"),Yir=l(),fT=a("li"),Upe=a("strong"),Kir=o("marian"),Zir=o(" \u2014 "),hG=a("a"),edr=o("TFMarianMTModel"),odr=o(" (Marian model)"),rdr=l(),mT=a("li"),Jpe=a("strong"),tdr=o("mbart"),adr=o(" \u2014 "),pG=a("a"),ndr=o("TFMBartForConditionalGeneration"),sdr=o(" (mBART model)"),ldr=l(),gT=a("li"),Ype=a("strong"),idr=o("mt5"),ddr=o(" \u2014 "),_G=a("a"),cdr=o("TFMT5ForConditionalGeneration"),fdr=o(" (mT5 model)"),mdr=l(),hT=a("li"),Kpe=a("strong"),gdr=o("pegasus"),hdr=o(" \u2014 "),uG=a("a"),pdr=o("TFPegasusForConditionalGeneration"),_dr=o(" (Pegasus model)"),udr=l(),pT=a("li"),Zpe=a("strong"),bdr=o("t5"),vdr=o(" \u2014 "),bG=a("a"),Tdr=o("TFT5ForConditionalGeneration"),Fdr=o(" (T5 model)"),Cdr=l(),e_e=a("p"),Mdr=o("Examples:"),Edr=l(),f(Bw.$$.fragment),dRe=l(),Dc=a("h2"),_T=a("a"),o_e=a("span"),f(xw.$$.fragment),ydr=l(),r_e=a("span"),wdr=o("TFAutoModelForSequenceClassification"),cRe=l(),wr=a("div"),f(kw.$$.fragment),Adr=l(),Nc=a("p"),Ldr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),t_e=a("code"),Bdr=o("from_pretrained()"),xdr=o("class method or the "),a_e=a("code"),kdr=o("from_config()"),Rdr=o(`class
method.`),Sdr=l(),Rw=a("p"),Pdr=o("This class cannot be instantiated directly using "),n_e=a("code"),$dr=o("__init__()"),Idr=o(" (throws an error)."),jdr=l(),Ft=a("div"),f(Sw.$$.fragment),Ddr=l(),s_e=a("p"),Ndr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),qdr=l(),qc=a("p"),Odr=o(`Note:
Loading a model from its configuration file does `),l_e=a("strong"),Gdr=o("not"),Xdr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),i_e=a("code"),Vdr=o("from_pretrained()"),zdr=o("to load the model weights."),Wdr=l(),d_e=a("p"),Qdr=o("Examples:"),Hdr=l(),f(Pw.$$.fragment),Udr=l(),To=a("div"),f($w.$$.fragment),Jdr=l(),c_e=a("p"),Ydr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Kdr=l(),wn=a("p"),Zdr=o("The model class to instantiate is selected based on the "),f_e=a("code"),ecr=o("model_type"),ocr=o(` property of the config object (either
passed as an argument or loaded from `),m_e=a("code"),rcr=o("pretrained_model_name_or_path"),tcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g_e=a("code"),acr=o("pretrained_model_name_or_path"),ncr=o(":"),scr=l(),V=a("ul"),uT=a("li"),h_e=a("strong"),lcr=o("albert"),icr=o(" \u2014 "),vG=a("a"),dcr=o("TFAlbertForSequenceClassification"),ccr=o(" (ALBERT model)"),fcr=l(),bT=a("li"),p_e=a("strong"),mcr=o("bert"),gcr=o(" \u2014 "),TG=a("a"),hcr=o("TFBertForSequenceClassification"),pcr=o(" (BERT model)"),_cr=l(),vT=a("li"),__e=a("strong"),ucr=o("camembert"),bcr=o(" \u2014 "),FG=a("a"),vcr=o("TFCamembertForSequenceClassification"),Tcr=o(" (CamemBERT model)"),Fcr=l(),TT=a("li"),u_e=a("strong"),Ccr=o("convbert"),Mcr=o(" \u2014 "),CG=a("a"),Ecr=o("TFConvBertForSequenceClassification"),ycr=o(" (ConvBERT model)"),wcr=l(),FT=a("li"),b_e=a("strong"),Acr=o("ctrl"),Lcr=o(" \u2014 "),MG=a("a"),Bcr=o("TFCTRLForSequenceClassification"),xcr=o(" (CTRL model)"),kcr=l(),CT=a("li"),v_e=a("strong"),Rcr=o("deberta"),Scr=o(" \u2014 "),EG=a("a"),Pcr=o("TFDebertaForSequenceClassification"),$cr=o(" (DeBERTa model)"),Icr=l(),MT=a("li"),T_e=a("strong"),jcr=o("deberta-v2"),Dcr=o(" \u2014 "),yG=a("a"),Ncr=o("TFDebertaV2ForSequenceClassification"),qcr=o(" (DeBERTa-v2 model)"),Ocr=l(),ET=a("li"),F_e=a("strong"),Gcr=o("distilbert"),Xcr=o(" \u2014 "),wG=a("a"),Vcr=o("TFDistilBertForSequenceClassification"),zcr=o(" (DistilBERT model)"),Wcr=l(),yT=a("li"),C_e=a("strong"),Qcr=o("electra"),Hcr=o(" \u2014 "),AG=a("a"),Ucr=o("TFElectraForSequenceClassification"),Jcr=o(" (ELECTRA model)"),Ycr=l(),wT=a("li"),M_e=a("strong"),Kcr=o("flaubert"),Zcr=o(" \u2014 "),LG=a("a"),efr=o("TFFlaubertForSequenceClassification"),ofr=o(" (FlauBERT model)"),rfr=l(),AT=a("li"),E_e=a("strong"),tfr=o("funnel"),afr=o(" \u2014 "),BG=a("a"),nfr=o("TFFunnelForSequenceClassification"),sfr=o(" (Funnel Transformer model)"),lfr=l(),LT=a("li"),y_e=a("strong"),ifr=o("gpt2"),dfr=o(" \u2014 "),xG=a("a"),cfr=o("TFGPT2ForSequenceClassification"),ffr=o(" (OpenAI GPT-2 model)"),mfr=l(),BT=a("li"),w_e=a("strong"),gfr=o("layoutlm"),hfr=o(" \u2014 "),kG=a("a"),pfr=o("TFLayoutLMForSequenceClassification"),_fr=o(" (LayoutLM model)"),ufr=l(),xT=a("li"),A_e=a("strong"),bfr=o("longformer"),vfr=o(" \u2014 "),RG=a("a"),Tfr=o("TFLongformerForSequenceClassification"),Ffr=o(" (Longformer model)"),Cfr=l(),kT=a("li"),L_e=a("strong"),Mfr=o("mobilebert"),Efr=o(" \u2014 "),SG=a("a"),yfr=o("TFMobileBertForSequenceClassification"),wfr=o(" (MobileBERT model)"),Afr=l(),RT=a("li"),B_e=a("strong"),Lfr=o("mpnet"),Bfr=o(" \u2014 "),PG=a("a"),xfr=o("TFMPNetForSequenceClassification"),kfr=o(" (MPNet model)"),Rfr=l(),ST=a("li"),x_e=a("strong"),Sfr=o("openai-gpt"),Pfr=o(" \u2014 "),$G=a("a"),$fr=o("TFOpenAIGPTForSequenceClassification"),Ifr=o(" (OpenAI GPT model)"),jfr=l(),PT=a("li"),k_e=a("strong"),Dfr=o("rembert"),Nfr=o(" \u2014 "),IG=a("a"),qfr=o("TFRemBertForSequenceClassification"),Ofr=o(" (RemBERT model)"),Gfr=l(),$T=a("li"),R_e=a("strong"),Xfr=o("roberta"),Vfr=o(" \u2014 "),jG=a("a"),zfr=o("TFRobertaForSequenceClassification"),Wfr=o(" (RoBERTa model)"),Qfr=l(),IT=a("li"),S_e=a("strong"),Hfr=o("roformer"),Ufr=o(" \u2014 "),DG=a("a"),Jfr=o("TFRoFormerForSequenceClassification"),Yfr=o(" (RoFormer model)"),Kfr=l(),jT=a("li"),P_e=a("strong"),Zfr=o("tapas"),emr=o(" \u2014 "),NG=a("a"),omr=o("TFTapasForSequenceClassification"),rmr=o(" (TAPAS model)"),tmr=l(),DT=a("li"),$_e=a("strong"),amr=o("transfo-xl"),nmr=o(" \u2014 "),qG=a("a"),smr=o("TFTransfoXLForSequenceClassification"),lmr=o(" (Transformer-XL model)"),imr=l(),NT=a("li"),I_e=a("strong"),dmr=o("xlm"),cmr=o(" \u2014 "),OG=a("a"),fmr=o("TFXLMForSequenceClassification"),mmr=o(" (XLM model)"),gmr=l(),qT=a("li"),j_e=a("strong"),hmr=o("xlm-roberta"),pmr=o(" \u2014 "),GG=a("a"),_mr=o("TFXLMRobertaForSequenceClassification"),umr=o(" (XLM-RoBERTa model)"),bmr=l(),OT=a("li"),D_e=a("strong"),vmr=o("xlnet"),Tmr=o(" \u2014 "),XG=a("a"),Fmr=o("TFXLNetForSequenceClassification"),Cmr=o(" (XLNet model)"),Mmr=l(),N_e=a("p"),Emr=o("Examples:"),ymr=l(),f(Iw.$$.fragment),fRe=l(),Oc=a("h2"),GT=a("a"),q_e=a("span"),f(jw.$$.fragment),wmr=l(),O_e=a("span"),Amr=o("TFAutoModelForMultipleChoice"),mRe=l(),Ar=a("div"),f(Dw.$$.fragment),Lmr=l(),Gc=a("p"),Bmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),G_e=a("code"),xmr=o("from_pretrained()"),kmr=o("class method or the "),X_e=a("code"),Rmr=o("from_config()"),Smr=o(`class
method.`),Pmr=l(),Nw=a("p"),$mr=o("This class cannot be instantiated directly using "),V_e=a("code"),Imr=o("__init__()"),jmr=o(" (throws an error)."),Dmr=l(),Ct=a("div"),f(qw.$$.fragment),Nmr=l(),z_e=a("p"),qmr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Omr=l(),Xc=a("p"),Gmr=o(`Note:
Loading a model from its configuration file does `),W_e=a("strong"),Xmr=o("not"),Vmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Q_e=a("code"),zmr=o("from_pretrained()"),Wmr=o("to load the model weights."),Qmr=l(),H_e=a("p"),Hmr=o("Examples:"),Umr=l(),f(Ow.$$.fragment),Jmr=l(),Fo=a("div"),f(Gw.$$.fragment),Ymr=l(),U_e=a("p"),Kmr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Zmr=l(),An=a("p"),egr=o("The model class to instantiate is selected based on the "),J_e=a("code"),ogr=o("model_type"),rgr=o(` property of the config object (either
passed as an argument or loaded from `),Y_e=a("code"),tgr=o("pretrained_model_name_or_path"),agr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K_e=a("code"),ngr=o("pretrained_model_name_or_path"),sgr=o(":"),lgr=l(),te=a("ul"),XT=a("li"),Z_e=a("strong"),igr=o("albert"),dgr=o(" \u2014 "),VG=a("a"),cgr=o("TFAlbertForMultipleChoice"),fgr=o(" (ALBERT model)"),mgr=l(),VT=a("li"),eue=a("strong"),ggr=o("bert"),hgr=o(" \u2014 "),zG=a("a"),pgr=o("TFBertForMultipleChoice"),_gr=o(" (BERT model)"),ugr=l(),zT=a("li"),oue=a("strong"),bgr=o("camembert"),vgr=o(" \u2014 "),WG=a("a"),Tgr=o("TFCamembertForMultipleChoice"),Fgr=o(" (CamemBERT model)"),Cgr=l(),WT=a("li"),rue=a("strong"),Mgr=o("convbert"),Egr=o(" \u2014 "),QG=a("a"),ygr=o("TFConvBertForMultipleChoice"),wgr=o(" (ConvBERT model)"),Agr=l(),QT=a("li"),tue=a("strong"),Lgr=o("distilbert"),Bgr=o(" \u2014 "),HG=a("a"),xgr=o("TFDistilBertForMultipleChoice"),kgr=o(" (DistilBERT model)"),Rgr=l(),HT=a("li"),aue=a("strong"),Sgr=o("electra"),Pgr=o(" \u2014 "),UG=a("a"),$gr=o("TFElectraForMultipleChoice"),Igr=o(" (ELECTRA model)"),jgr=l(),UT=a("li"),nue=a("strong"),Dgr=o("flaubert"),Ngr=o(" \u2014 "),JG=a("a"),qgr=o("TFFlaubertForMultipleChoice"),Ogr=o(" (FlauBERT model)"),Ggr=l(),JT=a("li"),sue=a("strong"),Xgr=o("funnel"),Vgr=o(" \u2014 "),YG=a("a"),zgr=o("TFFunnelForMultipleChoice"),Wgr=o(" (Funnel Transformer model)"),Qgr=l(),YT=a("li"),lue=a("strong"),Hgr=o("longformer"),Ugr=o(" \u2014 "),KG=a("a"),Jgr=o("TFLongformerForMultipleChoice"),Ygr=o(" (Longformer model)"),Kgr=l(),KT=a("li"),iue=a("strong"),Zgr=o("mobilebert"),ehr=o(" \u2014 "),ZG=a("a"),ohr=o("TFMobileBertForMultipleChoice"),rhr=o(" (MobileBERT model)"),thr=l(),ZT=a("li"),due=a("strong"),ahr=o("mpnet"),nhr=o(" \u2014 "),eX=a("a"),shr=o("TFMPNetForMultipleChoice"),lhr=o(" (MPNet model)"),ihr=l(),e8=a("li"),cue=a("strong"),dhr=o("rembert"),chr=o(" \u2014 "),oX=a("a"),fhr=o("TFRemBertForMultipleChoice"),mhr=o(" (RemBERT model)"),ghr=l(),o8=a("li"),fue=a("strong"),hhr=o("roberta"),phr=o(" \u2014 "),rX=a("a"),_hr=o("TFRobertaForMultipleChoice"),uhr=o(" (RoBERTa model)"),bhr=l(),r8=a("li"),mue=a("strong"),vhr=o("roformer"),Thr=o(" \u2014 "),tX=a("a"),Fhr=o("TFRoFormerForMultipleChoice"),Chr=o(" (RoFormer model)"),Mhr=l(),t8=a("li"),gue=a("strong"),Ehr=o("xlm"),yhr=o(" \u2014 "),aX=a("a"),whr=o("TFXLMForMultipleChoice"),Ahr=o(" (XLM model)"),Lhr=l(),a8=a("li"),hue=a("strong"),Bhr=o("xlm-roberta"),xhr=o(" \u2014 "),nX=a("a"),khr=o("TFXLMRobertaForMultipleChoice"),Rhr=o(" (XLM-RoBERTa model)"),Shr=l(),n8=a("li"),pue=a("strong"),Phr=o("xlnet"),$hr=o(" \u2014 "),sX=a("a"),Ihr=o("TFXLNetForMultipleChoice"),jhr=o(" (XLNet model)"),Dhr=l(),_ue=a("p"),Nhr=o("Examples:"),qhr=l(),f(Xw.$$.fragment),gRe=l(),Vc=a("h2"),s8=a("a"),uue=a("span"),f(Vw.$$.fragment),Ohr=l(),bue=a("span"),Ghr=o("TFAutoModelForTableQuestionAnswering"),hRe=l(),Lr=a("div"),f(zw.$$.fragment),Xhr=l(),zc=a("p"),Vhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),vue=a("code"),zhr=o("from_pretrained()"),Whr=o("class method or the "),Tue=a("code"),Qhr=o("from_config()"),Hhr=o(`class
method.`),Uhr=l(),Ww=a("p"),Jhr=o("This class cannot be instantiated directly using "),Fue=a("code"),Yhr=o("__init__()"),Khr=o(" (throws an error)."),Zhr=l(),Mt=a("div"),f(Qw.$$.fragment),epr=l(),Cue=a("p"),opr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),rpr=l(),Wc=a("p"),tpr=o(`Note:
Loading a model from its configuration file does `),Mue=a("strong"),apr=o("not"),npr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eue=a("code"),spr=o("from_pretrained()"),lpr=o("to load the model weights."),ipr=l(),yue=a("p"),dpr=o("Examples:"),cpr=l(),f(Hw.$$.fragment),fpr=l(),Co=a("div"),f(Uw.$$.fragment),mpr=l(),wue=a("p"),gpr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),hpr=l(),Ln=a("p"),ppr=o("The model class to instantiate is selected based on the "),Aue=a("code"),_pr=o("model_type"),upr=o(` property of the config object (either
passed as an argument or loaded from `),Lue=a("code"),bpr=o("pretrained_model_name_or_path"),vpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bue=a("code"),Tpr=o("pretrained_model_name_or_path"),Fpr=o(":"),Cpr=l(),xue=a("ul"),l8=a("li"),kue=a("strong"),Mpr=o("tapas"),Epr=o(" \u2014 "),lX=a("a"),ypr=o("TFTapasForQuestionAnswering"),wpr=o(" (TAPAS model)"),Apr=l(),Rue=a("p"),Lpr=o("Examples:"),Bpr=l(),f(Jw.$$.fragment),pRe=l(),Qc=a("h2"),i8=a("a"),Sue=a("span"),f(Yw.$$.fragment),xpr=l(),Pue=a("span"),kpr=o("TFAutoModelForTokenClassification"),_Re=l(),Br=a("div"),f(Kw.$$.fragment),Rpr=l(),Hc=a("p"),Spr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),$ue=a("code"),Ppr=o("from_pretrained()"),$pr=o("class method or the "),Iue=a("code"),Ipr=o("from_config()"),jpr=o(`class
method.`),Dpr=l(),Zw=a("p"),Npr=o("This class cannot be instantiated directly using "),jue=a("code"),qpr=o("__init__()"),Opr=o(" (throws an error)."),Gpr=l(),Et=a("div"),f(eA.$$.fragment),Xpr=l(),Due=a("p"),Vpr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),zpr=l(),Uc=a("p"),Wpr=o(`Note:
Loading a model from its configuration file does `),Nue=a("strong"),Qpr=o("not"),Hpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),que=a("code"),Upr=o("from_pretrained()"),Jpr=o("to load the model weights."),Ypr=l(),Oue=a("p"),Kpr=o("Examples:"),Zpr=l(),f(oA.$$.fragment),e_r=l(),Mo=a("div"),f(rA.$$.fragment),o_r=l(),Gue=a("p"),r_r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),t_r=l(),Bn=a("p"),a_r=o("The model class to instantiate is selected based on the "),Xue=a("code"),n_r=o("model_type"),s_r=o(` property of the config object (either
passed as an argument or loaded from `),Vue=a("code"),l_r=o("pretrained_model_name_or_path"),i_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zue=a("code"),d_r=o("pretrained_model_name_or_path"),c_r=o(":"),f_r=l(),K=a("ul"),d8=a("li"),Wue=a("strong"),m_r=o("albert"),g_r=o(" \u2014 "),iX=a("a"),h_r=o("TFAlbertForTokenClassification"),p_r=o(" (ALBERT model)"),__r=l(),c8=a("li"),Que=a("strong"),u_r=o("bert"),b_r=o(" \u2014 "),dX=a("a"),v_r=o("TFBertForTokenClassification"),T_r=o(" (BERT model)"),F_r=l(),f8=a("li"),Hue=a("strong"),C_r=o("camembert"),M_r=o(" \u2014 "),cX=a("a"),E_r=o("TFCamembertForTokenClassification"),y_r=o(" (CamemBERT model)"),w_r=l(),m8=a("li"),Uue=a("strong"),A_r=o("convbert"),L_r=o(" \u2014 "),fX=a("a"),B_r=o("TFConvBertForTokenClassification"),x_r=o(" (ConvBERT model)"),k_r=l(),g8=a("li"),Jue=a("strong"),R_r=o("deberta"),S_r=o(" \u2014 "),mX=a("a"),P_r=o("TFDebertaForTokenClassification"),$_r=o(" (DeBERTa model)"),I_r=l(),h8=a("li"),Yue=a("strong"),j_r=o("deberta-v2"),D_r=o(" \u2014 "),gX=a("a"),N_r=o("TFDebertaV2ForTokenClassification"),q_r=o(" (DeBERTa-v2 model)"),O_r=l(),p8=a("li"),Kue=a("strong"),G_r=o("distilbert"),X_r=o(" \u2014 "),hX=a("a"),V_r=o("TFDistilBertForTokenClassification"),z_r=o(" (DistilBERT model)"),W_r=l(),_8=a("li"),Zue=a("strong"),Q_r=o("electra"),H_r=o(" \u2014 "),pX=a("a"),U_r=o("TFElectraForTokenClassification"),J_r=o(" (ELECTRA model)"),Y_r=l(),u8=a("li"),e1e=a("strong"),K_r=o("flaubert"),Z_r=o(" \u2014 "),_X=a("a"),eur=o("TFFlaubertForTokenClassification"),our=o(" (FlauBERT model)"),rur=l(),b8=a("li"),o1e=a("strong"),tur=o("funnel"),aur=o(" \u2014 "),uX=a("a"),nur=o("TFFunnelForTokenClassification"),sur=o(" (Funnel Transformer model)"),lur=l(),v8=a("li"),r1e=a("strong"),iur=o("layoutlm"),dur=o(" \u2014 "),bX=a("a"),cur=o("TFLayoutLMForTokenClassification"),fur=o(" (LayoutLM model)"),mur=l(),T8=a("li"),t1e=a("strong"),gur=o("longformer"),hur=o(" \u2014 "),vX=a("a"),pur=o("TFLongformerForTokenClassification"),_ur=o(" (Longformer model)"),uur=l(),F8=a("li"),a1e=a("strong"),bur=o("mobilebert"),vur=o(" \u2014 "),TX=a("a"),Tur=o("TFMobileBertForTokenClassification"),Fur=o(" (MobileBERT model)"),Cur=l(),C8=a("li"),n1e=a("strong"),Mur=o("mpnet"),Eur=o(" \u2014 "),FX=a("a"),yur=o("TFMPNetForTokenClassification"),wur=o(" (MPNet model)"),Aur=l(),M8=a("li"),s1e=a("strong"),Lur=o("rembert"),Bur=o(" \u2014 "),CX=a("a"),xur=o("TFRemBertForTokenClassification"),kur=o(" (RemBERT model)"),Rur=l(),E8=a("li"),l1e=a("strong"),Sur=o("roberta"),Pur=o(" \u2014 "),MX=a("a"),$ur=o("TFRobertaForTokenClassification"),Iur=o(" (RoBERTa model)"),jur=l(),y8=a("li"),i1e=a("strong"),Dur=o("roformer"),Nur=o(" \u2014 "),EX=a("a"),qur=o("TFRoFormerForTokenClassification"),Our=o(" (RoFormer model)"),Gur=l(),w8=a("li"),d1e=a("strong"),Xur=o("xlm"),Vur=o(" \u2014 "),yX=a("a"),zur=o("TFXLMForTokenClassification"),Wur=o(" (XLM model)"),Qur=l(),A8=a("li"),c1e=a("strong"),Hur=o("xlm-roberta"),Uur=o(" \u2014 "),wX=a("a"),Jur=o("TFXLMRobertaForTokenClassification"),Yur=o(" (XLM-RoBERTa model)"),Kur=l(),L8=a("li"),f1e=a("strong"),Zur=o("xlnet"),e1r=o(" \u2014 "),AX=a("a"),o1r=o("TFXLNetForTokenClassification"),r1r=o(" (XLNet model)"),t1r=l(),m1e=a("p"),a1r=o("Examples:"),n1r=l(),f(tA.$$.fragment),uRe=l(),Jc=a("h2"),B8=a("a"),g1e=a("span"),f(aA.$$.fragment),s1r=l(),h1e=a("span"),l1r=o("TFAutoModelForQuestionAnswering"),bRe=l(),xr=a("div"),f(nA.$$.fragment),i1r=l(),Yc=a("p"),d1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),p1e=a("code"),c1r=o("from_pretrained()"),f1r=o("class method or the "),_1e=a("code"),m1r=o("from_config()"),g1r=o(`class
method.`),h1r=l(),sA=a("p"),p1r=o("This class cannot be instantiated directly using "),u1e=a("code"),_1r=o("__init__()"),u1r=o(" (throws an error)."),b1r=l(),yt=a("div"),f(lA.$$.fragment),v1r=l(),b1e=a("p"),T1r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),F1r=l(),Kc=a("p"),C1r=o(`Note:
Loading a model from its configuration file does `),v1e=a("strong"),M1r=o("not"),E1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),T1e=a("code"),y1r=o("from_pretrained()"),w1r=o("to load the model weights."),A1r=l(),F1e=a("p"),L1r=o("Examples:"),B1r=l(),f(iA.$$.fragment),x1r=l(),Eo=a("div"),f(dA.$$.fragment),k1r=l(),C1e=a("p"),R1r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),S1r=l(),xn=a("p"),P1r=o("The model class to instantiate is selected based on the "),M1e=a("code"),$1r=o("model_type"),I1r=o(` property of the config object (either
passed as an argument or loaded from `),E1e=a("code"),j1r=o("pretrained_model_name_or_path"),D1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y1e=a("code"),N1r=o("pretrained_model_name_or_path"),q1r=o(":"),O1r=l(),Z=a("ul"),x8=a("li"),w1e=a("strong"),G1r=o("albert"),X1r=o(" \u2014 "),LX=a("a"),V1r=o("TFAlbertForQuestionAnswering"),z1r=o(" (ALBERT model)"),W1r=l(),k8=a("li"),A1e=a("strong"),Q1r=o("bert"),H1r=o(" \u2014 "),BX=a("a"),U1r=o("TFBertForQuestionAnswering"),J1r=o(" (BERT model)"),Y1r=l(),R8=a("li"),L1e=a("strong"),K1r=o("camembert"),Z1r=o(" \u2014 "),xX=a("a"),ebr=o("TFCamembertForQuestionAnswering"),obr=o(" (CamemBERT model)"),rbr=l(),S8=a("li"),B1e=a("strong"),tbr=o("convbert"),abr=o(" \u2014 "),kX=a("a"),nbr=o("TFConvBertForQuestionAnswering"),sbr=o(" (ConvBERT model)"),lbr=l(),P8=a("li"),x1e=a("strong"),ibr=o("deberta"),dbr=o(" \u2014 "),RX=a("a"),cbr=o("TFDebertaForQuestionAnswering"),fbr=o(" (DeBERTa model)"),mbr=l(),$8=a("li"),k1e=a("strong"),gbr=o("deberta-v2"),hbr=o(" \u2014 "),SX=a("a"),pbr=o("TFDebertaV2ForQuestionAnswering"),_br=o(" (DeBERTa-v2 model)"),ubr=l(),I8=a("li"),R1e=a("strong"),bbr=o("distilbert"),vbr=o(" \u2014 "),PX=a("a"),Tbr=o("TFDistilBertForQuestionAnswering"),Fbr=o(" (DistilBERT model)"),Cbr=l(),j8=a("li"),S1e=a("strong"),Mbr=o("electra"),Ebr=o(" \u2014 "),$X=a("a"),ybr=o("TFElectraForQuestionAnswering"),wbr=o(" (ELECTRA model)"),Abr=l(),D8=a("li"),P1e=a("strong"),Lbr=o("flaubert"),Bbr=o(" \u2014 "),IX=a("a"),xbr=o("TFFlaubertForQuestionAnsweringSimple"),kbr=o(" (FlauBERT model)"),Rbr=l(),N8=a("li"),$1e=a("strong"),Sbr=o("funnel"),Pbr=o(" \u2014 "),jX=a("a"),$br=o("TFFunnelForQuestionAnswering"),Ibr=o(" (Funnel Transformer model)"),jbr=l(),q8=a("li"),I1e=a("strong"),Dbr=o("longformer"),Nbr=o(" \u2014 "),DX=a("a"),qbr=o("TFLongformerForQuestionAnswering"),Obr=o(" (Longformer model)"),Gbr=l(),O8=a("li"),j1e=a("strong"),Xbr=o("mobilebert"),Vbr=o(" \u2014 "),NX=a("a"),zbr=o("TFMobileBertForQuestionAnswering"),Wbr=o(" (MobileBERT model)"),Qbr=l(),G8=a("li"),D1e=a("strong"),Hbr=o("mpnet"),Ubr=o(" \u2014 "),qX=a("a"),Jbr=o("TFMPNetForQuestionAnswering"),Ybr=o(" (MPNet model)"),Kbr=l(),X8=a("li"),N1e=a("strong"),Zbr=o("rembert"),e5r=o(" \u2014 "),OX=a("a"),o5r=o("TFRemBertForQuestionAnswering"),r5r=o(" (RemBERT model)"),t5r=l(),V8=a("li"),q1e=a("strong"),a5r=o("roberta"),n5r=o(" \u2014 "),GX=a("a"),s5r=o("TFRobertaForQuestionAnswering"),l5r=o(" (RoBERTa model)"),i5r=l(),z8=a("li"),O1e=a("strong"),d5r=o("roformer"),c5r=o(" \u2014 "),XX=a("a"),f5r=o("TFRoFormerForQuestionAnswering"),m5r=o(" (RoFormer model)"),g5r=l(),W8=a("li"),G1e=a("strong"),h5r=o("xlm"),p5r=o(" \u2014 "),VX=a("a"),_5r=o("TFXLMForQuestionAnsweringSimple"),u5r=o(" (XLM model)"),b5r=l(),Q8=a("li"),X1e=a("strong"),v5r=o("xlm-roberta"),T5r=o(" \u2014 "),zX=a("a"),F5r=o("TFXLMRobertaForQuestionAnswering"),C5r=o(" (XLM-RoBERTa model)"),M5r=l(),H8=a("li"),V1e=a("strong"),E5r=o("xlnet"),y5r=o(" \u2014 "),WX=a("a"),w5r=o("TFXLNetForQuestionAnsweringSimple"),A5r=o(" (XLNet model)"),L5r=l(),z1e=a("p"),B5r=o("Examples:"),x5r=l(),f(cA.$$.fragment),vRe=l(),Zc=a("h2"),U8=a("a"),W1e=a("span"),f(fA.$$.fragment),k5r=l(),Q1e=a("span"),R5r=o("TFAutoModelForVision2Seq"),TRe=l(),kr=a("div"),f(mA.$$.fragment),S5r=l(),ef=a("p"),P5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),H1e=a("code"),$5r=o("from_pretrained()"),I5r=o("class method or the "),U1e=a("code"),j5r=o("from_config()"),D5r=o(`class
method.`),N5r=l(),gA=a("p"),q5r=o("This class cannot be instantiated directly using "),J1e=a("code"),O5r=o("__init__()"),G5r=o(" (throws an error)."),X5r=l(),wt=a("div"),f(hA.$$.fragment),V5r=l(),Y1e=a("p"),z5r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),W5r=l(),of=a("p"),Q5r=o(`Note:
Loading a model from its configuration file does `),K1e=a("strong"),H5r=o("not"),U5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Z1e=a("code"),J5r=o("from_pretrained()"),Y5r=o("to load the model weights."),K5r=l(),ebe=a("p"),Z5r=o("Examples:"),e2r=l(),f(pA.$$.fragment),o2r=l(),yo=a("div"),f(_A.$$.fragment),r2r=l(),obe=a("p"),t2r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),a2r=l(),kn=a("p"),n2r=o("The model class to instantiate is selected based on the "),rbe=a("code"),s2r=o("model_type"),l2r=o(` property of the config object (either
passed as an argument or loaded from `),tbe=a("code"),i2r=o("pretrained_model_name_or_path"),d2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),abe=a("code"),c2r=o("pretrained_model_name_or_path"),f2r=o(":"),m2r=l(),nbe=a("ul"),J8=a("li"),sbe=a("strong"),g2r=o("vision-encoder-decoder"),h2r=o(" \u2014 "),QX=a("a"),p2r=o("TFVisionEncoderDecoderModel"),_2r=o(" (Vision Encoder decoder model)"),u2r=l(),lbe=a("p"),b2r=o("Examples:"),v2r=l(),f(uA.$$.fragment),FRe=l(),rf=a("h2"),Y8=a("a"),ibe=a("span"),f(bA.$$.fragment),T2r=l(),dbe=a("span"),F2r=o("TFAutoModelForSpeechSeq2Seq"),CRe=l(),Rr=a("div"),f(vA.$$.fragment),C2r=l(),tf=a("p"),M2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),cbe=a("code"),E2r=o("from_pretrained()"),y2r=o("class method or the "),fbe=a("code"),w2r=o("from_config()"),A2r=o(`class
method.`),L2r=l(),TA=a("p"),B2r=o("This class cannot be instantiated directly using "),mbe=a("code"),x2r=o("__init__()"),k2r=o(" (throws an error)."),R2r=l(),At=a("div"),f(FA.$$.fragment),S2r=l(),gbe=a("p"),P2r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),$2r=l(),af=a("p"),I2r=o(`Note:
Loading a model from its configuration file does `),hbe=a("strong"),j2r=o("not"),D2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pbe=a("code"),N2r=o("from_pretrained()"),q2r=o("to load the model weights."),O2r=l(),_be=a("p"),G2r=o("Examples:"),X2r=l(),f(CA.$$.fragment),V2r=l(),wo=a("div"),f(MA.$$.fragment),z2r=l(),ube=a("p"),W2r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Q2r=l(),Rn=a("p"),H2r=o("The model class to instantiate is selected based on the "),bbe=a("code"),U2r=o("model_type"),J2r=o(` property of the config object (either
passed as an argument or loaded from `),vbe=a("code"),Y2r=o("pretrained_model_name_or_path"),K2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tbe=a("code"),Z2r=o("pretrained_model_name_or_path"),evr=o(":"),ovr=l(),Fbe=a("ul"),K8=a("li"),Cbe=a("strong"),rvr=o("speech_to_text"),tvr=o(" \u2014 "),HX=a("a"),avr=o("TFSpeech2TextForConditionalGeneration"),nvr=o(" (Speech2Text model)"),svr=l(),Mbe=a("p"),lvr=o("Examples:"),ivr=l(),f(EA.$$.fragment),MRe=l(),nf=a("h2"),Z8=a("a"),Ebe=a("span"),f(yA.$$.fragment),dvr=l(),ybe=a("span"),cvr=o("FlaxAutoModel"),ERe=l(),Sr=a("div"),f(wA.$$.fragment),fvr=l(),sf=a("p"),mvr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),wbe=a("code"),gvr=o("from_pretrained()"),hvr=o("class method or the "),Abe=a("code"),pvr=o("from_config()"),_vr=o(`class
method.`),uvr=l(),AA=a("p"),bvr=o("This class cannot be instantiated directly using "),Lbe=a("code"),vvr=o("__init__()"),Tvr=o(" (throws an error)."),Fvr=l(),Lt=a("div"),f(LA.$$.fragment),Cvr=l(),Bbe=a("p"),Mvr=o("Instantiates one of the base model classes of the library from a configuration."),Evr=l(),lf=a("p"),yvr=o(`Note:
Loading a model from its configuration file does `),xbe=a("strong"),wvr=o("not"),Avr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kbe=a("code"),Lvr=o("from_pretrained()"),Bvr=o("to load the model weights."),xvr=l(),Rbe=a("p"),kvr=o("Examples:"),Rvr=l(),f(BA.$$.fragment),Svr=l(),Ao=a("div"),f(xA.$$.fragment),Pvr=l(),Sbe=a("p"),$vr=o("Instantiate one of the base model classes of the library from a pretrained model."),Ivr=l(),Sn=a("p"),jvr=o("The model class to instantiate is selected based on the "),Pbe=a("code"),Dvr=o("model_type"),Nvr=o(` property of the config object (either
passed as an argument or loaded from `),$be=a("code"),qvr=o("pretrained_model_name_or_path"),Ovr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ibe=a("code"),Gvr=o("pretrained_model_name_or_path"),Xvr=o(":"),Vvr=l(),z=a("ul"),eF=a("li"),jbe=a("strong"),zvr=o("albert"),Wvr=o(" \u2014 "),UX=a("a"),Qvr=o("FlaxAlbertModel"),Hvr=o(" (ALBERT model)"),Uvr=l(),oF=a("li"),Dbe=a("strong"),Jvr=o("bart"),Yvr=o(" \u2014 "),JX=a("a"),Kvr=o("FlaxBartModel"),Zvr=o(" (BART model)"),e6r=l(),rF=a("li"),Nbe=a("strong"),o6r=o("beit"),r6r=o(" \u2014 "),YX=a("a"),t6r=o("FlaxBeitModel"),a6r=o(" (BEiT model)"),n6r=l(),tF=a("li"),qbe=a("strong"),s6r=o("bert"),l6r=o(" \u2014 "),KX=a("a"),i6r=o("FlaxBertModel"),d6r=o(" (BERT model)"),c6r=l(),aF=a("li"),Obe=a("strong"),f6r=o("big_bird"),m6r=o(" \u2014 "),ZX=a("a"),g6r=o("FlaxBigBirdModel"),h6r=o(" (BigBird model)"),p6r=l(),nF=a("li"),Gbe=a("strong"),_6r=o("blenderbot"),u6r=o(" \u2014 "),eV=a("a"),b6r=o("FlaxBlenderbotModel"),v6r=o(" (Blenderbot model)"),T6r=l(),sF=a("li"),Xbe=a("strong"),F6r=o("blenderbot-small"),C6r=o(" \u2014 "),oV=a("a"),M6r=o("FlaxBlenderbotSmallModel"),E6r=o(" (BlenderbotSmall model)"),y6r=l(),lF=a("li"),Vbe=a("strong"),w6r=o("clip"),A6r=o(" \u2014 "),rV=a("a"),L6r=o("FlaxCLIPModel"),B6r=o(" (CLIP model)"),x6r=l(),iF=a("li"),zbe=a("strong"),k6r=o("distilbert"),R6r=o(" \u2014 "),tV=a("a"),S6r=o("FlaxDistilBertModel"),P6r=o(" (DistilBERT model)"),$6r=l(),dF=a("li"),Wbe=a("strong"),I6r=o("electra"),j6r=o(" \u2014 "),aV=a("a"),D6r=o("FlaxElectraModel"),N6r=o(" (ELECTRA model)"),q6r=l(),cF=a("li"),Qbe=a("strong"),O6r=o("gpt2"),G6r=o(" \u2014 "),nV=a("a"),X6r=o("FlaxGPT2Model"),V6r=o(" (OpenAI GPT-2 model)"),z6r=l(),fF=a("li"),Hbe=a("strong"),W6r=o("gpt_neo"),Q6r=o(" \u2014 "),sV=a("a"),H6r=o("FlaxGPTNeoModel"),U6r=o(" (GPT Neo model)"),J6r=l(),mF=a("li"),Ube=a("strong"),Y6r=o("gptj"),K6r=o(" \u2014 "),lV=a("a"),Z6r=o("FlaxGPTJModel"),e0r=o(" (GPT-J model)"),o0r=l(),gF=a("li"),Jbe=a("strong"),r0r=o("marian"),t0r=o(" \u2014 "),iV=a("a"),a0r=o("FlaxMarianModel"),n0r=o(" (Marian model)"),s0r=l(),hF=a("li"),Ybe=a("strong"),l0r=o("mbart"),i0r=o(" \u2014 "),dV=a("a"),d0r=o("FlaxMBartModel"),c0r=o(" (mBART model)"),f0r=l(),pF=a("li"),Kbe=a("strong"),m0r=o("mt5"),g0r=o(" \u2014 "),cV=a("a"),h0r=o("FlaxMT5Model"),p0r=o(" (mT5 model)"),_0r=l(),_F=a("li"),Zbe=a("strong"),u0r=o("pegasus"),b0r=o(" \u2014 "),fV=a("a"),v0r=o("FlaxPegasusModel"),T0r=o(" (Pegasus model)"),F0r=l(),uF=a("li"),e5e=a("strong"),C0r=o("roberta"),M0r=o(" \u2014 "),mV=a("a"),E0r=o("FlaxRobertaModel"),y0r=o(" (RoBERTa model)"),w0r=l(),bF=a("li"),o5e=a("strong"),A0r=o("roformer"),L0r=o(" \u2014 "),gV=a("a"),B0r=o("FlaxRoFormerModel"),x0r=o(" (RoFormer model)"),k0r=l(),vF=a("li"),r5e=a("strong"),R0r=o("t5"),S0r=o(" \u2014 "),hV=a("a"),P0r=o("FlaxT5Model"),$0r=o(" (T5 model)"),I0r=l(),TF=a("li"),t5e=a("strong"),j0r=o("vision-text-dual-encoder"),D0r=o(" \u2014 "),pV=a("a"),N0r=o("FlaxVisionTextDualEncoderModel"),q0r=o(" (VisionTextDualEncoder model)"),O0r=l(),FF=a("li"),a5e=a("strong"),G0r=o("vit"),X0r=o(" \u2014 "),_V=a("a"),V0r=o("FlaxViTModel"),z0r=o(" (ViT model)"),W0r=l(),CF=a("li"),n5e=a("strong"),Q0r=o("wav2vec2"),H0r=o(" \u2014 "),uV=a("a"),U0r=o("FlaxWav2Vec2Model"),J0r=o(" (Wav2Vec2 model)"),Y0r=l(),MF=a("li"),s5e=a("strong"),K0r=o("xglm"),Z0r=o(" \u2014 "),bV=a("a"),eTr=o("FlaxXGLMModel"),oTr=o(" (XGLM model)"),rTr=l(),EF=a("li"),l5e=a("strong"),tTr=o("xlm-roberta"),aTr=o(" \u2014 "),vV=a("a"),nTr=o("FlaxXLMRobertaModel"),sTr=o(" (XLM-RoBERTa model)"),lTr=l(),i5e=a("p"),iTr=o("Examples:"),dTr=l(),f(kA.$$.fragment),yRe=l(),df=a("h2"),yF=a("a"),d5e=a("span"),f(RA.$$.fragment),cTr=l(),c5e=a("span"),fTr=o("FlaxAutoModelForCausalLM"),wRe=l(),Pr=a("div"),f(SA.$$.fragment),mTr=l(),cf=a("p"),gTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),f5e=a("code"),hTr=o("from_pretrained()"),pTr=o("class method or the "),m5e=a("code"),_Tr=o("from_config()"),uTr=o(`class
method.`),bTr=l(),PA=a("p"),vTr=o("This class cannot be instantiated directly using "),g5e=a("code"),TTr=o("__init__()"),FTr=o(" (throws an error)."),CTr=l(),Bt=a("div"),f($A.$$.fragment),MTr=l(),h5e=a("p"),ETr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yTr=l(),ff=a("p"),wTr=o(`Note:
Loading a model from its configuration file does `),p5e=a("strong"),ATr=o("not"),LTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_5e=a("code"),BTr=o("from_pretrained()"),xTr=o("to load the model weights."),kTr=l(),u5e=a("p"),RTr=o("Examples:"),STr=l(),f(IA.$$.fragment),PTr=l(),Lo=a("div"),f(jA.$$.fragment),$Tr=l(),b5e=a("p"),ITr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),jTr=l(),Pn=a("p"),DTr=o("The model class to instantiate is selected based on the "),v5e=a("code"),NTr=o("model_type"),qTr=o(` property of the config object (either
passed as an argument or loaded from `),T5e=a("code"),OTr=o("pretrained_model_name_or_path"),GTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F5e=a("code"),XTr=o("pretrained_model_name_or_path"),VTr=o(":"),zTr=l(),ga=a("ul"),wF=a("li"),C5e=a("strong"),WTr=o("bart"),QTr=o(" \u2014 "),TV=a("a"),HTr=o("FlaxBartForCausalLM"),UTr=o(" (BART model)"),JTr=l(),AF=a("li"),M5e=a("strong"),YTr=o("gpt2"),KTr=o(" \u2014 "),FV=a("a"),ZTr=o("FlaxGPT2LMHeadModel"),e8r=o(" (OpenAI GPT-2 model)"),o8r=l(),LF=a("li"),E5e=a("strong"),r8r=o("gpt_neo"),t8r=o(" \u2014 "),CV=a("a"),a8r=o("FlaxGPTNeoForCausalLM"),n8r=o(" (GPT Neo model)"),s8r=l(),BF=a("li"),y5e=a("strong"),l8r=o("gptj"),i8r=o(" \u2014 "),MV=a("a"),d8r=o("FlaxGPTJForCausalLM"),c8r=o(" (GPT-J model)"),f8r=l(),xF=a("li"),w5e=a("strong"),m8r=o("xglm"),g8r=o(" \u2014 "),EV=a("a"),h8r=o("FlaxXGLMForCausalLM"),p8r=o(" (XGLM model)"),_8r=l(),A5e=a("p"),u8r=o("Examples:"),b8r=l(),f(DA.$$.fragment),ARe=l(),mf=a("h2"),kF=a("a"),L5e=a("span"),f(NA.$$.fragment),v8r=l(),B5e=a("span"),T8r=o("FlaxAutoModelForPreTraining"),LRe=l(),$r=a("div"),f(qA.$$.fragment),F8r=l(),gf=a("p"),C8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),x5e=a("code"),M8r=o("from_pretrained()"),E8r=o("class method or the "),k5e=a("code"),y8r=o("from_config()"),w8r=o(`class
method.`),A8r=l(),OA=a("p"),L8r=o("This class cannot be instantiated directly using "),R5e=a("code"),B8r=o("__init__()"),x8r=o(" (throws an error)."),k8r=l(),xt=a("div"),f(GA.$$.fragment),R8r=l(),S5e=a("p"),S8r=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),P8r=l(),hf=a("p"),$8r=o(`Note:
Loading a model from its configuration file does `),P5e=a("strong"),I8r=o("not"),j8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$5e=a("code"),D8r=o("from_pretrained()"),N8r=o("to load the model weights."),q8r=l(),I5e=a("p"),O8r=o("Examples:"),G8r=l(),f(XA.$$.fragment),X8r=l(),Bo=a("div"),f(VA.$$.fragment),V8r=l(),j5e=a("p"),z8r=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),W8r=l(),$n=a("p"),Q8r=o("The model class to instantiate is selected based on the "),D5e=a("code"),H8r=o("model_type"),U8r=o(` property of the config object (either
passed as an argument or loaded from `),N5e=a("code"),J8r=o("pretrained_model_name_or_path"),Y8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q5e=a("code"),K8r=o("pretrained_model_name_or_path"),Z8r=o(":"),eFr=l(),ce=a("ul"),RF=a("li"),O5e=a("strong"),oFr=o("albert"),rFr=o(" \u2014 "),yV=a("a"),tFr=o("FlaxAlbertForPreTraining"),aFr=o(" (ALBERT model)"),nFr=l(),SF=a("li"),G5e=a("strong"),sFr=o("bart"),lFr=o(" \u2014 "),wV=a("a"),iFr=o("FlaxBartForConditionalGeneration"),dFr=o(" (BART model)"),cFr=l(),PF=a("li"),X5e=a("strong"),fFr=o("bert"),mFr=o(" \u2014 "),AV=a("a"),gFr=o("FlaxBertForPreTraining"),hFr=o(" (BERT model)"),pFr=l(),$F=a("li"),V5e=a("strong"),_Fr=o("big_bird"),uFr=o(" \u2014 "),LV=a("a"),bFr=o("FlaxBigBirdForPreTraining"),vFr=o(" (BigBird model)"),TFr=l(),IF=a("li"),z5e=a("strong"),FFr=o("electra"),CFr=o(" \u2014 "),BV=a("a"),MFr=o("FlaxElectraForPreTraining"),EFr=o(" (ELECTRA model)"),yFr=l(),jF=a("li"),W5e=a("strong"),wFr=o("mbart"),AFr=o(" \u2014 "),xV=a("a"),LFr=o("FlaxMBartForConditionalGeneration"),BFr=o(" (mBART model)"),xFr=l(),DF=a("li"),Q5e=a("strong"),kFr=o("mt5"),RFr=o(" \u2014 "),kV=a("a"),SFr=o("FlaxMT5ForConditionalGeneration"),PFr=o(" (mT5 model)"),$Fr=l(),NF=a("li"),H5e=a("strong"),IFr=o("roberta"),jFr=o(" \u2014 "),RV=a("a"),DFr=o("FlaxRobertaForMaskedLM"),NFr=o(" (RoBERTa model)"),qFr=l(),qF=a("li"),U5e=a("strong"),OFr=o("roformer"),GFr=o(" \u2014 "),SV=a("a"),XFr=o("FlaxRoFormerForMaskedLM"),VFr=o(" (RoFormer model)"),zFr=l(),OF=a("li"),J5e=a("strong"),WFr=o("t5"),QFr=o(" \u2014 "),PV=a("a"),HFr=o("FlaxT5ForConditionalGeneration"),UFr=o(" (T5 model)"),JFr=l(),GF=a("li"),Y5e=a("strong"),YFr=o("wav2vec2"),KFr=o(" \u2014 "),$V=a("a"),ZFr=o("FlaxWav2Vec2ForPreTraining"),eCr=o(" (Wav2Vec2 model)"),oCr=l(),XF=a("li"),K5e=a("strong"),rCr=o("xlm-roberta"),tCr=o(" \u2014 "),IV=a("a"),aCr=o("FlaxXLMRobertaForMaskedLM"),nCr=o(" (XLM-RoBERTa model)"),sCr=l(),Z5e=a("p"),lCr=o("Examples:"),iCr=l(),f(zA.$$.fragment),BRe=l(),pf=a("h2"),VF=a("a"),e2e=a("span"),f(WA.$$.fragment),dCr=l(),o2e=a("span"),cCr=o("FlaxAutoModelForMaskedLM"),xRe=l(),Ir=a("div"),f(QA.$$.fragment),fCr=l(),_f=a("p"),mCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),r2e=a("code"),gCr=o("from_pretrained()"),hCr=o("class method or the "),t2e=a("code"),pCr=o("from_config()"),_Cr=o(`class
method.`),uCr=l(),HA=a("p"),bCr=o("This class cannot be instantiated directly using "),a2e=a("code"),vCr=o("__init__()"),TCr=o(" (throws an error)."),FCr=l(),kt=a("div"),f(UA.$$.fragment),CCr=l(),n2e=a("p"),MCr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),ECr=l(),uf=a("p"),yCr=o(`Note:
Loading a model from its configuration file does `),s2e=a("strong"),wCr=o("not"),ACr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),l2e=a("code"),LCr=o("from_pretrained()"),BCr=o("to load the model weights."),xCr=l(),i2e=a("p"),kCr=o("Examples:"),RCr=l(),f(JA.$$.fragment),SCr=l(),xo=a("div"),f(YA.$$.fragment),PCr=l(),d2e=a("p"),$Cr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ICr=l(),In=a("p"),jCr=o("The model class to instantiate is selected based on the "),c2e=a("code"),DCr=o("model_type"),NCr=o(` property of the config object (either
passed as an argument or loaded from `),f2e=a("code"),qCr=o("pretrained_model_name_or_path"),OCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m2e=a("code"),GCr=o("pretrained_model_name_or_path"),XCr=o(":"),VCr=l(),ue=a("ul"),zF=a("li"),g2e=a("strong"),zCr=o("albert"),WCr=o(" \u2014 "),jV=a("a"),QCr=o("FlaxAlbertForMaskedLM"),HCr=o(" (ALBERT model)"),UCr=l(),WF=a("li"),h2e=a("strong"),JCr=o("bart"),YCr=o(" \u2014 "),DV=a("a"),KCr=o("FlaxBartForConditionalGeneration"),ZCr=o(" (BART model)"),eMr=l(),QF=a("li"),p2e=a("strong"),oMr=o("bert"),rMr=o(" \u2014 "),NV=a("a"),tMr=o("FlaxBertForMaskedLM"),aMr=o(" (BERT model)"),nMr=l(),HF=a("li"),_2e=a("strong"),sMr=o("big_bird"),lMr=o(" \u2014 "),qV=a("a"),iMr=o("FlaxBigBirdForMaskedLM"),dMr=o(" (BigBird model)"),cMr=l(),UF=a("li"),u2e=a("strong"),fMr=o("distilbert"),mMr=o(" \u2014 "),OV=a("a"),gMr=o("FlaxDistilBertForMaskedLM"),hMr=o(" (DistilBERT model)"),pMr=l(),JF=a("li"),b2e=a("strong"),_Mr=o("electra"),uMr=o(" \u2014 "),GV=a("a"),bMr=o("FlaxElectraForMaskedLM"),vMr=o(" (ELECTRA model)"),TMr=l(),YF=a("li"),v2e=a("strong"),FMr=o("mbart"),CMr=o(" \u2014 "),XV=a("a"),MMr=o("FlaxMBartForConditionalGeneration"),EMr=o(" (mBART model)"),yMr=l(),KF=a("li"),T2e=a("strong"),wMr=o("roberta"),AMr=o(" \u2014 "),VV=a("a"),LMr=o("FlaxRobertaForMaskedLM"),BMr=o(" (RoBERTa model)"),xMr=l(),ZF=a("li"),F2e=a("strong"),kMr=o("roformer"),RMr=o(" \u2014 "),zV=a("a"),SMr=o("FlaxRoFormerForMaskedLM"),PMr=o(" (RoFormer model)"),$Mr=l(),eC=a("li"),C2e=a("strong"),IMr=o("xlm-roberta"),jMr=o(" \u2014 "),WV=a("a"),DMr=o("FlaxXLMRobertaForMaskedLM"),NMr=o(" (XLM-RoBERTa model)"),qMr=l(),M2e=a("p"),OMr=o("Examples:"),GMr=l(),f(KA.$$.fragment),kRe=l(),bf=a("h2"),oC=a("a"),E2e=a("span"),f(ZA.$$.fragment),XMr=l(),y2e=a("span"),VMr=o("FlaxAutoModelForSeq2SeqLM"),RRe=l(),jr=a("div"),f(eL.$$.fragment),zMr=l(),vf=a("p"),WMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),w2e=a("code"),QMr=o("from_pretrained()"),HMr=o("class method or the "),A2e=a("code"),UMr=o("from_config()"),JMr=o(`class
method.`),YMr=l(),oL=a("p"),KMr=o("This class cannot be instantiated directly using "),L2e=a("code"),ZMr=o("__init__()"),e4r=o(" (throws an error)."),o4r=l(),Rt=a("div"),f(rL.$$.fragment),r4r=l(),B2e=a("p"),t4r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),a4r=l(),Tf=a("p"),n4r=o(`Note:
Loading a model from its configuration file does `),x2e=a("strong"),s4r=o("not"),l4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),k2e=a("code"),i4r=o("from_pretrained()"),d4r=o("to load the model weights."),c4r=l(),R2e=a("p"),f4r=o("Examples:"),m4r=l(),f(tL.$$.fragment),g4r=l(),ko=a("div"),f(aL.$$.fragment),h4r=l(),S2e=a("p"),p4r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),_4r=l(),jn=a("p"),u4r=o("The model class to instantiate is selected based on the "),P2e=a("code"),b4r=o("model_type"),v4r=o(` property of the config object (either
passed as an argument or loaded from `),$2e=a("code"),T4r=o("pretrained_model_name_or_path"),F4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I2e=a("code"),C4r=o("pretrained_model_name_or_path"),M4r=o(":"),E4r=l(),Me=a("ul"),rC=a("li"),j2e=a("strong"),y4r=o("bart"),w4r=o(" \u2014 "),QV=a("a"),A4r=o("FlaxBartForConditionalGeneration"),L4r=o(" (BART model)"),B4r=l(),tC=a("li"),D2e=a("strong"),x4r=o("blenderbot"),k4r=o(" \u2014 "),HV=a("a"),R4r=o("FlaxBlenderbotForConditionalGeneration"),S4r=o(" (Blenderbot model)"),P4r=l(),aC=a("li"),N2e=a("strong"),$4r=o("blenderbot-small"),I4r=o(" \u2014 "),UV=a("a"),j4r=o("FlaxBlenderbotSmallForConditionalGeneration"),D4r=o(" (BlenderbotSmall model)"),N4r=l(),nC=a("li"),q2e=a("strong"),q4r=o("encoder-decoder"),O4r=o(" \u2014 "),JV=a("a"),G4r=o("FlaxEncoderDecoderModel"),X4r=o(" (Encoder decoder model)"),V4r=l(),sC=a("li"),O2e=a("strong"),z4r=o("marian"),W4r=o(" \u2014 "),YV=a("a"),Q4r=o("FlaxMarianMTModel"),H4r=o(" (Marian model)"),U4r=l(),lC=a("li"),G2e=a("strong"),J4r=o("mbart"),Y4r=o(" \u2014 "),KV=a("a"),K4r=o("FlaxMBartForConditionalGeneration"),Z4r=o(" (mBART model)"),eEr=l(),iC=a("li"),X2e=a("strong"),oEr=o("mt5"),rEr=o(" \u2014 "),ZV=a("a"),tEr=o("FlaxMT5ForConditionalGeneration"),aEr=o(" (mT5 model)"),nEr=l(),dC=a("li"),V2e=a("strong"),sEr=o("pegasus"),lEr=o(" \u2014 "),ez=a("a"),iEr=o("FlaxPegasusForConditionalGeneration"),dEr=o(" (Pegasus model)"),cEr=l(),cC=a("li"),z2e=a("strong"),fEr=o("t5"),mEr=o(" \u2014 "),oz=a("a"),gEr=o("FlaxT5ForConditionalGeneration"),hEr=o(" (T5 model)"),pEr=l(),W2e=a("p"),_Er=o("Examples:"),uEr=l(),f(nL.$$.fragment),SRe=l(),Ff=a("h2"),fC=a("a"),Q2e=a("span"),f(sL.$$.fragment),bEr=l(),H2e=a("span"),vEr=o("FlaxAutoModelForSequenceClassification"),PRe=l(),Dr=a("div"),f(lL.$$.fragment),TEr=l(),Cf=a("p"),FEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),U2e=a("code"),CEr=o("from_pretrained()"),MEr=o("class method or the "),J2e=a("code"),EEr=o("from_config()"),yEr=o(`class
method.`),wEr=l(),iL=a("p"),AEr=o("This class cannot be instantiated directly using "),Y2e=a("code"),LEr=o("__init__()"),BEr=o(" (throws an error)."),xEr=l(),St=a("div"),f(dL.$$.fragment),kEr=l(),K2e=a("p"),REr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),SEr=l(),Mf=a("p"),PEr=o(`Note:
Loading a model from its configuration file does `),Z2e=a("strong"),$Er=o("not"),IEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eve=a("code"),jEr=o("from_pretrained()"),DEr=o("to load the model weights."),NEr=l(),ove=a("p"),qEr=o("Examples:"),OEr=l(),f(cL.$$.fragment),GEr=l(),Ro=a("div"),f(fL.$$.fragment),XEr=l(),rve=a("p"),VEr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),zEr=l(),Dn=a("p"),WEr=o("The model class to instantiate is selected based on the "),tve=a("code"),QEr=o("model_type"),HEr=o(` property of the config object (either
passed as an argument or loaded from `),ave=a("code"),UEr=o("pretrained_model_name_or_path"),JEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nve=a("code"),YEr=o("pretrained_model_name_or_path"),KEr=o(":"),ZEr=l(),be=a("ul"),mC=a("li"),sve=a("strong"),e3r=o("albert"),o3r=o(" \u2014 "),rz=a("a"),r3r=o("FlaxAlbertForSequenceClassification"),t3r=o(" (ALBERT model)"),a3r=l(),gC=a("li"),lve=a("strong"),n3r=o("bart"),s3r=o(" \u2014 "),tz=a("a"),l3r=o("FlaxBartForSequenceClassification"),i3r=o(" (BART model)"),d3r=l(),hC=a("li"),ive=a("strong"),c3r=o("bert"),f3r=o(" \u2014 "),az=a("a"),m3r=o("FlaxBertForSequenceClassification"),g3r=o(" (BERT model)"),h3r=l(),pC=a("li"),dve=a("strong"),p3r=o("big_bird"),_3r=o(" \u2014 "),nz=a("a"),u3r=o("FlaxBigBirdForSequenceClassification"),b3r=o(" (BigBird model)"),v3r=l(),_C=a("li"),cve=a("strong"),T3r=o("distilbert"),F3r=o(" \u2014 "),sz=a("a"),C3r=o("FlaxDistilBertForSequenceClassification"),M3r=o(" (DistilBERT model)"),E3r=l(),uC=a("li"),fve=a("strong"),y3r=o("electra"),w3r=o(" \u2014 "),lz=a("a"),A3r=o("FlaxElectraForSequenceClassification"),L3r=o(" (ELECTRA model)"),B3r=l(),bC=a("li"),mve=a("strong"),x3r=o("mbart"),k3r=o(" \u2014 "),iz=a("a"),R3r=o("FlaxMBartForSequenceClassification"),S3r=o(" (mBART model)"),P3r=l(),vC=a("li"),gve=a("strong"),$3r=o("roberta"),I3r=o(" \u2014 "),dz=a("a"),j3r=o("FlaxRobertaForSequenceClassification"),D3r=o(" (RoBERTa model)"),N3r=l(),TC=a("li"),hve=a("strong"),q3r=o("roformer"),O3r=o(" \u2014 "),cz=a("a"),G3r=o("FlaxRoFormerForSequenceClassification"),X3r=o(" (RoFormer model)"),V3r=l(),FC=a("li"),pve=a("strong"),z3r=o("xlm-roberta"),W3r=o(" \u2014 "),fz=a("a"),Q3r=o("FlaxXLMRobertaForSequenceClassification"),H3r=o(" (XLM-RoBERTa model)"),U3r=l(),_ve=a("p"),J3r=o("Examples:"),Y3r=l(),f(mL.$$.fragment),$Re=l(),Ef=a("h2"),CC=a("a"),uve=a("span"),f(gL.$$.fragment),K3r=l(),bve=a("span"),Z3r=o("FlaxAutoModelForSpeechSeq2Seq"),IRe=l(),Nr=a("div"),f(hL.$$.fragment),eyr=l(),yf=a("p"),oyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),vve=a("code"),ryr=o("from_pretrained()"),tyr=o("class method or the "),Tve=a("code"),ayr=o("from_config()"),nyr=o(`class
method.`),syr=l(),pL=a("p"),lyr=o("This class cannot be instantiated directly using "),Fve=a("code"),iyr=o("__init__()"),dyr=o(" (throws an error)."),cyr=l(),Pt=a("div"),f(_L.$$.fragment),fyr=l(),Cve=a("p"),myr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),gyr=l(),wf=a("p"),hyr=o(`Note:
Loading a model from its configuration file does `),Mve=a("strong"),pyr=o("not"),_yr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eve=a("code"),uyr=o("from_pretrained()"),byr=o("to load the model weights."),vyr=l(),yve=a("p"),Tyr=o("Examples:"),Fyr=l(),f(uL.$$.fragment),Cyr=l(),So=a("div"),f(bL.$$.fragment),Myr=l(),wve=a("p"),Eyr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),yyr=l(),Nn=a("p"),wyr=o("The model class to instantiate is selected based on the "),Ave=a("code"),Ayr=o("model_type"),Lyr=o(` property of the config object (either
passed as an argument or loaded from `),Lve=a("code"),Byr=o("pretrained_model_name_or_path"),xyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bve=a("code"),kyr=o("pretrained_model_name_or_path"),Ryr=o(":"),Syr=l(),xve=a("ul"),MC=a("li"),kve=a("strong"),Pyr=o("speech-encoder-decoder"),$yr=o(" \u2014 "),mz=a("a"),Iyr=o("FlaxSpeechEncoderDecoderModel"),jyr=o(" (Speech Encoder decoder model)"),Dyr=l(),Rve=a("p"),Nyr=o("Examples:"),qyr=l(),f(vL.$$.fragment),jRe=l(),Af=a("h2"),EC=a("a"),Sve=a("span"),f(TL.$$.fragment),Oyr=l(),Pve=a("span"),Gyr=o("FlaxAutoModelForQuestionAnswering"),DRe=l(),qr=a("div"),f(FL.$$.fragment),Xyr=l(),Lf=a("p"),Vyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$ve=a("code"),zyr=o("from_pretrained()"),Wyr=o("class method or the "),Ive=a("code"),Qyr=o("from_config()"),Hyr=o(`class
method.`),Uyr=l(),CL=a("p"),Jyr=o("This class cannot be instantiated directly using "),jve=a("code"),Yyr=o("__init__()"),Kyr=o(" (throws an error)."),Zyr=l(),$t=a("div"),f(ML.$$.fragment),ewr=l(),Dve=a("p"),owr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),rwr=l(),Bf=a("p"),twr=o(`Note:
Loading a model from its configuration file does `),Nve=a("strong"),awr=o("not"),nwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qve=a("code"),swr=o("from_pretrained()"),lwr=o("to load the model weights."),iwr=l(),Ove=a("p"),dwr=o("Examples:"),cwr=l(),f(EL.$$.fragment),fwr=l(),Po=a("div"),f(yL.$$.fragment),mwr=l(),Gve=a("p"),gwr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),hwr=l(),qn=a("p"),pwr=o("The model class to instantiate is selected based on the "),Xve=a("code"),_wr=o("model_type"),uwr=o(` property of the config object (either
passed as an argument or loaded from `),Vve=a("code"),bwr=o("pretrained_model_name_or_path"),vwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zve=a("code"),Twr=o("pretrained_model_name_or_path"),Fwr=o(":"),Cwr=l(),ve=a("ul"),yC=a("li"),Wve=a("strong"),Mwr=o("albert"),Ewr=o(" \u2014 "),gz=a("a"),ywr=o("FlaxAlbertForQuestionAnswering"),wwr=o(" (ALBERT model)"),Awr=l(),wC=a("li"),Qve=a("strong"),Lwr=o("bart"),Bwr=o(" \u2014 "),hz=a("a"),xwr=o("FlaxBartForQuestionAnswering"),kwr=o(" (BART model)"),Rwr=l(),AC=a("li"),Hve=a("strong"),Swr=o("bert"),Pwr=o(" \u2014 "),pz=a("a"),$wr=o("FlaxBertForQuestionAnswering"),Iwr=o(" (BERT model)"),jwr=l(),LC=a("li"),Uve=a("strong"),Dwr=o("big_bird"),Nwr=o(" \u2014 "),_z=a("a"),qwr=o("FlaxBigBirdForQuestionAnswering"),Owr=o(" (BigBird model)"),Gwr=l(),BC=a("li"),Jve=a("strong"),Xwr=o("distilbert"),Vwr=o(" \u2014 "),uz=a("a"),zwr=o("FlaxDistilBertForQuestionAnswering"),Wwr=o(" (DistilBERT model)"),Qwr=l(),xC=a("li"),Yve=a("strong"),Hwr=o("electra"),Uwr=o(" \u2014 "),bz=a("a"),Jwr=o("FlaxElectraForQuestionAnswering"),Ywr=o(" (ELECTRA model)"),Kwr=l(),kC=a("li"),Kve=a("strong"),Zwr=o("mbart"),eAr=o(" \u2014 "),vz=a("a"),oAr=o("FlaxMBartForQuestionAnswering"),rAr=o(" (mBART model)"),tAr=l(),RC=a("li"),Zve=a("strong"),aAr=o("roberta"),nAr=o(" \u2014 "),Tz=a("a"),sAr=o("FlaxRobertaForQuestionAnswering"),lAr=o(" (RoBERTa model)"),iAr=l(),SC=a("li"),e6e=a("strong"),dAr=o("roformer"),cAr=o(" \u2014 "),Fz=a("a"),fAr=o("FlaxRoFormerForQuestionAnswering"),mAr=o(" (RoFormer model)"),gAr=l(),PC=a("li"),o6e=a("strong"),hAr=o("xlm-roberta"),pAr=o(" \u2014 "),Cz=a("a"),_Ar=o("FlaxXLMRobertaForQuestionAnswering"),uAr=o(" (XLM-RoBERTa model)"),bAr=l(),r6e=a("p"),vAr=o("Examples:"),TAr=l(),f(wL.$$.fragment),NRe=l(),xf=a("h2"),$C=a("a"),t6e=a("span"),f(AL.$$.fragment),FAr=l(),a6e=a("span"),CAr=o("FlaxAutoModelForTokenClassification"),qRe=l(),Or=a("div"),f(LL.$$.fragment),MAr=l(),kf=a("p"),EAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),n6e=a("code"),yAr=o("from_pretrained()"),wAr=o("class method or the "),s6e=a("code"),AAr=o("from_config()"),LAr=o(`class
method.`),BAr=l(),BL=a("p"),xAr=o("This class cannot be instantiated directly using "),l6e=a("code"),kAr=o("__init__()"),RAr=o(" (throws an error)."),SAr=l(),It=a("div"),f(xL.$$.fragment),PAr=l(),i6e=a("p"),$Ar=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),IAr=l(),Rf=a("p"),jAr=o(`Note:
Loading a model from its configuration file does `),d6e=a("strong"),DAr=o("not"),NAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),c6e=a("code"),qAr=o("from_pretrained()"),OAr=o("to load the model weights."),GAr=l(),f6e=a("p"),XAr=o("Examples:"),VAr=l(),f(kL.$$.fragment),zAr=l(),$o=a("div"),f(RL.$$.fragment),WAr=l(),m6e=a("p"),QAr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),HAr=l(),On=a("p"),UAr=o("The model class to instantiate is selected based on the "),g6e=a("code"),JAr=o("model_type"),YAr=o(` property of the config object (either
passed as an argument or loaded from `),h6e=a("code"),KAr=o("pretrained_model_name_or_path"),ZAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p6e=a("code"),eLr=o("pretrained_model_name_or_path"),oLr=o(":"),rLr=l(),Re=a("ul"),IC=a("li"),_6e=a("strong"),tLr=o("albert"),aLr=o(" \u2014 "),Mz=a("a"),nLr=o("FlaxAlbertForTokenClassification"),sLr=o(" (ALBERT model)"),lLr=l(),jC=a("li"),u6e=a("strong"),iLr=o("bert"),dLr=o(" \u2014 "),Ez=a("a"),cLr=o("FlaxBertForTokenClassification"),fLr=o(" (BERT model)"),mLr=l(),DC=a("li"),b6e=a("strong"),gLr=o("big_bird"),hLr=o(" \u2014 "),yz=a("a"),pLr=o("FlaxBigBirdForTokenClassification"),_Lr=o(" (BigBird model)"),uLr=l(),NC=a("li"),v6e=a("strong"),bLr=o("distilbert"),vLr=o(" \u2014 "),wz=a("a"),TLr=o("FlaxDistilBertForTokenClassification"),FLr=o(" (DistilBERT model)"),CLr=l(),qC=a("li"),T6e=a("strong"),MLr=o("electra"),ELr=o(" \u2014 "),Az=a("a"),yLr=o("FlaxElectraForTokenClassification"),wLr=o(" (ELECTRA model)"),ALr=l(),OC=a("li"),F6e=a("strong"),LLr=o("roberta"),BLr=o(" \u2014 "),Lz=a("a"),xLr=o("FlaxRobertaForTokenClassification"),kLr=o(" (RoBERTa model)"),RLr=l(),GC=a("li"),C6e=a("strong"),SLr=o("roformer"),PLr=o(" \u2014 "),Bz=a("a"),$Lr=o("FlaxRoFormerForTokenClassification"),ILr=o(" (RoFormer model)"),jLr=l(),XC=a("li"),M6e=a("strong"),DLr=o("xlm-roberta"),NLr=o(" \u2014 "),xz=a("a"),qLr=o("FlaxXLMRobertaForTokenClassification"),OLr=o(" (XLM-RoBERTa model)"),GLr=l(),E6e=a("p"),XLr=o("Examples:"),VLr=l(),f(SL.$$.fragment),ORe=l(),Sf=a("h2"),VC=a("a"),y6e=a("span"),f(PL.$$.fragment),zLr=l(),w6e=a("span"),WLr=o("FlaxAutoModelForMultipleChoice"),GRe=l(),Gr=a("div"),f($L.$$.fragment),QLr=l(),Pf=a("p"),HLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),A6e=a("code"),ULr=o("from_pretrained()"),JLr=o("class method or the "),L6e=a("code"),YLr=o("from_config()"),KLr=o(`class
method.`),ZLr=l(),IL=a("p"),e7r=o("This class cannot be instantiated directly using "),B6e=a("code"),o7r=o("__init__()"),r7r=o(" (throws an error)."),t7r=l(),jt=a("div"),f(jL.$$.fragment),a7r=l(),x6e=a("p"),n7r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),s7r=l(),$f=a("p"),l7r=o(`Note:
Loading a model from its configuration file does `),k6e=a("strong"),i7r=o("not"),d7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),R6e=a("code"),c7r=o("from_pretrained()"),f7r=o("to load the model weights."),m7r=l(),S6e=a("p"),g7r=o("Examples:"),h7r=l(),f(DL.$$.fragment),p7r=l(),Io=a("div"),f(NL.$$.fragment),_7r=l(),P6e=a("p"),u7r=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),b7r=l(),Gn=a("p"),v7r=o("The model class to instantiate is selected based on the "),$6e=a("code"),T7r=o("model_type"),F7r=o(` property of the config object (either
passed as an argument or loaded from `),I6e=a("code"),C7r=o("pretrained_model_name_or_path"),M7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j6e=a("code"),E7r=o("pretrained_model_name_or_path"),y7r=o(":"),w7r=l(),Se=a("ul"),zC=a("li"),D6e=a("strong"),A7r=o("albert"),L7r=o(" \u2014 "),kz=a("a"),B7r=o("FlaxAlbertForMultipleChoice"),x7r=o(" (ALBERT model)"),k7r=l(),WC=a("li"),N6e=a("strong"),R7r=o("bert"),S7r=o(" \u2014 "),Rz=a("a"),P7r=o("FlaxBertForMultipleChoice"),$7r=o(" (BERT model)"),I7r=l(),QC=a("li"),q6e=a("strong"),j7r=o("big_bird"),D7r=o(" \u2014 "),Sz=a("a"),N7r=o("FlaxBigBirdForMultipleChoice"),q7r=o(" (BigBird model)"),O7r=l(),HC=a("li"),O6e=a("strong"),G7r=o("distilbert"),X7r=o(" \u2014 "),Pz=a("a"),V7r=o("FlaxDistilBertForMultipleChoice"),z7r=o(" (DistilBERT model)"),W7r=l(),UC=a("li"),G6e=a("strong"),Q7r=o("electra"),H7r=o(" \u2014 "),$z=a("a"),U7r=o("FlaxElectraForMultipleChoice"),J7r=o(" (ELECTRA model)"),Y7r=l(),JC=a("li"),X6e=a("strong"),K7r=o("roberta"),Z7r=o(" \u2014 "),Iz=a("a"),e9r=o("FlaxRobertaForMultipleChoice"),o9r=o(" (RoBERTa model)"),r9r=l(),YC=a("li"),V6e=a("strong"),t9r=o("roformer"),a9r=o(" \u2014 "),jz=a("a"),n9r=o("FlaxRoFormerForMultipleChoice"),s9r=o(" (RoFormer model)"),l9r=l(),KC=a("li"),z6e=a("strong"),i9r=o("xlm-roberta"),d9r=o(" \u2014 "),Dz=a("a"),c9r=o("FlaxXLMRobertaForMultipleChoice"),f9r=o(" (XLM-RoBERTa model)"),m9r=l(),W6e=a("p"),g9r=o("Examples:"),h9r=l(),f(qL.$$.fragment),XRe=l(),If=a("h2"),ZC=a("a"),Q6e=a("span"),f(OL.$$.fragment),p9r=l(),H6e=a("span"),_9r=o("FlaxAutoModelForNextSentencePrediction"),VRe=l(),Xr=a("div"),f(GL.$$.fragment),u9r=l(),jf=a("p"),b9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),U6e=a("code"),v9r=o("from_pretrained()"),T9r=o("class method or the "),J6e=a("code"),F9r=o("from_config()"),C9r=o(`class
method.`),M9r=l(),XL=a("p"),E9r=o("This class cannot be instantiated directly using "),Y6e=a("code"),y9r=o("__init__()"),w9r=o(" (throws an error)."),A9r=l(),Dt=a("div"),f(VL.$$.fragment),L9r=l(),K6e=a("p"),B9r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),x9r=l(),Df=a("p"),k9r=o(`Note:
Loading a model from its configuration file does `),Z6e=a("strong"),R9r=o("not"),S9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),e0e=a("code"),P9r=o("from_pretrained()"),$9r=o("to load the model weights."),I9r=l(),o0e=a("p"),j9r=o("Examples:"),D9r=l(),f(zL.$$.fragment),N9r=l(),jo=a("div"),f(WL.$$.fragment),q9r=l(),r0e=a("p"),O9r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),G9r=l(),Xn=a("p"),X9r=o("The model class to instantiate is selected based on the "),t0e=a("code"),V9r=o("model_type"),z9r=o(` property of the config object (either
passed as an argument or loaded from `),a0e=a("code"),W9r=o("pretrained_model_name_or_path"),Q9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n0e=a("code"),H9r=o("pretrained_model_name_or_path"),U9r=o(":"),J9r=l(),s0e=a("ul"),eM=a("li"),l0e=a("strong"),Y9r=o("bert"),K9r=o(" \u2014 "),Nz=a("a"),Z9r=o("FlaxBertForNextSentencePrediction"),eBr=o(" (BERT model)"),oBr=l(),i0e=a("p"),rBr=o("Examples:"),tBr=l(),f(QL.$$.fragment),zRe=l(),Nf=a("h2"),oM=a("a"),d0e=a("span"),f(HL.$$.fragment),aBr=l(),c0e=a("span"),nBr=o("FlaxAutoModelForImageClassification"),WRe=l(),Vr=a("div"),f(UL.$$.fragment),sBr=l(),qf=a("p"),lBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),f0e=a("code"),iBr=o("from_pretrained()"),dBr=o("class method or the "),m0e=a("code"),cBr=o("from_config()"),fBr=o(`class
method.`),mBr=l(),JL=a("p"),gBr=o("This class cannot be instantiated directly using "),g0e=a("code"),hBr=o("__init__()"),pBr=o(" (throws an error)."),_Br=l(),Nt=a("div"),f(YL.$$.fragment),uBr=l(),h0e=a("p"),bBr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),vBr=l(),Of=a("p"),TBr=o(`Note:
Loading a model from its configuration file does `),p0e=a("strong"),FBr=o("not"),CBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_0e=a("code"),MBr=o("from_pretrained()"),EBr=o("to load the model weights."),yBr=l(),u0e=a("p"),wBr=o("Examples:"),ABr=l(),f(KL.$$.fragment),LBr=l(),Do=a("div"),f(ZL.$$.fragment),BBr=l(),b0e=a("p"),xBr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),kBr=l(),Vn=a("p"),RBr=o("The model class to instantiate is selected based on the "),v0e=a("code"),SBr=o("model_type"),PBr=o(` property of the config object (either
passed as an argument or loaded from `),T0e=a("code"),$Br=o("pretrained_model_name_or_path"),IBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F0e=a("code"),jBr=o("pretrained_model_name_or_path"),DBr=o(":"),NBr=l(),e7=a("ul"),rM=a("li"),C0e=a("strong"),qBr=o("beit"),OBr=o(" \u2014 "),qz=a("a"),GBr=o("FlaxBeitForImageClassification"),XBr=o(" (BEiT model)"),VBr=l(),tM=a("li"),M0e=a("strong"),zBr=o("vit"),WBr=o(" \u2014 "),Oz=a("a"),QBr=o("FlaxViTForImageClassification"),HBr=o(" (ViT model)"),UBr=l(),E0e=a("p"),JBr=o("Examples:"),YBr=l(),f(o7.$$.fragment),QRe=l(),Gf=a("h2"),aM=a("a"),y0e=a("span"),f(r7.$$.fragment),KBr=l(),w0e=a("span"),ZBr=o("FlaxAutoModelForVision2Seq"),HRe=l(),zr=a("div"),f(t7.$$.fragment),exr=l(),Xf=a("p"),oxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),A0e=a("code"),rxr=o("from_pretrained()"),txr=o("class method or the "),L0e=a("code"),axr=o("from_config()"),nxr=o(`class
method.`),sxr=l(),a7=a("p"),lxr=o("This class cannot be instantiated directly using "),B0e=a("code"),ixr=o("__init__()"),dxr=o(" (throws an error)."),cxr=l(),qt=a("div"),f(n7.$$.fragment),fxr=l(),x0e=a("p"),mxr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),gxr=l(),Vf=a("p"),hxr=o(`Note:
Loading a model from its configuration file does `),k0e=a("strong"),pxr=o("not"),_xr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),R0e=a("code"),uxr=o("from_pretrained()"),bxr=o("to load the model weights."),vxr=l(),S0e=a("p"),Txr=o("Examples:"),Fxr=l(),f(s7.$$.fragment),Cxr=l(),No=a("div"),f(l7.$$.fragment),Mxr=l(),P0e=a("p"),Exr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),yxr=l(),zn=a("p"),wxr=o("The model class to instantiate is selected based on the "),$0e=a("code"),Axr=o("model_type"),Lxr=o(` property of the config object (either
passed as an argument or loaded from `),I0e=a("code"),Bxr=o("pretrained_model_name_or_path"),xxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j0e=a("code"),kxr=o("pretrained_model_name_or_path"),Rxr=o(":"),Sxr=l(),D0e=a("ul"),nM=a("li"),N0e=a("strong"),Pxr=o("vision-encoder-decoder"),$xr=o(" \u2014 "),Gz=a("a"),Ixr=o("FlaxVisionEncoderDecoderModel"),jxr=o(" (Vision Encoder decoder model)"),Dxr=l(),q0e=a("p"),Nxr=o("Examples:"),qxr=l(),f(i7.$$.fragment),this.h()},l(d){const u=$8t('[data-svelte="svelte-1phssyn"]',document.head);J=n(u,"META",{name:!0,content:!0}),u.forEach(t),Pe=i(d),de=n(d,"H1",{class:!0});var d7=s(de);he=n(d7,"A",{id:!0,class:!0,href:!0});var O0e=s(he);io=n(O0e,"SPAN",{});var G0e=s(io);m(fe.$$.fragment,G0e),G0e.forEach(t),O0e.forEach(t),Fe=i(d7),zo=n(d7,"SPAN",{});var Gxr=s(zo);Vi=r(Gxr,"Auto Classes"),Gxr.forEach(t),d7.forEach(t),Wf=i(d),ha=n(d,"P",{});var JRe=s(ha);zi=r(JRe,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Wi=n(JRe,"CODE",{});var Xxr=s(Wi);s4=r(Xxr,"from_pretrained()"),Xxr.forEach(t),Qf=r(JRe,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),JRe.forEach(t),Le=i(d),co=n(d,"P",{});var sM=s(co);Qi=r(sM,"Instantiating one of "),Wn=n(sM,"A",{href:!0});var Vxr=s(Wn);l4=r(Vxr,"AutoConfig"),Vxr.forEach(t),Qn=r(sM,", "),Hn=n(sM,"A",{href:!0});var zxr=s(Hn);i4=r(zxr,"AutoModel"),zxr.forEach(t),Hi=r(sM,`, and
`),Un=n(sM,"A",{href:!0});var Wxr=s(Un);d4=r(Wxr,"AutoTokenizer"),Wxr.forEach(t),Ui=r(sM," will directly create a class of the relevant architecture. For instance"),sM.forEach(t),Hf=i(d),m(Va.$$.fragment,d),fo=i(d),pe=n(d,"P",{});var YRe=s(pe);s9=r(YRe,"will create a model that is an instance of "),Ji=n(YRe,"A",{href:!0});var Qxr=s(Ji);l9=r(Qxr,"BertModel"),Qxr.forEach(t),i9=r(YRe,"."),YRe.forEach(t),Wo=i(d),za=n(d,"P",{});var KRe=s(za);d9=r(KRe,"There is one class of "),Uf=n(KRe,"CODE",{});var Hxr=s(Uf);c9=r(Hxr,"AutoModel"),Hxr.forEach(t),c$e=r(KRe," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),KRe.forEach(t),Wxe=i(d),Yi=n(d,"H2",{class:!0});var ZRe=s(Yi);Jf=n(ZRe,"A",{id:!0,class:!0,href:!0});var Uxr=s(Jf);jQ=n(Uxr,"SPAN",{});var Jxr=s(jQ);m(c4.$$.fragment,Jxr),Jxr.forEach(t),Uxr.forEach(t),f$e=i(ZRe),DQ=n(ZRe,"SPAN",{});var Yxr=s(DQ);m$e=r(Yxr,"Extending the Auto Classes"),Yxr.forEach(t),ZRe.forEach(t),Qxe=i(d),Jn=n(d,"P",{});var Xz=s(Jn);g$e=r(Xz,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),NQ=n(Xz,"CODE",{});var Kxr=s(NQ);h$e=r(Kxr,"NewModel"),Kxr.forEach(t),p$e=r(Xz,", make sure you have a "),qQ=n(Xz,"CODE",{});var Zxr=s(qQ);_$e=r(Zxr,"NewModelConfig"),Zxr.forEach(t),u$e=r(Xz,` then you can add those to the auto
classes like this:`),Xz.forEach(t),Hxe=i(d),m(f4.$$.fragment,d),Uxe=i(d),f9=n(d,"P",{});var ekr=s(f9);b$e=r(ekr,"You will then be able to use the auto classes like you would usually do!"),ekr.forEach(t),Jxe=i(d),m(Yf.$$.fragment,d),Yxe=i(d),Ki=n(d,"H2",{class:!0});var eSe=s(Ki);Kf=n(eSe,"A",{id:!0,class:!0,href:!0});var okr=s(Kf);OQ=n(okr,"SPAN",{});var rkr=s(OQ);m(m4.$$.fragment,rkr),rkr.forEach(t),okr.forEach(t),v$e=i(eSe),GQ=n(eSe,"SPAN",{});var tkr=s(GQ);T$e=r(tkr,"AutoConfig"),tkr.forEach(t),eSe.forEach(t),Kxe=i(d),Qo=n(d,"DIV",{class:!0});var Qs=s(Qo);m(g4.$$.fragment,Qs),F$e=i(Qs),h4=n(Qs,"P",{});var oSe=s(h4);C$e=r(oSe,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),m9=n(oSe,"A",{href:!0});var akr=s(m9);M$e=r(akr,"from_pretrained()"),akr.forEach(t),E$e=r(oSe," class method."),oSe.forEach(t),y$e=i(Qs),p4=n(Qs,"P",{});var rSe=s(p4);w$e=r(rSe,"This class cannot be instantiated directly using "),XQ=n(rSe,"CODE",{});var nkr=s(XQ);A$e=r(nkr,"__init__()"),nkr.forEach(t),L$e=r(rSe," (throws an error)."),rSe.forEach(t),B$e=i(Qs),mo=n(Qs,"DIV",{class:!0});var _a=s(mo);m(_4.$$.fragment,_a),x$e=i(_a),VQ=n(_a,"P",{});var skr=s(VQ);k$e=r(skr,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),skr.forEach(t),R$e=i(_a),Zi=n(_a,"P",{});var Vz=s(Zi);S$e=r(Vz,"The configuration class to instantiate is selected based on the "),zQ=n(Vz,"CODE",{});var lkr=s(zQ);P$e=r(lkr,"model_type"),lkr.forEach(t),$$e=r(Vz,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),WQ=n(Vz,"CODE",{});var ikr=s(WQ);I$e=r(ikr,"pretrained_model_name_or_path"),ikr.forEach(t),j$e=r(Vz,":"),Vz.forEach(t),D$e=i(_a),v=n(_a,"UL",{});var T=s(v);Zf=n(T,"LI",{});var X0e=s(Zf);QQ=n(X0e,"STRONG",{});var dkr=s(QQ);N$e=r(dkr,"albert"),dkr.forEach(t),q$e=r(X0e," \u2014 "),g9=n(X0e,"A",{href:!0});var ckr=s(g9);O$e=r(ckr,"AlbertConfig"),ckr.forEach(t),G$e=r(X0e," (ALBERT model)"),X0e.forEach(t),X$e=i(T),em=n(T,"LI",{});var V0e=s(em);HQ=n(V0e,"STRONG",{});var fkr=s(HQ);V$e=r(fkr,"bart"),fkr.forEach(t),z$e=r(V0e," \u2014 "),h9=n(V0e,"A",{href:!0});var mkr=s(h9);W$e=r(mkr,"BartConfig"),mkr.forEach(t),Q$e=r(V0e," (BART model)"),V0e.forEach(t),H$e=i(T),om=n(T,"LI",{});var z0e=s(om);UQ=n(z0e,"STRONG",{});var gkr=s(UQ);U$e=r(gkr,"beit"),gkr.forEach(t),J$e=r(z0e," \u2014 "),p9=n(z0e,"A",{href:!0});var hkr=s(p9);Y$e=r(hkr,"BeitConfig"),hkr.forEach(t),K$e=r(z0e," (BEiT model)"),z0e.forEach(t),Z$e=i(T),rm=n(T,"LI",{});var W0e=s(rm);JQ=n(W0e,"STRONG",{});var pkr=s(JQ);eIe=r(pkr,"bert"),pkr.forEach(t),oIe=r(W0e," \u2014 "),_9=n(W0e,"A",{href:!0});var _kr=s(_9);rIe=r(_kr,"BertConfig"),_kr.forEach(t),tIe=r(W0e," (BERT model)"),W0e.forEach(t),aIe=i(T),tm=n(T,"LI",{});var Q0e=s(tm);YQ=n(Q0e,"STRONG",{});var ukr=s(YQ);nIe=r(ukr,"bert-generation"),ukr.forEach(t),sIe=r(Q0e," \u2014 "),u9=n(Q0e,"A",{href:!0});var bkr=s(u9);lIe=r(bkr,"BertGenerationConfig"),bkr.forEach(t),iIe=r(Q0e," (Bert Generation model)"),Q0e.forEach(t),dIe=i(T),am=n(T,"LI",{});var H0e=s(am);KQ=n(H0e,"STRONG",{});var vkr=s(KQ);cIe=r(vkr,"big_bird"),vkr.forEach(t),fIe=r(H0e," \u2014 "),b9=n(H0e,"A",{href:!0});var Tkr=s(b9);mIe=r(Tkr,"BigBirdConfig"),Tkr.forEach(t),gIe=r(H0e," (BigBird model)"),H0e.forEach(t),hIe=i(T),nm=n(T,"LI",{});var U0e=s(nm);ZQ=n(U0e,"STRONG",{});var Fkr=s(ZQ);pIe=r(Fkr,"bigbird_pegasus"),Fkr.forEach(t),_Ie=r(U0e," \u2014 "),v9=n(U0e,"A",{href:!0});var Ckr=s(v9);uIe=r(Ckr,"BigBirdPegasusConfig"),Ckr.forEach(t),bIe=r(U0e," (BigBirdPegasus model)"),U0e.forEach(t),vIe=i(T),sm=n(T,"LI",{});var J0e=s(sm);eH=n(J0e,"STRONG",{});var Mkr=s(eH);TIe=r(Mkr,"blenderbot"),Mkr.forEach(t),FIe=r(J0e," \u2014 "),T9=n(J0e,"A",{href:!0});var Ekr=s(T9);CIe=r(Ekr,"BlenderbotConfig"),Ekr.forEach(t),MIe=r(J0e," (Blenderbot model)"),J0e.forEach(t),EIe=i(T),lm=n(T,"LI",{});var Y0e=s(lm);oH=n(Y0e,"STRONG",{});var ykr=s(oH);yIe=r(ykr,"blenderbot-small"),ykr.forEach(t),wIe=r(Y0e," \u2014 "),F9=n(Y0e,"A",{href:!0});var wkr=s(F9);AIe=r(wkr,"BlenderbotSmallConfig"),wkr.forEach(t),LIe=r(Y0e," (BlenderbotSmall model)"),Y0e.forEach(t),BIe=i(T),im=n(T,"LI",{});var K0e=s(im);rH=n(K0e,"STRONG",{});var Akr=s(rH);xIe=r(Akr,"camembert"),Akr.forEach(t),kIe=r(K0e," \u2014 "),C9=n(K0e,"A",{href:!0});var Lkr=s(C9);RIe=r(Lkr,"CamembertConfig"),Lkr.forEach(t),SIe=r(K0e," (CamemBERT model)"),K0e.forEach(t),PIe=i(T),dm=n(T,"LI",{});var Z0e=s(dm);tH=n(Z0e,"STRONG",{});var Bkr=s(tH);$Ie=r(Bkr,"canine"),Bkr.forEach(t),IIe=r(Z0e," \u2014 "),M9=n(Z0e,"A",{href:!0});var xkr=s(M9);jIe=r(xkr,"CanineConfig"),xkr.forEach(t),DIe=r(Z0e," (Canine model)"),Z0e.forEach(t),NIe=i(T),cm=n(T,"LI",{});var eTe=s(cm);aH=n(eTe,"STRONG",{});var kkr=s(aH);qIe=r(kkr,"clip"),kkr.forEach(t),OIe=r(eTe," \u2014 "),E9=n(eTe,"A",{href:!0});var Rkr=s(E9);GIe=r(Rkr,"CLIPConfig"),Rkr.forEach(t),XIe=r(eTe," (CLIP model)"),eTe.forEach(t),VIe=i(T),fm=n(T,"LI",{});var oTe=s(fm);nH=n(oTe,"STRONG",{});var Skr=s(nH);zIe=r(Skr,"convbert"),Skr.forEach(t),WIe=r(oTe," \u2014 "),y9=n(oTe,"A",{href:!0});var Pkr=s(y9);QIe=r(Pkr,"ConvBertConfig"),Pkr.forEach(t),HIe=r(oTe," (ConvBERT model)"),oTe.forEach(t),UIe=i(T),mm=n(T,"LI",{});var rTe=s(mm);sH=n(rTe,"STRONG",{});var $kr=s(sH);JIe=r($kr,"convnext"),$kr.forEach(t),YIe=r(rTe," \u2014 "),w9=n(rTe,"A",{href:!0});var Ikr=s(w9);KIe=r(Ikr,"ConvNextConfig"),Ikr.forEach(t),ZIe=r(rTe," (ConvNext model)"),rTe.forEach(t),eje=i(T),gm=n(T,"LI",{});var tTe=s(gm);lH=n(tTe,"STRONG",{});var jkr=s(lH);oje=r(jkr,"ctrl"),jkr.forEach(t),rje=r(tTe," \u2014 "),A9=n(tTe,"A",{href:!0});var Dkr=s(A9);tje=r(Dkr,"CTRLConfig"),Dkr.forEach(t),aje=r(tTe," (CTRL model)"),tTe.forEach(t),nje=i(T),hm=n(T,"LI",{});var aTe=s(hm);iH=n(aTe,"STRONG",{});var Nkr=s(iH);sje=r(Nkr,"data2vec-audio"),Nkr.forEach(t),lje=r(aTe," \u2014 "),L9=n(aTe,"A",{href:!0});var qkr=s(L9);ije=r(qkr,"Data2VecAudioConfig"),qkr.forEach(t),dje=r(aTe," (Data2VecAudio model)"),aTe.forEach(t),cje=i(T),pm=n(T,"LI",{});var nTe=s(pm);dH=n(nTe,"STRONG",{});var Okr=s(dH);fje=r(Okr,"data2vec-text"),Okr.forEach(t),mje=r(nTe," \u2014 "),B9=n(nTe,"A",{href:!0});var Gkr=s(B9);gje=r(Gkr,"Data2VecTextConfig"),Gkr.forEach(t),hje=r(nTe," (Data2VecText model)"),nTe.forEach(t),pje=i(T),_m=n(T,"LI",{});var sTe=s(_m);cH=n(sTe,"STRONG",{});var Xkr=s(cH);_je=r(Xkr,"deberta"),Xkr.forEach(t),uje=r(sTe," \u2014 "),x9=n(sTe,"A",{href:!0});var Vkr=s(x9);bje=r(Vkr,"DebertaConfig"),Vkr.forEach(t),vje=r(sTe," (DeBERTa model)"),sTe.forEach(t),Tje=i(T),um=n(T,"LI",{});var lTe=s(um);fH=n(lTe,"STRONG",{});var zkr=s(fH);Fje=r(zkr,"deberta-v2"),zkr.forEach(t),Cje=r(lTe," \u2014 "),k9=n(lTe,"A",{href:!0});var Wkr=s(k9);Mje=r(Wkr,"DebertaV2Config"),Wkr.forEach(t),Eje=r(lTe," (DeBERTa-v2 model)"),lTe.forEach(t),yje=i(T),bm=n(T,"LI",{});var iTe=s(bm);mH=n(iTe,"STRONG",{});var Qkr=s(mH);wje=r(Qkr,"deit"),Qkr.forEach(t),Aje=r(iTe," \u2014 "),R9=n(iTe,"A",{href:!0});var Hkr=s(R9);Lje=r(Hkr,"DeiTConfig"),Hkr.forEach(t),Bje=r(iTe," (DeiT model)"),iTe.forEach(t),xje=i(T),vm=n(T,"LI",{});var dTe=s(vm);gH=n(dTe,"STRONG",{});var Ukr=s(gH);kje=r(Ukr,"detr"),Ukr.forEach(t),Rje=r(dTe," \u2014 "),S9=n(dTe,"A",{href:!0});var Jkr=s(S9);Sje=r(Jkr,"DetrConfig"),Jkr.forEach(t),Pje=r(dTe," (DETR model)"),dTe.forEach(t),$je=i(T),Tm=n(T,"LI",{});var cTe=s(Tm);hH=n(cTe,"STRONG",{});var Ykr=s(hH);Ije=r(Ykr,"distilbert"),Ykr.forEach(t),jje=r(cTe," \u2014 "),P9=n(cTe,"A",{href:!0});var Kkr=s(P9);Dje=r(Kkr,"DistilBertConfig"),Kkr.forEach(t),Nje=r(cTe," (DistilBERT model)"),cTe.forEach(t),qje=i(T),Fm=n(T,"LI",{});var fTe=s(Fm);pH=n(fTe,"STRONG",{});var Zkr=s(pH);Oje=r(Zkr,"dpr"),Zkr.forEach(t),Gje=r(fTe," \u2014 "),$9=n(fTe,"A",{href:!0});var eRr=s($9);Xje=r(eRr,"DPRConfig"),eRr.forEach(t),Vje=r(fTe," (DPR model)"),fTe.forEach(t),zje=i(T),Cm=n(T,"LI",{});var mTe=s(Cm);_H=n(mTe,"STRONG",{});var oRr=s(_H);Wje=r(oRr,"electra"),oRr.forEach(t),Qje=r(mTe," \u2014 "),I9=n(mTe,"A",{href:!0});var rRr=s(I9);Hje=r(rRr,"ElectraConfig"),rRr.forEach(t),Uje=r(mTe," (ELECTRA model)"),mTe.forEach(t),Jje=i(T),Mm=n(T,"LI",{});var gTe=s(Mm);uH=n(gTe,"STRONG",{});var tRr=s(uH);Yje=r(tRr,"encoder-decoder"),tRr.forEach(t),Kje=r(gTe," \u2014 "),j9=n(gTe,"A",{href:!0});var aRr=s(j9);Zje=r(aRr,"EncoderDecoderConfig"),aRr.forEach(t),eDe=r(gTe," (Encoder decoder model)"),gTe.forEach(t),oDe=i(T),Em=n(T,"LI",{});var hTe=s(Em);bH=n(hTe,"STRONG",{});var nRr=s(bH);rDe=r(nRr,"flaubert"),nRr.forEach(t),tDe=r(hTe," \u2014 "),D9=n(hTe,"A",{href:!0});var sRr=s(D9);aDe=r(sRr,"FlaubertConfig"),sRr.forEach(t),nDe=r(hTe," (FlauBERT model)"),hTe.forEach(t),sDe=i(T),ym=n(T,"LI",{});var pTe=s(ym);vH=n(pTe,"STRONG",{});var lRr=s(vH);lDe=r(lRr,"fnet"),lRr.forEach(t),iDe=r(pTe," \u2014 "),N9=n(pTe,"A",{href:!0});var iRr=s(N9);dDe=r(iRr,"FNetConfig"),iRr.forEach(t),cDe=r(pTe," (FNet model)"),pTe.forEach(t),fDe=i(T),wm=n(T,"LI",{});var _Te=s(wm);TH=n(_Te,"STRONG",{});var dRr=s(TH);mDe=r(dRr,"fsmt"),dRr.forEach(t),gDe=r(_Te," \u2014 "),q9=n(_Te,"A",{href:!0});var cRr=s(q9);hDe=r(cRr,"FSMTConfig"),cRr.forEach(t),pDe=r(_Te," (FairSeq Machine-Translation model)"),_Te.forEach(t),_De=i(T),Am=n(T,"LI",{});var uTe=s(Am);FH=n(uTe,"STRONG",{});var fRr=s(FH);uDe=r(fRr,"funnel"),fRr.forEach(t),bDe=r(uTe," \u2014 "),O9=n(uTe,"A",{href:!0});var mRr=s(O9);vDe=r(mRr,"FunnelConfig"),mRr.forEach(t),TDe=r(uTe," (Funnel Transformer model)"),uTe.forEach(t),FDe=i(T),Lm=n(T,"LI",{});var bTe=s(Lm);CH=n(bTe,"STRONG",{});var gRr=s(CH);CDe=r(gRr,"gpt2"),gRr.forEach(t),MDe=r(bTe," \u2014 "),G9=n(bTe,"A",{href:!0});var hRr=s(G9);EDe=r(hRr,"GPT2Config"),hRr.forEach(t),yDe=r(bTe," (OpenAI GPT-2 model)"),bTe.forEach(t),wDe=i(T),Bm=n(T,"LI",{});var vTe=s(Bm);MH=n(vTe,"STRONG",{});var pRr=s(MH);ADe=r(pRr,"gpt_neo"),pRr.forEach(t),LDe=r(vTe," \u2014 "),X9=n(vTe,"A",{href:!0});var _Rr=s(X9);BDe=r(_Rr,"GPTNeoConfig"),_Rr.forEach(t),xDe=r(vTe," (GPT Neo model)"),vTe.forEach(t),kDe=i(T),xm=n(T,"LI",{});var TTe=s(xm);EH=n(TTe,"STRONG",{});var uRr=s(EH);RDe=r(uRr,"gptj"),uRr.forEach(t),SDe=r(TTe," \u2014 "),V9=n(TTe,"A",{href:!0});var bRr=s(V9);PDe=r(bRr,"GPTJConfig"),bRr.forEach(t),$De=r(TTe," (GPT-J model)"),TTe.forEach(t),IDe=i(T),km=n(T,"LI",{});var FTe=s(km);yH=n(FTe,"STRONG",{});var vRr=s(yH);jDe=r(vRr,"hubert"),vRr.forEach(t),DDe=r(FTe," \u2014 "),z9=n(FTe,"A",{href:!0});var TRr=s(z9);NDe=r(TRr,"HubertConfig"),TRr.forEach(t),qDe=r(FTe," (Hubert model)"),FTe.forEach(t),ODe=i(T),Rm=n(T,"LI",{});var CTe=s(Rm);wH=n(CTe,"STRONG",{});var FRr=s(wH);GDe=r(FRr,"ibert"),FRr.forEach(t),XDe=r(CTe," \u2014 "),W9=n(CTe,"A",{href:!0});var CRr=s(W9);VDe=r(CRr,"IBertConfig"),CRr.forEach(t),zDe=r(CTe," (I-BERT model)"),CTe.forEach(t),WDe=i(T),Sm=n(T,"LI",{});var MTe=s(Sm);AH=n(MTe,"STRONG",{});var MRr=s(AH);QDe=r(MRr,"imagegpt"),MRr.forEach(t),HDe=r(MTe," \u2014 "),Q9=n(MTe,"A",{href:!0});var ERr=s(Q9);UDe=r(ERr,"ImageGPTConfig"),ERr.forEach(t),JDe=r(MTe," (ImageGPT model)"),MTe.forEach(t),YDe=i(T),Pm=n(T,"LI",{});var ETe=s(Pm);LH=n(ETe,"STRONG",{});var yRr=s(LH);KDe=r(yRr,"layoutlm"),yRr.forEach(t),ZDe=r(ETe," \u2014 "),H9=n(ETe,"A",{href:!0});var wRr=s(H9);eNe=r(wRr,"LayoutLMConfig"),wRr.forEach(t),oNe=r(ETe," (LayoutLM model)"),ETe.forEach(t),rNe=i(T),$m=n(T,"LI",{});var yTe=s($m);BH=n(yTe,"STRONG",{});var ARr=s(BH);tNe=r(ARr,"layoutlmv2"),ARr.forEach(t),aNe=r(yTe," \u2014 "),U9=n(yTe,"A",{href:!0});var LRr=s(U9);nNe=r(LRr,"LayoutLMv2Config"),LRr.forEach(t),sNe=r(yTe," (LayoutLMv2 model)"),yTe.forEach(t),lNe=i(T),Im=n(T,"LI",{});var wTe=s(Im);xH=n(wTe,"STRONG",{});var BRr=s(xH);iNe=r(BRr,"led"),BRr.forEach(t),dNe=r(wTe," \u2014 "),J9=n(wTe,"A",{href:!0});var xRr=s(J9);cNe=r(xRr,"LEDConfig"),xRr.forEach(t),fNe=r(wTe," (LED model)"),wTe.forEach(t),mNe=i(T),jm=n(T,"LI",{});var ATe=s(jm);kH=n(ATe,"STRONG",{});var kRr=s(kH);gNe=r(kRr,"longformer"),kRr.forEach(t),hNe=r(ATe," \u2014 "),Y9=n(ATe,"A",{href:!0});var RRr=s(Y9);pNe=r(RRr,"LongformerConfig"),RRr.forEach(t),_Ne=r(ATe," (Longformer model)"),ATe.forEach(t),uNe=i(T),Dm=n(T,"LI",{});var LTe=s(Dm);RH=n(LTe,"STRONG",{});var SRr=s(RH);bNe=r(SRr,"luke"),SRr.forEach(t),vNe=r(LTe," \u2014 "),K9=n(LTe,"A",{href:!0});var PRr=s(K9);TNe=r(PRr,"LukeConfig"),PRr.forEach(t),FNe=r(LTe," (LUKE model)"),LTe.forEach(t),CNe=i(T),Nm=n(T,"LI",{});var BTe=s(Nm);SH=n(BTe,"STRONG",{});var $Rr=s(SH);MNe=r($Rr,"lxmert"),$Rr.forEach(t),ENe=r(BTe," \u2014 "),Z9=n(BTe,"A",{href:!0});var IRr=s(Z9);yNe=r(IRr,"LxmertConfig"),IRr.forEach(t),wNe=r(BTe," (LXMERT model)"),BTe.forEach(t),ANe=i(T),qm=n(T,"LI",{});var xTe=s(qm);PH=n(xTe,"STRONG",{});var jRr=s(PH);LNe=r(jRr,"m2m_100"),jRr.forEach(t),BNe=r(xTe," \u2014 "),eB=n(xTe,"A",{href:!0});var DRr=s(eB);xNe=r(DRr,"M2M100Config"),DRr.forEach(t),kNe=r(xTe," (M2M100 model)"),xTe.forEach(t),RNe=i(T),Om=n(T,"LI",{});var kTe=s(Om);$H=n(kTe,"STRONG",{});var NRr=s($H);SNe=r(NRr,"marian"),NRr.forEach(t),PNe=r(kTe," \u2014 "),oB=n(kTe,"A",{href:!0});var qRr=s(oB);$Ne=r(qRr,"MarianConfig"),qRr.forEach(t),INe=r(kTe," (Marian model)"),kTe.forEach(t),jNe=i(T),Gm=n(T,"LI",{});var RTe=s(Gm);IH=n(RTe,"STRONG",{});var ORr=s(IH);DNe=r(ORr,"maskformer"),ORr.forEach(t),NNe=r(RTe," \u2014 "),rB=n(RTe,"A",{href:!0});var GRr=s(rB);qNe=r(GRr,"MaskFormerConfig"),GRr.forEach(t),ONe=r(RTe," (MaskFormer model)"),RTe.forEach(t),GNe=i(T),Xm=n(T,"LI",{});var STe=s(Xm);jH=n(STe,"STRONG",{});var XRr=s(jH);XNe=r(XRr,"mbart"),XRr.forEach(t),VNe=r(STe," \u2014 "),tB=n(STe,"A",{href:!0});var VRr=s(tB);zNe=r(VRr,"MBartConfig"),VRr.forEach(t),WNe=r(STe," (mBART model)"),STe.forEach(t),QNe=i(T),Vm=n(T,"LI",{});var PTe=s(Vm);DH=n(PTe,"STRONG",{});var zRr=s(DH);HNe=r(zRr,"megatron-bert"),zRr.forEach(t),UNe=r(PTe," \u2014 "),aB=n(PTe,"A",{href:!0});var WRr=s(aB);JNe=r(WRr,"MegatronBertConfig"),WRr.forEach(t),YNe=r(PTe," (MegatronBert model)"),PTe.forEach(t),KNe=i(T),zm=n(T,"LI",{});var $Te=s(zm);NH=n($Te,"STRONG",{});var QRr=s(NH);ZNe=r(QRr,"mobilebert"),QRr.forEach(t),eqe=r($Te," \u2014 "),nB=n($Te,"A",{href:!0});var HRr=s(nB);oqe=r(HRr,"MobileBertConfig"),HRr.forEach(t),rqe=r($Te," (MobileBERT model)"),$Te.forEach(t),tqe=i(T),Wm=n(T,"LI",{});var ITe=s(Wm);qH=n(ITe,"STRONG",{});var URr=s(qH);aqe=r(URr,"mpnet"),URr.forEach(t),nqe=r(ITe," \u2014 "),sB=n(ITe,"A",{href:!0});var JRr=s(sB);sqe=r(JRr,"MPNetConfig"),JRr.forEach(t),lqe=r(ITe," (MPNet model)"),ITe.forEach(t),iqe=i(T),Qm=n(T,"LI",{});var jTe=s(Qm);OH=n(jTe,"STRONG",{});var YRr=s(OH);dqe=r(YRr,"mt5"),YRr.forEach(t),cqe=r(jTe," \u2014 "),lB=n(jTe,"A",{href:!0});var KRr=s(lB);fqe=r(KRr,"MT5Config"),KRr.forEach(t),mqe=r(jTe," (mT5 model)"),jTe.forEach(t),gqe=i(T),Hm=n(T,"LI",{});var DTe=s(Hm);GH=n(DTe,"STRONG",{});var ZRr=s(GH);hqe=r(ZRr,"nystromformer"),ZRr.forEach(t),pqe=r(DTe," \u2014 "),iB=n(DTe,"A",{href:!0});var eSr=s(iB);_qe=r(eSr,"NystromformerConfig"),eSr.forEach(t),uqe=r(DTe," (Nystromformer model)"),DTe.forEach(t),bqe=i(T),Um=n(T,"LI",{});var NTe=s(Um);XH=n(NTe,"STRONG",{});var oSr=s(XH);vqe=r(oSr,"openai-gpt"),oSr.forEach(t),Tqe=r(NTe," \u2014 "),dB=n(NTe,"A",{href:!0});var rSr=s(dB);Fqe=r(rSr,"OpenAIGPTConfig"),rSr.forEach(t),Cqe=r(NTe," (OpenAI GPT model)"),NTe.forEach(t),Mqe=i(T),Jm=n(T,"LI",{});var qTe=s(Jm);VH=n(qTe,"STRONG",{});var tSr=s(VH);Eqe=r(tSr,"pegasus"),tSr.forEach(t),yqe=r(qTe," \u2014 "),cB=n(qTe,"A",{href:!0});var aSr=s(cB);wqe=r(aSr,"PegasusConfig"),aSr.forEach(t),Aqe=r(qTe," (Pegasus model)"),qTe.forEach(t),Lqe=i(T),Ym=n(T,"LI",{});var OTe=s(Ym);zH=n(OTe,"STRONG",{});var nSr=s(zH);Bqe=r(nSr,"perceiver"),nSr.forEach(t),xqe=r(OTe," \u2014 "),fB=n(OTe,"A",{href:!0});var sSr=s(fB);kqe=r(sSr,"PerceiverConfig"),sSr.forEach(t),Rqe=r(OTe," (Perceiver model)"),OTe.forEach(t),Sqe=i(T),Km=n(T,"LI",{});var GTe=s(Km);WH=n(GTe,"STRONG",{});var lSr=s(WH);Pqe=r(lSr,"plbart"),lSr.forEach(t),$qe=r(GTe," \u2014 "),mB=n(GTe,"A",{href:!0});var iSr=s(mB);Iqe=r(iSr,"PLBartConfig"),iSr.forEach(t),jqe=r(GTe," (PLBart model)"),GTe.forEach(t),Dqe=i(T),Zm=n(T,"LI",{});var XTe=s(Zm);QH=n(XTe,"STRONG",{});var dSr=s(QH);Nqe=r(dSr,"poolformer"),dSr.forEach(t),qqe=r(XTe," \u2014 "),gB=n(XTe,"A",{href:!0});var cSr=s(gB);Oqe=r(cSr,"PoolFormerConfig"),cSr.forEach(t),Gqe=r(XTe," (PoolFormer model)"),XTe.forEach(t),Xqe=i(T),eg=n(T,"LI",{});var VTe=s(eg);HH=n(VTe,"STRONG",{});var fSr=s(HH);Vqe=r(fSr,"prophetnet"),fSr.forEach(t),zqe=r(VTe," \u2014 "),hB=n(VTe,"A",{href:!0});var mSr=s(hB);Wqe=r(mSr,"ProphetNetConfig"),mSr.forEach(t),Qqe=r(VTe," (ProphetNet model)"),VTe.forEach(t),Hqe=i(T),og=n(T,"LI",{});var zTe=s(og);UH=n(zTe,"STRONG",{});var gSr=s(UH);Uqe=r(gSr,"qdqbert"),gSr.forEach(t),Jqe=r(zTe," \u2014 "),pB=n(zTe,"A",{href:!0});var hSr=s(pB);Yqe=r(hSr,"QDQBertConfig"),hSr.forEach(t),Kqe=r(zTe," (QDQBert model)"),zTe.forEach(t),Zqe=i(T),rg=n(T,"LI",{});var WTe=s(rg);JH=n(WTe,"STRONG",{});var pSr=s(JH);eOe=r(pSr,"rag"),pSr.forEach(t),oOe=r(WTe," \u2014 "),_B=n(WTe,"A",{href:!0});var _Sr=s(_B);rOe=r(_Sr,"RagConfig"),_Sr.forEach(t),tOe=r(WTe," (RAG model)"),WTe.forEach(t),aOe=i(T),tg=n(T,"LI",{});var QTe=s(tg);YH=n(QTe,"STRONG",{});var uSr=s(YH);nOe=r(uSr,"realm"),uSr.forEach(t),sOe=r(QTe," \u2014 "),uB=n(QTe,"A",{href:!0});var bSr=s(uB);lOe=r(bSr,"RealmConfig"),bSr.forEach(t),iOe=r(QTe," (Realm model)"),QTe.forEach(t),dOe=i(T),ag=n(T,"LI",{});var HTe=s(ag);KH=n(HTe,"STRONG",{});var vSr=s(KH);cOe=r(vSr,"reformer"),vSr.forEach(t),fOe=r(HTe," \u2014 "),bB=n(HTe,"A",{href:!0});var TSr=s(bB);mOe=r(TSr,"ReformerConfig"),TSr.forEach(t),gOe=r(HTe," (Reformer model)"),HTe.forEach(t),hOe=i(T),ng=n(T,"LI",{});var UTe=s(ng);ZH=n(UTe,"STRONG",{});var FSr=s(ZH);pOe=r(FSr,"rembert"),FSr.forEach(t),_Oe=r(UTe," \u2014 "),vB=n(UTe,"A",{href:!0});var CSr=s(vB);uOe=r(CSr,"RemBertConfig"),CSr.forEach(t),bOe=r(UTe," (RemBERT model)"),UTe.forEach(t),vOe=i(T),sg=n(T,"LI",{});var JTe=s(sg);eU=n(JTe,"STRONG",{});var MSr=s(eU);TOe=r(MSr,"retribert"),MSr.forEach(t),FOe=r(JTe," \u2014 "),TB=n(JTe,"A",{href:!0});var ESr=s(TB);COe=r(ESr,"RetriBertConfig"),ESr.forEach(t),MOe=r(JTe," (RetriBERT model)"),JTe.forEach(t),EOe=i(T),lg=n(T,"LI",{});var YTe=s(lg);oU=n(YTe,"STRONG",{});var ySr=s(oU);yOe=r(ySr,"roberta"),ySr.forEach(t),wOe=r(YTe," \u2014 "),FB=n(YTe,"A",{href:!0});var wSr=s(FB);AOe=r(wSr,"RobertaConfig"),wSr.forEach(t),LOe=r(YTe," (RoBERTa model)"),YTe.forEach(t),BOe=i(T),ig=n(T,"LI",{});var KTe=s(ig);rU=n(KTe,"STRONG",{});var ASr=s(rU);xOe=r(ASr,"roformer"),ASr.forEach(t),kOe=r(KTe," \u2014 "),CB=n(KTe,"A",{href:!0});var LSr=s(CB);ROe=r(LSr,"RoFormerConfig"),LSr.forEach(t),SOe=r(KTe," (RoFormer model)"),KTe.forEach(t),POe=i(T),dg=n(T,"LI",{});var ZTe=s(dg);tU=n(ZTe,"STRONG",{});var BSr=s(tU);$Oe=r(BSr,"segformer"),BSr.forEach(t),IOe=r(ZTe," \u2014 "),MB=n(ZTe,"A",{href:!0});var xSr=s(MB);jOe=r(xSr,"SegformerConfig"),xSr.forEach(t),DOe=r(ZTe," (SegFormer model)"),ZTe.forEach(t),NOe=i(T),cg=n(T,"LI",{});var e8e=s(cg);aU=n(e8e,"STRONG",{});var kSr=s(aU);qOe=r(kSr,"sew"),kSr.forEach(t),OOe=r(e8e," \u2014 "),EB=n(e8e,"A",{href:!0});var RSr=s(EB);GOe=r(RSr,"SEWConfig"),RSr.forEach(t),XOe=r(e8e," (SEW model)"),e8e.forEach(t),VOe=i(T),fg=n(T,"LI",{});var o8e=s(fg);nU=n(o8e,"STRONG",{});var SSr=s(nU);zOe=r(SSr,"sew-d"),SSr.forEach(t),WOe=r(o8e," \u2014 "),yB=n(o8e,"A",{href:!0});var PSr=s(yB);QOe=r(PSr,"SEWDConfig"),PSr.forEach(t),HOe=r(o8e," (SEW-D model)"),o8e.forEach(t),UOe=i(T),mg=n(T,"LI",{});var r8e=s(mg);sU=n(r8e,"STRONG",{});var $Sr=s(sU);JOe=r($Sr,"speech-encoder-decoder"),$Sr.forEach(t),YOe=r(r8e," \u2014 "),wB=n(r8e,"A",{href:!0});var ISr=s(wB);KOe=r(ISr,"SpeechEncoderDecoderConfig"),ISr.forEach(t),ZOe=r(r8e," (Speech Encoder decoder model)"),r8e.forEach(t),eGe=i(T),gg=n(T,"LI",{});var t8e=s(gg);lU=n(t8e,"STRONG",{});var jSr=s(lU);oGe=r(jSr,"speech_to_text"),jSr.forEach(t),rGe=r(t8e," \u2014 "),AB=n(t8e,"A",{href:!0});var DSr=s(AB);tGe=r(DSr,"Speech2TextConfig"),DSr.forEach(t),aGe=r(t8e," (Speech2Text model)"),t8e.forEach(t),nGe=i(T),hg=n(T,"LI",{});var a8e=s(hg);iU=n(a8e,"STRONG",{});var NSr=s(iU);sGe=r(NSr,"speech_to_text_2"),NSr.forEach(t),lGe=r(a8e," \u2014 "),LB=n(a8e,"A",{href:!0});var qSr=s(LB);iGe=r(qSr,"Speech2Text2Config"),qSr.forEach(t),dGe=r(a8e," (Speech2Text2 model)"),a8e.forEach(t),cGe=i(T),pg=n(T,"LI",{});var n8e=s(pg);dU=n(n8e,"STRONG",{});var OSr=s(dU);fGe=r(OSr,"splinter"),OSr.forEach(t),mGe=r(n8e," \u2014 "),BB=n(n8e,"A",{href:!0});var GSr=s(BB);gGe=r(GSr,"SplinterConfig"),GSr.forEach(t),hGe=r(n8e," (Splinter model)"),n8e.forEach(t),pGe=i(T),_g=n(T,"LI",{});var s8e=s(_g);cU=n(s8e,"STRONG",{});var XSr=s(cU);_Ge=r(XSr,"squeezebert"),XSr.forEach(t),uGe=r(s8e," \u2014 "),xB=n(s8e,"A",{href:!0});var VSr=s(xB);bGe=r(VSr,"SqueezeBertConfig"),VSr.forEach(t),vGe=r(s8e," (SqueezeBERT model)"),s8e.forEach(t),TGe=i(T),ug=n(T,"LI",{});var l8e=s(ug);fU=n(l8e,"STRONG",{});var zSr=s(fU);FGe=r(zSr,"swin"),zSr.forEach(t),CGe=r(l8e," \u2014 "),kB=n(l8e,"A",{href:!0});var WSr=s(kB);MGe=r(WSr,"SwinConfig"),WSr.forEach(t),EGe=r(l8e," (Swin model)"),l8e.forEach(t),yGe=i(T),bg=n(T,"LI",{});var i8e=s(bg);mU=n(i8e,"STRONG",{});var QSr=s(mU);wGe=r(QSr,"t5"),QSr.forEach(t),AGe=r(i8e," \u2014 "),RB=n(i8e,"A",{href:!0});var HSr=s(RB);LGe=r(HSr,"T5Config"),HSr.forEach(t),BGe=r(i8e," (T5 model)"),i8e.forEach(t),xGe=i(T),vg=n(T,"LI",{});var d8e=s(vg);gU=n(d8e,"STRONG",{});var USr=s(gU);kGe=r(USr,"tapas"),USr.forEach(t),RGe=r(d8e," \u2014 "),SB=n(d8e,"A",{href:!0});var JSr=s(SB);SGe=r(JSr,"TapasConfig"),JSr.forEach(t),PGe=r(d8e," (TAPAS model)"),d8e.forEach(t),$Ge=i(T),Tg=n(T,"LI",{});var c8e=s(Tg);hU=n(c8e,"STRONG",{});var YSr=s(hU);IGe=r(YSr,"transfo-xl"),YSr.forEach(t),jGe=r(c8e," \u2014 "),PB=n(c8e,"A",{href:!0});var KSr=s(PB);DGe=r(KSr,"TransfoXLConfig"),KSr.forEach(t),NGe=r(c8e," (Transformer-XL model)"),c8e.forEach(t),qGe=i(T),Fg=n(T,"LI",{});var f8e=s(Fg);pU=n(f8e,"STRONG",{});var ZSr=s(pU);OGe=r(ZSr,"trocr"),ZSr.forEach(t),GGe=r(f8e," \u2014 "),$B=n(f8e,"A",{href:!0});var ePr=s($B);XGe=r(ePr,"TrOCRConfig"),ePr.forEach(t),VGe=r(f8e," (TrOCR model)"),f8e.forEach(t),zGe=i(T),Cg=n(T,"LI",{});var m8e=s(Cg);_U=n(m8e,"STRONG",{});var oPr=s(_U);WGe=r(oPr,"unispeech"),oPr.forEach(t),QGe=r(m8e," \u2014 "),IB=n(m8e,"A",{href:!0});var rPr=s(IB);HGe=r(rPr,"UniSpeechConfig"),rPr.forEach(t),UGe=r(m8e," (UniSpeech model)"),m8e.forEach(t),JGe=i(T),Mg=n(T,"LI",{});var g8e=s(Mg);uU=n(g8e,"STRONG",{});var tPr=s(uU);YGe=r(tPr,"unispeech-sat"),tPr.forEach(t),KGe=r(g8e," \u2014 "),jB=n(g8e,"A",{href:!0});var aPr=s(jB);ZGe=r(aPr,"UniSpeechSatConfig"),aPr.forEach(t),eXe=r(g8e," (UniSpeechSat model)"),g8e.forEach(t),oXe=i(T),Eg=n(T,"LI",{});var h8e=s(Eg);bU=n(h8e,"STRONG",{});var nPr=s(bU);rXe=r(nPr,"vilt"),nPr.forEach(t),tXe=r(h8e," \u2014 "),DB=n(h8e,"A",{href:!0});var sPr=s(DB);aXe=r(sPr,"ViltConfig"),sPr.forEach(t),nXe=r(h8e," (ViLT model)"),h8e.forEach(t),sXe=i(T),yg=n(T,"LI",{});var p8e=s(yg);vU=n(p8e,"STRONG",{});var lPr=s(vU);lXe=r(lPr,"vision-encoder-decoder"),lPr.forEach(t),iXe=r(p8e," \u2014 "),NB=n(p8e,"A",{href:!0});var iPr=s(NB);dXe=r(iPr,"VisionEncoderDecoderConfig"),iPr.forEach(t),cXe=r(p8e," (Vision Encoder decoder model)"),p8e.forEach(t),fXe=i(T),wg=n(T,"LI",{});var _8e=s(wg);TU=n(_8e,"STRONG",{});var dPr=s(TU);mXe=r(dPr,"vision-text-dual-encoder"),dPr.forEach(t),gXe=r(_8e," \u2014 "),qB=n(_8e,"A",{href:!0});var cPr=s(qB);hXe=r(cPr,"VisionTextDualEncoderConfig"),cPr.forEach(t),pXe=r(_8e," (VisionTextDualEncoder model)"),_8e.forEach(t),_Xe=i(T),Ag=n(T,"LI",{});var u8e=s(Ag);FU=n(u8e,"STRONG",{});var fPr=s(FU);uXe=r(fPr,"visual_bert"),fPr.forEach(t),bXe=r(u8e," \u2014 "),OB=n(u8e,"A",{href:!0});var mPr=s(OB);vXe=r(mPr,"VisualBertConfig"),mPr.forEach(t),TXe=r(u8e," (VisualBert model)"),u8e.forEach(t),FXe=i(T),Lg=n(T,"LI",{});var b8e=s(Lg);CU=n(b8e,"STRONG",{});var gPr=s(CU);CXe=r(gPr,"vit"),gPr.forEach(t),MXe=r(b8e," \u2014 "),GB=n(b8e,"A",{href:!0});var hPr=s(GB);EXe=r(hPr,"ViTConfig"),hPr.forEach(t),yXe=r(b8e," (ViT model)"),b8e.forEach(t),wXe=i(T),Bg=n(T,"LI",{});var v8e=s(Bg);MU=n(v8e,"STRONG",{});var pPr=s(MU);AXe=r(pPr,"vit_mae"),pPr.forEach(t),LXe=r(v8e," \u2014 "),XB=n(v8e,"A",{href:!0});var _Pr=s(XB);BXe=r(_Pr,"ViTMAEConfig"),_Pr.forEach(t),xXe=r(v8e," (ViTMAE model)"),v8e.forEach(t),kXe=i(T),xg=n(T,"LI",{});var T8e=s(xg);EU=n(T8e,"STRONG",{});var uPr=s(EU);RXe=r(uPr,"wav2vec2"),uPr.forEach(t),SXe=r(T8e," \u2014 "),VB=n(T8e,"A",{href:!0});var bPr=s(VB);PXe=r(bPr,"Wav2Vec2Config"),bPr.forEach(t),$Xe=r(T8e," (Wav2Vec2 model)"),T8e.forEach(t),IXe=i(T),kg=n(T,"LI",{});var F8e=s(kg);yU=n(F8e,"STRONG",{});var vPr=s(yU);jXe=r(vPr,"wavlm"),vPr.forEach(t),DXe=r(F8e," \u2014 "),zB=n(F8e,"A",{href:!0});var TPr=s(zB);NXe=r(TPr,"WavLMConfig"),TPr.forEach(t),qXe=r(F8e," (WavLM model)"),F8e.forEach(t),OXe=i(T),Rg=n(T,"LI",{});var C8e=s(Rg);wU=n(C8e,"STRONG",{});var FPr=s(wU);GXe=r(FPr,"xglm"),FPr.forEach(t),XXe=r(C8e," \u2014 "),WB=n(C8e,"A",{href:!0});var CPr=s(WB);VXe=r(CPr,"XGLMConfig"),CPr.forEach(t),zXe=r(C8e," (XGLM model)"),C8e.forEach(t),WXe=i(T),Sg=n(T,"LI",{});var M8e=s(Sg);AU=n(M8e,"STRONG",{});var MPr=s(AU);QXe=r(MPr,"xlm"),MPr.forEach(t),HXe=r(M8e," \u2014 "),QB=n(M8e,"A",{href:!0});var EPr=s(QB);UXe=r(EPr,"XLMConfig"),EPr.forEach(t),JXe=r(M8e," (XLM model)"),M8e.forEach(t),YXe=i(T),Pg=n(T,"LI",{});var E8e=s(Pg);LU=n(E8e,"STRONG",{});var yPr=s(LU);KXe=r(yPr,"xlm-prophetnet"),yPr.forEach(t),ZXe=r(E8e," \u2014 "),HB=n(E8e,"A",{href:!0});var wPr=s(HB);eVe=r(wPr,"XLMProphetNetConfig"),wPr.forEach(t),oVe=r(E8e," (XLMProphetNet model)"),E8e.forEach(t),rVe=i(T),$g=n(T,"LI",{});var y8e=s($g);BU=n(y8e,"STRONG",{});var APr=s(BU);tVe=r(APr,"xlm-roberta"),APr.forEach(t),aVe=r(y8e," \u2014 "),UB=n(y8e,"A",{href:!0});var LPr=s(UB);nVe=r(LPr,"XLMRobertaConfig"),LPr.forEach(t),sVe=r(y8e," (XLM-RoBERTa model)"),y8e.forEach(t),lVe=i(T),Ig=n(T,"LI",{});var w8e=s(Ig);xU=n(w8e,"STRONG",{});var BPr=s(xU);iVe=r(BPr,"xlm-roberta-xl"),BPr.forEach(t),dVe=r(w8e," \u2014 "),JB=n(w8e,"A",{href:!0});var xPr=s(JB);cVe=r(xPr,"XLMRobertaXLConfig"),xPr.forEach(t),fVe=r(w8e," (XLM-RoBERTa-XL model)"),w8e.forEach(t),mVe=i(T),jg=n(T,"LI",{});var A8e=s(jg);kU=n(A8e,"STRONG",{});var kPr=s(kU);gVe=r(kPr,"xlnet"),kPr.forEach(t),hVe=r(A8e," \u2014 "),YB=n(A8e,"A",{href:!0});var RPr=s(YB);pVe=r(RPr,"XLNetConfig"),RPr.forEach(t),_Ve=r(A8e," (XLNet model)"),A8e.forEach(t),uVe=i(T),Dg=n(T,"LI",{});var L8e=s(Dg);RU=n(L8e,"STRONG",{});var SPr=s(RU);bVe=r(SPr,"yoso"),SPr.forEach(t),vVe=r(L8e," \u2014 "),KB=n(L8e,"A",{href:!0});var PPr=s(KB);TVe=r(PPr,"YosoConfig"),PPr.forEach(t),FVe=r(L8e," (YOSO model)"),L8e.forEach(t),T.forEach(t),CVe=i(_a),SU=n(_a,"P",{});var $Pr=s(SU);MVe=r($Pr,"Examples:"),$Pr.forEach(t),EVe=i(_a),m(u4.$$.fragment,_a),_a.forEach(t),yVe=i(Qs),Ng=n(Qs,"DIV",{class:!0});var tSe=s(Ng);m(b4.$$.fragment,tSe),wVe=i(tSe),PU=n(tSe,"P",{});var IPr=s(PU);AVe=r(IPr,"Register a new configuration for this class."),IPr.forEach(t),tSe.forEach(t),Qs.forEach(t),Zxe=i(d),ed=n(d,"H2",{class:!0});var aSe=s(ed);qg=n(aSe,"A",{id:!0,class:!0,href:!0});var jPr=s(qg);$U=n(jPr,"SPAN",{});var DPr=s($U);m(v4.$$.fragment,DPr),DPr.forEach(t),jPr.forEach(t),LVe=i(aSe),IU=n(aSe,"SPAN",{});var NPr=s(IU);BVe=r(NPr,"AutoTokenizer"),NPr.forEach(t),aSe.forEach(t),eke=i(d),Ho=n(d,"DIV",{class:!0});var Hs=s(Ho);m(T4.$$.fragment,Hs),xVe=i(Hs),F4=n(Hs,"P",{});var nSe=s(F4);kVe=r(nSe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),ZB=n(nSe,"A",{href:!0});var qPr=s(ZB);RVe=r(qPr,"AutoTokenizer.from_pretrained()"),qPr.forEach(t),SVe=r(nSe," class method."),nSe.forEach(t),PVe=i(Hs),C4=n(Hs,"P",{});var sSe=s(C4);$Ve=r(sSe,"This class cannot be instantiated directly using "),jU=n(sSe,"CODE",{});var OPr=s(jU);IVe=r(OPr,"__init__()"),OPr.forEach(t),jVe=r(sSe," (throws an error)."),sSe.forEach(t),DVe=i(Hs),go=n(Hs,"DIV",{class:!0});var ua=s(go);m(M4.$$.fragment,ua),NVe=i(ua),DU=n(ua,"P",{});var GPr=s(DU);qVe=r(GPr,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),GPr.forEach(t),OVe=i(ua),Wa=n(ua,"P",{});var lM=s(Wa);GVe=r(lM,"The tokenizer class to instantiate is selected based on the "),NU=n(lM,"CODE",{});var XPr=s(NU);XVe=r(XPr,"model_type"),XPr.forEach(t),VVe=r(lM,` property of the config object (either
passed as an argument or loaded from `),qU=n(lM,"CODE",{});var VPr=s(qU);zVe=r(VPr,"pretrained_model_name_or_path"),VPr.forEach(t),WVe=r(lM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OU=n(lM,"CODE",{});var zPr=s(OU);QVe=r(zPr,"pretrained_model_name_or_path"),zPr.forEach(t),HVe=r(lM,":"),lM.forEach(t),UVe=i(ua),E=n(ua,"UL",{});var y=s(E);Yn=n(y,"LI",{});var c7=s(Yn);GU=n(c7,"STRONG",{});var WPr=s(GU);JVe=r(WPr,"albert"),WPr.forEach(t),YVe=r(c7," \u2014 "),ex=n(c7,"A",{href:!0});var QPr=s(ex);KVe=r(QPr,"AlbertTokenizer"),QPr.forEach(t),ZVe=r(c7," or "),ox=n(c7,"A",{href:!0});var HPr=s(ox);eze=r(HPr,"AlbertTokenizerFast"),HPr.forEach(t),oze=r(c7," (ALBERT model)"),c7.forEach(t),rze=i(y),Kn=n(y,"LI",{});var f7=s(Kn);XU=n(f7,"STRONG",{});var UPr=s(XU);tze=r(UPr,"bart"),UPr.forEach(t),aze=r(f7," \u2014 "),rx=n(f7,"A",{href:!0});var JPr=s(rx);nze=r(JPr,"BartTokenizer"),JPr.forEach(t),sze=r(f7," or "),tx=n(f7,"A",{href:!0});var YPr=s(tx);lze=r(YPr,"BartTokenizerFast"),YPr.forEach(t),ize=r(f7," (BART model)"),f7.forEach(t),dze=i(y),Zn=n(y,"LI",{});var m7=s(Zn);VU=n(m7,"STRONG",{});var KPr=s(VU);cze=r(KPr,"barthez"),KPr.forEach(t),fze=r(m7," \u2014 "),ax=n(m7,"A",{href:!0});var ZPr=s(ax);mze=r(ZPr,"BarthezTokenizer"),ZPr.forEach(t),gze=r(m7," or "),nx=n(m7,"A",{href:!0});var e$r=s(nx);hze=r(e$r,"BarthezTokenizerFast"),e$r.forEach(t),pze=r(m7," (BARThez model)"),m7.forEach(t),_ze=i(y),Og=n(y,"LI",{});var B8e=s(Og);zU=n(B8e,"STRONG",{});var o$r=s(zU);uze=r(o$r,"bartpho"),o$r.forEach(t),bze=r(B8e," \u2014 "),sx=n(B8e,"A",{href:!0});var r$r=s(sx);vze=r(r$r,"BartphoTokenizer"),r$r.forEach(t),Tze=r(B8e," (BARTpho model)"),B8e.forEach(t),Fze=i(y),es=n(y,"LI",{});var g7=s(es);WU=n(g7,"STRONG",{});var t$r=s(WU);Cze=r(t$r,"bert"),t$r.forEach(t),Mze=r(g7," \u2014 "),lx=n(g7,"A",{href:!0});var a$r=s(lx);Eze=r(a$r,"BertTokenizer"),a$r.forEach(t),yze=r(g7," or "),ix=n(g7,"A",{href:!0});var n$r=s(ix);wze=r(n$r,"BertTokenizerFast"),n$r.forEach(t),Aze=r(g7," (BERT model)"),g7.forEach(t),Lze=i(y),Gg=n(y,"LI",{});var x8e=s(Gg);QU=n(x8e,"STRONG",{});var s$r=s(QU);Bze=r(s$r,"bert-generation"),s$r.forEach(t),xze=r(x8e," \u2014 "),dx=n(x8e,"A",{href:!0});var l$r=s(dx);kze=r(l$r,"BertGenerationTokenizer"),l$r.forEach(t),Rze=r(x8e," (Bert Generation model)"),x8e.forEach(t),Sze=i(y),Xg=n(y,"LI",{});var k8e=s(Xg);HU=n(k8e,"STRONG",{});var i$r=s(HU);Pze=r(i$r,"bert-japanese"),i$r.forEach(t),$ze=r(k8e," \u2014 "),cx=n(k8e,"A",{href:!0});var d$r=s(cx);Ize=r(d$r,"BertJapaneseTokenizer"),d$r.forEach(t),jze=r(k8e," (BertJapanese model)"),k8e.forEach(t),Dze=i(y),Vg=n(y,"LI",{});var R8e=s(Vg);UU=n(R8e,"STRONG",{});var c$r=s(UU);Nze=r(c$r,"bertweet"),c$r.forEach(t),qze=r(R8e," \u2014 "),fx=n(R8e,"A",{href:!0});var f$r=s(fx);Oze=r(f$r,"BertweetTokenizer"),f$r.forEach(t),Gze=r(R8e," (Bertweet model)"),R8e.forEach(t),Xze=i(y),os=n(y,"LI",{});var h7=s(os);JU=n(h7,"STRONG",{});var m$r=s(JU);Vze=r(m$r,"big_bird"),m$r.forEach(t),zze=r(h7," \u2014 "),mx=n(h7,"A",{href:!0});var g$r=s(mx);Wze=r(g$r,"BigBirdTokenizer"),g$r.forEach(t),Qze=r(h7," or "),gx=n(h7,"A",{href:!0});var h$r=s(gx);Hze=r(h$r,"BigBirdTokenizerFast"),h$r.forEach(t),Uze=r(h7," (BigBird model)"),h7.forEach(t),Jze=i(y),rs=n(y,"LI",{});var p7=s(rs);YU=n(p7,"STRONG",{});var p$r=s(YU);Yze=r(p$r,"bigbird_pegasus"),p$r.forEach(t),Kze=r(p7," \u2014 "),hx=n(p7,"A",{href:!0});var _$r=s(hx);Zze=r(_$r,"PegasusTokenizer"),_$r.forEach(t),eWe=r(p7," or "),px=n(p7,"A",{href:!0});var u$r=s(px);oWe=r(u$r,"PegasusTokenizerFast"),u$r.forEach(t),rWe=r(p7," (BigBirdPegasus model)"),p7.forEach(t),tWe=i(y),ts=n(y,"LI",{});var _7=s(ts);KU=n(_7,"STRONG",{});var b$r=s(KU);aWe=r(b$r,"blenderbot"),b$r.forEach(t),nWe=r(_7," \u2014 "),_x=n(_7,"A",{href:!0});var v$r=s(_x);sWe=r(v$r,"BlenderbotTokenizer"),v$r.forEach(t),lWe=r(_7," or "),ux=n(_7,"A",{href:!0});var T$r=s(ux);iWe=r(T$r,"BlenderbotTokenizerFast"),T$r.forEach(t),dWe=r(_7," (Blenderbot model)"),_7.forEach(t),cWe=i(y),zg=n(y,"LI",{});var S8e=s(zg);ZU=n(S8e,"STRONG",{});var F$r=s(ZU);fWe=r(F$r,"blenderbot-small"),F$r.forEach(t),mWe=r(S8e," \u2014 "),bx=n(S8e,"A",{href:!0});var C$r=s(bx);gWe=r(C$r,"BlenderbotSmallTokenizer"),C$r.forEach(t),hWe=r(S8e," (BlenderbotSmall model)"),S8e.forEach(t),pWe=i(y),Wg=n(y,"LI",{});var P8e=s(Wg);eJ=n(P8e,"STRONG",{});var M$r=s(eJ);_We=r(M$r,"byt5"),M$r.forEach(t),uWe=r(P8e," \u2014 "),vx=n(P8e,"A",{href:!0});var E$r=s(vx);bWe=r(E$r,"ByT5Tokenizer"),E$r.forEach(t),vWe=r(P8e," (ByT5 model)"),P8e.forEach(t),TWe=i(y),as=n(y,"LI",{});var u7=s(as);oJ=n(u7,"STRONG",{});var y$r=s(oJ);FWe=r(y$r,"camembert"),y$r.forEach(t),CWe=r(u7," \u2014 "),Tx=n(u7,"A",{href:!0});var w$r=s(Tx);MWe=r(w$r,"CamembertTokenizer"),w$r.forEach(t),EWe=r(u7," or "),Fx=n(u7,"A",{href:!0});var A$r=s(Fx);yWe=r(A$r,"CamembertTokenizerFast"),A$r.forEach(t),wWe=r(u7," (CamemBERT model)"),u7.forEach(t),AWe=i(y),Qg=n(y,"LI",{});var $8e=s(Qg);rJ=n($8e,"STRONG",{});var L$r=s(rJ);LWe=r(L$r,"canine"),L$r.forEach(t),BWe=r($8e," \u2014 "),Cx=n($8e,"A",{href:!0});var B$r=s(Cx);xWe=r(B$r,"CanineTokenizer"),B$r.forEach(t),kWe=r($8e," (Canine model)"),$8e.forEach(t),RWe=i(y),ns=n(y,"LI",{});var b7=s(ns);tJ=n(b7,"STRONG",{});var x$r=s(tJ);SWe=r(x$r,"clip"),x$r.forEach(t),PWe=r(b7," \u2014 "),Mx=n(b7,"A",{href:!0});var k$r=s(Mx);$We=r(k$r,"CLIPTokenizer"),k$r.forEach(t),IWe=r(b7," or "),Ex=n(b7,"A",{href:!0});var R$r=s(Ex);jWe=r(R$r,"CLIPTokenizerFast"),R$r.forEach(t),DWe=r(b7," (CLIP model)"),b7.forEach(t),NWe=i(y),ss=n(y,"LI",{});var v7=s(ss);aJ=n(v7,"STRONG",{});var S$r=s(aJ);qWe=r(S$r,"convbert"),S$r.forEach(t),OWe=r(v7," \u2014 "),yx=n(v7,"A",{href:!0});var P$r=s(yx);GWe=r(P$r,"ConvBertTokenizer"),P$r.forEach(t),XWe=r(v7," or "),wx=n(v7,"A",{href:!0});var $$r=s(wx);VWe=r($$r,"ConvBertTokenizerFast"),$$r.forEach(t),zWe=r(v7," (ConvBERT model)"),v7.forEach(t),WWe=i(y),ls=n(y,"LI",{});var T7=s(ls);nJ=n(T7,"STRONG",{});var I$r=s(nJ);QWe=r(I$r,"cpm"),I$r.forEach(t),HWe=r(T7," \u2014 "),Ax=n(T7,"A",{href:!0});var j$r=s(Ax);UWe=r(j$r,"CpmTokenizer"),j$r.forEach(t),JWe=r(T7," or "),sJ=n(T7,"CODE",{});var D$r=s(sJ);YWe=r(D$r,"CpmTokenizerFast"),D$r.forEach(t),KWe=r(T7," (CPM model)"),T7.forEach(t),ZWe=i(y),Hg=n(y,"LI",{});var I8e=s(Hg);lJ=n(I8e,"STRONG",{});var N$r=s(lJ);eQe=r(N$r,"ctrl"),N$r.forEach(t),oQe=r(I8e," \u2014 "),Lx=n(I8e,"A",{href:!0});var q$r=s(Lx);rQe=r(q$r,"CTRLTokenizer"),q$r.forEach(t),tQe=r(I8e," (CTRL model)"),I8e.forEach(t),aQe=i(y),is=n(y,"LI",{});var F7=s(is);iJ=n(F7,"STRONG",{});var O$r=s(iJ);nQe=r(O$r,"deberta"),O$r.forEach(t),sQe=r(F7," \u2014 "),Bx=n(F7,"A",{href:!0});var G$r=s(Bx);lQe=r(G$r,"DebertaTokenizer"),G$r.forEach(t),iQe=r(F7," or "),xx=n(F7,"A",{href:!0});var X$r=s(xx);dQe=r(X$r,"DebertaTokenizerFast"),X$r.forEach(t),cQe=r(F7," (DeBERTa model)"),F7.forEach(t),fQe=i(y),Ug=n(y,"LI",{});var j8e=s(Ug);dJ=n(j8e,"STRONG",{});var V$r=s(dJ);mQe=r(V$r,"deberta-v2"),V$r.forEach(t),gQe=r(j8e," \u2014 "),kx=n(j8e,"A",{href:!0});var z$r=s(kx);hQe=r(z$r,"DebertaV2Tokenizer"),z$r.forEach(t),pQe=r(j8e," (DeBERTa-v2 model)"),j8e.forEach(t),_Qe=i(y),ds=n(y,"LI",{});var C7=s(ds);cJ=n(C7,"STRONG",{});var W$r=s(cJ);uQe=r(W$r,"distilbert"),W$r.forEach(t),bQe=r(C7," \u2014 "),Rx=n(C7,"A",{href:!0});var Q$r=s(Rx);vQe=r(Q$r,"DistilBertTokenizer"),Q$r.forEach(t),TQe=r(C7," or "),Sx=n(C7,"A",{href:!0});var H$r=s(Sx);FQe=r(H$r,"DistilBertTokenizerFast"),H$r.forEach(t),CQe=r(C7," (DistilBERT model)"),C7.forEach(t),MQe=i(y),cs=n(y,"LI",{});var M7=s(cs);fJ=n(M7,"STRONG",{});var U$r=s(fJ);EQe=r(U$r,"dpr"),U$r.forEach(t),yQe=r(M7," \u2014 "),Px=n(M7,"A",{href:!0});var J$r=s(Px);wQe=r(J$r,"DPRQuestionEncoderTokenizer"),J$r.forEach(t),AQe=r(M7," or "),$x=n(M7,"A",{href:!0});var Y$r=s($x);LQe=r(Y$r,"DPRQuestionEncoderTokenizerFast"),Y$r.forEach(t),BQe=r(M7," (DPR model)"),M7.forEach(t),xQe=i(y),fs=n(y,"LI",{});var E7=s(fs);mJ=n(E7,"STRONG",{});var K$r=s(mJ);kQe=r(K$r,"electra"),K$r.forEach(t),RQe=r(E7," \u2014 "),Ix=n(E7,"A",{href:!0});var Z$r=s(Ix);SQe=r(Z$r,"ElectraTokenizer"),Z$r.forEach(t),PQe=r(E7," or "),jx=n(E7,"A",{href:!0});var eIr=s(jx);$Qe=r(eIr,"ElectraTokenizerFast"),eIr.forEach(t),IQe=r(E7," (ELECTRA model)"),E7.forEach(t),jQe=i(y),Jg=n(y,"LI",{});var D8e=s(Jg);gJ=n(D8e,"STRONG",{});var oIr=s(gJ);DQe=r(oIr,"flaubert"),oIr.forEach(t),NQe=r(D8e," \u2014 "),Dx=n(D8e,"A",{href:!0});var rIr=s(Dx);qQe=r(rIr,"FlaubertTokenizer"),rIr.forEach(t),OQe=r(D8e," (FlauBERT model)"),D8e.forEach(t),GQe=i(y),ms=n(y,"LI",{});var y7=s(ms);hJ=n(y7,"STRONG",{});var tIr=s(hJ);XQe=r(tIr,"fnet"),tIr.forEach(t),VQe=r(y7," \u2014 "),Nx=n(y7,"A",{href:!0});var aIr=s(Nx);zQe=r(aIr,"FNetTokenizer"),aIr.forEach(t),WQe=r(y7," or "),qx=n(y7,"A",{href:!0});var nIr=s(qx);QQe=r(nIr,"FNetTokenizerFast"),nIr.forEach(t),HQe=r(y7," (FNet model)"),y7.forEach(t),UQe=i(y),Yg=n(y,"LI",{});var N8e=s(Yg);pJ=n(N8e,"STRONG",{});var sIr=s(pJ);JQe=r(sIr,"fsmt"),sIr.forEach(t),YQe=r(N8e," \u2014 "),Ox=n(N8e,"A",{href:!0});var lIr=s(Ox);KQe=r(lIr,"FSMTTokenizer"),lIr.forEach(t),ZQe=r(N8e," (FairSeq Machine-Translation model)"),N8e.forEach(t),eHe=i(y),gs=n(y,"LI",{});var w7=s(gs);_J=n(w7,"STRONG",{});var iIr=s(_J);oHe=r(iIr,"funnel"),iIr.forEach(t),rHe=r(w7," \u2014 "),Gx=n(w7,"A",{href:!0});var dIr=s(Gx);tHe=r(dIr,"FunnelTokenizer"),dIr.forEach(t),aHe=r(w7," or "),Xx=n(w7,"A",{href:!0});var cIr=s(Xx);nHe=r(cIr,"FunnelTokenizerFast"),cIr.forEach(t),sHe=r(w7," (Funnel Transformer model)"),w7.forEach(t),lHe=i(y),hs=n(y,"LI",{});var A7=s(hs);uJ=n(A7,"STRONG",{});var fIr=s(uJ);iHe=r(fIr,"gpt2"),fIr.forEach(t),dHe=r(A7," \u2014 "),Vx=n(A7,"A",{href:!0});var mIr=s(Vx);cHe=r(mIr,"GPT2Tokenizer"),mIr.forEach(t),fHe=r(A7," or "),zx=n(A7,"A",{href:!0});var gIr=s(zx);mHe=r(gIr,"GPT2TokenizerFast"),gIr.forEach(t),gHe=r(A7," (OpenAI GPT-2 model)"),A7.forEach(t),hHe=i(y),ps=n(y,"LI",{});var L7=s(ps);bJ=n(L7,"STRONG",{});var hIr=s(bJ);pHe=r(hIr,"gpt_neo"),hIr.forEach(t),_He=r(L7," \u2014 "),Wx=n(L7,"A",{href:!0});var pIr=s(Wx);uHe=r(pIr,"GPT2Tokenizer"),pIr.forEach(t),bHe=r(L7," or "),Qx=n(L7,"A",{href:!0});var _Ir=s(Qx);vHe=r(_Ir,"GPT2TokenizerFast"),_Ir.forEach(t),THe=r(L7," (GPT Neo model)"),L7.forEach(t),FHe=i(y),_s=n(y,"LI",{});var B7=s(_s);vJ=n(B7,"STRONG",{});var uIr=s(vJ);CHe=r(uIr,"herbert"),uIr.forEach(t),MHe=r(B7," \u2014 "),Hx=n(B7,"A",{href:!0});var bIr=s(Hx);EHe=r(bIr,"HerbertTokenizer"),bIr.forEach(t),yHe=r(B7," or "),Ux=n(B7,"A",{href:!0});var vIr=s(Ux);wHe=r(vIr,"HerbertTokenizerFast"),vIr.forEach(t),AHe=r(B7," (HerBERT model)"),B7.forEach(t),LHe=i(y),Kg=n(y,"LI",{});var q8e=s(Kg);TJ=n(q8e,"STRONG",{});var TIr=s(TJ);BHe=r(TIr,"hubert"),TIr.forEach(t),xHe=r(q8e," \u2014 "),Jx=n(q8e,"A",{href:!0});var FIr=s(Jx);kHe=r(FIr,"Wav2Vec2CTCTokenizer"),FIr.forEach(t),RHe=r(q8e," (Hubert model)"),q8e.forEach(t),SHe=i(y),us=n(y,"LI",{});var x7=s(us);FJ=n(x7,"STRONG",{});var CIr=s(FJ);PHe=r(CIr,"ibert"),CIr.forEach(t),$He=r(x7," \u2014 "),Yx=n(x7,"A",{href:!0});var MIr=s(Yx);IHe=r(MIr,"RobertaTokenizer"),MIr.forEach(t),jHe=r(x7," or "),Kx=n(x7,"A",{href:!0});var EIr=s(Kx);DHe=r(EIr,"RobertaTokenizerFast"),EIr.forEach(t),NHe=r(x7," (I-BERT model)"),x7.forEach(t),qHe=i(y),bs=n(y,"LI",{});var k7=s(bs);CJ=n(k7,"STRONG",{});var yIr=s(CJ);OHe=r(yIr,"layoutlm"),yIr.forEach(t),GHe=r(k7," \u2014 "),Zx=n(k7,"A",{href:!0});var wIr=s(Zx);XHe=r(wIr,"LayoutLMTokenizer"),wIr.forEach(t),VHe=r(k7," or "),ek=n(k7,"A",{href:!0});var AIr=s(ek);zHe=r(AIr,"LayoutLMTokenizerFast"),AIr.forEach(t),WHe=r(k7," (LayoutLM model)"),k7.forEach(t),QHe=i(y),vs=n(y,"LI",{});var R7=s(vs);MJ=n(R7,"STRONG",{});var LIr=s(MJ);HHe=r(LIr,"layoutlmv2"),LIr.forEach(t),UHe=r(R7," \u2014 "),ok=n(R7,"A",{href:!0});var BIr=s(ok);JHe=r(BIr,"LayoutLMv2Tokenizer"),BIr.forEach(t),YHe=r(R7," or "),rk=n(R7,"A",{href:!0});var xIr=s(rk);KHe=r(xIr,"LayoutLMv2TokenizerFast"),xIr.forEach(t),ZHe=r(R7," (LayoutLMv2 model)"),R7.forEach(t),eUe=i(y),Ts=n(y,"LI",{});var S7=s(Ts);EJ=n(S7,"STRONG",{});var kIr=s(EJ);oUe=r(kIr,"layoutxlm"),kIr.forEach(t),rUe=r(S7," \u2014 "),tk=n(S7,"A",{href:!0});var RIr=s(tk);tUe=r(RIr,"LayoutXLMTokenizer"),RIr.forEach(t),aUe=r(S7," or "),ak=n(S7,"A",{href:!0});var SIr=s(ak);nUe=r(SIr,"LayoutXLMTokenizerFast"),SIr.forEach(t),sUe=r(S7," (LayoutXLM model)"),S7.forEach(t),lUe=i(y),Fs=n(y,"LI",{});var P7=s(Fs);yJ=n(P7,"STRONG",{});var PIr=s(yJ);iUe=r(PIr,"led"),PIr.forEach(t),dUe=r(P7," \u2014 "),nk=n(P7,"A",{href:!0});var $Ir=s(nk);cUe=r($Ir,"LEDTokenizer"),$Ir.forEach(t),fUe=r(P7," or "),sk=n(P7,"A",{href:!0});var IIr=s(sk);mUe=r(IIr,"LEDTokenizerFast"),IIr.forEach(t),gUe=r(P7," (LED model)"),P7.forEach(t),hUe=i(y),Cs=n(y,"LI",{});var $7=s(Cs);wJ=n($7,"STRONG",{});var jIr=s(wJ);pUe=r(jIr,"longformer"),jIr.forEach(t),_Ue=r($7," \u2014 "),lk=n($7,"A",{href:!0});var DIr=s(lk);uUe=r(DIr,"LongformerTokenizer"),DIr.forEach(t),bUe=r($7," or "),ik=n($7,"A",{href:!0});var NIr=s(ik);vUe=r(NIr,"LongformerTokenizerFast"),NIr.forEach(t),TUe=r($7," (Longformer model)"),$7.forEach(t),FUe=i(y),Zg=n(y,"LI",{});var O8e=s(Zg);AJ=n(O8e,"STRONG",{});var qIr=s(AJ);CUe=r(qIr,"luke"),qIr.forEach(t),MUe=r(O8e," \u2014 "),dk=n(O8e,"A",{href:!0});var OIr=s(dk);EUe=r(OIr,"LukeTokenizer"),OIr.forEach(t),yUe=r(O8e," (LUKE model)"),O8e.forEach(t),wUe=i(y),Ms=n(y,"LI",{});var I7=s(Ms);LJ=n(I7,"STRONG",{});var GIr=s(LJ);AUe=r(GIr,"lxmert"),GIr.forEach(t),LUe=r(I7," \u2014 "),ck=n(I7,"A",{href:!0});var XIr=s(ck);BUe=r(XIr,"LxmertTokenizer"),XIr.forEach(t),xUe=r(I7," or "),fk=n(I7,"A",{href:!0});var VIr=s(fk);kUe=r(VIr,"LxmertTokenizerFast"),VIr.forEach(t),RUe=r(I7," (LXMERT model)"),I7.forEach(t),SUe=i(y),eh=n(y,"LI",{});var G8e=s(eh);BJ=n(G8e,"STRONG",{});var zIr=s(BJ);PUe=r(zIr,"m2m_100"),zIr.forEach(t),$Ue=r(G8e," \u2014 "),mk=n(G8e,"A",{href:!0});var WIr=s(mk);IUe=r(WIr,"M2M100Tokenizer"),WIr.forEach(t),jUe=r(G8e," (M2M100 model)"),G8e.forEach(t),DUe=i(y),oh=n(y,"LI",{});var X8e=s(oh);xJ=n(X8e,"STRONG",{});var QIr=s(xJ);NUe=r(QIr,"marian"),QIr.forEach(t),qUe=r(X8e," \u2014 "),gk=n(X8e,"A",{href:!0});var HIr=s(gk);OUe=r(HIr,"MarianTokenizer"),HIr.forEach(t),GUe=r(X8e," (Marian model)"),X8e.forEach(t),XUe=i(y),Es=n(y,"LI",{});var j7=s(Es);kJ=n(j7,"STRONG",{});var UIr=s(kJ);VUe=r(UIr,"mbart"),UIr.forEach(t),zUe=r(j7," \u2014 "),hk=n(j7,"A",{href:!0});var JIr=s(hk);WUe=r(JIr,"MBartTokenizer"),JIr.forEach(t),QUe=r(j7," or "),pk=n(j7,"A",{href:!0});var YIr=s(pk);HUe=r(YIr,"MBartTokenizerFast"),YIr.forEach(t),UUe=r(j7," (mBART model)"),j7.forEach(t),JUe=i(y),ys=n(y,"LI",{});var D7=s(ys);RJ=n(D7,"STRONG",{});var KIr=s(RJ);YUe=r(KIr,"mbart50"),KIr.forEach(t),KUe=r(D7," \u2014 "),_k=n(D7,"A",{href:!0});var ZIr=s(_k);ZUe=r(ZIr,"MBart50Tokenizer"),ZIr.forEach(t),eJe=r(D7," or "),uk=n(D7,"A",{href:!0});var ejr=s(uk);oJe=r(ejr,"MBart50TokenizerFast"),ejr.forEach(t),rJe=r(D7," (mBART-50 model)"),D7.forEach(t),tJe=i(y),rh=n(y,"LI",{});var V8e=s(rh);SJ=n(V8e,"STRONG",{});var ojr=s(SJ);aJe=r(ojr,"mluke"),ojr.forEach(t),nJe=r(V8e," \u2014 "),bk=n(V8e,"A",{href:!0});var rjr=s(bk);sJe=r(rjr,"MLukeTokenizer"),rjr.forEach(t),lJe=r(V8e," (mLUKE model)"),V8e.forEach(t),iJe=i(y),ws=n(y,"LI",{});var N7=s(ws);PJ=n(N7,"STRONG",{});var tjr=s(PJ);dJe=r(tjr,"mobilebert"),tjr.forEach(t),cJe=r(N7," \u2014 "),vk=n(N7,"A",{href:!0});var ajr=s(vk);fJe=r(ajr,"MobileBertTokenizer"),ajr.forEach(t),mJe=r(N7," or "),Tk=n(N7,"A",{href:!0});var njr=s(Tk);gJe=r(njr,"MobileBertTokenizerFast"),njr.forEach(t),hJe=r(N7," (MobileBERT model)"),N7.forEach(t),pJe=i(y),As=n(y,"LI",{});var q7=s(As);$J=n(q7,"STRONG",{});var sjr=s($J);_Je=r(sjr,"mpnet"),sjr.forEach(t),uJe=r(q7," \u2014 "),Fk=n(q7,"A",{href:!0});var ljr=s(Fk);bJe=r(ljr,"MPNetTokenizer"),ljr.forEach(t),vJe=r(q7," or "),Ck=n(q7,"A",{href:!0});var ijr=s(Ck);TJe=r(ijr,"MPNetTokenizerFast"),ijr.forEach(t),FJe=r(q7," (MPNet model)"),q7.forEach(t),CJe=i(y),Ls=n(y,"LI",{});var O7=s(Ls);IJ=n(O7,"STRONG",{});var djr=s(IJ);MJe=r(djr,"mt5"),djr.forEach(t),EJe=r(O7," \u2014 "),Mk=n(O7,"A",{href:!0});var cjr=s(Mk);yJe=r(cjr,"MT5Tokenizer"),cjr.forEach(t),wJe=r(O7," or "),Ek=n(O7,"A",{href:!0});var fjr=s(Ek);AJe=r(fjr,"MT5TokenizerFast"),fjr.forEach(t),LJe=r(O7," (mT5 model)"),O7.forEach(t),BJe=i(y),Bs=n(y,"LI",{});var G7=s(Bs);jJ=n(G7,"STRONG",{});var mjr=s(jJ);xJe=r(mjr,"openai-gpt"),mjr.forEach(t),kJe=r(G7," \u2014 "),yk=n(G7,"A",{href:!0});var gjr=s(yk);RJe=r(gjr,"OpenAIGPTTokenizer"),gjr.forEach(t),SJe=r(G7," or "),wk=n(G7,"A",{href:!0});var hjr=s(wk);PJe=r(hjr,"OpenAIGPTTokenizerFast"),hjr.forEach(t),$Je=r(G7," (OpenAI GPT model)"),G7.forEach(t),IJe=i(y),xs=n(y,"LI",{});var X7=s(xs);DJ=n(X7,"STRONG",{});var pjr=s(DJ);jJe=r(pjr,"pegasus"),pjr.forEach(t),DJe=r(X7," \u2014 "),Ak=n(X7,"A",{href:!0});var _jr=s(Ak);NJe=r(_jr,"PegasusTokenizer"),_jr.forEach(t),qJe=r(X7," or "),Lk=n(X7,"A",{href:!0});var ujr=s(Lk);OJe=r(ujr,"PegasusTokenizerFast"),ujr.forEach(t),GJe=r(X7," (Pegasus model)"),X7.forEach(t),XJe=i(y),th=n(y,"LI",{});var z8e=s(th);NJ=n(z8e,"STRONG",{});var bjr=s(NJ);VJe=r(bjr,"perceiver"),bjr.forEach(t),zJe=r(z8e," \u2014 "),Bk=n(z8e,"A",{href:!0});var vjr=s(Bk);WJe=r(vjr,"PerceiverTokenizer"),vjr.forEach(t),QJe=r(z8e," (Perceiver model)"),z8e.forEach(t),HJe=i(y),ah=n(y,"LI",{});var W8e=s(ah);qJ=n(W8e,"STRONG",{});var Tjr=s(qJ);UJe=r(Tjr,"phobert"),Tjr.forEach(t),JJe=r(W8e," \u2014 "),xk=n(W8e,"A",{href:!0});var Fjr=s(xk);YJe=r(Fjr,"PhobertTokenizer"),Fjr.forEach(t),KJe=r(W8e," (PhoBERT model)"),W8e.forEach(t),ZJe=i(y),nh=n(y,"LI",{});var Q8e=s(nh);OJ=n(Q8e,"STRONG",{});var Cjr=s(OJ);eYe=r(Cjr,"plbart"),Cjr.forEach(t),oYe=r(Q8e," \u2014 "),kk=n(Q8e,"A",{href:!0});var Mjr=s(kk);rYe=r(Mjr,"PLBartTokenizer"),Mjr.forEach(t),tYe=r(Q8e," (PLBart model)"),Q8e.forEach(t),aYe=i(y),sh=n(y,"LI",{});var H8e=s(sh);GJ=n(H8e,"STRONG",{});var Ejr=s(GJ);nYe=r(Ejr,"prophetnet"),Ejr.forEach(t),sYe=r(H8e," \u2014 "),Rk=n(H8e,"A",{href:!0});var yjr=s(Rk);lYe=r(yjr,"ProphetNetTokenizer"),yjr.forEach(t),iYe=r(H8e," (ProphetNet model)"),H8e.forEach(t),dYe=i(y),ks=n(y,"LI",{});var V7=s(ks);XJ=n(V7,"STRONG",{});var wjr=s(XJ);cYe=r(wjr,"qdqbert"),wjr.forEach(t),fYe=r(V7," \u2014 "),Sk=n(V7,"A",{href:!0});var Ajr=s(Sk);mYe=r(Ajr,"BertTokenizer"),Ajr.forEach(t),gYe=r(V7," or "),Pk=n(V7,"A",{href:!0});var Ljr=s(Pk);hYe=r(Ljr,"BertTokenizerFast"),Ljr.forEach(t),pYe=r(V7," (QDQBert model)"),V7.forEach(t),_Ye=i(y),lh=n(y,"LI",{});var U8e=s(lh);VJ=n(U8e,"STRONG",{});var Bjr=s(VJ);uYe=r(Bjr,"rag"),Bjr.forEach(t),bYe=r(U8e," \u2014 "),$k=n(U8e,"A",{href:!0});var xjr=s($k);vYe=r(xjr,"RagTokenizer"),xjr.forEach(t),TYe=r(U8e," (RAG model)"),U8e.forEach(t),FYe=i(y),Rs=n(y,"LI",{});var z7=s(Rs);zJ=n(z7,"STRONG",{});var kjr=s(zJ);CYe=r(kjr,"realm"),kjr.forEach(t),MYe=r(z7," \u2014 "),Ik=n(z7,"A",{href:!0});var Rjr=s(Ik);EYe=r(Rjr,"RealmTokenizer"),Rjr.forEach(t),yYe=r(z7," or "),jk=n(z7,"A",{href:!0});var Sjr=s(jk);wYe=r(Sjr,"RealmTokenizerFast"),Sjr.forEach(t),AYe=r(z7," (Realm model)"),z7.forEach(t),LYe=i(y),Ss=n(y,"LI",{});var W7=s(Ss);WJ=n(W7,"STRONG",{});var Pjr=s(WJ);BYe=r(Pjr,"reformer"),Pjr.forEach(t),xYe=r(W7," \u2014 "),Dk=n(W7,"A",{href:!0});var $jr=s(Dk);kYe=r($jr,"ReformerTokenizer"),$jr.forEach(t),RYe=r(W7," or "),Nk=n(W7,"A",{href:!0});var Ijr=s(Nk);SYe=r(Ijr,"ReformerTokenizerFast"),Ijr.forEach(t),PYe=r(W7," (Reformer model)"),W7.forEach(t),$Ye=i(y),Ps=n(y,"LI",{});var Q7=s(Ps);QJ=n(Q7,"STRONG",{});var jjr=s(QJ);IYe=r(jjr,"rembert"),jjr.forEach(t),jYe=r(Q7," \u2014 "),qk=n(Q7,"A",{href:!0});var Djr=s(qk);DYe=r(Djr,"RemBertTokenizer"),Djr.forEach(t),NYe=r(Q7," or "),Ok=n(Q7,"A",{href:!0});var Njr=s(Ok);qYe=r(Njr,"RemBertTokenizerFast"),Njr.forEach(t),OYe=r(Q7," (RemBERT model)"),Q7.forEach(t),GYe=i(y),$s=n(y,"LI",{});var H7=s($s);HJ=n(H7,"STRONG",{});var qjr=s(HJ);XYe=r(qjr,"retribert"),qjr.forEach(t),VYe=r(H7," \u2014 "),Gk=n(H7,"A",{href:!0});var Ojr=s(Gk);zYe=r(Ojr,"RetriBertTokenizer"),Ojr.forEach(t),WYe=r(H7," or "),Xk=n(H7,"A",{href:!0});var Gjr=s(Xk);QYe=r(Gjr,"RetriBertTokenizerFast"),Gjr.forEach(t),HYe=r(H7," (RetriBERT model)"),H7.forEach(t),UYe=i(y),Is=n(y,"LI",{});var U7=s(Is);UJ=n(U7,"STRONG",{});var Xjr=s(UJ);JYe=r(Xjr,"roberta"),Xjr.forEach(t),YYe=r(U7," \u2014 "),Vk=n(U7,"A",{href:!0});var Vjr=s(Vk);KYe=r(Vjr,"RobertaTokenizer"),Vjr.forEach(t),ZYe=r(U7," or "),zk=n(U7,"A",{href:!0});var zjr=s(zk);eKe=r(zjr,"RobertaTokenizerFast"),zjr.forEach(t),oKe=r(U7," (RoBERTa model)"),U7.forEach(t),rKe=i(y),js=n(y,"LI",{});var J7=s(js);JJ=n(J7,"STRONG",{});var Wjr=s(JJ);tKe=r(Wjr,"roformer"),Wjr.forEach(t),aKe=r(J7," \u2014 "),Wk=n(J7,"A",{href:!0});var Qjr=s(Wk);nKe=r(Qjr,"RoFormerTokenizer"),Qjr.forEach(t),sKe=r(J7," or "),Qk=n(J7,"A",{href:!0});var Hjr=s(Qk);lKe=r(Hjr,"RoFormerTokenizerFast"),Hjr.forEach(t),iKe=r(J7," (RoFormer model)"),J7.forEach(t),dKe=i(y),ih=n(y,"LI",{});var J8e=s(ih);YJ=n(J8e,"STRONG",{});var Ujr=s(YJ);cKe=r(Ujr,"speech_to_text"),Ujr.forEach(t),fKe=r(J8e," \u2014 "),Hk=n(J8e,"A",{href:!0});var Jjr=s(Hk);mKe=r(Jjr,"Speech2TextTokenizer"),Jjr.forEach(t),gKe=r(J8e," (Speech2Text model)"),J8e.forEach(t),hKe=i(y),dh=n(y,"LI",{});var Y8e=s(dh);KJ=n(Y8e,"STRONG",{});var Yjr=s(KJ);pKe=r(Yjr,"speech_to_text_2"),Yjr.forEach(t),_Ke=r(Y8e," \u2014 "),Uk=n(Y8e,"A",{href:!0});var Kjr=s(Uk);uKe=r(Kjr,"Speech2Text2Tokenizer"),Kjr.forEach(t),bKe=r(Y8e," (Speech2Text2 model)"),Y8e.forEach(t),vKe=i(y),Ds=n(y,"LI",{});var Y7=s(Ds);ZJ=n(Y7,"STRONG",{});var Zjr=s(ZJ);TKe=r(Zjr,"splinter"),Zjr.forEach(t),FKe=r(Y7," \u2014 "),Jk=n(Y7,"A",{href:!0});var eDr=s(Jk);CKe=r(eDr,"SplinterTokenizer"),eDr.forEach(t),MKe=r(Y7," or "),Yk=n(Y7,"A",{href:!0});var oDr=s(Yk);EKe=r(oDr,"SplinterTokenizerFast"),oDr.forEach(t),yKe=r(Y7," (Splinter model)"),Y7.forEach(t),wKe=i(y),Ns=n(y,"LI",{});var K7=s(Ns);eY=n(K7,"STRONG",{});var rDr=s(eY);AKe=r(rDr,"squeezebert"),rDr.forEach(t),LKe=r(K7," \u2014 "),Kk=n(K7,"A",{href:!0});var tDr=s(Kk);BKe=r(tDr,"SqueezeBertTokenizer"),tDr.forEach(t),xKe=r(K7," or "),Zk=n(K7,"A",{href:!0});var aDr=s(Zk);kKe=r(aDr,"SqueezeBertTokenizerFast"),aDr.forEach(t),RKe=r(K7," (SqueezeBERT model)"),K7.forEach(t),SKe=i(y),qs=n(y,"LI",{});var Z7=s(qs);oY=n(Z7,"STRONG",{});var nDr=s(oY);PKe=r(nDr,"t5"),nDr.forEach(t),$Ke=r(Z7," \u2014 "),eR=n(Z7,"A",{href:!0});var sDr=s(eR);IKe=r(sDr,"T5Tokenizer"),sDr.forEach(t),jKe=r(Z7," or "),oR=n(Z7,"A",{href:!0});var lDr=s(oR);DKe=r(lDr,"T5TokenizerFast"),lDr.forEach(t),NKe=r(Z7," (T5 model)"),Z7.forEach(t),qKe=i(y),ch=n(y,"LI",{});var K8e=s(ch);rY=n(K8e,"STRONG",{});var iDr=s(rY);OKe=r(iDr,"tapas"),iDr.forEach(t),GKe=r(K8e," \u2014 "),rR=n(K8e,"A",{href:!0});var dDr=s(rR);XKe=r(dDr,"TapasTokenizer"),dDr.forEach(t),VKe=r(K8e," (TAPAS model)"),K8e.forEach(t),zKe=i(y),fh=n(y,"LI",{});var Z8e=s(fh);tY=n(Z8e,"STRONG",{});var cDr=s(tY);WKe=r(cDr,"transfo-xl"),cDr.forEach(t),QKe=r(Z8e," \u2014 "),tR=n(Z8e,"A",{href:!0});var fDr=s(tR);HKe=r(fDr,"TransfoXLTokenizer"),fDr.forEach(t),UKe=r(Z8e," (Transformer-XL model)"),Z8e.forEach(t),JKe=i(y),mh=n(y,"LI",{});var eFe=s(mh);aY=n(eFe,"STRONG",{});var mDr=s(aY);YKe=r(mDr,"wav2vec2"),mDr.forEach(t),KKe=r(eFe," \u2014 "),aR=n(eFe,"A",{href:!0});var gDr=s(aR);ZKe=r(gDr,"Wav2Vec2CTCTokenizer"),gDr.forEach(t),eZe=r(eFe," (Wav2Vec2 model)"),eFe.forEach(t),oZe=i(y),gh=n(y,"LI",{});var oFe=s(gh);nY=n(oFe,"STRONG",{});var hDr=s(nY);rZe=r(hDr,"wav2vec2_phoneme"),hDr.forEach(t),tZe=r(oFe," \u2014 "),nR=n(oFe,"A",{href:!0});var pDr=s(nR);aZe=r(pDr,"Wav2Vec2PhonemeCTCTokenizer"),pDr.forEach(t),nZe=r(oFe," (Wav2Vec2Phoneme model)"),oFe.forEach(t),sZe=i(y),Os=n(y,"LI",{});var e9=s(Os);sY=n(e9,"STRONG",{});var _Dr=s(sY);lZe=r(_Dr,"xglm"),_Dr.forEach(t),iZe=r(e9," \u2014 "),sR=n(e9,"A",{href:!0});var uDr=s(sR);dZe=r(uDr,"XGLMTokenizer"),uDr.forEach(t),cZe=r(e9," or "),lR=n(e9,"A",{href:!0});var bDr=s(lR);fZe=r(bDr,"XGLMTokenizerFast"),bDr.forEach(t),mZe=r(e9," (XGLM model)"),e9.forEach(t),gZe=i(y),hh=n(y,"LI",{});var rFe=s(hh);lY=n(rFe,"STRONG",{});var vDr=s(lY);hZe=r(vDr,"xlm"),vDr.forEach(t),pZe=r(rFe," \u2014 "),iR=n(rFe,"A",{href:!0});var TDr=s(iR);_Ze=r(TDr,"XLMTokenizer"),TDr.forEach(t),uZe=r(rFe," (XLM model)"),rFe.forEach(t),bZe=i(y),ph=n(y,"LI",{});var tFe=s(ph);iY=n(tFe,"STRONG",{});var FDr=s(iY);vZe=r(FDr,"xlm-prophetnet"),FDr.forEach(t),TZe=r(tFe," \u2014 "),dR=n(tFe,"A",{href:!0});var CDr=s(dR);FZe=r(CDr,"XLMProphetNetTokenizer"),CDr.forEach(t),CZe=r(tFe," (XLMProphetNet model)"),tFe.forEach(t),MZe=i(y),Gs=n(y,"LI",{});var o9=s(Gs);dY=n(o9,"STRONG",{});var MDr=s(dY);EZe=r(MDr,"xlm-roberta"),MDr.forEach(t),yZe=r(o9," \u2014 "),cR=n(o9,"A",{href:!0});var EDr=s(cR);wZe=r(EDr,"XLMRobertaTokenizer"),EDr.forEach(t),AZe=r(o9," or "),fR=n(o9,"A",{href:!0});var yDr=s(fR);LZe=r(yDr,"XLMRobertaTokenizerFast"),yDr.forEach(t),BZe=r(o9," (XLM-RoBERTa model)"),o9.forEach(t),xZe=i(y),Xs=n(y,"LI",{});var r9=s(Xs);cY=n(r9,"STRONG",{});var wDr=s(cY);kZe=r(wDr,"xlnet"),wDr.forEach(t),RZe=r(r9," \u2014 "),mR=n(r9,"A",{href:!0});var ADr=s(mR);SZe=r(ADr,"XLNetTokenizer"),ADr.forEach(t),PZe=r(r9," or "),gR=n(r9,"A",{href:!0});var LDr=s(gR);$Ze=r(LDr,"XLNetTokenizerFast"),LDr.forEach(t),IZe=r(r9," (XLNet model)"),r9.forEach(t),y.forEach(t),jZe=i(ua),fY=n(ua,"P",{});var BDr=s(fY);DZe=r(BDr,"Examples:"),BDr.forEach(t),NZe=i(ua),m(E4.$$.fragment,ua),ua.forEach(t),qZe=i(Hs),_h=n(Hs,"DIV",{class:!0});var lSe=s(_h);m(y4.$$.fragment,lSe),OZe=i(lSe),mY=n(lSe,"P",{});var xDr=s(mY);GZe=r(xDr,"Register a new tokenizer in this mapping."),xDr.forEach(t),lSe.forEach(t),Hs.forEach(t),oke=i(d),od=n(d,"H2",{class:!0});var iSe=s(od);uh=n(iSe,"A",{id:!0,class:!0,href:!0});var kDr=s(uh);gY=n(kDr,"SPAN",{});var RDr=s(gY);m(w4.$$.fragment,RDr),RDr.forEach(t),kDr.forEach(t),XZe=i(iSe),hY=n(iSe,"SPAN",{});var SDr=s(hY);VZe=r(SDr,"AutoFeatureExtractor"),SDr.forEach(t),iSe.forEach(t),rke=i(d),Uo=n(d,"DIV",{class:!0});var Us=s(Uo);m(A4.$$.fragment,Us),zZe=i(Us),L4=n(Us,"P",{});var dSe=s(L4);WZe=r(dSe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),hR=n(dSe,"A",{href:!0});var PDr=s(hR);QZe=r(PDr,"AutoFeatureExtractor.from_pretrained()"),PDr.forEach(t),HZe=r(dSe," class method."),dSe.forEach(t),UZe=i(Us),B4=n(Us,"P",{});var cSe=s(B4);JZe=r(cSe,"This class cannot be instantiated directly using "),pY=n(cSe,"CODE",{});var $Dr=s(pY);YZe=r($Dr,"__init__()"),$Dr.forEach(t),KZe=r(cSe," (throws an error)."),cSe.forEach(t),ZZe=i(Us),$e=n(Us,"DIV",{class:!0});var Ot=s($e);m(x4.$$.fragment,Ot),eeo=i(Ot),_Y=n(Ot,"P",{});var IDr=s(_Y);oeo=r(IDr,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),IDr.forEach(t),reo=i(Ot),Qa=n(Ot,"P",{});var iM=s(Qa);teo=r(iM,"The feature extractor class to instantiate is selected based on the "),uY=n(iM,"CODE",{});var jDr=s(uY);aeo=r(jDr,"model_type"),jDr.forEach(t),neo=r(iM,` property of the config object
(either passed as an argument or loaded from `),bY=n(iM,"CODE",{});var DDr=s(bY);seo=r(DDr,"pretrained_model_name_or_path"),DDr.forEach(t),leo=r(iM,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),vY=n(iM,"CODE",{});var NDr=s(vY);ieo=r(NDr,"pretrained_model_name_or_path"),NDr.forEach(t),deo=r(iM,":"),iM.forEach(t),ceo=i(Ot),ae=n(Ot,"UL",{});var le=s(ae);bh=n(le,"LI",{});var aFe=s(bh);TY=n(aFe,"STRONG",{});var qDr=s(TY);feo=r(qDr,"beit"),qDr.forEach(t),meo=r(aFe," \u2014 "),pR=n(aFe,"A",{href:!0});var ODr=s(pR);geo=r(ODr,"BeitFeatureExtractor"),ODr.forEach(t),heo=r(aFe," (BEiT model)"),aFe.forEach(t),peo=i(le),vh=n(le,"LI",{});var nFe=s(vh);FY=n(nFe,"STRONG",{});var GDr=s(FY);_eo=r(GDr,"clip"),GDr.forEach(t),ueo=r(nFe," \u2014 "),_R=n(nFe,"A",{href:!0});var XDr=s(_R);beo=r(XDr,"CLIPFeatureExtractor"),XDr.forEach(t),veo=r(nFe," (CLIP model)"),nFe.forEach(t),Teo=i(le),Th=n(le,"LI",{});var sFe=s(Th);CY=n(sFe,"STRONG",{});var VDr=s(CY);Feo=r(VDr,"convnext"),VDr.forEach(t),Ceo=r(sFe," \u2014 "),uR=n(sFe,"A",{href:!0});var zDr=s(uR);Meo=r(zDr,"ConvNextFeatureExtractor"),zDr.forEach(t),Eeo=r(sFe," (ConvNext model)"),sFe.forEach(t),yeo=i(le),Fh=n(le,"LI",{});var lFe=s(Fh);MY=n(lFe,"STRONG",{});var WDr=s(MY);weo=r(WDr,"deit"),WDr.forEach(t),Aeo=r(lFe," \u2014 "),bR=n(lFe,"A",{href:!0});var QDr=s(bR);Leo=r(QDr,"DeiTFeatureExtractor"),QDr.forEach(t),Beo=r(lFe," (DeiT model)"),lFe.forEach(t),xeo=i(le),Ch=n(le,"LI",{});var iFe=s(Ch);EY=n(iFe,"STRONG",{});var HDr=s(EY);keo=r(HDr,"detr"),HDr.forEach(t),Reo=r(iFe," \u2014 "),vR=n(iFe,"A",{href:!0});var UDr=s(vR);Seo=r(UDr,"DetrFeatureExtractor"),UDr.forEach(t),Peo=r(iFe," (DETR model)"),iFe.forEach(t),$eo=i(le),Mh=n(le,"LI",{});var dFe=s(Mh);yY=n(dFe,"STRONG",{});var JDr=s(yY);Ieo=r(JDr,"hubert"),JDr.forEach(t),jeo=r(dFe," \u2014 "),TR=n(dFe,"A",{href:!0});var YDr=s(TR);Deo=r(YDr,"Wav2Vec2FeatureExtractor"),YDr.forEach(t),Neo=r(dFe," (Hubert model)"),dFe.forEach(t),qeo=i(le),Eh=n(le,"LI",{});var cFe=s(Eh);wY=n(cFe,"STRONG",{});var KDr=s(wY);Oeo=r(KDr,"layoutlmv2"),KDr.forEach(t),Geo=r(cFe," \u2014 "),FR=n(cFe,"A",{href:!0});var ZDr=s(FR);Xeo=r(ZDr,"LayoutLMv2FeatureExtractor"),ZDr.forEach(t),Veo=r(cFe," (LayoutLMv2 model)"),cFe.forEach(t),zeo=i(le),yh=n(le,"LI",{});var fFe=s(yh);AY=n(fFe,"STRONG",{});var eNr=s(AY);Weo=r(eNr,"maskformer"),eNr.forEach(t),Qeo=r(fFe," \u2014 "),CR=n(fFe,"A",{href:!0});var oNr=s(CR);Heo=r(oNr,"MaskFormerFeatureExtractor"),oNr.forEach(t),Ueo=r(fFe," (MaskFormer model)"),fFe.forEach(t),Jeo=i(le),wh=n(le,"LI",{});var mFe=s(wh);LY=n(mFe,"STRONG",{});var rNr=s(LY);Yeo=r(rNr,"perceiver"),rNr.forEach(t),Keo=r(mFe," \u2014 "),MR=n(mFe,"A",{href:!0});var tNr=s(MR);Zeo=r(tNr,"PerceiverFeatureExtractor"),tNr.forEach(t),eoo=r(mFe," (Perceiver model)"),mFe.forEach(t),ooo=i(le),Ah=n(le,"LI",{});var gFe=s(Ah);BY=n(gFe,"STRONG",{});var aNr=s(BY);roo=r(aNr,"poolformer"),aNr.forEach(t),too=r(gFe," \u2014 "),ER=n(gFe,"A",{href:!0});var nNr=s(ER);aoo=r(nNr,"PoolFormerFeatureExtractor"),nNr.forEach(t),noo=r(gFe," (PoolFormer model)"),gFe.forEach(t),soo=i(le),Lh=n(le,"LI",{});var hFe=s(Lh);xY=n(hFe,"STRONG",{});var sNr=s(xY);loo=r(sNr,"segformer"),sNr.forEach(t),ioo=r(hFe," \u2014 "),yR=n(hFe,"A",{href:!0});var lNr=s(yR);doo=r(lNr,"SegformerFeatureExtractor"),lNr.forEach(t),coo=r(hFe," (SegFormer model)"),hFe.forEach(t),foo=i(le),Bh=n(le,"LI",{});var pFe=s(Bh);kY=n(pFe,"STRONG",{});var iNr=s(kY);moo=r(iNr,"speech_to_text"),iNr.forEach(t),goo=r(pFe," \u2014 "),wR=n(pFe,"A",{href:!0});var dNr=s(wR);hoo=r(dNr,"Speech2TextFeatureExtractor"),dNr.forEach(t),poo=r(pFe," (Speech2Text model)"),pFe.forEach(t),_oo=i(le),xh=n(le,"LI",{});var _Fe=s(xh);RY=n(_Fe,"STRONG",{});var cNr=s(RY);uoo=r(cNr,"swin"),cNr.forEach(t),boo=r(_Fe," \u2014 "),AR=n(_Fe,"A",{href:!0});var fNr=s(AR);voo=r(fNr,"ViTFeatureExtractor"),fNr.forEach(t),Too=r(_Fe," (Swin model)"),_Fe.forEach(t),Foo=i(le),kh=n(le,"LI",{});var uFe=s(kh);SY=n(uFe,"STRONG",{});var mNr=s(SY);Coo=r(mNr,"vit"),mNr.forEach(t),Moo=r(uFe," \u2014 "),LR=n(uFe,"A",{href:!0});var gNr=s(LR);Eoo=r(gNr,"ViTFeatureExtractor"),gNr.forEach(t),yoo=r(uFe," (ViT model)"),uFe.forEach(t),woo=i(le),Rh=n(le,"LI",{});var bFe=s(Rh);PY=n(bFe,"STRONG",{});var hNr=s(PY);Aoo=r(hNr,"vit_mae"),hNr.forEach(t),Loo=r(bFe," \u2014 "),BR=n(bFe,"A",{href:!0});var pNr=s(BR);Boo=r(pNr,"ViTFeatureExtractor"),pNr.forEach(t),xoo=r(bFe," (ViTMAE model)"),bFe.forEach(t),koo=i(le),Sh=n(le,"LI",{});var vFe=s(Sh);$Y=n(vFe,"STRONG",{});var _Nr=s($Y);Roo=r(_Nr,"wav2vec2"),_Nr.forEach(t),Soo=r(vFe," \u2014 "),xR=n(vFe,"A",{href:!0});var uNr=s(xR);Poo=r(uNr,"Wav2Vec2FeatureExtractor"),uNr.forEach(t),$oo=r(vFe," (Wav2Vec2 model)"),vFe.forEach(t),le.forEach(t),Ioo=i(Ot),m(Ph.$$.fragment,Ot),joo=i(Ot),IY=n(Ot,"P",{});var bNr=s(IY);Doo=r(bNr,"Examples:"),bNr.forEach(t),Noo=i(Ot),m(k4.$$.fragment,Ot),Ot.forEach(t),qoo=i(Us),$h=n(Us,"DIV",{class:!0});var fSe=s($h);m(R4.$$.fragment,fSe),Ooo=i(fSe),jY=n(fSe,"P",{});var vNr=s(jY);Goo=r(vNr,"Register a new feature extractor for this class."),vNr.forEach(t),fSe.forEach(t),Us.forEach(t),tke=i(d),rd=n(d,"H2",{class:!0});var mSe=s(rd);Ih=n(mSe,"A",{id:!0,class:!0,href:!0});var TNr=s(Ih);DY=n(TNr,"SPAN",{});var FNr=s(DY);m(S4.$$.fragment,FNr),FNr.forEach(t),TNr.forEach(t),Xoo=i(mSe),NY=n(mSe,"SPAN",{});var CNr=s(NY);Voo=r(CNr,"AutoProcessor"),CNr.forEach(t),mSe.forEach(t),ake=i(d),Jo=n(d,"DIV",{class:!0});var Js=s(Jo);m(P4.$$.fragment,Js),zoo=i(Js),$4=n(Js,"P",{});var gSe=s($4);Woo=r(gSe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),kR=n(gSe,"A",{href:!0});var MNr=s(kR);Qoo=r(MNr,"AutoProcessor.from_pretrained()"),MNr.forEach(t),Hoo=r(gSe," class method."),gSe.forEach(t),Uoo=i(Js),I4=n(Js,"P",{});var hSe=s(I4);Joo=r(hSe,"This class cannot be instantiated directly using "),qY=n(hSe,"CODE",{});var ENr=s(qY);Yoo=r(ENr,"__init__()"),ENr.forEach(t),Koo=r(hSe," (throws an error)."),hSe.forEach(t),Zoo=i(Js),Ie=n(Js,"DIV",{class:!0});var Gt=s(Ie);m(j4.$$.fragment,Gt),ero=i(Gt),OY=n(Gt,"P",{});var yNr=s(OY);oro=r(yNr,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),yNr.forEach(t),rro=i(Gt),td=n(Gt,"P",{});var zz=s(td);tro=r(zz,"The processor class to instantiate is selected based on the "),GY=n(zz,"CODE",{});var wNr=s(GY);aro=r(wNr,"model_type"),wNr.forEach(t),nro=r(zz,` property of the config object (either
passed as an argument or loaded from `),XY=n(zz,"CODE",{});var ANr=s(XY);sro=r(ANr,"pretrained_model_name_or_path"),ANr.forEach(t),lro=r(zz," if possible):"),zz.forEach(t),iro=i(Gt),Be=n(Gt,"UL",{});var qo=s(Be);jh=n(qo,"LI",{});var TFe=s(jh);VY=n(TFe,"STRONG",{});var LNr=s(VY);dro=r(LNr,"clip"),LNr.forEach(t),cro=r(TFe," \u2014 "),RR=n(TFe,"A",{href:!0});var BNr=s(RR);fro=r(BNr,"CLIPProcessor"),BNr.forEach(t),mro=r(TFe," (CLIP model)"),TFe.forEach(t),gro=i(qo),Dh=n(qo,"LI",{});var FFe=s(Dh);zY=n(FFe,"STRONG",{});var xNr=s(zY);hro=r(xNr,"layoutlmv2"),xNr.forEach(t),pro=r(FFe," \u2014 "),SR=n(FFe,"A",{href:!0});var kNr=s(SR);_ro=r(kNr,"LayoutLMv2Processor"),kNr.forEach(t),uro=r(FFe," (LayoutLMv2 model)"),FFe.forEach(t),bro=i(qo),Nh=n(qo,"LI",{});var CFe=s(Nh);WY=n(CFe,"STRONG",{});var RNr=s(WY);vro=r(RNr,"layoutxlm"),RNr.forEach(t),Tro=r(CFe," \u2014 "),PR=n(CFe,"A",{href:!0});var SNr=s(PR);Fro=r(SNr,"LayoutXLMProcessor"),SNr.forEach(t),Cro=r(CFe," (LayoutXLM model)"),CFe.forEach(t),Mro=i(qo),qh=n(qo,"LI",{});var MFe=s(qh);QY=n(MFe,"STRONG",{});var PNr=s(QY);Ero=r(PNr,"speech_to_text"),PNr.forEach(t),yro=r(MFe," \u2014 "),$R=n(MFe,"A",{href:!0});var $Nr=s($R);wro=r($Nr,"Speech2TextProcessor"),$Nr.forEach(t),Aro=r(MFe," (Speech2Text model)"),MFe.forEach(t),Lro=i(qo),Oh=n(qo,"LI",{});var EFe=s(Oh);HY=n(EFe,"STRONG",{});var INr=s(HY);Bro=r(INr,"speech_to_text_2"),INr.forEach(t),xro=r(EFe," \u2014 "),IR=n(EFe,"A",{href:!0});var jNr=s(IR);kro=r(jNr,"Speech2Text2Processor"),jNr.forEach(t),Rro=r(EFe," (Speech2Text2 model)"),EFe.forEach(t),Sro=i(qo),Gh=n(qo,"LI",{});var yFe=s(Gh);UY=n(yFe,"STRONG",{});var DNr=s(UY);Pro=r(DNr,"trocr"),DNr.forEach(t),$ro=r(yFe," \u2014 "),jR=n(yFe,"A",{href:!0});var NNr=s(jR);Iro=r(NNr,"TrOCRProcessor"),NNr.forEach(t),jro=r(yFe," (TrOCR model)"),yFe.forEach(t),Dro=i(qo),Xh=n(qo,"LI",{});var wFe=s(Xh);JY=n(wFe,"STRONG",{});var qNr=s(JY);Nro=r(qNr,"vision-text-dual-encoder"),qNr.forEach(t),qro=r(wFe," \u2014 "),DR=n(wFe,"A",{href:!0});var ONr=s(DR);Oro=r(ONr,"VisionTextDualEncoderProcessor"),ONr.forEach(t),Gro=r(wFe," (VisionTextDualEncoder model)"),wFe.forEach(t),Xro=i(qo),Vh=n(qo,"LI",{});var AFe=s(Vh);YY=n(AFe,"STRONG",{});var GNr=s(YY);Vro=r(GNr,"wav2vec2"),GNr.forEach(t),zro=r(AFe," \u2014 "),NR=n(AFe,"A",{href:!0});var XNr=s(NR);Wro=r(XNr,"Wav2Vec2Processor"),XNr.forEach(t),Qro=r(AFe," (Wav2Vec2 model)"),AFe.forEach(t),qo.forEach(t),Hro=i(Gt),m(zh.$$.fragment,Gt),Uro=i(Gt),KY=n(Gt,"P",{});var VNr=s(KY);Jro=r(VNr,"Examples:"),VNr.forEach(t),Yro=i(Gt),m(D4.$$.fragment,Gt),Gt.forEach(t),Kro=i(Js),Wh=n(Js,"DIV",{class:!0});var pSe=s(Wh);m(N4.$$.fragment,pSe),Zro=i(pSe),ZY=n(pSe,"P",{});var zNr=s(ZY);eto=r(zNr,"Register a new processor for this class."),zNr.forEach(t),pSe.forEach(t),Js.forEach(t),nke=i(d),ad=n(d,"H2",{class:!0});var _Se=s(ad);Qh=n(_Se,"A",{id:!0,class:!0,href:!0});var WNr=s(Qh);eK=n(WNr,"SPAN",{});var QNr=s(eK);m(q4.$$.fragment,QNr),QNr.forEach(t),WNr.forEach(t),oto=i(_Se),oK=n(_Se,"SPAN",{});var HNr=s(oK);rto=r(HNr,"AutoModel"),HNr.forEach(t),_Se.forEach(t),ske=i(d),Yo=n(d,"DIV",{class:!0});var Ys=s(Yo);m(O4.$$.fragment,Ys),tto=i(Ys),nd=n(Ys,"P",{});var Wz=s(nd);ato=r(Wz,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rK=n(Wz,"CODE",{});var UNr=s(rK);nto=r(UNr,"from_pretrained()"),UNr.forEach(t),sto=r(Wz,"class method or the "),tK=n(Wz,"CODE",{});var JNr=s(tK);lto=r(JNr,"from_config()"),JNr.forEach(t),ito=r(Wz,`class
method.`),Wz.forEach(t),dto=i(Ys),G4=n(Ys,"P",{});var uSe=s(G4);cto=r(uSe,"This class cannot be instantiated directly using "),aK=n(uSe,"CODE",{});var YNr=s(aK);fto=r(YNr,"__init__()"),YNr.forEach(t),mto=r(uSe," (throws an error)."),uSe.forEach(t),gto=i(Ys),Wr=n(Ys,"DIV",{class:!0});var Ks=s(Wr);m(X4.$$.fragment,Ks),hto=i(Ks),nK=n(Ks,"P",{});var KNr=s(nK);pto=r(KNr,"Instantiates one of the base model classes of the library from a configuration."),KNr.forEach(t),_to=i(Ks),sd=n(Ks,"P",{});var Qz=s(sd);uto=r(Qz,`Note:
Loading a model from its configuration file does `),sK=n(Qz,"STRONG",{});var ZNr=s(sK);bto=r(ZNr,"not"),ZNr.forEach(t),vto=r(Qz,` load the model weights. It only affects the
model\u2019s configuration. Use `),lK=n(Qz,"CODE",{});var eqr=s(lK);Tto=r(eqr,"from_pretrained()"),eqr.forEach(t),Fto=r(Qz,"to load the model weights."),Qz.forEach(t),Cto=i(Ks),iK=n(Ks,"P",{});var oqr=s(iK);Mto=r(oqr,"Examples:"),oqr.forEach(t),Eto=i(Ks),m(V4.$$.fragment,Ks),Ks.forEach(t),yto=i(Ys),je=n(Ys,"DIV",{class:!0});var Xt=s(je);m(z4.$$.fragment,Xt),wto=i(Xt),dK=n(Xt,"P",{});var rqr=s(dK);Ato=r(rqr,"Instantiate one of the base model classes of the library from a pretrained model."),rqr.forEach(t),Lto=i(Xt),Ha=n(Xt,"P",{});var dM=s(Ha);Bto=r(dM,"The model class to instantiate is selected based on the "),cK=n(dM,"CODE",{});var tqr=s(cK);xto=r(tqr,"model_type"),tqr.forEach(t),kto=r(dM,` property of the config object (either
passed as an argument or loaded from `),fK=n(dM,"CODE",{});var aqr=s(fK);Rto=r(aqr,"pretrained_model_name_or_path"),aqr.forEach(t),Sto=r(dM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mK=n(dM,"CODE",{});var nqr=s(mK);Pto=r(nqr,"pretrained_model_name_or_path"),nqr.forEach(t),$to=r(dM,":"),dM.forEach(t),Ito=i(Xt),F=n(Xt,"UL",{});var C=s(F);Hh=n(C,"LI",{});var LFe=s(Hh);gK=n(LFe,"STRONG",{});var sqr=s(gK);jto=r(sqr,"albert"),sqr.forEach(t),Dto=r(LFe," \u2014 "),qR=n(LFe,"A",{href:!0});var lqr=s(qR);Nto=r(lqr,"AlbertModel"),lqr.forEach(t),qto=r(LFe," (ALBERT model)"),LFe.forEach(t),Oto=i(C),Uh=n(C,"LI",{});var BFe=s(Uh);hK=n(BFe,"STRONG",{});var iqr=s(hK);Gto=r(iqr,"bart"),iqr.forEach(t),Xto=r(BFe," \u2014 "),OR=n(BFe,"A",{href:!0});var dqr=s(OR);Vto=r(dqr,"BartModel"),dqr.forEach(t),zto=r(BFe," (BART model)"),BFe.forEach(t),Wto=i(C),Jh=n(C,"LI",{});var xFe=s(Jh);pK=n(xFe,"STRONG",{});var cqr=s(pK);Qto=r(cqr,"beit"),cqr.forEach(t),Hto=r(xFe," \u2014 "),GR=n(xFe,"A",{href:!0});var fqr=s(GR);Uto=r(fqr,"BeitModel"),fqr.forEach(t),Jto=r(xFe," (BEiT model)"),xFe.forEach(t),Yto=i(C),Yh=n(C,"LI",{});var kFe=s(Yh);_K=n(kFe,"STRONG",{});var mqr=s(_K);Kto=r(mqr,"bert"),mqr.forEach(t),Zto=r(kFe," \u2014 "),XR=n(kFe,"A",{href:!0});var gqr=s(XR);eao=r(gqr,"BertModel"),gqr.forEach(t),oao=r(kFe," (BERT model)"),kFe.forEach(t),rao=i(C),Kh=n(C,"LI",{});var RFe=s(Kh);uK=n(RFe,"STRONG",{});var hqr=s(uK);tao=r(hqr,"bert-generation"),hqr.forEach(t),aao=r(RFe," \u2014 "),VR=n(RFe,"A",{href:!0});var pqr=s(VR);nao=r(pqr,"BertGenerationEncoder"),pqr.forEach(t),sao=r(RFe," (Bert Generation model)"),RFe.forEach(t),lao=i(C),Zh=n(C,"LI",{});var SFe=s(Zh);bK=n(SFe,"STRONG",{});var _qr=s(bK);iao=r(_qr,"big_bird"),_qr.forEach(t),dao=r(SFe," \u2014 "),zR=n(SFe,"A",{href:!0});var uqr=s(zR);cao=r(uqr,"BigBirdModel"),uqr.forEach(t),fao=r(SFe," (BigBird model)"),SFe.forEach(t),mao=i(C),ep=n(C,"LI",{});var PFe=s(ep);vK=n(PFe,"STRONG",{});var bqr=s(vK);gao=r(bqr,"bigbird_pegasus"),bqr.forEach(t),hao=r(PFe," \u2014 "),WR=n(PFe,"A",{href:!0});var vqr=s(WR);pao=r(vqr,"BigBirdPegasusModel"),vqr.forEach(t),_ao=r(PFe," (BigBirdPegasus model)"),PFe.forEach(t),uao=i(C),op=n(C,"LI",{});var $Fe=s(op);TK=n($Fe,"STRONG",{});var Tqr=s(TK);bao=r(Tqr,"blenderbot"),Tqr.forEach(t),vao=r($Fe," \u2014 "),QR=n($Fe,"A",{href:!0});var Fqr=s(QR);Tao=r(Fqr,"BlenderbotModel"),Fqr.forEach(t),Fao=r($Fe," (Blenderbot model)"),$Fe.forEach(t),Cao=i(C),rp=n(C,"LI",{});var IFe=s(rp);FK=n(IFe,"STRONG",{});var Cqr=s(FK);Mao=r(Cqr,"blenderbot-small"),Cqr.forEach(t),Eao=r(IFe," \u2014 "),HR=n(IFe,"A",{href:!0});var Mqr=s(HR);yao=r(Mqr,"BlenderbotSmallModel"),Mqr.forEach(t),wao=r(IFe," (BlenderbotSmall model)"),IFe.forEach(t),Aao=i(C),tp=n(C,"LI",{});var jFe=s(tp);CK=n(jFe,"STRONG",{});var Eqr=s(CK);Lao=r(Eqr,"camembert"),Eqr.forEach(t),Bao=r(jFe," \u2014 "),UR=n(jFe,"A",{href:!0});var yqr=s(UR);xao=r(yqr,"CamembertModel"),yqr.forEach(t),kao=r(jFe," (CamemBERT model)"),jFe.forEach(t),Rao=i(C),ap=n(C,"LI",{});var DFe=s(ap);MK=n(DFe,"STRONG",{});var wqr=s(MK);Sao=r(wqr,"canine"),wqr.forEach(t),Pao=r(DFe," \u2014 "),JR=n(DFe,"A",{href:!0});var Aqr=s(JR);$ao=r(Aqr,"CanineModel"),Aqr.forEach(t),Iao=r(DFe," (Canine model)"),DFe.forEach(t),jao=i(C),np=n(C,"LI",{});var NFe=s(np);EK=n(NFe,"STRONG",{});var Lqr=s(EK);Dao=r(Lqr,"clip"),Lqr.forEach(t),Nao=r(NFe," \u2014 "),YR=n(NFe,"A",{href:!0});var Bqr=s(YR);qao=r(Bqr,"CLIPModel"),Bqr.forEach(t),Oao=r(NFe," (CLIP model)"),NFe.forEach(t),Gao=i(C),sp=n(C,"LI",{});var qFe=s(sp);yK=n(qFe,"STRONG",{});var xqr=s(yK);Xao=r(xqr,"convbert"),xqr.forEach(t),Vao=r(qFe," \u2014 "),KR=n(qFe,"A",{href:!0});var kqr=s(KR);zao=r(kqr,"ConvBertModel"),kqr.forEach(t),Wao=r(qFe," (ConvBERT model)"),qFe.forEach(t),Qao=i(C),lp=n(C,"LI",{});var OFe=s(lp);wK=n(OFe,"STRONG",{});var Rqr=s(wK);Hao=r(Rqr,"convnext"),Rqr.forEach(t),Uao=r(OFe," \u2014 "),ZR=n(OFe,"A",{href:!0});var Sqr=s(ZR);Jao=r(Sqr,"ConvNextModel"),Sqr.forEach(t),Yao=r(OFe," (ConvNext model)"),OFe.forEach(t),Kao=i(C),ip=n(C,"LI",{});var GFe=s(ip);AK=n(GFe,"STRONG",{});var Pqr=s(AK);Zao=r(Pqr,"ctrl"),Pqr.forEach(t),eno=r(GFe," \u2014 "),eS=n(GFe,"A",{href:!0});var $qr=s(eS);ono=r($qr,"CTRLModel"),$qr.forEach(t),rno=r(GFe," (CTRL model)"),GFe.forEach(t),tno=i(C),dp=n(C,"LI",{});var XFe=s(dp);LK=n(XFe,"STRONG",{});var Iqr=s(LK);ano=r(Iqr,"data2vec-audio"),Iqr.forEach(t),nno=r(XFe," \u2014 "),oS=n(XFe,"A",{href:!0});var jqr=s(oS);sno=r(jqr,"Data2VecAudioModel"),jqr.forEach(t),lno=r(XFe," (Data2VecAudio model)"),XFe.forEach(t),ino=i(C),cp=n(C,"LI",{});var VFe=s(cp);BK=n(VFe,"STRONG",{});var Dqr=s(BK);dno=r(Dqr,"data2vec-text"),Dqr.forEach(t),cno=r(VFe," \u2014 "),rS=n(VFe,"A",{href:!0});var Nqr=s(rS);fno=r(Nqr,"Data2VecTextModel"),Nqr.forEach(t),mno=r(VFe," (Data2VecText model)"),VFe.forEach(t),gno=i(C),fp=n(C,"LI",{});var zFe=s(fp);xK=n(zFe,"STRONG",{});var qqr=s(xK);hno=r(qqr,"deberta"),qqr.forEach(t),pno=r(zFe," \u2014 "),tS=n(zFe,"A",{href:!0});var Oqr=s(tS);_no=r(Oqr,"DebertaModel"),Oqr.forEach(t),uno=r(zFe," (DeBERTa model)"),zFe.forEach(t),bno=i(C),mp=n(C,"LI",{});var WFe=s(mp);kK=n(WFe,"STRONG",{});var Gqr=s(kK);vno=r(Gqr,"deberta-v2"),Gqr.forEach(t),Tno=r(WFe," \u2014 "),aS=n(WFe,"A",{href:!0});var Xqr=s(aS);Fno=r(Xqr,"DebertaV2Model"),Xqr.forEach(t),Cno=r(WFe," (DeBERTa-v2 model)"),WFe.forEach(t),Mno=i(C),gp=n(C,"LI",{});var QFe=s(gp);RK=n(QFe,"STRONG",{});var Vqr=s(RK);Eno=r(Vqr,"deit"),Vqr.forEach(t),yno=r(QFe," \u2014 "),nS=n(QFe,"A",{href:!0});var zqr=s(nS);wno=r(zqr,"DeiTModel"),zqr.forEach(t),Ano=r(QFe," (DeiT model)"),QFe.forEach(t),Lno=i(C),hp=n(C,"LI",{});var HFe=s(hp);SK=n(HFe,"STRONG",{});var Wqr=s(SK);Bno=r(Wqr,"detr"),Wqr.forEach(t),xno=r(HFe," \u2014 "),sS=n(HFe,"A",{href:!0});var Qqr=s(sS);kno=r(Qqr,"DetrModel"),Qqr.forEach(t),Rno=r(HFe," (DETR model)"),HFe.forEach(t),Sno=i(C),pp=n(C,"LI",{});var UFe=s(pp);PK=n(UFe,"STRONG",{});var Hqr=s(PK);Pno=r(Hqr,"distilbert"),Hqr.forEach(t),$no=r(UFe," \u2014 "),lS=n(UFe,"A",{href:!0});var Uqr=s(lS);Ino=r(Uqr,"DistilBertModel"),Uqr.forEach(t),jno=r(UFe," (DistilBERT model)"),UFe.forEach(t),Dno=i(C),_p=n(C,"LI",{});var JFe=s(_p);$K=n(JFe,"STRONG",{});var Jqr=s($K);Nno=r(Jqr,"dpr"),Jqr.forEach(t),qno=r(JFe," \u2014 "),iS=n(JFe,"A",{href:!0});var Yqr=s(iS);Ono=r(Yqr,"DPRQuestionEncoder"),Yqr.forEach(t),Gno=r(JFe," (DPR model)"),JFe.forEach(t),Xno=i(C),up=n(C,"LI",{});var YFe=s(up);IK=n(YFe,"STRONG",{});var Kqr=s(IK);Vno=r(Kqr,"electra"),Kqr.forEach(t),zno=r(YFe," \u2014 "),dS=n(YFe,"A",{href:!0});var Zqr=s(dS);Wno=r(Zqr,"ElectraModel"),Zqr.forEach(t),Qno=r(YFe," (ELECTRA model)"),YFe.forEach(t),Hno=i(C),bp=n(C,"LI",{});var KFe=s(bp);jK=n(KFe,"STRONG",{});var eOr=s(jK);Uno=r(eOr,"flaubert"),eOr.forEach(t),Jno=r(KFe," \u2014 "),cS=n(KFe,"A",{href:!0});var oOr=s(cS);Yno=r(oOr,"FlaubertModel"),oOr.forEach(t),Kno=r(KFe," (FlauBERT model)"),KFe.forEach(t),Zno=i(C),vp=n(C,"LI",{});var ZFe=s(vp);DK=n(ZFe,"STRONG",{});var rOr=s(DK);eso=r(rOr,"fnet"),rOr.forEach(t),oso=r(ZFe," \u2014 "),fS=n(ZFe,"A",{href:!0});var tOr=s(fS);rso=r(tOr,"FNetModel"),tOr.forEach(t),tso=r(ZFe," (FNet model)"),ZFe.forEach(t),aso=i(C),Tp=n(C,"LI",{});var eCe=s(Tp);NK=n(eCe,"STRONG",{});var aOr=s(NK);nso=r(aOr,"fsmt"),aOr.forEach(t),sso=r(eCe," \u2014 "),mS=n(eCe,"A",{href:!0});var nOr=s(mS);lso=r(nOr,"FSMTModel"),nOr.forEach(t),iso=r(eCe," (FairSeq Machine-Translation model)"),eCe.forEach(t),dso=i(C),Vs=n(C,"LI",{});var t9=s(Vs);qK=n(t9,"STRONG",{});var sOr=s(qK);cso=r(sOr,"funnel"),sOr.forEach(t),fso=r(t9," \u2014 "),gS=n(t9,"A",{href:!0});var lOr=s(gS);mso=r(lOr,"FunnelModel"),lOr.forEach(t),gso=r(t9," or "),hS=n(t9,"A",{href:!0});var iOr=s(hS);hso=r(iOr,"FunnelBaseModel"),iOr.forEach(t),pso=r(t9," (Funnel Transformer model)"),t9.forEach(t),_so=i(C),Fp=n(C,"LI",{});var oCe=s(Fp);OK=n(oCe,"STRONG",{});var dOr=s(OK);uso=r(dOr,"gpt2"),dOr.forEach(t),bso=r(oCe," \u2014 "),pS=n(oCe,"A",{href:!0});var cOr=s(pS);vso=r(cOr,"GPT2Model"),cOr.forEach(t),Tso=r(oCe," (OpenAI GPT-2 model)"),oCe.forEach(t),Fso=i(C),Cp=n(C,"LI",{});var rCe=s(Cp);GK=n(rCe,"STRONG",{});var fOr=s(GK);Cso=r(fOr,"gpt_neo"),fOr.forEach(t),Mso=r(rCe," \u2014 "),_S=n(rCe,"A",{href:!0});var mOr=s(_S);Eso=r(mOr,"GPTNeoModel"),mOr.forEach(t),yso=r(rCe," (GPT Neo model)"),rCe.forEach(t),wso=i(C),Mp=n(C,"LI",{});var tCe=s(Mp);XK=n(tCe,"STRONG",{});var gOr=s(XK);Aso=r(gOr,"gptj"),gOr.forEach(t),Lso=r(tCe," \u2014 "),uS=n(tCe,"A",{href:!0});var hOr=s(uS);Bso=r(hOr,"GPTJModel"),hOr.forEach(t),xso=r(tCe," (GPT-J model)"),tCe.forEach(t),kso=i(C),Ep=n(C,"LI",{});var aCe=s(Ep);VK=n(aCe,"STRONG",{});var pOr=s(VK);Rso=r(pOr,"hubert"),pOr.forEach(t),Sso=r(aCe," \u2014 "),bS=n(aCe,"A",{href:!0});var _Or=s(bS);Pso=r(_Or,"HubertModel"),_Or.forEach(t),$so=r(aCe," (Hubert model)"),aCe.forEach(t),Iso=i(C),yp=n(C,"LI",{});var nCe=s(yp);zK=n(nCe,"STRONG",{});var uOr=s(zK);jso=r(uOr,"ibert"),uOr.forEach(t),Dso=r(nCe," \u2014 "),vS=n(nCe,"A",{href:!0});var bOr=s(vS);Nso=r(bOr,"IBertModel"),bOr.forEach(t),qso=r(nCe," (I-BERT model)"),nCe.forEach(t),Oso=i(C),wp=n(C,"LI",{});var sCe=s(wp);WK=n(sCe,"STRONG",{});var vOr=s(WK);Gso=r(vOr,"imagegpt"),vOr.forEach(t),Xso=r(sCe," \u2014 "),TS=n(sCe,"A",{href:!0});var TOr=s(TS);Vso=r(TOr,"ImageGPTModel"),TOr.forEach(t),zso=r(sCe," (ImageGPT model)"),sCe.forEach(t),Wso=i(C),Ap=n(C,"LI",{});var lCe=s(Ap);QK=n(lCe,"STRONG",{});var FOr=s(QK);Qso=r(FOr,"layoutlm"),FOr.forEach(t),Hso=r(lCe," \u2014 "),FS=n(lCe,"A",{href:!0});var COr=s(FS);Uso=r(COr,"LayoutLMModel"),COr.forEach(t),Jso=r(lCe," (LayoutLM model)"),lCe.forEach(t),Yso=i(C),Lp=n(C,"LI",{});var iCe=s(Lp);HK=n(iCe,"STRONG",{});var MOr=s(HK);Kso=r(MOr,"layoutlmv2"),MOr.forEach(t),Zso=r(iCe," \u2014 "),CS=n(iCe,"A",{href:!0});var EOr=s(CS);elo=r(EOr,"LayoutLMv2Model"),EOr.forEach(t),olo=r(iCe," (LayoutLMv2 model)"),iCe.forEach(t),rlo=i(C),Bp=n(C,"LI",{});var dCe=s(Bp);UK=n(dCe,"STRONG",{});var yOr=s(UK);tlo=r(yOr,"led"),yOr.forEach(t),alo=r(dCe," \u2014 "),MS=n(dCe,"A",{href:!0});var wOr=s(MS);nlo=r(wOr,"LEDModel"),wOr.forEach(t),slo=r(dCe," (LED model)"),dCe.forEach(t),llo=i(C),xp=n(C,"LI",{});var cCe=s(xp);JK=n(cCe,"STRONG",{});var AOr=s(JK);ilo=r(AOr,"longformer"),AOr.forEach(t),dlo=r(cCe," \u2014 "),ES=n(cCe,"A",{href:!0});var LOr=s(ES);clo=r(LOr,"LongformerModel"),LOr.forEach(t),flo=r(cCe," (Longformer model)"),cCe.forEach(t),mlo=i(C),kp=n(C,"LI",{});var fCe=s(kp);YK=n(fCe,"STRONG",{});var BOr=s(YK);glo=r(BOr,"luke"),BOr.forEach(t),hlo=r(fCe," \u2014 "),yS=n(fCe,"A",{href:!0});var xOr=s(yS);plo=r(xOr,"LukeModel"),xOr.forEach(t),_lo=r(fCe," (LUKE model)"),fCe.forEach(t),ulo=i(C),Rp=n(C,"LI",{});var mCe=s(Rp);KK=n(mCe,"STRONG",{});var kOr=s(KK);blo=r(kOr,"lxmert"),kOr.forEach(t),vlo=r(mCe," \u2014 "),wS=n(mCe,"A",{href:!0});var ROr=s(wS);Tlo=r(ROr,"LxmertModel"),ROr.forEach(t),Flo=r(mCe," (LXMERT model)"),mCe.forEach(t),Clo=i(C),Sp=n(C,"LI",{});var gCe=s(Sp);ZK=n(gCe,"STRONG",{});var SOr=s(ZK);Mlo=r(SOr,"m2m_100"),SOr.forEach(t),Elo=r(gCe," \u2014 "),AS=n(gCe,"A",{href:!0});var POr=s(AS);ylo=r(POr,"M2M100Model"),POr.forEach(t),wlo=r(gCe," (M2M100 model)"),gCe.forEach(t),Alo=i(C),Pp=n(C,"LI",{});var hCe=s(Pp);eZ=n(hCe,"STRONG",{});var $Or=s(eZ);Llo=r($Or,"marian"),$Or.forEach(t),Blo=r(hCe," \u2014 "),LS=n(hCe,"A",{href:!0});var IOr=s(LS);xlo=r(IOr,"MarianModel"),IOr.forEach(t),klo=r(hCe," (Marian model)"),hCe.forEach(t),Rlo=i(C),$p=n(C,"LI",{});var pCe=s($p);oZ=n(pCe,"STRONG",{});var jOr=s(oZ);Slo=r(jOr,"maskformer"),jOr.forEach(t),Plo=r(pCe," \u2014 "),BS=n(pCe,"A",{href:!0});var DOr=s(BS);$lo=r(DOr,"MaskFormerModel"),DOr.forEach(t),Ilo=r(pCe," (MaskFormer model)"),pCe.forEach(t),jlo=i(C),Ip=n(C,"LI",{});var _Ce=s(Ip);rZ=n(_Ce,"STRONG",{});var NOr=s(rZ);Dlo=r(NOr,"mbart"),NOr.forEach(t),Nlo=r(_Ce," \u2014 "),xS=n(_Ce,"A",{href:!0});var qOr=s(xS);qlo=r(qOr,"MBartModel"),qOr.forEach(t),Olo=r(_Ce," (mBART model)"),_Ce.forEach(t),Glo=i(C),jp=n(C,"LI",{});var uCe=s(jp);tZ=n(uCe,"STRONG",{});var OOr=s(tZ);Xlo=r(OOr,"megatron-bert"),OOr.forEach(t),Vlo=r(uCe," \u2014 "),kS=n(uCe,"A",{href:!0});var GOr=s(kS);zlo=r(GOr,"MegatronBertModel"),GOr.forEach(t),Wlo=r(uCe," (MegatronBert model)"),uCe.forEach(t),Qlo=i(C),Dp=n(C,"LI",{});var bCe=s(Dp);aZ=n(bCe,"STRONG",{});var XOr=s(aZ);Hlo=r(XOr,"mobilebert"),XOr.forEach(t),Ulo=r(bCe," \u2014 "),RS=n(bCe,"A",{href:!0});var VOr=s(RS);Jlo=r(VOr,"MobileBertModel"),VOr.forEach(t),Ylo=r(bCe," (MobileBERT model)"),bCe.forEach(t),Klo=i(C),Np=n(C,"LI",{});var vCe=s(Np);nZ=n(vCe,"STRONG",{});var zOr=s(nZ);Zlo=r(zOr,"mpnet"),zOr.forEach(t),eio=r(vCe," \u2014 "),SS=n(vCe,"A",{href:!0});var WOr=s(SS);oio=r(WOr,"MPNetModel"),WOr.forEach(t),rio=r(vCe," (MPNet model)"),vCe.forEach(t),tio=i(C),qp=n(C,"LI",{});var TCe=s(qp);sZ=n(TCe,"STRONG",{});var QOr=s(sZ);aio=r(QOr,"mt5"),QOr.forEach(t),nio=r(TCe," \u2014 "),PS=n(TCe,"A",{href:!0});var HOr=s(PS);sio=r(HOr,"MT5Model"),HOr.forEach(t),lio=r(TCe," (mT5 model)"),TCe.forEach(t),iio=i(C),Op=n(C,"LI",{});var FCe=s(Op);lZ=n(FCe,"STRONG",{});var UOr=s(lZ);dio=r(UOr,"nystromformer"),UOr.forEach(t),cio=r(FCe," \u2014 "),$S=n(FCe,"A",{href:!0});var JOr=s($S);fio=r(JOr,"NystromformerModel"),JOr.forEach(t),mio=r(FCe," (Nystromformer model)"),FCe.forEach(t),gio=i(C),Gp=n(C,"LI",{});var CCe=s(Gp);iZ=n(CCe,"STRONG",{});var YOr=s(iZ);hio=r(YOr,"openai-gpt"),YOr.forEach(t),pio=r(CCe," \u2014 "),IS=n(CCe,"A",{href:!0});var KOr=s(IS);_io=r(KOr,"OpenAIGPTModel"),KOr.forEach(t),uio=r(CCe," (OpenAI GPT model)"),CCe.forEach(t),bio=i(C),Xp=n(C,"LI",{});var MCe=s(Xp);dZ=n(MCe,"STRONG",{});var ZOr=s(dZ);vio=r(ZOr,"pegasus"),ZOr.forEach(t),Tio=r(MCe," \u2014 "),jS=n(MCe,"A",{href:!0});var eGr=s(jS);Fio=r(eGr,"PegasusModel"),eGr.forEach(t),Cio=r(MCe," (Pegasus model)"),MCe.forEach(t),Mio=i(C),Vp=n(C,"LI",{});var ECe=s(Vp);cZ=n(ECe,"STRONG",{});var oGr=s(cZ);Eio=r(oGr,"perceiver"),oGr.forEach(t),yio=r(ECe," \u2014 "),DS=n(ECe,"A",{href:!0});var rGr=s(DS);wio=r(rGr,"PerceiverModel"),rGr.forEach(t),Aio=r(ECe," (Perceiver model)"),ECe.forEach(t),Lio=i(C),zp=n(C,"LI",{});var yCe=s(zp);fZ=n(yCe,"STRONG",{});var tGr=s(fZ);Bio=r(tGr,"plbart"),tGr.forEach(t),xio=r(yCe," \u2014 "),NS=n(yCe,"A",{href:!0});var aGr=s(NS);kio=r(aGr,"PLBartModel"),aGr.forEach(t),Rio=r(yCe," (PLBart model)"),yCe.forEach(t),Sio=i(C),Wp=n(C,"LI",{});var wCe=s(Wp);mZ=n(wCe,"STRONG",{});var nGr=s(mZ);Pio=r(nGr,"poolformer"),nGr.forEach(t),$io=r(wCe," \u2014 "),qS=n(wCe,"A",{href:!0});var sGr=s(qS);Iio=r(sGr,"PoolFormerModel"),sGr.forEach(t),jio=r(wCe," (PoolFormer model)"),wCe.forEach(t),Dio=i(C),Qp=n(C,"LI",{});var ACe=s(Qp);gZ=n(ACe,"STRONG",{});var lGr=s(gZ);Nio=r(lGr,"prophetnet"),lGr.forEach(t),qio=r(ACe," \u2014 "),OS=n(ACe,"A",{href:!0});var iGr=s(OS);Oio=r(iGr,"ProphetNetModel"),iGr.forEach(t),Gio=r(ACe," (ProphetNet model)"),ACe.forEach(t),Xio=i(C),Hp=n(C,"LI",{});var LCe=s(Hp);hZ=n(LCe,"STRONG",{});var dGr=s(hZ);Vio=r(dGr,"qdqbert"),dGr.forEach(t),zio=r(LCe," \u2014 "),GS=n(LCe,"A",{href:!0});var cGr=s(GS);Wio=r(cGr,"QDQBertModel"),cGr.forEach(t),Qio=r(LCe," (QDQBert model)"),LCe.forEach(t),Hio=i(C),Up=n(C,"LI",{});var BCe=s(Up);pZ=n(BCe,"STRONG",{});var fGr=s(pZ);Uio=r(fGr,"reformer"),fGr.forEach(t),Jio=r(BCe," \u2014 "),XS=n(BCe,"A",{href:!0});var mGr=s(XS);Yio=r(mGr,"ReformerModel"),mGr.forEach(t),Kio=r(BCe," (Reformer model)"),BCe.forEach(t),Zio=i(C),Jp=n(C,"LI",{});var xCe=s(Jp);_Z=n(xCe,"STRONG",{});var gGr=s(_Z);edo=r(gGr,"rembert"),gGr.forEach(t),odo=r(xCe," \u2014 "),VS=n(xCe,"A",{href:!0});var hGr=s(VS);rdo=r(hGr,"RemBertModel"),hGr.forEach(t),tdo=r(xCe," (RemBERT model)"),xCe.forEach(t),ado=i(C),Yp=n(C,"LI",{});var kCe=s(Yp);uZ=n(kCe,"STRONG",{});var pGr=s(uZ);ndo=r(pGr,"retribert"),pGr.forEach(t),sdo=r(kCe," \u2014 "),zS=n(kCe,"A",{href:!0});var _Gr=s(zS);ldo=r(_Gr,"RetriBertModel"),_Gr.forEach(t),ido=r(kCe," (RetriBERT model)"),kCe.forEach(t),ddo=i(C),Kp=n(C,"LI",{});var RCe=s(Kp);bZ=n(RCe,"STRONG",{});var uGr=s(bZ);cdo=r(uGr,"roberta"),uGr.forEach(t),fdo=r(RCe," \u2014 "),WS=n(RCe,"A",{href:!0});var bGr=s(WS);mdo=r(bGr,"RobertaModel"),bGr.forEach(t),gdo=r(RCe," (RoBERTa model)"),RCe.forEach(t),hdo=i(C),Zp=n(C,"LI",{});var SCe=s(Zp);vZ=n(SCe,"STRONG",{});var vGr=s(vZ);pdo=r(vGr,"roformer"),vGr.forEach(t),_do=r(SCe," \u2014 "),QS=n(SCe,"A",{href:!0});var TGr=s(QS);udo=r(TGr,"RoFormerModel"),TGr.forEach(t),bdo=r(SCe," (RoFormer model)"),SCe.forEach(t),vdo=i(C),e_=n(C,"LI",{});var PCe=s(e_);TZ=n(PCe,"STRONG",{});var FGr=s(TZ);Tdo=r(FGr,"segformer"),FGr.forEach(t),Fdo=r(PCe," \u2014 "),HS=n(PCe,"A",{href:!0});var CGr=s(HS);Cdo=r(CGr,"SegformerModel"),CGr.forEach(t),Mdo=r(PCe," (SegFormer model)"),PCe.forEach(t),Edo=i(C),o_=n(C,"LI",{});var $Ce=s(o_);FZ=n($Ce,"STRONG",{});var MGr=s(FZ);ydo=r(MGr,"sew"),MGr.forEach(t),wdo=r($Ce," \u2014 "),US=n($Ce,"A",{href:!0});var EGr=s(US);Ado=r(EGr,"SEWModel"),EGr.forEach(t),Ldo=r($Ce," (SEW model)"),$Ce.forEach(t),Bdo=i(C),r_=n(C,"LI",{});var ICe=s(r_);CZ=n(ICe,"STRONG",{});var yGr=s(CZ);xdo=r(yGr,"sew-d"),yGr.forEach(t),kdo=r(ICe," \u2014 "),JS=n(ICe,"A",{href:!0});var wGr=s(JS);Rdo=r(wGr,"SEWDModel"),wGr.forEach(t),Sdo=r(ICe," (SEW-D model)"),ICe.forEach(t),Pdo=i(C),t_=n(C,"LI",{});var jCe=s(t_);MZ=n(jCe,"STRONG",{});var AGr=s(MZ);$do=r(AGr,"speech_to_text"),AGr.forEach(t),Ido=r(jCe," \u2014 "),YS=n(jCe,"A",{href:!0});var LGr=s(YS);jdo=r(LGr,"Speech2TextModel"),LGr.forEach(t),Ddo=r(jCe," (Speech2Text model)"),jCe.forEach(t),Ndo=i(C),a_=n(C,"LI",{});var DCe=s(a_);EZ=n(DCe,"STRONG",{});var BGr=s(EZ);qdo=r(BGr,"splinter"),BGr.forEach(t),Odo=r(DCe," \u2014 "),KS=n(DCe,"A",{href:!0});var xGr=s(KS);Gdo=r(xGr,"SplinterModel"),xGr.forEach(t),Xdo=r(DCe," (Splinter model)"),DCe.forEach(t),Vdo=i(C),n_=n(C,"LI",{});var NCe=s(n_);yZ=n(NCe,"STRONG",{});var kGr=s(yZ);zdo=r(kGr,"squeezebert"),kGr.forEach(t),Wdo=r(NCe," \u2014 "),ZS=n(NCe,"A",{href:!0});var RGr=s(ZS);Qdo=r(RGr,"SqueezeBertModel"),RGr.forEach(t),Hdo=r(NCe," (SqueezeBERT model)"),NCe.forEach(t),Udo=i(C),s_=n(C,"LI",{});var qCe=s(s_);wZ=n(qCe,"STRONG",{});var SGr=s(wZ);Jdo=r(SGr,"swin"),SGr.forEach(t),Ydo=r(qCe," \u2014 "),eP=n(qCe,"A",{href:!0});var PGr=s(eP);Kdo=r(PGr,"SwinModel"),PGr.forEach(t),Zdo=r(qCe," (Swin model)"),qCe.forEach(t),eco=i(C),l_=n(C,"LI",{});var OCe=s(l_);AZ=n(OCe,"STRONG",{});var $Gr=s(AZ);oco=r($Gr,"t5"),$Gr.forEach(t),rco=r(OCe," \u2014 "),oP=n(OCe,"A",{href:!0});var IGr=s(oP);tco=r(IGr,"T5Model"),IGr.forEach(t),aco=r(OCe," (T5 model)"),OCe.forEach(t),nco=i(C),i_=n(C,"LI",{});var GCe=s(i_);LZ=n(GCe,"STRONG",{});var jGr=s(LZ);sco=r(jGr,"tapas"),jGr.forEach(t),lco=r(GCe," \u2014 "),rP=n(GCe,"A",{href:!0});var DGr=s(rP);ico=r(DGr,"TapasModel"),DGr.forEach(t),dco=r(GCe," (TAPAS model)"),GCe.forEach(t),cco=i(C),d_=n(C,"LI",{});var XCe=s(d_);BZ=n(XCe,"STRONG",{});var NGr=s(BZ);fco=r(NGr,"transfo-xl"),NGr.forEach(t),mco=r(XCe," \u2014 "),tP=n(XCe,"A",{href:!0});var qGr=s(tP);gco=r(qGr,"TransfoXLModel"),qGr.forEach(t),hco=r(XCe," (Transformer-XL model)"),XCe.forEach(t),pco=i(C),c_=n(C,"LI",{});var VCe=s(c_);xZ=n(VCe,"STRONG",{});var OGr=s(xZ);_co=r(OGr,"unispeech"),OGr.forEach(t),uco=r(VCe," \u2014 "),aP=n(VCe,"A",{href:!0});var GGr=s(aP);bco=r(GGr,"UniSpeechModel"),GGr.forEach(t),vco=r(VCe," (UniSpeech model)"),VCe.forEach(t),Tco=i(C),f_=n(C,"LI",{});var zCe=s(f_);kZ=n(zCe,"STRONG",{});var XGr=s(kZ);Fco=r(XGr,"unispeech-sat"),XGr.forEach(t),Cco=r(zCe," \u2014 "),nP=n(zCe,"A",{href:!0});var VGr=s(nP);Mco=r(VGr,"UniSpeechSatModel"),VGr.forEach(t),Eco=r(zCe," (UniSpeechSat model)"),zCe.forEach(t),yco=i(C),m_=n(C,"LI",{});var WCe=s(m_);RZ=n(WCe,"STRONG",{});var zGr=s(RZ);wco=r(zGr,"vilt"),zGr.forEach(t),Aco=r(WCe," \u2014 "),sP=n(WCe,"A",{href:!0});var WGr=s(sP);Lco=r(WGr,"ViltModel"),WGr.forEach(t),Bco=r(WCe," (ViLT model)"),WCe.forEach(t),xco=i(C),g_=n(C,"LI",{});var QCe=s(g_);SZ=n(QCe,"STRONG",{});var QGr=s(SZ);kco=r(QGr,"vision-text-dual-encoder"),QGr.forEach(t),Rco=r(QCe," \u2014 "),lP=n(QCe,"A",{href:!0});var HGr=s(lP);Sco=r(HGr,"VisionTextDualEncoderModel"),HGr.forEach(t),Pco=r(QCe," (VisionTextDualEncoder model)"),QCe.forEach(t),$co=i(C),h_=n(C,"LI",{});var HCe=s(h_);PZ=n(HCe,"STRONG",{});var UGr=s(PZ);Ico=r(UGr,"visual_bert"),UGr.forEach(t),jco=r(HCe," \u2014 "),iP=n(HCe,"A",{href:!0});var JGr=s(iP);Dco=r(JGr,"VisualBertModel"),JGr.forEach(t),Nco=r(HCe," (VisualBert model)"),HCe.forEach(t),qco=i(C),p_=n(C,"LI",{});var UCe=s(p_);$Z=n(UCe,"STRONG",{});var YGr=s($Z);Oco=r(YGr,"vit"),YGr.forEach(t),Gco=r(UCe," \u2014 "),dP=n(UCe,"A",{href:!0});var KGr=s(dP);Xco=r(KGr,"ViTModel"),KGr.forEach(t),Vco=r(UCe," (ViT model)"),UCe.forEach(t),zco=i(C),__=n(C,"LI",{});var JCe=s(__);IZ=n(JCe,"STRONG",{});var ZGr=s(IZ);Wco=r(ZGr,"vit_mae"),ZGr.forEach(t),Qco=r(JCe," \u2014 "),cP=n(JCe,"A",{href:!0});var eXr=s(cP);Hco=r(eXr,"ViTMAEModel"),eXr.forEach(t),Uco=r(JCe," (ViTMAE model)"),JCe.forEach(t),Jco=i(C),u_=n(C,"LI",{});var YCe=s(u_);jZ=n(YCe,"STRONG",{});var oXr=s(jZ);Yco=r(oXr,"wav2vec2"),oXr.forEach(t),Kco=r(YCe," \u2014 "),fP=n(YCe,"A",{href:!0});var rXr=s(fP);Zco=r(rXr,"Wav2Vec2Model"),rXr.forEach(t),efo=r(YCe," (Wav2Vec2 model)"),YCe.forEach(t),ofo=i(C),b_=n(C,"LI",{});var KCe=s(b_);DZ=n(KCe,"STRONG",{});var tXr=s(DZ);rfo=r(tXr,"wavlm"),tXr.forEach(t),tfo=r(KCe," \u2014 "),mP=n(KCe,"A",{href:!0});var aXr=s(mP);afo=r(aXr,"WavLMModel"),aXr.forEach(t),nfo=r(KCe," (WavLM model)"),KCe.forEach(t),sfo=i(C),v_=n(C,"LI",{});var ZCe=s(v_);NZ=n(ZCe,"STRONG",{});var nXr=s(NZ);lfo=r(nXr,"xglm"),nXr.forEach(t),ifo=r(ZCe," \u2014 "),gP=n(ZCe,"A",{href:!0});var sXr=s(gP);dfo=r(sXr,"XGLMModel"),sXr.forEach(t),cfo=r(ZCe," (XGLM model)"),ZCe.forEach(t),ffo=i(C),T_=n(C,"LI",{});var eMe=s(T_);qZ=n(eMe,"STRONG",{});var lXr=s(qZ);mfo=r(lXr,"xlm"),lXr.forEach(t),gfo=r(eMe," \u2014 "),hP=n(eMe,"A",{href:!0});var iXr=s(hP);hfo=r(iXr,"XLMModel"),iXr.forEach(t),pfo=r(eMe," (XLM model)"),eMe.forEach(t),_fo=i(C),F_=n(C,"LI",{});var oMe=s(F_);OZ=n(oMe,"STRONG",{});var dXr=s(OZ);ufo=r(dXr,"xlm-prophetnet"),dXr.forEach(t),bfo=r(oMe," \u2014 "),pP=n(oMe,"A",{href:!0});var cXr=s(pP);vfo=r(cXr,"XLMProphetNetModel"),cXr.forEach(t),Tfo=r(oMe," (XLMProphetNet model)"),oMe.forEach(t),Ffo=i(C),C_=n(C,"LI",{});var rMe=s(C_);GZ=n(rMe,"STRONG",{});var fXr=s(GZ);Cfo=r(fXr,"xlm-roberta"),fXr.forEach(t),Mfo=r(rMe," \u2014 "),_P=n(rMe,"A",{href:!0});var mXr=s(_P);Efo=r(mXr,"XLMRobertaModel"),mXr.forEach(t),yfo=r(rMe," (XLM-RoBERTa model)"),rMe.forEach(t),wfo=i(C),M_=n(C,"LI",{});var tMe=s(M_);XZ=n(tMe,"STRONG",{});var gXr=s(XZ);Afo=r(gXr,"xlm-roberta-xl"),gXr.forEach(t),Lfo=r(tMe," \u2014 "),uP=n(tMe,"A",{href:!0});var hXr=s(uP);Bfo=r(hXr,"XLMRobertaXLModel"),hXr.forEach(t),xfo=r(tMe," (XLM-RoBERTa-XL model)"),tMe.forEach(t),kfo=i(C),E_=n(C,"LI",{});var aMe=s(E_);VZ=n(aMe,"STRONG",{});var pXr=s(VZ);Rfo=r(pXr,"xlnet"),pXr.forEach(t),Sfo=r(aMe," \u2014 "),bP=n(aMe,"A",{href:!0});var _Xr=s(bP);Pfo=r(_Xr,"XLNetModel"),_Xr.forEach(t),$fo=r(aMe," (XLNet model)"),aMe.forEach(t),Ifo=i(C),y_=n(C,"LI",{});var nMe=s(y_);zZ=n(nMe,"STRONG",{});var uXr=s(zZ);jfo=r(uXr,"yoso"),uXr.forEach(t),Dfo=r(nMe," \u2014 "),vP=n(nMe,"A",{href:!0});var bXr=s(vP);Nfo=r(bXr,"YosoModel"),bXr.forEach(t),qfo=r(nMe," (YOSO model)"),nMe.forEach(t),C.forEach(t),Ofo=i(Xt),w_=n(Xt,"P",{});var sMe=s(w_);Gfo=r(sMe,"The model is set in evaluation mode by default using "),WZ=n(sMe,"CODE",{});var vXr=s(WZ);Xfo=r(vXr,"model.eval()"),vXr.forEach(t),Vfo=r(sMe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),QZ=n(sMe,"CODE",{});var TXr=s(QZ);zfo=r(TXr,"model.train()"),TXr.forEach(t),sMe.forEach(t),Wfo=i(Xt),HZ=n(Xt,"P",{});var FXr=s(HZ);Qfo=r(FXr,"Examples:"),FXr.forEach(t),Hfo=i(Xt),m(W4.$$.fragment,Xt),Xt.forEach(t),Ys.forEach(t),lke=i(d),ld=n(d,"H2",{class:!0});var bSe=s(ld);A_=n(bSe,"A",{id:!0,class:!0,href:!0});var CXr=s(A_);UZ=n(CXr,"SPAN",{});var MXr=s(UZ);m(Q4.$$.fragment,MXr),MXr.forEach(t),CXr.forEach(t),Ufo=i(bSe),JZ=n(bSe,"SPAN",{});var EXr=s(JZ);Jfo=r(EXr,"AutoModelForPreTraining"),EXr.forEach(t),bSe.forEach(t),ike=i(d),Ko=n(d,"DIV",{class:!0});var Zs=s(Ko);m(H4.$$.fragment,Zs),Yfo=i(Zs),id=n(Zs,"P",{});var Hz=s(id);Kfo=r(Hz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),YZ=n(Hz,"CODE",{});var yXr=s(YZ);Zfo=r(yXr,"from_pretrained()"),yXr.forEach(t),emo=r(Hz,"class method or the "),KZ=n(Hz,"CODE",{});var wXr=s(KZ);omo=r(wXr,"from_config()"),wXr.forEach(t),rmo=r(Hz,`class
method.`),Hz.forEach(t),tmo=i(Zs),U4=n(Zs,"P",{});var vSe=s(U4);amo=r(vSe,"This class cannot be instantiated directly using "),ZZ=n(vSe,"CODE",{});var AXr=s(ZZ);nmo=r(AXr,"__init__()"),AXr.forEach(t),smo=r(vSe," (throws an error)."),vSe.forEach(t),lmo=i(Zs),Qr=n(Zs,"DIV",{class:!0});var el=s(Qr);m(J4.$$.fragment,el),imo=i(el),eee=n(el,"P",{});var LXr=s(eee);dmo=r(LXr,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),LXr.forEach(t),cmo=i(el),dd=n(el,"P",{});var Uz=s(dd);fmo=r(Uz,`Note:
Loading a model from its configuration file does `),oee=n(Uz,"STRONG",{});var BXr=s(oee);mmo=r(BXr,"not"),BXr.forEach(t),gmo=r(Uz,` load the model weights. It only affects the
model\u2019s configuration. Use `),ree=n(Uz,"CODE",{});var xXr=s(ree);hmo=r(xXr,"from_pretrained()"),xXr.forEach(t),pmo=r(Uz,"to load the model weights."),Uz.forEach(t),_mo=i(el),tee=n(el,"P",{});var kXr=s(tee);umo=r(kXr,"Examples:"),kXr.forEach(t),bmo=i(el),m(Y4.$$.fragment,el),el.forEach(t),vmo=i(Zs),De=n(Zs,"DIV",{class:!0});var Vt=s(De);m(K4.$$.fragment,Vt),Tmo=i(Vt),aee=n(Vt,"P",{});var RXr=s(aee);Fmo=r(RXr,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),RXr.forEach(t),Cmo=i(Vt),Ua=n(Vt,"P",{});var cM=s(Ua);Mmo=r(cM,"The model class to instantiate is selected based on the "),nee=n(cM,"CODE",{});var SXr=s(nee);Emo=r(SXr,"model_type"),SXr.forEach(t),ymo=r(cM,` property of the config object (either
passed as an argument or loaded from `),see=n(cM,"CODE",{});var PXr=s(see);wmo=r(PXr,"pretrained_model_name_or_path"),PXr.forEach(t),Amo=r(cM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lee=n(cM,"CODE",{});var $Xr=s(lee);Lmo=r($Xr,"pretrained_model_name_or_path"),$Xr.forEach(t),Bmo=r(cM,":"),cM.forEach(t),xmo=i(Vt),k=n(Vt,"UL",{});var S=s(k);L_=n(S,"LI",{});var lMe=s(L_);iee=n(lMe,"STRONG",{});var IXr=s(iee);kmo=r(IXr,"albert"),IXr.forEach(t),Rmo=r(lMe," \u2014 "),TP=n(lMe,"A",{href:!0});var jXr=s(TP);Smo=r(jXr,"AlbertForPreTraining"),jXr.forEach(t),Pmo=r(lMe," (ALBERT model)"),lMe.forEach(t),$mo=i(S),B_=n(S,"LI",{});var iMe=s(B_);dee=n(iMe,"STRONG",{});var DXr=s(dee);Imo=r(DXr,"bart"),DXr.forEach(t),jmo=r(iMe," \u2014 "),FP=n(iMe,"A",{href:!0});var NXr=s(FP);Dmo=r(NXr,"BartForConditionalGeneration"),NXr.forEach(t),Nmo=r(iMe," (BART model)"),iMe.forEach(t),qmo=i(S),x_=n(S,"LI",{});var dMe=s(x_);cee=n(dMe,"STRONG",{});var qXr=s(cee);Omo=r(qXr,"bert"),qXr.forEach(t),Gmo=r(dMe," \u2014 "),CP=n(dMe,"A",{href:!0});var OXr=s(CP);Xmo=r(OXr,"BertForPreTraining"),OXr.forEach(t),Vmo=r(dMe," (BERT model)"),dMe.forEach(t),zmo=i(S),k_=n(S,"LI",{});var cMe=s(k_);fee=n(cMe,"STRONG",{});var GXr=s(fee);Wmo=r(GXr,"big_bird"),GXr.forEach(t),Qmo=r(cMe," \u2014 "),MP=n(cMe,"A",{href:!0});var XXr=s(MP);Hmo=r(XXr,"BigBirdForPreTraining"),XXr.forEach(t),Umo=r(cMe," (BigBird model)"),cMe.forEach(t),Jmo=i(S),R_=n(S,"LI",{});var fMe=s(R_);mee=n(fMe,"STRONG",{});var VXr=s(mee);Ymo=r(VXr,"camembert"),VXr.forEach(t),Kmo=r(fMe," \u2014 "),EP=n(fMe,"A",{href:!0});var zXr=s(EP);Zmo=r(zXr,"CamembertForMaskedLM"),zXr.forEach(t),ego=r(fMe," (CamemBERT model)"),fMe.forEach(t),ogo=i(S),S_=n(S,"LI",{});var mMe=s(S_);gee=n(mMe,"STRONG",{});var WXr=s(gee);rgo=r(WXr,"ctrl"),WXr.forEach(t),tgo=r(mMe," \u2014 "),yP=n(mMe,"A",{href:!0});var QXr=s(yP);ago=r(QXr,"CTRLLMHeadModel"),QXr.forEach(t),ngo=r(mMe," (CTRL model)"),mMe.forEach(t),sgo=i(S),P_=n(S,"LI",{});var gMe=s(P_);hee=n(gMe,"STRONG",{});var HXr=s(hee);lgo=r(HXr,"data2vec-text"),HXr.forEach(t),igo=r(gMe," \u2014 "),wP=n(gMe,"A",{href:!0});var UXr=s(wP);dgo=r(UXr,"Data2VecTextForMaskedLM"),UXr.forEach(t),cgo=r(gMe," (Data2VecText model)"),gMe.forEach(t),fgo=i(S),$_=n(S,"LI",{});var hMe=s($_);pee=n(hMe,"STRONG",{});var JXr=s(pee);mgo=r(JXr,"deberta"),JXr.forEach(t),ggo=r(hMe," \u2014 "),AP=n(hMe,"A",{href:!0});var YXr=s(AP);hgo=r(YXr,"DebertaForMaskedLM"),YXr.forEach(t),pgo=r(hMe," (DeBERTa model)"),hMe.forEach(t),_go=i(S),I_=n(S,"LI",{});var pMe=s(I_);_ee=n(pMe,"STRONG",{});var KXr=s(_ee);ugo=r(KXr,"deberta-v2"),KXr.forEach(t),bgo=r(pMe," \u2014 "),LP=n(pMe,"A",{href:!0});var ZXr=s(LP);vgo=r(ZXr,"DebertaV2ForMaskedLM"),ZXr.forEach(t),Tgo=r(pMe," (DeBERTa-v2 model)"),pMe.forEach(t),Fgo=i(S),j_=n(S,"LI",{});var _Me=s(j_);uee=n(_Me,"STRONG",{});var eVr=s(uee);Cgo=r(eVr,"distilbert"),eVr.forEach(t),Mgo=r(_Me," \u2014 "),BP=n(_Me,"A",{href:!0});var oVr=s(BP);Ego=r(oVr,"DistilBertForMaskedLM"),oVr.forEach(t),ygo=r(_Me," (DistilBERT model)"),_Me.forEach(t),wgo=i(S),D_=n(S,"LI",{});var uMe=s(D_);bee=n(uMe,"STRONG",{});var rVr=s(bee);Ago=r(rVr,"electra"),rVr.forEach(t),Lgo=r(uMe," \u2014 "),xP=n(uMe,"A",{href:!0});var tVr=s(xP);Bgo=r(tVr,"ElectraForPreTraining"),tVr.forEach(t),xgo=r(uMe," (ELECTRA model)"),uMe.forEach(t),kgo=i(S),N_=n(S,"LI",{});var bMe=s(N_);vee=n(bMe,"STRONG",{});var aVr=s(vee);Rgo=r(aVr,"flaubert"),aVr.forEach(t),Sgo=r(bMe," \u2014 "),kP=n(bMe,"A",{href:!0});var nVr=s(kP);Pgo=r(nVr,"FlaubertWithLMHeadModel"),nVr.forEach(t),$go=r(bMe," (FlauBERT model)"),bMe.forEach(t),Igo=i(S),q_=n(S,"LI",{});var vMe=s(q_);Tee=n(vMe,"STRONG",{});var sVr=s(Tee);jgo=r(sVr,"fnet"),sVr.forEach(t),Dgo=r(vMe," \u2014 "),RP=n(vMe,"A",{href:!0});var lVr=s(RP);Ngo=r(lVr,"FNetForPreTraining"),lVr.forEach(t),qgo=r(vMe," (FNet model)"),vMe.forEach(t),Ogo=i(S),O_=n(S,"LI",{});var TMe=s(O_);Fee=n(TMe,"STRONG",{});var iVr=s(Fee);Ggo=r(iVr,"fsmt"),iVr.forEach(t),Xgo=r(TMe," \u2014 "),SP=n(TMe,"A",{href:!0});var dVr=s(SP);Vgo=r(dVr,"FSMTForConditionalGeneration"),dVr.forEach(t),zgo=r(TMe," (FairSeq Machine-Translation model)"),TMe.forEach(t),Wgo=i(S),G_=n(S,"LI",{});var FMe=s(G_);Cee=n(FMe,"STRONG",{});var cVr=s(Cee);Qgo=r(cVr,"funnel"),cVr.forEach(t),Hgo=r(FMe," \u2014 "),PP=n(FMe,"A",{href:!0});var fVr=s(PP);Ugo=r(fVr,"FunnelForPreTraining"),fVr.forEach(t),Jgo=r(FMe," (Funnel Transformer model)"),FMe.forEach(t),Ygo=i(S),X_=n(S,"LI",{});var CMe=s(X_);Mee=n(CMe,"STRONG",{});var mVr=s(Mee);Kgo=r(mVr,"gpt2"),mVr.forEach(t),Zgo=r(CMe," \u2014 "),$P=n(CMe,"A",{href:!0});var gVr=s($P);eho=r(gVr,"GPT2LMHeadModel"),gVr.forEach(t),oho=r(CMe," (OpenAI GPT-2 model)"),CMe.forEach(t),rho=i(S),V_=n(S,"LI",{});var MMe=s(V_);Eee=n(MMe,"STRONG",{});var hVr=s(Eee);tho=r(hVr,"ibert"),hVr.forEach(t),aho=r(MMe," \u2014 "),IP=n(MMe,"A",{href:!0});var pVr=s(IP);nho=r(pVr,"IBertForMaskedLM"),pVr.forEach(t),sho=r(MMe," (I-BERT model)"),MMe.forEach(t),lho=i(S),z_=n(S,"LI",{});var EMe=s(z_);yee=n(EMe,"STRONG",{});var _Vr=s(yee);iho=r(_Vr,"layoutlm"),_Vr.forEach(t),dho=r(EMe," \u2014 "),jP=n(EMe,"A",{href:!0});var uVr=s(jP);cho=r(uVr,"LayoutLMForMaskedLM"),uVr.forEach(t),fho=r(EMe," (LayoutLM model)"),EMe.forEach(t),mho=i(S),W_=n(S,"LI",{});var yMe=s(W_);wee=n(yMe,"STRONG",{});var bVr=s(wee);gho=r(bVr,"longformer"),bVr.forEach(t),hho=r(yMe," \u2014 "),DP=n(yMe,"A",{href:!0});var vVr=s(DP);pho=r(vVr,"LongformerForMaskedLM"),vVr.forEach(t),_ho=r(yMe," (Longformer model)"),yMe.forEach(t),uho=i(S),Q_=n(S,"LI",{});var wMe=s(Q_);Aee=n(wMe,"STRONG",{});var TVr=s(Aee);bho=r(TVr,"lxmert"),TVr.forEach(t),vho=r(wMe," \u2014 "),NP=n(wMe,"A",{href:!0});var FVr=s(NP);Tho=r(FVr,"LxmertForPreTraining"),FVr.forEach(t),Fho=r(wMe," (LXMERT model)"),wMe.forEach(t),Cho=i(S),H_=n(S,"LI",{});var AMe=s(H_);Lee=n(AMe,"STRONG",{});var CVr=s(Lee);Mho=r(CVr,"megatron-bert"),CVr.forEach(t),Eho=r(AMe," \u2014 "),qP=n(AMe,"A",{href:!0});var MVr=s(qP);yho=r(MVr,"MegatronBertForPreTraining"),MVr.forEach(t),who=r(AMe," (MegatronBert model)"),AMe.forEach(t),Aho=i(S),U_=n(S,"LI",{});var LMe=s(U_);Bee=n(LMe,"STRONG",{});var EVr=s(Bee);Lho=r(EVr,"mobilebert"),EVr.forEach(t),Bho=r(LMe," \u2014 "),OP=n(LMe,"A",{href:!0});var yVr=s(OP);xho=r(yVr,"MobileBertForPreTraining"),yVr.forEach(t),kho=r(LMe," (MobileBERT model)"),LMe.forEach(t),Rho=i(S),J_=n(S,"LI",{});var BMe=s(J_);xee=n(BMe,"STRONG",{});var wVr=s(xee);Sho=r(wVr,"mpnet"),wVr.forEach(t),Pho=r(BMe," \u2014 "),GP=n(BMe,"A",{href:!0});var AVr=s(GP);$ho=r(AVr,"MPNetForMaskedLM"),AVr.forEach(t),Iho=r(BMe," (MPNet model)"),BMe.forEach(t),jho=i(S),Y_=n(S,"LI",{});var xMe=s(Y_);kee=n(xMe,"STRONG",{});var LVr=s(kee);Dho=r(LVr,"openai-gpt"),LVr.forEach(t),Nho=r(xMe," \u2014 "),XP=n(xMe,"A",{href:!0});var BVr=s(XP);qho=r(BVr,"OpenAIGPTLMHeadModel"),BVr.forEach(t),Oho=r(xMe," (OpenAI GPT model)"),xMe.forEach(t),Gho=i(S),K_=n(S,"LI",{});var kMe=s(K_);Ree=n(kMe,"STRONG",{});var xVr=s(Ree);Xho=r(xVr,"retribert"),xVr.forEach(t),Vho=r(kMe," \u2014 "),VP=n(kMe,"A",{href:!0});var kVr=s(VP);zho=r(kVr,"RetriBertModel"),kVr.forEach(t),Who=r(kMe," (RetriBERT model)"),kMe.forEach(t),Qho=i(S),Z_=n(S,"LI",{});var RMe=s(Z_);See=n(RMe,"STRONG",{});var RVr=s(See);Hho=r(RVr,"roberta"),RVr.forEach(t),Uho=r(RMe," \u2014 "),zP=n(RMe,"A",{href:!0});var SVr=s(zP);Jho=r(SVr,"RobertaForMaskedLM"),SVr.forEach(t),Yho=r(RMe," (RoBERTa model)"),RMe.forEach(t),Kho=i(S),eu=n(S,"LI",{});var SMe=s(eu);Pee=n(SMe,"STRONG",{});var PVr=s(Pee);Zho=r(PVr,"squeezebert"),PVr.forEach(t),epo=r(SMe," \u2014 "),WP=n(SMe,"A",{href:!0});var $Vr=s(WP);opo=r($Vr,"SqueezeBertForMaskedLM"),$Vr.forEach(t),rpo=r(SMe," (SqueezeBERT model)"),SMe.forEach(t),tpo=i(S),ou=n(S,"LI",{});var PMe=s(ou);$ee=n(PMe,"STRONG",{});var IVr=s($ee);apo=r(IVr,"t5"),IVr.forEach(t),npo=r(PMe," \u2014 "),QP=n(PMe,"A",{href:!0});var jVr=s(QP);spo=r(jVr,"T5ForConditionalGeneration"),jVr.forEach(t),lpo=r(PMe," (T5 model)"),PMe.forEach(t),ipo=i(S),ru=n(S,"LI",{});var $Me=s(ru);Iee=n($Me,"STRONG",{});var DVr=s(Iee);dpo=r(DVr,"tapas"),DVr.forEach(t),cpo=r($Me," \u2014 "),HP=n($Me,"A",{href:!0});var NVr=s(HP);fpo=r(NVr,"TapasForMaskedLM"),NVr.forEach(t),mpo=r($Me," (TAPAS model)"),$Me.forEach(t),gpo=i(S),tu=n(S,"LI",{});var IMe=s(tu);jee=n(IMe,"STRONG",{});var qVr=s(jee);hpo=r(qVr,"transfo-xl"),qVr.forEach(t),ppo=r(IMe," \u2014 "),UP=n(IMe,"A",{href:!0});var OVr=s(UP);_po=r(OVr,"TransfoXLLMHeadModel"),OVr.forEach(t),upo=r(IMe," (Transformer-XL model)"),IMe.forEach(t),bpo=i(S),au=n(S,"LI",{});var jMe=s(au);Dee=n(jMe,"STRONG",{});var GVr=s(Dee);vpo=r(GVr,"unispeech"),GVr.forEach(t),Tpo=r(jMe," \u2014 "),JP=n(jMe,"A",{href:!0});var XVr=s(JP);Fpo=r(XVr,"UniSpeechForPreTraining"),XVr.forEach(t),Cpo=r(jMe," (UniSpeech model)"),jMe.forEach(t),Mpo=i(S),nu=n(S,"LI",{});var DMe=s(nu);Nee=n(DMe,"STRONG",{});var VVr=s(Nee);Epo=r(VVr,"unispeech-sat"),VVr.forEach(t),ypo=r(DMe," \u2014 "),YP=n(DMe,"A",{href:!0});var zVr=s(YP);wpo=r(zVr,"UniSpeechSatForPreTraining"),zVr.forEach(t),Apo=r(DMe," (UniSpeechSat model)"),DMe.forEach(t),Lpo=i(S),su=n(S,"LI",{});var NMe=s(su);qee=n(NMe,"STRONG",{});var WVr=s(qee);Bpo=r(WVr,"visual_bert"),WVr.forEach(t),xpo=r(NMe," \u2014 "),KP=n(NMe,"A",{href:!0});var QVr=s(KP);kpo=r(QVr,"VisualBertForPreTraining"),QVr.forEach(t),Rpo=r(NMe," (VisualBert model)"),NMe.forEach(t),Spo=i(S),lu=n(S,"LI",{});var qMe=s(lu);Oee=n(qMe,"STRONG",{});var HVr=s(Oee);Ppo=r(HVr,"vit_mae"),HVr.forEach(t),$po=r(qMe," \u2014 "),ZP=n(qMe,"A",{href:!0});var UVr=s(ZP);Ipo=r(UVr,"ViTMAEForPreTraining"),UVr.forEach(t),jpo=r(qMe," (ViTMAE model)"),qMe.forEach(t),Dpo=i(S),iu=n(S,"LI",{});var OMe=s(iu);Gee=n(OMe,"STRONG",{});var JVr=s(Gee);Npo=r(JVr,"wav2vec2"),JVr.forEach(t),qpo=r(OMe," \u2014 "),e$=n(OMe,"A",{href:!0});var YVr=s(e$);Opo=r(YVr,"Wav2Vec2ForPreTraining"),YVr.forEach(t),Gpo=r(OMe," (Wav2Vec2 model)"),OMe.forEach(t),Xpo=i(S),du=n(S,"LI",{});var GMe=s(du);Xee=n(GMe,"STRONG",{});var KVr=s(Xee);Vpo=r(KVr,"xlm"),KVr.forEach(t),zpo=r(GMe," \u2014 "),o$=n(GMe,"A",{href:!0});var ZVr=s(o$);Wpo=r(ZVr,"XLMWithLMHeadModel"),ZVr.forEach(t),Qpo=r(GMe," (XLM model)"),GMe.forEach(t),Hpo=i(S),cu=n(S,"LI",{});var XMe=s(cu);Vee=n(XMe,"STRONG",{});var ezr=s(Vee);Upo=r(ezr,"xlm-roberta"),ezr.forEach(t),Jpo=r(XMe," \u2014 "),r$=n(XMe,"A",{href:!0});var ozr=s(r$);Ypo=r(ozr,"XLMRobertaForMaskedLM"),ozr.forEach(t),Kpo=r(XMe," (XLM-RoBERTa model)"),XMe.forEach(t),Zpo=i(S),fu=n(S,"LI",{});var VMe=s(fu);zee=n(VMe,"STRONG",{});var rzr=s(zee);e_o=r(rzr,"xlm-roberta-xl"),rzr.forEach(t),o_o=r(VMe," \u2014 "),t$=n(VMe,"A",{href:!0});var tzr=s(t$);r_o=r(tzr,"XLMRobertaXLForMaskedLM"),tzr.forEach(t),t_o=r(VMe," (XLM-RoBERTa-XL model)"),VMe.forEach(t),a_o=i(S),mu=n(S,"LI",{});var zMe=s(mu);Wee=n(zMe,"STRONG",{});var azr=s(Wee);n_o=r(azr,"xlnet"),azr.forEach(t),s_o=r(zMe," \u2014 "),a$=n(zMe,"A",{href:!0});var nzr=s(a$);l_o=r(nzr,"XLNetLMHeadModel"),nzr.forEach(t),i_o=r(zMe," (XLNet model)"),zMe.forEach(t),S.forEach(t),d_o=i(Vt),gu=n(Vt,"P",{});var WMe=s(gu);c_o=r(WMe,"The model is set in evaluation mode by default using "),Qee=n(WMe,"CODE",{});var szr=s(Qee);f_o=r(szr,"model.eval()"),szr.forEach(t),m_o=r(WMe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Hee=n(WMe,"CODE",{});var lzr=s(Hee);g_o=r(lzr,"model.train()"),lzr.forEach(t),WMe.forEach(t),h_o=i(Vt),Uee=n(Vt,"P",{});var izr=s(Uee);p_o=r(izr,"Examples:"),izr.forEach(t),__o=i(Vt),m(Z4.$$.fragment,Vt),Vt.forEach(t),Zs.forEach(t),dke=i(d),cd=n(d,"H2",{class:!0});var TSe=s(cd);hu=n(TSe,"A",{id:!0,class:!0,href:!0});var dzr=s(hu);Jee=n(dzr,"SPAN",{});var czr=s(Jee);m(eE.$$.fragment,czr),czr.forEach(t),dzr.forEach(t),u_o=i(TSe),Yee=n(TSe,"SPAN",{});var fzr=s(Yee);b_o=r(fzr,"AutoModelForCausalLM"),fzr.forEach(t),TSe.forEach(t),cke=i(d),Zo=n(d,"DIV",{class:!0});var ol=s(Zo);m(oE.$$.fragment,ol),v_o=i(ol),fd=n(ol,"P",{});var Jz=s(fd);T_o=r(Jz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Kee=n(Jz,"CODE",{});var mzr=s(Kee);F_o=r(mzr,"from_pretrained()"),mzr.forEach(t),C_o=r(Jz,"class method or the "),Zee=n(Jz,"CODE",{});var gzr=s(Zee);M_o=r(gzr,"from_config()"),gzr.forEach(t),E_o=r(Jz,`class
method.`),Jz.forEach(t),y_o=i(ol),rE=n(ol,"P",{});var FSe=s(rE);w_o=r(FSe,"This class cannot be instantiated directly using "),eoe=n(FSe,"CODE",{});var hzr=s(eoe);A_o=r(hzr,"__init__()"),hzr.forEach(t),L_o=r(FSe," (throws an error)."),FSe.forEach(t),B_o=i(ol),Hr=n(ol,"DIV",{class:!0});var rl=s(Hr);m(tE.$$.fragment,rl),x_o=i(rl),ooe=n(rl,"P",{});var pzr=s(ooe);k_o=r(pzr,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),pzr.forEach(t),R_o=i(rl),md=n(rl,"P",{});var Yz=s(md);S_o=r(Yz,`Note:
Loading a model from its configuration file does `),roe=n(Yz,"STRONG",{});var _zr=s(roe);P_o=r(_zr,"not"),_zr.forEach(t),$_o=r(Yz,` load the model weights. It only affects the
model\u2019s configuration. Use `),toe=n(Yz,"CODE",{});var uzr=s(toe);I_o=r(uzr,"from_pretrained()"),uzr.forEach(t),j_o=r(Yz,"to load the model weights."),Yz.forEach(t),D_o=i(rl),aoe=n(rl,"P",{});var bzr=s(aoe);N_o=r(bzr,"Examples:"),bzr.forEach(t),q_o=i(rl),m(aE.$$.fragment,rl),rl.forEach(t),O_o=i(ol),Ne=n(ol,"DIV",{class:!0});var zt=s(Ne);m(nE.$$.fragment,zt),G_o=i(zt),noe=n(zt,"P",{});var vzr=s(noe);X_o=r(vzr,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),vzr.forEach(t),V_o=i(zt),Ja=n(zt,"P",{});var fM=s(Ja);z_o=r(fM,"The model class to instantiate is selected based on the "),soe=n(fM,"CODE",{});var Tzr=s(soe);W_o=r(Tzr,"model_type"),Tzr.forEach(t),Q_o=r(fM,` property of the config object (either
passed as an argument or loaded from `),loe=n(fM,"CODE",{});var Fzr=s(loe);H_o=r(Fzr,"pretrained_model_name_or_path"),Fzr.forEach(t),U_o=r(fM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ioe=n(fM,"CODE",{});var Czr=s(ioe);J_o=r(Czr,"pretrained_model_name_or_path"),Czr.forEach(t),Y_o=r(fM,":"),fM.forEach(t),K_o=i(zt),$=n(zt,"UL",{});var j=s($);pu=n(j,"LI",{});var QMe=s(pu);doe=n(QMe,"STRONG",{});var Mzr=s(doe);Z_o=r(Mzr,"bart"),Mzr.forEach(t),euo=r(QMe," \u2014 "),n$=n(QMe,"A",{href:!0});var Ezr=s(n$);ouo=r(Ezr,"BartForCausalLM"),Ezr.forEach(t),ruo=r(QMe," (BART model)"),QMe.forEach(t),tuo=i(j),_u=n(j,"LI",{});var HMe=s(_u);coe=n(HMe,"STRONG",{});var yzr=s(coe);auo=r(yzr,"bert"),yzr.forEach(t),nuo=r(HMe," \u2014 "),s$=n(HMe,"A",{href:!0});var wzr=s(s$);suo=r(wzr,"BertLMHeadModel"),wzr.forEach(t),luo=r(HMe," (BERT model)"),HMe.forEach(t),iuo=i(j),uu=n(j,"LI",{});var UMe=s(uu);foe=n(UMe,"STRONG",{});var Azr=s(foe);duo=r(Azr,"bert-generation"),Azr.forEach(t),cuo=r(UMe," \u2014 "),l$=n(UMe,"A",{href:!0});var Lzr=s(l$);fuo=r(Lzr,"BertGenerationDecoder"),Lzr.forEach(t),muo=r(UMe," (Bert Generation model)"),UMe.forEach(t),guo=i(j),bu=n(j,"LI",{});var JMe=s(bu);moe=n(JMe,"STRONG",{});var Bzr=s(moe);huo=r(Bzr,"big_bird"),Bzr.forEach(t),puo=r(JMe," \u2014 "),i$=n(JMe,"A",{href:!0});var xzr=s(i$);_uo=r(xzr,"BigBirdForCausalLM"),xzr.forEach(t),uuo=r(JMe," (BigBird model)"),JMe.forEach(t),buo=i(j),vu=n(j,"LI",{});var YMe=s(vu);goe=n(YMe,"STRONG",{});var kzr=s(goe);vuo=r(kzr,"bigbird_pegasus"),kzr.forEach(t),Tuo=r(YMe," \u2014 "),d$=n(YMe,"A",{href:!0});var Rzr=s(d$);Fuo=r(Rzr,"BigBirdPegasusForCausalLM"),Rzr.forEach(t),Cuo=r(YMe," (BigBirdPegasus model)"),YMe.forEach(t),Muo=i(j),Tu=n(j,"LI",{});var KMe=s(Tu);hoe=n(KMe,"STRONG",{});var Szr=s(hoe);Euo=r(Szr,"blenderbot"),Szr.forEach(t),yuo=r(KMe," \u2014 "),c$=n(KMe,"A",{href:!0});var Pzr=s(c$);wuo=r(Pzr,"BlenderbotForCausalLM"),Pzr.forEach(t),Auo=r(KMe," (Blenderbot model)"),KMe.forEach(t),Luo=i(j),Fu=n(j,"LI",{});var ZMe=s(Fu);poe=n(ZMe,"STRONG",{});var $zr=s(poe);Buo=r($zr,"blenderbot-small"),$zr.forEach(t),xuo=r(ZMe," \u2014 "),f$=n(ZMe,"A",{href:!0});var Izr=s(f$);kuo=r(Izr,"BlenderbotSmallForCausalLM"),Izr.forEach(t),Ruo=r(ZMe," (BlenderbotSmall model)"),ZMe.forEach(t),Suo=i(j),Cu=n(j,"LI",{});var e4e=s(Cu);_oe=n(e4e,"STRONG",{});var jzr=s(_oe);Puo=r(jzr,"camembert"),jzr.forEach(t),$uo=r(e4e," \u2014 "),m$=n(e4e,"A",{href:!0});var Dzr=s(m$);Iuo=r(Dzr,"CamembertForCausalLM"),Dzr.forEach(t),juo=r(e4e," (CamemBERT model)"),e4e.forEach(t),Duo=i(j),Mu=n(j,"LI",{});var o4e=s(Mu);uoe=n(o4e,"STRONG",{});var Nzr=s(uoe);Nuo=r(Nzr,"ctrl"),Nzr.forEach(t),quo=r(o4e," \u2014 "),g$=n(o4e,"A",{href:!0});var qzr=s(g$);Ouo=r(qzr,"CTRLLMHeadModel"),qzr.forEach(t),Guo=r(o4e," (CTRL model)"),o4e.forEach(t),Xuo=i(j),Eu=n(j,"LI",{});var r4e=s(Eu);boe=n(r4e,"STRONG",{});var Ozr=s(boe);Vuo=r(Ozr,"data2vec-text"),Ozr.forEach(t),zuo=r(r4e," \u2014 "),h$=n(r4e,"A",{href:!0});var Gzr=s(h$);Wuo=r(Gzr,"Data2VecTextForCausalLM"),Gzr.forEach(t),Quo=r(r4e," (Data2VecText model)"),r4e.forEach(t),Huo=i(j),yu=n(j,"LI",{});var t4e=s(yu);voe=n(t4e,"STRONG",{});var Xzr=s(voe);Uuo=r(Xzr,"electra"),Xzr.forEach(t),Juo=r(t4e," \u2014 "),p$=n(t4e,"A",{href:!0});var Vzr=s(p$);Yuo=r(Vzr,"ElectraForCausalLM"),Vzr.forEach(t),Kuo=r(t4e," (ELECTRA model)"),t4e.forEach(t),Zuo=i(j),wu=n(j,"LI",{});var a4e=s(wu);Toe=n(a4e,"STRONG",{});var zzr=s(Toe);e1o=r(zzr,"gpt2"),zzr.forEach(t),o1o=r(a4e," \u2014 "),_$=n(a4e,"A",{href:!0});var Wzr=s(_$);r1o=r(Wzr,"GPT2LMHeadModel"),Wzr.forEach(t),t1o=r(a4e," (OpenAI GPT-2 model)"),a4e.forEach(t),a1o=i(j),Au=n(j,"LI",{});var n4e=s(Au);Foe=n(n4e,"STRONG",{});var Qzr=s(Foe);n1o=r(Qzr,"gpt_neo"),Qzr.forEach(t),s1o=r(n4e," \u2014 "),u$=n(n4e,"A",{href:!0});var Hzr=s(u$);l1o=r(Hzr,"GPTNeoForCausalLM"),Hzr.forEach(t),i1o=r(n4e," (GPT Neo model)"),n4e.forEach(t),d1o=i(j),Lu=n(j,"LI",{});var s4e=s(Lu);Coe=n(s4e,"STRONG",{});var Uzr=s(Coe);c1o=r(Uzr,"gptj"),Uzr.forEach(t),f1o=r(s4e," \u2014 "),b$=n(s4e,"A",{href:!0});var Jzr=s(b$);m1o=r(Jzr,"GPTJForCausalLM"),Jzr.forEach(t),g1o=r(s4e," (GPT-J model)"),s4e.forEach(t),h1o=i(j),Bu=n(j,"LI",{});var l4e=s(Bu);Moe=n(l4e,"STRONG",{});var Yzr=s(Moe);p1o=r(Yzr,"marian"),Yzr.forEach(t),_1o=r(l4e," \u2014 "),v$=n(l4e,"A",{href:!0});var Kzr=s(v$);u1o=r(Kzr,"MarianForCausalLM"),Kzr.forEach(t),b1o=r(l4e," (Marian model)"),l4e.forEach(t),v1o=i(j),xu=n(j,"LI",{});var i4e=s(xu);Eoe=n(i4e,"STRONG",{});var Zzr=s(Eoe);T1o=r(Zzr,"mbart"),Zzr.forEach(t),F1o=r(i4e," \u2014 "),T$=n(i4e,"A",{href:!0});var eWr=s(T$);C1o=r(eWr,"MBartForCausalLM"),eWr.forEach(t),M1o=r(i4e," (mBART model)"),i4e.forEach(t),E1o=i(j),ku=n(j,"LI",{});var d4e=s(ku);yoe=n(d4e,"STRONG",{});var oWr=s(yoe);y1o=r(oWr,"megatron-bert"),oWr.forEach(t),w1o=r(d4e," \u2014 "),F$=n(d4e,"A",{href:!0});var rWr=s(F$);A1o=r(rWr,"MegatronBertForCausalLM"),rWr.forEach(t),L1o=r(d4e," (MegatronBert model)"),d4e.forEach(t),B1o=i(j),Ru=n(j,"LI",{});var c4e=s(Ru);woe=n(c4e,"STRONG",{});var tWr=s(woe);x1o=r(tWr,"openai-gpt"),tWr.forEach(t),k1o=r(c4e," \u2014 "),C$=n(c4e,"A",{href:!0});var aWr=s(C$);R1o=r(aWr,"OpenAIGPTLMHeadModel"),aWr.forEach(t),S1o=r(c4e," (OpenAI GPT model)"),c4e.forEach(t),P1o=i(j),Su=n(j,"LI",{});var f4e=s(Su);Aoe=n(f4e,"STRONG",{});var nWr=s(Aoe);$1o=r(nWr,"pegasus"),nWr.forEach(t),I1o=r(f4e," \u2014 "),M$=n(f4e,"A",{href:!0});var sWr=s(M$);j1o=r(sWr,"PegasusForCausalLM"),sWr.forEach(t),D1o=r(f4e," (Pegasus model)"),f4e.forEach(t),N1o=i(j),Pu=n(j,"LI",{});var m4e=s(Pu);Loe=n(m4e,"STRONG",{});var lWr=s(Loe);q1o=r(lWr,"plbart"),lWr.forEach(t),O1o=r(m4e," \u2014 "),E$=n(m4e,"A",{href:!0});var iWr=s(E$);G1o=r(iWr,"PLBartForCausalLM"),iWr.forEach(t),X1o=r(m4e," (PLBart model)"),m4e.forEach(t),V1o=i(j),$u=n(j,"LI",{});var g4e=s($u);Boe=n(g4e,"STRONG",{});var dWr=s(Boe);z1o=r(dWr,"prophetnet"),dWr.forEach(t),W1o=r(g4e," \u2014 "),y$=n(g4e,"A",{href:!0});var cWr=s(y$);Q1o=r(cWr,"ProphetNetForCausalLM"),cWr.forEach(t),H1o=r(g4e," (ProphetNet model)"),g4e.forEach(t),U1o=i(j),Iu=n(j,"LI",{});var h4e=s(Iu);xoe=n(h4e,"STRONG",{});var fWr=s(xoe);J1o=r(fWr,"qdqbert"),fWr.forEach(t),Y1o=r(h4e," \u2014 "),w$=n(h4e,"A",{href:!0});var mWr=s(w$);K1o=r(mWr,"QDQBertLMHeadModel"),mWr.forEach(t),Z1o=r(h4e," (QDQBert model)"),h4e.forEach(t),ebo=i(j),ju=n(j,"LI",{});var p4e=s(ju);koe=n(p4e,"STRONG",{});var gWr=s(koe);obo=r(gWr,"reformer"),gWr.forEach(t),rbo=r(p4e," \u2014 "),A$=n(p4e,"A",{href:!0});var hWr=s(A$);tbo=r(hWr,"ReformerModelWithLMHead"),hWr.forEach(t),abo=r(p4e," (Reformer model)"),p4e.forEach(t),nbo=i(j),Du=n(j,"LI",{});var _4e=s(Du);Roe=n(_4e,"STRONG",{});var pWr=s(Roe);sbo=r(pWr,"rembert"),pWr.forEach(t),lbo=r(_4e," \u2014 "),L$=n(_4e,"A",{href:!0});var _Wr=s(L$);ibo=r(_Wr,"RemBertForCausalLM"),_Wr.forEach(t),dbo=r(_4e," (RemBERT model)"),_4e.forEach(t),cbo=i(j),Nu=n(j,"LI",{});var u4e=s(Nu);Soe=n(u4e,"STRONG",{});var uWr=s(Soe);fbo=r(uWr,"roberta"),uWr.forEach(t),mbo=r(u4e," \u2014 "),B$=n(u4e,"A",{href:!0});var bWr=s(B$);gbo=r(bWr,"RobertaForCausalLM"),bWr.forEach(t),hbo=r(u4e," (RoBERTa model)"),u4e.forEach(t),pbo=i(j),qu=n(j,"LI",{});var b4e=s(qu);Poe=n(b4e,"STRONG",{});var vWr=s(Poe);_bo=r(vWr,"roformer"),vWr.forEach(t),ubo=r(b4e," \u2014 "),x$=n(b4e,"A",{href:!0});var TWr=s(x$);bbo=r(TWr,"RoFormerForCausalLM"),TWr.forEach(t),vbo=r(b4e," (RoFormer model)"),b4e.forEach(t),Tbo=i(j),Ou=n(j,"LI",{});var v4e=s(Ou);$oe=n(v4e,"STRONG",{});var FWr=s($oe);Fbo=r(FWr,"speech_to_text_2"),FWr.forEach(t),Cbo=r(v4e," \u2014 "),k$=n(v4e,"A",{href:!0});var CWr=s(k$);Mbo=r(CWr,"Speech2Text2ForCausalLM"),CWr.forEach(t),Ebo=r(v4e," (Speech2Text2 model)"),v4e.forEach(t),ybo=i(j),Gu=n(j,"LI",{});var T4e=s(Gu);Ioe=n(T4e,"STRONG",{});var MWr=s(Ioe);wbo=r(MWr,"transfo-xl"),MWr.forEach(t),Abo=r(T4e," \u2014 "),R$=n(T4e,"A",{href:!0});var EWr=s(R$);Lbo=r(EWr,"TransfoXLLMHeadModel"),EWr.forEach(t),Bbo=r(T4e," (Transformer-XL model)"),T4e.forEach(t),xbo=i(j),Xu=n(j,"LI",{});var F4e=s(Xu);joe=n(F4e,"STRONG",{});var yWr=s(joe);kbo=r(yWr,"trocr"),yWr.forEach(t),Rbo=r(F4e," \u2014 "),S$=n(F4e,"A",{href:!0});var wWr=s(S$);Sbo=r(wWr,"TrOCRForCausalLM"),wWr.forEach(t),Pbo=r(F4e," (TrOCR model)"),F4e.forEach(t),$bo=i(j),Vu=n(j,"LI",{});var C4e=s(Vu);Doe=n(C4e,"STRONG",{});var AWr=s(Doe);Ibo=r(AWr,"xglm"),AWr.forEach(t),jbo=r(C4e," \u2014 "),P$=n(C4e,"A",{href:!0});var LWr=s(P$);Dbo=r(LWr,"XGLMForCausalLM"),LWr.forEach(t),Nbo=r(C4e," (XGLM model)"),C4e.forEach(t),qbo=i(j),zu=n(j,"LI",{});var M4e=s(zu);Noe=n(M4e,"STRONG",{});var BWr=s(Noe);Obo=r(BWr,"xlm"),BWr.forEach(t),Gbo=r(M4e," \u2014 "),$$=n(M4e,"A",{href:!0});var xWr=s($$);Xbo=r(xWr,"XLMWithLMHeadModel"),xWr.forEach(t),Vbo=r(M4e," (XLM model)"),M4e.forEach(t),zbo=i(j),Wu=n(j,"LI",{});var E4e=s(Wu);qoe=n(E4e,"STRONG",{});var kWr=s(qoe);Wbo=r(kWr,"xlm-prophetnet"),kWr.forEach(t),Qbo=r(E4e," \u2014 "),I$=n(E4e,"A",{href:!0});var RWr=s(I$);Hbo=r(RWr,"XLMProphetNetForCausalLM"),RWr.forEach(t),Ubo=r(E4e," (XLMProphetNet model)"),E4e.forEach(t),Jbo=i(j),Qu=n(j,"LI",{});var y4e=s(Qu);Ooe=n(y4e,"STRONG",{});var SWr=s(Ooe);Ybo=r(SWr,"xlm-roberta"),SWr.forEach(t),Kbo=r(y4e," \u2014 "),j$=n(y4e,"A",{href:!0});var PWr=s(j$);Zbo=r(PWr,"XLMRobertaForCausalLM"),PWr.forEach(t),e5o=r(y4e," (XLM-RoBERTa model)"),y4e.forEach(t),o5o=i(j),Hu=n(j,"LI",{});var w4e=s(Hu);Goe=n(w4e,"STRONG",{});var $Wr=s(Goe);r5o=r($Wr,"xlm-roberta-xl"),$Wr.forEach(t),t5o=r(w4e," \u2014 "),D$=n(w4e,"A",{href:!0});var IWr=s(D$);a5o=r(IWr,"XLMRobertaXLForCausalLM"),IWr.forEach(t),n5o=r(w4e," (XLM-RoBERTa-XL model)"),w4e.forEach(t),s5o=i(j),Uu=n(j,"LI",{});var A4e=s(Uu);Xoe=n(A4e,"STRONG",{});var jWr=s(Xoe);l5o=r(jWr,"xlnet"),jWr.forEach(t),i5o=r(A4e," \u2014 "),N$=n(A4e,"A",{href:!0});var DWr=s(N$);d5o=r(DWr,"XLNetLMHeadModel"),DWr.forEach(t),c5o=r(A4e," (XLNet model)"),A4e.forEach(t),j.forEach(t),f5o=i(zt),Ju=n(zt,"P",{});var L4e=s(Ju);m5o=r(L4e,"The model is set in evaluation mode by default using "),Voe=n(L4e,"CODE",{});var NWr=s(Voe);g5o=r(NWr,"model.eval()"),NWr.forEach(t),h5o=r(L4e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),zoe=n(L4e,"CODE",{});var qWr=s(zoe);p5o=r(qWr,"model.train()"),qWr.forEach(t),L4e.forEach(t),_5o=i(zt),Woe=n(zt,"P",{});var OWr=s(Woe);u5o=r(OWr,"Examples:"),OWr.forEach(t),b5o=i(zt),m(sE.$$.fragment,zt),zt.forEach(t),ol.forEach(t),fke=i(d),gd=n(d,"H2",{class:!0});var CSe=s(gd);Yu=n(CSe,"A",{id:!0,class:!0,href:!0});var GWr=s(Yu);Qoe=n(GWr,"SPAN",{});var XWr=s(Qoe);m(lE.$$.fragment,XWr),XWr.forEach(t),GWr.forEach(t),v5o=i(CSe),Hoe=n(CSe,"SPAN",{});var VWr=s(Hoe);T5o=r(VWr,"AutoModelForMaskedLM"),VWr.forEach(t),CSe.forEach(t),mke=i(d),er=n(d,"DIV",{class:!0});var tl=s(er);m(iE.$$.fragment,tl),F5o=i(tl),hd=n(tl,"P",{});var Kz=s(hd);C5o=r(Kz,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Uoe=n(Kz,"CODE",{});var zWr=s(Uoe);M5o=r(zWr,"from_pretrained()"),zWr.forEach(t),E5o=r(Kz,"class method or the "),Joe=n(Kz,"CODE",{});var WWr=s(Joe);y5o=r(WWr,"from_config()"),WWr.forEach(t),w5o=r(Kz,`class
method.`),Kz.forEach(t),A5o=i(tl),dE=n(tl,"P",{});var MSe=s(dE);L5o=r(MSe,"This class cannot be instantiated directly using "),Yoe=n(MSe,"CODE",{});var QWr=s(Yoe);B5o=r(QWr,"__init__()"),QWr.forEach(t),x5o=r(MSe," (throws an error)."),MSe.forEach(t),k5o=i(tl),Ur=n(tl,"DIV",{class:!0});var al=s(Ur);m(cE.$$.fragment,al),R5o=i(al),Koe=n(al,"P",{});var HWr=s(Koe);S5o=r(HWr,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),HWr.forEach(t),P5o=i(al),pd=n(al,"P",{});var Zz=s(pd);$5o=r(Zz,`Note:
Loading a model from its configuration file does `),Zoe=n(Zz,"STRONG",{});var UWr=s(Zoe);I5o=r(UWr,"not"),UWr.forEach(t),j5o=r(Zz,` load the model weights. It only affects the
model\u2019s configuration. Use `),ere=n(Zz,"CODE",{});var JWr=s(ere);D5o=r(JWr,"from_pretrained()"),JWr.forEach(t),N5o=r(Zz,"to load the model weights."),Zz.forEach(t),q5o=i(al),ore=n(al,"P",{});var YWr=s(ore);O5o=r(YWr,"Examples:"),YWr.forEach(t),G5o=i(al),m(fE.$$.fragment,al),al.forEach(t),X5o=i(tl),qe=n(tl,"DIV",{class:!0});var Wt=s(qe);m(mE.$$.fragment,Wt),V5o=i(Wt),rre=n(Wt,"P",{});var KWr=s(rre);z5o=r(KWr,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),KWr.forEach(t),W5o=i(Wt),Ya=n(Wt,"P",{});var mM=s(Ya);Q5o=r(mM,"The model class to instantiate is selected based on the "),tre=n(mM,"CODE",{});var ZWr=s(tre);H5o=r(ZWr,"model_type"),ZWr.forEach(t),U5o=r(mM,` property of the config object (either
passed as an argument or loaded from `),are=n(mM,"CODE",{});var eQr=s(are);J5o=r(eQr,"pretrained_model_name_or_path"),eQr.forEach(t),Y5o=r(mM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nre=n(mM,"CODE",{});var oQr=s(nre);K5o=r(oQr,"pretrained_model_name_or_path"),oQr.forEach(t),Z5o=r(mM,":"),mM.forEach(t),e2o=i(Wt),I=n(Wt,"UL",{});var D=s(I);Ku=n(D,"LI",{});var B4e=s(Ku);sre=n(B4e,"STRONG",{});var rQr=s(sre);o2o=r(rQr,"albert"),rQr.forEach(t),r2o=r(B4e," \u2014 "),q$=n(B4e,"A",{href:!0});var tQr=s(q$);t2o=r(tQr,"AlbertForMaskedLM"),tQr.forEach(t),a2o=r(B4e," (ALBERT model)"),B4e.forEach(t),n2o=i(D),Zu=n(D,"LI",{});var x4e=s(Zu);lre=n(x4e,"STRONG",{});var aQr=s(lre);s2o=r(aQr,"bart"),aQr.forEach(t),l2o=r(x4e," \u2014 "),O$=n(x4e,"A",{href:!0});var nQr=s(O$);i2o=r(nQr,"BartForConditionalGeneration"),nQr.forEach(t),d2o=r(x4e," (BART model)"),x4e.forEach(t),c2o=i(D),e1=n(D,"LI",{});var k4e=s(e1);ire=n(k4e,"STRONG",{});var sQr=s(ire);f2o=r(sQr,"bert"),sQr.forEach(t),m2o=r(k4e," \u2014 "),G$=n(k4e,"A",{href:!0});var lQr=s(G$);g2o=r(lQr,"BertForMaskedLM"),lQr.forEach(t),h2o=r(k4e," (BERT model)"),k4e.forEach(t),p2o=i(D),o1=n(D,"LI",{});var R4e=s(o1);dre=n(R4e,"STRONG",{});var iQr=s(dre);_2o=r(iQr,"big_bird"),iQr.forEach(t),u2o=r(R4e," \u2014 "),X$=n(R4e,"A",{href:!0});var dQr=s(X$);b2o=r(dQr,"BigBirdForMaskedLM"),dQr.forEach(t),v2o=r(R4e," (BigBird model)"),R4e.forEach(t),T2o=i(D),r1=n(D,"LI",{});var S4e=s(r1);cre=n(S4e,"STRONG",{});var cQr=s(cre);F2o=r(cQr,"camembert"),cQr.forEach(t),C2o=r(S4e," \u2014 "),V$=n(S4e,"A",{href:!0});var fQr=s(V$);M2o=r(fQr,"CamembertForMaskedLM"),fQr.forEach(t),E2o=r(S4e," (CamemBERT model)"),S4e.forEach(t),y2o=i(D),t1=n(D,"LI",{});var P4e=s(t1);fre=n(P4e,"STRONG",{});var mQr=s(fre);w2o=r(mQr,"convbert"),mQr.forEach(t),A2o=r(P4e," \u2014 "),z$=n(P4e,"A",{href:!0});var gQr=s(z$);L2o=r(gQr,"ConvBertForMaskedLM"),gQr.forEach(t),B2o=r(P4e," (ConvBERT model)"),P4e.forEach(t),x2o=i(D),a1=n(D,"LI",{});var $4e=s(a1);mre=n($4e,"STRONG",{});var hQr=s(mre);k2o=r(hQr,"data2vec-text"),hQr.forEach(t),R2o=r($4e," \u2014 "),W$=n($4e,"A",{href:!0});var pQr=s(W$);S2o=r(pQr,"Data2VecTextForMaskedLM"),pQr.forEach(t),P2o=r($4e," (Data2VecText model)"),$4e.forEach(t),$2o=i(D),n1=n(D,"LI",{});var I4e=s(n1);gre=n(I4e,"STRONG",{});var _Qr=s(gre);I2o=r(_Qr,"deberta"),_Qr.forEach(t),j2o=r(I4e," \u2014 "),Q$=n(I4e,"A",{href:!0});var uQr=s(Q$);D2o=r(uQr,"DebertaForMaskedLM"),uQr.forEach(t),N2o=r(I4e," (DeBERTa model)"),I4e.forEach(t),q2o=i(D),s1=n(D,"LI",{});var j4e=s(s1);hre=n(j4e,"STRONG",{});var bQr=s(hre);O2o=r(bQr,"deberta-v2"),bQr.forEach(t),G2o=r(j4e," \u2014 "),H$=n(j4e,"A",{href:!0});var vQr=s(H$);X2o=r(vQr,"DebertaV2ForMaskedLM"),vQr.forEach(t),V2o=r(j4e," (DeBERTa-v2 model)"),j4e.forEach(t),z2o=i(D),l1=n(D,"LI",{});var D4e=s(l1);pre=n(D4e,"STRONG",{});var TQr=s(pre);W2o=r(TQr,"distilbert"),TQr.forEach(t),Q2o=r(D4e," \u2014 "),U$=n(D4e,"A",{href:!0});var FQr=s(U$);H2o=r(FQr,"DistilBertForMaskedLM"),FQr.forEach(t),U2o=r(D4e," (DistilBERT model)"),D4e.forEach(t),J2o=i(D),i1=n(D,"LI",{});var N4e=s(i1);_re=n(N4e,"STRONG",{});var CQr=s(_re);Y2o=r(CQr,"electra"),CQr.forEach(t),K2o=r(N4e," \u2014 "),J$=n(N4e,"A",{href:!0});var MQr=s(J$);Z2o=r(MQr,"ElectraForMaskedLM"),MQr.forEach(t),evo=r(N4e," (ELECTRA model)"),N4e.forEach(t),ovo=i(D),d1=n(D,"LI",{});var q4e=s(d1);ure=n(q4e,"STRONG",{});var EQr=s(ure);rvo=r(EQr,"flaubert"),EQr.forEach(t),tvo=r(q4e," \u2014 "),Y$=n(q4e,"A",{href:!0});var yQr=s(Y$);avo=r(yQr,"FlaubertWithLMHeadModel"),yQr.forEach(t),nvo=r(q4e," (FlauBERT model)"),q4e.forEach(t),svo=i(D),c1=n(D,"LI",{});var O4e=s(c1);bre=n(O4e,"STRONG",{});var wQr=s(bre);lvo=r(wQr,"fnet"),wQr.forEach(t),ivo=r(O4e," \u2014 "),K$=n(O4e,"A",{href:!0});var AQr=s(K$);dvo=r(AQr,"FNetForMaskedLM"),AQr.forEach(t),cvo=r(O4e," (FNet model)"),O4e.forEach(t),fvo=i(D),f1=n(D,"LI",{});var G4e=s(f1);vre=n(G4e,"STRONG",{});var LQr=s(vre);mvo=r(LQr,"funnel"),LQr.forEach(t),gvo=r(G4e," \u2014 "),Z$=n(G4e,"A",{href:!0});var BQr=s(Z$);hvo=r(BQr,"FunnelForMaskedLM"),BQr.forEach(t),pvo=r(G4e," (Funnel Transformer model)"),G4e.forEach(t),_vo=i(D),m1=n(D,"LI",{});var X4e=s(m1);Tre=n(X4e,"STRONG",{});var xQr=s(Tre);uvo=r(xQr,"ibert"),xQr.forEach(t),bvo=r(X4e," \u2014 "),eI=n(X4e,"A",{href:!0});var kQr=s(eI);vvo=r(kQr,"IBertForMaskedLM"),kQr.forEach(t),Tvo=r(X4e," (I-BERT model)"),X4e.forEach(t),Fvo=i(D),g1=n(D,"LI",{});var V4e=s(g1);Fre=n(V4e,"STRONG",{});var RQr=s(Fre);Cvo=r(RQr,"layoutlm"),RQr.forEach(t),Mvo=r(V4e," \u2014 "),oI=n(V4e,"A",{href:!0});var SQr=s(oI);Evo=r(SQr,"LayoutLMForMaskedLM"),SQr.forEach(t),yvo=r(V4e," (LayoutLM model)"),V4e.forEach(t),wvo=i(D),h1=n(D,"LI",{});var z4e=s(h1);Cre=n(z4e,"STRONG",{});var PQr=s(Cre);Avo=r(PQr,"longformer"),PQr.forEach(t),Lvo=r(z4e," \u2014 "),rI=n(z4e,"A",{href:!0});var $Qr=s(rI);Bvo=r($Qr,"LongformerForMaskedLM"),$Qr.forEach(t),xvo=r(z4e," (Longformer model)"),z4e.forEach(t),kvo=i(D),p1=n(D,"LI",{});var W4e=s(p1);Mre=n(W4e,"STRONG",{});var IQr=s(Mre);Rvo=r(IQr,"mbart"),IQr.forEach(t),Svo=r(W4e," \u2014 "),tI=n(W4e,"A",{href:!0});var jQr=s(tI);Pvo=r(jQr,"MBartForConditionalGeneration"),jQr.forEach(t),$vo=r(W4e," (mBART model)"),W4e.forEach(t),Ivo=i(D),_1=n(D,"LI",{});var Q4e=s(_1);Ere=n(Q4e,"STRONG",{});var DQr=s(Ere);jvo=r(DQr,"megatron-bert"),DQr.forEach(t),Dvo=r(Q4e," \u2014 "),aI=n(Q4e,"A",{href:!0});var NQr=s(aI);Nvo=r(NQr,"MegatronBertForMaskedLM"),NQr.forEach(t),qvo=r(Q4e," (MegatronBert model)"),Q4e.forEach(t),Ovo=i(D),u1=n(D,"LI",{});var H4e=s(u1);yre=n(H4e,"STRONG",{});var qQr=s(yre);Gvo=r(qQr,"mobilebert"),qQr.forEach(t),Xvo=r(H4e," \u2014 "),nI=n(H4e,"A",{href:!0});var OQr=s(nI);Vvo=r(OQr,"MobileBertForMaskedLM"),OQr.forEach(t),zvo=r(H4e," (MobileBERT model)"),H4e.forEach(t),Wvo=i(D),b1=n(D,"LI",{});var U4e=s(b1);wre=n(U4e,"STRONG",{});var GQr=s(wre);Qvo=r(GQr,"mpnet"),GQr.forEach(t),Hvo=r(U4e," \u2014 "),sI=n(U4e,"A",{href:!0});var XQr=s(sI);Uvo=r(XQr,"MPNetForMaskedLM"),XQr.forEach(t),Jvo=r(U4e," (MPNet model)"),U4e.forEach(t),Yvo=i(D),v1=n(D,"LI",{});var J4e=s(v1);Are=n(J4e,"STRONG",{});var VQr=s(Are);Kvo=r(VQr,"nystromformer"),VQr.forEach(t),Zvo=r(J4e," \u2014 "),lI=n(J4e,"A",{href:!0});var zQr=s(lI);e6o=r(zQr,"NystromformerForMaskedLM"),zQr.forEach(t),o6o=r(J4e," (Nystromformer model)"),J4e.forEach(t),r6o=i(D),T1=n(D,"LI",{});var Y4e=s(T1);Lre=n(Y4e,"STRONG",{});var WQr=s(Lre);t6o=r(WQr,"perceiver"),WQr.forEach(t),a6o=r(Y4e," \u2014 "),iI=n(Y4e,"A",{href:!0});var QQr=s(iI);n6o=r(QQr,"PerceiverForMaskedLM"),QQr.forEach(t),s6o=r(Y4e," (Perceiver model)"),Y4e.forEach(t),l6o=i(D),F1=n(D,"LI",{});var K4e=s(F1);Bre=n(K4e,"STRONG",{});var HQr=s(Bre);i6o=r(HQr,"qdqbert"),HQr.forEach(t),d6o=r(K4e," \u2014 "),dI=n(K4e,"A",{href:!0});var UQr=s(dI);c6o=r(UQr,"QDQBertForMaskedLM"),UQr.forEach(t),f6o=r(K4e," (QDQBert model)"),K4e.forEach(t),m6o=i(D),C1=n(D,"LI",{});var Z4e=s(C1);xre=n(Z4e,"STRONG",{});var JQr=s(xre);g6o=r(JQr,"reformer"),JQr.forEach(t),h6o=r(Z4e," \u2014 "),cI=n(Z4e,"A",{href:!0});var YQr=s(cI);p6o=r(YQr,"ReformerForMaskedLM"),YQr.forEach(t),_6o=r(Z4e," (Reformer model)"),Z4e.forEach(t),u6o=i(D),M1=n(D,"LI",{});var eEe=s(M1);kre=n(eEe,"STRONG",{});var KQr=s(kre);b6o=r(KQr,"rembert"),KQr.forEach(t),v6o=r(eEe," \u2014 "),fI=n(eEe,"A",{href:!0});var ZQr=s(fI);T6o=r(ZQr,"RemBertForMaskedLM"),ZQr.forEach(t),F6o=r(eEe," (RemBERT model)"),eEe.forEach(t),C6o=i(D),E1=n(D,"LI",{});var oEe=s(E1);Rre=n(oEe,"STRONG",{});var eHr=s(Rre);M6o=r(eHr,"roberta"),eHr.forEach(t),E6o=r(oEe," \u2014 "),mI=n(oEe,"A",{href:!0});var oHr=s(mI);y6o=r(oHr,"RobertaForMaskedLM"),oHr.forEach(t),w6o=r(oEe," (RoBERTa model)"),oEe.forEach(t),A6o=i(D),y1=n(D,"LI",{});var rEe=s(y1);Sre=n(rEe,"STRONG",{});var rHr=s(Sre);L6o=r(rHr,"roformer"),rHr.forEach(t),B6o=r(rEe," \u2014 "),gI=n(rEe,"A",{href:!0});var tHr=s(gI);x6o=r(tHr,"RoFormerForMaskedLM"),tHr.forEach(t),k6o=r(rEe," (RoFormer model)"),rEe.forEach(t),R6o=i(D),w1=n(D,"LI",{});var tEe=s(w1);Pre=n(tEe,"STRONG",{});var aHr=s(Pre);S6o=r(aHr,"squeezebert"),aHr.forEach(t),P6o=r(tEe," \u2014 "),hI=n(tEe,"A",{href:!0});var nHr=s(hI);$6o=r(nHr,"SqueezeBertForMaskedLM"),nHr.forEach(t),I6o=r(tEe," (SqueezeBERT model)"),tEe.forEach(t),j6o=i(D),A1=n(D,"LI",{});var aEe=s(A1);$re=n(aEe,"STRONG",{});var sHr=s($re);D6o=r(sHr,"tapas"),sHr.forEach(t),N6o=r(aEe," \u2014 "),pI=n(aEe,"A",{href:!0});var lHr=s(pI);q6o=r(lHr,"TapasForMaskedLM"),lHr.forEach(t),O6o=r(aEe," (TAPAS model)"),aEe.forEach(t),G6o=i(D),L1=n(D,"LI",{});var nEe=s(L1);Ire=n(nEe,"STRONG",{});var iHr=s(Ire);X6o=r(iHr,"wav2vec2"),iHr.forEach(t),V6o=r(nEe," \u2014 "),jre=n(nEe,"CODE",{});var dHr=s(jre);z6o=r(dHr,"Wav2Vec2ForMaskedLM"),dHr.forEach(t),W6o=r(nEe,"(Wav2Vec2 model)"),nEe.forEach(t),Q6o=i(D),B1=n(D,"LI",{});var sEe=s(B1);Dre=n(sEe,"STRONG",{});var cHr=s(Dre);H6o=r(cHr,"xlm"),cHr.forEach(t),U6o=r(sEe," \u2014 "),_I=n(sEe,"A",{href:!0});var fHr=s(_I);J6o=r(fHr,"XLMWithLMHeadModel"),fHr.forEach(t),Y6o=r(sEe," (XLM model)"),sEe.forEach(t),K6o=i(D),x1=n(D,"LI",{});var lEe=s(x1);Nre=n(lEe,"STRONG",{});var mHr=s(Nre);Z6o=r(mHr,"xlm-roberta"),mHr.forEach(t),e0o=r(lEe," \u2014 "),uI=n(lEe,"A",{href:!0});var gHr=s(uI);o0o=r(gHr,"XLMRobertaForMaskedLM"),gHr.forEach(t),r0o=r(lEe," (XLM-RoBERTa model)"),lEe.forEach(t),t0o=i(D),k1=n(D,"LI",{});var iEe=s(k1);qre=n(iEe,"STRONG",{});var hHr=s(qre);a0o=r(hHr,"xlm-roberta-xl"),hHr.forEach(t),n0o=r(iEe," \u2014 "),bI=n(iEe,"A",{href:!0});var pHr=s(bI);s0o=r(pHr,"XLMRobertaXLForMaskedLM"),pHr.forEach(t),l0o=r(iEe," (XLM-RoBERTa-XL model)"),iEe.forEach(t),i0o=i(D),R1=n(D,"LI",{});var dEe=s(R1);Ore=n(dEe,"STRONG",{});var _Hr=s(Ore);d0o=r(_Hr,"yoso"),_Hr.forEach(t),c0o=r(dEe," \u2014 "),vI=n(dEe,"A",{href:!0});var uHr=s(vI);f0o=r(uHr,"YosoForMaskedLM"),uHr.forEach(t),m0o=r(dEe," (YOSO model)"),dEe.forEach(t),D.forEach(t),g0o=i(Wt),S1=n(Wt,"P",{});var cEe=s(S1);h0o=r(cEe,"The model is set in evaluation mode by default using "),Gre=n(cEe,"CODE",{});var bHr=s(Gre);p0o=r(bHr,"model.eval()"),bHr.forEach(t),_0o=r(cEe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xre=n(cEe,"CODE",{});var vHr=s(Xre);u0o=r(vHr,"model.train()"),vHr.forEach(t),cEe.forEach(t),b0o=i(Wt),Vre=n(Wt,"P",{});var THr=s(Vre);v0o=r(THr,"Examples:"),THr.forEach(t),T0o=i(Wt),m(gE.$$.fragment,Wt),Wt.forEach(t),tl.forEach(t),gke=i(d),_d=n(d,"H2",{class:!0});var ESe=s(_d);P1=n(ESe,"A",{id:!0,class:!0,href:!0});var FHr=s(P1);zre=n(FHr,"SPAN",{});var CHr=s(zre);m(hE.$$.fragment,CHr),CHr.forEach(t),FHr.forEach(t),F0o=i(ESe),Wre=n(ESe,"SPAN",{});var MHr=s(Wre);C0o=r(MHr,"AutoModelForSeq2SeqLM"),MHr.forEach(t),ESe.forEach(t),hke=i(d),or=n(d,"DIV",{class:!0});var nl=s(or);m(pE.$$.fragment,nl),M0o=i(nl),ud=n(nl,"P",{});var eW=s(ud);E0o=r(eW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Qre=n(eW,"CODE",{});var EHr=s(Qre);y0o=r(EHr,"from_pretrained()"),EHr.forEach(t),w0o=r(eW,"class method or the "),Hre=n(eW,"CODE",{});var yHr=s(Hre);A0o=r(yHr,"from_config()"),yHr.forEach(t),L0o=r(eW,`class
method.`),eW.forEach(t),B0o=i(nl),_E=n(nl,"P",{});var ySe=s(_E);x0o=r(ySe,"This class cannot be instantiated directly using "),Ure=n(ySe,"CODE",{});var wHr=s(Ure);k0o=r(wHr,"__init__()"),wHr.forEach(t),R0o=r(ySe," (throws an error)."),ySe.forEach(t),S0o=i(nl),Jr=n(nl,"DIV",{class:!0});var sl=s(Jr);m(uE.$$.fragment,sl),P0o=i(sl),Jre=n(sl,"P",{});var AHr=s(Jre);$0o=r(AHr,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),AHr.forEach(t),I0o=i(sl),bd=n(sl,"P",{});var oW=s(bd);j0o=r(oW,`Note:
Loading a model from its configuration file does `),Yre=n(oW,"STRONG",{});var LHr=s(Yre);D0o=r(LHr,"not"),LHr.forEach(t),N0o=r(oW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kre=n(oW,"CODE",{});var BHr=s(Kre);q0o=r(BHr,"from_pretrained()"),BHr.forEach(t),O0o=r(oW,"to load the model weights."),oW.forEach(t),G0o=i(sl),Zre=n(sl,"P",{});var xHr=s(Zre);X0o=r(xHr,"Examples:"),xHr.forEach(t),V0o=i(sl),m(bE.$$.fragment,sl),sl.forEach(t),z0o=i(nl),Oe=n(nl,"DIV",{class:!0});var Qt=s(Oe);m(vE.$$.fragment,Qt),W0o=i(Qt),ete=n(Qt,"P",{});var kHr=s(ete);Q0o=r(kHr,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),kHr.forEach(t),H0o=i(Qt),Ka=n(Qt,"P",{});var gM=s(Ka);U0o=r(gM,"The model class to instantiate is selected based on the "),ote=n(gM,"CODE",{});var RHr=s(ote);J0o=r(RHr,"model_type"),RHr.forEach(t),Y0o=r(gM,` property of the config object (either
passed as an argument or loaded from `),rte=n(gM,"CODE",{});var SHr=s(rte);K0o=r(SHr,"pretrained_model_name_or_path"),SHr.forEach(t),Z0o=r(gM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tte=n(gM,"CODE",{});var PHr=s(tte);eTo=r(PHr,"pretrained_model_name_or_path"),PHr.forEach(t),oTo=r(gM,":"),gM.forEach(t),rTo=i(Qt),ne=n(Qt,"UL",{});var ie=s(ne);$1=n(ie,"LI",{});var fEe=s($1);ate=n(fEe,"STRONG",{});var $Hr=s(ate);tTo=r($Hr,"bart"),$Hr.forEach(t),aTo=r(fEe," \u2014 "),TI=n(fEe,"A",{href:!0});var IHr=s(TI);nTo=r(IHr,"BartForConditionalGeneration"),IHr.forEach(t),sTo=r(fEe," (BART model)"),fEe.forEach(t),lTo=i(ie),I1=n(ie,"LI",{});var mEe=s(I1);nte=n(mEe,"STRONG",{});var jHr=s(nte);iTo=r(jHr,"bigbird_pegasus"),jHr.forEach(t),dTo=r(mEe," \u2014 "),FI=n(mEe,"A",{href:!0});var DHr=s(FI);cTo=r(DHr,"BigBirdPegasusForConditionalGeneration"),DHr.forEach(t),fTo=r(mEe," (BigBirdPegasus model)"),mEe.forEach(t),mTo=i(ie),j1=n(ie,"LI",{});var gEe=s(j1);ste=n(gEe,"STRONG",{});var NHr=s(ste);gTo=r(NHr,"blenderbot"),NHr.forEach(t),hTo=r(gEe," \u2014 "),CI=n(gEe,"A",{href:!0});var qHr=s(CI);pTo=r(qHr,"BlenderbotForConditionalGeneration"),qHr.forEach(t),_To=r(gEe," (Blenderbot model)"),gEe.forEach(t),uTo=i(ie),D1=n(ie,"LI",{});var hEe=s(D1);lte=n(hEe,"STRONG",{});var OHr=s(lte);bTo=r(OHr,"blenderbot-small"),OHr.forEach(t),vTo=r(hEe," \u2014 "),MI=n(hEe,"A",{href:!0});var GHr=s(MI);TTo=r(GHr,"BlenderbotSmallForConditionalGeneration"),GHr.forEach(t),FTo=r(hEe," (BlenderbotSmall model)"),hEe.forEach(t),CTo=i(ie),N1=n(ie,"LI",{});var pEe=s(N1);ite=n(pEe,"STRONG",{});var XHr=s(ite);MTo=r(XHr,"encoder-decoder"),XHr.forEach(t),ETo=r(pEe," \u2014 "),EI=n(pEe,"A",{href:!0});var VHr=s(EI);yTo=r(VHr,"EncoderDecoderModel"),VHr.forEach(t),wTo=r(pEe," (Encoder decoder model)"),pEe.forEach(t),ATo=i(ie),q1=n(ie,"LI",{});var _Ee=s(q1);dte=n(_Ee,"STRONG",{});var zHr=s(dte);LTo=r(zHr,"fsmt"),zHr.forEach(t),BTo=r(_Ee," \u2014 "),yI=n(_Ee,"A",{href:!0});var WHr=s(yI);xTo=r(WHr,"FSMTForConditionalGeneration"),WHr.forEach(t),kTo=r(_Ee," (FairSeq Machine-Translation model)"),_Ee.forEach(t),RTo=i(ie),O1=n(ie,"LI",{});var uEe=s(O1);cte=n(uEe,"STRONG",{});var QHr=s(cte);STo=r(QHr,"led"),QHr.forEach(t),PTo=r(uEe," \u2014 "),wI=n(uEe,"A",{href:!0});var HHr=s(wI);$To=r(HHr,"LEDForConditionalGeneration"),HHr.forEach(t),ITo=r(uEe," (LED model)"),uEe.forEach(t),jTo=i(ie),G1=n(ie,"LI",{});var bEe=s(G1);fte=n(bEe,"STRONG",{});var UHr=s(fte);DTo=r(UHr,"m2m_100"),UHr.forEach(t),NTo=r(bEe," \u2014 "),AI=n(bEe,"A",{href:!0});var JHr=s(AI);qTo=r(JHr,"M2M100ForConditionalGeneration"),JHr.forEach(t),OTo=r(bEe," (M2M100 model)"),bEe.forEach(t),GTo=i(ie),X1=n(ie,"LI",{});var vEe=s(X1);mte=n(vEe,"STRONG",{});var YHr=s(mte);XTo=r(YHr,"marian"),YHr.forEach(t),VTo=r(vEe," \u2014 "),LI=n(vEe,"A",{href:!0});var KHr=s(LI);zTo=r(KHr,"MarianMTModel"),KHr.forEach(t),WTo=r(vEe," (Marian model)"),vEe.forEach(t),QTo=i(ie),V1=n(ie,"LI",{});var TEe=s(V1);gte=n(TEe,"STRONG",{});var ZHr=s(gte);HTo=r(ZHr,"mbart"),ZHr.forEach(t),UTo=r(TEe," \u2014 "),BI=n(TEe,"A",{href:!0});var eUr=s(BI);JTo=r(eUr,"MBartForConditionalGeneration"),eUr.forEach(t),YTo=r(TEe," (mBART model)"),TEe.forEach(t),KTo=i(ie),z1=n(ie,"LI",{});var FEe=s(z1);hte=n(FEe,"STRONG",{});var oUr=s(hte);ZTo=r(oUr,"mt5"),oUr.forEach(t),e8o=r(FEe," \u2014 "),xI=n(FEe,"A",{href:!0});var rUr=s(xI);o8o=r(rUr,"MT5ForConditionalGeneration"),rUr.forEach(t),r8o=r(FEe," (mT5 model)"),FEe.forEach(t),t8o=i(ie),W1=n(ie,"LI",{});var CEe=s(W1);pte=n(CEe,"STRONG",{});var tUr=s(pte);a8o=r(tUr,"pegasus"),tUr.forEach(t),n8o=r(CEe," \u2014 "),kI=n(CEe,"A",{href:!0});var aUr=s(kI);s8o=r(aUr,"PegasusForConditionalGeneration"),aUr.forEach(t),l8o=r(CEe," (Pegasus model)"),CEe.forEach(t),i8o=i(ie),Q1=n(ie,"LI",{});var MEe=s(Q1);_te=n(MEe,"STRONG",{});var nUr=s(_te);d8o=r(nUr,"plbart"),nUr.forEach(t),c8o=r(MEe," \u2014 "),RI=n(MEe,"A",{href:!0});var sUr=s(RI);f8o=r(sUr,"PLBartForConditionalGeneration"),sUr.forEach(t),m8o=r(MEe," (PLBart model)"),MEe.forEach(t),g8o=i(ie),H1=n(ie,"LI",{});var EEe=s(H1);ute=n(EEe,"STRONG",{});var lUr=s(ute);h8o=r(lUr,"prophetnet"),lUr.forEach(t),p8o=r(EEe," \u2014 "),SI=n(EEe,"A",{href:!0});var iUr=s(SI);_8o=r(iUr,"ProphetNetForConditionalGeneration"),iUr.forEach(t),u8o=r(EEe," (ProphetNet model)"),EEe.forEach(t),b8o=i(ie),U1=n(ie,"LI",{});var yEe=s(U1);bte=n(yEe,"STRONG",{});var dUr=s(bte);v8o=r(dUr,"t5"),dUr.forEach(t),T8o=r(yEe," \u2014 "),PI=n(yEe,"A",{href:!0});var cUr=s(PI);F8o=r(cUr,"T5ForConditionalGeneration"),cUr.forEach(t),C8o=r(yEe," (T5 model)"),yEe.forEach(t),M8o=i(ie),J1=n(ie,"LI",{});var wEe=s(J1);vte=n(wEe,"STRONG",{});var fUr=s(vte);E8o=r(fUr,"xlm-prophetnet"),fUr.forEach(t),y8o=r(wEe," \u2014 "),$I=n(wEe,"A",{href:!0});var mUr=s($I);w8o=r(mUr,"XLMProphetNetForConditionalGeneration"),mUr.forEach(t),A8o=r(wEe," (XLMProphetNet model)"),wEe.forEach(t),ie.forEach(t),L8o=i(Qt),Y1=n(Qt,"P",{});var AEe=s(Y1);B8o=r(AEe,"The model is set in evaluation mode by default using "),Tte=n(AEe,"CODE",{});var gUr=s(Tte);x8o=r(gUr,"model.eval()"),gUr.forEach(t),k8o=r(AEe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fte=n(AEe,"CODE",{});var hUr=s(Fte);R8o=r(hUr,"model.train()"),hUr.forEach(t),AEe.forEach(t),S8o=i(Qt),Cte=n(Qt,"P",{});var pUr=s(Cte);P8o=r(pUr,"Examples:"),pUr.forEach(t),$8o=i(Qt),m(TE.$$.fragment,Qt),Qt.forEach(t),nl.forEach(t),pke=i(d),vd=n(d,"H2",{class:!0});var wSe=s(vd);K1=n(wSe,"A",{id:!0,class:!0,href:!0});var _Ur=s(K1);Mte=n(_Ur,"SPAN",{});var uUr=s(Mte);m(FE.$$.fragment,uUr),uUr.forEach(t),_Ur.forEach(t),I8o=i(wSe),Ete=n(wSe,"SPAN",{});var bUr=s(Ete);j8o=r(bUr,"AutoModelForSequenceClassification"),bUr.forEach(t),wSe.forEach(t),_ke=i(d),rr=n(d,"DIV",{class:!0});var ll=s(rr);m(CE.$$.fragment,ll),D8o=i(ll),Td=n(ll,"P",{});var rW=s(Td);N8o=r(rW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),yte=n(rW,"CODE",{});var vUr=s(yte);q8o=r(vUr,"from_pretrained()"),vUr.forEach(t),O8o=r(rW,"class method or the "),wte=n(rW,"CODE",{});var TUr=s(wte);G8o=r(TUr,"from_config()"),TUr.forEach(t),X8o=r(rW,`class
method.`),rW.forEach(t),V8o=i(ll),ME=n(ll,"P",{});var ASe=s(ME);z8o=r(ASe,"This class cannot be instantiated directly using "),Ate=n(ASe,"CODE",{});var FUr=s(Ate);W8o=r(FUr,"__init__()"),FUr.forEach(t),Q8o=r(ASe," (throws an error)."),ASe.forEach(t),H8o=i(ll),Yr=n(ll,"DIV",{class:!0});var il=s(Yr);m(EE.$$.fragment,il),U8o=i(il),Lte=n(il,"P",{});var CUr=s(Lte);J8o=r(CUr,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),CUr.forEach(t),Y8o=i(il),Fd=n(il,"P",{});var tW=s(Fd);K8o=r(tW,`Note:
Loading a model from its configuration file does `),Bte=n(tW,"STRONG",{});var MUr=s(Bte);Z8o=r(MUr,"not"),MUr.forEach(t),eFo=r(tW,` load the model weights. It only affects the
model\u2019s configuration. Use `),xte=n(tW,"CODE",{});var EUr=s(xte);oFo=r(EUr,"from_pretrained()"),EUr.forEach(t),rFo=r(tW,"to load the model weights."),tW.forEach(t),tFo=i(il),kte=n(il,"P",{});var yUr=s(kte);aFo=r(yUr,"Examples:"),yUr.forEach(t),nFo=i(il),m(yE.$$.fragment,il),il.forEach(t),sFo=i(ll),Ge=n(ll,"DIV",{class:!0});var Ht=s(Ge);m(wE.$$.fragment,Ht),lFo=i(Ht),Rte=n(Ht,"P",{});var wUr=s(Rte);iFo=r(wUr,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),wUr.forEach(t),dFo=i(Ht),Za=n(Ht,"P",{});var hM=s(Za);cFo=r(hM,"The model class to instantiate is selected based on the "),Ste=n(hM,"CODE",{});var AUr=s(Ste);fFo=r(AUr,"model_type"),AUr.forEach(t),mFo=r(hM,` property of the config object (either
passed as an argument or loaded from `),Pte=n(hM,"CODE",{});var LUr=s(Pte);gFo=r(LUr,"pretrained_model_name_or_path"),LUr.forEach(t),hFo=r(hM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$te=n(hM,"CODE",{});var BUr=s($te);pFo=r(BUr,"pretrained_model_name_or_path"),BUr.forEach(t),_Fo=r(hM,":"),hM.forEach(t),uFo=i(Ht),A=n(Ht,"UL",{});var L=s(A);Z1=n(L,"LI",{});var LEe=s(Z1);Ite=n(LEe,"STRONG",{});var xUr=s(Ite);bFo=r(xUr,"albert"),xUr.forEach(t),vFo=r(LEe," \u2014 "),II=n(LEe,"A",{href:!0});var kUr=s(II);TFo=r(kUr,"AlbertForSequenceClassification"),kUr.forEach(t),FFo=r(LEe," (ALBERT model)"),LEe.forEach(t),CFo=i(L),eb=n(L,"LI",{});var BEe=s(eb);jte=n(BEe,"STRONG",{});var RUr=s(jte);MFo=r(RUr,"bart"),RUr.forEach(t),EFo=r(BEe," \u2014 "),jI=n(BEe,"A",{href:!0});var SUr=s(jI);yFo=r(SUr,"BartForSequenceClassification"),SUr.forEach(t),wFo=r(BEe," (BART model)"),BEe.forEach(t),AFo=i(L),ob=n(L,"LI",{});var xEe=s(ob);Dte=n(xEe,"STRONG",{});var PUr=s(Dte);LFo=r(PUr,"bert"),PUr.forEach(t),BFo=r(xEe," \u2014 "),DI=n(xEe,"A",{href:!0});var $Ur=s(DI);xFo=r($Ur,"BertForSequenceClassification"),$Ur.forEach(t),kFo=r(xEe," (BERT model)"),xEe.forEach(t),RFo=i(L),rb=n(L,"LI",{});var kEe=s(rb);Nte=n(kEe,"STRONG",{});var IUr=s(Nte);SFo=r(IUr,"big_bird"),IUr.forEach(t),PFo=r(kEe," \u2014 "),NI=n(kEe,"A",{href:!0});var jUr=s(NI);$Fo=r(jUr,"BigBirdForSequenceClassification"),jUr.forEach(t),IFo=r(kEe," (BigBird model)"),kEe.forEach(t),jFo=i(L),tb=n(L,"LI",{});var REe=s(tb);qte=n(REe,"STRONG",{});var DUr=s(qte);DFo=r(DUr,"bigbird_pegasus"),DUr.forEach(t),NFo=r(REe," \u2014 "),qI=n(REe,"A",{href:!0});var NUr=s(qI);qFo=r(NUr,"BigBirdPegasusForSequenceClassification"),NUr.forEach(t),OFo=r(REe," (BigBirdPegasus model)"),REe.forEach(t),GFo=i(L),ab=n(L,"LI",{});var SEe=s(ab);Ote=n(SEe,"STRONG",{});var qUr=s(Ote);XFo=r(qUr,"camembert"),qUr.forEach(t),VFo=r(SEe," \u2014 "),OI=n(SEe,"A",{href:!0});var OUr=s(OI);zFo=r(OUr,"CamembertForSequenceClassification"),OUr.forEach(t),WFo=r(SEe," (CamemBERT model)"),SEe.forEach(t),QFo=i(L),nb=n(L,"LI",{});var PEe=s(nb);Gte=n(PEe,"STRONG",{});var GUr=s(Gte);HFo=r(GUr,"canine"),GUr.forEach(t),UFo=r(PEe," \u2014 "),GI=n(PEe,"A",{href:!0});var XUr=s(GI);JFo=r(XUr,"CanineForSequenceClassification"),XUr.forEach(t),YFo=r(PEe," (Canine model)"),PEe.forEach(t),KFo=i(L),sb=n(L,"LI",{});var $Ee=s(sb);Xte=n($Ee,"STRONG",{});var VUr=s(Xte);ZFo=r(VUr,"convbert"),VUr.forEach(t),eCo=r($Ee," \u2014 "),XI=n($Ee,"A",{href:!0});var zUr=s(XI);oCo=r(zUr,"ConvBertForSequenceClassification"),zUr.forEach(t),rCo=r($Ee," (ConvBERT model)"),$Ee.forEach(t),tCo=i(L),lb=n(L,"LI",{});var IEe=s(lb);Vte=n(IEe,"STRONG",{});var WUr=s(Vte);aCo=r(WUr,"ctrl"),WUr.forEach(t),nCo=r(IEe," \u2014 "),VI=n(IEe,"A",{href:!0});var QUr=s(VI);sCo=r(QUr,"CTRLForSequenceClassification"),QUr.forEach(t),lCo=r(IEe," (CTRL model)"),IEe.forEach(t),iCo=i(L),ib=n(L,"LI",{});var jEe=s(ib);zte=n(jEe,"STRONG",{});var HUr=s(zte);dCo=r(HUr,"data2vec-text"),HUr.forEach(t),cCo=r(jEe," \u2014 "),zI=n(jEe,"A",{href:!0});var UUr=s(zI);fCo=r(UUr,"Data2VecTextForSequenceClassification"),UUr.forEach(t),mCo=r(jEe," (Data2VecText model)"),jEe.forEach(t),gCo=i(L),db=n(L,"LI",{});var DEe=s(db);Wte=n(DEe,"STRONG",{});var JUr=s(Wte);hCo=r(JUr,"deberta"),JUr.forEach(t),pCo=r(DEe," \u2014 "),WI=n(DEe,"A",{href:!0});var YUr=s(WI);_Co=r(YUr,"DebertaForSequenceClassification"),YUr.forEach(t),uCo=r(DEe," (DeBERTa model)"),DEe.forEach(t),bCo=i(L),cb=n(L,"LI",{});var NEe=s(cb);Qte=n(NEe,"STRONG",{});var KUr=s(Qte);vCo=r(KUr,"deberta-v2"),KUr.forEach(t),TCo=r(NEe," \u2014 "),QI=n(NEe,"A",{href:!0});var ZUr=s(QI);FCo=r(ZUr,"DebertaV2ForSequenceClassification"),ZUr.forEach(t),CCo=r(NEe," (DeBERTa-v2 model)"),NEe.forEach(t),MCo=i(L),fb=n(L,"LI",{});var qEe=s(fb);Hte=n(qEe,"STRONG",{});var eJr=s(Hte);ECo=r(eJr,"distilbert"),eJr.forEach(t),yCo=r(qEe," \u2014 "),HI=n(qEe,"A",{href:!0});var oJr=s(HI);wCo=r(oJr,"DistilBertForSequenceClassification"),oJr.forEach(t),ACo=r(qEe," (DistilBERT model)"),qEe.forEach(t),LCo=i(L),mb=n(L,"LI",{});var OEe=s(mb);Ute=n(OEe,"STRONG",{});var rJr=s(Ute);BCo=r(rJr,"electra"),rJr.forEach(t),xCo=r(OEe," \u2014 "),UI=n(OEe,"A",{href:!0});var tJr=s(UI);kCo=r(tJr,"ElectraForSequenceClassification"),tJr.forEach(t),RCo=r(OEe," (ELECTRA model)"),OEe.forEach(t),SCo=i(L),gb=n(L,"LI",{});var GEe=s(gb);Jte=n(GEe,"STRONG",{});var aJr=s(Jte);PCo=r(aJr,"flaubert"),aJr.forEach(t),$Co=r(GEe," \u2014 "),JI=n(GEe,"A",{href:!0});var nJr=s(JI);ICo=r(nJr,"FlaubertForSequenceClassification"),nJr.forEach(t),jCo=r(GEe," (FlauBERT model)"),GEe.forEach(t),DCo=i(L),hb=n(L,"LI",{});var XEe=s(hb);Yte=n(XEe,"STRONG",{});var sJr=s(Yte);NCo=r(sJr,"fnet"),sJr.forEach(t),qCo=r(XEe," \u2014 "),YI=n(XEe,"A",{href:!0});var lJr=s(YI);OCo=r(lJr,"FNetForSequenceClassification"),lJr.forEach(t),GCo=r(XEe," (FNet model)"),XEe.forEach(t),XCo=i(L),pb=n(L,"LI",{});var VEe=s(pb);Kte=n(VEe,"STRONG",{});var iJr=s(Kte);VCo=r(iJr,"funnel"),iJr.forEach(t),zCo=r(VEe," \u2014 "),KI=n(VEe,"A",{href:!0});var dJr=s(KI);WCo=r(dJr,"FunnelForSequenceClassification"),dJr.forEach(t),QCo=r(VEe," (Funnel Transformer model)"),VEe.forEach(t),HCo=i(L),_b=n(L,"LI",{});var zEe=s(_b);Zte=n(zEe,"STRONG",{});var cJr=s(Zte);UCo=r(cJr,"gpt2"),cJr.forEach(t),JCo=r(zEe," \u2014 "),ZI=n(zEe,"A",{href:!0});var fJr=s(ZI);YCo=r(fJr,"GPT2ForSequenceClassification"),fJr.forEach(t),KCo=r(zEe," (OpenAI GPT-2 model)"),zEe.forEach(t),ZCo=i(L),ub=n(L,"LI",{});var WEe=s(ub);eae=n(WEe,"STRONG",{});var mJr=s(eae);eMo=r(mJr,"gpt_neo"),mJr.forEach(t),oMo=r(WEe," \u2014 "),ej=n(WEe,"A",{href:!0});var gJr=s(ej);rMo=r(gJr,"GPTNeoForSequenceClassification"),gJr.forEach(t),tMo=r(WEe," (GPT Neo model)"),WEe.forEach(t),aMo=i(L),bb=n(L,"LI",{});var QEe=s(bb);oae=n(QEe,"STRONG",{});var hJr=s(oae);nMo=r(hJr,"gptj"),hJr.forEach(t),sMo=r(QEe," \u2014 "),oj=n(QEe,"A",{href:!0});var pJr=s(oj);lMo=r(pJr,"GPTJForSequenceClassification"),pJr.forEach(t),iMo=r(QEe," (GPT-J model)"),QEe.forEach(t),dMo=i(L),vb=n(L,"LI",{});var HEe=s(vb);rae=n(HEe,"STRONG",{});var _Jr=s(rae);cMo=r(_Jr,"ibert"),_Jr.forEach(t),fMo=r(HEe," \u2014 "),rj=n(HEe,"A",{href:!0});var uJr=s(rj);mMo=r(uJr,"IBertForSequenceClassification"),uJr.forEach(t),gMo=r(HEe," (I-BERT model)"),HEe.forEach(t),hMo=i(L),Tb=n(L,"LI",{});var UEe=s(Tb);tae=n(UEe,"STRONG",{});var bJr=s(tae);pMo=r(bJr,"layoutlm"),bJr.forEach(t),_Mo=r(UEe," \u2014 "),tj=n(UEe,"A",{href:!0});var vJr=s(tj);uMo=r(vJr,"LayoutLMForSequenceClassification"),vJr.forEach(t),bMo=r(UEe," (LayoutLM model)"),UEe.forEach(t),vMo=i(L),Fb=n(L,"LI",{});var JEe=s(Fb);aae=n(JEe,"STRONG",{});var TJr=s(aae);TMo=r(TJr,"layoutlmv2"),TJr.forEach(t),FMo=r(JEe," \u2014 "),aj=n(JEe,"A",{href:!0});var FJr=s(aj);CMo=r(FJr,"LayoutLMv2ForSequenceClassification"),FJr.forEach(t),MMo=r(JEe," (LayoutLMv2 model)"),JEe.forEach(t),EMo=i(L),Cb=n(L,"LI",{});var YEe=s(Cb);nae=n(YEe,"STRONG",{});var CJr=s(nae);yMo=r(CJr,"led"),CJr.forEach(t),wMo=r(YEe," \u2014 "),nj=n(YEe,"A",{href:!0});var MJr=s(nj);AMo=r(MJr,"LEDForSequenceClassification"),MJr.forEach(t),LMo=r(YEe," (LED model)"),YEe.forEach(t),BMo=i(L),Mb=n(L,"LI",{});var KEe=s(Mb);sae=n(KEe,"STRONG",{});var EJr=s(sae);xMo=r(EJr,"longformer"),EJr.forEach(t),kMo=r(KEe," \u2014 "),sj=n(KEe,"A",{href:!0});var yJr=s(sj);RMo=r(yJr,"LongformerForSequenceClassification"),yJr.forEach(t),SMo=r(KEe," (Longformer model)"),KEe.forEach(t),PMo=i(L),Eb=n(L,"LI",{});var ZEe=s(Eb);lae=n(ZEe,"STRONG",{});var wJr=s(lae);$Mo=r(wJr,"mbart"),wJr.forEach(t),IMo=r(ZEe," \u2014 "),lj=n(ZEe,"A",{href:!0});var AJr=s(lj);jMo=r(AJr,"MBartForSequenceClassification"),AJr.forEach(t),DMo=r(ZEe," (mBART model)"),ZEe.forEach(t),NMo=i(L),yb=n(L,"LI",{});var e3e=s(yb);iae=n(e3e,"STRONG",{});var LJr=s(iae);qMo=r(LJr,"megatron-bert"),LJr.forEach(t),OMo=r(e3e," \u2014 "),ij=n(e3e,"A",{href:!0});var BJr=s(ij);GMo=r(BJr,"MegatronBertForSequenceClassification"),BJr.forEach(t),XMo=r(e3e," (MegatronBert model)"),e3e.forEach(t),VMo=i(L),wb=n(L,"LI",{});var o3e=s(wb);dae=n(o3e,"STRONG",{});var xJr=s(dae);zMo=r(xJr,"mobilebert"),xJr.forEach(t),WMo=r(o3e," \u2014 "),dj=n(o3e,"A",{href:!0});var kJr=s(dj);QMo=r(kJr,"MobileBertForSequenceClassification"),kJr.forEach(t),HMo=r(o3e," (MobileBERT model)"),o3e.forEach(t),UMo=i(L),Ab=n(L,"LI",{});var r3e=s(Ab);cae=n(r3e,"STRONG",{});var RJr=s(cae);JMo=r(RJr,"mpnet"),RJr.forEach(t),YMo=r(r3e," \u2014 "),cj=n(r3e,"A",{href:!0});var SJr=s(cj);KMo=r(SJr,"MPNetForSequenceClassification"),SJr.forEach(t),ZMo=r(r3e," (MPNet model)"),r3e.forEach(t),e4o=i(L),Lb=n(L,"LI",{});var t3e=s(Lb);fae=n(t3e,"STRONG",{});var PJr=s(fae);o4o=r(PJr,"nystromformer"),PJr.forEach(t),r4o=r(t3e," \u2014 "),fj=n(t3e,"A",{href:!0});var $Jr=s(fj);t4o=r($Jr,"NystromformerForSequenceClassification"),$Jr.forEach(t),a4o=r(t3e," (Nystromformer model)"),t3e.forEach(t),n4o=i(L),Bb=n(L,"LI",{});var a3e=s(Bb);mae=n(a3e,"STRONG",{});var IJr=s(mae);s4o=r(IJr,"openai-gpt"),IJr.forEach(t),l4o=r(a3e," \u2014 "),mj=n(a3e,"A",{href:!0});var jJr=s(mj);i4o=r(jJr,"OpenAIGPTForSequenceClassification"),jJr.forEach(t),d4o=r(a3e," (OpenAI GPT model)"),a3e.forEach(t),c4o=i(L),xb=n(L,"LI",{});var n3e=s(xb);gae=n(n3e,"STRONG",{});var DJr=s(gae);f4o=r(DJr,"perceiver"),DJr.forEach(t),m4o=r(n3e," \u2014 "),gj=n(n3e,"A",{href:!0});var NJr=s(gj);g4o=r(NJr,"PerceiverForSequenceClassification"),NJr.forEach(t),h4o=r(n3e," (Perceiver model)"),n3e.forEach(t),p4o=i(L),kb=n(L,"LI",{});var s3e=s(kb);hae=n(s3e,"STRONG",{});var qJr=s(hae);_4o=r(qJr,"plbart"),qJr.forEach(t),u4o=r(s3e," \u2014 "),hj=n(s3e,"A",{href:!0});var OJr=s(hj);b4o=r(OJr,"PLBartForSequenceClassification"),OJr.forEach(t),v4o=r(s3e," (PLBart model)"),s3e.forEach(t),T4o=i(L),Rb=n(L,"LI",{});var l3e=s(Rb);pae=n(l3e,"STRONG",{});var GJr=s(pae);F4o=r(GJr,"qdqbert"),GJr.forEach(t),C4o=r(l3e," \u2014 "),pj=n(l3e,"A",{href:!0});var XJr=s(pj);M4o=r(XJr,"QDQBertForSequenceClassification"),XJr.forEach(t),E4o=r(l3e," (QDQBert model)"),l3e.forEach(t),y4o=i(L),Sb=n(L,"LI",{});var i3e=s(Sb);_ae=n(i3e,"STRONG",{});var VJr=s(_ae);w4o=r(VJr,"reformer"),VJr.forEach(t),A4o=r(i3e," \u2014 "),_j=n(i3e,"A",{href:!0});var zJr=s(_j);L4o=r(zJr,"ReformerForSequenceClassification"),zJr.forEach(t),B4o=r(i3e," (Reformer model)"),i3e.forEach(t),x4o=i(L),Pb=n(L,"LI",{});var d3e=s(Pb);uae=n(d3e,"STRONG",{});var WJr=s(uae);k4o=r(WJr,"rembert"),WJr.forEach(t),R4o=r(d3e," \u2014 "),uj=n(d3e,"A",{href:!0});var QJr=s(uj);S4o=r(QJr,"RemBertForSequenceClassification"),QJr.forEach(t),P4o=r(d3e," (RemBERT model)"),d3e.forEach(t),$4o=i(L),$b=n(L,"LI",{});var c3e=s($b);bae=n(c3e,"STRONG",{});var HJr=s(bae);I4o=r(HJr,"roberta"),HJr.forEach(t),j4o=r(c3e," \u2014 "),bj=n(c3e,"A",{href:!0});var UJr=s(bj);D4o=r(UJr,"RobertaForSequenceClassification"),UJr.forEach(t),N4o=r(c3e," (RoBERTa model)"),c3e.forEach(t),q4o=i(L),Ib=n(L,"LI",{});var f3e=s(Ib);vae=n(f3e,"STRONG",{});var JJr=s(vae);O4o=r(JJr,"roformer"),JJr.forEach(t),G4o=r(f3e," \u2014 "),vj=n(f3e,"A",{href:!0});var YJr=s(vj);X4o=r(YJr,"RoFormerForSequenceClassification"),YJr.forEach(t),V4o=r(f3e," (RoFormer model)"),f3e.forEach(t),z4o=i(L),jb=n(L,"LI",{});var m3e=s(jb);Tae=n(m3e,"STRONG",{});var KJr=s(Tae);W4o=r(KJr,"squeezebert"),KJr.forEach(t),Q4o=r(m3e," \u2014 "),Tj=n(m3e,"A",{href:!0});var ZJr=s(Tj);H4o=r(ZJr,"SqueezeBertForSequenceClassification"),ZJr.forEach(t),U4o=r(m3e," (SqueezeBERT model)"),m3e.forEach(t),J4o=i(L),Db=n(L,"LI",{});var g3e=s(Db);Fae=n(g3e,"STRONG",{});var eYr=s(Fae);Y4o=r(eYr,"tapas"),eYr.forEach(t),K4o=r(g3e," \u2014 "),Fj=n(g3e,"A",{href:!0});var oYr=s(Fj);Z4o=r(oYr,"TapasForSequenceClassification"),oYr.forEach(t),eEo=r(g3e," (TAPAS model)"),g3e.forEach(t),oEo=i(L),Nb=n(L,"LI",{});var h3e=s(Nb);Cae=n(h3e,"STRONG",{});var rYr=s(Cae);rEo=r(rYr,"transfo-xl"),rYr.forEach(t),tEo=r(h3e," \u2014 "),Cj=n(h3e,"A",{href:!0});var tYr=s(Cj);aEo=r(tYr,"TransfoXLForSequenceClassification"),tYr.forEach(t),nEo=r(h3e," (Transformer-XL model)"),h3e.forEach(t),sEo=i(L),qb=n(L,"LI",{});var p3e=s(qb);Mae=n(p3e,"STRONG",{});var aYr=s(Mae);lEo=r(aYr,"xlm"),aYr.forEach(t),iEo=r(p3e," \u2014 "),Mj=n(p3e,"A",{href:!0});var nYr=s(Mj);dEo=r(nYr,"XLMForSequenceClassification"),nYr.forEach(t),cEo=r(p3e," (XLM model)"),p3e.forEach(t),fEo=i(L),Ob=n(L,"LI",{});var _3e=s(Ob);Eae=n(_3e,"STRONG",{});var sYr=s(Eae);mEo=r(sYr,"xlm-roberta"),sYr.forEach(t),gEo=r(_3e," \u2014 "),Ej=n(_3e,"A",{href:!0});var lYr=s(Ej);hEo=r(lYr,"XLMRobertaForSequenceClassification"),lYr.forEach(t),pEo=r(_3e," (XLM-RoBERTa model)"),_3e.forEach(t),_Eo=i(L),Gb=n(L,"LI",{});var u3e=s(Gb);yae=n(u3e,"STRONG",{});var iYr=s(yae);uEo=r(iYr,"xlm-roberta-xl"),iYr.forEach(t),bEo=r(u3e," \u2014 "),yj=n(u3e,"A",{href:!0});var dYr=s(yj);vEo=r(dYr,"XLMRobertaXLForSequenceClassification"),dYr.forEach(t),TEo=r(u3e," (XLM-RoBERTa-XL model)"),u3e.forEach(t),FEo=i(L),Xb=n(L,"LI",{});var b3e=s(Xb);wae=n(b3e,"STRONG",{});var cYr=s(wae);CEo=r(cYr,"xlnet"),cYr.forEach(t),MEo=r(b3e," \u2014 "),wj=n(b3e,"A",{href:!0});var fYr=s(wj);EEo=r(fYr,"XLNetForSequenceClassification"),fYr.forEach(t),yEo=r(b3e," (XLNet model)"),b3e.forEach(t),wEo=i(L),Vb=n(L,"LI",{});var v3e=s(Vb);Aae=n(v3e,"STRONG",{});var mYr=s(Aae);AEo=r(mYr,"yoso"),mYr.forEach(t),LEo=r(v3e," \u2014 "),Aj=n(v3e,"A",{href:!0});var gYr=s(Aj);BEo=r(gYr,"YosoForSequenceClassification"),gYr.forEach(t),xEo=r(v3e," (YOSO model)"),v3e.forEach(t),L.forEach(t),kEo=i(Ht),zb=n(Ht,"P",{});var T3e=s(zb);REo=r(T3e,"The model is set in evaluation mode by default using "),Lae=n(T3e,"CODE",{});var hYr=s(Lae);SEo=r(hYr,"model.eval()"),hYr.forEach(t),PEo=r(T3e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bae=n(T3e,"CODE",{});var pYr=s(Bae);$Eo=r(pYr,"model.train()"),pYr.forEach(t),T3e.forEach(t),IEo=i(Ht),xae=n(Ht,"P",{});var _Yr=s(xae);jEo=r(_Yr,"Examples:"),_Yr.forEach(t),DEo=i(Ht),m(AE.$$.fragment,Ht),Ht.forEach(t),ll.forEach(t),uke=i(d),Cd=n(d,"H2",{class:!0});var LSe=s(Cd);Wb=n(LSe,"A",{id:!0,class:!0,href:!0});var uYr=s(Wb);kae=n(uYr,"SPAN",{});var bYr=s(kae);m(LE.$$.fragment,bYr),bYr.forEach(t),uYr.forEach(t),NEo=i(LSe),Rae=n(LSe,"SPAN",{});var vYr=s(Rae);qEo=r(vYr,"AutoModelForMultipleChoice"),vYr.forEach(t),LSe.forEach(t),bke=i(d),tr=n(d,"DIV",{class:!0});var dl=s(tr);m(BE.$$.fragment,dl),OEo=i(dl),Md=n(dl,"P",{});var aW=s(Md);GEo=r(aW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Sae=n(aW,"CODE",{});var TYr=s(Sae);XEo=r(TYr,"from_pretrained()"),TYr.forEach(t),VEo=r(aW,"class method or the "),Pae=n(aW,"CODE",{});var FYr=s(Pae);zEo=r(FYr,"from_config()"),FYr.forEach(t),WEo=r(aW,`class
method.`),aW.forEach(t),QEo=i(dl),xE=n(dl,"P",{});var BSe=s(xE);HEo=r(BSe,"This class cannot be instantiated directly using "),$ae=n(BSe,"CODE",{});var CYr=s($ae);UEo=r(CYr,"__init__()"),CYr.forEach(t),JEo=r(BSe," (throws an error)."),BSe.forEach(t),YEo=i(dl),Kr=n(dl,"DIV",{class:!0});var cl=s(Kr);m(kE.$$.fragment,cl),KEo=i(cl),Iae=n(cl,"P",{});var MYr=s(Iae);ZEo=r(MYr,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),MYr.forEach(t),e3o=i(cl),Ed=n(cl,"P",{});var nW=s(Ed);o3o=r(nW,`Note:
Loading a model from its configuration file does `),jae=n(nW,"STRONG",{});var EYr=s(jae);r3o=r(EYr,"not"),EYr.forEach(t),t3o=r(nW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dae=n(nW,"CODE",{});var yYr=s(Dae);a3o=r(yYr,"from_pretrained()"),yYr.forEach(t),n3o=r(nW,"to load the model weights."),nW.forEach(t),s3o=i(cl),Nae=n(cl,"P",{});var wYr=s(Nae);l3o=r(wYr,"Examples:"),wYr.forEach(t),i3o=i(cl),m(RE.$$.fragment,cl),cl.forEach(t),d3o=i(dl),Xe=n(dl,"DIV",{class:!0});var Ut=s(Xe);m(SE.$$.fragment,Ut),c3o=i(Ut),qae=n(Ut,"P",{});var AYr=s(qae);f3o=r(AYr,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),AYr.forEach(t),m3o=i(Ut),en=n(Ut,"P",{});var pM=s(en);g3o=r(pM,"The model class to instantiate is selected based on the "),Oae=n(pM,"CODE",{});var LYr=s(Oae);h3o=r(LYr,"model_type"),LYr.forEach(t),p3o=r(pM,` property of the config object (either
passed as an argument or loaded from `),Gae=n(pM,"CODE",{});var BYr=s(Gae);_3o=r(BYr,"pretrained_model_name_or_path"),BYr.forEach(t),u3o=r(pM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xae=n(pM,"CODE",{});var xYr=s(Xae);b3o=r(xYr,"pretrained_model_name_or_path"),xYr.forEach(t),v3o=r(pM,":"),pM.forEach(t),T3o=i(Ut),O=n(Ut,"UL",{});var G=s(O);Qb=n(G,"LI",{});var F3e=s(Qb);Vae=n(F3e,"STRONG",{});var kYr=s(Vae);F3o=r(kYr,"albert"),kYr.forEach(t),C3o=r(F3e," \u2014 "),Lj=n(F3e,"A",{href:!0});var RYr=s(Lj);M3o=r(RYr,"AlbertForMultipleChoice"),RYr.forEach(t),E3o=r(F3e," (ALBERT model)"),F3e.forEach(t),y3o=i(G),Hb=n(G,"LI",{});var C3e=s(Hb);zae=n(C3e,"STRONG",{});var SYr=s(zae);w3o=r(SYr,"bert"),SYr.forEach(t),A3o=r(C3e," \u2014 "),Bj=n(C3e,"A",{href:!0});var PYr=s(Bj);L3o=r(PYr,"BertForMultipleChoice"),PYr.forEach(t),B3o=r(C3e," (BERT model)"),C3e.forEach(t),x3o=i(G),Ub=n(G,"LI",{});var M3e=s(Ub);Wae=n(M3e,"STRONG",{});var $Yr=s(Wae);k3o=r($Yr,"big_bird"),$Yr.forEach(t),R3o=r(M3e," \u2014 "),xj=n(M3e,"A",{href:!0});var IYr=s(xj);S3o=r(IYr,"BigBirdForMultipleChoice"),IYr.forEach(t),P3o=r(M3e," (BigBird model)"),M3e.forEach(t),$3o=i(G),Jb=n(G,"LI",{});var E3e=s(Jb);Qae=n(E3e,"STRONG",{});var jYr=s(Qae);I3o=r(jYr,"camembert"),jYr.forEach(t),j3o=r(E3e," \u2014 "),kj=n(E3e,"A",{href:!0});var DYr=s(kj);D3o=r(DYr,"CamembertForMultipleChoice"),DYr.forEach(t),N3o=r(E3e," (CamemBERT model)"),E3e.forEach(t),q3o=i(G),Yb=n(G,"LI",{});var y3e=s(Yb);Hae=n(y3e,"STRONG",{});var NYr=s(Hae);O3o=r(NYr,"canine"),NYr.forEach(t),G3o=r(y3e," \u2014 "),Rj=n(y3e,"A",{href:!0});var qYr=s(Rj);X3o=r(qYr,"CanineForMultipleChoice"),qYr.forEach(t),V3o=r(y3e," (Canine model)"),y3e.forEach(t),z3o=i(G),Kb=n(G,"LI",{});var w3e=s(Kb);Uae=n(w3e,"STRONG",{});var OYr=s(Uae);W3o=r(OYr,"convbert"),OYr.forEach(t),Q3o=r(w3e," \u2014 "),Sj=n(w3e,"A",{href:!0});var GYr=s(Sj);H3o=r(GYr,"ConvBertForMultipleChoice"),GYr.forEach(t),U3o=r(w3e," (ConvBERT model)"),w3e.forEach(t),J3o=i(G),Zb=n(G,"LI",{});var A3e=s(Zb);Jae=n(A3e,"STRONG",{});var XYr=s(Jae);Y3o=r(XYr,"data2vec-text"),XYr.forEach(t),K3o=r(A3e," \u2014 "),Pj=n(A3e,"A",{href:!0});var VYr=s(Pj);Z3o=r(VYr,"Data2VecTextForMultipleChoice"),VYr.forEach(t),eyo=r(A3e," (Data2VecText model)"),A3e.forEach(t),oyo=i(G),e5=n(G,"LI",{});var L3e=s(e5);Yae=n(L3e,"STRONG",{});var zYr=s(Yae);ryo=r(zYr,"distilbert"),zYr.forEach(t),tyo=r(L3e," \u2014 "),$j=n(L3e,"A",{href:!0});var WYr=s($j);ayo=r(WYr,"DistilBertForMultipleChoice"),WYr.forEach(t),nyo=r(L3e," (DistilBERT model)"),L3e.forEach(t),syo=i(G),o5=n(G,"LI",{});var B3e=s(o5);Kae=n(B3e,"STRONG",{});var QYr=s(Kae);lyo=r(QYr,"electra"),QYr.forEach(t),iyo=r(B3e," \u2014 "),Ij=n(B3e,"A",{href:!0});var HYr=s(Ij);dyo=r(HYr,"ElectraForMultipleChoice"),HYr.forEach(t),cyo=r(B3e," (ELECTRA model)"),B3e.forEach(t),fyo=i(G),r5=n(G,"LI",{});var x3e=s(r5);Zae=n(x3e,"STRONG",{});var UYr=s(Zae);myo=r(UYr,"flaubert"),UYr.forEach(t),gyo=r(x3e," \u2014 "),jj=n(x3e,"A",{href:!0});var JYr=s(jj);hyo=r(JYr,"FlaubertForMultipleChoice"),JYr.forEach(t),pyo=r(x3e," (FlauBERT model)"),x3e.forEach(t),_yo=i(G),t5=n(G,"LI",{});var k3e=s(t5);ene=n(k3e,"STRONG",{});var YYr=s(ene);uyo=r(YYr,"fnet"),YYr.forEach(t),byo=r(k3e," \u2014 "),Dj=n(k3e,"A",{href:!0});var KYr=s(Dj);vyo=r(KYr,"FNetForMultipleChoice"),KYr.forEach(t),Tyo=r(k3e," (FNet model)"),k3e.forEach(t),Fyo=i(G),a5=n(G,"LI",{});var R3e=s(a5);one=n(R3e,"STRONG",{});var ZYr=s(one);Cyo=r(ZYr,"funnel"),ZYr.forEach(t),Myo=r(R3e," \u2014 "),Nj=n(R3e,"A",{href:!0});var eKr=s(Nj);Eyo=r(eKr,"FunnelForMultipleChoice"),eKr.forEach(t),yyo=r(R3e," (Funnel Transformer model)"),R3e.forEach(t),wyo=i(G),n5=n(G,"LI",{});var S3e=s(n5);rne=n(S3e,"STRONG",{});var oKr=s(rne);Ayo=r(oKr,"ibert"),oKr.forEach(t),Lyo=r(S3e," \u2014 "),qj=n(S3e,"A",{href:!0});var rKr=s(qj);Byo=r(rKr,"IBertForMultipleChoice"),rKr.forEach(t),xyo=r(S3e," (I-BERT model)"),S3e.forEach(t),kyo=i(G),s5=n(G,"LI",{});var P3e=s(s5);tne=n(P3e,"STRONG",{});var tKr=s(tne);Ryo=r(tKr,"longformer"),tKr.forEach(t),Syo=r(P3e," \u2014 "),Oj=n(P3e,"A",{href:!0});var aKr=s(Oj);Pyo=r(aKr,"LongformerForMultipleChoice"),aKr.forEach(t),$yo=r(P3e," (Longformer model)"),P3e.forEach(t),Iyo=i(G),l5=n(G,"LI",{});var $3e=s(l5);ane=n($3e,"STRONG",{});var nKr=s(ane);jyo=r(nKr,"megatron-bert"),nKr.forEach(t),Dyo=r($3e," \u2014 "),Gj=n($3e,"A",{href:!0});var sKr=s(Gj);Nyo=r(sKr,"MegatronBertForMultipleChoice"),sKr.forEach(t),qyo=r($3e," (MegatronBert model)"),$3e.forEach(t),Oyo=i(G),i5=n(G,"LI",{});var I3e=s(i5);nne=n(I3e,"STRONG",{});var lKr=s(nne);Gyo=r(lKr,"mobilebert"),lKr.forEach(t),Xyo=r(I3e," \u2014 "),Xj=n(I3e,"A",{href:!0});var iKr=s(Xj);Vyo=r(iKr,"MobileBertForMultipleChoice"),iKr.forEach(t),zyo=r(I3e," (MobileBERT model)"),I3e.forEach(t),Wyo=i(G),d5=n(G,"LI",{});var j3e=s(d5);sne=n(j3e,"STRONG",{});var dKr=s(sne);Qyo=r(dKr,"mpnet"),dKr.forEach(t),Hyo=r(j3e," \u2014 "),Vj=n(j3e,"A",{href:!0});var cKr=s(Vj);Uyo=r(cKr,"MPNetForMultipleChoice"),cKr.forEach(t),Jyo=r(j3e," (MPNet model)"),j3e.forEach(t),Yyo=i(G),c5=n(G,"LI",{});var D3e=s(c5);lne=n(D3e,"STRONG",{});var fKr=s(lne);Kyo=r(fKr,"nystromformer"),fKr.forEach(t),Zyo=r(D3e," \u2014 "),zj=n(D3e,"A",{href:!0});var mKr=s(zj);ewo=r(mKr,"NystromformerForMultipleChoice"),mKr.forEach(t),owo=r(D3e," (Nystromformer model)"),D3e.forEach(t),rwo=i(G),f5=n(G,"LI",{});var N3e=s(f5);ine=n(N3e,"STRONG",{});var gKr=s(ine);two=r(gKr,"qdqbert"),gKr.forEach(t),awo=r(N3e," \u2014 "),Wj=n(N3e,"A",{href:!0});var hKr=s(Wj);nwo=r(hKr,"QDQBertForMultipleChoice"),hKr.forEach(t),swo=r(N3e," (QDQBert model)"),N3e.forEach(t),lwo=i(G),m5=n(G,"LI",{});var q3e=s(m5);dne=n(q3e,"STRONG",{});var pKr=s(dne);iwo=r(pKr,"rembert"),pKr.forEach(t),dwo=r(q3e," \u2014 "),Qj=n(q3e,"A",{href:!0});var _Kr=s(Qj);cwo=r(_Kr,"RemBertForMultipleChoice"),_Kr.forEach(t),fwo=r(q3e," (RemBERT model)"),q3e.forEach(t),mwo=i(G),g5=n(G,"LI",{});var O3e=s(g5);cne=n(O3e,"STRONG",{});var uKr=s(cne);gwo=r(uKr,"roberta"),uKr.forEach(t),hwo=r(O3e," \u2014 "),Hj=n(O3e,"A",{href:!0});var bKr=s(Hj);pwo=r(bKr,"RobertaForMultipleChoice"),bKr.forEach(t),_wo=r(O3e," (RoBERTa model)"),O3e.forEach(t),uwo=i(G),h5=n(G,"LI",{});var G3e=s(h5);fne=n(G3e,"STRONG",{});var vKr=s(fne);bwo=r(vKr,"roformer"),vKr.forEach(t),vwo=r(G3e," \u2014 "),Uj=n(G3e,"A",{href:!0});var TKr=s(Uj);Two=r(TKr,"RoFormerForMultipleChoice"),TKr.forEach(t),Fwo=r(G3e," (RoFormer model)"),G3e.forEach(t),Cwo=i(G),p5=n(G,"LI",{});var X3e=s(p5);mne=n(X3e,"STRONG",{});var FKr=s(mne);Mwo=r(FKr,"squeezebert"),FKr.forEach(t),Ewo=r(X3e," \u2014 "),Jj=n(X3e,"A",{href:!0});var CKr=s(Jj);ywo=r(CKr,"SqueezeBertForMultipleChoice"),CKr.forEach(t),wwo=r(X3e," (SqueezeBERT model)"),X3e.forEach(t),Awo=i(G),_5=n(G,"LI",{});var V3e=s(_5);gne=n(V3e,"STRONG",{});var MKr=s(gne);Lwo=r(MKr,"xlm"),MKr.forEach(t),Bwo=r(V3e," \u2014 "),Yj=n(V3e,"A",{href:!0});var EKr=s(Yj);xwo=r(EKr,"XLMForMultipleChoice"),EKr.forEach(t),kwo=r(V3e," (XLM model)"),V3e.forEach(t),Rwo=i(G),u5=n(G,"LI",{});var z3e=s(u5);hne=n(z3e,"STRONG",{});var yKr=s(hne);Swo=r(yKr,"xlm-roberta"),yKr.forEach(t),Pwo=r(z3e," \u2014 "),Kj=n(z3e,"A",{href:!0});var wKr=s(Kj);$wo=r(wKr,"XLMRobertaForMultipleChoice"),wKr.forEach(t),Iwo=r(z3e," (XLM-RoBERTa model)"),z3e.forEach(t),jwo=i(G),b5=n(G,"LI",{});var W3e=s(b5);pne=n(W3e,"STRONG",{});var AKr=s(pne);Dwo=r(AKr,"xlm-roberta-xl"),AKr.forEach(t),Nwo=r(W3e," \u2014 "),Zj=n(W3e,"A",{href:!0});var LKr=s(Zj);qwo=r(LKr,"XLMRobertaXLForMultipleChoice"),LKr.forEach(t),Owo=r(W3e," (XLM-RoBERTa-XL model)"),W3e.forEach(t),Gwo=i(G),v5=n(G,"LI",{});var Q3e=s(v5);_ne=n(Q3e,"STRONG",{});var BKr=s(_ne);Xwo=r(BKr,"xlnet"),BKr.forEach(t),Vwo=r(Q3e," \u2014 "),eD=n(Q3e,"A",{href:!0});var xKr=s(eD);zwo=r(xKr,"XLNetForMultipleChoice"),xKr.forEach(t),Wwo=r(Q3e," (XLNet model)"),Q3e.forEach(t),Qwo=i(G),T5=n(G,"LI",{});var H3e=s(T5);une=n(H3e,"STRONG",{});var kKr=s(une);Hwo=r(kKr,"yoso"),kKr.forEach(t),Uwo=r(H3e," \u2014 "),oD=n(H3e,"A",{href:!0});var RKr=s(oD);Jwo=r(RKr,"YosoForMultipleChoice"),RKr.forEach(t),Ywo=r(H3e," (YOSO model)"),H3e.forEach(t),G.forEach(t),Kwo=i(Ut),F5=n(Ut,"P",{});var U3e=s(F5);Zwo=r(U3e,"The model is set in evaluation mode by default using "),bne=n(U3e,"CODE",{});var SKr=s(bne);eAo=r(SKr,"model.eval()"),SKr.forEach(t),oAo=r(U3e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vne=n(U3e,"CODE",{});var PKr=s(vne);rAo=r(PKr,"model.train()"),PKr.forEach(t),U3e.forEach(t),tAo=i(Ut),Tne=n(Ut,"P",{});var $Kr=s(Tne);aAo=r($Kr,"Examples:"),$Kr.forEach(t),nAo=i(Ut),m(PE.$$.fragment,Ut),Ut.forEach(t),dl.forEach(t),vke=i(d),yd=n(d,"H2",{class:!0});var xSe=s(yd);C5=n(xSe,"A",{id:!0,class:!0,href:!0});var IKr=s(C5);Fne=n(IKr,"SPAN",{});var jKr=s(Fne);m($E.$$.fragment,jKr),jKr.forEach(t),IKr.forEach(t),sAo=i(xSe),Cne=n(xSe,"SPAN",{});var DKr=s(Cne);lAo=r(DKr,"AutoModelForNextSentencePrediction"),DKr.forEach(t),xSe.forEach(t),Tke=i(d),ar=n(d,"DIV",{class:!0});var fl=s(ar);m(IE.$$.fragment,fl),iAo=i(fl),wd=n(fl,"P",{});var sW=s(wd);dAo=r(sW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Mne=n(sW,"CODE",{});var NKr=s(Mne);cAo=r(NKr,"from_pretrained()"),NKr.forEach(t),fAo=r(sW,"class method or the "),Ene=n(sW,"CODE",{});var qKr=s(Ene);mAo=r(qKr,"from_config()"),qKr.forEach(t),gAo=r(sW,`class
method.`),sW.forEach(t),hAo=i(fl),jE=n(fl,"P",{});var kSe=s(jE);pAo=r(kSe,"This class cannot be instantiated directly using "),yne=n(kSe,"CODE",{});var OKr=s(yne);_Ao=r(OKr,"__init__()"),OKr.forEach(t),uAo=r(kSe," (throws an error)."),kSe.forEach(t),bAo=i(fl),Zr=n(fl,"DIV",{class:!0});var ml=s(Zr);m(DE.$$.fragment,ml),vAo=i(ml),wne=n(ml,"P",{});var GKr=s(wne);TAo=r(GKr,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),GKr.forEach(t),FAo=i(ml),Ad=n(ml,"P",{});var lW=s(Ad);CAo=r(lW,`Note:
Loading a model from its configuration file does `),Ane=n(lW,"STRONG",{});var XKr=s(Ane);MAo=r(XKr,"not"),XKr.forEach(t),EAo=r(lW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lne=n(lW,"CODE",{});var VKr=s(Lne);yAo=r(VKr,"from_pretrained()"),VKr.forEach(t),wAo=r(lW,"to load the model weights."),lW.forEach(t),AAo=i(ml),Bne=n(ml,"P",{});var zKr=s(Bne);LAo=r(zKr,"Examples:"),zKr.forEach(t),BAo=i(ml),m(NE.$$.fragment,ml),ml.forEach(t),xAo=i(fl),Ve=n(fl,"DIV",{class:!0});var Jt=s(Ve);m(qE.$$.fragment,Jt),kAo=i(Jt),xne=n(Jt,"P",{});var WKr=s(xne);RAo=r(WKr,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),WKr.forEach(t),SAo=i(Jt),on=n(Jt,"P",{});var _M=s(on);PAo=r(_M,"The model class to instantiate is selected based on the "),kne=n(_M,"CODE",{});var QKr=s(kne);$Ao=r(QKr,"model_type"),QKr.forEach(t),IAo=r(_M,` property of the config object (either
passed as an argument or loaded from `),Rne=n(_M,"CODE",{});var HKr=s(Rne);jAo=r(HKr,"pretrained_model_name_or_path"),HKr.forEach(t),DAo=r(_M,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sne=n(_M,"CODE",{});var UKr=s(Sne);NAo=r(UKr,"pretrained_model_name_or_path"),UKr.forEach(t),qAo=r(_M,":"),_M.forEach(t),OAo=i(Jt),ma=n(Jt,"UL",{});var gl=s(ma);M5=n(gl,"LI",{});var J3e=s(M5);Pne=n(J3e,"STRONG",{});var JKr=s(Pne);GAo=r(JKr,"bert"),JKr.forEach(t),XAo=r(J3e," \u2014 "),rD=n(J3e,"A",{href:!0});var YKr=s(rD);VAo=r(YKr,"BertForNextSentencePrediction"),YKr.forEach(t),zAo=r(J3e," (BERT model)"),J3e.forEach(t),WAo=i(gl),E5=n(gl,"LI",{});var Y3e=s(E5);$ne=n(Y3e,"STRONG",{});var KKr=s($ne);QAo=r(KKr,"fnet"),KKr.forEach(t),HAo=r(Y3e," \u2014 "),tD=n(Y3e,"A",{href:!0});var ZKr=s(tD);UAo=r(ZKr,"FNetForNextSentencePrediction"),ZKr.forEach(t),JAo=r(Y3e," (FNet model)"),Y3e.forEach(t),YAo=i(gl),y5=n(gl,"LI",{});var K3e=s(y5);Ine=n(K3e,"STRONG",{});var eZr=s(Ine);KAo=r(eZr,"megatron-bert"),eZr.forEach(t),ZAo=r(K3e," \u2014 "),aD=n(K3e,"A",{href:!0});var oZr=s(aD);eLo=r(oZr,"MegatronBertForNextSentencePrediction"),oZr.forEach(t),oLo=r(K3e," (MegatronBert model)"),K3e.forEach(t),rLo=i(gl),w5=n(gl,"LI",{});var Z3e=s(w5);jne=n(Z3e,"STRONG",{});var rZr=s(jne);tLo=r(rZr,"mobilebert"),rZr.forEach(t),aLo=r(Z3e," \u2014 "),nD=n(Z3e,"A",{href:!0});var tZr=s(nD);nLo=r(tZr,"MobileBertForNextSentencePrediction"),tZr.forEach(t),sLo=r(Z3e," (MobileBERT model)"),Z3e.forEach(t),lLo=i(gl),A5=n(gl,"LI",{});var eye=s(A5);Dne=n(eye,"STRONG",{});var aZr=s(Dne);iLo=r(aZr,"qdqbert"),aZr.forEach(t),dLo=r(eye," \u2014 "),sD=n(eye,"A",{href:!0});var nZr=s(sD);cLo=r(nZr,"QDQBertForNextSentencePrediction"),nZr.forEach(t),fLo=r(eye," (QDQBert model)"),eye.forEach(t),gl.forEach(t),mLo=i(Jt),L5=n(Jt,"P",{});var oye=s(L5);gLo=r(oye,"The model is set in evaluation mode by default using "),Nne=n(oye,"CODE",{});var sZr=s(Nne);hLo=r(sZr,"model.eval()"),sZr.forEach(t),pLo=r(oye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qne=n(oye,"CODE",{});var lZr=s(qne);_Lo=r(lZr,"model.train()"),lZr.forEach(t),oye.forEach(t),uLo=i(Jt),One=n(Jt,"P",{});var iZr=s(One);bLo=r(iZr,"Examples:"),iZr.forEach(t),vLo=i(Jt),m(OE.$$.fragment,Jt),Jt.forEach(t),fl.forEach(t),Fke=i(d),Ld=n(d,"H2",{class:!0});var RSe=s(Ld);B5=n(RSe,"A",{id:!0,class:!0,href:!0});var dZr=s(B5);Gne=n(dZr,"SPAN",{});var cZr=s(Gne);m(GE.$$.fragment,cZr),cZr.forEach(t),dZr.forEach(t),TLo=i(RSe),Xne=n(RSe,"SPAN",{});var fZr=s(Xne);FLo=r(fZr,"AutoModelForTokenClassification"),fZr.forEach(t),RSe.forEach(t),Cke=i(d),nr=n(d,"DIV",{class:!0});var hl=s(nr);m(XE.$$.fragment,hl),CLo=i(hl),Bd=n(hl,"P",{});var iW=s(Bd);MLo=r(iW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Vne=n(iW,"CODE",{});var mZr=s(Vne);ELo=r(mZr,"from_pretrained()"),mZr.forEach(t),yLo=r(iW,"class method or the "),zne=n(iW,"CODE",{});var gZr=s(zne);wLo=r(gZr,"from_config()"),gZr.forEach(t),ALo=r(iW,`class
method.`),iW.forEach(t),LLo=i(hl),VE=n(hl,"P",{});var SSe=s(VE);BLo=r(SSe,"This class cannot be instantiated directly using "),Wne=n(SSe,"CODE",{});var hZr=s(Wne);xLo=r(hZr,"__init__()"),hZr.forEach(t),kLo=r(SSe," (throws an error)."),SSe.forEach(t),RLo=i(hl),et=n(hl,"DIV",{class:!0});var pl=s(et);m(zE.$$.fragment,pl),SLo=i(pl),Qne=n(pl,"P",{});var pZr=s(Qne);PLo=r(pZr,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),pZr.forEach(t),$Lo=i(pl),xd=n(pl,"P",{});var dW=s(xd);ILo=r(dW,`Note:
Loading a model from its configuration file does `),Hne=n(dW,"STRONG",{});var _Zr=s(Hne);jLo=r(_Zr,"not"),_Zr.forEach(t),DLo=r(dW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Une=n(dW,"CODE",{});var uZr=s(Une);NLo=r(uZr,"from_pretrained()"),uZr.forEach(t),qLo=r(dW,"to load the model weights."),dW.forEach(t),OLo=i(pl),Jne=n(pl,"P",{});var bZr=s(Jne);GLo=r(bZr,"Examples:"),bZr.forEach(t),XLo=i(pl),m(WE.$$.fragment,pl),pl.forEach(t),VLo=i(hl),ze=n(hl,"DIV",{class:!0});var Yt=s(ze);m(QE.$$.fragment,Yt),zLo=i(Yt),Yne=n(Yt,"P",{});var vZr=s(Yne);WLo=r(vZr,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),vZr.forEach(t),QLo=i(Yt),rn=n(Yt,"P",{});var uM=s(rn);HLo=r(uM,"The model class to instantiate is selected based on the "),Kne=n(uM,"CODE",{});var TZr=s(Kne);ULo=r(TZr,"model_type"),TZr.forEach(t),JLo=r(uM,` property of the config object (either
passed as an argument or loaded from `),Zne=n(uM,"CODE",{});var FZr=s(Zne);YLo=r(FZr,"pretrained_model_name_or_path"),FZr.forEach(t),KLo=r(uM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ese=n(uM,"CODE",{});var CZr=s(ese);ZLo=r(CZr,"pretrained_model_name_or_path"),CZr.forEach(t),e7o=r(uM,":"),uM.forEach(t),o7o=i(Yt),N=n(Yt,"UL",{});var q=s(N);x5=n(q,"LI",{});var rye=s(x5);ose=n(rye,"STRONG",{});var MZr=s(ose);r7o=r(MZr,"albert"),MZr.forEach(t),t7o=r(rye," \u2014 "),lD=n(rye,"A",{href:!0});var EZr=s(lD);a7o=r(EZr,"AlbertForTokenClassification"),EZr.forEach(t),n7o=r(rye," (ALBERT model)"),rye.forEach(t),s7o=i(q),k5=n(q,"LI",{});var tye=s(k5);rse=n(tye,"STRONG",{});var yZr=s(rse);l7o=r(yZr,"bert"),yZr.forEach(t),i7o=r(tye," \u2014 "),iD=n(tye,"A",{href:!0});var wZr=s(iD);d7o=r(wZr,"BertForTokenClassification"),wZr.forEach(t),c7o=r(tye," (BERT model)"),tye.forEach(t),f7o=i(q),R5=n(q,"LI",{});var aye=s(R5);tse=n(aye,"STRONG",{});var AZr=s(tse);m7o=r(AZr,"big_bird"),AZr.forEach(t),g7o=r(aye," \u2014 "),dD=n(aye,"A",{href:!0});var LZr=s(dD);h7o=r(LZr,"BigBirdForTokenClassification"),LZr.forEach(t),p7o=r(aye," (BigBird model)"),aye.forEach(t),_7o=i(q),S5=n(q,"LI",{});var nye=s(S5);ase=n(nye,"STRONG",{});var BZr=s(ase);u7o=r(BZr,"camembert"),BZr.forEach(t),b7o=r(nye," \u2014 "),cD=n(nye,"A",{href:!0});var xZr=s(cD);v7o=r(xZr,"CamembertForTokenClassification"),xZr.forEach(t),T7o=r(nye," (CamemBERT model)"),nye.forEach(t),F7o=i(q),P5=n(q,"LI",{});var sye=s(P5);nse=n(sye,"STRONG",{});var kZr=s(nse);C7o=r(kZr,"canine"),kZr.forEach(t),M7o=r(sye," \u2014 "),fD=n(sye,"A",{href:!0});var RZr=s(fD);E7o=r(RZr,"CanineForTokenClassification"),RZr.forEach(t),y7o=r(sye," (Canine model)"),sye.forEach(t),w7o=i(q),$5=n(q,"LI",{});var lye=s($5);sse=n(lye,"STRONG",{});var SZr=s(sse);A7o=r(SZr,"convbert"),SZr.forEach(t),L7o=r(lye," \u2014 "),mD=n(lye,"A",{href:!0});var PZr=s(mD);B7o=r(PZr,"ConvBertForTokenClassification"),PZr.forEach(t),x7o=r(lye," (ConvBERT model)"),lye.forEach(t),k7o=i(q),I5=n(q,"LI",{});var iye=s(I5);lse=n(iye,"STRONG",{});var $Zr=s(lse);R7o=r($Zr,"data2vec-text"),$Zr.forEach(t),S7o=r(iye," \u2014 "),gD=n(iye,"A",{href:!0});var IZr=s(gD);P7o=r(IZr,"Data2VecTextForTokenClassification"),IZr.forEach(t),$7o=r(iye," (Data2VecText model)"),iye.forEach(t),I7o=i(q),j5=n(q,"LI",{});var dye=s(j5);ise=n(dye,"STRONG",{});var jZr=s(ise);j7o=r(jZr,"deberta"),jZr.forEach(t),D7o=r(dye," \u2014 "),hD=n(dye,"A",{href:!0});var DZr=s(hD);N7o=r(DZr,"DebertaForTokenClassification"),DZr.forEach(t),q7o=r(dye," (DeBERTa model)"),dye.forEach(t),O7o=i(q),D5=n(q,"LI",{});var cye=s(D5);dse=n(cye,"STRONG",{});var NZr=s(dse);G7o=r(NZr,"deberta-v2"),NZr.forEach(t),X7o=r(cye," \u2014 "),pD=n(cye,"A",{href:!0});var qZr=s(pD);V7o=r(qZr,"DebertaV2ForTokenClassification"),qZr.forEach(t),z7o=r(cye," (DeBERTa-v2 model)"),cye.forEach(t),W7o=i(q),N5=n(q,"LI",{});var fye=s(N5);cse=n(fye,"STRONG",{});var OZr=s(cse);Q7o=r(OZr,"distilbert"),OZr.forEach(t),H7o=r(fye," \u2014 "),_D=n(fye,"A",{href:!0});var GZr=s(_D);U7o=r(GZr,"DistilBertForTokenClassification"),GZr.forEach(t),J7o=r(fye," (DistilBERT model)"),fye.forEach(t),Y7o=i(q),q5=n(q,"LI",{});var mye=s(q5);fse=n(mye,"STRONG",{});var XZr=s(fse);K7o=r(XZr,"electra"),XZr.forEach(t),Z7o=r(mye," \u2014 "),uD=n(mye,"A",{href:!0});var VZr=s(uD);e9o=r(VZr,"ElectraForTokenClassification"),VZr.forEach(t),o9o=r(mye," (ELECTRA model)"),mye.forEach(t),r9o=i(q),O5=n(q,"LI",{});var gye=s(O5);mse=n(gye,"STRONG",{});var zZr=s(mse);t9o=r(zZr,"flaubert"),zZr.forEach(t),a9o=r(gye," \u2014 "),bD=n(gye,"A",{href:!0});var WZr=s(bD);n9o=r(WZr,"FlaubertForTokenClassification"),WZr.forEach(t),s9o=r(gye," (FlauBERT model)"),gye.forEach(t),l9o=i(q),G5=n(q,"LI",{});var hye=s(G5);gse=n(hye,"STRONG",{});var QZr=s(gse);i9o=r(QZr,"fnet"),QZr.forEach(t),d9o=r(hye," \u2014 "),vD=n(hye,"A",{href:!0});var HZr=s(vD);c9o=r(HZr,"FNetForTokenClassification"),HZr.forEach(t),f9o=r(hye," (FNet model)"),hye.forEach(t),m9o=i(q),X5=n(q,"LI",{});var pye=s(X5);hse=n(pye,"STRONG",{});var UZr=s(hse);g9o=r(UZr,"funnel"),UZr.forEach(t),h9o=r(pye," \u2014 "),TD=n(pye,"A",{href:!0});var JZr=s(TD);p9o=r(JZr,"FunnelForTokenClassification"),JZr.forEach(t),_9o=r(pye," (Funnel Transformer model)"),pye.forEach(t),u9o=i(q),V5=n(q,"LI",{});var _ye=s(V5);pse=n(_ye,"STRONG",{});var YZr=s(pse);b9o=r(YZr,"gpt2"),YZr.forEach(t),v9o=r(_ye," \u2014 "),FD=n(_ye,"A",{href:!0});var KZr=s(FD);T9o=r(KZr,"GPT2ForTokenClassification"),KZr.forEach(t),F9o=r(_ye," (OpenAI GPT-2 model)"),_ye.forEach(t),C9o=i(q),z5=n(q,"LI",{});var uye=s(z5);_se=n(uye,"STRONG",{});var ZZr=s(_se);M9o=r(ZZr,"ibert"),ZZr.forEach(t),E9o=r(uye," \u2014 "),CD=n(uye,"A",{href:!0});var eet=s(CD);y9o=r(eet,"IBertForTokenClassification"),eet.forEach(t),w9o=r(uye," (I-BERT model)"),uye.forEach(t),A9o=i(q),W5=n(q,"LI",{});var bye=s(W5);use=n(bye,"STRONG",{});var oet=s(use);L9o=r(oet,"layoutlm"),oet.forEach(t),B9o=r(bye," \u2014 "),MD=n(bye,"A",{href:!0});var ret=s(MD);x9o=r(ret,"LayoutLMForTokenClassification"),ret.forEach(t),k9o=r(bye," (LayoutLM model)"),bye.forEach(t),R9o=i(q),Q5=n(q,"LI",{});var vye=s(Q5);bse=n(vye,"STRONG",{});var tet=s(bse);S9o=r(tet,"layoutlmv2"),tet.forEach(t),P9o=r(vye," \u2014 "),ED=n(vye,"A",{href:!0});var aet=s(ED);$9o=r(aet,"LayoutLMv2ForTokenClassification"),aet.forEach(t),I9o=r(vye," (LayoutLMv2 model)"),vye.forEach(t),j9o=i(q),H5=n(q,"LI",{});var Tye=s(H5);vse=n(Tye,"STRONG",{});var net=s(vse);D9o=r(net,"longformer"),net.forEach(t),N9o=r(Tye," \u2014 "),yD=n(Tye,"A",{href:!0});var set=s(yD);q9o=r(set,"LongformerForTokenClassification"),set.forEach(t),O9o=r(Tye," (Longformer model)"),Tye.forEach(t),G9o=i(q),U5=n(q,"LI",{});var Fye=s(U5);Tse=n(Fye,"STRONG",{});var iet=s(Tse);X9o=r(iet,"megatron-bert"),iet.forEach(t),V9o=r(Fye," \u2014 "),wD=n(Fye,"A",{href:!0});var det=s(wD);z9o=r(det,"MegatronBertForTokenClassification"),det.forEach(t),W9o=r(Fye," (MegatronBert model)"),Fye.forEach(t),Q9o=i(q),J5=n(q,"LI",{});var Cye=s(J5);Fse=n(Cye,"STRONG",{});var cet=s(Fse);H9o=r(cet,"mobilebert"),cet.forEach(t),U9o=r(Cye," \u2014 "),AD=n(Cye,"A",{href:!0});var fet=s(AD);J9o=r(fet,"MobileBertForTokenClassification"),fet.forEach(t),Y9o=r(Cye," (MobileBERT model)"),Cye.forEach(t),K9o=i(q),Y5=n(q,"LI",{});var Mye=s(Y5);Cse=n(Mye,"STRONG",{});var met=s(Cse);Z9o=r(met,"mpnet"),met.forEach(t),eBo=r(Mye," \u2014 "),LD=n(Mye,"A",{href:!0});var get=s(LD);oBo=r(get,"MPNetForTokenClassification"),get.forEach(t),rBo=r(Mye," (MPNet model)"),Mye.forEach(t),tBo=i(q),K5=n(q,"LI",{});var Eye=s(K5);Mse=n(Eye,"STRONG",{});var het=s(Mse);aBo=r(het,"nystromformer"),het.forEach(t),nBo=r(Eye," \u2014 "),BD=n(Eye,"A",{href:!0});var pet=s(BD);sBo=r(pet,"NystromformerForTokenClassification"),pet.forEach(t),lBo=r(Eye," (Nystromformer model)"),Eye.forEach(t),iBo=i(q),Z5=n(q,"LI",{});var yye=s(Z5);Ese=n(yye,"STRONG",{});var _et=s(Ese);dBo=r(_et,"qdqbert"),_et.forEach(t),cBo=r(yye," \u2014 "),xD=n(yye,"A",{href:!0});var uet=s(xD);fBo=r(uet,"QDQBertForTokenClassification"),uet.forEach(t),mBo=r(yye," (QDQBert model)"),yye.forEach(t),gBo=i(q),e2=n(q,"LI",{});var wye=s(e2);yse=n(wye,"STRONG",{});var bet=s(yse);hBo=r(bet,"rembert"),bet.forEach(t),pBo=r(wye," \u2014 "),kD=n(wye,"A",{href:!0});var vet=s(kD);_Bo=r(vet,"RemBertForTokenClassification"),vet.forEach(t),uBo=r(wye," (RemBERT model)"),wye.forEach(t),bBo=i(q),o2=n(q,"LI",{});var Aye=s(o2);wse=n(Aye,"STRONG",{});var Tet=s(wse);vBo=r(Tet,"roberta"),Tet.forEach(t),TBo=r(Aye," \u2014 "),RD=n(Aye,"A",{href:!0});var Fet=s(RD);FBo=r(Fet,"RobertaForTokenClassification"),Fet.forEach(t),CBo=r(Aye," (RoBERTa model)"),Aye.forEach(t),MBo=i(q),r2=n(q,"LI",{});var Lye=s(r2);Ase=n(Lye,"STRONG",{});var Cet=s(Ase);EBo=r(Cet,"roformer"),Cet.forEach(t),yBo=r(Lye," \u2014 "),SD=n(Lye,"A",{href:!0});var Met=s(SD);wBo=r(Met,"RoFormerForTokenClassification"),Met.forEach(t),ABo=r(Lye," (RoFormer model)"),Lye.forEach(t),LBo=i(q),t2=n(q,"LI",{});var Bye=s(t2);Lse=n(Bye,"STRONG",{});var Eet=s(Lse);BBo=r(Eet,"squeezebert"),Eet.forEach(t),xBo=r(Bye," \u2014 "),PD=n(Bye,"A",{href:!0});var yet=s(PD);kBo=r(yet,"SqueezeBertForTokenClassification"),yet.forEach(t),RBo=r(Bye," (SqueezeBERT model)"),Bye.forEach(t),SBo=i(q),a2=n(q,"LI",{});var xye=s(a2);Bse=n(xye,"STRONG",{});var wet=s(Bse);PBo=r(wet,"xlm"),wet.forEach(t),$Bo=r(xye," \u2014 "),$D=n(xye,"A",{href:!0});var Aet=s($D);IBo=r(Aet,"XLMForTokenClassification"),Aet.forEach(t),jBo=r(xye," (XLM model)"),xye.forEach(t),DBo=i(q),n2=n(q,"LI",{});var kye=s(n2);xse=n(kye,"STRONG",{});var Let=s(xse);NBo=r(Let,"xlm-roberta"),Let.forEach(t),qBo=r(kye," \u2014 "),ID=n(kye,"A",{href:!0});var Bet=s(ID);OBo=r(Bet,"XLMRobertaForTokenClassification"),Bet.forEach(t),GBo=r(kye," (XLM-RoBERTa model)"),kye.forEach(t),XBo=i(q),s2=n(q,"LI",{});var Rye=s(s2);kse=n(Rye,"STRONG",{});var xet=s(kse);VBo=r(xet,"xlm-roberta-xl"),xet.forEach(t),zBo=r(Rye," \u2014 "),jD=n(Rye,"A",{href:!0});var ket=s(jD);WBo=r(ket,"XLMRobertaXLForTokenClassification"),ket.forEach(t),QBo=r(Rye," (XLM-RoBERTa-XL model)"),Rye.forEach(t),HBo=i(q),l2=n(q,"LI",{});var Sye=s(l2);Rse=n(Sye,"STRONG",{});var Ret=s(Rse);UBo=r(Ret,"xlnet"),Ret.forEach(t),JBo=r(Sye," \u2014 "),DD=n(Sye,"A",{href:!0});var Set=s(DD);YBo=r(Set,"XLNetForTokenClassification"),Set.forEach(t),KBo=r(Sye," (XLNet model)"),Sye.forEach(t),ZBo=i(q),i2=n(q,"LI",{});var Pye=s(i2);Sse=n(Pye,"STRONG",{});var Pet=s(Sse);exo=r(Pet,"yoso"),Pet.forEach(t),oxo=r(Pye," \u2014 "),ND=n(Pye,"A",{href:!0});var $et=s(ND);rxo=r($et,"YosoForTokenClassification"),$et.forEach(t),txo=r(Pye," (YOSO model)"),Pye.forEach(t),q.forEach(t),axo=i(Yt),d2=n(Yt,"P",{});var $ye=s(d2);nxo=r($ye,"The model is set in evaluation mode by default using "),Pse=n($ye,"CODE",{});var Iet=s(Pse);sxo=r(Iet,"model.eval()"),Iet.forEach(t),lxo=r($ye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$se=n($ye,"CODE",{});var jet=s($se);ixo=r(jet,"model.train()"),jet.forEach(t),$ye.forEach(t),dxo=i(Yt),Ise=n(Yt,"P",{});var Det=s(Ise);cxo=r(Det,"Examples:"),Det.forEach(t),fxo=i(Yt),m(HE.$$.fragment,Yt),Yt.forEach(t),hl.forEach(t),Mke=i(d),kd=n(d,"H2",{class:!0});var PSe=s(kd);c2=n(PSe,"A",{id:!0,class:!0,href:!0});var Net=s(c2);jse=n(Net,"SPAN",{});var qet=s(jse);m(UE.$$.fragment,qet),qet.forEach(t),Net.forEach(t),mxo=i(PSe),Dse=n(PSe,"SPAN",{});var Oet=s(Dse);gxo=r(Oet,"AutoModelForQuestionAnswering"),Oet.forEach(t),PSe.forEach(t),Eke=i(d),sr=n(d,"DIV",{class:!0});var _l=s(sr);m(JE.$$.fragment,_l),hxo=i(_l),Rd=n(_l,"P",{});var cW=s(Rd);pxo=r(cW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Nse=n(cW,"CODE",{});var Get=s(Nse);_xo=r(Get,"from_pretrained()"),Get.forEach(t),uxo=r(cW,"class method or the "),qse=n(cW,"CODE",{});var Xet=s(qse);bxo=r(Xet,"from_config()"),Xet.forEach(t),vxo=r(cW,`class
method.`),cW.forEach(t),Txo=i(_l),YE=n(_l,"P",{});var $Se=s(YE);Fxo=r($Se,"This class cannot be instantiated directly using "),Ose=n($Se,"CODE",{});var Vet=s(Ose);Cxo=r(Vet,"__init__()"),Vet.forEach(t),Mxo=r($Se," (throws an error)."),$Se.forEach(t),Exo=i(_l),ot=n(_l,"DIV",{class:!0});var ul=s(ot);m(KE.$$.fragment,ul),yxo=i(ul),Gse=n(ul,"P",{});var zet=s(Gse);wxo=r(zet,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),zet.forEach(t),Axo=i(ul),Sd=n(ul,"P",{});var fW=s(Sd);Lxo=r(fW,`Note:
Loading a model from its configuration file does `),Xse=n(fW,"STRONG",{});var Wet=s(Xse);Bxo=r(Wet,"not"),Wet.forEach(t),xxo=r(fW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vse=n(fW,"CODE",{});var Qet=s(Vse);kxo=r(Qet,"from_pretrained()"),Qet.forEach(t),Rxo=r(fW,"to load the model weights."),fW.forEach(t),Sxo=i(ul),zse=n(ul,"P",{});var Het=s(zse);Pxo=r(Het,"Examples:"),Het.forEach(t),$xo=i(ul),m(ZE.$$.fragment,ul),ul.forEach(t),Ixo=i(_l),We=n(_l,"DIV",{class:!0});var Kt=s(We);m(e3.$$.fragment,Kt),jxo=i(Kt),Wse=n(Kt,"P",{});var Uet=s(Wse);Dxo=r(Uet,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Uet.forEach(t),Nxo=i(Kt),tn=n(Kt,"P",{});var bM=s(tn);qxo=r(bM,"The model class to instantiate is selected based on the "),Qse=n(bM,"CODE",{});var Jet=s(Qse);Oxo=r(Jet,"model_type"),Jet.forEach(t),Gxo=r(bM,` property of the config object (either
passed as an argument or loaded from `),Hse=n(bM,"CODE",{});var Yet=s(Hse);Xxo=r(Yet,"pretrained_model_name_or_path"),Yet.forEach(t),Vxo=r(bM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Use=n(bM,"CODE",{});var Ket=s(Use);zxo=r(Ket,"pretrained_model_name_or_path"),Ket.forEach(t),Wxo=r(bM,":"),bM.forEach(t),Qxo=i(Kt),R=n(Kt,"UL",{});var P=s(R);f2=n(P,"LI",{});var Iye=s(f2);Jse=n(Iye,"STRONG",{});var Zet=s(Jse);Hxo=r(Zet,"albert"),Zet.forEach(t),Uxo=r(Iye," \u2014 "),qD=n(Iye,"A",{href:!0});var eot=s(qD);Jxo=r(eot,"AlbertForQuestionAnswering"),eot.forEach(t),Yxo=r(Iye," (ALBERT model)"),Iye.forEach(t),Kxo=i(P),m2=n(P,"LI",{});var jye=s(m2);Yse=n(jye,"STRONG",{});var oot=s(Yse);Zxo=r(oot,"bart"),oot.forEach(t),eko=r(jye," \u2014 "),OD=n(jye,"A",{href:!0});var rot=s(OD);oko=r(rot,"BartForQuestionAnswering"),rot.forEach(t),rko=r(jye," (BART model)"),jye.forEach(t),tko=i(P),g2=n(P,"LI",{});var Dye=s(g2);Kse=n(Dye,"STRONG",{});var tot=s(Kse);ako=r(tot,"bert"),tot.forEach(t),nko=r(Dye," \u2014 "),GD=n(Dye,"A",{href:!0});var aot=s(GD);sko=r(aot,"BertForQuestionAnswering"),aot.forEach(t),lko=r(Dye," (BERT model)"),Dye.forEach(t),iko=i(P),h2=n(P,"LI",{});var Nye=s(h2);Zse=n(Nye,"STRONG",{});var not=s(Zse);dko=r(not,"big_bird"),not.forEach(t),cko=r(Nye," \u2014 "),XD=n(Nye,"A",{href:!0});var sot=s(XD);fko=r(sot,"BigBirdForQuestionAnswering"),sot.forEach(t),mko=r(Nye," (BigBird model)"),Nye.forEach(t),gko=i(P),p2=n(P,"LI",{});var qye=s(p2);ele=n(qye,"STRONG",{});var lot=s(ele);hko=r(lot,"bigbird_pegasus"),lot.forEach(t),pko=r(qye," \u2014 "),VD=n(qye,"A",{href:!0});var iot=s(VD);_ko=r(iot,"BigBirdPegasusForQuestionAnswering"),iot.forEach(t),uko=r(qye," (BigBirdPegasus model)"),qye.forEach(t),bko=i(P),_2=n(P,"LI",{});var Oye=s(_2);ole=n(Oye,"STRONG",{});var dot=s(ole);vko=r(dot,"camembert"),dot.forEach(t),Tko=r(Oye," \u2014 "),zD=n(Oye,"A",{href:!0});var cot=s(zD);Fko=r(cot,"CamembertForQuestionAnswering"),cot.forEach(t),Cko=r(Oye," (CamemBERT model)"),Oye.forEach(t),Mko=i(P),u2=n(P,"LI",{});var Gye=s(u2);rle=n(Gye,"STRONG",{});var fot=s(rle);Eko=r(fot,"canine"),fot.forEach(t),yko=r(Gye," \u2014 "),WD=n(Gye,"A",{href:!0});var mot=s(WD);wko=r(mot,"CanineForQuestionAnswering"),mot.forEach(t),Ako=r(Gye," (Canine model)"),Gye.forEach(t),Lko=i(P),b2=n(P,"LI",{});var Xye=s(b2);tle=n(Xye,"STRONG",{});var got=s(tle);Bko=r(got,"convbert"),got.forEach(t),xko=r(Xye," \u2014 "),QD=n(Xye,"A",{href:!0});var hot=s(QD);kko=r(hot,"ConvBertForQuestionAnswering"),hot.forEach(t),Rko=r(Xye," (ConvBERT model)"),Xye.forEach(t),Sko=i(P),v2=n(P,"LI",{});var Vye=s(v2);ale=n(Vye,"STRONG",{});var pot=s(ale);Pko=r(pot,"data2vec-text"),pot.forEach(t),$ko=r(Vye," \u2014 "),HD=n(Vye,"A",{href:!0});var _ot=s(HD);Iko=r(_ot,"Data2VecTextForQuestionAnswering"),_ot.forEach(t),jko=r(Vye," (Data2VecText model)"),Vye.forEach(t),Dko=i(P),T2=n(P,"LI",{});var zye=s(T2);nle=n(zye,"STRONG",{});var uot=s(nle);Nko=r(uot,"deberta"),uot.forEach(t),qko=r(zye," \u2014 "),UD=n(zye,"A",{href:!0});var bot=s(UD);Oko=r(bot,"DebertaForQuestionAnswering"),bot.forEach(t),Gko=r(zye," (DeBERTa model)"),zye.forEach(t),Xko=i(P),F2=n(P,"LI",{});var Wye=s(F2);sle=n(Wye,"STRONG",{});var vot=s(sle);Vko=r(vot,"deberta-v2"),vot.forEach(t),zko=r(Wye," \u2014 "),JD=n(Wye,"A",{href:!0});var Tot=s(JD);Wko=r(Tot,"DebertaV2ForQuestionAnswering"),Tot.forEach(t),Qko=r(Wye," (DeBERTa-v2 model)"),Wye.forEach(t),Hko=i(P),C2=n(P,"LI",{});var Qye=s(C2);lle=n(Qye,"STRONG",{});var Fot=s(lle);Uko=r(Fot,"distilbert"),Fot.forEach(t),Jko=r(Qye," \u2014 "),YD=n(Qye,"A",{href:!0});var Cot=s(YD);Yko=r(Cot,"DistilBertForQuestionAnswering"),Cot.forEach(t),Kko=r(Qye," (DistilBERT model)"),Qye.forEach(t),Zko=i(P),M2=n(P,"LI",{});var Hye=s(M2);ile=n(Hye,"STRONG",{});var Mot=s(ile);eRo=r(Mot,"electra"),Mot.forEach(t),oRo=r(Hye," \u2014 "),KD=n(Hye,"A",{href:!0});var Eot=s(KD);rRo=r(Eot,"ElectraForQuestionAnswering"),Eot.forEach(t),tRo=r(Hye," (ELECTRA model)"),Hye.forEach(t),aRo=i(P),E2=n(P,"LI",{});var Uye=s(E2);dle=n(Uye,"STRONG",{});var yot=s(dle);nRo=r(yot,"flaubert"),yot.forEach(t),sRo=r(Uye," \u2014 "),ZD=n(Uye,"A",{href:!0});var wot=s(ZD);lRo=r(wot,"FlaubertForQuestionAnsweringSimple"),wot.forEach(t),iRo=r(Uye," (FlauBERT model)"),Uye.forEach(t),dRo=i(P),y2=n(P,"LI",{});var Jye=s(y2);cle=n(Jye,"STRONG",{});var Aot=s(cle);cRo=r(Aot,"fnet"),Aot.forEach(t),fRo=r(Jye," \u2014 "),eN=n(Jye,"A",{href:!0});var Lot=s(eN);mRo=r(Lot,"FNetForQuestionAnswering"),Lot.forEach(t),gRo=r(Jye," (FNet model)"),Jye.forEach(t),hRo=i(P),w2=n(P,"LI",{});var Yye=s(w2);fle=n(Yye,"STRONG",{});var Bot=s(fle);pRo=r(Bot,"funnel"),Bot.forEach(t),_Ro=r(Yye," \u2014 "),oN=n(Yye,"A",{href:!0});var xot=s(oN);uRo=r(xot,"FunnelForQuestionAnswering"),xot.forEach(t),bRo=r(Yye," (Funnel Transformer model)"),Yye.forEach(t),vRo=i(P),A2=n(P,"LI",{});var Kye=s(A2);mle=n(Kye,"STRONG",{});var kot=s(mle);TRo=r(kot,"gptj"),kot.forEach(t),FRo=r(Kye," \u2014 "),rN=n(Kye,"A",{href:!0});var Rot=s(rN);CRo=r(Rot,"GPTJForQuestionAnswering"),Rot.forEach(t),MRo=r(Kye," (GPT-J model)"),Kye.forEach(t),ERo=i(P),L2=n(P,"LI",{});var Zye=s(L2);gle=n(Zye,"STRONG",{});var Sot=s(gle);yRo=r(Sot,"ibert"),Sot.forEach(t),wRo=r(Zye," \u2014 "),tN=n(Zye,"A",{href:!0});var Pot=s(tN);ARo=r(Pot,"IBertForQuestionAnswering"),Pot.forEach(t),LRo=r(Zye," (I-BERT model)"),Zye.forEach(t),BRo=i(P),B2=n(P,"LI",{});var ewe=s(B2);hle=n(ewe,"STRONG",{});var $ot=s(hle);xRo=r($ot,"layoutlmv2"),$ot.forEach(t),kRo=r(ewe," \u2014 "),aN=n(ewe,"A",{href:!0});var Iot=s(aN);RRo=r(Iot,"LayoutLMv2ForQuestionAnswering"),Iot.forEach(t),SRo=r(ewe," (LayoutLMv2 model)"),ewe.forEach(t),PRo=i(P),x2=n(P,"LI",{});var owe=s(x2);ple=n(owe,"STRONG",{});var jot=s(ple);$Ro=r(jot,"led"),jot.forEach(t),IRo=r(owe," \u2014 "),nN=n(owe,"A",{href:!0});var Dot=s(nN);jRo=r(Dot,"LEDForQuestionAnswering"),Dot.forEach(t),DRo=r(owe," (LED model)"),owe.forEach(t),NRo=i(P),k2=n(P,"LI",{});var rwe=s(k2);_le=n(rwe,"STRONG",{});var Not=s(_le);qRo=r(Not,"longformer"),Not.forEach(t),ORo=r(rwe," \u2014 "),sN=n(rwe,"A",{href:!0});var qot=s(sN);GRo=r(qot,"LongformerForQuestionAnswering"),qot.forEach(t),XRo=r(rwe," (Longformer model)"),rwe.forEach(t),VRo=i(P),R2=n(P,"LI",{});var twe=s(R2);ule=n(twe,"STRONG",{});var Oot=s(ule);zRo=r(Oot,"lxmert"),Oot.forEach(t),WRo=r(twe," \u2014 "),lN=n(twe,"A",{href:!0});var Got=s(lN);QRo=r(Got,"LxmertForQuestionAnswering"),Got.forEach(t),HRo=r(twe," (LXMERT model)"),twe.forEach(t),URo=i(P),S2=n(P,"LI",{});var awe=s(S2);ble=n(awe,"STRONG",{});var Xot=s(ble);JRo=r(Xot,"mbart"),Xot.forEach(t),YRo=r(awe," \u2014 "),iN=n(awe,"A",{href:!0});var Vot=s(iN);KRo=r(Vot,"MBartForQuestionAnswering"),Vot.forEach(t),ZRo=r(awe," (mBART model)"),awe.forEach(t),eSo=i(P),P2=n(P,"LI",{});var nwe=s(P2);vle=n(nwe,"STRONG",{});var zot=s(vle);oSo=r(zot,"megatron-bert"),zot.forEach(t),rSo=r(nwe," \u2014 "),dN=n(nwe,"A",{href:!0});var Wot=s(dN);tSo=r(Wot,"MegatronBertForQuestionAnswering"),Wot.forEach(t),aSo=r(nwe," (MegatronBert model)"),nwe.forEach(t),nSo=i(P),$2=n(P,"LI",{});var swe=s($2);Tle=n(swe,"STRONG",{});var Qot=s(Tle);sSo=r(Qot,"mobilebert"),Qot.forEach(t),lSo=r(swe," \u2014 "),cN=n(swe,"A",{href:!0});var Hot=s(cN);iSo=r(Hot,"MobileBertForQuestionAnswering"),Hot.forEach(t),dSo=r(swe," (MobileBERT model)"),swe.forEach(t),cSo=i(P),I2=n(P,"LI",{});var lwe=s(I2);Fle=n(lwe,"STRONG",{});var Uot=s(Fle);fSo=r(Uot,"mpnet"),Uot.forEach(t),mSo=r(lwe," \u2014 "),fN=n(lwe,"A",{href:!0});var Jot=s(fN);gSo=r(Jot,"MPNetForQuestionAnswering"),Jot.forEach(t),hSo=r(lwe," (MPNet model)"),lwe.forEach(t),pSo=i(P),j2=n(P,"LI",{});var iwe=s(j2);Cle=n(iwe,"STRONG",{});var Yot=s(Cle);_So=r(Yot,"nystromformer"),Yot.forEach(t),uSo=r(iwe," \u2014 "),mN=n(iwe,"A",{href:!0});var Kot=s(mN);bSo=r(Kot,"NystromformerForQuestionAnswering"),Kot.forEach(t),vSo=r(iwe," (Nystromformer model)"),iwe.forEach(t),TSo=i(P),D2=n(P,"LI",{});var dwe=s(D2);Mle=n(dwe,"STRONG",{});var Zot=s(Mle);FSo=r(Zot,"qdqbert"),Zot.forEach(t),CSo=r(dwe," \u2014 "),gN=n(dwe,"A",{href:!0});var ert=s(gN);MSo=r(ert,"QDQBertForQuestionAnswering"),ert.forEach(t),ESo=r(dwe," (QDQBert model)"),dwe.forEach(t),ySo=i(P),N2=n(P,"LI",{});var cwe=s(N2);Ele=n(cwe,"STRONG",{});var ort=s(Ele);wSo=r(ort,"reformer"),ort.forEach(t),ASo=r(cwe," \u2014 "),hN=n(cwe,"A",{href:!0});var rrt=s(hN);LSo=r(rrt,"ReformerForQuestionAnswering"),rrt.forEach(t),BSo=r(cwe," (Reformer model)"),cwe.forEach(t),xSo=i(P),q2=n(P,"LI",{});var fwe=s(q2);yle=n(fwe,"STRONG",{});var trt=s(yle);kSo=r(trt,"rembert"),trt.forEach(t),RSo=r(fwe," \u2014 "),pN=n(fwe,"A",{href:!0});var art=s(pN);SSo=r(art,"RemBertForQuestionAnswering"),art.forEach(t),PSo=r(fwe," (RemBERT model)"),fwe.forEach(t),$So=i(P),O2=n(P,"LI",{});var mwe=s(O2);wle=n(mwe,"STRONG",{});var nrt=s(wle);ISo=r(nrt,"roberta"),nrt.forEach(t),jSo=r(mwe," \u2014 "),_N=n(mwe,"A",{href:!0});var srt=s(_N);DSo=r(srt,"RobertaForQuestionAnswering"),srt.forEach(t),NSo=r(mwe," (RoBERTa model)"),mwe.forEach(t),qSo=i(P),G2=n(P,"LI",{});var gwe=s(G2);Ale=n(gwe,"STRONG",{});var lrt=s(Ale);OSo=r(lrt,"roformer"),lrt.forEach(t),GSo=r(gwe," \u2014 "),uN=n(gwe,"A",{href:!0});var irt=s(uN);XSo=r(irt,"RoFormerForQuestionAnswering"),irt.forEach(t),VSo=r(gwe," (RoFormer model)"),gwe.forEach(t),zSo=i(P),X2=n(P,"LI",{});var hwe=s(X2);Lle=n(hwe,"STRONG",{});var drt=s(Lle);WSo=r(drt,"splinter"),drt.forEach(t),QSo=r(hwe," \u2014 "),bN=n(hwe,"A",{href:!0});var crt=s(bN);HSo=r(crt,"SplinterForQuestionAnswering"),crt.forEach(t),USo=r(hwe," (Splinter model)"),hwe.forEach(t),JSo=i(P),V2=n(P,"LI",{});var pwe=s(V2);Ble=n(pwe,"STRONG",{});var frt=s(Ble);YSo=r(frt,"squeezebert"),frt.forEach(t),KSo=r(pwe," \u2014 "),vN=n(pwe,"A",{href:!0});var mrt=s(vN);ZSo=r(mrt,"SqueezeBertForQuestionAnswering"),mrt.forEach(t),ePo=r(pwe," (SqueezeBERT model)"),pwe.forEach(t),oPo=i(P),z2=n(P,"LI",{});var _we=s(z2);xle=n(_we,"STRONG",{});var grt=s(xle);rPo=r(grt,"xlm"),grt.forEach(t),tPo=r(_we," \u2014 "),TN=n(_we,"A",{href:!0});var hrt=s(TN);aPo=r(hrt,"XLMForQuestionAnsweringSimple"),hrt.forEach(t),nPo=r(_we," (XLM model)"),_we.forEach(t),sPo=i(P),W2=n(P,"LI",{});var uwe=s(W2);kle=n(uwe,"STRONG",{});var prt=s(kle);lPo=r(prt,"xlm-roberta"),prt.forEach(t),iPo=r(uwe," \u2014 "),FN=n(uwe,"A",{href:!0});var _rt=s(FN);dPo=r(_rt,"XLMRobertaForQuestionAnswering"),_rt.forEach(t),cPo=r(uwe," (XLM-RoBERTa model)"),uwe.forEach(t),fPo=i(P),Q2=n(P,"LI",{});var bwe=s(Q2);Rle=n(bwe,"STRONG",{});var urt=s(Rle);mPo=r(urt,"xlm-roberta-xl"),urt.forEach(t),gPo=r(bwe," \u2014 "),CN=n(bwe,"A",{href:!0});var brt=s(CN);hPo=r(brt,"XLMRobertaXLForQuestionAnswering"),brt.forEach(t),pPo=r(bwe," (XLM-RoBERTa-XL model)"),bwe.forEach(t),_Po=i(P),H2=n(P,"LI",{});var vwe=s(H2);Sle=n(vwe,"STRONG",{});var vrt=s(Sle);uPo=r(vrt,"xlnet"),vrt.forEach(t),bPo=r(vwe," \u2014 "),MN=n(vwe,"A",{href:!0});var Trt=s(MN);vPo=r(Trt,"XLNetForQuestionAnsweringSimple"),Trt.forEach(t),TPo=r(vwe," (XLNet model)"),vwe.forEach(t),FPo=i(P),U2=n(P,"LI",{});var Twe=s(U2);Ple=n(Twe,"STRONG",{});var Frt=s(Ple);CPo=r(Frt,"yoso"),Frt.forEach(t),MPo=r(Twe," \u2014 "),EN=n(Twe,"A",{href:!0});var Crt=s(EN);EPo=r(Crt,"YosoForQuestionAnswering"),Crt.forEach(t),yPo=r(Twe," (YOSO model)"),Twe.forEach(t),P.forEach(t),wPo=i(Kt),J2=n(Kt,"P",{});var Fwe=s(J2);APo=r(Fwe,"The model is set in evaluation mode by default using "),$le=n(Fwe,"CODE",{});var Mrt=s($le);LPo=r(Mrt,"model.eval()"),Mrt.forEach(t),BPo=r(Fwe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ile=n(Fwe,"CODE",{});var Ert=s(Ile);xPo=r(Ert,"model.train()"),Ert.forEach(t),Fwe.forEach(t),kPo=i(Kt),jle=n(Kt,"P",{});var yrt=s(jle);RPo=r(yrt,"Examples:"),yrt.forEach(t),SPo=i(Kt),m(o3.$$.fragment,Kt),Kt.forEach(t),_l.forEach(t),yke=i(d),Pd=n(d,"H2",{class:!0});var ISe=s(Pd);Y2=n(ISe,"A",{id:!0,class:!0,href:!0});var wrt=s(Y2);Dle=n(wrt,"SPAN",{});var Art=s(Dle);m(r3.$$.fragment,Art),Art.forEach(t),wrt.forEach(t),PPo=i(ISe),Nle=n(ISe,"SPAN",{});var Lrt=s(Nle);$Po=r(Lrt,"AutoModelForTableQuestionAnswering"),Lrt.forEach(t),ISe.forEach(t),wke=i(d),lr=n(d,"DIV",{class:!0});var bl=s(lr);m(t3.$$.fragment,bl),IPo=i(bl),$d=n(bl,"P",{});var mW=s($d);jPo=r(mW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),qle=n(mW,"CODE",{});var Brt=s(qle);DPo=r(Brt,"from_pretrained()"),Brt.forEach(t),NPo=r(mW,"class method or the "),Ole=n(mW,"CODE",{});var xrt=s(Ole);qPo=r(xrt,"from_config()"),xrt.forEach(t),OPo=r(mW,`class
method.`),mW.forEach(t),GPo=i(bl),a3=n(bl,"P",{});var jSe=s(a3);XPo=r(jSe,"This class cannot be instantiated directly using "),Gle=n(jSe,"CODE",{});var krt=s(Gle);VPo=r(krt,"__init__()"),krt.forEach(t),zPo=r(jSe," (throws an error)."),jSe.forEach(t),WPo=i(bl),rt=n(bl,"DIV",{class:!0});var vl=s(rt);m(n3.$$.fragment,vl),QPo=i(vl),Xle=n(vl,"P",{});var Rrt=s(Xle);HPo=r(Rrt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Rrt.forEach(t),UPo=i(vl),Id=n(vl,"P",{});var gW=s(Id);JPo=r(gW,`Note:
Loading a model from its configuration file does `),Vle=n(gW,"STRONG",{});var Srt=s(Vle);YPo=r(Srt,"not"),Srt.forEach(t),KPo=r(gW,` load the model weights. It only affects the
model\u2019s configuration. Use `),zle=n(gW,"CODE",{});var Prt=s(zle);ZPo=r(Prt,"from_pretrained()"),Prt.forEach(t),e$o=r(gW,"to load the model weights."),gW.forEach(t),o$o=i(vl),Wle=n(vl,"P",{});var $rt=s(Wle);r$o=r($rt,"Examples:"),$rt.forEach(t),t$o=i(vl),m(s3.$$.fragment,vl),vl.forEach(t),a$o=i(bl),Qe=n(bl,"DIV",{class:!0});var Zt=s(Qe);m(l3.$$.fragment,Zt),n$o=i(Zt),Qle=n(Zt,"P",{});var Irt=s(Qle);s$o=r(Irt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Irt.forEach(t),l$o=i(Zt),an=n(Zt,"P",{});var vM=s(an);i$o=r(vM,"The model class to instantiate is selected based on the "),Hle=n(vM,"CODE",{});var jrt=s(Hle);d$o=r(jrt,"model_type"),jrt.forEach(t),c$o=r(vM,` property of the config object (either
passed as an argument or loaded from `),Ule=n(vM,"CODE",{});var Drt=s(Ule);f$o=r(Drt,"pretrained_model_name_or_path"),Drt.forEach(t),m$o=r(vM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jle=n(vM,"CODE",{});var Nrt=s(Jle);g$o=r(Nrt,"pretrained_model_name_or_path"),Nrt.forEach(t),h$o=r(vM,":"),vM.forEach(t),p$o=i(Zt),Yle=n(Zt,"UL",{});var qrt=s(Yle);K2=n(qrt,"LI",{});var Cwe=s(K2);Kle=n(Cwe,"STRONG",{});var Ort=s(Kle);_$o=r(Ort,"tapas"),Ort.forEach(t),u$o=r(Cwe," \u2014 "),yN=n(Cwe,"A",{href:!0});var Grt=s(yN);b$o=r(Grt,"TapasForQuestionAnswering"),Grt.forEach(t),v$o=r(Cwe," (TAPAS model)"),Cwe.forEach(t),qrt.forEach(t),T$o=i(Zt),Z2=n(Zt,"P",{});var Mwe=s(Z2);F$o=r(Mwe,"The model is set in evaluation mode by default using "),Zle=n(Mwe,"CODE",{});var Xrt=s(Zle);C$o=r(Xrt,"model.eval()"),Xrt.forEach(t),M$o=r(Mwe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eie=n(Mwe,"CODE",{});var Vrt=s(eie);E$o=r(Vrt,"model.train()"),Vrt.forEach(t),Mwe.forEach(t),y$o=i(Zt),oie=n(Zt,"P",{});var zrt=s(oie);w$o=r(zrt,"Examples:"),zrt.forEach(t),A$o=i(Zt),m(i3.$$.fragment,Zt),Zt.forEach(t),bl.forEach(t),Ake=i(d),jd=n(d,"H2",{class:!0});var DSe=s(jd);ev=n(DSe,"A",{id:!0,class:!0,href:!0});var Wrt=s(ev);rie=n(Wrt,"SPAN",{});var Qrt=s(rie);m(d3.$$.fragment,Qrt),Qrt.forEach(t),Wrt.forEach(t),L$o=i(DSe),tie=n(DSe,"SPAN",{});var Hrt=s(tie);B$o=r(Hrt,"AutoModelForImageClassification"),Hrt.forEach(t),DSe.forEach(t),Lke=i(d),ir=n(d,"DIV",{class:!0});var Tl=s(ir);m(c3.$$.fragment,Tl),x$o=i(Tl),Dd=n(Tl,"P",{});var hW=s(Dd);k$o=r(hW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),aie=n(hW,"CODE",{});var Urt=s(aie);R$o=r(Urt,"from_pretrained()"),Urt.forEach(t),S$o=r(hW,"class method or the "),nie=n(hW,"CODE",{});var Jrt=s(nie);P$o=r(Jrt,"from_config()"),Jrt.forEach(t),$$o=r(hW,`class
method.`),hW.forEach(t),I$o=i(Tl),f3=n(Tl,"P",{});var NSe=s(f3);j$o=r(NSe,"This class cannot be instantiated directly using "),sie=n(NSe,"CODE",{});var Yrt=s(sie);D$o=r(Yrt,"__init__()"),Yrt.forEach(t),N$o=r(NSe," (throws an error)."),NSe.forEach(t),q$o=i(Tl),tt=n(Tl,"DIV",{class:!0});var Fl=s(tt);m(m3.$$.fragment,Fl),O$o=i(Fl),lie=n(Fl,"P",{});var Krt=s(lie);G$o=r(Krt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Krt.forEach(t),X$o=i(Fl),Nd=n(Fl,"P",{});var pW=s(Nd);V$o=r(pW,`Note:
Loading a model from its configuration file does `),iie=n(pW,"STRONG",{});var Zrt=s(iie);z$o=r(Zrt,"not"),Zrt.forEach(t),W$o=r(pW,` load the model weights. It only affects the
model\u2019s configuration. Use `),die=n(pW,"CODE",{});var ett=s(die);Q$o=r(ett,"from_pretrained()"),ett.forEach(t),H$o=r(pW,"to load the model weights."),pW.forEach(t),U$o=i(Fl),cie=n(Fl,"P",{});var ott=s(cie);J$o=r(ott,"Examples:"),ott.forEach(t),Y$o=i(Fl),m(g3.$$.fragment,Fl),Fl.forEach(t),K$o=i(Tl),He=n(Tl,"DIV",{class:!0});var ea=s(He);m(h3.$$.fragment,ea),Z$o=i(ea),fie=n(ea,"P",{});var rtt=s(fie);eIo=r(rtt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),rtt.forEach(t),oIo=i(ea),nn=n(ea,"P",{});var TM=s(nn);rIo=r(TM,"The model class to instantiate is selected based on the "),mie=n(TM,"CODE",{});var ttt=s(mie);tIo=r(ttt,"model_type"),ttt.forEach(t),aIo=r(TM,` property of the config object (either
passed as an argument or loaded from `),gie=n(TM,"CODE",{});var att=s(gie);nIo=r(att,"pretrained_model_name_or_path"),att.forEach(t),sIo=r(TM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hie=n(TM,"CODE",{});var ntt=s(hie);lIo=r(ntt,"pretrained_model_name_or_path"),ntt.forEach(t),iIo=r(TM,":"),TM.forEach(t),dIo=i(ea),Ce=n(ea,"UL",{});var so=s(Ce);ov=n(so,"LI",{});var Ewe=s(ov);pie=n(Ewe,"STRONG",{});var stt=s(pie);cIo=r(stt,"beit"),stt.forEach(t),fIo=r(Ewe," \u2014 "),wN=n(Ewe,"A",{href:!0});var ltt=s(wN);mIo=r(ltt,"BeitForImageClassification"),ltt.forEach(t),gIo=r(Ewe," (BEiT model)"),Ewe.forEach(t),hIo=i(so),rv=n(so,"LI",{});var ywe=s(rv);_ie=n(ywe,"STRONG",{});var itt=s(_ie);pIo=r(itt,"convnext"),itt.forEach(t),_Io=r(ywe," \u2014 "),AN=n(ywe,"A",{href:!0});var dtt=s(AN);uIo=r(dtt,"ConvNextForImageClassification"),dtt.forEach(t),bIo=r(ywe," (ConvNext model)"),ywe.forEach(t),vIo=i(so),zs=n(so,"LI",{});var a9=s(zs);uie=n(a9,"STRONG",{});var ctt=s(uie);TIo=r(ctt,"deit"),ctt.forEach(t),FIo=r(a9," \u2014 "),LN=n(a9,"A",{href:!0});var ftt=s(LN);CIo=r(ftt,"DeiTForImageClassification"),ftt.forEach(t),MIo=r(a9," or "),BN=n(a9,"A",{href:!0});var mtt=s(BN);EIo=r(mtt,"DeiTForImageClassificationWithTeacher"),mtt.forEach(t),yIo=r(a9," (DeiT model)"),a9.forEach(t),wIo=i(so),tv=n(so,"LI",{});var wwe=s(tv);bie=n(wwe,"STRONG",{});var gtt=s(bie);AIo=r(gtt,"imagegpt"),gtt.forEach(t),LIo=r(wwe," \u2014 "),xN=n(wwe,"A",{href:!0});var htt=s(xN);BIo=r(htt,"ImageGPTForImageClassification"),htt.forEach(t),xIo=r(wwe," (ImageGPT model)"),wwe.forEach(t),kIo=i(so),pa=n(so,"LI",{});var zf=s(pa);vie=n(zf,"STRONG",{});var ptt=s(vie);RIo=r(ptt,"perceiver"),ptt.forEach(t),SIo=r(zf," \u2014 "),kN=n(zf,"A",{href:!0});var _tt=s(kN);PIo=r(_tt,"PerceiverForImageClassificationLearned"),_tt.forEach(t),$Io=r(zf," or "),RN=n(zf,"A",{href:!0});var utt=s(RN);IIo=r(utt,"PerceiverForImageClassificationFourier"),utt.forEach(t),jIo=r(zf," or "),SN=n(zf,"A",{href:!0});var btt=s(SN);DIo=r(btt,"PerceiverForImageClassificationConvProcessing"),btt.forEach(t),NIo=r(zf," (Perceiver model)"),zf.forEach(t),qIo=i(so),av=n(so,"LI",{});var Awe=s(av);Tie=n(Awe,"STRONG",{});var vtt=s(Tie);OIo=r(vtt,"poolformer"),vtt.forEach(t),GIo=r(Awe," \u2014 "),PN=n(Awe,"A",{href:!0});var Ttt=s(PN);XIo=r(Ttt,"PoolFormerForImageClassification"),Ttt.forEach(t),VIo=r(Awe," (PoolFormer model)"),Awe.forEach(t),zIo=i(so),nv=n(so,"LI",{});var Lwe=s(nv);Fie=n(Lwe,"STRONG",{});var Ftt=s(Fie);WIo=r(Ftt,"segformer"),Ftt.forEach(t),QIo=r(Lwe," \u2014 "),$N=n(Lwe,"A",{href:!0});var Ctt=s($N);HIo=r(Ctt,"SegformerForImageClassification"),Ctt.forEach(t),UIo=r(Lwe," (SegFormer model)"),Lwe.forEach(t),JIo=i(so),sv=n(so,"LI",{});var Bwe=s(sv);Cie=n(Bwe,"STRONG",{});var Mtt=s(Cie);YIo=r(Mtt,"swin"),Mtt.forEach(t),KIo=r(Bwe," \u2014 "),IN=n(Bwe,"A",{href:!0});var Ett=s(IN);ZIo=r(Ett,"SwinForImageClassification"),Ett.forEach(t),ejo=r(Bwe," (Swin model)"),Bwe.forEach(t),ojo=i(so),lv=n(so,"LI",{});var xwe=s(lv);Mie=n(xwe,"STRONG",{});var ytt=s(Mie);rjo=r(ytt,"vit"),ytt.forEach(t),tjo=r(xwe," \u2014 "),jN=n(xwe,"A",{href:!0});var wtt=s(jN);ajo=r(wtt,"ViTForImageClassification"),wtt.forEach(t),njo=r(xwe," (ViT model)"),xwe.forEach(t),so.forEach(t),sjo=i(ea),iv=n(ea,"P",{});var kwe=s(iv);ljo=r(kwe,"The model is set in evaluation mode by default using "),Eie=n(kwe,"CODE",{});var Att=s(Eie);ijo=r(Att,"model.eval()"),Att.forEach(t),djo=r(kwe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yie=n(kwe,"CODE",{});var Ltt=s(yie);cjo=r(Ltt,"model.train()"),Ltt.forEach(t),kwe.forEach(t),fjo=i(ea),wie=n(ea,"P",{});var Btt=s(wie);mjo=r(Btt,"Examples:"),Btt.forEach(t),gjo=i(ea),m(p3.$$.fragment,ea),ea.forEach(t),Tl.forEach(t),Bke=i(d),qd=n(d,"H2",{class:!0});var qSe=s(qd);dv=n(qSe,"A",{id:!0,class:!0,href:!0});var xtt=s(dv);Aie=n(xtt,"SPAN",{});var ktt=s(Aie);m(_3.$$.fragment,ktt),ktt.forEach(t),xtt.forEach(t),hjo=i(qSe),Lie=n(qSe,"SPAN",{});var Rtt=s(Lie);pjo=r(Rtt,"AutoModelForVision2Seq"),Rtt.forEach(t),qSe.forEach(t),xke=i(d),dr=n(d,"DIV",{class:!0});var Cl=s(dr);m(u3.$$.fragment,Cl),_jo=i(Cl),Od=n(Cl,"P",{});var _W=s(Od);ujo=r(_W,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Bie=n(_W,"CODE",{});var Stt=s(Bie);bjo=r(Stt,"from_pretrained()"),Stt.forEach(t),vjo=r(_W,"class method or the "),xie=n(_W,"CODE",{});var Ptt=s(xie);Tjo=r(Ptt,"from_config()"),Ptt.forEach(t),Fjo=r(_W,`class
method.`),_W.forEach(t),Cjo=i(Cl),b3=n(Cl,"P",{});var OSe=s(b3);Mjo=r(OSe,"This class cannot be instantiated directly using "),kie=n(OSe,"CODE",{});var $tt=s(kie);Ejo=r($tt,"__init__()"),$tt.forEach(t),yjo=r(OSe," (throws an error)."),OSe.forEach(t),wjo=i(Cl),at=n(Cl,"DIV",{class:!0});var Ml=s(at);m(v3.$$.fragment,Ml),Ajo=i(Ml),Rie=n(Ml,"P",{});var Itt=s(Rie);Ljo=r(Itt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Itt.forEach(t),Bjo=i(Ml),Gd=n(Ml,"P",{});var uW=s(Gd);xjo=r(uW,`Note:
Loading a model from its configuration file does `),Sie=n(uW,"STRONG",{});var jtt=s(Sie);kjo=r(jtt,"not"),jtt.forEach(t),Rjo=r(uW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Pie=n(uW,"CODE",{});var Dtt=s(Pie);Sjo=r(Dtt,"from_pretrained()"),Dtt.forEach(t),Pjo=r(uW,"to load the model weights."),uW.forEach(t),$jo=i(Ml),$ie=n(Ml,"P",{});var Ntt=s($ie);Ijo=r(Ntt,"Examples:"),Ntt.forEach(t),jjo=i(Ml),m(T3.$$.fragment,Ml),Ml.forEach(t),Djo=i(Cl),Ue=n(Cl,"DIV",{class:!0});var oa=s(Ue);m(F3.$$.fragment,oa),Njo=i(oa),Iie=n(oa,"P",{});var qtt=s(Iie);qjo=r(qtt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),qtt.forEach(t),Ojo=i(oa),sn=n(oa,"P",{});var FM=s(sn);Gjo=r(FM,"The model class to instantiate is selected based on the "),jie=n(FM,"CODE",{});var Ott=s(jie);Xjo=r(Ott,"model_type"),Ott.forEach(t),Vjo=r(FM,` property of the config object (either
passed as an argument or loaded from `),Die=n(FM,"CODE",{});var Gtt=s(Die);zjo=r(Gtt,"pretrained_model_name_or_path"),Gtt.forEach(t),Wjo=r(FM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nie=n(FM,"CODE",{});var Xtt=s(Nie);Qjo=r(Xtt,"pretrained_model_name_or_path"),Xtt.forEach(t),Hjo=r(FM,":"),FM.forEach(t),Ujo=i(oa),qie=n(oa,"UL",{});var Vtt=s(qie);cv=n(Vtt,"LI",{});var Rwe=s(cv);Oie=n(Rwe,"STRONG",{});var ztt=s(Oie);Jjo=r(ztt,"vision-encoder-decoder"),ztt.forEach(t),Yjo=r(Rwe," \u2014 "),DN=n(Rwe,"A",{href:!0});var Wtt=s(DN);Kjo=r(Wtt,"VisionEncoderDecoderModel"),Wtt.forEach(t),Zjo=r(Rwe," (Vision Encoder decoder model)"),Rwe.forEach(t),Vtt.forEach(t),eDo=i(oa),fv=n(oa,"P",{});var Swe=s(fv);oDo=r(Swe,"The model is set in evaluation mode by default using "),Gie=n(Swe,"CODE",{});var Qtt=s(Gie);rDo=r(Qtt,"model.eval()"),Qtt.forEach(t),tDo=r(Swe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Xie=n(Swe,"CODE",{});var Htt=s(Xie);aDo=r(Htt,"model.train()"),Htt.forEach(t),Swe.forEach(t),nDo=i(oa),Vie=n(oa,"P",{});var Utt=s(Vie);sDo=r(Utt,"Examples:"),Utt.forEach(t),lDo=i(oa),m(C3.$$.fragment,oa),oa.forEach(t),Cl.forEach(t),kke=i(d),Xd=n(d,"H2",{class:!0});var GSe=s(Xd);mv=n(GSe,"A",{id:!0,class:!0,href:!0});var Jtt=s(mv);zie=n(Jtt,"SPAN",{});var Ytt=s(zie);m(M3.$$.fragment,Ytt),Ytt.forEach(t),Jtt.forEach(t),iDo=i(GSe),Wie=n(GSe,"SPAN",{});var Ktt=s(Wie);dDo=r(Ktt,"AutoModelForAudioClassification"),Ktt.forEach(t),GSe.forEach(t),Rke=i(d),cr=n(d,"DIV",{class:!0});var El=s(cr);m(E3.$$.fragment,El),cDo=i(El),Vd=n(El,"P",{});var bW=s(Vd);fDo=r(bW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Qie=n(bW,"CODE",{});var Ztt=s(Qie);mDo=r(Ztt,"from_pretrained()"),Ztt.forEach(t),gDo=r(bW,"class method or the "),Hie=n(bW,"CODE",{});var eat=s(Hie);hDo=r(eat,"from_config()"),eat.forEach(t),pDo=r(bW,`class
method.`),bW.forEach(t),_Do=i(El),y3=n(El,"P",{});var XSe=s(y3);uDo=r(XSe,"This class cannot be instantiated directly using "),Uie=n(XSe,"CODE",{});var oat=s(Uie);bDo=r(oat,"__init__()"),oat.forEach(t),vDo=r(XSe," (throws an error)."),XSe.forEach(t),TDo=i(El),nt=n(El,"DIV",{class:!0});var yl=s(nt);m(w3.$$.fragment,yl),FDo=i(yl),Jie=n(yl,"P",{});var rat=s(Jie);CDo=r(rat,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),rat.forEach(t),MDo=i(yl),zd=n(yl,"P",{});var vW=s(zd);EDo=r(vW,`Note:
Loading a model from its configuration file does `),Yie=n(vW,"STRONG",{});var tat=s(Yie);yDo=r(tat,"not"),tat.forEach(t),wDo=r(vW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kie=n(vW,"CODE",{});var aat=s(Kie);ADo=r(aat,"from_pretrained()"),aat.forEach(t),LDo=r(vW,"to load the model weights."),vW.forEach(t),BDo=i(yl),Zie=n(yl,"P",{});var nat=s(Zie);xDo=r(nat,"Examples:"),nat.forEach(t),kDo=i(yl),m(A3.$$.fragment,yl),yl.forEach(t),RDo=i(El),Je=n(El,"DIV",{class:!0});var ra=s(Je);m(L3.$$.fragment,ra),SDo=i(ra),ede=n(ra,"P",{});var sat=s(ede);PDo=r(sat,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),sat.forEach(t),$Do=i(ra),ln=n(ra,"P",{});var CM=s(ln);IDo=r(CM,"The model class to instantiate is selected based on the "),ode=n(CM,"CODE",{});var lat=s(ode);jDo=r(lat,"model_type"),lat.forEach(t),DDo=r(CM,` property of the config object (either
passed as an argument or loaded from `),rde=n(CM,"CODE",{});var iat=s(rde);NDo=r(iat,"pretrained_model_name_or_path"),iat.forEach(t),qDo=r(CM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tde=n(CM,"CODE",{});var dat=s(tde);ODo=r(dat,"pretrained_model_name_or_path"),dat.forEach(t),GDo=r(CM,":"),CM.forEach(t),XDo=i(ra),xe=n(ra,"UL",{});var Oo=s(xe);gv=n(Oo,"LI",{});var Pwe=s(gv);ade=n(Pwe,"STRONG",{});var cat=s(ade);VDo=r(cat,"data2vec-audio"),cat.forEach(t),zDo=r(Pwe," \u2014 "),NN=n(Pwe,"A",{href:!0});var fat=s(NN);WDo=r(fat,"Data2VecAudioForSequenceClassification"),fat.forEach(t),QDo=r(Pwe," (Data2VecAudio model)"),Pwe.forEach(t),HDo=i(Oo),hv=n(Oo,"LI",{});var $we=s(hv);nde=n($we,"STRONG",{});var mat=s(nde);UDo=r(mat,"hubert"),mat.forEach(t),JDo=r($we," \u2014 "),qN=n($we,"A",{href:!0});var gat=s(qN);YDo=r(gat,"HubertForSequenceClassification"),gat.forEach(t),KDo=r($we," (Hubert model)"),$we.forEach(t),ZDo=i(Oo),pv=n(Oo,"LI",{});var Iwe=s(pv);sde=n(Iwe,"STRONG",{});var hat=s(sde);eNo=r(hat,"sew"),hat.forEach(t),oNo=r(Iwe," \u2014 "),ON=n(Iwe,"A",{href:!0});var pat=s(ON);rNo=r(pat,"SEWForSequenceClassification"),pat.forEach(t),tNo=r(Iwe," (SEW model)"),Iwe.forEach(t),aNo=i(Oo),_v=n(Oo,"LI",{});var jwe=s(_v);lde=n(jwe,"STRONG",{});var _at=s(lde);nNo=r(_at,"sew-d"),_at.forEach(t),sNo=r(jwe," \u2014 "),GN=n(jwe,"A",{href:!0});var uat=s(GN);lNo=r(uat,"SEWDForSequenceClassification"),uat.forEach(t),iNo=r(jwe," (SEW-D model)"),jwe.forEach(t),dNo=i(Oo),uv=n(Oo,"LI",{});var Dwe=s(uv);ide=n(Dwe,"STRONG",{});var bat=s(ide);cNo=r(bat,"unispeech"),bat.forEach(t),fNo=r(Dwe," \u2014 "),XN=n(Dwe,"A",{href:!0});var vat=s(XN);mNo=r(vat,"UniSpeechForSequenceClassification"),vat.forEach(t),gNo=r(Dwe," (UniSpeech model)"),Dwe.forEach(t),hNo=i(Oo),bv=n(Oo,"LI",{});var Nwe=s(bv);dde=n(Nwe,"STRONG",{});var Tat=s(dde);pNo=r(Tat,"unispeech-sat"),Tat.forEach(t),_No=r(Nwe," \u2014 "),VN=n(Nwe,"A",{href:!0});var Fat=s(VN);uNo=r(Fat,"UniSpeechSatForSequenceClassification"),Fat.forEach(t),bNo=r(Nwe," (UniSpeechSat model)"),Nwe.forEach(t),vNo=i(Oo),vv=n(Oo,"LI",{});var qwe=s(vv);cde=n(qwe,"STRONG",{});var Cat=s(cde);TNo=r(Cat,"wav2vec2"),Cat.forEach(t),FNo=r(qwe," \u2014 "),zN=n(qwe,"A",{href:!0});var Mat=s(zN);CNo=r(Mat,"Wav2Vec2ForSequenceClassification"),Mat.forEach(t),MNo=r(qwe," (Wav2Vec2 model)"),qwe.forEach(t),ENo=i(Oo),Tv=n(Oo,"LI",{});var Owe=s(Tv);fde=n(Owe,"STRONG",{});var Eat=s(fde);yNo=r(Eat,"wavlm"),Eat.forEach(t),wNo=r(Owe," \u2014 "),WN=n(Owe,"A",{href:!0});var yat=s(WN);ANo=r(yat,"WavLMForSequenceClassification"),yat.forEach(t),LNo=r(Owe," (WavLM model)"),Owe.forEach(t),Oo.forEach(t),BNo=i(ra),Fv=n(ra,"P",{});var Gwe=s(Fv);xNo=r(Gwe,"The model is set in evaluation mode by default using "),mde=n(Gwe,"CODE",{});var wat=s(mde);kNo=r(wat,"model.eval()"),wat.forEach(t),RNo=r(Gwe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gde=n(Gwe,"CODE",{});var Aat=s(gde);SNo=r(Aat,"model.train()"),Aat.forEach(t),Gwe.forEach(t),PNo=i(ra),hde=n(ra,"P",{});var Lat=s(hde);$No=r(Lat,"Examples:"),Lat.forEach(t),INo=i(ra),m(B3.$$.fragment,ra),ra.forEach(t),El.forEach(t),Ske=i(d),Wd=n(d,"H2",{class:!0});var VSe=s(Wd);Cv=n(VSe,"A",{id:!0,class:!0,href:!0});var Bat=s(Cv);pde=n(Bat,"SPAN",{});var xat=s(pde);m(x3.$$.fragment,xat),xat.forEach(t),Bat.forEach(t),jNo=i(VSe),_de=n(VSe,"SPAN",{});var kat=s(_de);DNo=r(kat,"AutoModelForAudioFrameClassification"),kat.forEach(t),VSe.forEach(t),Pke=i(d),fr=n(d,"DIV",{class:!0});var wl=s(fr);m(k3.$$.fragment,wl),NNo=i(wl),Qd=n(wl,"P",{});var TW=s(Qd);qNo=r(TW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),ude=n(TW,"CODE",{});var Rat=s(ude);ONo=r(Rat,"from_pretrained()"),Rat.forEach(t),GNo=r(TW,"class method or the "),bde=n(TW,"CODE",{});var Sat=s(bde);XNo=r(Sat,"from_config()"),Sat.forEach(t),VNo=r(TW,`class
method.`),TW.forEach(t),zNo=i(wl),R3=n(wl,"P",{});var zSe=s(R3);WNo=r(zSe,"This class cannot be instantiated directly using "),vde=n(zSe,"CODE",{});var Pat=s(vde);QNo=r(Pat,"__init__()"),Pat.forEach(t),HNo=r(zSe," (throws an error)."),zSe.forEach(t),UNo=i(wl),st=n(wl,"DIV",{class:!0});var Al=s(st);m(S3.$$.fragment,Al),JNo=i(Al),Tde=n(Al,"P",{});var $at=s(Tde);YNo=r($at,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),$at.forEach(t),KNo=i(Al),Hd=n(Al,"P",{});var FW=s(Hd);ZNo=r(FW,`Note:
Loading a model from its configuration file does `),Fde=n(FW,"STRONG",{});var Iat=s(Fde);eqo=r(Iat,"not"),Iat.forEach(t),oqo=r(FW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cde=n(FW,"CODE",{});var jat=s(Cde);rqo=r(jat,"from_pretrained()"),jat.forEach(t),tqo=r(FW,"to load the model weights."),FW.forEach(t),aqo=i(Al),Mde=n(Al,"P",{});var Dat=s(Mde);nqo=r(Dat,"Examples:"),Dat.forEach(t),sqo=i(Al),m(P3.$$.fragment,Al),Al.forEach(t),lqo=i(wl),Ye=n(wl,"DIV",{class:!0});var ta=s(Ye);m($3.$$.fragment,ta),iqo=i(ta),Ede=n(ta,"P",{});var Nat=s(Ede);dqo=r(Nat,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Nat.forEach(t),cqo=i(ta),dn=n(ta,"P",{});var MM=s(dn);fqo=r(MM,"The model class to instantiate is selected based on the "),yde=n(MM,"CODE",{});var qat=s(yde);mqo=r(qat,"model_type"),qat.forEach(t),gqo=r(MM,` property of the config object (either
passed as an argument or loaded from `),wde=n(MM,"CODE",{});var Oat=s(wde);hqo=r(Oat,"pretrained_model_name_or_path"),Oat.forEach(t),pqo=r(MM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ade=n(MM,"CODE",{});var Gat=s(Ade);_qo=r(Gat,"pretrained_model_name_or_path"),Gat.forEach(t),uqo=r(MM,":"),MM.forEach(t),bqo=i(ta),cn=n(ta,"UL",{});var EM=s(cn);Mv=n(EM,"LI",{});var Xwe=s(Mv);Lde=n(Xwe,"STRONG",{});var Xat=s(Lde);vqo=r(Xat,"data2vec-audio"),Xat.forEach(t),Tqo=r(Xwe," \u2014 "),QN=n(Xwe,"A",{href:!0});var Vat=s(QN);Fqo=r(Vat,"Data2VecAudioForAudioFrameClassification"),Vat.forEach(t),Cqo=r(Xwe," (Data2VecAudio model)"),Xwe.forEach(t),Mqo=i(EM),Ev=n(EM,"LI",{});var Vwe=s(Ev);Bde=n(Vwe,"STRONG",{});var zat=s(Bde);Eqo=r(zat,"unispeech-sat"),zat.forEach(t),yqo=r(Vwe," \u2014 "),HN=n(Vwe,"A",{href:!0});var Wat=s(HN);wqo=r(Wat,"UniSpeechSatForAudioFrameClassification"),Wat.forEach(t),Aqo=r(Vwe," (UniSpeechSat model)"),Vwe.forEach(t),Lqo=i(EM),yv=n(EM,"LI",{});var zwe=s(yv);xde=n(zwe,"STRONG",{});var Qat=s(xde);Bqo=r(Qat,"wav2vec2"),Qat.forEach(t),xqo=r(zwe," \u2014 "),UN=n(zwe,"A",{href:!0});var Hat=s(UN);kqo=r(Hat,"Wav2Vec2ForAudioFrameClassification"),Hat.forEach(t),Rqo=r(zwe," (Wav2Vec2 model)"),zwe.forEach(t),Sqo=i(EM),wv=n(EM,"LI",{});var Wwe=s(wv);kde=n(Wwe,"STRONG",{});var Uat=s(kde);Pqo=r(Uat,"wavlm"),Uat.forEach(t),$qo=r(Wwe," \u2014 "),JN=n(Wwe,"A",{href:!0});var Jat=s(JN);Iqo=r(Jat,"WavLMForAudioFrameClassification"),Jat.forEach(t),jqo=r(Wwe," (WavLM model)"),Wwe.forEach(t),EM.forEach(t),Dqo=i(ta),Av=n(ta,"P",{});var Qwe=s(Av);Nqo=r(Qwe,"The model is set in evaluation mode by default using "),Rde=n(Qwe,"CODE",{});var Yat=s(Rde);qqo=r(Yat,"model.eval()"),Yat.forEach(t),Oqo=r(Qwe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sde=n(Qwe,"CODE",{});var Kat=s(Sde);Gqo=r(Kat,"model.train()"),Kat.forEach(t),Qwe.forEach(t),Xqo=i(ta),Pde=n(ta,"P",{});var Zat=s(Pde);Vqo=r(Zat,"Examples:"),Zat.forEach(t),zqo=i(ta),m(I3.$$.fragment,ta),ta.forEach(t),wl.forEach(t),$ke=i(d),Ud=n(d,"H2",{class:!0});var WSe=s(Ud);Lv=n(WSe,"A",{id:!0,class:!0,href:!0});var ent=s(Lv);$de=n(ent,"SPAN",{});var ont=s($de);m(j3.$$.fragment,ont),ont.forEach(t),ent.forEach(t),Wqo=i(WSe),Ide=n(WSe,"SPAN",{});var rnt=s(Ide);Qqo=r(rnt,"AutoModelForCTC"),rnt.forEach(t),WSe.forEach(t),Ike=i(d),mr=n(d,"DIV",{class:!0});var Ll=s(mr);m(D3.$$.fragment,Ll),Hqo=i(Ll),Jd=n(Ll,"P",{});var CW=s(Jd);Uqo=r(CW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),jde=n(CW,"CODE",{});var tnt=s(jde);Jqo=r(tnt,"from_pretrained()"),tnt.forEach(t),Yqo=r(CW,"class method or the "),Dde=n(CW,"CODE",{});var ant=s(Dde);Kqo=r(ant,"from_config()"),ant.forEach(t),Zqo=r(CW,`class
method.`),CW.forEach(t),eOo=i(Ll),N3=n(Ll,"P",{});var QSe=s(N3);oOo=r(QSe,"This class cannot be instantiated directly using "),Nde=n(QSe,"CODE",{});var nnt=s(Nde);rOo=r(nnt,"__init__()"),nnt.forEach(t),tOo=r(QSe," (throws an error)."),QSe.forEach(t),aOo=i(Ll),lt=n(Ll,"DIV",{class:!0});var Bl=s(lt);m(q3.$$.fragment,Bl),nOo=i(Bl),qde=n(Bl,"P",{});var snt=s(qde);sOo=r(snt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),snt.forEach(t),lOo=i(Bl),Yd=n(Bl,"P",{});var MW=s(Yd);iOo=r(MW,`Note:
Loading a model from its configuration file does `),Ode=n(MW,"STRONG",{});var lnt=s(Ode);dOo=r(lnt,"not"),lnt.forEach(t),cOo=r(MW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gde=n(MW,"CODE",{});var int=s(Gde);fOo=r(int,"from_pretrained()"),int.forEach(t),mOo=r(MW,"to load the model weights."),MW.forEach(t),gOo=i(Bl),Xde=n(Bl,"P",{});var dnt=s(Xde);hOo=r(dnt,"Examples:"),dnt.forEach(t),pOo=i(Bl),m(O3.$$.fragment,Bl),Bl.forEach(t),_Oo=i(Ll),Ke=n(Ll,"DIV",{class:!0});var aa=s(Ke);m(G3.$$.fragment,aa),uOo=i(aa),Vde=n(aa,"P",{});var cnt=s(Vde);bOo=r(cnt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),cnt.forEach(t),vOo=i(aa),fn=n(aa,"P",{});var yM=s(fn);TOo=r(yM,"The model class to instantiate is selected based on the "),zde=n(yM,"CODE",{});var fnt=s(zde);FOo=r(fnt,"model_type"),fnt.forEach(t),COo=r(yM,` property of the config object (either
passed as an argument or loaded from `),Wde=n(yM,"CODE",{});var mnt=s(Wde);MOo=r(mnt,"pretrained_model_name_or_path"),mnt.forEach(t),EOo=r(yM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qde=n(yM,"CODE",{});var gnt=s(Qde);yOo=r(gnt,"pretrained_model_name_or_path"),gnt.forEach(t),wOo=r(yM,":"),yM.forEach(t),AOo=i(aa),ke=n(aa,"UL",{});var Go=s(ke);Bv=n(Go,"LI",{});var Hwe=s(Bv);Hde=n(Hwe,"STRONG",{});var hnt=s(Hde);LOo=r(hnt,"data2vec-audio"),hnt.forEach(t),BOo=r(Hwe," \u2014 "),YN=n(Hwe,"A",{href:!0});var pnt=s(YN);xOo=r(pnt,"Data2VecAudioForCTC"),pnt.forEach(t),kOo=r(Hwe," (Data2VecAudio model)"),Hwe.forEach(t),ROo=i(Go),xv=n(Go,"LI",{});var Uwe=s(xv);Ude=n(Uwe,"STRONG",{});var _nt=s(Ude);SOo=r(_nt,"hubert"),_nt.forEach(t),POo=r(Uwe," \u2014 "),KN=n(Uwe,"A",{href:!0});var unt=s(KN);$Oo=r(unt,"HubertForCTC"),unt.forEach(t),IOo=r(Uwe," (Hubert model)"),Uwe.forEach(t),jOo=i(Go),kv=n(Go,"LI",{});var Jwe=s(kv);Jde=n(Jwe,"STRONG",{});var bnt=s(Jde);DOo=r(bnt,"sew"),bnt.forEach(t),NOo=r(Jwe," \u2014 "),ZN=n(Jwe,"A",{href:!0});var vnt=s(ZN);qOo=r(vnt,"SEWForCTC"),vnt.forEach(t),OOo=r(Jwe," (SEW model)"),Jwe.forEach(t),GOo=i(Go),Rv=n(Go,"LI",{});var Ywe=s(Rv);Yde=n(Ywe,"STRONG",{});var Tnt=s(Yde);XOo=r(Tnt,"sew-d"),Tnt.forEach(t),VOo=r(Ywe," \u2014 "),eq=n(Ywe,"A",{href:!0});var Fnt=s(eq);zOo=r(Fnt,"SEWDForCTC"),Fnt.forEach(t),WOo=r(Ywe," (SEW-D model)"),Ywe.forEach(t),QOo=i(Go),Sv=n(Go,"LI",{});var Kwe=s(Sv);Kde=n(Kwe,"STRONG",{});var Cnt=s(Kde);HOo=r(Cnt,"unispeech"),Cnt.forEach(t),UOo=r(Kwe," \u2014 "),oq=n(Kwe,"A",{href:!0});var Mnt=s(oq);JOo=r(Mnt,"UniSpeechForCTC"),Mnt.forEach(t),YOo=r(Kwe," (UniSpeech model)"),Kwe.forEach(t),KOo=i(Go),Pv=n(Go,"LI",{});var Zwe=s(Pv);Zde=n(Zwe,"STRONG",{});var Ent=s(Zde);ZOo=r(Ent,"unispeech-sat"),Ent.forEach(t),eGo=r(Zwe," \u2014 "),rq=n(Zwe,"A",{href:!0});var ynt=s(rq);oGo=r(ynt,"UniSpeechSatForCTC"),ynt.forEach(t),rGo=r(Zwe," (UniSpeechSat model)"),Zwe.forEach(t),tGo=i(Go),$v=n(Go,"LI",{});var eAe=s($v);ece=n(eAe,"STRONG",{});var wnt=s(ece);aGo=r(wnt,"wav2vec2"),wnt.forEach(t),nGo=r(eAe," \u2014 "),tq=n(eAe,"A",{href:!0});var Ant=s(tq);sGo=r(Ant,"Wav2Vec2ForCTC"),Ant.forEach(t),lGo=r(eAe," (Wav2Vec2 model)"),eAe.forEach(t),iGo=i(Go),Iv=n(Go,"LI",{});var oAe=s(Iv);oce=n(oAe,"STRONG",{});var Lnt=s(oce);dGo=r(Lnt,"wavlm"),Lnt.forEach(t),cGo=r(oAe," \u2014 "),aq=n(oAe,"A",{href:!0});var Bnt=s(aq);fGo=r(Bnt,"WavLMForCTC"),Bnt.forEach(t),mGo=r(oAe," (WavLM model)"),oAe.forEach(t),Go.forEach(t),gGo=i(aa),jv=n(aa,"P",{});var rAe=s(jv);hGo=r(rAe,"The model is set in evaluation mode by default using "),rce=n(rAe,"CODE",{});var xnt=s(rce);pGo=r(xnt,"model.eval()"),xnt.forEach(t),_Go=r(rAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tce=n(rAe,"CODE",{});var knt=s(tce);uGo=r(knt,"model.train()"),knt.forEach(t),rAe.forEach(t),bGo=i(aa),ace=n(aa,"P",{});var Rnt=s(ace);vGo=r(Rnt,"Examples:"),Rnt.forEach(t),TGo=i(aa),m(X3.$$.fragment,aa),aa.forEach(t),Ll.forEach(t),jke=i(d),Kd=n(d,"H2",{class:!0});var HSe=s(Kd);Dv=n(HSe,"A",{id:!0,class:!0,href:!0});var Snt=s(Dv);nce=n(Snt,"SPAN",{});var Pnt=s(nce);m(V3.$$.fragment,Pnt),Pnt.forEach(t),Snt.forEach(t),FGo=i(HSe),sce=n(HSe,"SPAN",{});var $nt=s(sce);CGo=r($nt,"AutoModelForSpeechSeq2Seq"),$nt.forEach(t),HSe.forEach(t),Dke=i(d),gr=n(d,"DIV",{class:!0});var xl=s(gr);m(z3.$$.fragment,xl),MGo=i(xl),Zd=n(xl,"P",{});var EW=s(Zd);EGo=r(EW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),lce=n(EW,"CODE",{});var Int=s(lce);yGo=r(Int,"from_pretrained()"),Int.forEach(t),wGo=r(EW,"class method or the "),ice=n(EW,"CODE",{});var jnt=s(ice);AGo=r(jnt,"from_config()"),jnt.forEach(t),LGo=r(EW,`class
method.`),EW.forEach(t),BGo=i(xl),W3=n(xl,"P",{});var USe=s(W3);xGo=r(USe,"This class cannot be instantiated directly using "),dce=n(USe,"CODE",{});var Dnt=s(dce);kGo=r(Dnt,"__init__()"),Dnt.forEach(t),RGo=r(USe," (throws an error)."),USe.forEach(t),SGo=i(xl),it=n(xl,"DIV",{class:!0});var kl=s(it);m(Q3.$$.fragment,kl),PGo=i(kl),cce=n(kl,"P",{});var Nnt=s(cce);$Go=r(Nnt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Nnt.forEach(t),IGo=i(kl),ec=n(kl,"P",{});var yW=s(ec);jGo=r(yW,`Note:
Loading a model from its configuration file does `),fce=n(yW,"STRONG",{});var qnt=s(fce);DGo=r(qnt,"not"),qnt.forEach(t),NGo=r(yW,` load the model weights. It only affects the
model\u2019s configuration. Use `),mce=n(yW,"CODE",{});var Ont=s(mce);qGo=r(Ont,"from_pretrained()"),Ont.forEach(t),OGo=r(yW,"to load the model weights."),yW.forEach(t),GGo=i(kl),gce=n(kl,"P",{});var Gnt=s(gce);XGo=r(Gnt,"Examples:"),Gnt.forEach(t),VGo=i(kl),m(H3.$$.fragment,kl),kl.forEach(t),zGo=i(xl),Ze=n(xl,"DIV",{class:!0});var na=s(Ze);m(U3.$$.fragment,na),WGo=i(na),hce=n(na,"P",{});var Xnt=s(hce);QGo=r(Xnt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Xnt.forEach(t),HGo=i(na),mn=n(na,"P",{});var wM=s(mn);UGo=r(wM,"The model class to instantiate is selected based on the "),pce=n(wM,"CODE",{});var Vnt=s(pce);JGo=r(Vnt,"model_type"),Vnt.forEach(t),YGo=r(wM,` property of the config object (either
passed as an argument or loaded from `),_ce=n(wM,"CODE",{});var znt=s(_ce);KGo=r(znt,"pretrained_model_name_or_path"),znt.forEach(t),ZGo=r(wM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uce=n(wM,"CODE",{});var Wnt=s(uce);eXo=r(Wnt,"pretrained_model_name_or_path"),Wnt.forEach(t),oXo=r(wM,":"),wM.forEach(t),rXo=i(na),J3=n(na,"UL",{});var JSe=s(J3);Nv=n(JSe,"LI",{});var tAe=s(Nv);bce=n(tAe,"STRONG",{});var Qnt=s(bce);tXo=r(Qnt,"speech-encoder-decoder"),Qnt.forEach(t),aXo=r(tAe," \u2014 "),nq=n(tAe,"A",{href:!0});var Hnt=s(nq);nXo=r(Hnt,"SpeechEncoderDecoderModel"),Hnt.forEach(t),sXo=r(tAe," (Speech Encoder decoder model)"),tAe.forEach(t),lXo=i(JSe),qv=n(JSe,"LI",{});var aAe=s(qv);vce=n(aAe,"STRONG",{});var Unt=s(vce);iXo=r(Unt,"speech_to_text"),Unt.forEach(t),dXo=r(aAe," \u2014 "),sq=n(aAe,"A",{href:!0});var Jnt=s(sq);cXo=r(Jnt,"Speech2TextForConditionalGeneration"),Jnt.forEach(t),fXo=r(aAe," (Speech2Text model)"),aAe.forEach(t),JSe.forEach(t),mXo=i(na),Ov=n(na,"P",{});var nAe=s(Ov);gXo=r(nAe,"The model is set in evaluation mode by default using "),Tce=n(nAe,"CODE",{});var Ynt=s(Tce);hXo=r(Ynt,"model.eval()"),Ynt.forEach(t),pXo=r(nAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fce=n(nAe,"CODE",{});var Knt=s(Fce);_Xo=r(Knt,"model.train()"),Knt.forEach(t),nAe.forEach(t),uXo=i(na),Cce=n(na,"P",{});var Znt=s(Cce);bXo=r(Znt,"Examples:"),Znt.forEach(t),vXo=i(na),m(Y3.$$.fragment,na),na.forEach(t),xl.forEach(t),Nke=i(d),oc=n(d,"H2",{class:!0});var YSe=s(oc);Gv=n(YSe,"A",{id:!0,class:!0,href:!0});var est=s(Gv);Mce=n(est,"SPAN",{});var ost=s(Mce);m(K3.$$.fragment,ost),ost.forEach(t),est.forEach(t),TXo=i(YSe),Ece=n(YSe,"SPAN",{});var rst=s(Ece);FXo=r(rst,"AutoModelForAudioXVector"),rst.forEach(t),YSe.forEach(t),qke=i(d),hr=n(d,"DIV",{class:!0});var Rl=s(hr);m(Z3.$$.fragment,Rl),CXo=i(Rl),rc=n(Rl,"P",{});var wW=s(rc);MXo=r(wW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),yce=n(wW,"CODE",{});var tst=s(yce);EXo=r(tst,"from_pretrained()"),tst.forEach(t),yXo=r(wW,"class method or the "),wce=n(wW,"CODE",{});var ast=s(wce);wXo=r(ast,"from_config()"),ast.forEach(t),AXo=r(wW,`class
method.`),wW.forEach(t),LXo=i(Rl),ey=n(Rl,"P",{});var KSe=s(ey);BXo=r(KSe,"This class cannot be instantiated directly using "),Ace=n(KSe,"CODE",{});var nst=s(Ace);xXo=r(nst,"__init__()"),nst.forEach(t),kXo=r(KSe," (throws an error)."),KSe.forEach(t),RXo=i(Rl),dt=n(Rl,"DIV",{class:!0});var Sl=s(dt);m(oy.$$.fragment,Sl),SXo=i(Sl),Lce=n(Sl,"P",{});var sst=s(Lce);PXo=r(sst,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),sst.forEach(t),$Xo=i(Sl),tc=n(Sl,"P",{});var AW=s(tc);IXo=r(AW,`Note:
Loading a model from its configuration file does `),Bce=n(AW,"STRONG",{});var lst=s(Bce);jXo=r(lst,"not"),lst.forEach(t),DXo=r(AW,` load the model weights. It only affects the
model\u2019s configuration. Use `),xce=n(AW,"CODE",{});var ist=s(xce);NXo=r(ist,"from_pretrained()"),ist.forEach(t),qXo=r(AW,"to load the model weights."),AW.forEach(t),OXo=i(Sl),kce=n(Sl,"P",{});var dst=s(kce);GXo=r(dst,"Examples:"),dst.forEach(t),XXo=i(Sl),m(ry.$$.fragment,Sl),Sl.forEach(t),VXo=i(Rl),eo=n(Rl,"DIV",{class:!0});var sa=s(eo);m(ty.$$.fragment,sa),zXo=i(sa),Rce=n(sa,"P",{});var cst=s(Rce);WXo=r(cst,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),cst.forEach(t),QXo=i(sa),gn=n(sa,"P",{});var AM=s(gn);HXo=r(AM,"The model class to instantiate is selected based on the "),Sce=n(AM,"CODE",{});var fst=s(Sce);UXo=r(fst,"model_type"),fst.forEach(t),JXo=r(AM,` property of the config object (either
passed as an argument or loaded from `),Pce=n(AM,"CODE",{});var mst=s(Pce);YXo=r(mst,"pretrained_model_name_or_path"),mst.forEach(t),KXo=r(AM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ce=n(AM,"CODE",{});var gst=s($ce);ZXo=r(gst,"pretrained_model_name_or_path"),gst.forEach(t),eVo=r(AM,":"),AM.forEach(t),oVo=i(sa),hn=n(sa,"UL",{});var LM=s(hn);Xv=n(LM,"LI",{});var sAe=s(Xv);Ice=n(sAe,"STRONG",{});var hst=s(Ice);rVo=r(hst,"data2vec-audio"),hst.forEach(t),tVo=r(sAe," \u2014 "),lq=n(sAe,"A",{href:!0});var pst=s(lq);aVo=r(pst,"Data2VecAudioForXVector"),pst.forEach(t),nVo=r(sAe," (Data2VecAudio model)"),sAe.forEach(t),sVo=i(LM),Vv=n(LM,"LI",{});var lAe=s(Vv);jce=n(lAe,"STRONG",{});var _st=s(jce);lVo=r(_st,"unispeech-sat"),_st.forEach(t),iVo=r(lAe," \u2014 "),iq=n(lAe,"A",{href:!0});var ust=s(iq);dVo=r(ust,"UniSpeechSatForXVector"),ust.forEach(t),cVo=r(lAe," (UniSpeechSat model)"),lAe.forEach(t),fVo=i(LM),zv=n(LM,"LI",{});var iAe=s(zv);Dce=n(iAe,"STRONG",{});var bst=s(Dce);mVo=r(bst,"wav2vec2"),bst.forEach(t),gVo=r(iAe," \u2014 "),dq=n(iAe,"A",{href:!0});var vst=s(dq);hVo=r(vst,"Wav2Vec2ForXVector"),vst.forEach(t),pVo=r(iAe," (Wav2Vec2 model)"),iAe.forEach(t),_Vo=i(LM),Wv=n(LM,"LI",{});var dAe=s(Wv);Nce=n(dAe,"STRONG",{});var Tst=s(Nce);uVo=r(Tst,"wavlm"),Tst.forEach(t),bVo=r(dAe," \u2014 "),cq=n(dAe,"A",{href:!0});var Fst=s(cq);vVo=r(Fst,"WavLMForXVector"),Fst.forEach(t),TVo=r(dAe," (WavLM model)"),dAe.forEach(t),LM.forEach(t),FVo=i(sa),Qv=n(sa,"P",{});var cAe=s(Qv);CVo=r(cAe,"The model is set in evaluation mode by default using "),qce=n(cAe,"CODE",{});var Cst=s(qce);MVo=r(Cst,"model.eval()"),Cst.forEach(t),EVo=r(cAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Oce=n(cAe,"CODE",{});var Mst=s(Oce);yVo=r(Mst,"model.train()"),Mst.forEach(t),cAe.forEach(t),wVo=i(sa),Gce=n(sa,"P",{});var Est=s(Gce);AVo=r(Est,"Examples:"),Est.forEach(t),LVo=i(sa),m(ay.$$.fragment,sa),sa.forEach(t),Rl.forEach(t),Oke=i(d),ac=n(d,"H2",{class:!0});var ZSe=s(ac);Hv=n(ZSe,"A",{id:!0,class:!0,href:!0});var yst=s(Hv);Xce=n(yst,"SPAN",{});var wst=s(Xce);m(ny.$$.fragment,wst),wst.forEach(t),yst.forEach(t),BVo=i(ZSe),Vce=n(ZSe,"SPAN",{});var Ast=s(Vce);xVo=r(Ast,"AutoModelForMaskedImageModeling"),Ast.forEach(t),ZSe.forEach(t),Gke=i(d),pr=n(d,"DIV",{class:!0});var Pl=s(pr);m(sy.$$.fragment,Pl),kVo=i(Pl),nc=n(Pl,"P",{});var LW=s(nc);RVo=r(LW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),zce=n(LW,"CODE",{});var Lst=s(zce);SVo=r(Lst,"from_pretrained()"),Lst.forEach(t),PVo=r(LW,"class method or the "),Wce=n(LW,"CODE",{});var Bst=s(Wce);$Vo=r(Bst,"from_config()"),Bst.forEach(t),IVo=r(LW,`class
method.`),LW.forEach(t),jVo=i(Pl),ly=n(Pl,"P",{});var ePe=s(ly);DVo=r(ePe,"This class cannot be instantiated directly using "),Qce=n(ePe,"CODE",{});var xst=s(Qce);NVo=r(xst,"__init__()"),xst.forEach(t),qVo=r(ePe," (throws an error)."),ePe.forEach(t),OVo=i(Pl),ct=n(Pl,"DIV",{class:!0});var $l=s(ct);m(iy.$$.fragment,$l),GVo=i($l),Hce=n($l,"P",{});var kst=s(Hce);XVo=r(kst,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),kst.forEach(t),VVo=i($l),sc=n($l,"P",{});var BW=s(sc);zVo=r(BW,`Note:
Loading a model from its configuration file does `),Uce=n(BW,"STRONG",{});var Rst=s(Uce);WVo=r(Rst,"not"),Rst.forEach(t),QVo=r(BW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jce=n(BW,"CODE",{});var Sst=s(Jce);HVo=r(Sst,"from_pretrained()"),Sst.forEach(t),UVo=r(BW,"to load the model weights."),BW.forEach(t),JVo=i($l),Yce=n($l,"P",{});var Pst=s(Yce);YVo=r(Pst,"Examples:"),Pst.forEach(t),KVo=i($l),m(dy.$$.fragment,$l),$l.forEach(t),ZVo=i(Pl),oo=n(Pl,"DIV",{class:!0});var la=s(oo);m(cy.$$.fragment,la),ezo=i(la),Kce=n(la,"P",{});var $st=s(Kce);ozo=r($st,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),$st.forEach(t),rzo=i(la),pn=n(la,"P",{});var BM=s(pn);tzo=r(BM,"The model class to instantiate is selected based on the "),Zce=n(BM,"CODE",{});var Ist=s(Zce);azo=r(Ist,"model_type"),Ist.forEach(t),nzo=r(BM,` property of the config object (either
passed as an argument or loaded from `),efe=n(BM,"CODE",{});var jst=s(efe);szo=r(jst,"pretrained_model_name_or_path"),jst.forEach(t),lzo=r(BM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ofe=n(BM,"CODE",{});var Dst=s(ofe);izo=r(Dst,"pretrained_model_name_or_path"),Dst.forEach(t),dzo=r(BM,":"),BM.forEach(t),czo=i(la),lc=n(la,"UL",{});var xW=s(lc);Uv=n(xW,"LI",{});var fAe=s(Uv);rfe=n(fAe,"STRONG",{});var Nst=s(rfe);fzo=r(Nst,"deit"),Nst.forEach(t),mzo=r(fAe," \u2014 "),fq=n(fAe,"A",{href:!0});var qst=s(fq);gzo=r(qst,"DeiTForMaskedImageModeling"),qst.forEach(t),hzo=r(fAe," (DeiT model)"),fAe.forEach(t),pzo=i(xW),Jv=n(xW,"LI",{});var mAe=s(Jv);tfe=n(mAe,"STRONG",{});var Ost=s(tfe);_zo=r(Ost,"swin"),Ost.forEach(t),uzo=r(mAe," \u2014 "),mq=n(mAe,"A",{href:!0});var Gst=s(mq);bzo=r(Gst,"SwinForMaskedImageModeling"),Gst.forEach(t),vzo=r(mAe," (Swin model)"),mAe.forEach(t),Tzo=i(xW),Yv=n(xW,"LI",{});var gAe=s(Yv);afe=n(gAe,"STRONG",{});var Xst=s(afe);Fzo=r(Xst,"vit"),Xst.forEach(t),Czo=r(gAe," \u2014 "),gq=n(gAe,"A",{href:!0});var Vst=s(gq);Mzo=r(Vst,"ViTForMaskedImageModeling"),Vst.forEach(t),Ezo=r(gAe," (ViT model)"),gAe.forEach(t),xW.forEach(t),yzo=i(la),Kv=n(la,"P",{});var hAe=s(Kv);wzo=r(hAe,"The model is set in evaluation mode by default using "),nfe=n(hAe,"CODE",{});var zst=s(nfe);Azo=r(zst,"model.eval()"),zst.forEach(t),Lzo=r(hAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sfe=n(hAe,"CODE",{});var Wst=s(sfe);Bzo=r(Wst,"model.train()"),Wst.forEach(t),hAe.forEach(t),xzo=i(la),lfe=n(la,"P",{});var Qst=s(lfe);kzo=r(Qst,"Examples:"),Qst.forEach(t),Rzo=i(la),m(fy.$$.fragment,la),la.forEach(t),Pl.forEach(t),Xke=i(d),ic=n(d,"H2",{class:!0});var oPe=s(ic);Zv=n(oPe,"A",{id:!0,class:!0,href:!0});var Hst=s(Zv);ife=n(Hst,"SPAN",{});var Ust=s(ife);m(my.$$.fragment,Ust),Ust.forEach(t),Hst.forEach(t),Szo=i(oPe),dfe=n(oPe,"SPAN",{});var Jst=s(dfe);Pzo=r(Jst,"AutoModelForObjectDetection"),Jst.forEach(t),oPe.forEach(t),Vke=i(d),_r=n(d,"DIV",{class:!0});var Il=s(_r);m(gy.$$.fragment,Il),$zo=i(Il),dc=n(Il,"P",{});var kW=s(dc);Izo=r(kW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),cfe=n(kW,"CODE",{});var Yst=s(cfe);jzo=r(Yst,"from_pretrained()"),Yst.forEach(t),Dzo=r(kW,"class method or the "),ffe=n(kW,"CODE",{});var Kst=s(ffe);Nzo=r(Kst,"from_config()"),Kst.forEach(t),qzo=r(kW,`class
method.`),kW.forEach(t),Ozo=i(Il),hy=n(Il,"P",{});var rPe=s(hy);Gzo=r(rPe,"This class cannot be instantiated directly using "),mfe=n(rPe,"CODE",{});var Zst=s(mfe);Xzo=r(Zst,"__init__()"),Zst.forEach(t),Vzo=r(rPe," (throws an error)."),rPe.forEach(t),zzo=i(Il),ft=n(Il,"DIV",{class:!0});var jl=s(ft);m(py.$$.fragment,jl),Wzo=i(jl),gfe=n(jl,"P",{});var elt=s(gfe);Qzo=r(elt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),elt.forEach(t),Hzo=i(jl),cc=n(jl,"P",{});var RW=s(cc);Uzo=r(RW,`Note:
Loading a model from its configuration file does `),hfe=n(RW,"STRONG",{});var olt=s(hfe);Jzo=r(olt,"not"),olt.forEach(t),Yzo=r(RW,` load the model weights. It only affects the
model\u2019s configuration. Use `),pfe=n(RW,"CODE",{});var rlt=s(pfe);Kzo=r(rlt,"from_pretrained()"),rlt.forEach(t),Zzo=r(RW,"to load the model weights."),RW.forEach(t),eWo=i(jl),_fe=n(jl,"P",{});var tlt=s(_fe);oWo=r(tlt,"Examples:"),tlt.forEach(t),rWo=i(jl),m(_y.$$.fragment,jl),jl.forEach(t),tWo=i(Il),ro=n(Il,"DIV",{class:!0});var ia=s(ro);m(uy.$$.fragment,ia),aWo=i(ia),ufe=n(ia,"P",{});var alt=s(ufe);nWo=r(alt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),alt.forEach(t),sWo=i(ia),_n=n(ia,"P",{});var xM=s(_n);lWo=r(xM,"The model class to instantiate is selected based on the "),bfe=n(xM,"CODE",{});var nlt=s(bfe);iWo=r(nlt,"model_type"),nlt.forEach(t),dWo=r(xM,` property of the config object (either
passed as an argument or loaded from `),vfe=n(xM,"CODE",{});var slt=s(vfe);cWo=r(slt,"pretrained_model_name_or_path"),slt.forEach(t),fWo=r(xM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tfe=n(xM,"CODE",{});var llt=s(Tfe);mWo=r(llt,"pretrained_model_name_or_path"),llt.forEach(t),gWo=r(xM,":"),xM.forEach(t),hWo=i(ia),Ffe=n(ia,"UL",{});var ilt=s(Ffe);e6=n(ilt,"LI",{});var pAe=s(e6);Cfe=n(pAe,"STRONG",{});var dlt=s(Cfe);pWo=r(dlt,"detr"),dlt.forEach(t),_Wo=r(pAe," \u2014 "),hq=n(pAe,"A",{href:!0});var clt=s(hq);uWo=r(clt,"DetrForObjectDetection"),clt.forEach(t),bWo=r(pAe," (DETR model)"),pAe.forEach(t),ilt.forEach(t),vWo=i(ia),o6=n(ia,"P",{});var _Ae=s(o6);TWo=r(_Ae,"The model is set in evaluation mode by default using "),Mfe=n(_Ae,"CODE",{});var flt=s(Mfe);FWo=r(flt,"model.eval()"),flt.forEach(t),CWo=r(_Ae,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Efe=n(_Ae,"CODE",{});var mlt=s(Efe);MWo=r(mlt,"model.train()"),mlt.forEach(t),_Ae.forEach(t),EWo=i(ia),yfe=n(ia,"P",{});var glt=s(yfe);yWo=r(glt,"Examples:"),glt.forEach(t),wWo=i(ia),m(by.$$.fragment,ia),ia.forEach(t),Il.forEach(t),zke=i(d),fc=n(d,"H2",{class:!0});var tPe=s(fc);r6=n(tPe,"A",{id:!0,class:!0,href:!0});var hlt=s(r6);wfe=n(hlt,"SPAN",{});var plt=s(wfe);m(vy.$$.fragment,plt),plt.forEach(t),hlt.forEach(t),AWo=i(tPe),Afe=n(tPe,"SPAN",{});var _lt=s(Afe);LWo=r(_lt,"AutoModelForImageSegmentation"),_lt.forEach(t),tPe.forEach(t),Wke=i(d),ur=n(d,"DIV",{class:!0});var Dl=s(ur);m(Ty.$$.fragment,Dl),BWo=i(Dl),mc=n(Dl,"P",{});var SW=s(mc);xWo=r(SW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Lfe=n(SW,"CODE",{});var ult=s(Lfe);kWo=r(ult,"from_pretrained()"),ult.forEach(t),RWo=r(SW,"class method or the "),Bfe=n(SW,"CODE",{});var blt=s(Bfe);SWo=r(blt,"from_config()"),blt.forEach(t),PWo=r(SW,`class
method.`),SW.forEach(t),$Wo=i(Dl),Fy=n(Dl,"P",{});var aPe=s(Fy);IWo=r(aPe,"This class cannot be instantiated directly using "),xfe=n(aPe,"CODE",{});var vlt=s(xfe);jWo=r(vlt,"__init__()"),vlt.forEach(t),DWo=r(aPe," (throws an error)."),aPe.forEach(t),NWo=i(Dl),mt=n(Dl,"DIV",{class:!0});var Nl=s(mt);m(Cy.$$.fragment,Nl),qWo=i(Nl),kfe=n(Nl,"P",{});var Tlt=s(kfe);OWo=r(Tlt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Tlt.forEach(t),GWo=i(Nl),gc=n(Nl,"P",{});var PW=s(gc);XWo=r(PW,`Note:
Loading a model from its configuration file does `),Rfe=n(PW,"STRONG",{});var Flt=s(Rfe);VWo=r(Flt,"not"),Flt.forEach(t),zWo=r(PW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sfe=n(PW,"CODE",{});var Clt=s(Sfe);WWo=r(Clt,"from_pretrained()"),Clt.forEach(t),QWo=r(PW,"to load the model weights."),PW.forEach(t),HWo=i(Nl),Pfe=n(Nl,"P",{});var Mlt=s(Pfe);UWo=r(Mlt,"Examples:"),Mlt.forEach(t),JWo=i(Nl),m(My.$$.fragment,Nl),Nl.forEach(t),YWo=i(Dl),to=n(Dl,"DIV",{class:!0});var da=s(to);m(Ey.$$.fragment,da),KWo=i(da),$fe=n(da,"P",{});var Elt=s($fe);ZWo=r(Elt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Elt.forEach(t),eQo=i(da),un=n(da,"P",{});var kM=s(un);oQo=r(kM,"The model class to instantiate is selected based on the "),Ife=n(kM,"CODE",{});var ylt=s(Ife);rQo=r(ylt,"model_type"),ylt.forEach(t),tQo=r(kM,` property of the config object (either
passed as an argument or loaded from `),jfe=n(kM,"CODE",{});var wlt=s(jfe);aQo=r(wlt,"pretrained_model_name_or_path"),wlt.forEach(t),nQo=r(kM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dfe=n(kM,"CODE",{});var Alt=s(Dfe);sQo=r(Alt,"pretrained_model_name_or_path"),Alt.forEach(t),lQo=r(kM,":"),kM.forEach(t),iQo=i(da),Nfe=n(da,"UL",{});var Llt=s(Nfe);t6=n(Llt,"LI",{});var uAe=s(t6);qfe=n(uAe,"STRONG",{});var Blt=s(qfe);dQo=r(Blt,"detr"),Blt.forEach(t),cQo=r(uAe," \u2014 "),pq=n(uAe,"A",{href:!0});var xlt=s(pq);fQo=r(xlt,"DetrForSegmentation"),xlt.forEach(t),mQo=r(uAe," (DETR model)"),uAe.forEach(t),Llt.forEach(t),gQo=i(da),a6=n(da,"P",{});var bAe=s(a6);hQo=r(bAe,"The model is set in evaluation mode by default using "),Ofe=n(bAe,"CODE",{});var klt=s(Ofe);pQo=r(klt,"model.eval()"),klt.forEach(t),_Qo=r(bAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gfe=n(bAe,"CODE",{});var Rlt=s(Gfe);uQo=r(Rlt,"model.train()"),Rlt.forEach(t),bAe.forEach(t),bQo=i(da),Xfe=n(da,"P",{});var Slt=s(Xfe);vQo=r(Slt,"Examples:"),Slt.forEach(t),TQo=i(da),m(yy.$$.fragment,da),da.forEach(t),Dl.forEach(t),Qke=i(d),hc=n(d,"H2",{class:!0});var nPe=s(hc);n6=n(nPe,"A",{id:!0,class:!0,href:!0});var Plt=s(n6);Vfe=n(Plt,"SPAN",{});var $lt=s(Vfe);m(wy.$$.fragment,$lt),$lt.forEach(t),Plt.forEach(t),FQo=i(nPe),zfe=n(nPe,"SPAN",{});var Ilt=s(zfe);CQo=r(Ilt,"AutoModelForSemanticSegmentation"),Ilt.forEach(t),nPe.forEach(t),Hke=i(d),br=n(d,"DIV",{class:!0});var ql=s(br);m(Ay.$$.fragment,ql),MQo=i(ql),pc=n(ql,"P",{});var $W=s(pc);EQo=r($W,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Wfe=n($W,"CODE",{});var jlt=s(Wfe);yQo=r(jlt,"from_pretrained()"),jlt.forEach(t),wQo=r($W,"class method or the "),Qfe=n($W,"CODE",{});var Dlt=s(Qfe);AQo=r(Dlt,"from_config()"),Dlt.forEach(t),LQo=r($W,`class
method.`),$W.forEach(t),BQo=i(ql),Ly=n(ql,"P",{});var sPe=s(Ly);xQo=r(sPe,"This class cannot be instantiated directly using "),Hfe=n(sPe,"CODE",{});var Nlt=s(Hfe);kQo=r(Nlt,"__init__()"),Nlt.forEach(t),RQo=r(sPe," (throws an error)."),sPe.forEach(t),SQo=i(ql),gt=n(ql,"DIV",{class:!0});var Ol=s(gt);m(By.$$.fragment,Ol),PQo=i(Ol),Ufe=n(Ol,"P",{});var qlt=s(Ufe);$Qo=r(qlt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),qlt.forEach(t),IQo=i(Ol),_c=n(Ol,"P",{});var IW=s(_c);jQo=r(IW,`Note:
Loading a model from its configuration file does `),Jfe=n(IW,"STRONG",{});var Olt=s(Jfe);DQo=r(Olt,"not"),Olt.forEach(t),NQo=r(IW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yfe=n(IW,"CODE",{});var Glt=s(Yfe);qQo=r(Glt,"from_pretrained()"),Glt.forEach(t),OQo=r(IW,"to load the model weights."),IW.forEach(t),GQo=i(Ol),Kfe=n(Ol,"P",{});var Xlt=s(Kfe);XQo=r(Xlt,"Examples:"),Xlt.forEach(t),VQo=i(Ol),m(xy.$$.fragment,Ol),Ol.forEach(t),zQo=i(ql),ao=n(ql,"DIV",{class:!0});var ca=s(ao);m(ky.$$.fragment,ca),WQo=i(ca),Zfe=n(ca,"P",{});var Vlt=s(Zfe);QQo=r(Vlt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Vlt.forEach(t),HQo=i(ca),bn=n(ca,"P",{});var RM=s(bn);UQo=r(RM,"The model class to instantiate is selected based on the "),eme=n(RM,"CODE",{});var zlt=s(eme);JQo=r(zlt,"model_type"),zlt.forEach(t),YQo=r(RM,` property of the config object (either
passed as an argument or loaded from `),ome=n(RM,"CODE",{});var Wlt=s(ome);KQo=r(Wlt,"pretrained_model_name_or_path"),Wlt.forEach(t),ZQo=r(RM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rme=n(RM,"CODE",{});var Qlt=s(rme);eHo=r(Qlt,"pretrained_model_name_or_path"),Qlt.forEach(t),oHo=r(RM,":"),RM.forEach(t),rHo=i(ca),Ry=n(ca,"UL",{});var lPe=s(Ry);s6=n(lPe,"LI",{});var vAe=s(s6);tme=n(vAe,"STRONG",{});var Hlt=s(tme);tHo=r(Hlt,"beit"),Hlt.forEach(t),aHo=r(vAe," \u2014 "),_q=n(vAe,"A",{href:!0});var Ult=s(_q);nHo=r(Ult,"BeitForSemanticSegmentation"),Ult.forEach(t),sHo=r(vAe," (BEiT model)"),vAe.forEach(t),lHo=i(lPe),l6=n(lPe,"LI",{});var TAe=s(l6);ame=n(TAe,"STRONG",{});var Jlt=s(ame);iHo=r(Jlt,"segformer"),Jlt.forEach(t),dHo=r(TAe," \u2014 "),uq=n(TAe,"A",{href:!0});var Ylt=s(uq);cHo=r(Ylt,"SegformerForSemanticSegmentation"),Ylt.forEach(t),fHo=r(TAe," (SegFormer model)"),TAe.forEach(t),lPe.forEach(t),mHo=i(ca),i6=n(ca,"P",{});var FAe=s(i6);gHo=r(FAe,"The model is set in evaluation mode by default using "),nme=n(FAe,"CODE",{});var Klt=s(nme);hHo=r(Klt,"model.eval()"),Klt.forEach(t),pHo=r(FAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sme=n(FAe,"CODE",{});var Zlt=s(sme);_Ho=r(Zlt,"model.train()"),Zlt.forEach(t),FAe.forEach(t),uHo=i(ca),lme=n(ca,"P",{});var eit=s(lme);bHo=r(eit,"Examples:"),eit.forEach(t),vHo=i(ca),m(Sy.$$.fragment,ca),ca.forEach(t),ql.forEach(t),Uke=i(d),uc=n(d,"H2",{class:!0});var iPe=s(uc);d6=n(iPe,"A",{id:!0,class:!0,href:!0});var oit=s(d6);ime=n(oit,"SPAN",{});var rit=s(ime);m(Py.$$.fragment,rit),rit.forEach(t),oit.forEach(t),THo=i(iPe),dme=n(iPe,"SPAN",{});var tit=s(dme);FHo=r(tit,"AutoModelForInstanceSegmentation"),tit.forEach(t),iPe.forEach(t),Jke=i(d),vr=n(d,"DIV",{class:!0});var Gl=s(vr);m($y.$$.fragment,Gl),CHo=i(Gl),bc=n(Gl,"P",{});var jW=s(bc);MHo=r(jW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),cme=n(jW,"CODE",{});var ait=s(cme);EHo=r(ait,"from_pretrained()"),ait.forEach(t),yHo=r(jW,"class method or the "),fme=n(jW,"CODE",{});var nit=s(fme);wHo=r(nit,"from_config()"),nit.forEach(t),AHo=r(jW,`class
method.`),jW.forEach(t),LHo=i(Gl),Iy=n(Gl,"P",{});var dPe=s(Iy);BHo=r(dPe,"This class cannot be instantiated directly using "),mme=n(dPe,"CODE",{});var sit=s(mme);xHo=r(sit,"__init__()"),sit.forEach(t),kHo=r(dPe," (throws an error)."),dPe.forEach(t),RHo=i(Gl),ht=n(Gl,"DIV",{class:!0});var Xl=s(ht);m(jy.$$.fragment,Xl),SHo=i(Xl),gme=n(Xl,"P",{});var lit=s(gme);PHo=r(lit,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),lit.forEach(t),$Ho=i(Xl),vc=n(Xl,"P",{});var DW=s(vc);IHo=r(DW,`Note:
Loading a model from its configuration file does `),hme=n(DW,"STRONG",{});var iit=s(hme);jHo=r(iit,"not"),iit.forEach(t),DHo=r(DW,` load the model weights. It only affects the
model\u2019s configuration. Use `),pme=n(DW,"CODE",{});var dit=s(pme);NHo=r(dit,"from_pretrained()"),dit.forEach(t),qHo=r(DW,"to load the model weights."),DW.forEach(t),OHo=i(Xl),_me=n(Xl,"P",{});var cit=s(_me);GHo=r(cit,"Examples:"),cit.forEach(t),XHo=i(Xl),m(Dy.$$.fragment,Xl),Xl.forEach(t),VHo=i(Gl),no=n(Gl,"DIV",{class:!0});var fa=s(no);m(Ny.$$.fragment,fa),zHo=i(fa),ume=n(fa,"P",{});var fit=s(ume);WHo=r(fit,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),fit.forEach(t),QHo=i(fa),vn=n(fa,"P",{});var SM=s(vn);HHo=r(SM,"The model class to instantiate is selected based on the "),bme=n(SM,"CODE",{});var mit=s(bme);UHo=r(mit,"model_type"),mit.forEach(t),JHo=r(SM,` property of the config object (either
passed as an argument or loaded from `),vme=n(SM,"CODE",{});var git=s(vme);YHo=r(git,"pretrained_model_name_or_path"),git.forEach(t),KHo=r(SM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tme=n(SM,"CODE",{});var hit=s(Tme);ZHo=r(hit,"pretrained_model_name_or_path"),hit.forEach(t),eUo=r(SM,":"),SM.forEach(t),oUo=i(fa),Fme=n(fa,"UL",{});var pit=s(Fme);c6=n(pit,"LI",{});var CAe=s(c6);Cme=n(CAe,"STRONG",{});var _it=s(Cme);rUo=r(_it,"maskformer"),_it.forEach(t),tUo=r(CAe," \u2014 "),bq=n(CAe,"A",{href:!0});var uit=s(bq);aUo=r(uit,"MaskFormerForInstanceSegmentation"),uit.forEach(t),nUo=r(CAe," (MaskFormer model)"),CAe.forEach(t),pit.forEach(t),sUo=i(fa),f6=n(fa,"P",{});var MAe=s(f6);lUo=r(MAe,"The model is set in evaluation mode by default using "),Mme=n(MAe,"CODE",{});var bit=s(Mme);iUo=r(bit,"model.eval()"),bit.forEach(t),dUo=r(MAe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Eme=n(MAe,"CODE",{});var vit=s(Eme);cUo=r(vit,"model.train()"),vit.forEach(t),MAe.forEach(t),fUo=i(fa),yme=n(fa,"P",{});var Tit=s(yme);mUo=r(Tit,"Examples:"),Tit.forEach(t),gUo=i(fa),m(qy.$$.fragment,fa),fa.forEach(t),Gl.forEach(t),Yke=i(d),Tc=n(d,"H2",{class:!0});var cPe=s(Tc);m6=n(cPe,"A",{id:!0,class:!0,href:!0});var Fit=s(m6);wme=n(Fit,"SPAN",{});var Cit=s(wme);m(Oy.$$.fragment,Cit),Cit.forEach(t),Fit.forEach(t),hUo=i(cPe),Ame=n(cPe,"SPAN",{});var Mit=s(Ame);pUo=r(Mit,"TFAutoModel"),Mit.forEach(t),cPe.forEach(t),Kke=i(d),Tr=n(d,"DIV",{class:!0});var Vl=s(Tr);m(Gy.$$.fragment,Vl),_Uo=i(Vl),Fc=n(Vl,"P",{});var NW=s(Fc);uUo=r(NW,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Lme=n(NW,"CODE",{});var Eit=s(Lme);bUo=r(Eit,"from_pretrained()"),Eit.forEach(t),vUo=r(NW,"class method or the "),Bme=n(NW,"CODE",{});var yit=s(Bme);TUo=r(yit,"from_config()"),yit.forEach(t),FUo=r(NW,`class
method.`),NW.forEach(t),CUo=i(Vl),Xy=n(Vl,"P",{});var fPe=s(Xy);MUo=r(fPe,"This class cannot be instantiated directly using "),xme=n(fPe,"CODE",{});var wit=s(xme);EUo=r(wit,"__init__()"),wit.forEach(t),yUo=r(fPe," (throws an error)."),fPe.forEach(t),wUo=i(Vl),pt=n(Vl,"DIV",{class:!0});var zl=s(pt);m(Vy.$$.fragment,zl),AUo=i(zl),kme=n(zl,"P",{});var Ait=s(kme);LUo=r(Ait,"Instantiates one of the base model classes of the library from a configuration."),Ait.forEach(t),BUo=i(zl),Cc=n(zl,"P",{});var qW=s(Cc);xUo=r(qW,`Note:
Loading a model from its configuration file does `),Rme=n(qW,"STRONG",{});var Lit=s(Rme);kUo=r(Lit,"not"),Lit.forEach(t),RUo=r(qW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sme=n(qW,"CODE",{});var Bit=s(Sme);SUo=r(Bit,"from_pretrained()"),Bit.forEach(t),PUo=r(qW,"to load the model weights."),qW.forEach(t),$Uo=i(zl),Pme=n(zl,"P",{});var xit=s(Pme);IUo=r(xit,"Examples:"),xit.forEach(t),jUo=i(zl),m(zy.$$.fragment,zl),zl.forEach(t),DUo=i(Vl),ho=n(Vl,"DIV",{class:!0});var ba=s(ho);m(Wy.$$.fragment,ba),NUo=i(ba),$me=n(ba,"P",{});var kit=s($me);qUo=r(kit,"Instantiate one of the base model classes of the library from a pretrained model."),kit.forEach(t),OUo=i(ba),Tn=n(ba,"P",{});var PM=s(Tn);GUo=r(PM,"The model class to instantiate is selected based on the "),Ime=n(PM,"CODE",{});var Rit=s(Ime);XUo=r(Rit,"model_type"),Rit.forEach(t),VUo=r(PM,` property of the config object (either
passed as an argument or loaded from `),jme=n(PM,"CODE",{});var Sit=s(jme);zUo=r(Sit,"pretrained_model_name_or_path"),Sit.forEach(t),WUo=r(PM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dme=n(PM,"CODE",{});var Pit=s(Dme);QUo=r(Pit,"pretrained_model_name_or_path"),Pit.forEach(t),HUo=r(PM,":"),PM.forEach(t),UUo=i(ba),B=n(ba,"UL",{});var x=s(B);g6=n(x,"LI",{});var EAe=s(g6);Nme=n(EAe,"STRONG",{});var $it=s(Nme);JUo=r($it,"albert"),$it.forEach(t),YUo=r(EAe," \u2014 "),vq=n(EAe,"A",{href:!0});var Iit=s(vq);KUo=r(Iit,"TFAlbertModel"),Iit.forEach(t),ZUo=r(EAe," (ALBERT model)"),EAe.forEach(t),eJo=i(x),h6=n(x,"LI",{});var yAe=s(h6);qme=n(yAe,"STRONG",{});var jit=s(qme);oJo=r(jit,"bart"),jit.forEach(t),rJo=r(yAe," \u2014 "),Tq=n(yAe,"A",{href:!0});var Dit=s(Tq);tJo=r(Dit,"TFBartModel"),Dit.forEach(t),aJo=r(yAe," (BART model)"),yAe.forEach(t),nJo=i(x),p6=n(x,"LI",{});var wAe=s(p6);Ome=n(wAe,"STRONG",{});var Nit=s(Ome);sJo=r(Nit,"bert"),Nit.forEach(t),lJo=r(wAe," \u2014 "),Fq=n(wAe,"A",{href:!0});var qit=s(Fq);iJo=r(qit,"TFBertModel"),qit.forEach(t),dJo=r(wAe," (BERT model)"),wAe.forEach(t),cJo=i(x),_6=n(x,"LI",{});var AAe=s(_6);Gme=n(AAe,"STRONG",{});var Oit=s(Gme);fJo=r(Oit,"blenderbot"),Oit.forEach(t),mJo=r(AAe," \u2014 "),Cq=n(AAe,"A",{href:!0});var Git=s(Cq);gJo=r(Git,"TFBlenderbotModel"),Git.forEach(t),hJo=r(AAe," (Blenderbot model)"),AAe.forEach(t),pJo=i(x),u6=n(x,"LI",{});var LAe=s(u6);Xme=n(LAe,"STRONG",{});var Xit=s(Xme);_Jo=r(Xit,"blenderbot-small"),Xit.forEach(t),uJo=r(LAe," \u2014 "),Mq=n(LAe,"A",{href:!0});var Vit=s(Mq);bJo=r(Vit,"TFBlenderbotSmallModel"),Vit.forEach(t),vJo=r(LAe," (BlenderbotSmall model)"),LAe.forEach(t),TJo=i(x),b6=n(x,"LI",{});var BAe=s(b6);Vme=n(BAe,"STRONG",{});var zit=s(Vme);FJo=r(zit,"camembert"),zit.forEach(t),CJo=r(BAe," \u2014 "),Eq=n(BAe,"A",{href:!0});var Wit=s(Eq);MJo=r(Wit,"TFCamembertModel"),Wit.forEach(t),EJo=r(BAe," (CamemBERT model)"),BAe.forEach(t),yJo=i(x),v6=n(x,"LI",{});var xAe=s(v6);zme=n(xAe,"STRONG",{});var Qit=s(zme);wJo=r(Qit,"clip"),Qit.forEach(t),AJo=r(xAe," \u2014 "),yq=n(xAe,"A",{href:!0});var Hit=s(yq);LJo=r(Hit,"TFCLIPModel"),Hit.forEach(t),BJo=r(xAe," (CLIP model)"),xAe.forEach(t),xJo=i(x),T6=n(x,"LI",{});var kAe=s(T6);Wme=n(kAe,"STRONG",{});var Uit=s(Wme);kJo=r(Uit,"convbert"),Uit.forEach(t),RJo=r(kAe," \u2014 "),wq=n(kAe,"A",{href:!0});var Jit=s(wq);SJo=r(Jit,"TFConvBertModel"),Jit.forEach(t),PJo=r(kAe," (ConvBERT model)"),kAe.forEach(t),$Jo=i(x),F6=n(x,"LI",{});var RAe=s(F6);Qme=n(RAe,"STRONG",{});var Yit=s(Qme);IJo=r(Yit,"convnext"),Yit.forEach(t),jJo=r(RAe," \u2014 "),Aq=n(RAe,"A",{href:!0});var Kit=s(Aq);DJo=r(Kit,"TFConvNextModel"),Kit.forEach(t),NJo=r(RAe," (ConvNext model)"),RAe.forEach(t),qJo=i(x),C6=n(x,"LI",{});var SAe=s(C6);Hme=n(SAe,"STRONG",{});var Zit=s(Hme);OJo=r(Zit,"ctrl"),Zit.forEach(t),GJo=r(SAe," \u2014 "),Lq=n(SAe,"A",{href:!0});var edt=s(Lq);XJo=r(edt,"TFCTRLModel"),edt.forEach(t),VJo=r(SAe," (CTRL model)"),SAe.forEach(t),zJo=i(x),M6=n(x,"LI",{});var PAe=s(M6);Ume=n(PAe,"STRONG",{});var odt=s(Ume);WJo=r(odt,"deberta"),odt.forEach(t),QJo=r(PAe," \u2014 "),Bq=n(PAe,"A",{href:!0});var rdt=s(Bq);HJo=r(rdt,"TFDebertaModel"),rdt.forEach(t),UJo=r(PAe," (DeBERTa model)"),PAe.forEach(t),JJo=i(x),E6=n(x,"LI",{});var $Ae=s(E6);Jme=n($Ae,"STRONG",{});var tdt=s(Jme);YJo=r(tdt,"deberta-v2"),tdt.forEach(t),KJo=r($Ae," \u2014 "),xq=n($Ae,"A",{href:!0});var adt=s(xq);ZJo=r(adt,"TFDebertaV2Model"),adt.forEach(t),eYo=r($Ae," (DeBERTa-v2 model)"),$Ae.forEach(t),oYo=i(x),y6=n(x,"LI",{});var IAe=s(y6);Yme=n(IAe,"STRONG",{});var ndt=s(Yme);rYo=r(ndt,"distilbert"),ndt.forEach(t),tYo=r(IAe," \u2014 "),kq=n(IAe,"A",{href:!0});var sdt=s(kq);aYo=r(sdt,"TFDistilBertModel"),sdt.forEach(t),nYo=r(IAe," (DistilBERT model)"),IAe.forEach(t),sYo=i(x),w6=n(x,"LI",{});var jAe=s(w6);Kme=n(jAe,"STRONG",{});var ldt=s(Kme);lYo=r(ldt,"dpr"),ldt.forEach(t),iYo=r(jAe," \u2014 "),Rq=n(jAe,"A",{href:!0});var idt=s(Rq);dYo=r(idt,"TFDPRQuestionEncoder"),idt.forEach(t),cYo=r(jAe," (DPR model)"),jAe.forEach(t),fYo=i(x),A6=n(x,"LI",{});var DAe=s(A6);Zme=n(DAe,"STRONG",{});var ddt=s(Zme);mYo=r(ddt,"electra"),ddt.forEach(t),gYo=r(DAe," \u2014 "),Sq=n(DAe,"A",{href:!0});var cdt=s(Sq);hYo=r(cdt,"TFElectraModel"),cdt.forEach(t),pYo=r(DAe," (ELECTRA model)"),DAe.forEach(t),_Yo=i(x),L6=n(x,"LI",{});var NAe=s(L6);ege=n(NAe,"STRONG",{});var fdt=s(ege);uYo=r(fdt,"flaubert"),fdt.forEach(t),bYo=r(NAe," \u2014 "),Pq=n(NAe,"A",{href:!0});var mdt=s(Pq);vYo=r(mdt,"TFFlaubertModel"),mdt.forEach(t),TYo=r(NAe," (FlauBERT model)"),NAe.forEach(t),FYo=i(x),Ws=n(x,"LI",{});var n9=s(Ws);oge=n(n9,"STRONG",{});var gdt=s(oge);CYo=r(gdt,"funnel"),gdt.forEach(t),MYo=r(n9," \u2014 "),$q=n(n9,"A",{href:!0});var hdt=s($q);EYo=r(hdt,"TFFunnelModel"),hdt.forEach(t),yYo=r(n9," or "),Iq=n(n9,"A",{href:!0});var pdt=s(Iq);wYo=r(pdt,"TFFunnelBaseModel"),pdt.forEach(t),AYo=r(n9," (Funnel Transformer model)"),n9.forEach(t),LYo=i(x),B6=n(x,"LI",{});var qAe=s(B6);rge=n(qAe,"STRONG",{});var _dt=s(rge);BYo=r(_dt,"gpt2"),_dt.forEach(t),xYo=r(qAe," \u2014 "),jq=n(qAe,"A",{href:!0});var udt=s(jq);kYo=r(udt,"TFGPT2Model"),udt.forEach(t),RYo=r(qAe," (OpenAI GPT-2 model)"),qAe.forEach(t),SYo=i(x),x6=n(x,"LI",{});var OAe=s(x6);tge=n(OAe,"STRONG",{});var bdt=s(tge);PYo=r(bdt,"hubert"),bdt.forEach(t),$Yo=r(OAe," \u2014 "),Dq=n(OAe,"A",{href:!0});var vdt=s(Dq);IYo=r(vdt,"TFHubertModel"),vdt.forEach(t),jYo=r(OAe," (Hubert model)"),OAe.forEach(t),DYo=i(x),k6=n(x,"LI",{});var GAe=s(k6);age=n(GAe,"STRONG",{});var Tdt=s(age);NYo=r(Tdt,"layoutlm"),Tdt.forEach(t),qYo=r(GAe," \u2014 "),Nq=n(GAe,"A",{href:!0});var Fdt=s(Nq);OYo=r(Fdt,"TFLayoutLMModel"),Fdt.forEach(t),GYo=r(GAe," (LayoutLM model)"),GAe.forEach(t),XYo=i(x),R6=n(x,"LI",{});var XAe=s(R6);nge=n(XAe,"STRONG",{});var Cdt=s(nge);VYo=r(Cdt,"led"),Cdt.forEach(t),zYo=r(XAe," \u2014 "),qq=n(XAe,"A",{href:!0});var Mdt=s(qq);WYo=r(Mdt,"TFLEDModel"),Mdt.forEach(t),QYo=r(XAe," (LED model)"),XAe.forEach(t),HYo=i(x),S6=n(x,"LI",{});var VAe=s(S6);sge=n(VAe,"STRONG",{});var Edt=s(sge);UYo=r(Edt,"longformer"),Edt.forEach(t),JYo=r(VAe," \u2014 "),Oq=n(VAe,"A",{href:!0});var ydt=s(Oq);YYo=r(ydt,"TFLongformerModel"),ydt.forEach(t),KYo=r(VAe," (Longformer model)"),VAe.forEach(t),ZYo=i(x),P6=n(x,"LI",{});var zAe=s(P6);lge=n(zAe,"STRONG",{});var wdt=s(lge);eKo=r(wdt,"lxmert"),wdt.forEach(t),oKo=r(zAe," \u2014 "),Gq=n(zAe,"A",{href:!0});var Adt=s(Gq);rKo=r(Adt,"TFLxmertModel"),Adt.forEach(t),tKo=r(zAe," (LXMERT model)"),zAe.forEach(t),aKo=i(x),$6=n(x,"LI",{});var WAe=s($6);ige=n(WAe,"STRONG",{});var Ldt=s(ige);nKo=r(Ldt,"marian"),Ldt.forEach(t),sKo=r(WAe," \u2014 "),Xq=n(WAe,"A",{href:!0});var Bdt=s(Xq);lKo=r(Bdt,"TFMarianModel"),Bdt.forEach(t),iKo=r(WAe," (Marian model)"),WAe.forEach(t),dKo=i(x),I6=n(x,"LI",{});var QAe=s(I6);dge=n(QAe,"STRONG",{});var xdt=s(dge);cKo=r(xdt,"mbart"),xdt.forEach(t),fKo=r(QAe," \u2014 "),Vq=n(QAe,"A",{href:!0});var kdt=s(Vq);mKo=r(kdt,"TFMBartModel"),kdt.forEach(t),gKo=r(QAe," (mBART model)"),QAe.forEach(t),hKo=i(x),j6=n(x,"LI",{});var HAe=s(j6);cge=n(HAe,"STRONG",{});var Rdt=s(cge);pKo=r(Rdt,"mobilebert"),Rdt.forEach(t),_Ko=r(HAe," \u2014 "),zq=n(HAe,"A",{href:!0});var Sdt=s(zq);uKo=r(Sdt,"TFMobileBertModel"),Sdt.forEach(t),bKo=r(HAe," (MobileBERT model)"),HAe.forEach(t),vKo=i(x),D6=n(x,"LI",{});var UAe=s(D6);fge=n(UAe,"STRONG",{});var Pdt=s(fge);TKo=r(Pdt,"mpnet"),Pdt.forEach(t),FKo=r(UAe," \u2014 "),Wq=n(UAe,"A",{href:!0});var $dt=s(Wq);CKo=r($dt,"TFMPNetModel"),$dt.forEach(t),MKo=r(UAe," (MPNet model)"),UAe.forEach(t),EKo=i(x),N6=n(x,"LI",{});var JAe=s(N6);mge=n(JAe,"STRONG",{});var Idt=s(mge);yKo=r(Idt,"mt5"),Idt.forEach(t),wKo=r(JAe," \u2014 "),Qq=n(JAe,"A",{href:!0});var jdt=s(Qq);AKo=r(jdt,"TFMT5Model"),jdt.forEach(t),LKo=r(JAe," (mT5 model)"),JAe.forEach(t),BKo=i(x),q6=n(x,"LI",{});var YAe=s(q6);gge=n(YAe,"STRONG",{});var Ddt=s(gge);xKo=r(Ddt,"openai-gpt"),Ddt.forEach(t),kKo=r(YAe," \u2014 "),Hq=n(YAe,"A",{href:!0});var Ndt=s(Hq);RKo=r(Ndt,"TFOpenAIGPTModel"),Ndt.forEach(t),SKo=r(YAe," (OpenAI GPT model)"),YAe.forEach(t),PKo=i(x),O6=n(x,"LI",{});var KAe=s(O6);hge=n(KAe,"STRONG",{});var qdt=s(hge);$Ko=r(qdt,"pegasus"),qdt.forEach(t),IKo=r(KAe," \u2014 "),Uq=n(KAe,"A",{href:!0});var Odt=s(Uq);jKo=r(Odt,"TFPegasusModel"),Odt.forEach(t),DKo=r(KAe," (Pegasus model)"),KAe.forEach(t),NKo=i(x),G6=n(x,"LI",{});var ZAe=s(G6);pge=n(ZAe,"STRONG",{});var Gdt=s(pge);qKo=r(Gdt,"rembert"),Gdt.forEach(t),OKo=r(ZAe," \u2014 "),Jq=n(ZAe,"A",{href:!0});var Xdt=s(Jq);GKo=r(Xdt,"TFRemBertModel"),Xdt.forEach(t),XKo=r(ZAe," (RemBERT model)"),ZAe.forEach(t),VKo=i(x),X6=n(x,"LI",{});var eLe=s(X6);_ge=n(eLe,"STRONG",{});var Vdt=s(_ge);zKo=r(Vdt,"roberta"),Vdt.forEach(t),WKo=r(eLe," \u2014 "),Yq=n(eLe,"A",{href:!0});var zdt=s(Yq);QKo=r(zdt,"TFRobertaModel"),zdt.forEach(t),HKo=r(eLe," (RoBERTa model)"),eLe.forEach(t),UKo=i(x),V6=n(x,"LI",{});var oLe=s(V6);uge=n(oLe,"STRONG",{});var Wdt=s(uge);JKo=r(Wdt,"roformer"),Wdt.forEach(t),YKo=r(oLe," \u2014 "),Kq=n(oLe,"A",{href:!0});var Qdt=s(Kq);KKo=r(Qdt,"TFRoFormerModel"),Qdt.forEach(t),ZKo=r(oLe," (RoFormer model)"),oLe.forEach(t),eZo=i(x),z6=n(x,"LI",{});var rLe=s(z6);bge=n(rLe,"STRONG",{});var Hdt=s(bge);oZo=r(Hdt,"speech_to_text"),Hdt.forEach(t),rZo=r(rLe," \u2014 "),Zq=n(rLe,"A",{href:!0});var Udt=s(Zq);tZo=r(Udt,"TFSpeech2TextModel"),Udt.forEach(t),aZo=r(rLe," (Speech2Text model)"),rLe.forEach(t),nZo=i(x),W6=n(x,"LI",{});var tLe=s(W6);vge=n(tLe,"STRONG",{});var Jdt=s(vge);sZo=r(Jdt,"t5"),Jdt.forEach(t),lZo=r(tLe," \u2014 "),eO=n(tLe,"A",{href:!0});var Ydt=s(eO);iZo=r(Ydt,"TFT5Model"),Ydt.forEach(t),dZo=r(tLe," (T5 model)"),tLe.forEach(t),cZo=i(x),Q6=n(x,"LI",{});var aLe=s(Q6);Tge=n(aLe,"STRONG",{});var Kdt=s(Tge);fZo=r(Kdt,"tapas"),Kdt.forEach(t),mZo=r(aLe," \u2014 "),oO=n(aLe,"A",{href:!0});var Zdt=s(oO);gZo=r(Zdt,"TFTapasModel"),Zdt.forEach(t),hZo=r(aLe," (TAPAS model)"),aLe.forEach(t),pZo=i(x),H6=n(x,"LI",{});var nLe=s(H6);Fge=n(nLe,"STRONG",{});var ect=s(Fge);_Zo=r(ect,"transfo-xl"),ect.forEach(t),uZo=r(nLe," \u2014 "),rO=n(nLe,"A",{href:!0});var oct=s(rO);bZo=r(oct,"TFTransfoXLModel"),oct.forEach(t),vZo=r(nLe," (Transformer-XL model)"),nLe.forEach(t),TZo=i(x),U6=n(x,"LI",{});var sLe=s(U6);Cge=n(sLe,"STRONG",{});var rct=s(Cge);FZo=r(rct,"vit"),rct.forEach(t),CZo=r(sLe," \u2014 "),tO=n(sLe,"A",{href:!0});var tct=s(tO);MZo=r(tct,"TFViTModel"),tct.forEach(t),EZo=r(sLe," (ViT model)"),sLe.forEach(t),yZo=i(x),J6=n(x,"LI",{});var lLe=s(J6);Mge=n(lLe,"STRONG",{});var act=s(Mge);wZo=r(act,"wav2vec2"),act.forEach(t),AZo=r(lLe," \u2014 "),aO=n(lLe,"A",{href:!0});var nct=s(aO);LZo=r(nct,"TFWav2Vec2Model"),nct.forEach(t),BZo=r(lLe," (Wav2Vec2 model)"),lLe.forEach(t),xZo=i(x),Y6=n(x,"LI",{});var iLe=s(Y6);Ege=n(iLe,"STRONG",{});var sct=s(Ege);kZo=r(sct,"xlm"),sct.forEach(t),RZo=r(iLe," \u2014 "),nO=n(iLe,"A",{href:!0});var lct=s(nO);SZo=r(lct,"TFXLMModel"),lct.forEach(t),PZo=r(iLe," (XLM model)"),iLe.forEach(t),$Zo=i(x),K6=n(x,"LI",{});var dLe=s(K6);yge=n(dLe,"STRONG",{});var ict=s(yge);IZo=r(ict,"xlm-roberta"),ict.forEach(t),jZo=r(dLe," \u2014 "),sO=n(dLe,"A",{href:!0});var dct=s(sO);DZo=r(dct,"TFXLMRobertaModel"),dct.forEach(t),NZo=r(dLe," (XLM-RoBERTa model)"),dLe.forEach(t),qZo=i(x),Z6=n(x,"LI",{});var cLe=s(Z6);wge=n(cLe,"STRONG",{});var cct=s(wge);OZo=r(cct,"xlnet"),cct.forEach(t),GZo=r(cLe," \u2014 "),lO=n(cLe,"A",{href:!0});var fct=s(lO);XZo=r(fct,"TFXLNetModel"),fct.forEach(t),VZo=r(cLe," (XLNet model)"),cLe.forEach(t),x.forEach(t),zZo=i(ba),Age=n(ba,"P",{});var mct=s(Age);WZo=r(mct,"Examples:"),mct.forEach(t),QZo=i(ba),m(Qy.$$.fragment,ba),ba.forEach(t),Vl.forEach(t),Zke=i(d),Mc=n(d,"H2",{class:!0});var mPe=s(Mc);e0=n(mPe,"A",{id:!0,class:!0,href:!0});var gct=s(e0);Lge=n(gct,"SPAN",{});var hct=s(Lge);m(Hy.$$.fragment,hct),hct.forEach(t),gct.forEach(t),HZo=i(mPe),Bge=n(mPe,"SPAN",{});var pct=s(Bge);UZo=r(pct,"TFAutoModelForPreTraining"),pct.forEach(t),mPe.forEach(t),eRe=i(d),Fr=n(d,"DIV",{class:!0});var Wl=s(Fr);m(Uy.$$.fragment,Wl),JZo=i(Wl),Ec=n(Wl,"P",{});var OW=s(Ec);YZo=r(OW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),xge=n(OW,"CODE",{});var _ct=s(xge);KZo=r(_ct,"from_pretrained()"),_ct.forEach(t),ZZo=r(OW,"class method or the "),kge=n(OW,"CODE",{});var uct=s(kge);eer=r(uct,"from_config()"),uct.forEach(t),oer=r(OW,`class
method.`),OW.forEach(t),rer=i(Wl),Jy=n(Wl,"P",{});var gPe=s(Jy);ter=r(gPe,"This class cannot be instantiated directly using "),Rge=n(gPe,"CODE",{});var bct=s(Rge);aer=r(bct,"__init__()"),bct.forEach(t),ner=r(gPe," (throws an error)."),gPe.forEach(t),ser=i(Wl),_t=n(Wl,"DIV",{class:!0});var Ql=s(_t);m(Yy.$$.fragment,Ql),ler=i(Ql),Sge=n(Ql,"P",{});var vct=s(Sge);ier=r(vct,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),vct.forEach(t),der=i(Ql),yc=n(Ql,"P",{});var GW=s(yc);cer=r(GW,`Note:
Loading a model from its configuration file does `),Pge=n(GW,"STRONG",{});var Tct=s(Pge);fer=r(Tct,"not"),Tct.forEach(t),mer=r(GW,` load the model weights. It only affects the
model\u2019s configuration. Use `),$ge=n(GW,"CODE",{});var Fct=s($ge);ger=r(Fct,"from_pretrained()"),Fct.forEach(t),her=r(GW,"to load the model weights."),GW.forEach(t),per=i(Ql),Ige=n(Ql,"P",{});var Cct=s(Ige);_er=r(Cct,"Examples:"),Cct.forEach(t),uer=i(Ql),m(Ky.$$.fragment,Ql),Ql.forEach(t),ber=i(Wl),po=n(Wl,"DIV",{class:!0});var va=s(po);m(Zy.$$.fragment,va),ver=i(va),jge=n(va,"P",{});var Mct=s(jge);Ter=r(Mct,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Mct.forEach(t),Fer=i(va),Fn=n(va,"P",{});var $M=s(Fn);Cer=r($M,"The model class to instantiate is selected based on the "),Dge=n($M,"CODE",{});var Ect=s(Dge);Mer=r(Ect,"model_type"),Ect.forEach(t),Eer=r($M,` property of the config object (either
passed as an argument or loaded from `),Nge=n($M,"CODE",{});var yct=s(Nge);yer=r(yct,"pretrained_model_name_or_path"),yct.forEach(t),wer=r($M,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qge=n($M,"CODE",{});var wct=s(qge);Aer=r(wct,"pretrained_model_name_or_path"),wct.forEach(t),Ler=r($M,":"),$M.forEach(t),Ber=i(va),H=n(va,"UL",{});var U=s(H);o0=n(U,"LI",{});var fLe=s(o0);Oge=n(fLe,"STRONG",{});var Act=s(Oge);xer=r(Act,"albert"),Act.forEach(t),ker=r(fLe," \u2014 "),iO=n(fLe,"A",{href:!0});var Lct=s(iO);Rer=r(Lct,"TFAlbertForPreTraining"),Lct.forEach(t),Ser=r(fLe," (ALBERT model)"),fLe.forEach(t),Per=i(U),r0=n(U,"LI",{});var mLe=s(r0);Gge=n(mLe,"STRONG",{});var Bct=s(Gge);$er=r(Bct,"bart"),Bct.forEach(t),Ier=r(mLe," \u2014 "),dO=n(mLe,"A",{href:!0});var xct=s(dO);jer=r(xct,"TFBartForConditionalGeneration"),xct.forEach(t),Der=r(mLe," (BART model)"),mLe.forEach(t),Ner=i(U),t0=n(U,"LI",{});var gLe=s(t0);Xge=n(gLe,"STRONG",{});var kct=s(Xge);qer=r(kct,"bert"),kct.forEach(t),Oer=r(gLe," \u2014 "),cO=n(gLe,"A",{href:!0});var Rct=s(cO);Ger=r(Rct,"TFBertForPreTraining"),Rct.forEach(t),Xer=r(gLe," (BERT model)"),gLe.forEach(t),Ver=i(U),a0=n(U,"LI",{});var hLe=s(a0);Vge=n(hLe,"STRONG",{});var Sct=s(Vge);zer=r(Sct,"camembert"),Sct.forEach(t),Wer=r(hLe," \u2014 "),fO=n(hLe,"A",{href:!0});var Pct=s(fO);Qer=r(Pct,"TFCamembertForMaskedLM"),Pct.forEach(t),Her=r(hLe," (CamemBERT model)"),hLe.forEach(t),Uer=i(U),n0=n(U,"LI",{});var pLe=s(n0);zge=n(pLe,"STRONG",{});var $ct=s(zge);Jer=r($ct,"ctrl"),$ct.forEach(t),Yer=r(pLe," \u2014 "),mO=n(pLe,"A",{href:!0});var Ict=s(mO);Ker=r(Ict,"TFCTRLLMHeadModel"),Ict.forEach(t),Zer=r(pLe," (CTRL model)"),pLe.forEach(t),eor=i(U),s0=n(U,"LI",{});var _Le=s(s0);Wge=n(_Le,"STRONG",{});var jct=s(Wge);oor=r(jct,"distilbert"),jct.forEach(t),ror=r(_Le," \u2014 "),gO=n(_Le,"A",{href:!0});var Dct=s(gO);tor=r(Dct,"TFDistilBertForMaskedLM"),Dct.forEach(t),aor=r(_Le," (DistilBERT model)"),_Le.forEach(t),nor=i(U),l0=n(U,"LI",{});var uLe=s(l0);Qge=n(uLe,"STRONG",{});var Nct=s(Qge);sor=r(Nct,"electra"),Nct.forEach(t),lor=r(uLe," \u2014 "),hO=n(uLe,"A",{href:!0});var qct=s(hO);ior=r(qct,"TFElectraForPreTraining"),qct.forEach(t),dor=r(uLe," (ELECTRA model)"),uLe.forEach(t),cor=i(U),i0=n(U,"LI",{});var bLe=s(i0);Hge=n(bLe,"STRONG",{});var Oct=s(Hge);mor=r(Oct,"flaubert"),Oct.forEach(t),gor=r(bLe," \u2014 "),pO=n(bLe,"A",{href:!0});var Gct=s(pO);hor=r(Gct,"TFFlaubertWithLMHeadModel"),Gct.forEach(t),por=r(bLe," (FlauBERT model)"),bLe.forEach(t),_or=i(U),d0=n(U,"LI",{});var vLe=s(d0);Uge=n(vLe,"STRONG",{});var Xct=s(Uge);uor=r(Xct,"funnel"),Xct.forEach(t),bor=r(vLe," \u2014 "),_O=n(vLe,"A",{href:!0});var Vct=s(_O);vor=r(Vct,"TFFunnelForPreTraining"),Vct.forEach(t),Tor=r(vLe," (Funnel Transformer model)"),vLe.forEach(t),For=i(U),c0=n(U,"LI",{});var TLe=s(c0);Jge=n(TLe,"STRONG",{});var zct=s(Jge);Cor=r(zct,"gpt2"),zct.forEach(t),Mor=r(TLe," \u2014 "),uO=n(TLe,"A",{href:!0});var Wct=s(uO);Eor=r(Wct,"TFGPT2LMHeadModel"),Wct.forEach(t),yor=r(TLe," (OpenAI GPT-2 model)"),TLe.forEach(t),wor=i(U),f0=n(U,"LI",{});var FLe=s(f0);Yge=n(FLe,"STRONG",{});var Qct=s(Yge);Aor=r(Qct,"layoutlm"),Qct.forEach(t),Lor=r(FLe," \u2014 "),bO=n(FLe,"A",{href:!0});var Hct=s(bO);Bor=r(Hct,"TFLayoutLMForMaskedLM"),Hct.forEach(t),xor=r(FLe," (LayoutLM model)"),FLe.forEach(t),kor=i(U),m0=n(U,"LI",{});var CLe=s(m0);Kge=n(CLe,"STRONG",{});var Uct=s(Kge);Ror=r(Uct,"lxmert"),Uct.forEach(t),Sor=r(CLe," \u2014 "),vO=n(CLe,"A",{href:!0});var Jct=s(vO);Por=r(Jct,"TFLxmertForPreTraining"),Jct.forEach(t),$or=r(CLe," (LXMERT model)"),CLe.forEach(t),Ior=i(U),g0=n(U,"LI",{});var MLe=s(g0);Zge=n(MLe,"STRONG",{});var Yct=s(Zge);jor=r(Yct,"mobilebert"),Yct.forEach(t),Dor=r(MLe," \u2014 "),TO=n(MLe,"A",{href:!0});var Kct=s(TO);Nor=r(Kct,"TFMobileBertForPreTraining"),Kct.forEach(t),qor=r(MLe," (MobileBERT model)"),MLe.forEach(t),Oor=i(U),h0=n(U,"LI",{});var ELe=s(h0);ehe=n(ELe,"STRONG",{});var Zct=s(ehe);Gor=r(Zct,"mpnet"),Zct.forEach(t),Xor=r(ELe," \u2014 "),FO=n(ELe,"A",{href:!0});var eft=s(FO);Vor=r(eft,"TFMPNetForMaskedLM"),eft.forEach(t),zor=r(ELe," (MPNet model)"),ELe.forEach(t),Wor=i(U),p0=n(U,"LI",{});var yLe=s(p0);ohe=n(yLe,"STRONG",{});var oft=s(ohe);Qor=r(oft,"openai-gpt"),oft.forEach(t),Hor=r(yLe," \u2014 "),CO=n(yLe,"A",{href:!0});var rft=s(CO);Uor=r(rft,"TFOpenAIGPTLMHeadModel"),rft.forEach(t),Jor=r(yLe," (OpenAI GPT model)"),yLe.forEach(t),Yor=i(U),_0=n(U,"LI",{});var wLe=s(_0);rhe=n(wLe,"STRONG",{});var tft=s(rhe);Kor=r(tft,"roberta"),tft.forEach(t),Zor=r(wLe," \u2014 "),MO=n(wLe,"A",{href:!0});var aft=s(MO);err=r(aft,"TFRobertaForMaskedLM"),aft.forEach(t),orr=r(wLe," (RoBERTa model)"),wLe.forEach(t),rrr=i(U),u0=n(U,"LI",{});var ALe=s(u0);the=n(ALe,"STRONG",{});var nft=s(the);trr=r(nft,"t5"),nft.forEach(t),arr=r(ALe," \u2014 "),EO=n(ALe,"A",{href:!0});var sft=s(EO);nrr=r(sft,"TFT5ForConditionalGeneration"),sft.forEach(t),srr=r(ALe," (T5 model)"),ALe.forEach(t),lrr=i(U),b0=n(U,"LI",{});var LLe=s(b0);ahe=n(LLe,"STRONG",{});var lft=s(ahe);irr=r(lft,"tapas"),lft.forEach(t),drr=r(LLe," \u2014 "),yO=n(LLe,"A",{href:!0});var ift=s(yO);crr=r(ift,"TFTapasForMaskedLM"),ift.forEach(t),frr=r(LLe," (TAPAS model)"),LLe.forEach(t),mrr=i(U),v0=n(U,"LI",{});var BLe=s(v0);nhe=n(BLe,"STRONG",{});var dft=s(nhe);grr=r(dft,"transfo-xl"),dft.forEach(t),hrr=r(BLe," \u2014 "),wO=n(BLe,"A",{href:!0});var cft=s(wO);prr=r(cft,"TFTransfoXLLMHeadModel"),cft.forEach(t),_rr=r(BLe," (Transformer-XL model)"),BLe.forEach(t),urr=i(U),T0=n(U,"LI",{});var xLe=s(T0);she=n(xLe,"STRONG",{});var fft=s(she);brr=r(fft,"xlm"),fft.forEach(t),vrr=r(xLe," \u2014 "),AO=n(xLe,"A",{href:!0});var mft=s(AO);Trr=r(mft,"TFXLMWithLMHeadModel"),mft.forEach(t),Frr=r(xLe," (XLM model)"),xLe.forEach(t),Crr=i(U),F0=n(U,"LI",{});var kLe=s(F0);lhe=n(kLe,"STRONG",{});var gft=s(lhe);Mrr=r(gft,"xlm-roberta"),gft.forEach(t),Err=r(kLe," \u2014 "),LO=n(kLe,"A",{href:!0});var hft=s(LO);yrr=r(hft,"TFXLMRobertaForMaskedLM"),hft.forEach(t),wrr=r(kLe," (XLM-RoBERTa model)"),kLe.forEach(t),Arr=i(U),C0=n(U,"LI",{});var RLe=s(C0);ihe=n(RLe,"STRONG",{});var pft=s(ihe);Lrr=r(pft,"xlnet"),pft.forEach(t),Brr=r(RLe," \u2014 "),BO=n(RLe,"A",{href:!0});var _ft=s(BO);xrr=r(_ft,"TFXLNetLMHeadModel"),_ft.forEach(t),krr=r(RLe," (XLNet model)"),RLe.forEach(t),U.forEach(t),Rrr=i(va),dhe=n(va,"P",{});var uft=s(dhe);Srr=r(uft,"Examples:"),uft.forEach(t),Prr=i(va),m(ew.$$.fragment,va),va.forEach(t),Wl.forEach(t),oRe=i(d),wc=n(d,"H2",{class:!0});var hPe=s(wc);M0=n(hPe,"A",{id:!0,class:!0,href:!0});var bft=s(M0);che=n(bft,"SPAN",{});var vft=s(che);m(ow.$$.fragment,vft),vft.forEach(t),bft.forEach(t),$rr=i(hPe),fhe=n(hPe,"SPAN",{});var Tft=s(fhe);Irr=r(Tft,"TFAutoModelForCausalLM"),Tft.forEach(t),hPe.forEach(t),rRe=i(d),Cr=n(d,"DIV",{class:!0});var Hl=s(Cr);m(rw.$$.fragment,Hl),jrr=i(Hl),Ac=n(Hl,"P",{});var XW=s(Ac);Drr=r(XW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),mhe=n(XW,"CODE",{});var Fft=s(mhe);Nrr=r(Fft,"from_pretrained()"),Fft.forEach(t),qrr=r(XW,"class method or the "),ghe=n(XW,"CODE",{});var Cft=s(ghe);Orr=r(Cft,"from_config()"),Cft.forEach(t),Grr=r(XW,`class
method.`),XW.forEach(t),Xrr=i(Hl),tw=n(Hl,"P",{});var pPe=s(tw);Vrr=r(pPe,"This class cannot be instantiated directly using "),hhe=n(pPe,"CODE",{});var Mft=s(hhe);zrr=r(Mft,"__init__()"),Mft.forEach(t),Wrr=r(pPe," (throws an error)."),pPe.forEach(t),Qrr=i(Hl),ut=n(Hl,"DIV",{class:!0});var Ul=s(ut);m(aw.$$.fragment,Ul),Hrr=i(Ul),phe=n(Ul,"P",{});var Eft=s(phe);Urr=r(Eft,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Eft.forEach(t),Jrr=i(Ul),Lc=n(Ul,"P",{});var VW=s(Lc);Yrr=r(VW,`Note:
Loading a model from its configuration file does `),_he=n(VW,"STRONG",{});var yft=s(_he);Krr=r(yft,"not"),yft.forEach(t),Zrr=r(VW,` load the model weights. It only affects the
model\u2019s configuration. Use `),uhe=n(VW,"CODE",{});var wft=s(uhe);etr=r(wft,"from_pretrained()"),wft.forEach(t),otr=r(VW,"to load the model weights."),VW.forEach(t),rtr=i(Ul),bhe=n(Ul,"P",{});var Aft=s(bhe);ttr=r(Aft,"Examples:"),Aft.forEach(t),atr=i(Ul),m(nw.$$.fragment,Ul),Ul.forEach(t),ntr=i(Hl),_o=n(Hl,"DIV",{class:!0});var Ta=s(_o);m(sw.$$.fragment,Ta),str=i(Ta),vhe=n(Ta,"P",{});var Lft=s(vhe);ltr=r(Lft,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Lft.forEach(t),itr=i(Ta),Cn=n(Ta,"P",{});var IM=s(Cn);dtr=r(IM,"The model class to instantiate is selected based on the "),The=n(IM,"CODE",{});var Bft=s(The);ctr=r(Bft,"model_type"),Bft.forEach(t),ftr=r(IM,` property of the config object (either
passed as an argument or loaded from `),Fhe=n(IM,"CODE",{});var xft=s(Fhe);mtr=r(xft,"pretrained_model_name_or_path"),xft.forEach(t),gtr=r(IM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Che=n(IM,"CODE",{});var kft=s(Che);htr=r(kft,"pretrained_model_name_or_path"),kft.forEach(t),ptr=r(IM,":"),IM.forEach(t),_tr=i(Ta),me=n(Ta,"UL",{});var Te=s(me);E0=n(Te,"LI",{});var SLe=s(E0);Mhe=n(SLe,"STRONG",{});var Rft=s(Mhe);utr=r(Rft,"bert"),Rft.forEach(t),btr=r(SLe," \u2014 "),xO=n(SLe,"A",{href:!0});var Sft=s(xO);vtr=r(Sft,"TFBertLMHeadModel"),Sft.forEach(t),Ttr=r(SLe," (BERT model)"),SLe.forEach(t),Ftr=i(Te),y0=n(Te,"LI",{});var PLe=s(y0);Ehe=n(PLe,"STRONG",{});var Pft=s(Ehe);Ctr=r(Pft,"camembert"),Pft.forEach(t),Mtr=r(PLe," \u2014 "),kO=n(PLe,"A",{href:!0});var $ft=s(kO);Etr=r($ft,"TFCamembertForCausalLM"),$ft.forEach(t),ytr=r(PLe," (CamemBERT model)"),PLe.forEach(t),wtr=i(Te),w0=n(Te,"LI",{});var $Le=s(w0);yhe=n($Le,"STRONG",{});var Ift=s(yhe);Atr=r(Ift,"ctrl"),Ift.forEach(t),Ltr=r($Le," \u2014 "),RO=n($Le,"A",{href:!0});var jft=s(RO);Btr=r(jft,"TFCTRLLMHeadModel"),jft.forEach(t),xtr=r($Le," (CTRL model)"),$Le.forEach(t),ktr=i(Te),A0=n(Te,"LI",{});var ILe=s(A0);whe=n(ILe,"STRONG",{});var Dft=s(whe);Rtr=r(Dft,"gpt2"),Dft.forEach(t),Str=r(ILe," \u2014 "),SO=n(ILe,"A",{href:!0});var Nft=s(SO);Ptr=r(Nft,"TFGPT2LMHeadModel"),Nft.forEach(t),$tr=r(ILe," (OpenAI GPT-2 model)"),ILe.forEach(t),Itr=i(Te),L0=n(Te,"LI",{});var jLe=s(L0);Ahe=n(jLe,"STRONG",{});var qft=s(Ahe);jtr=r(qft,"openai-gpt"),qft.forEach(t),Dtr=r(jLe," \u2014 "),PO=n(jLe,"A",{href:!0});var Oft=s(PO);Ntr=r(Oft,"TFOpenAIGPTLMHeadModel"),Oft.forEach(t),qtr=r(jLe," (OpenAI GPT model)"),jLe.forEach(t),Otr=i(Te),B0=n(Te,"LI",{});var DLe=s(B0);Lhe=n(DLe,"STRONG",{});var Gft=s(Lhe);Gtr=r(Gft,"rembert"),Gft.forEach(t),Xtr=r(DLe," \u2014 "),$O=n(DLe,"A",{href:!0});var Xft=s($O);Vtr=r(Xft,"TFRemBertForCausalLM"),Xft.forEach(t),ztr=r(DLe," (RemBERT model)"),DLe.forEach(t),Wtr=i(Te),x0=n(Te,"LI",{});var NLe=s(x0);Bhe=n(NLe,"STRONG",{});var Vft=s(Bhe);Qtr=r(Vft,"roberta"),Vft.forEach(t),Htr=r(NLe," \u2014 "),IO=n(NLe,"A",{href:!0});var zft=s(IO);Utr=r(zft,"TFRobertaForCausalLM"),zft.forEach(t),Jtr=r(NLe," (RoBERTa model)"),NLe.forEach(t),Ytr=i(Te),k0=n(Te,"LI",{});var qLe=s(k0);xhe=n(qLe,"STRONG",{});var Wft=s(xhe);Ktr=r(Wft,"roformer"),Wft.forEach(t),Ztr=r(qLe," \u2014 "),jO=n(qLe,"A",{href:!0});var Qft=s(jO);ear=r(Qft,"TFRoFormerForCausalLM"),Qft.forEach(t),oar=r(qLe," (RoFormer model)"),qLe.forEach(t),rar=i(Te),R0=n(Te,"LI",{});var OLe=s(R0);khe=n(OLe,"STRONG",{});var Hft=s(khe);tar=r(Hft,"transfo-xl"),Hft.forEach(t),aar=r(OLe," \u2014 "),DO=n(OLe,"A",{href:!0});var Uft=s(DO);nar=r(Uft,"TFTransfoXLLMHeadModel"),Uft.forEach(t),sar=r(OLe," (Transformer-XL model)"),OLe.forEach(t),lar=i(Te),S0=n(Te,"LI",{});var GLe=s(S0);Rhe=n(GLe,"STRONG",{});var Jft=s(Rhe);iar=r(Jft,"xlm"),Jft.forEach(t),dar=r(GLe," \u2014 "),NO=n(GLe,"A",{href:!0});var Yft=s(NO);car=r(Yft,"TFXLMWithLMHeadModel"),Yft.forEach(t),far=r(GLe," (XLM model)"),GLe.forEach(t),mar=i(Te),P0=n(Te,"LI",{});var XLe=s(P0);She=n(XLe,"STRONG",{});var Kft=s(She);gar=r(Kft,"xlnet"),Kft.forEach(t),har=r(XLe," \u2014 "),qO=n(XLe,"A",{href:!0});var Zft=s(qO);par=r(Zft,"TFXLNetLMHeadModel"),Zft.forEach(t),_ar=r(XLe," (XLNet model)"),XLe.forEach(t),Te.forEach(t),uar=i(Ta),Phe=n(Ta,"P",{});var emt=s(Phe);bar=r(emt,"Examples:"),emt.forEach(t),Tar=i(Ta),m(lw.$$.fragment,Ta),Ta.forEach(t),Hl.forEach(t),tRe=i(d),Bc=n(d,"H2",{class:!0});var _Pe=s(Bc);$0=n(_Pe,"A",{id:!0,class:!0,href:!0});var omt=s($0);$he=n(omt,"SPAN",{});var rmt=s($he);m(iw.$$.fragment,rmt),rmt.forEach(t),omt.forEach(t),Far=i(_Pe),Ihe=n(_Pe,"SPAN",{});var tmt=s(Ihe);Car=r(tmt,"TFAutoModelForImageClassification"),tmt.forEach(t),_Pe.forEach(t),aRe=i(d),Mr=n(d,"DIV",{class:!0});var Jl=s(Mr);m(dw.$$.fragment,Jl),Mar=i(Jl),xc=n(Jl,"P",{});var zW=s(xc);Ear=r(zW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),jhe=n(zW,"CODE",{});var amt=s(jhe);yar=r(amt,"from_pretrained()"),amt.forEach(t),war=r(zW,"class method or the "),Dhe=n(zW,"CODE",{});var nmt=s(Dhe);Aar=r(nmt,"from_config()"),nmt.forEach(t),Lar=r(zW,`class
method.`),zW.forEach(t),Bar=i(Jl),cw=n(Jl,"P",{});var uPe=s(cw);xar=r(uPe,"This class cannot be instantiated directly using "),Nhe=n(uPe,"CODE",{});var smt=s(Nhe);kar=r(smt,"__init__()"),smt.forEach(t),Rar=r(uPe," (throws an error)."),uPe.forEach(t),Sar=i(Jl),bt=n(Jl,"DIV",{class:!0});var Yl=s(bt);m(fw.$$.fragment,Yl),Par=i(Yl),qhe=n(Yl,"P",{});var lmt=s(qhe);$ar=r(lmt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),lmt.forEach(t),Iar=i(Yl),kc=n(Yl,"P",{});var WW=s(kc);jar=r(WW,`Note:
Loading a model from its configuration file does `),Ohe=n(WW,"STRONG",{});var imt=s(Ohe);Dar=r(imt,"not"),imt.forEach(t),Nar=r(WW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ghe=n(WW,"CODE",{});var dmt=s(Ghe);qar=r(dmt,"from_pretrained()"),dmt.forEach(t),Oar=r(WW,"to load the model weights."),WW.forEach(t),Gar=i(Yl),Xhe=n(Yl,"P",{});var cmt=s(Xhe);Xar=r(cmt,"Examples:"),cmt.forEach(t),Var=i(Yl),m(mw.$$.fragment,Yl),Yl.forEach(t),zar=i(Jl),uo=n(Jl,"DIV",{class:!0});var Fa=s(uo);m(gw.$$.fragment,Fa),War=i(Fa),Vhe=n(Fa,"P",{});var fmt=s(Vhe);Qar=r(fmt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),fmt.forEach(t),Har=i(Fa),Mn=n(Fa,"P",{});var jM=s(Mn);Uar=r(jM,"The model class to instantiate is selected based on the "),zhe=n(jM,"CODE",{});var mmt=s(zhe);Jar=r(mmt,"model_type"),mmt.forEach(t),Yar=r(jM,` property of the config object (either
passed as an argument or loaded from `),Whe=n(jM,"CODE",{});var gmt=s(Whe);Kar=r(gmt,"pretrained_model_name_or_path"),gmt.forEach(t),Zar=r(jM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qhe=n(jM,"CODE",{});var hmt=s(Qhe);enr=r(hmt,"pretrained_model_name_or_path"),hmt.forEach(t),onr=r(jM,":"),jM.forEach(t),rnr=i(Fa),hw=n(Fa,"UL",{});var bPe=s(hw);I0=n(bPe,"LI",{});var VLe=s(I0);Hhe=n(VLe,"STRONG",{});var pmt=s(Hhe);tnr=r(pmt,"convnext"),pmt.forEach(t),anr=r(VLe," \u2014 "),OO=n(VLe,"A",{href:!0});var _mt=s(OO);nnr=r(_mt,"TFConvNextForImageClassification"),_mt.forEach(t),snr=r(VLe," (ConvNext model)"),VLe.forEach(t),lnr=i(bPe),j0=n(bPe,"LI",{});var zLe=s(j0);Uhe=n(zLe,"STRONG",{});var umt=s(Uhe);inr=r(umt,"vit"),umt.forEach(t),dnr=r(zLe," \u2014 "),GO=n(zLe,"A",{href:!0});var bmt=s(GO);cnr=r(bmt,"TFViTForImageClassification"),bmt.forEach(t),fnr=r(zLe," (ViT model)"),zLe.forEach(t),bPe.forEach(t),mnr=i(Fa),Jhe=n(Fa,"P",{});var vmt=s(Jhe);gnr=r(vmt,"Examples:"),vmt.forEach(t),hnr=i(Fa),m(pw.$$.fragment,Fa),Fa.forEach(t),Jl.forEach(t),nRe=i(d),Rc=n(d,"H2",{class:!0});var vPe=s(Rc);D0=n(vPe,"A",{id:!0,class:!0,href:!0});var Tmt=s(D0);Yhe=n(Tmt,"SPAN",{});var Fmt=s(Yhe);m(_w.$$.fragment,Fmt),Fmt.forEach(t),Tmt.forEach(t),pnr=i(vPe),Khe=n(vPe,"SPAN",{});var Cmt=s(Khe);_nr=r(Cmt,"TFAutoModelForMaskedLM"),Cmt.forEach(t),vPe.forEach(t),sRe=i(d),Er=n(d,"DIV",{class:!0});var Kl=s(Er);m(uw.$$.fragment,Kl),unr=i(Kl),Sc=n(Kl,"P",{});var QW=s(Sc);bnr=r(QW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Zhe=n(QW,"CODE",{});var Mmt=s(Zhe);vnr=r(Mmt,"from_pretrained()"),Mmt.forEach(t),Tnr=r(QW,"class method or the "),epe=n(QW,"CODE",{});var Emt=s(epe);Fnr=r(Emt,"from_config()"),Emt.forEach(t),Cnr=r(QW,`class
method.`),QW.forEach(t),Mnr=i(Kl),bw=n(Kl,"P",{});var TPe=s(bw);Enr=r(TPe,"This class cannot be instantiated directly using "),ope=n(TPe,"CODE",{});var ymt=s(ope);ynr=r(ymt,"__init__()"),ymt.forEach(t),wnr=r(TPe," (throws an error)."),TPe.forEach(t),Anr=i(Kl),vt=n(Kl,"DIV",{class:!0});var Zl=s(vt);m(vw.$$.fragment,Zl),Lnr=i(Zl),rpe=n(Zl,"P",{});var wmt=s(rpe);Bnr=r(wmt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),wmt.forEach(t),xnr=i(Zl),Pc=n(Zl,"P",{});var HW=s(Pc);knr=r(HW,`Note:
Loading a model from its configuration file does `),tpe=n(HW,"STRONG",{});var Amt=s(tpe);Rnr=r(Amt,"not"),Amt.forEach(t),Snr=r(HW,` load the model weights. It only affects the
model\u2019s configuration. Use `),ape=n(HW,"CODE",{});var Lmt=s(ape);Pnr=r(Lmt,"from_pretrained()"),Lmt.forEach(t),$nr=r(HW,"to load the model weights."),HW.forEach(t),Inr=i(Zl),npe=n(Zl,"P",{});var Bmt=s(npe);jnr=r(Bmt,"Examples:"),Bmt.forEach(t),Dnr=i(Zl),m(Tw.$$.fragment,Zl),Zl.forEach(t),Nnr=i(Kl),bo=n(Kl,"DIV",{class:!0});var Ca=s(bo);m(Fw.$$.fragment,Ca),qnr=i(Ca),spe=n(Ca,"P",{});var xmt=s(spe);Onr=r(xmt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),xmt.forEach(t),Gnr=i(Ca),En=n(Ca,"P",{});var DM=s(En);Xnr=r(DM,"The model class to instantiate is selected based on the "),lpe=n(DM,"CODE",{});var kmt=s(lpe);Vnr=r(kmt,"model_type"),kmt.forEach(t),znr=r(DM,` property of the config object (either
passed as an argument or loaded from `),ipe=n(DM,"CODE",{});var Rmt=s(ipe);Wnr=r(Rmt,"pretrained_model_name_or_path"),Rmt.forEach(t),Qnr=r(DM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dpe=n(DM,"CODE",{});var Smt=s(dpe);Hnr=r(Smt,"pretrained_model_name_or_path"),Smt.forEach(t),Unr=r(DM,":"),DM.forEach(t),Jnr=i(Ca),Y=n(Ca,"UL",{});var ee=s(Y);N0=n(ee,"LI",{});var WLe=s(N0);cpe=n(WLe,"STRONG",{});var Pmt=s(cpe);Ynr=r(Pmt,"albert"),Pmt.forEach(t),Knr=r(WLe," \u2014 "),XO=n(WLe,"A",{href:!0});var $mt=s(XO);Znr=r($mt,"TFAlbertForMaskedLM"),$mt.forEach(t),esr=r(WLe," (ALBERT model)"),WLe.forEach(t),osr=i(ee),q0=n(ee,"LI",{});var QLe=s(q0);fpe=n(QLe,"STRONG",{});var Imt=s(fpe);rsr=r(Imt,"bert"),Imt.forEach(t),tsr=r(QLe," \u2014 "),VO=n(QLe,"A",{href:!0});var jmt=s(VO);asr=r(jmt,"TFBertForMaskedLM"),jmt.forEach(t),nsr=r(QLe," (BERT model)"),QLe.forEach(t),ssr=i(ee),O0=n(ee,"LI",{});var HLe=s(O0);mpe=n(HLe,"STRONG",{});var Dmt=s(mpe);lsr=r(Dmt,"camembert"),Dmt.forEach(t),isr=r(HLe," \u2014 "),zO=n(HLe,"A",{href:!0});var Nmt=s(zO);dsr=r(Nmt,"TFCamembertForMaskedLM"),Nmt.forEach(t),csr=r(HLe," (CamemBERT model)"),HLe.forEach(t),fsr=i(ee),G0=n(ee,"LI",{});var ULe=s(G0);gpe=n(ULe,"STRONG",{});var qmt=s(gpe);msr=r(qmt,"convbert"),qmt.forEach(t),gsr=r(ULe," \u2014 "),WO=n(ULe,"A",{href:!0});var Omt=s(WO);hsr=r(Omt,"TFConvBertForMaskedLM"),Omt.forEach(t),psr=r(ULe," (ConvBERT model)"),ULe.forEach(t),_sr=i(ee),X0=n(ee,"LI",{});var JLe=s(X0);hpe=n(JLe,"STRONG",{});var Gmt=s(hpe);usr=r(Gmt,"deberta"),Gmt.forEach(t),bsr=r(JLe," \u2014 "),QO=n(JLe,"A",{href:!0});var Xmt=s(QO);vsr=r(Xmt,"TFDebertaForMaskedLM"),Xmt.forEach(t),Tsr=r(JLe," (DeBERTa model)"),JLe.forEach(t),Fsr=i(ee),V0=n(ee,"LI",{});var YLe=s(V0);ppe=n(YLe,"STRONG",{});var Vmt=s(ppe);Csr=r(Vmt,"deberta-v2"),Vmt.forEach(t),Msr=r(YLe," \u2014 "),HO=n(YLe,"A",{href:!0});var zmt=s(HO);Esr=r(zmt,"TFDebertaV2ForMaskedLM"),zmt.forEach(t),ysr=r(YLe," (DeBERTa-v2 model)"),YLe.forEach(t),wsr=i(ee),z0=n(ee,"LI",{});var KLe=s(z0);_pe=n(KLe,"STRONG",{});var Wmt=s(_pe);Asr=r(Wmt,"distilbert"),Wmt.forEach(t),Lsr=r(KLe," \u2014 "),UO=n(KLe,"A",{href:!0});var Qmt=s(UO);Bsr=r(Qmt,"TFDistilBertForMaskedLM"),Qmt.forEach(t),xsr=r(KLe," (DistilBERT model)"),KLe.forEach(t),ksr=i(ee),W0=n(ee,"LI",{});var ZLe=s(W0);upe=n(ZLe,"STRONG",{});var Hmt=s(upe);Rsr=r(Hmt,"electra"),Hmt.forEach(t),Ssr=r(ZLe," \u2014 "),JO=n(ZLe,"A",{href:!0});var Umt=s(JO);Psr=r(Umt,"TFElectraForMaskedLM"),Umt.forEach(t),$sr=r(ZLe," (ELECTRA model)"),ZLe.forEach(t),Isr=i(ee),Q0=n(ee,"LI",{});var e7e=s(Q0);bpe=n(e7e,"STRONG",{});var Jmt=s(bpe);jsr=r(Jmt,"flaubert"),Jmt.forEach(t),Dsr=r(e7e," \u2014 "),YO=n(e7e,"A",{href:!0});var Ymt=s(YO);Nsr=r(Ymt,"TFFlaubertWithLMHeadModel"),Ymt.forEach(t),qsr=r(e7e," (FlauBERT model)"),e7e.forEach(t),Osr=i(ee),H0=n(ee,"LI",{});var o7e=s(H0);vpe=n(o7e,"STRONG",{});var Kmt=s(vpe);Gsr=r(Kmt,"funnel"),Kmt.forEach(t),Xsr=r(o7e," \u2014 "),KO=n(o7e,"A",{href:!0});var Zmt=s(KO);Vsr=r(Zmt,"TFFunnelForMaskedLM"),Zmt.forEach(t),zsr=r(o7e," (Funnel Transformer model)"),o7e.forEach(t),Wsr=i(ee),U0=n(ee,"LI",{});var r7e=s(U0);Tpe=n(r7e,"STRONG",{});var egt=s(Tpe);Qsr=r(egt,"layoutlm"),egt.forEach(t),Hsr=r(r7e," \u2014 "),ZO=n(r7e,"A",{href:!0});var ogt=s(ZO);Usr=r(ogt,"TFLayoutLMForMaskedLM"),ogt.forEach(t),Jsr=r(r7e," (LayoutLM model)"),r7e.forEach(t),Ysr=i(ee),J0=n(ee,"LI",{});var t7e=s(J0);Fpe=n(t7e,"STRONG",{});var rgt=s(Fpe);Ksr=r(rgt,"longformer"),rgt.forEach(t),Zsr=r(t7e," \u2014 "),eG=n(t7e,"A",{href:!0});var tgt=s(eG);elr=r(tgt,"TFLongformerForMaskedLM"),tgt.forEach(t),olr=r(t7e," (Longformer model)"),t7e.forEach(t),rlr=i(ee),Y0=n(ee,"LI",{});var a7e=s(Y0);Cpe=n(a7e,"STRONG",{});var agt=s(Cpe);tlr=r(agt,"mobilebert"),agt.forEach(t),alr=r(a7e," \u2014 "),oG=n(a7e,"A",{href:!0});var ngt=s(oG);nlr=r(ngt,"TFMobileBertForMaskedLM"),ngt.forEach(t),slr=r(a7e," (MobileBERT model)"),a7e.forEach(t),llr=i(ee),K0=n(ee,"LI",{});var n7e=s(K0);Mpe=n(n7e,"STRONG",{});var sgt=s(Mpe);ilr=r(sgt,"mpnet"),sgt.forEach(t),dlr=r(n7e," \u2014 "),rG=n(n7e,"A",{href:!0});var lgt=s(rG);clr=r(lgt,"TFMPNetForMaskedLM"),lgt.forEach(t),flr=r(n7e," (MPNet model)"),n7e.forEach(t),mlr=i(ee),Z0=n(ee,"LI",{});var s7e=s(Z0);Epe=n(s7e,"STRONG",{});var igt=s(Epe);glr=r(igt,"rembert"),igt.forEach(t),hlr=r(s7e," \u2014 "),tG=n(s7e,"A",{href:!0});var dgt=s(tG);plr=r(dgt,"TFRemBertForMaskedLM"),dgt.forEach(t),_lr=r(s7e," (RemBERT model)"),s7e.forEach(t),ulr=i(ee),eT=n(ee,"LI",{});var l7e=s(eT);ype=n(l7e,"STRONG",{});var cgt=s(ype);blr=r(cgt,"roberta"),cgt.forEach(t),vlr=r(l7e," \u2014 "),aG=n(l7e,"A",{href:!0});var fgt=s(aG);Tlr=r(fgt,"TFRobertaForMaskedLM"),fgt.forEach(t),Flr=r(l7e," (RoBERTa model)"),l7e.forEach(t),Clr=i(ee),oT=n(ee,"LI",{});var i7e=s(oT);wpe=n(i7e,"STRONG",{});var mgt=s(wpe);Mlr=r(mgt,"roformer"),mgt.forEach(t),Elr=r(i7e," \u2014 "),nG=n(i7e,"A",{href:!0});var ggt=s(nG);ylr=r(ggt,"TFRoFormerForMaskedLM"),ggt.forEach(t),wlr=r(i7e," (RoFormer model)"),i7e.forEach(t),Alr=i(ee),rT=n(ee,"LI",{});var d7e=s(rT);Ape=n(d7e,"STRONG",{});var hgt=s(Ape);Llr=r(hgt,"tapas"),hgt.forEach(t),Blr=r(d7e," \u2014 "),sG=n(d7e,"A",{href:!0});var pgt=s(sG);xlr=r(pgt,"TFTapasForMaskedLM"),pgt.forEach(t),klr=r(d7e," (TAPAS model)"),d7e.forEach(t),Rlr=i(ee),tT=n(ee,"LI",{});var c7e=s(tT);Lpe=n(c7e,"STRONG",{});var _gt=s(Lpe);Slr=r(_gt,"xlm"),_gt.forEach(t),Plr=r(c7e," \u2014 "),lG=n(c7e,"A",{href:!0});var ugt=s(lG);$lr=r(ugt,"TFXLMWithLMHeadModel"),ugt.forEach(t),Ilr=r(c7e," (XLM model)"),c7e.forEach(t),jlr=i(ee),aT=n(ee,"LI",{});var f7e=s(aT);Bpe=n(f7e,"STRONG",{});var bgt=s(Bpe);Dlr=r(bgt,"xlm-roberta"),bgt.forEach(t),Nlr=r(f7e," \u2014 "),iG=n(f7e,"A",{href:!0});var vgt=s(iG);qlr=r(vgt,"TFXLMRobertaForMaskedLM"),vgt.forEach(t),Olr=r(f7e," (XLM-RoBERTa model)"),f7e.forEach(t),ee.forEach(t),Glr=i(Ca),xpe=n(Ca,"P",{});var Tgt=s(xpe);Xlr=r(Tgt,"Examples:"),Tgt.forEach(t),Vlr=i(Ca),m(Cw.$$.fragment,Ca),Ca.forEach(t),Kl.forEach(t),lRe=i(d),$c=n(d,"H2",{class:!0});var FPe=s($c);nT=n(FPe,"A",{id:!0,class:!0,href:!0});var Fgt=s(nT);kpe=n(Fgt,"SPAN",{});var Cgt=s(kpe);m(Mw.$$.fragment,Cgt),Cgt.forEach(t),Fgt.forEach(t),zlr=i(FPe),Rpe=n(FPe,"SPAN",{});var Mgt=s(Rpe);Wlr=r(Mgt,"TFAutoModelForSeq2SeqLM"),Mgt.forEach(t),FPe.forEach(t),iRe=i(d),yr=n(d,"DIV",{class:!0});var ei=s(yr);m(Ew.$$.fragment,ei),Qlr=i(ei),Ic=n(ei,"P",{});var UW=s(Ic);Hlr=r(UW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Spe=n(UW,"CODE",{});var Egt=s(Spe);Ulr=r(Egt,"from_pretrained()"),Egt.forEach(t),Jlr=r(UW,"class method or the "),Ppe=n(UW,"CODE",{});var ygt=s(Ppe);Ylr=r(ygt,"from_config()"),ygt.forEach(t),Klr=r(UW,`class
method.`),UW.forEach(t),Zlr=i(ei),yw=n(ei,"P",{});var CPe=s(yw);eir=r(CPe,"This class cannot be instantiated directly using "),$pe=n(CPe,"CODE",{});var wgt=s($pe);oir=r(wgt,"__init__()"),wgt.forEach(t),rir=r(CPe," (throws an error)."),CPe.forEach(t),tir=i(ei),Tt=n(ei,"DIV",{class:!0});var oi=s(Tt);m(ww.$$.fragment,oi),air=i(oi),Ipe=n(oi,"P",{});var Agt=s(Ipe);nir=r(Agt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Agt.forEach(t),sir=i(oi),jc=n(oi,"P",{});var JW=s(jc);lir=r(JW,`Note:
Loading a model from its configuration file does `),jpe=n(JW,"STRONG",{});var Lgt=s(jpe);iir=r(Lgt,"not"),Lgt.forEach(t),dir=r(JW,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dpe=n(JW,"CODE",{});var Bgt=s(Dpe);cir=r(Bgt,"from_pretrained()"),Bgt.forEach(t),fir=r(JW,"to load the model weights."),JW.forEach(t),mir=i(oi),Npe=n(oi,"P",{});var xgt=s(Npe);gir=r(xgt,"Examples:"),xgt.forEach(t),hir=i(oi),m(Aw.$$.fragment,oi),oi.forEach(t),pir=i(ei),vo=n(ei,"DIV",{class:!0});var Ma=s(vo);m(Lw.$$.fragment,Ma),_ir=i(Ma),qpe=n(Ma,"P",{});var kgt=s(qpe);uir=r(kgt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),kgt.forEach(t),bir=i(Ma),yn=n(Ma,"P",{});var NM=s(yn);vir=r(NM,"The model class to instantiate is selected based on the "),Ope=n(NM,"CODE",{});var Rgt=s(Ope);Tir=r(Rgt,"model_type"),Rgt.forEach(t),Fir=r(NM,` property of the config object (either
passed as an argument or loaded from `),Gpe=n(NM,"CODE",{});var Sgt=s(Gpe);Cir=r(Sgt,"pretrained_model_name_or_path"),Sgt.forEach(t),Mir=r(NM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xpe=n(NM,"CODE",{});var Pgt=s(Xpe);Eir=r(Pgt,"pretrained_model_name_or_path"),Pgt.forEach(t),yir=r(NM,":"),NM.forEach(t),wir=i(Ma),_e=n(Ma,"UL",{});var Ee=s(_e);sT=n(Ee,"LI",{});var m7e=s(sT);Vpe=n(m7e,"STRONG",{});var $gt=s(Vpe);Air=r($gt,"bart"),$gt.forEach(t),Lir=r(m7e," \u2014 "),dG=n(m7e,"A",{href:!0});var Igt=s(dG);Bir=r(Igt,"TFBartForConditionalGeneration"),Igt.forEach(t),xir=r(m7e," (BART model)"),m7e.forEach(t),kir=i(Ee),lT=n(Ee,"LI",{});var g7e=s(lT);zpe=n(g7e,"STRONG",{});var jgt=s(zpe);Rir=r(jgt,"blenderbot"),jgt.forEach(t),Sir=r(g7e," \u2014 "),cG=n(g7e,"A",{href:!0});var Dgt=s(cG);Pir=r(Dgt,"TFBlenderbotForConditionalGeneration"),Dgt.forEach(t),$ir=r(g7e," (Blenderbot model)"),g7e.forEach(t),Iir=i(Ee),iT=n(Ee,"LI",{});var h7e=s(iT);Wpe=n(h7e,"STRONG",{});var Ngt=s(Wpe);jir=r(Ngt,"blenderbot-small"),Ngt.forEach(t),Dir=r(h7e," \u2014 "),fG=n(h7e,"A",{href:!0});var qgt=s(fG);Nir=r(qgt,"TFBlenderbotSmallForConditionalGeneration"),qgt.forEach(t),qir=r(h7e," (BlenderbotSmall model)"),h7e.forEach(t),Oir=i(Ee),dT=n(Ee,"LI",{});var p7e=s(dT);Qpe=n(p7e,"STRONG",{});var Ogt=s(Qpe);Gir=r(Ogt,"encoder-decoder"),Ogt.forEach(t),Xir=r(p7e," \u2014 "),mG=n(p7e,"A",{href:!0});var Ggt=s(mG);Vir=r(Ggt,"TFEncoderDecoderModel"),Ggt.forEach(t),zir=r(p7e," (Encoder decoder model)"),p7e.forEach(t),Wir=i(Ee),cT=n(Ee,"LI",{});var _7e=s(cT);Hpe=n(_7e,"STRONG",{});var Xgt=s(Hpe);Qir=r(Xgt,"led"),Xgt.forEach(t),Hir=r(_7e," \u2014 "),gG=n(_7e,"A",{href:!0});var Vgt=s(gG);Uir=r(Vgt,"TFLEDForConditionalGeneration"),Vgt.forEach(t),Jir=r(_7e," (LED model)"),_7e.forEach(t),Yir=i(Ee),fT=n(Ee,"LI",{});var u7e=s(fT);Upe=n(u7e,"STRONG",{});var zgt=s(Upe);Kir=r(zgt,"marian"),zgt.forEach(t),Zir=r(u7e," \u2014 "),hG=n(u7e,"A",{href:!0});var Wgt=s(hG);edr=r(Wgt,"TFMarianMTModel"),Wgt.forEach(t),odr=r(u7e," (Marian model)"),u7e.forEach(t),rdr=i(Ee),mT=n(Ee,"LI",{});var b7e=s(mT);Jpe=n(b7e,"STRONG",{});var Qgt=s(Jpe);tdr=r(Qgt,"mbart"),Qgt.forEach(t),adr=r(b7e," \u2014 "),pG=n(b7e,"A",{href:!0});var Hgt=s(pG);ndr=r(Hgt,"TFMBartForConditionalGeneration"),Hgt.forEach(t),sdr=r(b7e," (mBART model)"),b7e.forEach(t),ldr=i(Ee),gT=n(Ee,"LI",{});var v7e=s(gT);Ype=n(v7e,"STRONG",{});var Ugt=s(Ype);idr=r(Ugt,"mt5"),Ugt.forEach(t),ddr=r(v7e," \u2014 "),_G=n(v7e,"A",{href:!0});var Jgt=s(_G);cdr=r(Jgt,"TFMT5ForConditionalGeneration"),Jgt.forEach(t),fdr=r(v7e," (mT5 model)"),v7e.forEach(t),mdr=i(Ee),hT=n(Ee,"LI",{});var T7e=s(hT);Kpe=n(T7e,"STRONG",{});var Ygt=s(Kpe);gdr=r(Ygt,"pegasus"),Ygt.forEach(t),hdr=r(T7e," \u2014 "),uG=n(T7e,"A",{href:!0});var Kgt=s(uG);pdr=r(Kgt,"TFPegasusForConditionalGeneration"),Kgt.forEach(t),_dr=r(T7e," (Pegasus model)"),T7e.forEach(t),udr=i(Ee),pT=n(Ee,"LI",{});var F7e=s(pT);Zpe=n(F7e,"STRONG",{});var Zgt=s(Zpe);bdr=r(Zgt,"t5"),Zgt.forEach(t),vdr=r(F7e," \u2014 "),bG=n(F7e,"A",{href:!0});var eht=s(bG);Tdr=r(eht,"TFT5ForConditionalGeneration"),eht.forEach(t),Fdr=r(F7e," (T5 model)"),F7e.forEach(t),Ee.forEach(t),Cdr=i(Ma),e_e=n(Ma,"P",{});var oht=s(e_e);Mdr=r(oht,"Examples:"),oht.forEach(t),Edr=i(Ma),m(Bw.$$.fragment,Ma),Ma.forEach(t),ei.forEach(t),dRe=i(d),Dc=n(d,"H2",{class:!0});var MPe=s(Dc);_T=n(MPe,"A",{id:!0,class:!0,href:!0});var rht=s(_T);o_e=n(rht,"SPAN",{});var tht=s(o_e);m(xw.$$.fragment,tht),tht.forEach(t),rht.forEach(t),ydr=i(MPe),r_e=n(MPe,"SPAN",{});var aht=s(r_e);wdr=r(aht,"TFAutoModelForSequenceClassification"),aht.forEach(t),MPe.forEach(t),cRe=i(d),wr=n(d,"DIV",{class:!0});var ri=s(wr);m(kw.$$.fragment,ri),Adr=i(ri),Nc=n(ri,"P",{});var YW=s(Nc);Ldr=r(YW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),t_e=n(YW,"CODE",{});var nht=s(t_e);Bdr=r(nht,"from_pretrained()"),nht.forEach(t),xdr=r(YW,"class method or the "),a_e=n(YW,"CODE",{});var sht=s(a_e);kdr=r(sht,"from_config()"),sht.forEach(t),Rdr=r(YW,`class
method.`),YW.forEach(t),Sdr=i(ri),Rw=n(ri,"P",{});var EPe=s(Rw);Pdr=r(EPe,"This class cannot be instantiated directly using "),n_e=n(EPe,"CODE",{});var lht=s(n_e);$dr=r(lht,"__init__()"),lht.forEach(t),Idr=r(EPe," (throws an error)."),EPe.forEach(t),jdr=i(ri),Ft=n(ri,"DIV",{class:!0});var ti=s(Ft);m(Sw.$$.fragment,ti),Ddr=i(ti),s_e=n(ti,"P",{});var iht=s(s_e);Ndr=r(iht,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),iht.forEach(t),qdr=i(ti),qc=n(ti,"P",{});var KW=s(qc);Odr=r(KW,`Note:
Loading a model from its configuration file does `),l_e=n(KW,"STRONG",{});var dht=s(l_e);Gdr=r(dht,"not"),dht.forEach(t),Xdr=r(KW,` load the model weights. It only affects the
model\u2019s configuration. Use `),i_e=n(KW,"CODE",{});var cht=s(i_e);Vdr=r(cht,"from_pretrained()"),cht.forEach(t),zdr=r(KW,"to load the model weights."),KW.forEach(t),Wdr=i(ti),d_e=n(ti,"P",{});var fht=s(d_e);Qdr=r(fht,"Examples:"),fht.forEach(t),Hdr=i(ti),m(Pw.$$.fragment,ti),ti.forEach(t),Udr=i(ri),To=n(ri,"DIV",{class:!0});var Ea=s(To);m($w.$$.fragment,Ea),Jdr=i(Ea),c_e=n(Ea,"P",{});var mht=s(c_e);Ydr=r(mht,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),mht.forEach(t),Kdr=i(Ea),wn=n(Ea,"P",{});var qM=s(wn);Zdr=r(qM,"The model class to instantiate is selected based on the "),f_e=n(qM,"CODE",{});var ght=s(f_e);ecr=r(ght,"model_type"),ght.forEach(t),ocr=r(qM,` property of the config object (either
passed as an argument or loaded from `),m_e=n(qM,"CODE",{});var hht=s(m_e);rcr=r(hht,"pretrained_model_name_or_path"),hht.forEach(t),tcr=r(qM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g_e=n(qM,"CODE",{});var pht=s(g_e);acr=r(pht,"pretrained_model_name_or_path"),pht.forEach(t),ncr=r(qM,":"),qM.forEach(t),scr=i(Ea),V=n(Ea,"UL",{});var W=s(V);uT=n(W,"LI",{});var C7e=s(uT);h_e=n(C7e,"STRONG",{});var _ht=s(h_e);lcr=r(_ht,"albert"),_ht.forEach(t),icr=r(C7e," \u2014 "),vG=n(C7e,"A",{href:!0});var uht=s(vG);dcr=r(uht,"TFAlbertForSequenceClassification"),uht.forEach(t),ccr=r(C7e," (ALBERT model)"),C7e.forEach(t),fcr=i(W),bT=n(W,"LI",{});var M7e=s(bT);p_e=n(M7e,"STRONG",{});var bht=s(p_e);mcr=r(bht,"bert"),bht.forEach(t),gcr=r(M7e," \u2014 "),TG=n(M7e,"A",{href:!0});var vht=s(TG);hcr=r(vht,"TFBertForSequenceClassification"),vht.forEach(t),pcr=r(M7e," (BERT model)"),M7e.forEach(t),_cr=i(W),vT=n(W,"LI",{});var E7e=s(vT);__e=n(E7e,"STRONG",{});var Tht=s(__e);ucr=r(Tht,"camembert"),Tht.forEach(t),bcr=r(E7e," \u2014 "),FG=n(E7e,"A",{href:!0});var Fht=s(FG);vcr=r(Fht,"TFCamembertForSequenceClassification"),Fht.forEach(t),Tcr=r(E7e," (CamemBERT model)"),E7e.forEach(t),Fcr=i(W),TT=n(W,"LI",{});var y7e=s(TT);u_e=n(y7e,"STRONG",{});var Cht=s(u_e);Ccr=r(Cht,"convbert"),Cht.forEach(t),Mcr=r(y7e," \u2014 "),CG=n(y7e,"A",{href:!0});var Mht=s(CG);Ecr=r(Mht,"TFConvBertForSequenceClassification"),Mht.forEach(t),ycr=r(y7e," (ConvBERT model)"),y7e.forEach(t),wcr=i(W),FT=n(W,"LI",{});var w7e=s(FT);b_e=n(w7e,"STRONG",{});var Eht=s(b_e);Acr=r(Eht,"ctrl"),Eht.forEach(t),Lcr=r(w7e," \u2014 "),MG=n(w7e,"A",{href:!0});var yht=s(MG);Bcr=r(yht,"TFCTRLForSequenceClassification"),yht.forEach(t),xcr=r(w7e," (CTRL model)"),w7e.forEach(t),kcr=i(W),CT=n(W,"LI",{});var A7e=s(CT);v_e=n(A7e,"STRONG",{});var wht=s(v_e);Rcr=r(wht,"deberta"),wht.forEach(t),Scr=r(A7e," \u2014 "),EG=n(A7e,"A",{href:!0});var Aht=s(EG);Pcr=r(Aht,"TFDebertaForSequenceClassification"),Aht.forEach(t),$cr=r(A7e," (DeBERTa model)"),A7e.forEach(t),Icr=i(W),MT=n(W,"LI",{});var L7e=s(MT);T_e=n(L7e,"STRONG",{});var Lht=s(T_e);jcr=r(Lht,"deberta-v2"),Lht.forEach(t),Dcr=r(L7e," \u2014 "),yG=n(L7e,"A",{href:!0});var Bht=s(yG);Ncr=r(Bht,"TFDebertaV2ForSequenceClassification"),Bht.forEach(t),qcr=r(L7e," (DeBERTa-v2 model)"),L7e.forEach(t),Ocr=i(W),ET=n(W,"LI",{});var B7e=s(ET);F_e=n(B7e,"STRONG",{});var xht=s(F_e);Gcr=r(xht,"distilbert"),xht.forEach(t),Xcr=r(B7e," \u2014 "),wG=n(B7e,"A",{href:!0});var kht=s(wG);Vcr=r(kht,"TFDistilBertForSequenceClassification"),kht.forEach(t),zcr=r(B7e," (DistilBERT model)"),B7e.forEach(t),Wcr=i(W),yT=n(W,"LI",{});var x7e=s(yT);C_e=n(x7e,"STRONG",{});var Rht=s(C_e);Qcr=r(Rht,"electra"),Rht.forEach(t),Hcr=r(x7e," \u2014 "),AG=n(x7e,"A",{href:!0});var Sht=s(AG);Ucr=r(Sht,"TFElectraForSequenceClassification"),Sht.forEach(t),Jcr=r(x7e," (ELECTRA model)"),x7e.forEach(t),Ycr=i(W),wT=n(W,"LI",{});var k7e=s(wT);M_e=n(k7e,"STRONG",{});var Pht=s(M_e);Kcr=r(Pht,"flaubert"),Pht.forEach(t),Zcr=r(k7e," \u2014 "),LG=n(k7e,"A",{href:!0});var $ht=s(LG);efr=r($ht,"TFFlaubertForSequenceClassification"),$ht.forEach(t),ofr=r(k7e," (FlauBERT model)"),k7e.forEach(t),rfr=i(W),AT=n(W,"LI",{});var R7e=s(AT);E_e=n(R7e,"STRONG",{});var Iht=s(E_e);tfr=r(Iht,"funnel"),Iht.forEach(t),afr=r(R7e," \u2014 "),BG=n(R7e,"A",{href:!0});var jht=s(BG);nfr=r(jht,"TFFunnelForSequenceClassification"),jht.forEach(t),sfr=r(R7e," (Funnel Transformer model)"),R7e.forEach(t),lfr=i(W),LT=n(W,"LI",{});var S7e=s(LT);y_e=n(S7e,"STRONG",{});var Dht=s(y_e);ifr=r(Dht,"gpt2"),Dht.forEach(t),dfr=r(S7e," \u2014 "),xG=n(S7e,"A",{href:!0});var Nht=s(xG);cfr=r(Nht,"TFGPT2ForSequenceClassification"),Nht.forEach(t),ffr=r(S7e," (OpenAI GPT-2 model)"),S7e.forEach(t),mfr=i(W),BT=n(W,"LI",{});var P7e=s(BT);w_e=n(P7e,"STRONG",{});var qht=s(w_e);gfr=r(qht,"layoutlm"),qht.forEach(t),hfr=r(P7e," \u2014 "),kG=n(P7e,"A",{href:!0});var Oht=s(kG);pfr=r(Oht,"TFLayoutLMForSequenceClassification"),Oht.forEach(t),_fr=r(P7e," (LayoutLM model)"),P7e.forEach(t),ufr=i(W),xT=n(W,"LI",{});var $7e=s(xT);A_e=n($7e,"STRONG",{});var Ght=s(A_e);bfr=r(Ght,"longformer"),Ght.forEach(t),vfr=r($7e," \u2014 "),RG=n($7e,"A",{href:!0});var Xht=s(RG);Tfr=r(Xht,"TFLongformerForSequenceClassification"),Xht.forEach(t),Ffr=r($7e," (Longformer model)"),$7e.forEach(t),Cfr=i(W),kT=n(W,"LI",{});var I7e=s(kT);L_e=n(I7e,"STRONG",{});var Vht=s(L_e);Mfr=r(Vht,"mobilebert"),Vht.forEach(t),Efr=r(I7e," \u2014 "),SG=n(I7e,"A",{href:!0});var zht=s(SG);yfr=r(zht,"TFMobileBertForSequenceClassification"),zht.forEach(t),wfr=r(I7e," (MobileBERT model)"),I7e.forEach(t),Afr=i(W),RT=n(W,"LI",{});var j7e=s(RT);B_e=n(j7e,"STRONG",{});var Wht=s(B_e);Lfr=r(Wht,"mpnet"),Wht.forEach(t),Bfr=r(j7e," \u2014 "),PG=n(j7e,"A",{href:!0});var Qht=s(PG);xfr=r(Qht,"TFMPNetForSequenceClassification"),Qht.forEach(t),kfr=r(j7e," (MPNet model)"),j7e.forEach(t),Rfr=i(W),ST=n(W,"LI",{});var D7e=s(ST);x_e=n(D7e,"STRONG",{});var Hht=s(x_e);Sfr=r(Hht,"openai-gpt"),Hht.forEach(t),Pfr=r(D7e," \u2014 "),$G=n(D7e,"A",{href:!0});var Uht=s($G);$fr=r(Uht,"TFOpenAIGPTForSequenceClassification"),Uht.forEach(t),Ifr=r(D7e," (OpenAI GPT model)"),D7e.forEach(t),jfr=i(W),PT=n(W,"LI",{});var N7e=s(PT);k_e=n(N7e,"STRONG",{});var Jht=s(k_e);Dfr=r(Jht,"rembert"),Jht.forEach(t),Nfr=r(N7e," \u2014 "),IG=n(N7e,"A",{href:!0});var Yht=s(IG);qfr=r(Yht,"TFRemBertForSequenceClassification"),Yht.forEach(t),Ofr=r(N7e," (RemBERT model)"),N7e.forEach(t),Gfr=i(W),$T=n(W,"LI",{});var q7e=s($T);R_e=n(q7e,"STRONG",{});var Kht=s(R_e);Xfr=r(Kht,"roberta"),Kht.forEach(t),Vfr=r(q7e," \u2014 "),jG=n(q7e,"A",{href:!0});var Zht=s(jG);zfr=r(Zht,"TFRobertaForSequenceClassification"),Zht.forEach(t),Wfr=r(q7e," (RoBERTa model)"),q7e.forEach(t),Qfr=i(W),IT=n(W,"LI",{});var O7e=s(IT);S_e=n(O7e,"STRONG",{});var ept=s(S_e);Hfr=r(ept,"roformer"),ept.forEach(t),Ufr=r(O7e," \u2014 "),DG=n(O7e,"A",{href:!0});var opt=s(DG);Jfr=r(opt,"TFRoFormerForSequenceClassification"),opt.forEach(t),Yfr=r(O7e," (RoFormer model)"),O7e.forEach(t),Kfr=i(W),jT=n(W,"LI",{});var G7e=s(jT);P_e=n(G7e,"STRONG",{});var rpt=s(P_e);Zfr=r(rpt,"tapas"),rpt.forEach(t),emr=r(G7e," \u2014 "),NG=n(G7e,"A",{href:!0});var tpt=s(NG);omr=r(tpt,"TFTapasForSequenceClassification"),tpt.forEach(t),rmr=r(G7e," (TAPAS model)"),G7e.forEach(t),tmr=i(W),DT=n(W,"LI",{});var X7e=s(DT);$_e=n(X7e,"STRONG",{});var apt=s($_e);amr=r(apt,"transfo-xl"),apt.forEach(t),nmr=r(X7e," \u2014 "),qG=n(X7e,"A",{href:!0});var npt=s(qG);smr=r(npt,"TFTransfoXLForSequenceClassification"),npt.forEach(t),lmr=r(X7e," (Transformer-XL model)"),X7e.forEach(t),imr=i(W),NT=n(W,"LI",{});var V7e=s(NT);I_e=n(V7e,"STRONG",{});var spt=s(I_e);dmr=r(spt,"xlm"),spt.forEach(t),cmr=r(V7e," \u2014 "),OG=n(V7e,"A",{href:!0});var lpt=s(OG);fmr=r(lpt,"TFXLMForSequenceClassification"),lpt.forEach(t),mmr=r(V7e," (XLM model)"),V7e.forEach(t),gmr=i(W),qT=n(W,"LI",{});var z7e=s(qT);j_e=n(z7e,"STRONG",{});var ipt=s(j_e);hmr=r(ipt,"xlm-roberta"),ipt.forEach(t),pmr=r(z7e," \u2014 "),GG=n(z7e,"A",{href:!0});var dpt=s(GG);_mr=r(dpt,"TFXLMRobertaForSequenceClassification"),dpt.forEach(t),umr=r(z7e," (XLM-RoBERTa model)"),z7e.forEach(t),bmr=i(W),OT=n(W,"LI",{});var W7e=s(OT);D_e=n(W7e,"STRONG",{});var cpt=s(D_e);vmr=r(cpt,"xlnet"),cpt.forEach(t),Tmr=r(W7e," \u2014 "),XG=n(W7e,"A",{href:!0});var fpt=s(XG);Fmr=r(fpt,"TFXLNetForSequenceClassification"),fpt.forEach(t),Cmr=r(W7e," (XLNet model)"),W7e.forEach(t),W.forEach(t),Mmr=i(Ea),N_e=n(Ea,"P",{});var mpt=s(N_e);Emr=r(mpt,"Examples:"),mpt.forEach(t),ymr=i(Ea),m(Iw.$$.fragment,Ea),Ea.forEach(t),ri.forEach(t),fRe=i(d),Oc=n(d,"H2",{class:!0});var yPe=s(Oc);GT=n(yPe,"A",{id:!0,class:!0,href:!0});var gpt=s(GT);q_e=n(gpt,"SPAN",{});var hpt=s(q_e);m(jw.$$.fragment,hpt),hpt.forEach(t),gpt.forEach(t),wmr=i(yPe),O_e=n(yPe,"SPAN",{});var ppt=s(O_e);Amr=r(ppt,"TFAutoModelForMultipleChoice"),ppt.forEach(t),yPe.forEach(t),mRe=i(d),Ar=n(d,"DIV",{class:!0});var ai=s(Ar);m(Dw.$$.fragment,ai),Lmr=i(ai),Gc=n(ai,"P",{});var ZW=s(Gc);Bmr=r(ZW,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),G_e=n(ZW,"CODE",{});var _pt=s(G_e);xmr=r(_pt,"from_pretrained()"),_pt.forEach(t),kmr=r(ZW,"class method or the "),X_e=n(ZW,"CODE",{});var upt=s(X_e);Rmr=r(upt,"from_config()"),upt.forEach(t),Smr=r(ZW,`class
method.`),ZW.forEach(t),Pmr=i(ai),Nw=n(ai,"P",{});var wPe=s(Nw);$mr=r(wPe,"This class cannot be instantiated directly using "),V_e=n(wPe,"CODE",{});var bpt=s(V_e);Imr=r(bpt,"__init__()"),bpt.forEach(t),jmr=r(wPe," (throws an error)."),wPe.forEach(t),Dmr=i(ai),Ct=n(ai,"DIV",{class:!0});var ni=s(Ct);m(qw.$$.fragment,ni),Nmr=i(ni),z_e=n(ni,"P",{});var vpt=s(z_e);qmr=r(vpt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),vpt.forEach(t),Omr=i(ni),Xc=n(ni,"P",{});var eQ=s(Xc);Gmr=r(eQ,`Note:
Loading a model from its configuration file does `),W_e=n(eQ,"STRONG",{});var Tpt=s(W_e);Xmr=r(Tpt,"not"),Tpt.forEach(t),Vmr=r(eQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Q_e=n(eQ,"CODE",{});var Fpt=s(Q_e);zmr=r(Fpt,"from_pretrained()"),Fpt.forEach(t),Wmr=r(eQ,"to load the model weights."),eQ.forEach(t),Qmr=i(ni),H_e=n(ni,"P",{});var Cpt=s(H_e);Hmr=r(Cpt,"Examples:"),Cpt.forEach(t),Umr=i(ni),m(Ow.$$.fragment,ni),ni.forEach(t),Jmr=i(ai),Fo=n(ai,"DIV",{class:!0});var ya=s(Fo);m(Gw.$$.fragment,ya),Ymr=i(ya),U_e=n(ya,"P",{});var Mpt=s(U_e);Kmr=r(Mpt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Mpt.forEach(t),Zmr=i(ya),An=n(ya,"P",{});var OM=s(An);egr=r(OM,"The model class to instantiate is selected based on the "),J_e=n(OM,"CODE",{});var Ept=s(J_e);ogr=r(Ept,"model_type"),Ept.forEach(t),rgr=r(OM,` property of the config object (either
passed as an argument or loaded from `),Y_e=n(OM,"CODE",{});var ypt=s(Y_e);tgr=r(ypt,"pretrained_model_name_or_path"),ypt.forEach(t),agr=r(OM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K_e=n(OM,"CODE",{});var wpt=s(K_e);ngr=r(wpt,"pretrained_model_name_or_path"),wpt.forEach(t),sgr=r(OM,":"),OM.forEach(t),lgr=i(ya),te=n(ya,"UL",{});var se=s(te);XT=n(se,"LI",{});var Q7e=s(XT);Z_e=n(Q7e,"STRONG",{});var Apt=s(Z_e);igr=r(Apt,"albert"),Apt.forEach(t),dgr=r(Q7e," \u2014 "),VG=n(Q7e,"A",{href:!0});var Lpt=s(VG);cgr=r(Lpt,"TFAlbertForMultipleChoice"),Lpt.forEach(t),fgr=r(Q7e," (ALBERT model)"),Q7e.forEach(t),mgr=i(se),VT=n(se,"LI",{});var H7e=s(VT);eue=n(H7e,"STRONG",{});var Bpt=s(eue);ggr=r(Bpt,"bert"),Bpt.forEach(t),hgr=r(H7e," \u2014 "),zG=n(H7e,"A",{href:!0});var xpt=s(zG);pgr=r(xpt,"TFBertForMultipleChoice"),xpt.forEach(t),_gr=r(H7e," (BERT model)"),H7e.forEach(t),ugr=i(se),zT=n(se,"LI",{});var U7e=s(zT);oue=n(U7e,"STRONG",{});var kpt=s(oue);bgr=r(kpt,"camembert"),kpt.forEach(t),vgr=r(U7e," \u2014 "),WG=n(U7e,"A",{href:!0});var Rpt=s(WG);Tgr=r(Rpt,"TFCamembertForMultipleChoice"),Rpt.forEach(t),Fgr=r(U7e," (CamemBERT model)"),U7e.forEach(t),Cgr=i(se),WT=n(se,"LI",{});var J7e=s(WT);rue=n(J7e,"STRONG",{});var Spt=s(rue);Mgr=r(Spt,"convbert"),Spt.forEach(t),Egr=r(J7e," \u2014 "),QG=n(J7e,"A",{href:!0});var Ppt=s(QG);ygr=r(Ppt,"TFConvBertForMultipleChoice"),Ppt.forEach(t),wgr=r(J7e," (ConvBERT model)"),J7e.forEach(t),Agr=i(se),QT=n(se,"LI",{});var Y7e=s(QT);tue=n(Y7e,"STRONG",{});var $pt=s(tue);Lgr=r($pt,"distilbert"),$pt.forEach(t),Bgr=r(Y7e," \u2014 "),HG=n(Y7e,"A",{href:!0});var Ipt=s(HG);xgr=r(Ipt,"TFDistilBertForMultipleChoice"),Ipt.forEach(t),kgr=r(Y7e," (DistilBERT model)"),Y7e.forEach(t),Rgr=i(se),HT=n(se,"LI",{});var K7e=s(HT);aue=n(K7e,"STRONG",{});var jpt=s(aue);Sgr=r(jpt,"electra"),jpt.forEach(t),Pgr=r(K7e," \u2014 "),UG=n(K7e,"A",{href:!0});var Dpt=s(UG);$gr=r(Dpt,"TFElectraForMultipleChoice"),Dpt.forEach(t),Igr=r(K7e," (ELECTRA model)"),K7e.forEach(t),jgr=i(se),UT=n(se,"LI",{});var Z7e=s(UT);nue=n(Z7e,"STRONG",{});var Npt=s(nue);Dgr=r(Npt,"flaubert"),Npt.forEach(t),Ngr=r(Z7e," \u2014 "),JG=n(Z7e,"A",{href:!0});var qpt=s(JG);qgr=r(qpt,"TFFlaubertForMultipleChoice"),qpt.forEach(t),Ogr=r(Z7e," (FlauBERT model)"),Z7e.forEach(t),Ggr=i(se),JT=n(se,"LI",{});var e9e=s(JT);sue=n(e9e,"STRONG",{});var Opt=s(sue);Xgr=r(Opt,"funnel"),Opt.forEach(t),Vgr=r(e9e," \u2014 "),YG=n(e9e,"A",{href:!0});var Gpt=s(YG);zgr=r(Gpt,"TFFunnelForMultipleChoice"),Gpt.forEach(t),Wgr=r(e9e," (Funnel Transformer model)"),e9e.forEach(t),Qgr=i(se),YT=n(se,"LI",{});var o9e=s(YT);lue=n(o9e,"STRONG",{});var Xpt=s(lue);Hgr=r(Xpt,"longformer"),Xpt.forEach(t),Ugr=r(o9e," \u2014 "),KG=n(o9e,"A",{href:!0});var Vpt=s(KG);Jgr=r(Vpt,"TFLongformerForMultipleChoice"),Vpt.forEach(t),Ygr=r(o9e," (Longformer model)"),o9e.forEach(t),Kgr=i(se),KT=n(se,"LI",{});var r9e=s(KT);iue=n(r9e,"STRONG",{});var zpt=s(iue);Zgr=r(zpt,"mobilebert"),zpt.forEach(t),ehr=r(r9e," \u2014 "),ZG=n(r9e,"A",{href:!0});var Wpt=s(ZG);ohr=r(Wpt,"TFMobileBertForMultipleChoice"),Wpt.forEach(t),rhr=r(r9e," (MobileBERT model)"),r9e.forEach(t),thr=i(se),ZT=n(se,"LI",{});var t9e=s(ZT);due=n(t9e,"STRONG",{});var Qpt=s(due);ahr=r(Qpt,"mpnet"),Qpt.forEach(t),nhr=r(t9e," \u2014 "),eX=n(t9e,"A",{href:!0});var Hpt=s(eX);shr=r(Hpt,"TFMPNetForMultipleChoice"),Hpt.forEach(t),lhr=r(t9e," (MPNet model)"),t9e.forEach(t),ihr=i(se),e8=n(se,"LI",{});var a9e=s(e8);cue=n(a9e,"STRONG",{});var Upt=s(cue);dhr=r(Upt,"rembert"),Upt.forEach(t),chr=r(a9e," \u2014 "),oX=n(a9e,"A",{href:!0});var Jpt=s(oX);fhr=r(Jpt,"TFRemBertForMultipleChoice"),Jpt.forEach(t),mhr=r(a9e," (RemBERT model)"),a9e.forEach(t),ghr=i(se),o8=n(se,"LI",{});var n9e=s(o8);fue=n(n9e,"STRONG",{});var Ypt=s(fue);hhr=r(Ypt,"roberta"),Ypt.forEach(t),phr=r(n9e," \u2014 "),rX=n(n9e,"A",{href:!0});var Kpt=s(rX);_hr=r(Kpt,"TFRobertaForMultipleChoice"),Kpt.forEach(t),uhr=r(n9e," (RoBERTa model)"),n9e.forEach(t),bhr=i(se),r8=n(se,"LI",{});var s9e=s(r8);mue=n(s9e,"STRONG",{});var Zpt=s(mue);vhr=r(Zpt,"roformer"),Zpt.forEach(t),Thr=r(s9e," \u2014 "),tX=n(s9e,"A",{href:!0});var e_t=s(tX);Fhr=r(e_t,"TFRoFormerForMultipleChoice"),e_t.forEach(t),Chr=r(s9e," (RoFormer model)"),s9e.forEach(t),Mhr=i(se),t8=n(se,"LI",{});var l9e=s(t8);gue=n(l9e,"STRONG",{});var o_t=s(gue);Ehr=r(o_t,"xlm"),o_t.forEach(t),yhr=r(l9e," \u2014 "),aX=n(l9e,"A",{href:!0});var r_t=s(aX);whr=r(r_t,"TFXLMForMultipleChoice"),r_t.forEach(t),Ahr=r(l9e," (XLM model)"),l9e.forEach(t),Lhr=i(se),a8=n(se,"LI",{});var i9e=s(a8);hue=n(i9e,"STRONG",{});var t_t=s(hue);Bhr=r(t_t,"xlm-roberta"),t_t.forEach(t),xhr=r(i9e," \u2014 "),nX=n(i9e,"A",{href:!0});var a_t=s(nX);khr=r(a_t,"TFXLMRobertaForMultipleChoice"),a_t.forEach(t),Rhr=r(i9e," (XLM-RoBERTa model)"),i9e.forEach(t),Shr=i(se),n8=n(se,"LI",{});var d9e=s(n8);pue=n(d9e,"STRONG",{});var n_t=s(pue);Phr=r(n_t,"xlnet"),n_t.forEach(t),$hr=r(d9e," \u2014 "),sX=n(d9e,"A",{href:!0});var s_t=s(sX);Ihr=r(s_t,"TFXLNetForMultipleChoice"),s_t.forEach(t),jhr=r(d9e," (XLNet model)"),d9e.forEach(t),se.forEach(t),Dhr=i(ya),_ue=n(ya,"P",{});var l_t=s(_ue);Nhr=r(l_t,"Examples:"),l_t.forEach(t),qhr=i(ya),m(Xw.$$.fragment,ya),ya.forEach(t),ai.forEach(t),gRe=i(d),Vc=n(d,"H2",{class:!0});var APe=s(Vc);s8=n(APe,"A",{id:!0,class:!0,href:!0});var i_t=s(s8);uue=n(i_t,"SPAN",{});var d_t=s(uue);m(Vw.$$.fragment,d_t),d_t.forEach(t),i_t.forEach(t),Ohr=i(APe),bue=n(APe,"SPAN",{});var c_t=s(bue);Ghr=r(c_t,"TFAutoModelForTableQuestionAnswering"),c_t.forEach(t),APe.forEach(t),hRe=i(d),Lr=n(d,"DIV",{class:!0});var si=s(Lr);m(zw.$$.fragment,si),Xhr=i(si),zc=n(si,"P",{});var oQ=s(zc);Vhr=r(oQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),vue=n(oQ,"CODE",{});var f_t=s(vue);zhr=r(f_t,"from_pretrained()"),f_t.forEach(t),Whr=r(oQ,"class method or the "),Tue=n(oQ,"CODE",{});var m_t=s(Tue);Qhr=r(m_t,"from_config()"),m_t.forEach(t),Hhr=r(oQ,`class
method.`),oQ.forEach(t),Uhr=i(si),Ww=n(si,"P",{});var LPe=s(Ww);Jhr=r(LPe,"This class cannot be instantiated directly using "),Fue=n(LPe,"CODE",{});var g_t=s(Fue);Yhr=r(g_t,"__init__()"),g_t.forEach(t),Khr=r(LPe," (throws an error)."),LPe.forEach(t),Zhr=i(si),Mt=n(si,"DIV",{class:!0});var li=s(Mt);m(Qw.$$.fragment,li),epr=i(li),Cue=n(li,"P",{});var h_t=s(Cue);opr=r(h_t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),h_t.forEach(t),rpr=i(li),Wc=n(li,"P",{});var rQ=s(Wc);tpr=r(rQ,`Note:
Loading a model from its configuration file does `),Mue=n(rQ,"STRONG",{});var p_t=s(Mue);apr=r(p_t,"not"),p_t.forEach(t),npr=r(rQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eue=n(rQ,"CODE",{});var __t=s(Eue);spr=r(__t,"from_pretrained()"),__t.forEach(t),lpr=r(rQ,"to load the model weights."),rQ.forEach(t),ipr=i(li),yue=n(li,"P",{});var u_t=s(yue);dpr=r(u_t,"Examples:"),u_t.forEach(t),cpr=i(li),m(Hw.$$.fragment,li),li.forEach(t),fpr=i(si),Co=n(si,"DIV",{class:!0});var wa=s(Co);m(Uw.$$.fragment,wa),mpr=i(wa),wue=n(wa,"P",{});var b_t=s(wue);gpr=r(b_t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),b_t.forEach(t),hpr=i(wa),Ln=n(wa,"P",{});var GM=s(Ln);ppr=r(GM,"The model class to instantiate is selected based on the "),Aue=n(GM,"CODE",{});var v_t=s(Aue);_pr=r(v_t,"model_type"),v_t.forEach(t),upr=r(GM,` property of the config object (either
passed as an argument or loaded from `),Lue=n(GM,"CODE",{});var T_t=s(Lue);bpr=r(T_t,"pretrained_model_name_or_path"),T_t.forEach(t),vpr=r(GM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bue=n(GM,"CODE",{});var F_t=s(Bue);Tpr=r(F_t,"pretrained_model_name_or_path"),F_t.forEach(t),Fpr=r(GM,":"),GM.forEach(t),Cpr=i(wa),xue=n(wa,"UL",{});var C_t=s(xue);l8=n(C_t,"LI",{});var c9e=s(l8);kue=n(c9e,"STRONG",{});var M_t=s(kue);Mpr=r(M_t,"tapas"),M_t.forEach(t),Epr=r(c9e," \u2014 "),lX=n(c9e,"A",{href:!0});var E_t=s(lX);ypr=r(E_t,"TFTapasForQuestionAnswering"),E_t.forEach(t),wpr=r(c9e," (TAPAS model)"),c9e.forEach(t),C_t.forEach(t),Apr=i(wa),Rue=n(wa,"P",{});var y_t=s(Rue);Lpr=r(y_t,"Examples:"),y_t.forEach(t),Bpr=i(wa),m(Jw.$$.fragment,wa),wa.forEach(t),si.forEach(t),pRe=i(d),Qc=n(d,"H2",{class:!0});var BPe=s(Qc);i8=n(BPe,"A",{id:!0,class:!0,href:!0});var w_t=s(i8);Sue=n(w_t,"SPAN",{});var A_t=s(Sue);m(Yw.$$.fragment,A_t),A_t.forEach(t),w_t.forEach(t),xpr=i(BPe),Pue=n(BPe,"SPAN",{});var L_t=s(Pue);kpr=r(L_t,"TFAutoModelForTokenClassification"),L_t.forEach(t),BPe.forEach(t),_Re=i(d),Br=n(d,"DIV",{class:!0});var ii=s(Br);m(Kw.$$.fragment,ii),Rpr=i(ii),Hc=n(ii,"P",{});var tQ=s(Hc);Spr=r(tQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),$ue=n(tQ,"CODE",{});var B_t=s($ue);Ppr=r(B_t,"from_pretrained()"),B_t.forEach(t),$pr=r(tQ,"class method or the "),Iue=n(tQ,"CODE",{});var x_t=s(Iue);Ipr=r(x_t,"from_config()"),x_t.forEach(t),jpr=r(tQ,`class
method.`),tQ.forEach(t),Dpr=i(ii),Zw=n(ii,"P",{});var xPe=s(Zw);Npr=r(xPe,"This class cannot be instantiated directly using "),jue=n(xPe,"CODE",{});var k_t=s(jue);qpr=r(k_t,"__init__()"),k_t.forEach(t),Opr=r(xPe," (throws an error)."),xPe.forEach(t),Gpr=i(ii),Et=n(ii,"DIV",{class:!0});var di=s(Et);m(eA.$$.fragment,di),Xpr=i(di),Due=n(di,"P",{});var R_t=s(Due);Vpr=r(R_t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),R_t.forEach(t),zpr=i(di),Uc=n(di,"P",{});var aQ=s(Uc);Wpr=r(aQ,`Note:
Loading a model from its configuration file does `),Nue=n(aQ,"STRONG",{});var S_t=s(Nue);Qpr=r(S_t,"not"),S_t.forEach(t),Hpr=r(aQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),que=n(aQ,"CODE",{});var P_t=s(que);Upr=r(P_t,"from_pretrained()"),P_t.forEach(t),Jpr=r(aQ,"to load the model weights."),aQ.forEach(t),Ypr=i(di),Oue=n(di,"P",{});var $_t=s(Oue);Kpr=r($_t,"Examples:"),$_t.forEach(t),Zpr=i(di),m(oA.$$.fragment,di),di.forEach(t),e_r=i(ii),Mo=n(ii,"DIV",{class:!0});var Aa=s(Mo);m(rA.$$.fragment,Aa),o_r=i(Aa),Gue=n(Aa,"P",{});var I_t=s(Gue);r_r=r(I_t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),I_t.forEach(t),t_r=i(Aa),Bn=n(Aa,"P",{});var XM=s(Bn);a_r=r(XM,"The model class to instantiate is selected based on the "),Xue=n(XM,"CODE",{});var j_t=s(Xue);n_r=r(j_t,"model_type"),j_t.forEach(t),s_r=r(XM,` property of the config object (either
passed as an argument or loaded from `),Vue=n(XM,"CODE",{});var D_t=s(Vue);l_r=r(D_t,"pretrained_model_name_or_path"),D_t.forEach(t),i_r=r(XM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zue=n(XM,"CODE",{});var N_t=s(zue);d_r=r(N_t,"pretrained_model_name_or_path"),N_t.forEach(t),c_r=r(XM,":"),XM.forEach(t),f_r=i(Aa),K=n(Aa,"UL",{});var oe=s(K);d8=n(oe,"LI",{});var f9e=s(d8);Wue=n(f9e,"STRONG",{});var q_t=s(Wue);m_r=r(q_t,"albert"),q_t.forEach(t),g_r=r(f9e," \u2014 "),iX=n(f9e,"A",{href:!0});var O_t=s(iX);h_r=r(O_t,"TFAlbertForTokenClassification"),O_t.forEach(t),p_r=r(f9e," (ALBERT model)"),f9e.forEach(t),__r=i(oe),c8=n(oe,"LI",{});var m9e=s(c8);Que=n(m9e,"STRONG",{});var G_t=s(Que);u_r=r(G_t,"bert"),G_t.forEach(t),b_r=r(m9e," \u2014 "),dX=n(m9e,"A",{href:!0});var X_t=s(dX);v_r=r(X_t,"TFBertForTokenClassification"),X_t.forEach(t),T_r=r(m9e," (BERT model)"),m9e.forEach(t),F_r=i(oe),f8=n(oe,"LI",{});var g9e=s(f8);Hue=n(g9e,"STRONG",{});var V_t=s(Hue);C_r=r(V_t,"camembert"),V_t.forEach(t),M_r=r(g9e," \u2014 "),cX=n(g9e,"A",{href:!0});var z_t=s(cX);E_r=r(z_t,"TFCamembertForTokenClassification"),z_t.forEach(t),y_r=r(g9e," (CamemBERT model)"),g9e.forEach(t),w_r=i(oe),m8=n(oe,"LI",{});var h9e=s(m8);Uue=n(h9e,"STRONG",{});var W_t=s(Uue);A_r=r(W_t,"convbert"),W_t.forEach(t),L_r=r(h9e," \u2014 "),fX=n(h9e,"A",{href:!0});var Q_t=s(fX);B_r=r(Q_t,"TFConvBertForTokenClassification"),Q_t.forEach(t),x_r=r(h9e," (ConvBERT model)"),h9e.forEach(t),k_r=i(oe),g8=n(oe,"LI",{});var p9e=s(g8);Jue=n(p9e,"STRONG",{});var H_t=s(Jue);R_r=r(H_t,"deberta"),H_t.forEach(t),S_r=r(p9e," \u2014 "),mX=n(p9e,"A",{href:!0});var U_t=s(mX);P_r=r(U_t,"TFDebertaForTokenClassification"),U_t.forEach(t),$_r=r(p9e," (DeBERTa model)"),p9e.forEach(t),I_r=i(oe),h8=n(oe,"LI",{});var _9e=s(h8);Yue=n(_9e,"STRONG",{});var J_t=s(Yue);j_r=r(J_t,"deberta-v2"),J_t.forEach(t),D_r=r(_9e," \u2014 "),gX=n(_9e,"A",{href:!0});var Y_t=s(gX);N_r=r(Y_t,"TFDebertaV2ForTokenClassification"),Y_t.forEach(t),q_r=r(_9e," (DeBERTa-v2 model)"),_9e.forEach(t),O_r=i(oe),p8=n(oe,"LI",{});var u9e=s(p8);Kue=n(u9e,"STRONG",{});var K_t=s(Kue);G_r=r(K_t,"distilbert"),K_t.forEach(t),X_r=r(u9e," \u2014 "),hX=n(u9e,"A",{href:!0});var Z_t=s(hX);V_r=r(Z_t,"TFDistilBertForTokenClassification"),Z_t.forEach(t),z_r=r(u9e," (DistilBERT model)"),u9e.forEach(t),W_r=i(oe),_8=n(oe,"LI",{});var b9e=s(_8);Zue=n(b9e,"STRONG",{});var eut=s(Zue);Q_r=r(eut,"electra"),eut.forEach(t),H_r=r(b9e," \u2014 "),pX=n(b9e,"A",{href:!0});var out=s(pX);U_r=r(out,"TFElectraForTokenClassification"),out.forEach(t),J_r=r(b9e," (ELECTRA model)"),b9e.forEach(t),Y_r=i(oe),u8=n(oe,"LI",{});var v9e=s(u8);e1e=n(v9e,"STRONG",{});var rut=s(e1e);K_r=r(rut,"flaubert"),rut.forEach(t),Z_r=r(v9e," \u2014 "),_X=n(v9e,"A",{href:!0});var tut=s(_X);eur=r(tut,"TFFlaubertForTokenClassification"),tut.forEach(t),our=r(v9e," (FlauBERT model)"),v9e.forEach(t),rur=i(oe),b8=n(oe,"LI",{});var T9e=s(b8);o1e=n(T9e,"STRONG",{});var aut=s(o1e);tur=r(aut,"funnel"),aut.forEach(t),aur=r(T9e," \u2014 "),uX=n(T9e,"A",{href:!0});var nut=s(uX);nur=r(nut,"TFFunnelForTokenClassification"),nut.forEach(t),sur=r(T9e," (Funnel Transformer model)"),T9e.forEach(t),lur=i(oe),v8=n(oe,"LI",{});var F9e=s(v8);r1e=n(F9e,"STRONG",{});var sut=s(r1e);iur=r(sut,"layoutlm"),sut.forEach(t),dur=r(F9e," \u2014 "),bX=n(F9e,"A",{href:!0});var lut=s(bX);cur=r(lut,"TFLayoutLMForTokenClassification"),lut.forEach(t),fur=r(F9e," (LayoutLM model)"),F9e.forEach(t),mur=i(oe),T8=n(oe,"LI",{});var C9e=s(T8);t1e=n(C9e,"STRONG",{});var iut=s(t1e);gur=r(iut,"longformer"),iut.forEach(t),hur=r(C9e," \u2014 "),vX=n(C9e,"A",{href:!0});var dut=s(vX);pur=r(dut,"TFLongformerForTokenClassification"),dut.forEach(t),_ur=r(C9e," (Longformer model)"),C9e.forEach(t),uur=i(oe),F8=n(oe,"LI",{});var M9e=s(F8);a1e=n(M9e,"STRONG",{});var cut=s(a1e);bur=r(cut,"mobilebert"),cut.forEach(t),vur=r(M9e," \u2014 "),TX=n(M9e,"A",{href:!0});var fut=s(TX);Tur=r(fut,"TFMobileBertForTokenClassification"),fut.forEach(t),Fur=r(M9e," (MobileBERT model)"),M9e.forEach(t),Cur=i(oe),C8=n(oe,"LI",{});var E9e=s(C8);n1e=n(E9e,"STRONG",{});var mut=s(n1e);Mur=r(mut,"mpnet"),mut.forEach(t),Eur=r(E9e," \u2014 "),FX=n(E9e,"A",{href:!0});var gut=s(FX);yur=r(gut,"TFMPNetForTokenClassification"),gut.forEach(t),wur=r(E9e," (MPNet model)"),E9e.forEach(t),Aur=i(oe),M8=n(oe,"LI",{});var y9e=s(M8);s1e=n(y9e,"STRONG",{});var hut=s(s1e);Lur=r(hut,"rembert"),hut.forEach(t),Bur=r(y9e," \u2014 "),CX=n(y9e,"A",{href:!0});var put=s(CX);xur=r(put,"TFRemBertForTokenClassification"),put.forEach(t),kur=r(y9e," (RemBERT model)"),y9e.forEach(t),Rur=i(oe),E8=n(oe,"LI",{});var w9e=s(E8);l1e=n(w9e,"STRONG",{});var _ut=s(l1e);Sur=r(_ut,"roberta"),_ut.forEach(t),Pur=r(w9e," \u2014 "),MX=n(w9e,"A",{href:!0});var uut=s(MX);$ur=r(uut,"TFRobertaForTokenClassification"),uut.forEach(t),Iur=r(w9e," (RoBERTa model)"),w9e.forEach(t),jur=i(oe),y8=n(oe,"LI",{});var A9e=s(y8);i1e=n(A9e,"STRONG",{});var but=s(i1e);Dur=r(but,"roformer"),but.forEach(t),Nur=r(A9e," \u2014 "),EX=n(A9e,"A",{href:!0});var vut=s(EX);qur=r(vut,"TFRoFormerForTokenClassification"),vut.forEach(t),Our=r(A9e," (RoFormer model)"),A9e.forEach(t),Gur=i(oe),w8=n(oe,"LI",{});var L9e=s(w8);d1e=n(L9e,"STRONG",{});var Tut=s(d1e);Xur=r(Tut,"xlm"),Tut.forEach(t),Vur=r(L9e," \u2014 "),yX=n(L9e,"A",{href:!0});var Fut=s(yX);zur=r(Fut,"TFXLMForTokenClassification"),Fut.forEach(t),Wur=r(L9e," (XLM model)"),L9e.forEach(t),Qur=i(oe),A8=n(oe,"LI",{});var B9e=s(A8);c1e=n(B9e,"STRONG",{});var Cut=s(c1e);Hur=r(Cut,"xlm-roberta"),Cut.forEach(t),Uur=r(B9e," \u2014 "),wX=n(B9e,"A",{href:!0});var Mut=s(wX);Jur=r(Mut,"TFXLMRobertaForTokenClassification"),Mut.forEach(t),Yur=r(B9e," (XLM-RoBERTa model)"),B9e.forEach(t),Kur=i(oe),L8=n(oe,"LI",{});var x9e=s(L8);f1e=n(x9e,"STRONG",{});var Eut=s(f1e);Zur=r(Eut,"xlnet"),Eut.forEach(t),e1r=r(x9e," \u2014 "),AX=n(x9e,"A",{href:!0});var yut=s(AX);o1r=r(yut,"TFXLNetForTokenClassification"),yut.forEach(t),r1r=r(x9e," (XLNet model)"),x9e.forEach(t),oe.forEach(t),t1r=i(Aa),m1e=n(Aa,"P",{});var wut=s(m1e);a1r=r(wut,"Examples:"),wut.forEach(t),n1r=i(Aa),m(tA.$$.fragment,Aa),Aa.forEach(t),ii.forEach(t),uRe=i(d),Jc=n(d,"H2",{class:!0});var kPe=s(Jc);B8=n(kPe,"A",{id:!0,class:!0,href:!0});var Aut=s(B8);g1e=n(Aut,"SPAN",{});var Lut=s(g1e);m(aA.$$.fragment,Lut),Lut.forEach(t),Aut.forEach(t),s1r=i(kPe),h1e=n(kPe,"SPAN",{});var But=s(h1e);l1r=r(But,"TFAutoModelForQuestionAnswering"),But.forEach(t),kPe.forEach(t),bRe=i(d),xr=n(d,"DIV",{class:!0});var ci=s(xr);m(nA.$$.fragment,ci),i1r=i(ci),Yc=n(ci,"P",{});var nQ=s(Yc);d1r=r(nQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),p1e=n(nQ,"CODE",{});var xut=s(p1e);c1r=r(xut,"from_pretrained()"),xut.forEach(t),f1r=r(nQ,"class method or the "),_1e=n(nQ,"CODE",{});var kut=s(_1e);m1r=r(kut,"from_config()"),kut.forEach(t),g1r=r(nQ,`class
method.`),nQ.forEach(t),h1r=i(ci),sA=n(ci,"P",{});var RPe=s(sA);p1r=r(RPe,"This class cannot be instantiated directly using "),u1e=n(RPe,"CODE",{});var Rut=s(u1e);_1r=r(Rut,"__init__()"),Rut.forEach(t),u1r=r(RPe," (throws an error)."),RPe.forEach(t),b1r=i(ci),yt=n(ci,"DIV",{class:!0});var fi=s(yt);m(lA.$$.fragment,fi),v1r=i(fi),b1e=n(fi,"P",{});var Sut=s(b1e);T1r=r(Sut,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Sut.forEach(t),F1r=i(fi),Kc=n(fi,"P",{});var sQ=s(Kc);C1r=r(sQ,`Note:
Loading a model from its configuration file does `),v1e=n(sQ,"STRONG",{});var Put=s(v1e);M1r=r(Put,"not"),Put.forEach(t),E1r=r(sQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),T1e=n(sQ,"CODE",{});var $ut=s(T1e);y1r=r($ut,"from_pretrained()"),$ut.forEach(t),w1r=r(sQ,"to load the model weights."),sQ.forEach(t),A1r=i(fi),F1e=n(fi,"P",{});var Iut=s(F1e);L1r=r(Iut,"Examples:"),Iut.forEach(t),B1r=i(fi),m(iA.$$.fragment,fi),fi.forEach(t),x1r=i(ci),Eo=n(ci,"DIV",{class:!0});var La=s(Eo);m(dA.$$.fragment,La),k1r=i(La),C1e=n(La,"P",{});var jut=s(C1e);R1r=r(jut,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),jut.forEach(t),S1r=i(La),xn=n(La,"P",{});var VM=s(xn);P1r=r(VM,"The model class to instantiate is selected based on the "),M1e=n(VM,"CODE",{});var Dut=s(M1e);$1r=r(Dut,"model_type"),Dut.forEach(t),I1r=r(VM,` property of the config object (either
passed as an argument or loaded from `),E1e=n(VM,"CODE",{});var Nut=s(E1e);j1r=r(Nut,"pretrained_model_name_or_path"),Nut.forEach(t),D1r=r(VM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y1e=n(VM,"CODE",{});var qut=s(y1e);N1r=r(qut,"pretrained_model_name_or_path"),qut.forEach(t),q1r=r(VM,":"),VM.forEach(t),O1r=i(La),Z=n(La,"UL",{});var re=s(Z);x8=n(re,"LI",{});var k9e=s(x8);w1e=n(k9e,"STRONG",{});var Out=s(w1e);G1r=r(Out,"albert"),Out.forEach(t),X1r=r(k9e," \u2014 "),LX=n(k9e,"A",{href:!0});var Gut=s(LX);V1r=r(Gut,"TFAlbertForQuestionAnswering"),Gut.forEach(t),z1r=r(k9e," (ALBERT model)"),k9e.forEach(t),W1r=i(re),k8=n(re,"LI",{});var R9e=s(k8);A1e=n(R9e,"STRONG",{});var Xut=s(A1e);Q1r=r(Xut,"bert"),Xut.forEach(t),H1r=r(R9e," \u2014 "),BX=n(R9e,"A",{href:!0});var Vut=s(BX);U1r=r(Vut,"TFBertForQuestionAnswering"),Vut.forEach(t),J1r=r(R9e," (BERT model)"),R9e.forEach(t),Y1r=i(re),R8=n(re,"LI",{});var S9e=s(R8);L1e=n(S9e,"STRONG",{});var zut=s(L1e);K1r=r(zut,"camembert"),zut.forEach(t),Z1r=r(S9e," \u2014 "),xX=n(S9e,"A",{href:!0});var Wut=s(xX);ebr=r(Wut,"TFCamembertForQuestionAnswering"),Wut.forEach(t),obr=r(S9e," (CamemBERT model)"),S9e.forEach(t),rbr=i(re),S8=n(re,"LI",{});var P9e=s(S8);B1e=n(P9e,"STRONG",{});var Qut=s(B1e);tbr=r(Qut,"convbert"),Qut.forEach(t),abr=r(P9e," \u2014 "),kX=n(P9e,"A",{href:!0});var Hut=s(kX);nbr=r(Hut,"TFConvBertForQuestionAnswering"),Hut.forEach(t),sbr=r(P9e," (ConvBERT model)"),P9e.forEach(t),lbr=i(re),P8=n(re,"LI",{});var $9e=s(P8);x1e=n($9e,"STRONG",{});var Uut=s(x1e);ibr=r(Uut,"deberta"),Uut.forEach(t),dbr=r($9e," \u2014 "),RX=n($9e,"A",{href:!0});var Jut=s(RX);cbr=r(Jut,"TFDebertaForQuestionAnswering"),Jut.forEach(t),fbr=r($9e," (DeBERTa model)"),$9e.forEach(t),mbr=i(re),$8=n(re,"LI",{});var I9e=s($8);k1e=n(I9e,"STRONG",{});var Yut=s(k1e);gbr=r(Yut,"deberta-v2"),Yut.forEach(t),hbr=r(I9e," \u2014 "),SX=n(I9e,"A",{href:!0});var Kut=s(SX);pbr=r(Kut,"TFDebertaV2ForQuestionAnswering"),Kut.forEach(t),_br=r(I9e," (DeBERTa-v2 model)"),I9e.forEach(t),ubr=i(re),I8=n(re,"LI",{});var j9e=s(I8);R1e=n(j9e,"STRONG",{});var Zut=s(R1e);bbr=r(Zut,"distilbert"),Zut.forEach(t),vbr=r(j9e," \u2014 "),PX=n(j9e,"A",{href:!0});var e1t=s(PX);Tbr=r(e1t,"TFDistilBertForQuestionAnswering"),e1t.forEach(t),Fbr=r(j9e," (DistilBERT model)"),j9e.forEach(t),Cbr=i(re),j8=n(re,"LI",{});var D9e=s(j8);S1e=n(D9e,"STRONG",{});var o1t=s(S1e);Mbr=r(o1t,"electra"),o1t.forEach(t),Ebr=r(D9e," \u2014 "),$X=n(D9e,"A",{href:!0});var r1t=s($X);ybr=r(r1t,"TFElectraForQuestionAnswering"),r1t.forEach(t),wbr=r(D9e," (ELECTRA model)"),D9e.forEach(t),Abr=i(re),D8=n(re,"LI",{});var N9e=s(D8);P1e=n(N9e,"STRONG",{});var t1t=s(P1e);Lbr=r(t1t,"flaubert"),t1t.forEach(t),Bbr=r(N9e," \u2014 "),IX=n(N9e,"A",{href:!0});var a1t=s(IX);xbr=r(a1t,"TFFlaubertForQuestionAnsweringSimple"),a1t.forEach(t),kbr=r(N9e," (FlauBERT model)"),N9e.forEach(t),Rbr=i(re),N8=n(re,"LI",{});var q9e=s(N8);$1e=n(q9e,"STRONG",{});var n1t=s($1e);Sbr=r(n1t,"funnel"),n1t.forEach(t),Pbr=r(q9e," \u2014 "),jX=n(q9e,"A",{href:!0});var s1t=s(jX);$br=r(s1t,"TFFunnelForQuestionAnswering"),s1t.forEach(t),Ibr=r(q9e," (Funnel Transformer model)"),q9e.forEach(t),jbr=i(re),q8=n(re,"LI",{});var O9e=s(q8);I1e=n(O9e,"STRONG",{});var l1t=s(I1e);Dbr=r(l1t,"longformer"),l1t.forEach(t),Nbr=r(O9e," \u2014 "),DX=n(O9e,"A",{href:!0});var i1t=s(DX);qbr=r(i1t,"TFLongformerForQuestionAnswering"),i1t.forEach(t),Obr=r(O9e," (Longformer model)"),O9e.forEach(t),Gbr=i(re),O8=n(re,"LI",{});var G9e=s(O8);j1e=n(G9e,"STRONG",{});var d1t=s(j1e);Xbr=r(d1t,"mobilebert"),d1t.forEach(t),Vbr=r(G9e," \u2014 "),NX=n(G9e,"A",{href:!0});var c1t=s(NX);zbr=r(c1t,"TFMobileBertForQuestionAnswering"),c1t.forEach(t),Wbr=r(G9e," (MobileBERT model)"),G9e.forEach(t),Qbr=i(re),G8=n(re,"LI",{});var X9e=s(G8);D1e=n(X9e,"STRONG",{});var f1t=s(D1e);Hbr=r(f1t,"mpnet"),f1t.forEach(t),Ubr=r(X9e," \u2014 "),qX=n(X9e,"A",{href:!0});var m1t=s(qX);Jbr=r(m1t,"TFMPNetForQuestionAnswering"),m1t.forEach(t),Ybr=r(X9e," (MPNet model)"),X9e.forEach(t),Kbr=i(re),X8=n(re,"LI",{});var V9e=s(X8);N1e=n(V9e,"STRONG",{});var g1t=s(N1e);Zbr=r(g1t,"rembert"),g1t.forEach(t),e5r=r(V9e," \u2014 "),OX=n(V9e,"A",{href:!0});var h1t=s(OX);o5r=r(h1t,"TFRemBertForQuestionAnswering"),h1t.forEach(t),r5r=r(V9e," (RemBERT model)"),V9e.forEach(t),t5r=i(re),V8=n(re,"LI",{});var z9e=s(V8);q1e=n(z9e,"STRONG",{});var p1t=s(q1e);a5r=r(p1t,"roberta"),p1t.forEach(t),n5r=r(z9e," \u2014 "),GX=n(z9e,"A",{href:!0});var _1t=s(GX);s5r=r(_1t,"TFRobertaForQuestionAnswering"),_1t.forEach(t),l5r=r(z9e," (RoBERTa model)"),z9e.forEach(t),i5r=i(re),z8=n(re,"LI",{});var W9e=s(z8);O1e=n(W9e,"STRONG",{});var u1t=s(O1e);d5r=r(u1t,"roformer"),u1t.forEach(t),c5r=r(W9e," \u2014 "),XX=n(W9e,"A",{href:!0});var b1t=s(XX);f5r=r(b1t,"TFRoFormerForQuestionAnswering"),b1t.forEach(t),m5r=r(W9e," (RoFormer model)"),W9e.forEach(t),g5r=i(re),W8=n(re,"LI",{});var Q9e=s(W8);G1e=n(Q9e,"STRONG",{});var v1t=s(G1e);h5r=r(v1t,"xlm"),v1t.forEach(t),p5r=r(Q9e," \u2014 "),VX=n(Q9e,"A",{href:!0});var T1t=s(VX);_5r=r(T1t,"TFXLMForQuestionAnsweringSimple"),T1t.forEach(t),u5r=r(Q9e," (XLM model)"),Q9e.forEach(t),b5r=i(re),Q8=n(re,"LI",{});var H9e=s(Q8);X1e=n(H9e,"STRONG",{});var F1t=s(X1e);v5r=r(F1t,"xlm-roberta"),F1t.forEach(t),T5r=r(H9e," \u2014 "),zX=n(H9e,"A",{href:!0});var C1t=s(zX);F5r=r(C1t,"TFXLMRobertaForQuestionAnswering"),C1t.forEach(t),C5r=r(H9e," (XLM-RoBERTa model)"),H9e.forEach(t),M5r=i(re),H8=n(re,"LI",{});var U9e=s(H8);V1e=n(U9e,"STRONG",{});var M1t=s(V1e);E5r=r(M1t,"xlnet"),M1t.forEach(t),y5r=r(U9e," \u2014 "),WX=n(U9e,"A",{href:!0});var E1t=s(WX);w5r=r(E1t,"TFXLNetForQuestionAnsweringSimple"),E1t.forEach(t),A5r=r(U9e," (XLNet model)"),U9e.forEach(t),re.forEach(t),L5r=i(La),z1e=n(La,"P",{});var y1t=s(z1e);B5r=r(y1t,"Examples:"),y1t.forEach(t),x5r=i(La),m(cA.$$.fragment,La),La.forEach(t),ci.forEach(t),vRe=i(d),Zc=n(d,"H2",{class:!0});var SPe=s(Zc);U8=n(SPe,"A",{id:!0,class:!0,href:!0});var w1t=s(U8);W1e=n(w1t,"SPAN",{});var A1t=s(W1e);m(fA.$$.fragment,A1t),A1t.forEach(t),w1t.forEach(t),k5r=i(SPe),Q1e=n(SPe,"SPAN",{});var L1t=s(Q1e);R5r=r(L1t,"TFAutoModelForVision2Seq"),L1t.forEach(t),SPe.forEach(t),TRe=i(d),kr=n(d,"DIV",{class:!0});var mi=s(kr);m(mA.$$.fragment,mi),S5r=i(mi),ef=n(mi,"P",{});var lQ=s(ef);P5r=r(lQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),H1e=n(lQ,"CODE",{});var B1t=s(H1e);$5r=r(B1t,"from_pretrained()"),B1t.forEach(t),I5r=r(lQ,"class method or the "),U1e=n(lQ,"CODE",{});var x1t=s(U1e);j5r=r(x1t,"from_config()"),x1t.forEach(t),D5r=r(lQ,`class
method.`),lQ.forEach(t),N5r=i(mi),gA=n(mi,"P",{});var PPe=s(gA);q5r=r(PPe,"This class cannot be instantiated directly using "),J1e=n(PPe,"CODE",{});var k1t=s(J1e);O5r=r(k1t,"__init__()"),k1t.forEach(t),G5r=r(PPe," (throws an error)."),PPe.forEach(t),X5r=i(mi),wt=n(mi,"DIV",{class:!0});var gi=s(wt);m(hA.$$.fragment,gi),V5r=i(gi),Y1e=n(gi,"P",{});var R1t=s(Y1e);z5r=r(R1t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),R1t.forEach(t),W5r=i(gi),of=n(gi,"P",{});var iQ=s(of);Q5r=r(iQ,`Note:
Loading a model from its configuration file does `),K1e=n(iQ,"STRONG",{});var S1t=s(K1e);H5r=r(S1t,"not"),S1t.forEach(t),U5r=r(iQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Z1e=n(iQ,"CODE",{});var P1t=s(Z1e);J5r=r(P1t,"from_pretrained()"),P1t.forEach(t),Y5r=r(iQ,"to load the model weights."),iQ.forEach(t),K5r=i(gi),ebe=n(gi,"P",{});var $1t=s(ebe);Z5r=r($1t,"Examples:"),$1t.forEach(t),e2r=i(gi),m(pA.$$.fragment,gi),gi.forEach(t),o2r=i(mi),yo=n(mi,"DIV",{class:!0});var Ba=s(yo);m(_A.$$.fragment,Ba),r2r=i(Ba),obe=n(Ba,"P",{});var I1t=s(obe);t2r=r(I1t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),I1t.forEach(t),a2r=i(Ba),kn=n(Ba,"P",{});var zM=s(kn);n2r=r(zM,"The model class to instantiate is selected based on the "),rbe=n(zM,"CODE",{});var j1t=s(rbe);s2r=r(j1t,"model_type"),j1t.forEach(t),l2r=r(zM,` property of the config object (either
passed as an argument or loaded from `),tbe=n(zM,"CODE",{});var D1t=s(tbe);i2r=r(D1t,"pretrained_model_name_or_path"),D1t.forEach(t),d2r=r(zM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),abe=n(zM,"CODE",{});var N1t=s(abe);c2r=r(N1t,"pretrained_model_name_or_path"),N1t.forEach(t),f2r=r(zM,":"),zM.forEach(t),m2r=i(Ba),nbe=n(Ba,"UL",{});var q1t=s(nbe);J8=n(q1t,"LI",{});var J9e=s(J8);sbe=n(J9e,"STRONG",{});var O1t=s(sbe);g2r=r(O1t,"vision-encoder-decoder"),O1t.forEach(t),h2r=r(J9e," \u2014 "),QX=n(J9e,"A",{href:!0});var G1t=s(QX);p2r=r(G1t,"TFVisionEncoderDecoderModel"),G1t.forEach(t),_2r=r(J9e," (Vision Encoder decoder model)"),J9e.forEach(t),q1t.forEach(t),u2r=i(Ba),lbe=n(Ba,"P",{});var X1t=s(lbe);b2r=r(X1t,"Examples:"),X1t.forEach(t),v2r=i(Ba),m(uA.$$.fragment,Ba),Ba.forEach(t),mi.forEach(t),FRe=i(d),rf=n(d,"H2",{class:!0});var $Pe=s(rf);Y8=n($Pe,"A",{id:!0,class:!0,href:!0});var V1t=s(Y8);ibe=n(V1t,"SPAN",{});var z1t=s(ibe);m(bA.$$.fragment,z1t),z1t.forEach(t),V1t.forEach(t),T2r=i($Pe),dbe=n($Pe,"SPAN",{});var W1t=s(dbe);F2r=r(W1t,"TFAutoModelForSpeechSeq2Seq"),W1t.forEach(t),$Pe.forEach(t),CRe=i(d),Rr=n(d,"DIV",{class:!0});var hi=s(Rr);m(vA.$$.fragment,hi),C2r=i(hi),tf=n(hi,"P",{});var dQ=s(tf);M2r=r(dQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),cbe=n(dQ,"CODE",{});var Q1t=s(cbe);E2r=r(Q1t,"from_pretrained()"),Q1t.forEach(t),y2r=r(dQ,"class method or the "),fbe=n(dQ,"CODE",{});var H1t=s(fbe);w2r=r(H1t,"from_config()"),H1t.forEach(t),A2r=r(dQ,`class
method.`),dQ.forEach(t),L2r=i(hi),TA=n(hi,"P",{});var IPe=s(TA);B2r=r(IPe,"This class cannot be instantiated directly using "),mbe=n(IPe,"CODE",{});var U1t=s(mbe);x2r=r(U1t,"__init__()"),U1t.forEach(t),k2r=r(IPe," (throws an error)."),IPe.forEach(t),R2r=i(hi),At=n(hi,"DIV",{class:!0});var pi=s(At);m(FA.$$.fragment,pi),S2r=i(pi),gbe=n(pi,"P",{});var J1t=s(gbe);P2r=r(J1t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),J1t.forEach(t),$2r=i(pi),af=n(pi,"P",{});var cQ=s(af);I2r=r(cQ,`Note:
Loading a model from its configuration file does `),hbe=n(cQ,"STRONG",{});var Y1t=s(hbe);j2r=r(Y1t,"not"),Y1t.forEach(t),D2r=r(cQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),pbe=n(cQ,"CODE",{});var K1t=s(pbe);N2r=r(K1t,"from_pretrained()"),K1t.forEach(t),q2r=r(cQ,"to load the model weights."),cQ.forEach(t),O2r=i(pi),_be=n(pi,"P",{});var Z1t=s(_be);G2r=r(Z1t,"Examples:"),Z1t.forEach(t),X2r=i(pi),m(CA.$$.fragment,pi),pi.forEach(t),V2r=i(hi),wo=n(hi,"DIV",{class:!0});var xa=s(wo);m(MA.$$.fragment,xa),z2r=i(xa),ube=n(xa,"P",{});var ebt=s(ube);W2r=r(ebt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),ebt.forEach(t),Q2r=i(xa),Rn=n(xa,"P",{});var WM=s(Rn);H2r=r(WM,"The model class to instantiate is selected based on the "),bbe=n(WM,"CODE",{});var obt=s(bbe);U2r=r(obt,"model_type"),obt.forEach(t),J2r=r(WM,` property of the config object (either
passed as an argument or loaded from `),vbe=n(WM,"CODE",{});var rbt=s(vbe);Y2r=r(rbt,"pretrained_model_name_or_path"),rbt.forEach(t),K2r=r(WM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tbe=n(WM,"CODE",{});var tbt=s(Tbe);Z2r=r(tbt,"pretrained_model_name_or_path"),tbt.forEach(t),evr=r(WM,":"),WM.forEach(t),ovr=i(xa),Fbe=n(xa,"UL",{});var abt=s(Fbe);K8=n(abt,"LI",{});var Y9e=s(K8);Cbe=n(Y9e,"STRONG",{});var nbt=s(Cbe);rvr=r(nbt,"speech_to_text"),nbt.forEach(t),tvr=r(Y9e," \u2014 "),HX=n(Y9e,"A",{href:!0});var sbt=s(HX);avr=r(sbt,"TFSpeech2TextForConditionalGeneration"),sbt.forEach(t),nvr=r(Y9e," (Speech2Text model)"),Y9e.forEach(t),abt.forEach(t),svr=i(xa),Mbe=n(xa,"P",{});var lbt=s(Mbe);lvr=r(lbt,"Examples:"),lbt.forEach(t),ivr=i(xa),m(EA.$$.fragment,xa),xa.forEach(t),hi.forEach(t),MRe=i(d),nf=n(d,"H2",{class:!0});var jPe=s(nf);Z8=n(jPe,"A",{id:!0,class:!0,href:!0});var ibt=s(Z8);Ebe=n(ibt,"SPAN",{});var dbt=s(Ebe);m(yA.$$.fragment,dbt),dbt.forEach(t),ibt.forEach(t),dvr=i(jPe),ybe=n(jPe,"SPAN",{});var cbt=s(ybe);cvr=r(cbt,"FlaxAutoModel"),cbt.forEach(t),jPe.forEach(t),ERe=i(d),Sr=n(d,"DIV",{class:!0});var _i=s(Sr);m(wA.$$.fragment,_i),fvr=i(_i),sf=n(_i,"P",{});var fQ=s(sf);mvr=r(fQ,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),wbe=n(fQ,"CODE",{});var fbt=s(wbe);gvr=r(fbt,"from_pretrained()"),fbt.forEach(t),hvr=r(fQ,"class method or the "),Abe=n(fQ,"CODE",{});var mbt=s(Abe);pvr=r(mbt,"from_config()"),mbt.forEach(t),_vr=r(fQ,`class
method.`),fQ.forEach(t),uvr=i(_i),AA=n(_i,"P",{});var DPe=s(AA);bvr=r(DPe,"This class cannot be instantiated directly using "),Lbe=n(DPe,"CODE",{});var gbt=s(Lbe);vvr=r(gbt,"__init__()"),gbt.forEach(t),Tvr=r(DPe," (throws an error)."),DPe.forEach(t),Fvr=i(_i),Lt=n(_i,"DIV",{class:!0});var ui=s(Lt);m(LA.$$.fragment,ui),Cvr=i(ui),Bbe=n(ui,"P",{});var hbt=s(Bbe);Mvr=r(hbt,"Instantiates one of the base model classes of the library from a configuration."),hbt.forEach(t),Evr=i(ui),lf=n(ui,"P",{});var mQ=s(lf);yvr=r(mQ,`Note:
Loading a model from its configuration file does `),xbe=n(mQ,"STRONG",{});var pbt=s(xbe);wvr=r(pbt,"not"),pbt.forEach(t),Avr=r(mQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),kbe=n(mQ,"CODE",{});var _bt=s(kbe);Lvr=r(_bt,"from_pretrained()"),_bt.forEach(t),Bvr=r(mQ,"to load the model weights."),mQ.forEach(t),xvr=i(ui),Rbe=n(ui,"P",{});var ubt=s(Rbe);kvr=r(ubt,"Examples:"),ubt.forEach(t),Rvr=i(ui),m(BA.$$.fragment,ui),ui.forEach(t),Svr=i(_i),Ao=n(_i,"DIV",{class:!0});var ka=s(Ao);m(xA.$$.fragment,ka),Pvr=i(ka),Sbe=n(ka,"P",{});var bbt=s(Sbe);$vr=r(bbt,"Instantiate one of the base model classes of the library from a pretrained model."),bbt.forEach(t),Ivr=i(ka),Sn=n(ka,"P",{});var QM=s(Sn);jvr=r(QM,"The model class to instantiate is selected based on the "),Pbe=n(QM,"CODE",{});var vbt=s(Pbe);Dvr=r(vbt,"model_type"),vbt.forEach(t),Nvr=r(QM,` property of the config object (either
passed as an argument or loaded from `),$be=n(QM,"CODE",{});var Tbt=s($be);qvr=r(Tbt,"pretrained_model_name_or_path"),Tbt.forEach(t),Ovr=r(QM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ibe=n(QM,"CODE",{});var Fbt=s(Ibe);Gvr=r(Fbt,"pretrained_model_name_or_path"),Fbt.forEach(t),Xvr=r(QM,":"),QM.forEach(t),Vvr=i(ka),z=n(ka,"UL",{});var Q=s(z);eF=n(Q,"LI",{});var K9e=s(eF);jbe=n(K9e,"STRONG",{});var Cbt=s(jbe);zvr=r(Cbt,"albert"),Cbt.forEach(t),Wvr=r(K9e," \u2014 "),UX=n(K9e,"A",{href:!0});var Mbt=s(UX);Qvr=r(Mbt,"FlaxAlbertModel"),Mbt.forEach(t),Hvr=r(K9e," (ALBERT model)"),K9e.forEach(t),Uvr=i(Q),oF=n(Q,"LI",{});var Z9e=s(oF);Dbe=n(Z9e,"STRONG",{});var Ebt=s(Dbe);Jvr=r(Ebt,"bart"),Ebt.forEach(t),Yvr=r(Z9e," \u2014 "),JX=n(Z9e,"A",{href:!0});var ybt=s(JX);Kvr=r(ybt,"FlaxBartModel"),ybt.forEach(t),Zvr=r(Z9e," (BART model)"),Z9e.forEach(t),e6r=i(Q),rF=n(Q,"LI",{});var eBe=s(rF);Nbe=n(eBe,"STRONG",{});var wbt=s(Nbe);o6r=r(wbt,"beit"),wbt.forEach(t),r6r=r(eBe," \u2014 "),YX=n(eBe,"A",{href:!0});var Abt=s(YX);t6r=r(Abt,"FlaxBeitModel"),Abt.forEach(t),a6r=r(eBe," (BEiT model)"),eBe.forEach(t),n6r=i(Q),tF=n(Q,"LI",{});var oBe=s(tF);qbe=n(oBe,"STRONG",{});var Lbt=s(qbe);s6r=r(Lbt,"bert"),Lbt.forEach(t),l6r=r(oBe," \u2014 "),KX=n(oBe,"A",{href:!0});var Bbt=s(KX);i6r=r(Bbt,"FlaxBertModel"),Bbt.forEach(t),d6r=r(oBe," (BERT model)"),oBe.forEach(t),c6r=i(Q),aF=n(Q,"LI",{});var rBe=s(aF);Obe=n(rBe,"STRONG",{});var xbt=s(Obe);f6r=r(xbt,"big_bird"),xbt.forEach(t),m6r=r(rBe," \u2014 "),ZX=n(rBe,"A",{href:!0});var kbt=s(ZX);g6r=r(kbt,"FlaxBigBirdModel"),kbt.forEach(t),h6r=r(rBe," (BigBird model)"),rBe.forEach(t),p6r=i(Q),nF=n(Q,"LI",{});var tBe=s(nF);Gbe=n(tBe,"STRONG",{});var Rbt=s(Gbe);_6r=r(Rbt,"blenderbot"),Rbt.forEach(t),u6r=r(tBe," \u2014 "),eV=n(tBe,"A",{href:!0});var Sbt=s(eV);b6r=r(Sbt,"FlaxBlenderbotModel"),Sbt.forEach(t),v6r=r(tBe," (Blenderbot model)"),tBe.forEach(t),T6r=i(Q),sF=n(Q,"LI",{});var aBe=s(sF);Xbe=n(aBe,"STRONG",{});var Pbt=s(Xbe);F6r=r(Pbt,"blenderbot-small"),Pbt.forEach(t),C6r=r(aBe," \u2014 "),oV=n(aBe,"A",{href:!0});var $bt=s(oV);M6r=r($bt,"FlaxBlenderbotSmallModel"),$bt.forEach(t),E6r=r(aBe," (BlenderbotSmall model)"),aBe.forEach(t),y6r=i(Q),lF=n(Q,"LI",{});var nBe=s(lF);Vbe=n(nBe,"STRONG",{});var Ibt=s(Vbe);w6r=r(Ibt,"clip"),Ibt.forEach(t),A6r=r(nBe," \u2014 "),rV=n(nBe,"A",{href:!0});var jbt=s(rV);L6r=r(jbt,"FlaxCLIPModel"),jbt.forEach(t),B6r=r(nBe," (CLIP model)"),nBe.forEach(t),x6r=i(Q),iF=n(Q,"LI",{});var sBe=s(iF);zbe=n(sBe,"STRONG",{});var Dbt=s(zbe);k6r=r(Dbt,"distilbert"),Dbt.forEach(t),R6r=r(sBe," \u2014 "),tV=n(sBe,"A",{href:!0});var Nbt=s(tV);S6r=r(Nbt,"FlaxDistilBertModel"),Nbt.forEach(t),P6r=r(sBe," (DistilBERT model)"),sBe.forEach(t),$6r=i(Q),dF=n(Q,"LI",{});var lBe=s(dF);Wbe=n(lBe,"STRONG",{});var qbt=s(Wbe);I6r=r(qbt,"electra"),qbt.forEach(t),j6r=r(lBe," \u2014 "),aV=n(lBe,"A",{href:!0});var Obt=s(aV);D6r=r(Obt,"FlaxElectraModel"),Obt.forEach(t),N6r=r(lBe," (ELECTRA model)"),lBe.forEach(t),q6r=i(Q),cF=n(Q,"LI",{});var iBe=s(cF);Qbe=n(iBe,"STRONG",{});var Gbt=s(Qbe);O6r=r(Gbt,"gpt2"),Gbt.forEach(t),G6r=r(iBe," \u2014 "),nV=n(iBe,"A",{href:!0});var Xbt=s(nV);X6r=r(Xbt,"FlaxGPT2Model"),Xbt.forEach(t),V6r=r(iBe," (OpenAI GPT-2 model)"),iBe.forEach(t),z6r=i(Q),fF=n(Q,"LI",{});var dBe=s(fF);Hbe=n(dBe,"STRONG",{});var Vbt=s(Hbe);W6r=r(Vbt,"gpt_neo"),Vbt.forEach(t),Q6r=r(dBe," \u2014 "),sV=n(dBe,"A",{href:!0});var zbt=s(sV);H6r=r(zbt,"FlaxGPTNeoModel"),zbt.forEach(t),U6r=r(dBe," (GPT Neo model)"),dBe.forEach(t),J6r=i(Q),mF=n(Q,"LI",{});var cBe=s(mF);Ube=n(cBe,"STRONG",{});var Wbt=s(Ube);Y6r=r(Wbt,"gptj"),Wbt.forEach(t),K6r=r(cBe," \u2014 "),lV=n(cBe,"A",{href:!0});var Qbt=s(lV);Z6r=r(Qbt,"FlaxGPTJModel"),Qbt.forEach(t),e0r=r(cBe," (GPT-J model)"),cBe.forEach(t),o0r=i(Q),gF=n(Q,"LI",{});var fBe=s(gF);Jbe=n(fBe,"STRONG",{});var Hbt=s(Jbe);r0r=r(Hbt,"marian"),Hbt.forEach(t),t0r=r(fBe," \u2014 "),iV=n(fBe,"A",{href:!0});var Ubt=s(iV);a0r=r(Ubt,"FlaxMarianModel"),Ubt.forEach(t),n0r=r(fBe," (Marian model)"),fBe.forEach(t),s0r=i(Q),hF=n(Q,"LI",{});var mBe=s(hF);Ybe=n(mBe,"STRONG",{});var Jbt=s(Ybe);l0r=r(Jbt,"mbart"),Jbt.forEach(t),i0r=r(mBe," \u2014 "),dV=n(mBe,"A",{href:!0});var Ybt=s(dV);d0r=r(Ybt,"FlaxMBartModel"),Ybt.forEach(t),c0r=r(mBe," (mBART model)"),mBe.forEach(t),f0r=i(Q),pF=n(Q,"LI",{});var gBe=s(pF);Kbe=n(gBe,"STRONG",{});var Kbt=s(Kbe);m0r=r(Kbt,"mt5"),Kbt.forEach(t),g0r=r(gBe," \u2014 "),cV=n(gBe,"A",{href:!0});var Zbt=s(cV);h0r=r(Zbt,"FlaxMT5Model"),Zbt.forEach(t),p0r=r(gBe," (mT5 model)"),gBe.forEach(t),_0r=i(Q),_F=n(Q,"LI",{});var hBe=s(_F);Zbe=n(hBe,"STRONG",{});var e5t=s(Zbe);u0r=r(e5t,"pegasus"),e5t.forEach(t),b0r=r(hBe," \u2014 "),fV=n(hBe,"A",{href:!0});var o5t=s(fV);v0r=r(o5t,"FlaxPegasusModel"),o5t.forEach(t),T0r=r(hBe," (Pegasus model)"),hBe.forEach(t),F0r=i(Q),uF=n(Q,"LI",{});var pBe=s(uF);e5e=n(pBe,"STRONG",{});var r5t=s(e5e);C0r=r(r5t,"roberta"),r5t.forEach(t),M0r=r(pBe," \u2014 "),mV=n(pBe,"A",{href:!0});var t5t=s(mV);E0r=r(t5t,"FlaxRobertaModel"),t5t.forEach(t),y0r=r(pBe," (RoBERTa model)"),pBe.forEach(t),w0r=i(Q),bF=n(Q,"LI",{});var _Be=s(bF);o5e=n(_Be,"STRONG",{});var a5t=s(o5e);A0r=r(a5t,"roformer"),a5t.forEach(t),L0r=r(_Be," \u2014 "),gV=n(_Be,"A",{href:!0});var n5t=s(gV);B0r=r(n5t,"FlaxRoFormerModel"),n5t.forEach(t),x0r=r(_Be," (RoFormer model)"),_Be.forEach(t),k0r=i(Q),vF=n(Q,"LI",{});var uBe=s(vF);r5e=n(uBe,"STRONG",{});var s5t=s(r5e);R0r=r(s5t,"t5"),s5t.forEach(t),S0r=r(uBe," \u2014 "),hV=n(uBe,"A",{href:!0});var l5t=s(hV);P0r=r(l5t,"FlaxT5Model"),l5t.forEach(t),$0r=r(uBe," (T5 model)"),uBe.forEach(t),I0r=i(Q),TF=n(Q,"LI",{});var bBe=s(TF);t5e=n(bBe,"STRONG",{});var i5t=s(t5e);j0r=r(i5t,"vision-text-dual-encoder"),i5t.forEach(t),D0r=r(bBe," \u2014 "),pV=n(bBe,"A",{href:!0});var d5t=s(pV);N0r=r(d5t,"FlaxVisionTextDualEncoderModel"),d5t.forEach(t),q0r=r(bBe," (VisionTextDualEncoder model)"),bBe.forEach(t),O0r=i(Q),FF=n(Q,"LI",{});var vBe=s(FF);a5e=n(vBe,"STRONG",{});var c5t=s(a5e);G0r=r(c5t,"vit"),c5t.forEach(t),X0r=r(vBe," \u2014 "),_V=n(vBe,"A",{href:!0});var f5t=s(_V);V0r=r(f5t,"FlaxViTModel"),f5t.forEach(t),z0r=r(vBe," (ViT model)"),vBe.forEach(t),W0r=i(Q),CF=n(Q,"LI",{});var TBe=s(CF);n5e=n(TBe,"STRONG",{});var m5t=s(n5e);Q0r=r(m5t,"wav2vec2"),m5t.forEach(t),H0r=r(TBe," \u2014 "),uV=n(TBe,"A",{href:!0});var g5t=s(uV);U0r=r(g5t,"FlaxWav2Vec2Model"),g5t.forEach(t),J0r=r(TBe," (Wav2Vec2 model)"),TBe.forEach(t),Y0r=i(Q),MF=n(Q,"LI",{});var FBe=s(MF);s5e=n(FBe,"STRONG",{});var h5t=s(s5e);K0r=r(h5t,"xglm"),h5t.forEach(t),Z0r=r(FBe," \u2014 "),bV=n(FBe,"A",{href:!0});var p5t=s(bV);eTr=r(p5t,"FlaxXGLMModel"),p5t.forEach(t),oTr=r(FBe," (XGLM model)"),FBe.forEach(t),rTr=i(Q),EF=n(Q,"LI",{});var CBe=s(EF);l5e=n(CBe,"STRONG",{});var _5t=s(l5e);tTr=r(_5t,"xlm-roberta"),_5t.forEach(t),aTr=r(CBe," \u2014 "),vV=n(CBe,"A",{href:!0});var u5t=s(vV);nTr=r(u5t,"FlaxXLMRobertaModel"),u5t.forEach(t),sTr=r(CBe," (XLM-RoBERTa model)"),CBe.forEach(t),Q.forEach(t),lTr=i(ka),i5e=n(ka,"P",{});var b5t=s(i5e);iTr=r(b5t,"Examples:"),b5t.forEach(t),dTr=i(ka),m(kA.$$.fragment,ka),ka.forEach(t),_i.forEach(t),yRe=i(d),df=n(d,"H2",{class:!0});var NPe=s(df);yF=n(NPe,"A",{id:!0,class:!0,href:!0});var v5t=s(yF);d5e=n(v5t,"SPAN",{});var T5t=s(d5e);m(RA.$$.fragment,T5t),T5t.forEach(t),v5t.forEach(t),cTr=i(NPe),c5e=n(NPe,"SPAN",{});var F5t=s(c5e);fTr=r(F5t,"FlaxAutoModelForCausalLM"),F5t.forEach(t),NPe.forEach(t),wRe=i(d),Pr=n(d,"DIV",{class:!0});var bi=s(Pr);m(SA.$$.fragment,bi),mTr=i(bi),cf=n(bi,"P",{});var gQ=s(cf);gTr=r(gQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),f5e=n(gQ,"CODE",{});var C5t=s(f5e);hTr=r(C5t,"from_pretrained()"),C5t.forEach(t),pTr=r(gQ,"class method or the "),m5e=n(gQ,"CODE",{});var M5t=s(m5e);_Tr=r(M5t,"from_config()"),M5t.forEach(t),uTr=r(gQ,`class
method.`),gQ.forEach(t),bTr=i(bi),PA=n(bi,"P",{});var qPe=s(PA);vTr=r(qPe,"This class cannot be instantiated directly using "),g5e=n(qPe,"CODE",{});var E5t=s(g5e);TTr=r(E5t,"__init__()"),E5t.forEach(t),FTr=r(qPe," (throws an error)."),qPe.forEach(t),CTr=i(bi),Bt=n(bi,"DIV",{class:!0});var vi=s(Bt);m($A.$$.fragment,vi),MTr=i(vi),h5e=n(vi,"P",{});var y5t=s(h5e);ETr=r(y5t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),y5t.forEach(t),yTr=i(vi),ff=n(vi,"P",{});var hQ=s(ff);wTr=r(hQ,`Note:
Loading a model from its configuration file does `),p5e=n(hQ,"STRONG",{});var w5t=s(p5e);ATr=r(w5t,"not"),w5t.forEach(t),LTr=r(hQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),_5e=n(hQ,"CODE",{});var A5t=s(_5e);BTr=r(A5t,"from_pretrained()"),A5t.forEach(t),xTr=r(hQ,"to load the model weights."),hQ.forEach(t),kTr=i(vi),u5e=n(vi,"P",{});var L5t=s(u5e);RTr=r(L5t,"Examples:"),L5t.forEach(t),STr=i(vi),m(IA.$$.fragment,vi),vi.forEach(t),PTr=i(bi),Lo=n(bi,"DIV",{class:!0});var Ra=s(Lo);m(jA.$$.fragment,Ra),$Tr=i(Ra),b5e=n(Ra,"P",{});var B5t=s(b5e);ITr=r(B5t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),B5t.forEach(t),jTr=i(Ra),Pn=n(Ra,"P",{});var HM=s(Pn);DTr=r(HM,"The model class to instantiate is selected based on the "),v5e=n(HM,"CODE",{});var x5t=s(v5e);NTr=r(x5t,"model_type"),x5t.forEach(t),qTr=r(HM,` property of the config object (either
passed as an argument or loaded from `),T5e=n(HM,"CODE",{});var k5t=s(T5e);OTr=r(k5t,"pretrained_model_name_or_path"),k5t.forEach(t),GTr=r(HM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F5e=n(HM,"CODE",{});var R5t=s(F5e);XTr=r(R5t,"pretrained_model_name_or_path"),R5t.forEach(t),VTr=r(HM,":"),HM.forEach(t),zTr=i(Ra),ga=n(Ra,"UL",{});var Ti=s(ga);wF=n(Ti,"LI",{});var MBe=s(wF);C5e=n(MBe,"STRONG",{});var S5t=s(C5e);WTr=r(S5t,"bart"),S5t.forEach(t),QTr=r(MBe," \u2014 "),TV=n(MBe,"A",{href:!0});var P5t=s(TV);HTr=r(P5t,"FlaxBartForCausalLM"),P5t.forEach(t),UTr=r(MBe," (BART model)"),MBe.forEach(t),JTr=i(Ti),AF=n(Ti,"LI",{});var EBe=s(AF);M5e=n(EBe,"STRONG",{});var $5t=s(M5e);YTr=r($5t,"gpt2"),$5t.forEach(t),KTr=r(EBe," \u2014 "),FV=n(EBe,"A",{href:!0});var I5t=s(FV);ZTr=r(I5t,"FlaxGPT2LMHeadModel"),I5t.forEach(t),e8r=r(EBe," (OpenAI GPT-2 model)"),EBe.forEach(t),o8r=i(Ti),LF=n(Ti,"LI",{});var yBe=s(LF);E5e=n(yBe,"STRONG",{});var j5t=s(E5e);r8r=r(j5t,"gpt_neo"),j5t.forEach(t),t8r=r(yBe," \u2014 "),CV=n(yBe,"A",{href:!0});var D5t=s(CV);a8r=r(D5t,"FlaxGPTNeoForCausalLM"),D5t.forEach(t),n8r=r(yBe," (GPT Neo model)"),yBe.forEach(t),s8r=i(Ti),BF=n(Ti,"LI",{});var wBe=s(BF);y5e=n(wBe,"STRONG",{});var N5t=s(y5e);l8r=r(N5t,"gptj"),N5t.forEach(t),i8r=r(wBe," \u2014 "),MV=n(wBe,"A",{href:!0});var q5t=s(MV);d8r=r(q5t,"FlaxGPTJForCausalLM"),q5t.forEach(t),c8r=r(wBe," (GPT-J model)"),wBe.forEach(t),f8r=i(Ti),xF=n(Ti,"LI",{});var ABe=s(xF);w5e=n(ABe,"STRONG",{});var O5t=s(w5e);m8r=r(O5t,"xglm"),O5t.forEach(t),g8r=r(ABe," \u2014 "),EV=n(ABe,"A",{href:!0});var G5t=s(EV);h8r=r(G5t,"FlaxXGLMForCausalLM"),G5t.forEach(t),p8r=r(ABe," (XGLM model)"),ABe.forEach(t),Ti.forEach(t),_8r=i(Ra),A5e=n(Ra,"P",{});var X5t=s(A5e);u8r=r(X5t,"Examples:"),X5t.forEach(t),b8r=i(Ra),m(DA.$$.fragment,Ra),Ra.forEach(t),bi.forEach(t),ARe=i(d),mf=n(d,"H2",{class:!0});var OPe=s(mf);kF=n(OPe,"A",{id:!0,class:!0,href:!0});var V5t=s(kF);L5e=n(V5t,"SPAN",{});var z5t=s(L5e);m(NA.$$.fragment,z5t),z5t.forEach(t),V5t.forEach(t),v8r=i(OPe),B5e=n(OPe,"SPAN",{});var W5t=s(B5e);T8r=r(W5t,"FlaxAutoModelForPreTraining"),W5t.forEach(t),OPe.forEach(t),LRe=i(d),$r=n(d,"DIV",{class:!0});var Fi=s($r);m(qA.$$.fragment,Fi),F8r=i(Fi),gf=n(Fi,"P",{});var pQ=s(gf);C8r=r(pQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),x5e=n(pQ,"CODE",{});var Q5t=s(x5e);M8r=r(Q5t,"from_pretrained()"),Q5t.forEach(t),E8r=r(pQ,"class method or the "),k5e=n(pQ,"CODE",{});var H5t=s(k5e);y8r=r(H5t,"from_config()"),H5t.forEach(t),w8r=r(pQ,`class
method.`),pQ.forEach(t),A8r=i(Fi),OA=n(Fi,"P",{});var GPe=s(OA);L8r=r(GPe,"This class cannot be instantiated directly using "),R5e=n(GPe,"CODE",{});var U5t=s(R5e);B8r=r(U5t,"__init__()"),U5t.forEach(t),x8r=r(GPe," (throws an error)."),GPe.forEach(t),k8r=i(Fi),xt=n(Fi,"DIV",{class:!0});var Ci=s(xt);m(GA.$$.fragment,Ci),R8r=i(Ci),S5e=n(Ci,"P",{});var J5t=s(S5e);S8r=r(J5t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),J5t.forEach(t),P8r=i(Ci),hf=n(Ci,"P",{});var _Q=s(hf);$8r=r(_Q,`Note:
Loading a model from its configuration file does `),P5e=n(_Q,"STRONG",{});var Y5t=s(P5e);I8r=r(Y5t,"not"),Y5t.forEach(t),j8r=r(_Q,` load the model weights. It only affects the
model\u2019s configuration. Use `),$5e=n(_Q,"CODE",{});var K5t=s($5e);D8r=r(K5t,"from_pretrained()"),K5t.forEach(t),N8r=r(_Q,"to load the model weights."),_Q.forEach(t),q8r=i(Ci),I5e=n(Ci,"P",{});var Z5t=s(I5e);O8r=r(Z5t,"Examples:"),Z5t.forEach(t),G8r=i(Ci),m(XA.$$.fragment,Ci),Ci.forEach(t),X8r=i(Fi),Bo=n(Fi,"DIV",{class:!0});var Sa=s(Bo);m(VA.$$.fragment,Sa),V8r=i(Sa),j5e=n(Sa,"P",{});var e2t=s(j5e);z8r=r(e2t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),e2t.forEach(t),W8r=i(Sa),$n=n(Sa,"P",{});var UM=s($n);Q8r=r(UM,"The model class to instantiate is selected based on the "),D5e=n(UM,"CODE",{});var o2t=s(D5e);H8r=r(o2t,"model_type"),o2t.forEach(t),U8r=r(UM,` property of the config object (either
passed as an argument or loaded from `),N5e=n(UM,"CODE",{});var r2t=s(N5e);J8r=r(r2t,"pretrained_model_name_or_path"),r2t.forEach(t),Y8r=r(UM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q5e=n(UM,"CODE",{});var t2t=s(q5e);K8r=r(t2t,"pretrained_model_name_or_path"),t2t.forEach(t),Z8r=r(UM,":"),UM.forEach(t),eFr=i(Sa),ce=n(Sa,"UL",{});var ge=s(ce);RF=n(ge,"LI",{});var LBe=s(RF);O5e=n(LBe,"STRONG",{});var a2t=s(O5e);oFr=r(a2t,"albert"),a2t.forEach(t),rFr=r(LBe," \u2014 "),yV=n(LBe,"A",{href:!0});var n2t=s(yV);tFr=r(n2t,"FlaxAlbertForPreTraining"),n2t.forEach(t),aFr=r(LBe," (ALBERT model)"),LBe.forEach(t),nFr=i(ge),SF=n(ge,"LI",{});var BBe=s(SF);G5e=n(BBe,"STRONG",{});var s2t=s(G5e);sFr=r(s2t,"bart"),s2t.forEach(t),lFr=r(BBe," \u2014 "),wV=n(BBe,"A",{href:!0});var l2t=s(wV);iFr=r(l2t,"FlaxBartForConditionalGeneration"),l2t.forEach(t),dFr=r(BBe," (BART model)"),BBe.forEach(t),cFr=i(ge),PF=n(ge,"LI",{});var xBe=s(PF);X5e=n(xBe,"STRONG",{});var i2t=s(X5e);fFr=r(i2t,"bert"),i2t.forEach(t),mFr=r(xBe," \u2014 "),AV=n(xBe,"A",{href:!0});var d2t=s(AV);gFr=r(d2t,"FlaxBertForPreTraining"),d2t.forEach(t),hFr=r(xBe," (BERT model)"),xBe.forEach(t),pFr=i(ge),$F=n(ge,"LI",{});var kBe=s($F);V5e=n(kBe,"STRONG",{});var c2t=s(V5e);_Fr=r(c2t,"big_bird"),c2t.forEach(t),uFr=r(kBe," \u2014 "),LV=n(kBe,"A",{href:!0});var f2t=s(LV);bFr=r(f2t,"FlaxBigBirdForPreTraining"),f2t.forEach(t),vFr=r(kBe," (BigBird model)"),kBe.forEach(t),TFr=i(ge),IF=n(ge,"LI",{});var RBe=s(IF);z5e=n(RBe,"STRONG",{});var m2t=s(z5e);FFr=r(m2t,"electra"),m2t.forEach(t),CFr=r(RBe," \u2014 "),BV=n(RBe,"A",{href:!0});var g2t=s(BV);MFr=r(g2t,"FlaxElectraForPreTraining"),g2t.forEach(t),EFr=r(RBe," (ELECTRA model)"),RBe.forEach(t),yFr=i(ge),jF=n(ge,"LI",{});var SBe=s(jF);W5e=n(SBe,"STRONG",{});var h2t=s(W5e);wFr=r(h2t,"mbart"),h2t.forEach(t),AFr=r(SBe," \u2014 "),xV=n(SBe,"A",{href:!0});var p2t=s(xV);LFr=r(p2t,"FlaxMBartForConditionalGeneration"),p2t.forEach(t),BFr=r(SBe," (mBART model)"),SBe.forEach(t),xFr=i(ge),DF=n(ge,"LI",{});var PBe=s(DF);Q5e=n(PBe,"STRONG",{});var _2t=s(Q5e);kFr=r(_2t,"mt5"),_2t.forEach(t),RFr=r(PBe," \u2014 "),kV=n(PBe,"A",{href:!0});var u2t=s(kV);SFr=r(u2t,"FlaxMT5ForConditionalGeneration"),u2t.forEach(t),PFr=r(PBe," (mT5 model)"),PBe.forEach(t),$Fr=i(ge),NF=n(ge,"LI",{});var $Be=s(NF);H5e=n($Be,"STRONG",{});var b2t=s(H5e);IFr=r(b2t,"roberta"),b2t.forEach(t),jFr=r($Be," \u2014 "),RV=n($Be,"A",{href:!0});var v2t=s(RV);DFr=r(v2t,"FlaxRobertaForMaskedLM"),v2t.forEach(t),NFr=r($Be," (RoBERTa model)"),$Be.forEach(t),qFr=i(ge),qF=n(ge,"LI",{});var IBe=s(qF);U5e=n(IBe,"STRONG",{});var T2t=s(U5e);OFr=r(T2t,"roformer"),T2t.forEach(t),GFr=r(IBe," \u2014 "),SV=n(IBe,"A",{href:!0});var F2t=s(SV);XFr=r(F2t,"FlaxRoFormerForMaskedLM"),F2t.forEach(t),VFr=r(IBe," (RoFormer model)"),IBe.forEach(t),zFr=i(ge),OF=n(ge,"LI",{});var jBe=s(OF);J5e=n(jBe,"STRONG",{});var C2t=s(J5e);WFr=r(C2t,"t5"),C2t.forEach(t),QFr=r(jBe," \u2014 "),PV=n(jBe,"A",{href:!0});var M2t=s(PV);HFr=r(M2t,"FlaxT5ForConditionalGeneration"),M2t.forEach(t),UFr=r(jBe," (T5 model)"),jBe.forEach(t),JFr=i(ge),GF=n(ge,"LI",{});var DBe=s(GF);Y5e=n(DBe,"STRONG",{});var E2t=s(Y5e);YFr=r(E2t,"wav2vec2"),E2t.forEach(t),KFr=r(DBe," \u2014 "),$V=n(DBe,"A",{href:!0});var y2t=s($V);ZFr=r(y2t,"FlaxWav2Vec2ForPreTraining"),y2t.forEach(t),eCr=r(DBe," (Wav2Vec2 model)"),DBe.forEach(t),oCr=i(ge),XF=n(ge,"LI",{});var NBe=s(XF);K5e=n(NBe,"STRONG",{});var w2t=s(K5e);rCr=r(w2t,"xlm-roberta"),w2t.forEach(t),tCr=r(NBe," \u2014 "),IV=n(NBe,"A",{href:!0});var A2t=s(IV);aCr=r(A2t,"FlaxXLMRobertaForMaskedLM"),A2t.forEach(t),nCr=r(NBe," (XLM-RoBERTa model)"),NBe.forEach(t),ge.forEach(t),sCr=i(Sa),Z5e=n(Sa,"P",{});var L2t=s(Z5e);lCr=r(L2t,"Examples:"),L2t.forEach(t),iCr=i(Sa),m(zA.$$.fragment,Sa),Sa.forEach(t),Fi.forEach(t),BRe=i(d),pf=n(d,"H2",{class:!0});var XPe=s(pf);VF=n(XPe,"A",{id:!0,class:!0,href:!0});var B2t=s(VF);e2e=n(B2t,"SPAN",{});var x2t=s(e2e);m(WA.$$.fragment,x2t),x2t.forEach(t),B2t.forEach(t),dCr=i(XPe),o2e=n(XPe,"SPAN",{});var k2t=s(o2e);cCr=r(k2t,"FlaxAutoModelForMaskedLM"),k2t.forEach(t),XPe.forEach(t),xRe=i(d),Ir=n(d,"DIV",{class:!0});var Mi=s(Ir);m(QA.$$.fragment,Mi),fCr=i(Mi),_f=n(Mi,"P",{});var uQ=s(_f);mCr=r(uQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),r2e=n(uQ,"CODE",{});var R2t=s(r2e);gCr=r(R2t,"from_pretrained()"),R2t.forEach(t),hCr=r(uQ,"class method or the "),t2e=n(uQ,"CODE",{});var S2t=s(t2e);pCr=r(S2t,"from_config()"),S2t.forEach(t),_Cr=r(uQ,`class
method.`),uQ.forEach(t),uCr=i(Mi),HA=n(Mi,"P",{});var VPe=s(HA);bCr=r(VPe,"This class cannot be instantiated directly using "),a2e=n(VPe,"CODE",{});var P2t=s(a2e);vCr=r(P2t,"__init__()"),P2t.forEach(t),TCr=r(VPe," (throws an error)."),VPe.forEach(t),FCr=i(Mi),kt=n(Mi,"DIV",{class:!0});var Ei=s(kt);m(UA.$$.fragment,Ei),CCr=i(Ei),n2e=n(Ei,"P",{});var $2t=s(n2e);MCr=r($2t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),$2t.forEach(t),ECr=i(Ei),uf=n(Ei,"P",{});var bQ=s(uf);yCr=r(bQ,`Note:
Loading a model from its configuration file does `),s2e=n(bQ,"STRONG",{});var I2t=s(s2e);wCr=r(I2t,"not"),I2t.forEach(t),ACr=r(bQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),l2e=n(bQ,"CODE",{});var j2t=s(l2e);LCr=r(j2t,"from_pretrained()"),j2t.forEach(t),BCr=r(bQ,"to load the model weights."),bQ.forEach(t),xCr=i(Ei),i2e=n(Ei,"P",{});var D2t=s(i2e);kCr=r(D2t,"Examples:"),D2t.forEach(t),RCr=i(Ei),m(JA.$$.fragment,Ei),Ei.forEach(t),SCr=i(Mi),xo=n(Mi,"DIV",{class:!0});var Pa=s(xo);m(YA.$$.fragment,Pa),PCr=i(Pa),d2e=n(Pa,"P",{});var N2t=s(d2e);$Cr=r(N2t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),N2t.forEach(t),ICr=i(Pa),In=n(Pa,"P",{});var JM=s(In);jCr=r(JM,"The model class to instantiate is selected based on the "),c2e=n(JM,"CODE",{});var q2t=s(c2e);DCr=r(q2t,"model_type"),q2t.forEach(t),NCr=r(JM,` property of the config object (either
passed as an argument or loaded from `),f2e=n(JM,"CODE",{});var O2t=s(f2e);qCr=r(O2t,"pretrained_model_name_or_path"),O2t.forEach(t),OCr=r(JM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m2e=n(JM,"CODE",{});var G2t=s(m2e);GCr=r(G2t,"pretrained_model_name_or_path"),G2t.forEach(t),XCr=r(JM,":"),JM.forEach(t),VCr=i(Pa),ue=n(Pa,"UL",{});var ye=s(ue);zF=n(ye,"LI",{});var qBe=s(zF);g2e=n(qBe,"STRONG",{});var X2t=s(g2e);zCr=r(X2t,"albert"),X2t.forEach(t),WCr=r(qBe," \u2014 "),jV=n(qBe,"A",{href:!0});var V2t=s(jV);QCr=r(V2t,"FlaxAlbertForMaskedLM"),V2t.forEach(t),HCr=r(qBe," (ALBERT model)"),qBe.forEach(t),UCr=i(ye),WF=n(ye,"LI",{});var OBe=s(WF);h2e=n(OBe,"STRONG",{});var z2t=s(h2e);JCr=r(z2t,"bart"),z2t.forEach(t),YCr=r(OBe," \u2014 "),DV=n(OBe,"A",{href:!0});var W2t=s(DV);KCr=r(W2t,"FlaxBartForConditionalGeneration"),W2t.forEach(t),ZCr=r(OBe," (BART model)"),OBe.forEach(t),eMr=i(ye),QF=n(ye,"LI",{});var GBe=s(QF);p2e=n(GBe,"STRONG",{});var Q2t=s(p2e);oMr=r(Q2t,"bert"),Q2t.forEach(t),rMr=r(GBe," \u2014 "),NV=n(GBe,"A",{href:!0});var H2t=s(NV);tMr=r(H2t,"FlaxBertForMaskedLM"),H2t.forEach(t),aMr=r(GBe," (BERT model)"),GBe.forEach(t),nMr=i(ye),HF=n(ye,"LI",{});var XBe=s(HF);_2e=n(XBe,"STRONG",{});var U2t=s(_2e);sMr=r(U2t,"big_bird"),U2t.forEach(t),lMr=r(XBe," \u2014 "),qV=n(XBe,"A",{href:!0});var J2t=s(qV);iMr=r(J2t,"FlaxBigBirdForMaskedLM"),J2t.forEach(t),dMr=r(XBe," (BigBird model)"),XBe.forEach(t),cMr=i(ye),UF=n(ye,"LI",{});var VBe=s(UF);u2e=n(VBe,"STRONG",{});var Y2t=s(u2e);fMr=r(Y2t,"distilbert"),Y2t.forEach(t),mMr=r(VBe," \u2014 "),OV=n(VBe,"A",{href:!0});var K2t=s(OV);gMr=r(K2t,"FlaxDistilBertForMaskedLM"),K2t.forEach(t),hMr=r(VBe," (DistilBERT model)"),VBe.forEach(t),pMr=i(ye),JF=n(ye,"LI",{});var zBe=s(JF);b2e=n(zBe,"STRONG",{});var Z2t=s(b2e);_Mr=r(Z2t,"electra"),Z2t.forEach(t),uMr=r(zBe," \u2014 "),GV=n(zBe,"A",{href:!0});var evt=s(GV);bMr=r(evt,"FlaxElectraForMaskedLM"),evt.forEach(t),vMr=r(zBe," (ELECTRA model)"),zBe.forEach(t),TMr=i(ye),YF=n(ye,"LI",{});var WBe=s(YF);v2e=n(WBe,"STRONG",{});var ovt=s(v2e);FMr=r(ovt,"mbart"),ovt.forEach(t),CMr=r(WBe," \u2014 "),XV=n(WBe,"A",{href:!0});var rvt=s(XV);MMr=r(rvt,"FlaxMBartForConditionalGeneration"),rvt.forEach(t),EMr=r(WBe," (mBART model)"),WBe.forEach(t),yMr=i(ye),KF=n(ye,"LI",{});var QBe=s(KF);T2e=n(QBe,"STRONG",{});var tvt=s(T2e);wMr=r(tvt,"roberta"),tvt.forEach(t),AMr=r(QBe," \u2014 "),VV=n(QBe,"A",{href:!0});var avt=s(VV);LMr=r(avt,"FlaxRobertaForMaskedLM"),avt.forEach(t),BMr=r(QBe," (RoBERTa model)"),QBe.forEach(t),xMr=i(ye),ZF=n(ye,"LI",{});var HBe=s(ZF);F2e=n(HBe,"STRONG",{});var nvt=s(F2e);kMr=r(nvt,"roformer"),nvt.forEach(t),RMr=r(HBe," \u2014 "),zV=n(HBe,"A",{href:!0});var svt=s(zV);SMr=r(svt,"FlaxRoFormerForMaskedLM"),svt.forEach(t),PMr=r(HBe," (RoFormer model)"),HBe.forEach(t),$Mr=i(ye),eC=n(ye,"LI",{});var UBe=s(eC);C2e=n(UBe,"STRONG",{});var lvt=s(C2e);IMr=r(lvt,"xlm-roberta"),lvt.forEach(t),jMr=r(UBe," \u2014 "),WV=n(UBe,"A",{href:!0});var ivt=s(WV);DMr=r(ivt,"FlaxXLMRobertaForMaskedLM"),ivt.forEach(t),NMr=r(UBe," (XLM-RoBERTa model)"),UBe.forEach(t),ye.forEach(t),qMr=i(Pa),M2e=n(Pa,"P",{});var dvt=s(M2e);OMr=r(dvt,"Examples:"),dvt.forEach(t),GMr=i(Pa),m(KA.$$.fragment,Pa),Pa.forEach(t),Mi.forEach(t),kRe=i(d),bf=n(d,"H2",{class:!0});var zPe=s(bf);oC=n(zPe,"A",{id:!0,class:!0,href:!0});var cvt=s(oC);E2e=n(cvt,"SPAN",{});var fvt=s(E2e);m(ZA.$$.fragment,fvt),fvt.forEach(t),cvt.forEach(t),XMr=i(zPe),y2e=n(zPe,"SPAN",{});var mvt=s(y2e);VMr=r(mvt,"FlaxAutoModelForSeq2SeqLM"),mvt.forEach(t),zPe.forEach(t),RRe=i(d),jr=n(d,"DIV",{class:!0});var yi=s(jr);m(eL.$$.fragment,yi),zMr=i(yi),vf=n(yi,"P",{});var vQ=s(vf);WMr=r(vQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),w2e=n(vQ,"CODE",{});var gvt=s(w2e);QMr=r(gvt,"from_pretrained()"),gvt.forEach(t),HMr=r(vQ,"class method or the "),A2e=n(vQ,"CODE",{});var hvt=s(A2e);UMr=r(hvt,"from_config()"),hvt.forEach(t),JMr=r(vQ,`class
method.`),vQ.forEach(t),YMr=i(yi),oL=n(yi,"P",{});var WPe=s(oL);KMr=r(WPe,"This class cannot be instantiated directly using "),L2e=n(WPe,"CODE",{});var pvt=s(L2e);ZMr=r(pvt,"__init__()"),pvt.forEach(t),e4r=r(WPe," (throws an error)."),WPe.forEach(t),o4r=i(yi),Rt=n(yi,"DIV",{class:!0});var wi=s(Rt);m(rL.$$.fragment,wi),r4r=i(wi),B2e=n(wi,"P",{});var _vt=s(B2e);t4r=r(_vt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_vt.forEach(t),a4r=i(wi),Tf=n(wi,"P",{});var TQ=s(Tf);n4r=r(TQ,`Note:
Loading a model from its configuration file does `),x2e=n(TQ,"STRONG",{});var uvt=s(x2e);s4r=r(uvt,"not"),uvt.forEach(t),l4r=r(TQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),k2e=n(TQ,"CODE",{});var bvt=s(k2e);i4r=r(bvt,"from_pretrained()"),bvt.forEach(t),d4r=r(TQ,"to load the model weights."),TQ.forEach(t),c4r=i(wi),R2e=n(wi,"P",{});var vvt=s(R2e);f4r=r(vvt,"Examples:"),vvt.forEach(t),m4r=i(wi),m(tL.$$.fragment,wi),wi.forEach(t),g4r=i(yi),ko=n(yi,"DIV",{class:!0});var $a=s(ko);m(aL.$$.fragment,$a),h4r=i($a),S2e=n($a,"P",{});var Tvt=s(S2e);p4r=r(Tvt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Tvt.forEach(t),_4r=i($a),jn=n($a,"P",{});var YM=s(jn);u4r=r(YM,"The model class to instantiate is selected based on the "),P2e=n(YM,"CODE",{});var Fvt=s(P2e);b4r=r(Fvt,"model_type"),Fvt.forEach(t),v4r=r(YM,` property of the config object (either
passed as an argument or loaded from `),$2e=n(YM,"CODE",{});var Cvt=s($2e);T4r=r(Cvt,"pretrained_model_name_or_path"),Cvt.forEach(t),F4r=r(YM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I2e=n(YM,"CODE",{});var Mvt=s(I2e);C4r=r(Mvt,"pretrained_model_name_or_path"),Mvt.forEach(t),M4r=r(YM,":"),YM.forEach(t),E4r=i($a),Me=n($a,"UL",{});var lo=s(Me);rC=n(lo,"LI",{});var JBe=s(rC);j2e=n(JBe,"STRONG",{});var Evt=s(j2e);y4r=r(Evt,"bart"),Evt.forEach(t),w4r=r(JBe," \u2014 "),QV=n(JBe,"A",{href:!0});var yvt=s(QV);A4r=r(yvt,"FlaxBartForConditionalGeneration"),yvt.forEach(t),L4r=r(JBe," (BART model)"),JBe.forEach(t),B4r=i(lo),tC=n(lo,"LI",{});var YBe=s(tC);D2e=n(YBe,"STRONG",{});var wvt=s(D2e);x4r=r(wvt,"blenderbot"),wvt.forEach(t),k4r=r(YBe," \u2014 "),HV=n(YBe,"A",{href:!0});var Avt=s(HV);R4r=r(Avt,"FlaxBlenderbotForConditionalGeneration"),Avt.forEach(t),S4r=r(YBe," (Blenderbot model)"),YBe.forEach(t),P4r=i(lo),aC=n(lo,"LI",{});var KBe=s(aC);N2e=n(KBe,"STRONG",{});var Lvt=s(N2e);$4r=r(Lvt,"blenderbot-small"),Lvt.forEach(t),I4r=r(KBe," \u2014 "),UV=n(KBe,"A",{href:!0});var Bvt=s(UV);j4r=r(Bvt,"FlaxBlenderbotSmallForConditionalGeneration"),Bvt.forEach(t),D4r=r(KBe," (BlenderbotSmall model)"),KBe.forEach(t),N4r=i(lo),nC=n(lo,"LI",{});var ZBe=s(nC);q2e=n(ZBe,"STRONG",{});var xvt=s(q2e);q4r=r(xvt,"encoder-decoder"),xvt.forEach(t),O4r=r(ZBe," \u2014 "),JV=n(ZBe,"A",{href:!0});var kvt=s(JV);G4r=r(kvt,"FlaxEncoderDecoderModel"),kvt.forEach(t),X4r=r(ZBe," (Encoder decoder model)"),ZBe.forEach(t),V4r=i(lo),sC=n(lo,"LI",{});var exe=s(sC);O2e=n(exe,"STRONG",{});var Rvt=s(O2e);z4r=r(Rvt,"marian"),Rvt.forEach(t),W4r=r(exe," \u2014 "),YV=n(exe,"A",{href:!0});var Svt=s(YV);Q4r=r(Svt,"FlaxMarianMTModel"),Svt.forEach(t),H4r=r(exe," (Marian model)"),exe.forEach(t),U4r=i(lo),lC=n(lo,"LI",{});var oxe=s(lC);G2e=n(oxe,"STRONG",{});var Pvt=s(G2e);J4r=r(Pvt,"mbart"),Pvt.forEach(t),Y4r=r(oxe," \u2014 "),KV=n(oxe,"A",{href:!0});var $vt=s(KV);K4r=r($vt,"FlaxMBartForConditionalGeneration"),$vt.forEach(t),Z4r=r(oxe," (mBART model)"),oxe.forEach(t),eEr=i(lo),iC=n(lo,"LI",{});var rxe=s(iC);X2e=n(rxe,"STRONG",{});var Ivt=s(X2e);oEr=r(Ivt,"mt5"),Ivt.forEach(t),rEr=r(rxe," \u2014 "),ZV=n(rxe,"A",{href:!0});var jvt=s(ZV);tEr=r(jvt,"FlaxMT5ForConditionalGeneration"),jvt.forEach(t),aEr=r(rxe," (mT5 model)"),rxe.forEach(t),nEr=i(lo),dC=n(lo,"LI",{});var txe=s(dC);V2e=n(txe,"STRONG",{});var Dvt=s(V2e);sEr=r(Dvt,"pegasus"),Dvt.forEach(t),lEr=r(txe," \u2014 "),ez=n(txe,"A",{href:!0});var Nvt=s(ez);iEr=r(Nvt,"FlaxPegasusForConditionalGeneration"),Nvt.forEach(t),dEr=r(txe," (Pegasus model)"),txe.forEach(t),cEr=i(lo),cC=n(lo,"LI",{});var axe=s(cC);z2e=n(axe,"STRONG",{});var qvt=s(z2e);fEr=r(qvt,"t5"),qvt.forEach(t),mEr=r(axe," \u2014 "),oz=n(axe,"A",{href:!0});var Ovt=s(oz);gEr=r(Ovt,"FlaxT5ForConditionalGeneration"),Ovt.forEach(t),hEr=r(axe," (T5 model)"),axe.forEach(t),lo.forEach(t),pEr=i($a),W2e=n($a,"P",{});var Gvt=s(W2e);_Er=r(Gvt,"Examples:"),Gvt.forEach(t),uEr=i($a),m(nL.$$.fragment,$a),$a.forEach(t),yi.forEach(t),SRe=i(d),Ff=n(d,"H2",{class:!0});var QPe=s(Ff);fC=n(QPe,"A",{id:!0,class:!0,href:!0});var Xvt=s(fC);Q2e=n(Xvt,"SPAN",{});var Vvt=s(Q2e);m(sL.$$.fragment,Vvt),Vvt.forEach(t),Xvt.forEach(t),bEr=i(QPe),H2e=n(QPe,"SPAN",{});var zvt=s(H2e);vEr=r(zvt,"FlaxAutoModelForSequenceClassification"),zvt.forEach(t),QPe.forEach(t),PRe=i(d),Dr=n(d,"DIV",{class:!0});var Ai=s(Dr);m(lL.$$.fragment,Ai),TEr=i(Ai),Cf=n(Ai,"P",{});var FQ=s(Cf);FEr=r(FQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),U2e=n(FQ,"CODE",{});var Wvt=s(U2e);CEr=r(Wvt,"from_pretrained()"),Wvt.forEach(t),MEr=r(FQ,"class method or the "),J2e=n(FQ,"CODE",{});var Qvt=s(J2e);EEr=r(Qvt,"from_config()"),Qvt.forEach(t),yEr=r(FQ,`class
method.`),FQ.forEach(t),wEr=i(Ai),iL=n(Ai,"P",{});var HPe=s(iL);AEr=r(HPe,"This class cannot be instantiated directly using "),Y2e=n(HPe,"CODE",{});var Hvt=s(Y2e);LEr=r(Hvt,"__init__()"),Hvt.forEach(t),BEr=r(HPe," (throws an error)."),HPe.forEach(t),xEr=i(Ai),St=n(Ai,"DIV",{class:!0});var Li=s(St);m(dL.$$.fragment,Li),kEr=i(Li),K2e=n(Li,"P",{});var Uvt=s(K2e);REr=r(Uvt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Uvt.forEach(t),SEr=i(Li),Mf=n(Li,"P",{});var CQ=s(Mf);PEr=r(CQ,`Note:
Loading a model from its configuration file does `),Z2e=n(CQ,"STRONG",{});var Jvt=s(Z2e);$Er=r(Jvt,"not"),Jvt.forEach(t),IEr=r(CQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),eve=n(CQ,"CODE",{});var Yvt=s(eve);jEr=r(Yvt,"from_pretrained()"),Yvt.forEach(t),DEr=r(CQ,"to load the model weights."),CQ.forEach(t),NEr=i(Li),ove=n(Li,"P",{});var Kvt=s(ove);qEr=r(Kvt,"Examples:"),Kvt.forEach(t),OEr=i(Li),m(cL.$$.fragment,Li),Li.forEach(t),GEr=i(Ai),Ro=n(Ai,"DIV",{class:!0});var Ia=s(Ro);m(fL.$$.fragment,Ia),XEr=i(Ia),rve=n(Ia,"P",{});var Zvt=s(rve);VEr=r(Zvt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Zvt.forEach(t),zEr=i(Ia),Dn=n(Ia,"P",{});var KM=s(Dn);WEr=r(KM,"The model class to instantiate is selected based on the "),tve=n(KM,"CODE",{});var e6t=s(tve);QEr=r(e6t,"model_type"),e6t.forEach(t),HEr=r(KM,` property of the config object (either
passed as an argument or loaded from `),ave=n(KM,"CODE",{});var o6t=s(ave);UEr=r(o6t,"pretrained_model_name_or_path"),o6t.forEach(t),JEr=r(KM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nve=n(KM,"CODE",{});var r6t=s(nve);YEr=r(r6t,"pretrained_model_name_or_path"),r6t.forEach(t),KEr=r(KM,":"),KM.forEach(t),ZEr=i(Ia),be=n(Ia,"UL",{});var we=s(be);mC=n(we,"LI",{});var nxe=s(mC);sve=n(nxe,"STRONG",{});var t6t=s(sve);e3r=r(t6t,"albert"),t6t.forEach(t),o3r=r(nxe," \u2014 "),rz=n(nxe,"A",{href:!0});var a6t=s(rz);r3r=r(a6t,"FlaxAlbertForSequenceClassification"),a6t.forEach(t),t3r=r(nxe," (ALBERT model)"),nxe.forEach(t),a3r=i(we),gC=n(we,"LI",{});var sxe=s(gC);lve=n(sxe,"STRONG",{});var n6t=s(lve);n3r=r(n6t,"bart"),n6t.forEach(t),s3r=r(sxe," \u2014 "),tz=n(sxe,"A",{href:!0});var s6t=s(tz);l3r=r(s6t,"FlaxBartForSequenceClassification"),s6t.forEach(t),i3r=r(sxe," (BART model)"),sxe.forEach(t),d3r=i(we),hC=n(we,"LI",{});var lxe=s(hC);ive=n(lxe,"STRONG",{});var l6t=s(ive);c3r=r(l6t,"bert"),l6t.forEach(t),f3r=r(lxe," \u2014 "),az=n(lxe,"A",{href:!0});var i6t=s(az);m3r=r(i6t,"FlaxBertForSequenceClassification"),i6t.forEach(t),g3r=r(lxe," (BERT model)"),lxe.forEach(t),h3r=i(we),pC=n(we,"LI",{});var ixe=s(pC);dve=n(ixe,"STRONG",{});var d6t=s(dve);p3r=r(d6t,"big_bird"),d6t.forEach(t),_3r=r(ixe," \u2014 "),nz=n(ixe,"A",{href:!0});var c6t=s(nz);u3r=r(c6t,"FlaxBigBirdForSequenceClassification"),c6t.forEach(t),b3r=r(ixe," (BigBird model)"),ixe.forEach(t),v3r=i(we),_C=n(we,"LI",{});var dxe=s(_C);cve=n(dxe,"STRONG",{});var f6t=s(cve);T3r=r(f6t,"distilbert"),f6t.forEach(t),F3r=r(dxe," \u2014 "),sz=n(dxe,"A",{href:!0});var m6t=s(sz);C3r=r(m6t,"FlaxDistilBertForSequenceClassification"),m6t.forEach(t),M3r=r(dxe," (DistilBERT model)"),dxe.forEach(t),E3r=i(we),uC=n(we,"LI",{});var cxe=s(uC);fve=n(cxe,"STRONG",{});var g6t=s(fve);y3r=r(g6t,"electra"),g6t.forEach(t),w3r=r(cxe," \u2014 "),lz=n(cxe,"A",{href:!0});var h6t=s(lz);A3r=r(h6t,"FlaxElectraForSequenceClassification"),h6t.forEach(t),L3r=r(cxe," (ELECTRA model)"),cxe.forEach(t),B3r=i(we),bC=n(we,"LI",{});var fxe=s(bC);mve=n(fxe,"STRONG",{});var p6t=s(mve);x3r=r(p6t,"mbart"),p6t.forEach(t),k3r=r(fxe," \u2014 "),iz=n(fxe,"A",{href:!0});var _6t=s(iz);R3r=r(_6t,"FlaxMBartForSequenceClassification"),_6t.forEach(t),S3r=r(fxe," (mBART model)"),fxe.forEach(t),P3r=i(we),vC=n(we,"LI",{});var mxe=s(vC);gve=n(mxe,"STRONG",{});var u6t=s(gve);$3r=r(u6t,"roberta"),u6t.forEach(t),I3r=r(mxe," \u2014 "),dz=n(mxe,"A",{href:!0});var b6t=s(dz);j3r=r(b6t,"FlaxRobertaForSequenceClassification"),b6t.forEach(t),D3r=r(mxe," (RoBERTa model)"),mxe.forEach(t),N3r=i(we),TC=n(we,"LI",{});var gxe=s(TC);hve=n(gxe,"STRONG",{});var v6t=s(hve);q3r=r(v6t,"roformer"),v6t.forEach(t),O3r=r(gxe," \u2014 "),cz=n(gxe,"A",{href:!0});var T6t=s(cz);G3r=r(T6t,"FlaxRoFormerForSequenceClassification"),T6t.forEach(t),X3r=r(gxe," (RoFormer model)"),gxe.forEach(t),V3r=i(we),FC=n(we,"LI",{});var hxe=s(FC);pve=n(hxe,"STRONG",{});var F6t=s(pve);z3r=r(F6t,"xlm-roberta"),F6t.forEach(t),W3r=r(hxe," \u2014 "),fz=n(hxe,"A",{href:!0});var C6t=s(fz);Q3r=r(C6t,"FlaxXLMRobertaForSequenceClassification"),C6t.forEach(t),H3r=r(hxe," (XLM-RoBERTa model)"),hxe.forEach(t),we.forEach(t),U3r=i(Ia),_ve=n(Ia,"P",{});var M6t=s(_ve);J3r=r(M6t,"Examples:"),M6t.forEach(t),Y3r=i(Ia),m(mL.$$.fragment,Ia),Ia.forEach(t),Ai.forEach(t),$Re=i(d),Ef=n(d,"H2",{class:!0});var UPe=s(Ef);CC=n(UPe,"A",{id:!0,class:!0,href:!0});var E6t=s(CC);uve=n(E6t,"SPAN",{});var y6t=s(uve);m(gL.$$.fragment,y6t),y6t.forEach(t),E6t.forEach(t),K3r=i(UPe),bve=n(UPe,"SPAN",{});var w6t=s(bve);Z3r=r(w6t,"FlaxAutoModelForSpeechSeq2Seq"),w6t.forEach(t),UPe.forEach(t),IRe=i(d),Nr=n(d,"DIV",{class:!0});var Bi=s(Nr);m(hL.$$.fragment,Bi),eyr=i(Bi),yf=n(Bi,"P",{});var MQ=s(yf);oyr=r(MQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),vve=n(MQ,"CODE",{});var A6t=s(vve);ryr=r(A6t,"from_pretrained()"),A6t.forEach(t),tyr=r(MQ,"class method or the "),Tve=n(MQ,"CODE",{});var L6t=s(Tve);ayr=r(L6t,"from_config()"),L6t.forEach(t),nyr=r(MQ,`class
method.`),MQ.forEach(t),syr=i(Bi),pL=n(Bi,"P",{});var JPe=s(pL);lyr=r(JPe,"This class cannot be instantiated directly using "),Fve=n(JPe,"CODE",{});var B6t=s(Fve);iyr=r(B6t,"__init__()"),B6t.forEach(t),dyr=r(JPe," (throws an error)."),JPe.forEach(t),cyr=i(Bi),Pt=n(Bi,"DIV",{class:!0});var xi=s(Pt);m(_L.$$.fragment,xi),fyr=i(xi),Cve=n(xi,"P",{});var x6t=s(Cve);myr=r(x6t,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),x6t.forEach(t),gyr=i(xi),wf=n(xi,"P",{});var EQ=s(wf);hyr=r(EQ,`Note:
Loading a model from its configuration file does `),Mve=n(EQ,"STRONG",{});var k6t=s(Mve);pyr=r(k6t,"not"),k6t.forEach(t),_yr=r(EQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eve=n(EQ,"CODE",{});var R6t=s(Eve);uyr=r(R6t,"from_pretrained()"),R6t.forEach(t),byr=r(EQ,"to load the model weights."),EQ.forEach(t),vyr=i(xi),yve=n(xi,"P",{});var S6t=s(yve);Tyr=r(S6t,"Examples:"),S6t.forEach(t),Fyr=i(xi),m(uL.$$.fragment,xi),xi.forEach(t),Cyr=i(Bi),So=n(Bi,"DIV",{class:!0});var ja=s(So);m(bL.$$.fragment,ja),Myr=i(ja),wve=n(ja,"P",{});var P6t=s(wve);Eyr=r(P6t,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),P6t.forEach(t),yyr=i(ja),Nn=n(ja,"P",{});var ZM=s(Nn);wyr=r(ZM,"The model class to instantiate is selected based on the "),Ave=n(ZM,"CODE",{});var $6t=s(Ave);Ayr=r($6t,"model_type"),$6t.forEach(t),Lyr=r(ZM,` property of the config object (either
passed as an argument or loaded from `),Lve=n(ZM,"CODE",{});var I6t=s(Lve);Byr=r(I6t,"pretrained_model_name_or_path"),I6t.forEach(t),xyr=r(ZM,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bve=n(ZM,"CODE",{});var j6t=s(Bve);kyr=r(j6t,"pretrained_model_name_or_path"),j6t.forEach(t),Ryr=r(ZM,":"),ZM.forEach(t),Syr=i(ja),xve=n(ja,"UL",{});var D6t=s(xve);MC=n(D6t,"LI",{});var pxe=s(MC);kve=n(pxe,"STRONG",{});var N6t=s(kve);Pyr=r(N6t,"speech-encoder-decoder"),N6t.forEach(t),$yr=r(pxe," \u2014 "),mz=n(pxe,"A",{href:!0});var q6t=s(mz);Iyr=r(q6t,"FlaxSpeechEncoderDecoderModel"),q6t.forEach(t),jyr=r(pxe," (Speech Encoder decoder model)"),pxe.forEach(t),D6t.forEach(t),Dyr=i(ja),Rve=n(ja,"P",{});var O6t=s(Rve);Nyr=r(O6t,"Examples:"),O6t.forEach(t),qyr=i(ja),m(vL.$$.fragment,ja),ja.forEach(t),Bi.forEach(t),jRe=i(d),Af=n(d,"H2",{class:!0});var YPe=s(Af);EC=n(YPe,"A",{id:!0,class:!0,href:!0});var G6t=s(EC);Sve=n(G6t,"SPAN",{});var X6t=s(Sve);m(TL.$$.fragment,X6t),X6t.forEach(t),G6t.forEach(t),Oyr=i(YPe),Pve=n(YPe,"SPAN",{});var V6t=s(Pve);Gyr=r(V6t,"FlaxAutoModelForQuestionAnswering"),V6t.forEach(t),YPe.forEach(t),DRe=i(d),qr=n(d,"DIV",{class:!0});var ki=s(qr);m(FL.$$.fragment,ki),Xyr=i(ki),Lf=n(ki,"P",{});var yQ=s(Lf);Vyr=r(yQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),$ve=n(yQ,"CODE",{});var z6t=s($ve);zyr=r(z6t,"from_pretrained()"),z6t.forEach(t),Wyr=r(yQ,"class method or the "),Ive=n(yQ,"CODE",{});var W6t=s(Ive);Qyr=r(W6t,"from_config()"),W6t.forEach(t),Hyr=r(yQ,`class
method.`),yQ.forEach(t),Uyr=i(ki),CL=n(ki,"P",{});var KPe=s(CL);Jyr=r(KPe,"This class cannot be instantiated directly using "),jve=n(KPe,"CODE",{});var Q6t=s(jve);Yyr=r(Q6t,"__init__()"),Q6t.forEach(t),Kyr=r(KPe," (throws an error)."),KPe.forEach(t),Zyr=i(ki),$t=n(ki,"DIV",{class:!0});var Ri=s($t);m(ML.$$.fragment,Ri),ewr=i(Ri),Dve=n(Ri,"P",{});var H6t=s(Dve);owr=r(H6t,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),H6t.forEach(t),rwr=i(Ri),Bf=n(Ri,"P",{});var wQ=s(Bf);twr=r(wQ,`Note:
Loading a model from its configuration file does `),Nve=n(wQ,"STRONG",{});var U6t=s(Nve);awr=r(U6t,"not"),U6t.forEach(t),nwr=r(wQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),qve=n(wQ,"CODE",{});var J6t=s(qve);swr=r(J6t,"from_pretrained()"),J6t.forEach(t),lwr=r(wQ,"to load the model weights."),wQ.forEach(t),iwr=i(Ri),Ove=n(Ri,"P",{});var Y6t=s(Ove);dwr=r(Y6t,"Examples:"),Y6t.forEach(t),cwr=i(Ri),m(EL.$$.fragment,Ri),Ri.forEach(t),fwr=i(ki),Po=n(ki,"DIV",{class:!0});var Da=s(Po);m(yL.$$.fragment,Da),mwr=i(Da),Gve=n(Da,"P",{});var K6t=s(Gve);gwr=r(K6t,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),K6t.forEach(t),hwr=i(Da),qn=n(Da,"P",{});var e4=s(qn);pwr=r(e4,"The model class to instantiate is selected based on the "),Xve=n(e4,"CODE",{});var Z6t=s(Xve);_wr=r(Z6t,"model_type"),Z6t.forEach(t),uwr=r(e4,` property of the config object (either
passed as an argument or loaded from `),Vve=n(e4,"CODE",{});var e0t=s(Vve);bwr=r(e0t,"pretrained_model_name_or_path"),e0t.forEach(t),vwr=r(e4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zve=n(e4,"CODE",{});var o0t=s(zve);Twr=r(o0t,"pretrained_model_name_or_path"),o0t.forEach(t),Fwr=r(e4,":"),e4.forEach(t),Cwr=i(Da),ve=n(Da,"UL",{});var Ae=s(ve);yC=n(Ae,"LI",{});var _xe=s(yC);Wve=n(_xe,"STRONG",{});var r0t=s(Wve);Mwr=r(r0t,"albert"),r0t.forEach(t),Ewr=r(_xe," \u2014 "),gz=n(_xe,"A",{href:!0});var t0t=s(gz);ywr=r(t0t,"FlaxAlbertForQuestionAnswering"),t0t.forEach(t),wwr=r(_xe," (ALBERT model)"),_xe.forEach(t),Awr=i(Ae),wC=n(Ae,"LI",{});var uxe=s(wC);Qve=n(uxe,"STRONG",{});var a0t=s(Qve);Lwr=r(a0t,"bart"),a0t.forEach(t),Bwr=r(uxe," \u2014 "),hz=n(uxe,"A",{href:!0});var n0t=s(hz);xwr=r(n0t,"FlaxBartForQuestionAnswering"),n0t.forEach(t),kwr=r(uxe," (BART model)"),uxe.forEach(t),Rwr=i(Ae),AC=n(Ae,"LI",{});var bxe=s(AC);Hve=n(bxe,"STRONG",{});var s0t=s(Hve);Swr=r(s0t,"bert"),s0t.forEach(t),Pwr=r(bxe," \u2014 "),pz=n(bxe,"A",{href:!0});var l0t=s(pz);$wr=r(l0t,"FlaxBertForQuestionAnswering"),l0t.forEach(t),Iwr=r(bxe," (BERT model)"),bxe.forEach(t),jwr=i(Ae),LC=n(Ae,"LI",{});var vxe=s(LC);Uve=n(vxe,"STRONG",{});var i0t=s(Uve);Dwr=r(i0t,"big_bird"),i0t.forEach(t),Nwr=r(vxe," \u2014 "),_z=n(vxe,"A",{href:!0});var d0t=s(_z);qwr=r(d0t,"FlaxBigBirdForQuestionAnswering"),d0t.forEach(t),Owr=r(vxe," (BigBird model)"),vxe.forEach(t),Gwr=i(Ae),BC=n(Ae,"LI",{});var Txe=s(BC);Jve=n(Txe,"STRONG",{});var c0t=s(Jve);Xwr=r(c0t,"distilbert"),c0t.forEach(t),Vwr=r(Txe," \u2014 "),uz=n(Txe,"A",{href:!0});var f0t=s(uz);zwr=r(f0t,"FlaxDistilBertForQuestionAnswering"),f0t.forEach(t),Wwr=r(Txe," (DistilBERT model)"),Txe.forEach(t),Qwr=i(Ae),xC=n(Ae,"LI",{});var Fxe=s(xC);Yve=n(Fxe,"STRONG",{});var m0t=s(Yve);Hwr=r(m0t,"electra"),m0t.forEach(t),Uwr=r(Fxe," \u2014 "),bz=n(Fxe,"A",{href:!0});var g0t=s(bz);Jwr=r(g0t,"FlaxElectraForQuestionAnswering"),g0t.forEach(t),Ywr=r(Fxe," (ELECTRA model)"),Fxe.forEach(t),Kwr=i(Ae),kC=n(Ae,"LI",{});var Cxe=s(kC);Kve=n(Cxe,"STRONG",{});var h0t=s(Kve);Zwr=r(h0t,"mbart"),h0t.forEach(t),eAr=r(Cxe," \u2014 "),vz=n(Cxe,"A",{href:!0});var p0t=s(vz);oAr=r(p0t,"FlaxMBartForQuestionAnswering"),p0t.forEach(t),rAr=r(Cxe," (mBART model)"),Cxe.forEach(t),tAr=i(Ae),RC=n(Ae,"LI",{});var Mxe=s(RC);Zve=n(Mxe,"STRONG",{});var _0t=s(Zve);aAr=r(_0t,"roberta"),_0t.forEach(t),nAr=r(Mxe," \u2014 "),Tz=n(Mxe,"A",{href:!0});var u0t=s(Tz);sAr=r(u0t,"FlaxRobertaForQuestionAnswering"),u0t.forEach(t),lAr=r(Mxe," (RoBERTa model)"),Mxe.forEach(t),iAr=i(Ae),SC=n(Ae,"LI",{});var Exe=s(SC);e6e=n(Exe,"STRONG",{});var b0t=s(e6e);dAr=r(b0t,"roformer"),b0t.forEach(t),cAr=r(Exe," \u2014 "),Fz=n(Exe,"A",{href:!0});var v0t=s(Fz);fAr=r(v0t,"FlaxRoFormerForQuestionAnswering"),v0t.forEach(t),mAr=r(Exe," (RoFormer model)"),Exe.forEach(t),gAr=i(Ae),PC=n(Ae,"LI",{});var yxe=s(PC);o6e=n(yxe,"STRONG",{});var T0t=s(o6e);hAr=r(T0t,"xlm-roberta"),T0t.forEach(t),pAr=r(yxe," \u2014 "),Cz=n(yxe,"A",{href:!0});var F0t=s(Cz);_Ar=r(F0t,"FlaxXLMRobertaForQuestionAnswering"),F0t.forEach(t),uAr=r(yxe," (XLM-RoBERTa model)"),yxe.forEach(t),Ae.forEach(t),bAr=i(Da),r6e=n(Da,"P",{});var C0t=s(r6e);vAr=r(C0t,"Examples:"),C0t.forEach(t),TAr=i(Da),m(wL.$$.fragment,Da),Da.forEach(t),ki.forEach(t),NRe=i(d),xf=n(d,"H2",{class:!0});var ZPe=s(xf);$C=n(ZPe,"A",{id:!0,class:!0,href:!0});var M0t=s($C);t6e=n(M0t,"SPAN",{});var E0t=s(t6e);m(AL.$$.fragment,E0t),E0t.forEach(t),M0t.forEach(t),FAr=i(ZPe),a6e=n(ZPe,"SPAN",{});var y0t=s(a6e);CAr=r(y0t,"FlaxAutoModelForTokenClassification"),y0t.forEach(t),ZPe.forEach(t),qRe=i(d),Or=n(d,"DIV",{class:!0});var Si=s(Or);m(LL.$$.fragment,Si),MAr=i(Si),kf=n(Si,"P",{});var AQ=s(kf);EAr=r(AQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),n6e=n(AQ,"CODE",{});var w0t=s(n6e);yAr=r(w0t,"from_pretrained()"),w0t.forEach(t),wAr=r(AQ,"class method or the "),s6e=n(AQ,"CODE",{});var A0t=s(s6e);AAr=r(A0t,"from_config()"),A0t.forEach(t),LAr=r(AQ,`class
method.`),AQ.forEach(t),BAr=i(Si),BL=n(Si,"P",{});var e$e=s(BL);xAr=r(e$e,"This class cannot be instantiated directly using "),l6e=n(e$e,"CODE",{});var L0t=s(l6e);kAr=r(L0t,"__init__()"),L0t.forEach(t),RAr=r(e$e," (throws an error)."),e$e.forEach(t),SAr=i(Si),It=n(Si,"DIV",{class:!0});var Pi=s(It);m(xL.$$.fragment,Pi),PAr=i(Pi),i6e=n(Pi,"P",{});var B0t=s(i6e);$Ar=r(B0t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),B0t.forEach(t),IAr=i(Pi),Rf=n(Pi,"P",{});var LQ=s(Rf);jAr=r(LQ,`Note:
Loading a model from its configuration file does `),d6e=n(LQ,"STRONG",{});var x0t=s(d6e);DAr=r(x0t,"not"),x0t.forEach(t),NAr=r(LQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),c6e=n(LQ,"CODE",{});var k0t=s(c6e);qAr=r(k0t,"from_pretrained()"),k0t.forEach(t),OAr=r(LQ,"to load the model weights."),LQ.forEach(t),GAr=i(Pi),f6e=n(Pi,"P",{});var R0t=s(f6e);XAr=r(R0t,"Examples:"),R0t.forEach(t),VAr=i(Pi),m(kL.$$.fragment,Pi),Pi.forEach(t),zAr=i(Si),$o=n(Si,"DIV",{class:!0});var Na=s($o);m(RL.$$.fragment,Na),WAr=i(Na),m6e=n(Na,"P",{});var S0t=s(m6e);QAr=r(S0t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),S0t.forEach(t),HAr=i(Na),On=n(Na,"P",{});var o4=s(On);UAr=r(o4,"The model class to instantiate is selected based on the "),g6e=n(o4,"CODE",{});var P0t=s(g6e);JAr=r(P0t,"model_type"),P0t.forEach(t),YAr=r(o4,` property of the config object (either
passed as an argument or loaded from `),h6e=n(o4,"CODE",{});var $0t=s(h6e);KAr=r($0t,"pretrained_model_name_or_path"),$0t.forEach(t),ZAr=r(o4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p6e=n(o4,"CODE",{});var I0t=s(p6e);eLr=r(I0t,"pretrained_model_name_or_path"),I0t.forEach(t),oLr=r(o4,":"),o4.forEach(t),rLr=i(Na),Re=n(Na,"UL",{});var Xo=s(Re);IC=n(Xo,"LI",{});var wxe=s(IC);_6e=n(wxe,"STRONG",{});var j0t=s(_6e);tLr=r(j0t,"albert"),j0t.forEach(t),aLr=r(wxe," \u2014 "),Mz=n(wxe,"A",{href:!0});var D0t=s(Mz);nLr=r(D0t,"FlaxAlbertForTokenClassification"),D0t.forEach(t),sLr=r(wxe," (ALBERT model)"),wxe.forEach(t),lLr=i(Xo),jC=n(Xo,"LI",{});var Axe=s(jC);u6e=n(Axe,"STRONG",{});var N0t=s(u6e);iLr=r(N0t,"bert"),N0t.forEach(t),dLr=r(Axe," \u2014 "),Ez=n(Axe,"A",{href:!0});var q0t=s(Ez);cLr=r(q0t,"FlaxBertForTokenClassification"),q0t.forEach(t),fLr=r(Axe," (BERT model)"),Axe.forEach(t),mLr=i(Xo),DC=n(Xo,"LI",{});var Lxe=s(DC);b6e=n(Lxe,"STRONG",{});var O0t=s(b6e);gLr=r(O0t,"big_bird"),O0t.forEach(t),hLr=r(Lxe," \u2014 "),yz=n(Lxe,"A",{href:!0});var G0t=s(yz);pLr=r(G0t,"FlaxBigBirdForTokenClassification"),G0t.forEach(t),_Lr=r(Lxe," (BigBird model)"),Lxe.forEach(t),uLr=i(Xo),NC=n(Xo,"LI",{});var Bxe=s(NC);v6e=n(Bxe,"STRONG",{});var X0t=s(v6e);bLr=r(X0t,"distilbert"),X0t.forEach(t),vLr=r(Bxe," \u2014 "),wz=n(Bxe,"A",{href:!0});var V0t=s(wz);TLr=r(V0t,"FlaxDistilBertForTokenClassification"),V0t.forEach(t),FLr=r(Bxe," (DistilBERT model)"),Bxe.forEach(t),CLr=i(Xo),qC=n(Xo,"LI",{});var xxe=s(qC);T6e=n(xxe,"STRONG",{});var z0t=s(T6e);MLr=r(z0t,"electra"),z0t.forEach(t),ELr=r(xxe," \u2014 "),Az=n(xxe,"A",{href:!0});var W0t=s(Az);yLr=r(W0t,"FlaxElectraForTokenClassification"),W0t.forEach(t),wLr=r(xxe," (ELECTRA model)"),xxe.forEach(t),ALr=i(Xo),OC=n(Xo,"LI",{});var kxe=s(OC);F6e=n(kxe,"STRONG",{});var Q0t=s(F6e);LLr=r(Q0t,"roberta"),Q0t.forEach(t),BLr=r(kxe," \u2014 "),Lz=n(kxe,"A",{href:!0});var H0t=s(Lz);xLr=r(H0t,"FlaxRobertaForTokenClassification"),H0t.forEach(t),kLr=r(kxe," (RoBERTa model)"),kxe.forEach(t),RLr=i(Xo),GC=n(Xo,"LI",{});var Rxe=s(GC);C6e=n(Rxe,"STRONG",{});var U0t=s(C6e);SLr=r(U0t,"roformer"),U0t.forEach(t),PLr=r(Rxe," \u2014 "),Bz=n(Rxe,"A",{href:!0});var J0t=s(Bz);$Lr=r(J0t,"FlaxRoFormerForTokenClassification"),J0t.forEach(t),ILr=r(Rxe," (RoFormer model)"),Rxe.forEach(t),jLr=i(Xo),XC=n(Xo,"LI",{});var Sxe=s(XC);M6e=n(Sxe,"STRONG",{});var Y0t=s(M6e);DLr=r(Y0t,"xlm-roberta"),Y0t.forEach(t),NLr=r(Sxe," \u2014 "),xz=n(Sxe,"A",{href:!0});var K0t=s(xz);qLr=r(K0t,"FlaxXLMRobertaForTokenClassification"),K0t.forEach(t),OLr=r(Sxe," (XLM-RoBERTa model)"),Sxe.forEach(t),Xo.forEach(t),GLr=i(Na),E6e=n(Na,"P",{});var Z0t=s(E6e);XLr=r(Z0t,"Examples:"),Z0t.forEach(t),VLr=i(Na),m(SL.$$.fragment,Na),Na.forEach(t),Si.forEach(t),ORe=i(d),Sf=n(d,"H2",{class:!0});var o$e=s(Sf);VC=n(o$e,"A",{id:!0,class:!0,href:!0});var eTt=s(VC);y6e=n(eTt,"SPAN",{});var oTt=s(y6e);m(PL.$$.fragment,oTt),oTt.forEach(t),eTt.forEach(t),zLr=i(o$e),w6e=n(o$e,"SPAN",{});var rTt=s(w6e);WLr=r(rTt,"FlaxAutoModelForMultipleChoice"),rTt.forEach(t),o$e.forEach(t),GRe=i(d),Gr=n(d,"DIV",{class:!0});var $i=s(Gr);m($L.$$.fragment,$i),QLr=i($i),Pf=n($i,"P",{});var BQ=s(Pf);HLr=r(BQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),A6e=n(BQ,"CODE",{});var tTt=s(A6e);ULr=r(tTt,"from_pretrained()"),tTt.forEach(t),JLr=r(BQ,"class method or the "),L6e=n(BQ,"CODE",{});var aTt=s(L6e);YLr=r(aTt,"from_config()"),aTt.forEach(t),KLr=r(BQ,`class
method.`),BQ.forEach(t),ZLr=i($i),IL=n($i,"P",{});var r$e=s(IL);e7r=r(r$e,"This class cannot be instantiated directly using "),B6e=n(r$e,"CODE",{});var nTt=s(B6e);o7r=r(nTt,"__init__()"),nTt.forEach(t),r7r=r(r$e," (throws an error)."),r$e.forEach(t),t7r=i($i),jt=n($i,"DIV",{class:!0});var Ii=s(jt);m(jL.$$.fragment,Ii),a7r=i(Ii),x6e=n(Ii,"P",{});var sTt=s(x6e);n7r=r(sTt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),sTt.forEach(t),s7r=i(Ii),$f=n(Ii,"P",{});var xQ=s($f);l7r=r(xQ,`Note:
Loading a model from its configuration file does `),k6e=n(xQ,"STRONG",{});var lTt=s(k6e);i7r=r(lTt,"not"),lTt.forEach(t),d7r=r(xQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),R6e=n(xQ,"CODE",{});var iTt=s(R6e);c7r=r(iTt,"from_pretrained()"),iTt.forEach(t),f7r=r(xQ,"to load the model weights."),xQ.forEach(t),m7r=i(Ii),S6e=n(Ii,"P",{});var dTt=s(S6e);g7r=r(dTt,"Examples:"),dTt.forEach(t),h7r=i(Ii),m(DL.$$.fragment,Ii),Ii.forEach(t),p7r=i($i),Io=n($i,"DIV",{class:!0});var qa=s(Io);m(NL.$$.fragment,qa),_7r=i(qa),P6e=n(qa,"P",{});var cTt=s(P6e);u7r=r(cTt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),cTt.forEach(t),b7r=i(qa),Gn=n(qa,"P",{});var r4=s(Gn);v7r=r(r4,"The model class to instantiate is selected based on the "),$6e=n(r4,"CODE",{});var fTt=s($6e);T7r=r(fTt,"model_type"),fTt.forEach(t),F7r=r(r4,` property of the config object (either
passed as an argument or loaded from `),I6e=n(r4,"CODE",{});var mTt=s(I6e);C7r=r(mTt,"pretrained_model_name_or_path"),mTt.forEach(t),M7r=r(r4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j6e=n(r4,"CODE",{});var gTt=s(j6e);E7r=r(gTt,"pretrained_model_name_or_path"),gTt.forEach(t),y7r=r(r4,":"),r4.forEach(t),w7r=i(qa),Se=n(qa,"UL",{});var Vo=s(Se);zC=n(Vo,"LI",{});var Pxe=s(zC);D6e=n(Pxe,"STRONG",{});var hTt=s(D6e);A7r=r(hTt,"albert"),hTt.forEach(t),L7r=r(Pxe," \u2014 "),kz=n(Pxe,"A",{href:!0});var pTt=s(kz);B7r=r(pTt,"FlaxAlbertForMultipleChoice"),pTt.forEach(t),x7r=r(Pxe," (ALBERT model)"),Pxe.forEach(t),k7r=i(Vo),WC=n(Vo,"LI",{});var $xe=s(WC);N6e=n($xe,"STRONG",{});var _Tt=s(N6e);R7r=r(_Tt,"bert"),_Tt.forEach(t),S7r=r($xe," \u2014 "),Rz=n($xe,"A",{href:!0});var uTt=s(Rz);P7r=r(uTt,"FlaxBertForMultipleChoice"),uTt.forEach(t),$7r=r($xe," (BERT model)"),$xe.forEach(t),I7r=i(Vo),QC=n(Vo,"LI",{});var Ixe=s(QC);q6e=n(Ixe,"STRONG",{});var bTt=s(q6e);j7r=r(bTt,"big_bird"),bTt.forEach(t),D7r=r(Ixe," \u2014 "),Sz=n(Ixe,"A",{href:!0});var vTt=s(Sz);N7r=r(vTt,"FlaxBigBirdForMultipleChoice"),vTt.forEach(t),q7r=r(Ixe," (BigBird model)"),Ixe.forEach(t),O7r=i(Vo),HC=n(Vo,"LI",{});var jxe=s(HC);O6e=n(jxe,"STRONG",{});var TTt=s(O6e);G7r=r(TTt,"distilbert"),TTt.forEach(t),X7r=r(jxe," \u2014 "),Pz=n(jxe,"A",{href:!0});var FTt=s(Pz);V7r=r(FTt,"FlaxDistilBertForMultipleChoice"),FTt.forEach(t),z7r=r(jxe," (DistilBERT model)"),jxe.forEach(t),W7r=i(Vo),UC=n(Vo,"LI",{});var Dxe=s(UC);G6e=n(Dxe,"STRONG",{});var CTt=s(G6e);Q7r=r(CTt,"electra"),CTt.forEach(t),H7r=r(Dxe," \u2014 "),$z=n(Dxe,"A",{href:!0});var MTt=s($z);U7r=r(MTt,"FlaxElectraForMultipleChoice"),MTt.forEach(t),J7r=r(Dxe," (ELECTRA model)"),Dxe.forEach(t),Y7r=i(Vo),JC=n(Vo,"LI",{});var Nxe=s(JC);X6e=n(Nxe,"STRONG",{});var ETt=s(X6e);K7r=r(ETt,"roberta"),ETt.forEach(t),Z7r=r(Nxe," \u2014 "),Iz=n(Nxe,"A",{href:!0});var yTt=s(Iz);e9r=r(yTt,"FlaxRobertaForMultipleChoice"),yTt.forEach(t),o9r=r(Nxe," (RoBERTa model)"),Nxe.forEach(t),r9r=i(Vo),YC=n(Vo,"LI",{});var qxe=s(YC);V6e=n(qxe,"STRONG",{});var wTt=s(V6e);t9r=r(wTt,"roformer"),wTt.forEach(t),a9r=r(qxe," \u2014 "),jz=n(qxe,"A",{href:!0});var ATt=s(jz);n9r=r(ATt,"FlaxRoFormerForMultipleChoice"),ATt.forEach(t),s9r=r(qxe," (RoFormer model)"),qxe.forEach(t),l9r=i(Vo),KC=n(Vo,"LI",{});var Oxe=s(KC);z6e=n(Oxe,"STRONG",{});var LTt=s(z6e);i9r=r(LTt,"xlm-roberta"),LTt.forEach(t),d9r=r(Oxe," \u2014 "),Dz=n(Oxe,"A",{href:!0});var BTt=s(Dz);c9r=r(BTt,"FlaxXLMRobertaForMultipleChoice"),BTt.forEach(t),f9r=r(Oxe," (XLM-RoBERTa model)"),Oxe.forEach(t),Vo.forEach(t),m9r=i(qa),W6e=n(qa,"P",{});var xTt=s(W6e);g9r=r(xTt,"Examples:"),xTt.forEach(t),h9r=i(qa),m(qL.$$.fragment,qa),qa.forEach(t),$i.forEach(t),XRe=i(d),If=n(d,"H2",{class:!0});var t$e=s(If);ZC=n(t$e,"A",{id:!0,class:!0,href:!0});var kTt=s(ZC);Q6e=n(kTt,"SPAN",{});var RTt=s(Q6e);m(OL.$$.fragment,RTt),RTt.forEach(t),kTt.forEach(t),p9r=i(t$e),H6e=n(t$e,"SPAN",{});var STt=s(H6e);_9r=r(STt,"FlaxAutoModelForNextSentencePrediction"),STt.forEach(t),t$e.forEach(t),VRe=i(d),Xr=n(d,"DIV",{class:!0});var ji=s(Xr);m(GL.$$.fragment,ji),u9r=i(ji),jf=n(ji,"P",{});var kQ=s(jf);b9r=r(kQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),U6e=n(kQ,"CODE",{});var PTt=s(U6e);v9r=r(PTt,"from_pretrained()"),PTt.forEach(t),T9r=r(kQ,"class method or the "),J6e=n(kQ,"CODE",{});var $Tt=s(J6e);F9r=r($Tt,"from_config()"),$Tt.forEach(t),C9r=r(kQ,`class
method.`),kQ.forEach(t),M9r=i(ji),XL=n(ji,"P",{});var a$e=s(XL);E9r=r(a$e,"This class cannot be instantiated directly using "),Y6e=n(a$e,"CODE",{});var ITt=s(Y6e);y9r=r(ITt,"__init__()"),ITt.forEach(t),w9r=r(a$e," (throws an error)."),a$e.forEach(t),A9r=i(ji),Dt=n(ji,"DIV",{class:!0});var Di=s(Dt);m(VL.$$.fragment,Di),L9r=i(Di),K6e=n(Di,"P",{});var jTt=s(K6e);B9r=r(jTt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),jTt.forEach(t),x9r=i(Di),Df=n(Di,"P",{});var RQ=s(Df);k9r=r(RQ,`Note:
Loading a model from its configuration file does `),Z6e=n(RQ,"STRONG",{});var DTt=s(Z6e);R9r=r(DTt,"not"),DTt.forEach(t),S9r=r(RQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),e0e=n(RQ,"CODE",{});var NTt=s(e0e);P9r=r(NTt,"from_pretrained()"),NTt.forEach(t),$9r=r(RQ,"to load the model weights."),RQ.forEach(t),I9r=i(Di),o0e=n(Di,"P",{});var qTt=s(o0e);j9r=r(qTt,"Examples:"),qTt.forEach(t),D9r=i(Di),m(zL.$$.fragment,Di),Di.forEach(t),N9r=i(ji),jo=n(ji,"DIV",{class:!0});var Oa=s(jo);m(WL.$$.fragment,Oa),q9r=i(Oa),r0e=n(Oa,"P",{});var OTt=s(r0e);O9r=r(OTt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),OTt.forEach(t),G9r=i(Oa),Xn=n(Oa,"P",{});var t4=s(Xn);X9r=r(t4,"The model class to instantiate is selected based on the "),t0e=n(t4,"CODE",{});var GTt=s(t0e);V9r=r(GTt,"model_type"),GTt.forEach(t),z9r=r(t4,` property of the config object (either
passed as an argument or loaded from `),a0e=n(t4,"CODE",{});var XTt=s(a0e);W9r=r(XTt,"pretrained_model_name_or_path"),XTt.forEach(t),Q9r=r(t4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n0e=n(t4,"CODE",{});var VTt=s(n0e);H9r=r(VTt,"pretrained_model_name_or_path"),VTt.forEach(t),U9r=r(t4,":"),t4.forEach(t),J9r=i(Oa),s0e=n(Oa,"UL",{});var zTt=s(s0e);eM=n(zTt,"LI",{});var Gxe=s(eM);l0e=n(Gxe,"STRONG",{});var WTt=s(l0e);Y9r=r(WTt,"bert"),WTt.forEach(t),K9r=r(Gxe," \u2014 "),Nz=n(Gxe,"A",{href:!0});var QTt=s(Nz);Z9r=r(QTt,"FlaxBertForNextSentencePrediction"),QTt.forEach(t),eBr=r(Gxe," (BERT model)"),Gxe.forEach(t),zTt.forEach(t),oBr=i(Oa),i0e=n(Oa,"P",{});var HTt=s(i0e);rBr=r(HTt,"Examples:"),HTt.forEach(t),tBr=i(Oa),m(QL.$$.fragment,Oa),Oa.forEach(t),ji.forEach(t),zRe=i(d),Nf=n(d,"H2",{class:!0});var n$e=s(Nf);oM=n(n$e,"A",{id:!0,class:!0,href:!0});var UTt=s(oM);d0e=n(UTt,"SPAN",{});var JTt=s(d0e);m(HL.$$.fragment,JTt),JTt.forEach(t),UTt.forEach(t),aBr=i(n$e),c0e=n(n$e,"SPAN",{});var YTt=s(c0e);nBr=r(YTt,"FlaxAutoModelForImageClassification"),YTt.forEach(t),n$e.forEach(t),WRe=i(d),Vr=n(d,"DIV",{class:!0});var Ni=s(Vr);m(UL.$$.fragment,Ni),sBr=i(Ni),qf=n(Ni,"P",{});var SQ=s(qf);lBr=r(SQ,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),f0e=n(SQ,"CODE",{});var KTt=s(f0e);iBr=r(KTt,"from_pretrained()"),KTt.forEach(t),dBr=r(SQ,"class method or the "),m0e=n(SQ,"CODE",{});var ZTt=s(m0e);cBr=r(ZTt,"from_config()"),ZTt.forEach(t),fBr=r(SQ,`class
method.`),SQ.forEach(t),mBr=i(Ni),JL=n(Ni,"P",{});var s$e=s(JL);gBr=r(s$e,"This class cannot be instantiated directly using "),g0e=n(s$e,"CODE",{});var e8t=s(g0e);hBr=r(e8t,"__init__()"),e8t.forEach(t),pBr=r(s$e," (throws an error)."),s$e.forEach(t),_Br=i(Ni),Nt=n(Ni,"DIV",{class:!0});var qi=s(Nt);m(YL.$$.fragment,qi),uBr=i(qi),h0e=n(qi,"P",{});var o8t=s(h0e);bBr=r(o8t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),o8t.forEach(t),vBr=i(qi),Of=n(qi,"P",{});var PQ=s(Of);TBr=r(PQ,`Note:
Loading a model from its configuration file does `),p0e=n(PQ,"STRONG",{});var r8t=s(p0e);FBr=r(r8t,"not"),r8t.forEach(t),CBr=r(PQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),_0e=n(PQ,"CODE",{});var t8t=s(_0e);MBr=r(t8t,"from_pretrained()"),t8t.forEach(t),EBr=r(PQ,"to load the model weights."),PQ.forEach(t),yBr=i(qi),u0e=n(qi,"P",{});var a8t=s(u0e);wBr=r(a8t,"Examples:"),a8t.forEach(t),ABr=i(qi),m(KL.$$.fragment,qi),qi.forEach(t),LBr=i(Ni),Do=n(Ni,"DIV",{class:!0});var Ga=s(Do);m(ZL.$$.fragment,Ga),BBr=i(Ga),b0e=n(Ga,"P",{});var n8t=s(b0e);xBr=r(n8t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),n8t.forEach(t),kBr=i(Ga),Vn=n(Ga,"P",{});var a4=s(Vn);RBr=r(a4,"The model class to instantiate is selected based on the "),v0e=n(a4,"CODE",{});var s8t=s(v0e);SBr=r(s8t,"model_type"),s8t.forEach(t),PBr=r(a4,` property of the config object (either
passed as an argument or loaded from `),T0e=n(a4,"CODE",{});var l8t=s(T0e);$Br=r(l8t,"pretrained_model_name_or_path"),l8t.forEach(t),IBr=r(a4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F0e=n(a4,"CODE",{});var i8t=s(F0e);jBr=r(i8t,"pretrained_model_name_or_path"),i8t.forEach(t),DBr=r(a4,":"),a4.forEach(t),NBr=i(Ga),e7=n(Ga,"UL",{});var l$e=s(e7);rM=n(l$e,"LI",{});var Xxe=s(rM);C0e=n(Xxe,"STRONG",{});var d8t=s(C0e);qBr=r(d8t,"beit"),d8t.forEach(t),OBr=r(Xxe," \u2014 "),qz=n(Xxe,"A",{href:!0});var c8t=s(qz);GBr=r(c8t,"FlaxBeitForImageClassification"),c8t.forEach(t),XBr=r(Xxe," (BEiT model)"),Xxe.forEach(t),VBr=i(l$e),tM=n(l$e,"LI",{});var Vxe=s(tM);M0e=n(Vxe,"STRONG",{});var f8t=s(M0e);zBr=r(f8t,"vit"),f8t.forEach(t),WBr=r(Vxe," \u2014 "),Oz=n(Vxe,"A",{href:!0});var m8t=s(Oz);QBr=r(m8t,"FlaxViTForImageClassification"),m8t.forEach(t),HBr=r(Vxe," (ViT model)"),Vxe.forEach(t),l$e.forEach(t),UBr=i(Ga),E0e=n(Ga,"P",{});var g8t=s(E0e);JBr=r(g8t,"Examples:"),g8t.forEach(t),YBr=i(Ga),m(o7.$$.fragment,Ga),Ga.forEach(t),Ni.forEach(t),QRe=i(d),Gf=n(d,"H2",{class:!0});var i$e=s(Gf);aM=n(i$e,"A",{id:!0,class:!0,href:!0});var h8t=s(aM);y0e=n(h8t,"SPAN",{});var p8t=s(y0e);m(r7.$$.fragment,p8t),p8t.forEach(t),h8t.forEach(t),KBr=i(i$e),w0e=n(i$e,"SPAN",{});var _8t=s(w0e);ZBr=r(_8t,"FlaxAutoModelForVision2Seq"),_8t.forEach(t),i$e.forEach(t),HRe=i(d),zr=n(d,"DIV",{class:!0});var Oi=s(zr);m(t7.$$.fragment,Oi),exr=i(Oi),Xf=n(Oi,"P",{});var $Q=s(Xf);oxr=r($Q,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),A0e=n($Q,"CODE",{});var u8t=s(A0e);rxr=r(u8t,"from_pretrained()"),u8t.forEach(t),txr=r($Q,"class method or the "),L0e=n($Q,"CODE",{});var b8t=s(L0e);axr=r(b8t,"from_config()"),b8t.forEach(t),nxr=r($Q,`class
method.`),$Q.forEach(t),sxr=i(Oi),a7=n(Oi,"P",{});var d$e=s(a7);lxr=r(d$e,"This class cannot be instantiated directly using "),B0e=n(d$e,"CODE",{});var v8t=s(B0e);ixr=r(v8t,"__init__()"),v8t.forEach(t),dxr=r(d$e," (throws an error)."),d$e.forEach(t),cxr=i(Oi),qt=n(Oi,"DIV",{class:!0});var Gi=s(qt);m(n7.$$.fragment,Gi),fxr=i(Gi),x0e=n(Gi,"P",{});var T8t=s(x0e);mxr=r(T8t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),T8t.forEach(t),gxr=i(Gi),Vf=n(Gi,"P",{});var IQ=s(Vf);hxr=r(IQ,`Note:
Loading a model from its configuration file does `),k0e=n(IQ,"STRONG",{});var F8t=s(k0e);pxr=r(F8t,"not"),F8t.forEach(t),_xr=r(IQ,` load the model weights. It only affects the
model\u2019s configuration. Use `),R0e=n(IQ,"CODE",{});var C8t=s(R0e);uxr=r(C8t,"from_pretrained()"),C8t.forEach(t),bxr=r(IQ,"to load the model weights."),IQ.forEach(t),vxr=i(Gi),S0e=n(Gi,"P",{});var M8t=s(S0e);Txr=r(M8t,"Examples:"),M8t.forEach(t),Fxr=i(Gi),m(s7.$$.fragment,Gi),Gi.forEach(t),Cxr=i(Oi),No=n(Oi,"DIV",{class:!0});var Xa=s(No);m(l7.$$.fragment,Xa),Mxr=i(Xa),P0e=n(Xa,"P",{});var E8t=s(P0e);Exr=r(E8t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),E8t.forEach(t),yxr=i(Xa),zn=n(Xa,"P",{});var n4=s(zn);wxr=r(n4,"The model class to instantiate is selected based on the "),$0e=n(n4,"CODE",{});var y8t=s($0e);Axr=r(y8t,"model_type"),y8t.forEach(t),Lxr=r(n4,` property of the config object (either
passed as an argument or loaded from `),I0e=n(n4,"CODE",{});var w8t=s(I0e);Bxr=r(w8t,"pretrained_model_name_or_path"),w8t.forEach(t),xxr=r(n4,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j0e=n(n4,"CODE",{});var A8t=s(j0e);kxr=r(A8t,"pretrained_model_name_or_path"),A8t.forEach(t),Rxr=r(n4,":"),n4.forEach(t),Sxr=i(Xa),D0e=n(Xa,"UL",{});var L8t=s(D0e);nM=n(L8t,"LI",{});var zxe=s(nM);N0e=n(zxe,"STRONG",{});var B8t=s(N0e);Pxr=r(B8t,"vision-encoder-decoder"),B8t.forEach(t),$xr=r(zxe," \u2014 "),Gz=n(zxe,"A",{href:!0});var x8t=s(Gz);Ixr=r(x8t,"FlaxVisionEncoderDecoderModel"),x8t.forEach(t),jxr=r(zxe," (Vision Encoder decoder model)"),zxe.forEach(t),L8t.forEach(t),Dxr=i(Xa),q0e=n(Xa,"P",{});var k8t=s(q0e);Nxr=r(k8t,"Examples:"),k8t.forEach(t),qxr=i(Xa),m(i7.$$.fragment,Xa),Xa.forEach(t),Oi.forEach(t),this.h()},h(){c(J,"name","hf:doc:metadata"),c(J,"content",JSON.stringify(q8t)),c(he,"id","auto-classes"),c(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(he,"href","#auto-classes"),c(de,"class","relative group"),c(Wn,"href","/docs/transformers/pr_16058/en/model_doc/auto#transformers.AutoConfig"),c(Hn,"href","/docs/transformers/pr_16058/en/model_doc/auto#transformers.AutoModel"),c(Un,"href","/docs/transformers/pr_16058/en/model_doc/auto#transformers.AutoTokenizer"),c(Ji,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertModel"),c(Jf,"id","extending-the-auto-classes"),c(Jf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jf,"href","#extending-the-auto-classes"),c(Yi,"class","relative group"),c(Kf,"id","transformers.AutoConfig"),c(Kf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Kf,"href","#transformers.AutoConfig"),c(Ki,"class","relative group"),c(m9,"href","/docs/transformers/pr_16058/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(g9,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertConfig"),c(h9,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartConfig"),c(p9,"href","/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitConfig"),c(_9,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertConfig"),c(u9,"href","/docs/transformers/pr_16058/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(b9,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdConfig"),c(v9,"href","/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(T9,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(F9,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(C9,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertConfig"),c(M9,"href","/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineConfig"),c(E9,"href","/docs/transformers/pr_16058/en/model_doc/clip#transformers.CLIPConfig"),c(y9,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertConfig"),c(w9,"href","/docs/transformers/pr_16058/en/model_doc/convnext#transformers.ConvNextConfig"),c(A9,"href","/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLConfig"),c(L9,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(B9,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(x9,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaConfig"),c(k9,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(R9,"href","/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTConfig"),c(S9,"href","/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrConfig"),c(P9,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertConfig"),c($9,"href","/docs/transformers/pr_16058/en/model_doc/dpr#transformers.DPRConfig"),c(I9,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraConfig"),c(j9,"href","/docs/transformers/pr_16058/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(D9,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertConfig"),c(N9,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetConfig"),c(q9,"href","/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTConfig"),c(O9,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelConfig"),c(G9,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Config"),c(X9,"href","/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(V9,"href","/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJConfig"),c(z9,"href","/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertConfig"),c(W9,"href","/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertConfig"),c(Q9,"href","/docs/transformers/pr_16058/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(H9,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(U9,"href","/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(J9,"href","/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDConfig"),c(Y9,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerConfig"),c(K9,"href","/docs/transformers/pr_16058/en/model_doc/luke#transformers.LukeConfig"),c(Z9,"href","/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertConfig"),c(eB,"href","/docs/transformers/pr_16058/en/model_doc/m2m_100#transformers.M2M100Config"),c(oB,"href","/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianConfig"),c(rB,"href","/docs/transformers/pr_16058/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(tB,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartConfig"),c(aB,"href","/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(nB,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(sB,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetConfig"),c(lB,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5Config"),c(iB,"href","/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(dB,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(cB,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusConfig"),c(fB,"href","/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverConfig"),c(mB,"href","/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartConfig"),c(gB,"href","/docs/transformers/pr_16058/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(hB,"href","/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(pB,"href","/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(_B,"href","/docs/transformers/pr_16058/en/model_doc/rag#transformers.RagConfig"),c(uB,"href","/docs/transformers/pr_16058/en/model_doc/realm#transformers.RealmConfig"),c(bB,"href","/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerConfig"),c(vB,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertConfig"),c(TB,"href","/docs/transformers/pr_16058/en/model_doc/retribert#transformers.RetriBertConfig"),c(FB,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaConfig"),c(CB,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerConfig"),c(MB,"href","/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerConfig"),c(EB,"href","/docs/transformers/pr_16058/en/model_doc/sew#transformers.SEWConfig"),c(yB,"href","/docs/transformers/pr_16058/en/model_doc/sew-d#transformers.SEWDConfig"),c(wB,"href","/docs/transformers/pr_16058/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(AB,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(LB,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(BB,"href","/docs/transformers/pr_16058/en/model_doc/splinter#transformers.SplinterConfig"),c(xB,"href","/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(kB,"href","/docs/transformers/pr_16058/en/model_doc/swin#transformers.SwinConfig"),c(RB,"href","/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Config"),c(SB,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasConfig"),c(PB,"href","/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c($B,"href","/docs/transformers/pr_16058/en/model_doc/trocr#transformers.TrOCRConfig"),c(IB,"href","/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(jB,"href","/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(DB,"href","/docs/transformers/pr_16058/en/model_doc/vilt#transformers.ViltConfig"),c(NB,"href","/docs/transformers/pr_16058/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(qB,"href","/docs/transformers/pr_16058/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(OB,"href","/docs/transformers/pr_16058/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(GB,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTConfig"),c(XB,"href","/docs/transformers/pr_16058/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(VB,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(zB,"href","/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMConfig"),c(WB,"href","/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMConfig"),c(QB,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMConfig"),c(HB,"href","/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(UB,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(JB,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(YB,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetConfig"),c(KB,"href","/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoConfig"),c(mo,"class","docstring"),c(Ng,"class","docstring"),c(Qo,"class","docstring"),c(qg,"id","transformers.AutoTokenizer"),c(qg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qg,"href","#transformers.AutoTokenizer"),c(ed,"class","relative group"),c(ZB,"href","/docs/transformers/pr_16058/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(ex,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertTokenizer"),c(ox,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(rx,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartTokenizer"),c(tx,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartTokenizerFast"),c(ax,"href","/docs/transformers/pr_16058/en/model_doc/barthez#transformers.BarthezTokenizer"),c(nx,"href","/docs/transformers/pr_16058/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(sx,"href","/docs/transformers/pr_16058/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(lx,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertTokenizer"),c(ix,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertTokenizerFast"),c(dx,"href","/docs/transformers/pr_16058/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(cx,"href","/docs/transformers/pr_16058/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(fx,"href","/docs/transformers/pr_16058/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(mx,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(gx,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(hx,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(px,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(_x,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(ux,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(bx,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(vx,"href","/docs/transformers/pr_16058/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(Tx,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertTokenizer"),c(Fx,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(Cx,"href","/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineTokenizer"),c(Mx,"href","/docs/transformers/pr_16058/en/model_doc/clip#transformers.CLIPTokenizer"),c(Ex,"href","/docs/transformers/pr_16058/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(yx,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(wx,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(Ax,"href","/docs/transformers/pr_16058/en/model_doc/cpm#transformers.CpmTokenizer"),c(Lx,"href","/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(Bx,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaTokenizer"),c(xx,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(kx,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(Rx,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(Sx,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(Px,"href","/docs/transformers/pr_16058/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c($x,"href","/docs/transformers/pr_16058/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(Ix,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraTokenizer"),c(jx,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(Dx,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(Nx,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetTokenizer"),c(qx,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(Ox,"href","/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(Gx,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelTokenizer"),c(Xx,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(Vx,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(zx,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(Wx,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(Qx,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(Hx,"href","/docs/transformers/pr_16058/en/model_doc/herbert#transformers.HerbertTokenizer"),c(Ux,"href","/docs/transformers/pr_16058/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(Jx,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(Yx,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaTokenizer"),c(Kx,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(Zx,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(ek,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(ok,"href","/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(rk,"href","/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(tk,"href","/docs/transformers/pr_16058/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(ak,"href","/docs/transformers/pr_16058/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(nk,"href","/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDTokenizer"),c(sk,"href","/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDTokenizerFast"),c(lk,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerTokenizer"),c(ik,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(dk,"href","/docs/transformers/pr_16058/en/model_doc/luke#transformers.LukeTokenizer"),c(ck,"href","/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(fk,"href","/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(mk,"href","/docs/transformers/pr_16058/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(gk,"href","/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianTokenizer"),c(hk,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartTokenizer"),c(pk,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(_k,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(uk,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(bk,"href","/docs/transformers/pr_16058/en/model_doc/mluke#transformers.MLukeTokenizer"),c(vk,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(Tk,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(Fk,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(Ck,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(Mk,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.T5Tokenizer"),c(Ek,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.T5TokenizerFast"),c(yk,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(wk,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(Ak,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(Lk,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(Bk,"href","/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(xk,"href","/docs/transformers/pr_16058/en/model_doc/phobert#transformers.PhobertTokenizer"),c(kk,"href","/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartTokenizer"),c(Rk,"href","/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(Sk,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertTokenizer"),c(Pk,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertTokenizerFast"),c($k,"href","/docs/transformers/pr_16058/en/model_doc/rag#transformers.RagTokenizer"),c(Ik,"href","/docs/transformers/pr_16058/en/model_doc/realm#transformers.RealmTokenizer"),c(jk,"href","/docs/transformers/pr_16058/en/model_doc/realm#transformers.RealmTokenizerFast"),c(Dk,"href","/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerTokenizer"),c(Nk,"href","/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(qk,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertTokenizer"),c(Ok,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(Gk,"href","/docs/transformers/pr_16058/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(Xk,"href","/docs/transformers/pr_16058/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(Vk,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaTokenizer"),c(zk,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(Wk,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(Qk,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(Hk,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(Uk,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(Jk,"href","/docs/transformers/pr_16058/en/model_doc/splinter#transformers.SplinterTokenizer"),c(Yk,"href","/docs/transformers/pr_16058/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(Kk,"href","/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(Zk,"href","/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(eR,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.T5Tokenizer"),c(oR,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.T5TokenizerFast"),c(rR,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasTokenizer"),c(tR,"href","/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(aR,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(nR,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(sR,"href","/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMTokenizer"),c(lR,"href","/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(iR,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMTokenizer"),c(dR,"href","/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(cR,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(fR,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(mR,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(gR,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(go,"class","docstring"),c(_h,"class","docstring"),c(Ho,"class","docstring"),c(uh,"id","transformers.AutoFeatureExtractor"),c(uh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uh,"href","#transformers.AutoFeatureExtractor"),c(od,"class","relative group"),c(hR,"href","/docs/transformers/pr_16058/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(pR,"href","/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(_R,"href","/docs/transformers/pr_16058/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(uR,"href","/docs/transformers/pr_16058/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(bR,"href","/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(vR,"href","/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(TR,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(FR,"href","/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(CR,"href","/docs/transformers/pr_16058/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(MR,"href","/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(ER,"href","/docs/transformers/pr_16058/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(yR,"href","/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(wR,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(AR,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(LR,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(BR,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(xR,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c($e,"class","docstring"),c($h,"class","docstring"),c(Uo,"class","docstring"),c(Ih,"id","transformers.AutoProcessor"),c(Ih,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ih,"href","#transformers.AutoProcessor"),c(rd,"class","relative group"),c(kR,"href","/docs/transformers/pr_16058/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(RR,"href","/docs/transformers/pr_16058/en/model_doc/clip#transformers.CLIPProcessor"),c(SR,"href","/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(PR,"href","/docs/transformers/pr_16058/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c($R,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(IR,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(jR,"href","/docs/transformers/pr_16058/en/model_doc/trocr#transformers.TrOCRProcessor"),c(DR,"href","/docs/transformers/pr_16058/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(NR,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ie,"class","docstring"),c(Wh,"class","docstring"),c(Jo,"class","docstring"),c(Qh,"id","transformers.AutoModel"),c(Qh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Qh,"href","#transformers.AutoModel"),c(ad,"class","relative group"),c(Wr,"class","docstring"),c(qR,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertModel"),c(OR,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartModel"),c(GR,"href","/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitModel"),c(XR,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertModel"),c(VR,"href","/docs/transformers/pr_16058/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(zR,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdModel"),c(WR,"href","/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(QR,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(HR,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(UR,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertModel"),c(JR,"href","/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineModel"),c(YR,"href","/docs/transformers/pr_16058/en/model_doc/clip#transformers.CLIPModel"),c(KR,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertModel"),c(ZR,"href","/docs/transformers/pr_16058/en/model_doc/convnext#transformers.ConvNextModel"),c(eS,"href","/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLModel"),c(oS,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(rS,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(tS,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaModel"),c(aS,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(nS,"href","/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTModel"),c(sS,"href","/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrModel"),c(lS,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertModel"),c(iS,"href","/docs/transformers/pr_16058/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(dS,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraModel"),c(cS,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertModel"),c(fS,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetModel"),c(mS,"href","/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTModel"),c(gS,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelModel"),c(hS,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelBaseModel"),c(pS,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2Model"),c(_S,"href","/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(uS,"href","/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJModel"),c(bS,"href","/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertModel"),c(vS,"href","/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertModel"),c(TS,"href","/docs/transformers/pr_16058/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(FS,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(CS,"href","/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(MS,"href","/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDModel"),c(ES,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerModel"),c(yS,"href","/docs/transformers/pr_16058/en/model_doc/luke#transformers.LukeModel"),c(wS,"href","/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertModel"),c(AS,"href","/docs/transformers/pr_16058/en/model_doc/m2m_100#transformers.M2M100Model"),c(LS,"href","/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianModel"),c(BS,"href","/docs/transformers/pr_16058/en/model_doc/maskformer#transformers.MaskFormerModel"),c(xS,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartModel"),c(kS,"href","/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(RS,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertModel"),c(SS,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetModel"),c(PS,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5Model"),c($S,"href","/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerModel"),c(IS,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(jS,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusModel"),c(DS,"href","/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverModel"),c(NS,"href","/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartModel"),c(qS,"href","/docs/transformers/pr_16058/en/model_doc/poolformer#transformers.PoolFormerModel"),c(OS,"href","/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(GS,"href","/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertModel"),c(XS,"href","/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerModel"),c(VS,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertModel"),c(zS,"href","/docs/transformers/pr_16058/en/model_doc/retribert#transformers.RetriBertModel"),c(WS,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaModel"),c(QS,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerModel"),c(HS,"href","/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerModel"),c(US,"href","/docs/transformers/pr_16058/en/model_doc/sew#transformers.SEWModel"),c(JS,"href","/docs/transformers/pr_16058/en/model_doc/sew-d#transformers.SEWDModel"),c(YS,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(KS,"href","/docs/transformers/pr_16058/en/model_doc/splinter#transformers.SplinterModel"),c(ZS,"href","/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(eP,"href","/docs/transformers/pr_16058/en/model_doc/swin#transformers.SwinModel"),c(oP,"href","/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5Model"),c(rP,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasModel"),c(tP,"href","/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(aP,"href","/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechModel"),c(nP,"href","/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(sP,"href","/docs/transformers/pr_16058/en/model_doc/vilt#transformers.ViltModel"),c(lP,"href","/docs/transformers/pr_16058/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(iP,"href","/docs/transformers/pr_16058/en/model_doc/visual_bert#transformers.VisualBertModel"),c(dP,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTModel"),c(cP,"href","/docs/transformers/pr_16058/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(fP,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(mP,"href","/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMModel"),c(gP,"href","/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMModel"),c(hP,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMModel"),c(pP,"href","/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(_P,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(uP,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(bP,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetModel"),c(vP,"href","/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoModel"),c(je,"class","docstring"),c(Yo,"class","docstring"),c(A_,"id","transformers.AutoModelForPreTraining"),c(A_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(A_,"href","#transformers.AutoModelForPreTraining"),c(ld,"class","relative group"),c(Qr,"class","docstring"),c(TP,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForPreTraining"),c(FP,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(CP,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForPreTraining"),c(MP,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(EP,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(yP,"href","/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(wP,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(AP,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(LP,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(BP,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(xP,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForPreTraining"),c(kP,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(RP,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForPreTraining"),c(SP,"href","/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(PP,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForPreTraining"),c($P,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(IP,"href","/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(jP,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(DP,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(NP,"href","/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(qP,"href","/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(OP,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(GP,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(XP,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(VP,"href","/docs/transformers/pr_16058/en/model_doc/retribert#transformers.RetriBertModel"),c(zP,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(WP,"href","/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(QP,"href","/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(HP,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(UP,"href","/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(JP,"href","/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(YP,"href","/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(KP,"href","/docs/transformers/pr_16058/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(ZP,"href","/docs/transformers/pr_16058/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(e$,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(o$,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(r$,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(t$,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(a$,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(De,"class","docstring"),c(Ko,"class","docstring"),c(hu,"id","transformers.AutoModelForCausalLM"),c(hu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hu,"href","#transformers.AutoModelForCausalLM"),c(cd,"class","relative group"),c(Hr,"class","docstring"),c(n$,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForCausalLM"),c(s$,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertLMHeadModel"),c(l$,"href","/docs/transformers/pr_16058/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(i$,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(d$,"href","/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(c$,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(f$,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(m$,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(g$,"href","/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(h$,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(p$,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForCausalLM"),c(_$,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(u$,"href","/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(b$,"href","/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(v$,"href","/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianForCausalLM"),c(T$,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartForCausalLM"),c(F$,"href","/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(C$,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(M$,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(E$,"href","/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(y$,"href","/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(w$,"href","/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(A$,"href","/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(L$,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(B$,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(x$,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(k$,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(R$,"href","/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(S$,"href","/docs/transformers/pr_16058/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(P$,"href","/docs/transformers/pr_16058/en/model_doc/xglm#transformers.XGLMForCausalLM"),c($$,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(I$,"href","/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(j$,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(D$,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(N$,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ne,"class","docstring"),c(Zo,"class","docstring"),c(Yu,"id","transformers.AutoModelForMaskedLM"),c(Yu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yu,"href","#transformers.AutoModelForMaskedLM"),c(gd,"class","relative group"),c(Ur,"class","docstring"),c(q$,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(O$,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(G$,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForMaskedLM"),c(X$,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(V$,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(z$,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(W$,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(Q$,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(H$,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(U$,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(J$,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(Y$,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(K$,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(Z$,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(eI,"href","/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(oI,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(rI,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(tI,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(aI,"href","/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(nI,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(sI,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(lI,"href","/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(iI,"href","/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(dI,"href","/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(cI,"href","/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(fI,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(mI,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(gI,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(hI,"href","/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(pI,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(_I,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(uI,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(bI,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(vI,"href","/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(qe,"class","docstring"),c(er,"class","docstring"),c(P1,"id","transformers.AutoModelForSeq2SeqLM"),c(P1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P1,"href","#transformers.AutoModelForSeq2SeqLM"),c(_d,"class","relative group"),c(Jr,"class","docstring"),c(TI,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(FI,"href","/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(CI,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(MI,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(EI,"href","/docs/transformers/pr_16058/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(yI,"href","/docs/transformers/pr_16058/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(wI,"href","/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(AI,"href","/docs/transformers/pr_16058/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(LI,"href","/docs/transformers/pr_16058/en/model_doc/marian#transformers.MarianMTModel"),c(BI,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(xI,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(kI,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(RI,"href","/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(SI,"href","/docs/transformers/pr_16058/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(PI,"href","/docs/transformers/pr_16058/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c($I,"href","/docs/transformers/pr_16058/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(Oe,"class","docstring"),c(or,"class","docstring"),c(K1,"id","transformers.AutoModelForSequenceClassification"),c(K1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K1,"href","#transformers.AutoModelForSequenceClassification"),c(vd,"class","relative group"),c(Yr,"class","docstring"),c(II,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(jI,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForSequenceClassification"),c(DI,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForSequenceClassification"),c(NI,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(qI,"href","/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(OI,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(GI,"href","/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(XI,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(VI,"href","/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(zI,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(WI,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(QI,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(HI,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(UI,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(JI,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(YI,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(KI,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(ZI,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(ej,"href","/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(oj,"href","/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(rj,"href","/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(tj,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(aj,"href","/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(nj,"href","/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDForSequenceClassification"),c(sj,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(lj,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(ij,"href","/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(dj,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(cj,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(fj,"href","/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(mj,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(gj,"href","/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(hj,"href","/docs/transformers/pr_16058/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(pj,"href","/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(_j,"href","/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(uj,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(bj,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(vj,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(Tj,"href","/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(Fj,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(Cj,"href","/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(Mj,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(Ej,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(yj,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(wj,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(Aj,"href","/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(Ge,"class","docstring"),c(rr,"class","docstring"),c(Wb,"id","transformers.AutoModelForMultipleChoice"),c(Wb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Wb,"href","#transformers.AutoModelForMultipleChoice"),c(Cd,"class","relative group"),c(Kr,"class","docstring"),c(Lj,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(Bj,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForMultipleChoice"),c(xj,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(kj,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(Rj,"href","/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(Sj,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(Pj,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c($j,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(Ij,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(jj,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(Dj,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(Nj,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(qj,"href","/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(Oj,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(Gj,"href","/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(Xj,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(Vj,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(zj,"href","/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(Wj,"href","/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(Qj,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(Hj,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(Uj,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(Jj,"href","/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(Yj,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(Kj,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(Zj,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(eD,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(oD,"href","/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(Xe,"class","docstring"),c(tr,"class","docstring"),c(C5,"id","transformers.AutoModelForNextSentencePrediction"),c(C5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C5,"href","#transformers.AutoModelForNextSentencePrediction"),c(yd,"class","relative group"),c(Zr,"class","docstring"),c(rD,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(tD,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(aD,"href","/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(nD,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(sD,"href","/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(Ve,"class","docstring"),c(ar,"class","docstring"),c(B5,"id","transformers.AutoModelForTokenClassification"),c(B5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B5,"href","#transformers.AutoModelForTokenClassification"),c(Ld,"class","relative group"),c(et,"class","docstring"),c(lD,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(iD,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForTokenClassification"),c(dD,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(cD,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(fD,"href","/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineForTokenClassification"),c(mD,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(gD,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(hD,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(pD,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(_D,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(uD,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(bD,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(vD,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(TD,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(FD,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(CD,"href","/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(MD,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(ED,"href","/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(yD,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(wD,"href","/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(AD,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(LD,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(BD,"href","/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(xD,"href","/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(kD,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(RD,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(SD,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(PD,"href","/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c($D,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(ID,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(jD,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(DD,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(ND,"href","/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ze,"class","docstring"),c(nr,"class","docstring"),c(c2,"id","transformers.AutoModelForQuestionAnswering"),c(c2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(c2,"href","#transformers.AutoModelForQuestionAnswering"),c(kd,"class","relative group"),c(ot,"class","docstring"),c(qD,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(OD,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(GD,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(XD,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(VD,"href","/docs/transformers/pr_16058/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(zD,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(WD,"href","/docs/transformers/pr_16058/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(QD,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(HD,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(UD,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(JD,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(YD,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(KD,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(ZD,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(eN,"href","/docs/transformers/pr_16058/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(oN,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(rN,"href","/docs/transformers/pr_16058/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(tN,"href","/docs/transformers/pr_16058/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(aN,"href","/docs/transformers/pr_16058/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(nN,"href","/docs/transformers/pr_16058/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(sN,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(lN,"href","/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(iN,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(dN,"href","/docs/transformers/pr_16058/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(cN,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(fN,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(mN,"href","/docs/transformers/pr_16058/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(gN,"href","/docs/transformers/pr_16058/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(hN,"href","/docs/transformers/pr_16058/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(pN,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(_N,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(uN,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(bN,"href","/docs/transformers/pr_16058/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(vN,"href","/docs/transformers/pr_16058/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(TN,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(FN,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(CN,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(MN,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(EN,"href","/docs/transformers/pr_16058/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(We,"class","docstring"),c(sr,"class","docstring"),c(Y2,"id","transformers.AutoModelForTableQuestionAnswering"),c(Y2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y2,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Pd,"class","relative group"),c(rt,"class","docstring"),c(yN,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(Qe,"class","docstring"),c(lr,"class","docstring"),c(ev,"id","transformers.AutoModelForImageClassification"),c(ev,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ev,"href","#transformers.AutoModelForImageClassification"),c(jd,"class","relative group"),c(tt,"class","docstring"),c(wN,"href","/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitForImageClassification"),c(AN,"href","/docs/transformers/pr_16058/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(LN,"href","/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTForImageClassification"),c(BN,"href","/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(xN,"href","/docs/transformers/pr_16058/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(kN,"href","/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(RN,"href","/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(SN,"href","/docs/transformers/pr_16058/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(PN,"href","/docs/transformers/pr_16058/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c($N,"href","/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(IN,"href","/docs/transformers/pr_16058/en/model_doc/swin#transformers.SwinForImageClassification"),c(jN,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTForImageClassification"),c(He,"class","docstring"),c(ir,"class","docstring"),c(dv,"id","transformers.AutoModelForVision2Seq"),c(dv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dv,"href","#transformers.AutoModelForVision2Seq"),c(qd,"class","relative group"),c(at,"class","docstring"),c(DN,"href","/docs/transformers/pr_16058/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(Ue,"class","docstring"),c(dr,"class","docstring"),c(mv,"id","transformers.AutoModelForAudioClassification"),c(mv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mv,"href","#transformers.AutoModelForAudioClassification"),c(Xd,"class","relative group"),c(nt,"class","docstring"),c(NN,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(qN,"href","/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(ON,"href","/docs/transformers/pr_16058/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(GN,"href","/docs/transformers/pr_16058/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(XN,"href","/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(VN,"href","/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(zN,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(WN,"href","/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(Je,"class","docstring"),c(cr,"class","docstring"),c(Cv,"id","transformers.AutoModelForAudioFrameClassification"),c(Cv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Cv,"href","#transformers.AutoModelForAudioFrameClassification"),c(Wd,"class","relative group"),c(st,"class","docstring"),c(QN,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(HN,"href","/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(UN,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(JN,"href","/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(Ye,"class","docstring"),c(fr,"class","docstring"),c(Lv,"id","transformers.AutoModelForCTC"),c(Lv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lv,"href","#transformers.AutoModelForCTC"),c(Ud,"class","relative group"),c(lt,"class","docstring"),c(YN,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(KN,"href","/docs/transformers/pr_16058/en/model_doc/hubert#transformers.HubertForCTC"),c(ZN,"href","/docs/transformers/pr_16058/en/model_doc/sew#transformers.SEWForCTC"),c(eq,"href","/docs/transformers/pr_16058/en/model_doc/sew-d#transformers.SEWDForCTC"),c(oq,"href","/docs/transformers/pr_16058/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(rq,"href","/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(tq,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(aq,"href","/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMForCTC"),c(Ke,"class","docstring"),c(mr,"class","docstring"),c(Dv,"id","transformers.AutoModelForSpeechSeq2Seq"),c(Dv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Dv,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Kd,"class","relative group"),c(it,"class","docstring"),c(nq,"href","/docs/transformers/pr_16058/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(sq,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(Ze,"class","docstring"),c(gr,"class","docstring"),c(Gv,"id","transformers.AutoModelForAudioXVector"),c(Gv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Gv,"href","#transformers.AutoModelForAudioXVector"),c(oc,"class","relative group"),c(dt,"class","docstring"),c(lq,"href","/docs/transformers/pr_16058/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(iq,"href","/docs/transformers/pr_16058/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(dq,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(cq,"href","/docs/transformers/pr_16058/en/model_doc/wavlm#transformers.WavLMForXVector"),c(eo,"class","docstring"),c(hr,"class","docstring"),c(Hv,"id","transformers.AutoModelForMaskedImageModeling"),c(Hv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hv,"href","#transformers.AutoModelForMaskedImageModeling"),c(ac,"class","relative group"),c(ct,"class","docstring"),c(fq,"href","/docs/transformers/pr_16058/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(mq,"href","/docs/transformers/pr_16058/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(gq,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(oo,"class","docstring"),c(pr,"class","docstring"),c(Zv,"id","transformers.AutoModelForObjectDetection"),c(Zv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Zv,"href","#transformers.AutoModelForObjectDetection"),c(ic,"class","relative group"),c(ft,"class","docstring"),c(hq,"href","/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrForObjectDetection"),c(ro,"class","docstring"),c(_r,"class","docstring"),c(r6,"id","transformers.AutoModelForImageSegmentation"),c(r6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r6,"href","#transformers.AutoModelForImageSegmentation"),c(fc,"class","relative group"),c(mt,"class","docstring"),c(pq,"href","/docs/transformers/pr_16058/en/model_doc/detr#transformers.DetrForSegmentation"),c(to,"class","docstring"),c(ur,"class","docstring"),c(n6,"id","transformers.AutoModelForSemanticSegmentation"),c(n6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n6,"href","#transformers.AutoModelForSemanticSegmentation"),c(hc,"class","relative group"),c(gt,"class","docstring"),c(_q,"href","/docs/transformers/pr_16058/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(uq,"href","/docs/transformers/pr_16058/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(ao,"class","docstring"),c(br,"class","docstring"),c(d6,"id","transformers.AutoModelForInstanceSegmentation"),c(d6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d6,"href","#transformers.AutoModelForInstanceSegmentation"),c(uc,"class","relative group"),c(ht,"class","docstring"),c(bq,"href","/docs/transformers/pr_16058/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(no,"class","docstring"),c(vr,"class","docstring"),c(m6,"id","transformers.TFAutoModel"),c(m6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m6,"href","#transformers.TFAutoModel"),c(Tc,"class","relative group"),c(pt,"class","docstring"),c(vq,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertModel"),c(Tq,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.TFBartModel"),c(Fq,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertModel"),c(Cq,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(Mq,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(Eq,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertModel"),c(yq,"href","/docs/transformers/pr_16058/en/model_doc/clip#transformers.TFCLIPModel"),c(wq,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertModel"),c(Aq,"href","/docs/transformers/pr_16058/en/model_doc/convnext#transformers.TFConvNextModel"),c(Lq,"href","/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.TFCTRLModel"),c(Bq,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.TFDebertaModel"),c(xq,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(kq,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(Rq,"href","/docs/transformers/pr_16058/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(Sq,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraModel"),c(Pq,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertModel"),c($q,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelModel"),c(Iq,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(jq,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.TFGPT2Model"),c(Dq,"href","/docs/transformers/pr_16058/en/model_doc/hubert#transformers.TFHubertModel"),c(Nq,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(qq,"href","/docs/transformers/pr_16058/en/model_doc/led#transformers.TFLEDModel"),c(Oq,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerModel"),c(Gq,"href","/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.TFLxmertModel"),c(Xq,"href","/docs/transformers/pr_16058/en/model_doc/marian#transformers.TFMarianModel"),c(Vq,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.TFMBartModel"),c(zq,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(Wq,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetModel"),c(Qq,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.TFMT5Model"),c(Hq,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(Uq,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.TFPegasusModel"),c(Jq,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertModel"),c(Yq,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaModel"),c(Kq,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerModel"),c(Zq,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(eO,"href","/docs/transformers/pr_16058/en/model_doc/t5#transformers.TFT5Model"),c(oO,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TFTapasModel"),c(rO,"href","/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(tO,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.TFViTModel"),c(aO,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(nO,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMModel"),c(sO,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(lO,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetModel"),c(ho,"class","docstring"),c(Tr,"class","docstring"),c(e0,"id","transformers.TFAutoModelForPreTraining"),c(e0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(e0,"href","#transformers.TFAutoModelForPreTraining"),c(Mc,"class","relative group"),c(_t,"class","docstring"),c(iO,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(dO,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(cO,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForPreTraining"),c(fO,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(mO,"href","/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(gO,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(hO,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(pO,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(_O,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(uO,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(bO,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(vO,"href","/docs/transformers/pr_16058/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(TO,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(FO,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(CO,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(MO,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(EO,"href","/docs/transformers/pr_16058/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(yO,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(wO,"href","/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(AO,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(LO,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(BO,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(po,"class","docstring"),c(Fr,"class","docstring"),c(M0,"id","transformers.TFAutoModelForCausalLM"),c(M0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M0,"href","#transformers.TFAutoModelForCausalLM"),c(wc,"class","relative group"),c(ut,"class","docstring"),c(xO,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(kO,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(RO,"href","/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(SO,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(PO,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c($O,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(IO,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(jO,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(DO,"href","/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(NO,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(qO,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(_o,"class","docstring"),c(Cr,"class","docstring"),c($0,"id","transformers.TFAutoModelForImageClassification"),c($0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($0,"href","#transformers.TFAutoModelForImageClassification"),c(Bc,"class","relative group"),c(bt,"class","docstring"),c(OO,"href","/docs/transformers/pr_16058/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(GO,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.TFViTForImageClassification"),c(uo,"class","docstring"),c(Mr,"class","docstring"),c(D0,"id","transformers.TFAutoModelForMaskedLM"),c(D0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D0,"href","#transformers.TFAutoModelForMaskedLM"),c(Rc,"class","relative group"),c(vt,"class","docstring"),c(XO,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(VO,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(zO,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(WO,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(QO,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(HO,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(UO,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(JO,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(YO,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(KO,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(ZO,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(eG,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(oG,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(rG,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(tG,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(aG,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(nG,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(sG,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(lG,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(iG,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(bo,"class","docstring"),c(Er,"class","docstring"),c(nT,"id","transformers.TFAutoModelForSeq2SeqLM"),c(nT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(nT,"href","#transformers.TFAutoModelForSeq2SeqLM"),c($c,"class","relative group"),c(Tt,"class","docstring"),c(dG,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(cG,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(fG,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(mG,"href","/docs/transformers/pr_16058/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(gG,"href","/docs/transformers/pr_16058/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(hG,"href","/docs/transformers/pr_16058/en/model_doc/marian#transformers.TFMarianMTModel"),c(pG,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(_G,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(uG,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(bG,"href","/docs/transformers/pr_16058/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(vo,"class","docstring"),c(yr,"class","docstring"),c(_T,"id","transformers.TFAutoModelForSequenceClassification"),c(_T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_T,"href","#transformers.TFAutoModelForSequenceClassification"),c(Dc,"class","relative group"),c(Ft,"class","docstring"),c(vG,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(TG,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(FG,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(CG,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(MG,"href","/docs/transformers/pr_16058/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(EG,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(yG,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(wG,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(AG,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(LG,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(BG,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(xG,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(kG,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(RG,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(SG,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(PG,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c($G,"href","/docs/transformers/pr_16058/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(IG,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(jG,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(DG,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(NG,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(qG,"href","/docs/transformers/pr_16058/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(OG,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(GG,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(XG,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(To,"class","docstring"),c(wr,"class","docstring"),c(GT,"id","transformers.TFAutoModelForMultipleChoice"),c(GT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(GT,"href","#transformers.TFAutoModelForMultipleChoice"),c(Oc,"class","relative group"),c(Ct,"class","docstring"),c(VG,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(zG,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(WG,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(QG,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(HG,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(UG,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(JG,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(YG,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(KG,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(ZG,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(eX,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(oX,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(rX,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(tX,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(aX,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(nX,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(sX,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Fo,"class","docstring"),c(Ar,"class","docstring"),c(s8,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(s8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s8,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Vc,"class","relative group"),c(Mt,"class","docstring"),c(lX,"href","/docs/transformers/pr_16058/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Co,"class","docstring"),c(Lr,"class","docstring"),c(i8,"id","transformers.TFAutoModelForTokenClassification"),c(i8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i8,"href","#transformers.TFAutoModelForTokenClassification"),c(Qc,"class","relative group"),c(Et,"class","docstring"),c(iX,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(dX,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(cX,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(fX,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(mX,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(gX,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(hX,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(pX,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(_X,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(uX,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(bX,"href","/docs/transformers/pr_16058/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(vX,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(TX,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(FX,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(CX,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(MX,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(EX,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(yX,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(wX,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(AX,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Mo,"class","docstring"),c(Br,"class","docstring"),c(B8,"id","transformers.TFAutoModelForQuestionAnswering"),c(B8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B8,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Jc,"class","relative group"),c(yt,"class","docstring"),c(LX,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(BX,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(xX,"href","/docs/transformers/pr_16058/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(kX,"href","/docs/transformers/pr_16058/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(RX,"href","/docs/transformers/pr_16058/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(SX,"href","/docs/transformers/pr_16058/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(PX,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c($X,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(IX,"href","/docs/transformers/pr_16058/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(jX,"href","/docs/transformers/pr_16058/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(DX,"href","/docs/transformers/pr_16058/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(NX,"href","/docs/transformers/pr_16058/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(qX,"href","/docs/transformers/pr_16058/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(OX,"href","/docs/transformers/pr_16058/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(GX,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(XX,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(VX,"href","/docs/transformers/pr_16058/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(zX,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(WX,"href","/docs/transformers/pr_16058/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Eo,"class","docstring"),c(xr,"class","docstring"),c(U8,"id","transformers.TFAutoModelForVision2Seq"),c(U8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U8,"href","#transformers.TFAutoModelForVision2Seq"),c(Zc,"class","relative group"),c(wt,"class","docstring"),c(QX,"href","/docs/transformers/pr_16058/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(yo,"class","docstring"),c(kr,"class","docstring"),c(Y8,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(Y8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y8,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(rf,"class","relative group"),c(At,"class","docstring"),c(HX,"href","/docs/transformers/pr_16058/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(wo,"class","docstring"),c(Rr,"class","docstring"),c(Z8,"id","transformers.FlaxAutoModel"),c(Z8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z8,"href","#transformers.FlaxAutoModel"),c(nf,"class","relative group"),c(Lt,"class","docstring"),c(UX,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertModel"),c(JX,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartModel"),c(YX,"href","/docs/transformers/pr_16058/en/model_doc/beit#transformers.FlaxBeitModel"),c(KX,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertModel"),c(ZX,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(eV,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(oV,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(rV,"href","/docs/transformers/pr_16058/en/model_doc/clip#transformers.FlaxCLIPModel"),c(tV,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(aV,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraModel"),c(nV,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(sV,"href","/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(lV,"href","/docs/transformers/pr_16058/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(iV,"href","/docs/transformers/pr_16058/en/model_doc/marian#transformers.FlaxMarianModel"),c(dV,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartModel"),c(cV,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.FlaxMT5Model"),c(fV,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(mV,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(gV,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(hV,"href","/docs/transformers/pr_16058/en/model_doc/t5#transformers.FlaxT5Model"),c(pV,"href","/docs/transformers/pr_16058/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(_V,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.FlaxViTModel"),c(uV,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(bV,"href","/docs/transformers/pr_16058/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(vV,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Ao,"class","docstring"),c(Sr,"class","docstring"),c(yF,"id","transformers.FlaxAutoModelForCausalLM"),c(yF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yF,"href","#transformers.FlaxAutoModelForCausalLM"),c(df,"class","relative group"),c(Bt,"class","docstring"),c(TV,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(FV,"href","/docs/transformers/pr_16058/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(CV,"href","/docs/transformers/pr_16058/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(MV,"href","/docs/transformers/pr_16058/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(EV,"href","/docs/transformers/pr_16058/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Lo,"class","docstring"),c(Pr,"class","docstring"),c(kF,"id","transformers.FlaxAutoModelForPreTraining"),c(kF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(kF,"href","#transformers.FlaxAutoModelForPreTraining"),c(mf,"class","relative group"),c(xt,"class","docstring"),c(yV,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(wV,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(AV,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(LV,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(BV,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(xV,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(kV,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(RV,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(SV,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(PV,"href","/docs/transformers/pr_16058/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c($V,"href","/docs/transformers/pr_16058/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(IV,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Bo,"class","docstring"),c($r,"class","docstring"),c(VF,"id","transformers.FlaxAutoModelForMaskedLM"),c(VF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(VF,"href","#transformers.FlaxAutoModelForMaskedLM"),c(pf,"class","relative group"),c(kt,"class","docstring"),c(jV,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(DV,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(NV,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(qV,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(OV,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(GV,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(XV,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(VV,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(zV,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(WV,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(xo,"class","docstring"),c(Ir,"class","docstring"),c(oC,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(oC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oC,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(bf,"class","relative group"),c(Rt,"class","docstring"),c(QV,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(HV,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(UV,"href","/docs/transformers/pr_16058/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(JV,"href","/docs/transformers/pr_16058/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(YV,"href","/docs/transformers/pr_16058/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(KV,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(ZV,"href","/docs/transformers/pr_16058/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(ez,"href","/docs/transformers/pr_16058/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(oz,"href","/docs/transformers/pr_16058/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(ko,"class","docstring"),c(jr,"class","docstring"),c(fC,"id","transformers.FlaxAutoModelForSequenceClassification"),c(fC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fC,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Ff,"class","relative group"),c(St,"class","docstring"),c(rz,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(tz,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(az,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(nz,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(sz,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(lz,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(iz,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(dz,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(cz,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(fz,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Ro,"class","docstring"),c(Dr,"class","docstring"),c(CC,"id","transformers.FlaxAutoModelForSpeechSeq2Seq"),c(CC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(CC,"href","#transformers.FlaxAutoModelForSpeechSeq2Seq"),c(Ef,"class","relative group"),c(Pt,"class","docstring"),c(mz,"href","/docs/transformers/pr_16058/en/model_doc/speech-encoder-decoder#transformers.FlaxSpeechEncoderDecoderModel"),c(So,"class","docstring"),c(Nr,"class","docstring"),c(EC,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(EC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(EC,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Af,"class","relative group"),c($t,"class","docstring"),c(gz,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(hz,"href","/docs/transformers/pr_16058/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(pz,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(_z,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(uz,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(bz,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(vz,"href","/docs/transformers/pr_16058/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Tz,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Fz,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Cz,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Po,"class","docstring"),c(qr,"class","docstring"),c($C,"id","transformers.FlaxAutoModelForTokenClassification"),c($C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($C,"href","#transformers.FlaxAutoModelForTokenClassification"),c(xf,"class","relative group"),c(It,"class","docstring"),c(Mz,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Ez,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(yz,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(wz,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Az,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Lz,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Bz,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(xz,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c($o,"class","docstring"),c(Or,"class","docstring"),c(VC,"id","transformers.FlaxAutoModelForMultipleChoice"),c(VC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(VC,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(Sf,"class","relative group"),c(jt,"class","docstring"),c(kz,"href","/docs/transformers/pr_16058/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Rz,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Sz,"href","/docs/transformers/pr_16058/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Pz,"href","/docs/transformers/pr_16058/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c($z,"href","/docs/transformers/pr_16058/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Iz,"href","/docs/transformers/pr_16058/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(jz,"href","/docs/transformers/pr_16058/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Dz,"href","/docs/transformers/pr_16058/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Io,"class","docstring"),c(Gr,"class","docstring"),c(ZC,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(ZC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZC,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(If,"class","relative group"),c(Dt,"class","docstring"),c(Nz,"href","/docs/transformers/pr_16058/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(jo,"class","docstring"),c(Xr,"class","docstring"),c(oM,"id","transformers.FlaxAutoModelForImageClassification"),c(oM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oM,"href","#transformers.FlaxAutoModelForImageClassification"),c(Nf,"class","relative group"),c(Nt,"class","docstring"),c(qz,"href","/docs/transformers/pr_16058/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Oz,"href","/docs/transformers/pr_16058/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Do,"class","docstring"),c(Vr,"class","docstring"),c(aM,"id","transformers.FlaxAutoModelForVision2Seq"),c(aM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aM,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Gf,"class","relative group"),c(qt,"class","docstring"),c(Gz,"href","/docs/transformers/pr_16058/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(No,"class","docstring"),c(zr,"class","docstring")},m(d,u){e(document.head,J),b(d,Pe,u),b(d,de,u),e(de,he),e(he,io),g(fe,io,null),e(de,Fe),e(de,zo),e(zo,Vi),b(d,Wf,u),b(d,ha,u),e(ha,zi),e(ha,Wi),e(Wi,s4),e(ha,Qf),b(d,Le,u),b(d,co,u),e(co,Qi),e(co,Wn),e(Wn,l4),e(co,Qn),e(co,Hn),e(Hn,i4),e(co,Hi),e(co,Un),e(Un,d4),e(co,Ui),b(d,Hf,u),g(Va,d,u),b(d,fo,u),b(d,pe,u),e(pe,s9),e(pe,Ji),e(Ji,l9),e(pe,i9),b(d,Wo,u),b(d,za,u),e(za,d9),e(za,Uf),e(Uf,c9),e(za,c$e),b(d,Wxe,u),b(d,Yi,u),e(Yi,Jf),e(Jf,jQ),g(c4,jQ,null),e(Yi,f$e),e(Yi,DQ),e(DQ,m$e),b(d,Qxe,u),b(d,Jn,u),e(Jn,g$e),e(Jn,NQ),e(NQ,h$e),e(Jn,p$e),e(Jn,qQ),e(qQ,_$e),e(Jn,u$e),b(d,Hxe,u),g(f4,d,u),b(d,Uxe,u),b(d,f9,u),e(f9,b$e),b(d,Jxe,u),g(Yf,d,u),b(d,Yxe,u),b(d,Ki,u),e(Ki,Kf),e(Kf,OQ),g(m4,OQ,null),e(Ki,v$e),e(Ki,GQ),e(GQ,T$e),b(d,Kxe,u),b(d,Qo,u),g(g4,Qo,null),e(Qo,F$e),e(Qo,h4),e(h4,C$e),e(h4,m9),e(m9,M$e),e(h4,E$e),e(Qo,y$e),e(Qo,p4),e(p4,w$e),e(p4,XQ),e(XQ,A$e),e(p4,L$e),e(Qo,B$e),e(Qo,mo),g(_4,mo,null),e(mo,x$e),e(mo,VQ),e(VQ,k$e),e(mo,R$e),e(mo,Zi),e(Zi,S$e),e(Zi,zQ),e(zQ,P$e),e(Zi,$$e),e(Zi,WQ),e(WQ,I$e),e(Zi,j$e),e(mo,D$e),e(mo,v),e(v,Zf),e(Zf,QQ),e(QQ,N$e),e(Zf,q$e),e(Zf,g9),e(g9,O$e),e(Zf,G$e),e(v,X$e),e(v,em),e(em,HQ),e(HQ,V$e),e(em,z$e),e(em,h9),e(h9,W$e),e(em,Q$e),e(v,H$e),e(v,om),e(om,UQ),e(UQ,U$e),e(om,J$e),e(om,p9),e(p9,Y$e),e(om,K$e),e(v,Z$e),e(v,rm),e(rm,JQ),e(JQ,eIe),e(rm,oIe),e(rm,_9),e(_9,rIe),e(rm,tIe),e(v,aIe),e(v,tm),e(tm,YQ),e(YQ,nIe),e(tm,sIe),e(tm,u9),e(u9,lIe),e(tm,iIe),e(v,dIe),e(v,am),e(am,KQ),e(KQ,cIe),e(am,fIe),e(am,b9),e(b9,mIe),e(am,gIe),e(v,hIe),e(v,nm),e(nm,ZQ),e(ZQ,pIe),e(nm,_Ie),e(nm,v9),e(v9,uIe),e(nm,bIe),e(v,vIe),e(v,sm),e(sm,eH),e(eH,TIe),e(sm,FIe),e(sm,T9),e(T9,CIe),e(sm,MIe),e(v,EIe),e(v,lm),e(lm,oH),e(oH,yIe),e(lm,wIe),e(lm,F9),e(F9,AIe),e(lm,LIe),e(v,BIe),e(v,im),e(im,rH),e(rH,xIe),e(im,kIe),e(im,C9),e(C9,RIe),e(im,SIe),e(v,PIe),e(v,dm),e(dm,tH),e(tH,$Ie),e(dm,IIe),e(dm,M9),e(M9,jIe),e(dm,DIe),e(v,NIe),e(v,cm),e(cm,aH),e(aH,qIe),e(cm,OIe),e(cm,E9),e(E9,GIe),e(cm,XIe),e(v,VIe),e(v,fm),e(fm,nH),e(nH,zIe),e(fm,WIe),e(fm,y9),e(y9,QIe),e(fm,HIe),e(v,UIe),e(v,mm),e(mm,sH),e(sH,JIe),e(mm,YIe),e(mm,w9),e(w9,KIe),e(mm,ZIe),e(v,eje),e(v,gm),e(gm,lH),e(lH,oje),e(gm,rje),e(gm,A9),e(A9,tje),e(gm,aje),e(v,nje),e(v,hm),e(hm,iH),e(iH,sje),e(hm,lje),e(hm,L9),e(L9,ije),e(hm,dje),e(v,cje),e(v,pm),e(pm,dH),e(dH,fje),e(pm,mje),e(pm,B9),e(B9,gje),e(pm,hje),e(v,pje),e(v,_m),e(_m,cH),e(cH,_je),e(_m,uje),e(_m,x9),e(x9,bje),e(_m,vje),e(v,Tje),e(v,um),e(um,fH),e(fH,Fje),e(um,Cje),e(um,k9),e(k9,Mje),e(um,Eje),e(v,yje),e(v,bm),e(bm,mH),e(mH,wje),e(bm,Aje),e(bm,R9),e(R9,Lje),e(bm,Bje),e(v,xje),e(v,vm),e(vm,gH),e(gH,kje),e(vm,Rje),e(vm,S9),e(S9,Sje),e(vm,Pje),e(v,$je),e(v,Tm),e(Tm,hH),e(hH,Ije),e(Tm,jje),e(Tm,P9),e(P9,Dje),e(Tm,Nje),e(v,qje),e(v,Fm),e(Fm,pH),e(pH,Oje),e(Fm,Gje),e(Fm,$9),e($9,Xje),e(Fm,Vje),e(v,zje),e(v,Cm),e(Cm,_H),e(_H,Wje),e(Cm,Qje),e(Cm,I9),e(I9,Hje),e(Cm,Uje),e(v,Jje),e(v,Mm),e(Mm,uH),e(uH,Yje),e(Mm,Kje),e(Mm,j9),e(j9,Zje),e(Mm,eDe),e(v,oDe),e(v,Em),e(Em,bH),e(bH,rDe),e(Em,tDe),e(Em,D9),e(D9,aDe),e(Em,nDe),e(v,sDe),e(v,ym),e(ym,vH),e(vH,lDe),e(ym,iDe),e(ym,N9),e(N9,dDe),e(ym,cDe),e(v,fDe),e(v,wm),e(wm,TH),e(TH,mDe),e(wm,gDe),e(wm,q9),e(q9,hDe),e(wm,pDe),e(v,_De),e(v,Am),e(Am,FH),e(FH,uDe),e(Am,bDe),e(Am,O9),e(O9,vDe),e(Am,TDe),e(v,FDe),e(v,Lm),e(Lm,CH),e(CH,CDe),e(Lm,MDe),e(Lm,G9),e(G9,EDe),e(Lm,yDe),e(v,wDe),e(v,Bm),e(Bm,MH),e(MH,ADe),e(Bm,LDe),e(Bm,X9),e(X9,BDe),e(Bm,xDe),e(v,kDe),e(v,xm),e(xm,EH),e(EH,RDe),e(xm,SDe),e(xm,V9),e(V9,PDe),e(xm,$De),e(v,IDe),e(v,km),e(km,yH),e(yH,jDe),e(km,DDe),e(km,z9),e(z9,NDe),e(km,qDe),e(v,ODe),e(v,Rm),e(Rm,wH),e(wH,GDe),e(Rm,XDe),e(Rm,W9),e(W9,VDe),e(Rm,zDe),e(v,WDe),e(v,Sm),e(Sm,AH),e(AH,QDe),e(Sm,HDe),e(Sm,Q9),e(Q9,UDe),e(Sm,JDe),e(v,YDe),e(v,Pm),e(Pm,LH),e(LH,KDe),e(Pm,ZDe),e(Pm,H9),e(H9,eNe),e(Pm,oNe),e(v,rNe),e(v,$m),e($m,BH),e(BH,tNe),e($m,aNe),e($m,U9),e(U9,nNe),e($m,sNe),e(v,lNe),e(v,Im),e(Im,xH),e(xH,iNe),e(Im,dNe),e(Im,J9),e(J9,cNe),e(Im,fNe),e(v,mNe),e(v,jm),e(jm,kH),e(kH,gNe),e(jm,hNe),e(jm,Y9),e(Y9,pNe),e(jm,_Ne),e(v,uNe),e(v,Dm),e(Dm,RH),e(RH,bNe),e(Dm,vNe),e(Dm,K9),e(K9,TNe),e(Dm,FNe),e(v,CNe),e(v,Nm),e(Nm,SH),e(SH,MNe),e(Nm,ENe),e(Nm,Z9),e(Z9,yNe),e(Nm,wNe),e(v,ANe),e(v,qm),e(qm,PH),e(PH,LNe),e(qm,BNe),e(qm,eB),e(eB,xNe),e(qm,kNe),e(v,RNe),e(v,Om),e(Om,$H),e($H,SNe),e(Om,PNe),e(Om,oB),e(oB,$Ne),e(Om,INe),e(v,jNe),e(v,Gm),e(Gm,IH),e(IH,DNe),e(Gm,NNe),e(Gm,rB),e(rB,qNe),e(Gm,ONe),e(v,GNe),e(v,Xm),e(Xm,jH),e(jH,XNe),e(Xm,VNe),e(Xm,tB),e(tB,zNe),e(Xm,WNe),e(v,QNe),e(v,Vm),e(Vm,DH),e(DH,HNe),e(Vm,UNe),e(Vm,aB),e(aB,JNe),e(Vm,YNe),e(v,KNe),e(v,zm),e(zm,NH),e(NH,ZNe),e(zm,eqe),e(zm,nB),e(nB,oqe),e(zm,rqe),e(v,tqe),e(v,Wm),e(Wm,qH),e(qH,aqe),e(Wm,nqe),e(Wm,sB),e(sB,sqe),e(Wm,lqe),e(v,iqe),e(v,Qm),e(Qm,OH),e(OH,dqe),e(Qm,cqe),e(Qm,lB),e(lB,fqe),e(Qm,mqe),e(v,gqe),e(v,Hm),e(Hm,GH),e(GH,hqe),e(Hm,pqe),e(Hm,iB),e(iB,_qe),e(Hm,uqe),e(v,bqe),e(v,Um),e(Um,XH),e(XH,vqe),e(Um,Tqe),e(Um,dB),e(dB,Fqe),e(Um,Cqe),e(v,Mqe),e(v,Jm),e(Jm,VH),e(VH,Eqe),e(Jm,yqe),e(Jm,cB),e(cB,wqe),e(Jm,Aqe),e(v,Lqe),e(v,Ym),e(Ym,zH),e(zH,Bqe),e(Ym,xqe),e(Ym,fB),e(fB,kqe),e(Ym,Rqe),e(v,Sqe),e(v,Km),e(Km,WH),e(WH,Pqe),e(Km,$qe),e(Km,mB),e(mB,Iqe),e(Km,jqe),e(v,Dqe),e(v,Zm),e(Zm,QH),e(QH,Nqe),e(Zm,qqe),e(Zm,gB),e(gB,Oqe),e(Zm,Gqe),e(v,Xqe),e(v,eg),e(eg,HH),e(HH,Vqe),e(eg,zqe),e(eg,hB),e(hB,Wqe),e(eg,Qqe),e(v,Hqe),e(v,og),e(og,UH),e(UH,Uqe),e(og,Jqe),e(og,pB),e(pB,Yqe),e(og,Kqe),e(v,Zqe),e(v,rg),e(rg,JH),e(JH,eOe),e(rg,oOe),e(rg,_B),e(_B,rOe),e(rg,tOe),e(v,aOe),e(v,tg),e(tg,YH),e(YH,nOe),e(tg,sOe),e(tg,uB),e(uB,lOe),e(tg,iOe),e(v,dOe),e(v,ag),e(ag,KH),e(KH,cOe),e(ag,fOe),e(ag,bB),e(bB,mOe),e(ag,gOe),e(v,hOe),e(v,ng),e(ng,ZH),e(ZH,pOe),e(ng,_Oe),e(ng,vB),e(vB,uOe),e(ng,bOe),e(v,vOe),e(v,sg),e(sg,eU),e(eU,TOe),e(sg,FOe),e(sg,TB),e(TB,COe),e(sg,MOe),e(v,EOe),e(v,lg),e(lg,oU),e(oU,yOe),e(lg,wOe),e(lg,FB),e(FB,AOe),e(lg,LOe),e(v,BOe),e(v,ig),e(ig,rU),e(rU,xOe),e(ig,kOe),e(ig,CB),e(CB,ROe),e(ig,SOe),e(v,POe),e(v,dg),e(dg,tU),e(tU,$Oe),e(dg,IOe),e(dg,MB),e(MB,jOe),e(dg,DOe),e(v,NOe),e(v,cg),e(cg,aU),e(aU,qOe),e(cg,OOe),e(cg,EB),e(EB,GOe),e(cg,XOe),e(v,VOe),e(v,fg),e(fg,nU),e(nU,zOe),e(fg,WOe),e(fg,yB),e(yB,QOe),e(fg,HOe),e(v,UOe),e(v,mg),e(mg,sU),e(sU,JOe),e(mg,YOe),e(mg,wB),e(wB,KOe),e(mg,ZOe),e(v,eGe),e(v,gg),e(gg,lU),e(lU,oGe),e(gg,rGe),e(gg,AB),e(AB,tGe),e(gg,aGe),e(v,nGe),e(v,hg),e(hg,iU),e(iU,sGe),e(hg,lGe),e(hg,LB),e(LB,iGe),e(hg,dGe),e(v,cGe),e(v,pg),e(pg,dU),e(dU,fGe),e(pg,mGe),e(pg,BB),e(BB,gGe),e(pg,hGe),e(v,pGe),e(v,_g),e(_g,cU),e(cU,_Ge),e(_g,uGe),e(_g,xB),e(xB,bGe),e(_g,vGe),e(v,TGe),e(v,ug),e(ug,fU),e(fU,FGe),e(ug,CGe),e(ug,kB),e(kB,MGe),e(ug,EGe),e(v,yGe),e(v,bg),e(bg,mU),e(mU,wGe),e(bg,AGe),e(bg,RB),e(RB,LGe),e(bg,BGe),e(v,xGe),e(v,vg),e(vg,gU),e(gU,kGe),e(vg,RGe),e(vg,SB),e(SB,SGe),e(vg,PGe),e(v,$Ge),e(v,Tg),e(Tg,hU),e(hU,IGe),e(Tg,jGe),e(Tg,PB),e(PB,DGe),e(Tg,NGe),e(v,qGe),e(v,Fg),e(Fg,pU),e(pU,OGe),e(Fg,GGe),e(Fg,$B),e($B,XGe),e(Fg,VGe),e(v,zGe),e(v,Cg),e(Cg,_U),e(_U,WGe),e(Cg,QGe),e(Cg,IB),e(IB,HGe),e(Cg,UGe),e(v,JGe),e(v,Mg),e(Mg,uU),e(uU,YGe),e(Mg,KGe),e(Mg,jB),e(jB,ZGe),e(Mg,eXe),e(v,oXe),e(v,Eg),e(Eg,bU),e(bU,rXe),e(Eg,tXe),e(Eg,DB),e(DB,aXe),e(Eg,nXe),e(v,sXe),e(v,yg),e(yg,vU),e(vU,lXe),e(yg,iXe),e(yg,NB),e(NB,dXe),e(yg,cXe),e(v,fXe),e(v,wg),e(wg,TU),e(TU,mXe),e(wg,gXe),e(wg,qB),e(qB,hXe),e(wg,pXe),e(v,_Xe),e(v,Ag),e(Ag,FU),e(FU,uXe),e(Ag,bXe),e(Ag,OB),e(OB,vXe),e(Ag,TXe),e(v,FXe),e(v,Lg),e(Lg,CU),e(CU,CXe),e(Lg,MXe),e(Lg,GB),e(GB,EXe),e(Lg,yXe),e(v,wXe),e(v,Bg),e(Bg,MU),e(MU,AXe),e(Bg,LXe),e(Bg,XB),e(XB,BXe),e(Bg,xXe),e(v,kXe),e(v,xg),e(xg,EU),e(EU,RXe),e(xg,SXe),e(xg,VB),e(VB,PXe),e(xg,$Xe),e(v,IXe),e(v,kg),e(kg,yU),e(yU,jXe),e(kg,DXe),e(kg,zB),e(zB,NXe),e(kg,qXe),e(v,OXe),e(v,Rg),e(Rg,wU),e(wU,GXe),e(Rg,XXe),e(Rg,WB),e(WB,VXe),e(Rg,zXe),e(v,WXe),e(v,Sg),e(Sg,AU),e(AU,QXe),e(Sg,HXe),e(Sg,QB),e(QB,UXe),e(Sg,JXe),e(v,YXe),e(v,Pg),e(Pg,LU),e(LU,KXe),e(Pg,ZXe),e(Pg,HB),e(HB,eVe),e(Pg,oVe),e(v,rVe),e(v,$g),e($g,BU),e(BU,tVe),e($g,aVe),e($g,UB),e(UB,nVe),e($g,sVe),e(v,lVe),e(v,Ig),e(Ig,xU),e(xU,iVe),e(Ig,dVe),e(Ig,JB),e(JB,cVe),e(Ig,fVe),e(v,mVe),e(v,jg),e(jg,kU),e(kU,gVe),e(jg,hVe),e(jg,YB),e(YB,pVe),e(jg,_Ve),e(v,uVe),e(v,Dg),e(Dg,RU),e(RU,bVe),e(Dg,vVe),e(Dg,KB),e(KB,TVe),e(Dg,FVe),e(mo,CVe),e(mo,SU),e(SU,MVe),e(mo,EVe),g(u4,mo,null),e(Qo,yVe),e(Qo,Ng),g(b4,Ng,null),e(Ng,wVe),e(Ng,PU),e(PU,AVe),b(d,Zxe,u),b(d,ed,u),e(ed,qg),e(qg,$U),g(v4,$U,null),e(ed,LVe),e(ed,IU),e(IU,BVe),b(d,eke,u),b(d,Ho,u),g(T4,Ho,null),e(Ho,xVe),e(Ho,F4),e(F4,kVe),e(F4,ZB),e(ZB,RVe),e(F4,SVe),e(Ho,PVe),e(Ho,C4),e(C4,$Ve),e(C4,jU),e(jU,IVe),e(C4,jVe),e(Ho,DVe),e(Ho,go),g(M4,go,null),e(go,NVe),e(go,DU),e(DU,qVe),e(go,OVe),e(go,Wa),e(Wa,GVe),e(Wa,NU),e(NU,XVe),e(Wa,VVe),e(Wa,qU),e(qU,zVe),e(Wa,WVe),e(Wa,OU),e(OU,QVe),e(Wa,HVe),e(go,UVe),e(go,E),e(E,Yn),e(Yn,GU),e(GU,JVe),e(Yn,YVe),e(Yn,ex),e(ex,KVe),e(Yn,ZVe),e(Yn,ox),e(ox,eze),e(Yn,oze),e(E,rze),e(E,Kn),e(Kn,XU),e(XU,tze),e(Kn,aze),e(Kn,rx),e(rx,nze),e(Kn,sze),e(Kn,tx),e(tx,lze),e(Kn,ize),e(E,dze),e(E,Zn),e(Zn,VU),e(VU,cze),e(Zn,fze),e(Zn,ax),e(ax,mze),e(Zn,gze),e(Zn,nx),e(nx,hze),e(Zn,pze),e(E,_ze),e(E,Og),e(Og,zU),e(zU,uze),e(Og,bze),e(Og,sx),e(sx,vze),e(Og,Tze),e(E,Fze),e(E,es),e(es,WU),e(WU,Cze),e(es,Mze),e(es,lx),e(lx,Eze),e(es,yze),e(es,ix),e(ix,wze),e(es,Aze),e(E,Lze),e(E,Gg),e(Gg,QU),e(QU,Bze),e(Gg,xze),e(Gg,dx),e(dx,kze),e(Gg,Rze),e(E,Sze),e(E,Xg),e(Xg,HU),e(HU,Pze),e(Xg,$ze),e(Xg,cx),e(cx,Ize),e(Xg,jze),e(E,Dze),e(E,Vg),e(Vg,UU),e(UU,Nze),e(Vg,qze),e(Vg,fx),e(fx,Oze),e(Vg,Gze),e(E,Xze),e(E,os),e(os,JU),e(JU,Vze),e(os,zze),e(os,mx),e(mx,Wze),e(os,Qze),e(os,gx),e(gx,Hze),e(os,Uze),e(E,Jze),e(E,rs),e(rs,YU),e(YU,Yze),e(rs,Kze),e(rs,hx),e(hx,Zze),e(rs,eWe),e(rs,px),e(px,oWe),e(rs,rWe),e(E,tWe),e(E,ts),e(ts,KU),e(KU,aWe),e(ts,nWe),e(ts,_x),e(_x,sWe),e(ts,lWe),e(ts,ux),e(ux,iWe),e(ts,dWe),e(E,cWe),e(E,zg),e(zg,ZU),e(ZU,fWe),e(zg,mWe),e(zg,bx),e(bx,gWe),e(zg,hWe),e(E,pWe),e(E,Wg),e(Wg,eJ),e(eJ,_We),e(Wg,uWe),e(Wg,vx),e(vx,bWe),e(Wg,vWe),e(E,TWe),e(E,as),e(as,oJ),e(oJ,FWe),e(as,CWe),e(as,Tx),e(Tx,MWe),e(as,EWe),e(as,Fx),e(Fx,yWe),e(as,wWe),e(E,AWe),e(E,Qg),e(Qg,rJ),e(rJ,LWe),e(Qg,BWe),e(Qg,Cx),e(Cx,xWe),e(Qg,kWe),e(E,RWe),e(E,ns),e(ns,tJ),e(tJ,SWe),e(ns,PWe),e(ns,Mx),e(Mx,$We),e(ns,IWe),e(ns,Ex),e(Ex,jWe),e(ns,DWe),e(E,NWe),e(E,ss),e(ss,aJ),e(aJ,qWe),e(ss,OWe),e(ss,yx),e(yx,GWe),e(ss,XWe),e(ss,wx),e(wx,VWe),e(ss,zWe),e(E,WWe),e(E,ls),e(ls,nJ),e(nJ,QWe),e(ls,HWe),e(ls,Ax),e(Ax,UWe),e(ls,JWe),e(ls,sJ),e(sJ,YWe),e(ls,KWe),e(E,ZWe),e(E,Hg),e(Hg,lJ),e(lJ,eQe),e(Hg,oQe),e(Hg,Lx),e(Lx,rQe),e(Hg,tQe),e(E,aQe),e(E,is),e(is,iJ),e(iJ,nQe),e(is,sQe),e(is,Bx),e(Bx,lQe),e(is,iQe),e(is,xx),e(xx,dQe),e(is,cQe),e(E,fQe),e(E,Ug),e(Ug,dJ),e(dJ,mQe),e(Ug,gQe),e(Ug,kx),e(kx,hQe),e(Ug,pQe),e(E,_Qe),e(E,ds),e(ds,cJ),e(cJ,uQe),e(ds,bQe),e(ds,Rx),e(Rx,vQe),e(ds,TQe),e(ds,Sx),e(Sx,FQe),e(ds,CQe),e(E,MQe),e(E,cs),e(cs,fJ),e(fJ,EQe),e(cs,yQe),e(cs,Px),e(Px,wQe),e(cs,AQe),e(cs,$x),e($x,LQe),e(cs,BQe),e(E,xQe),e(E,fs),e(fs,mJ),e(mJ,kQe),e(fs,RQe),e(fs,Ix),e(Ix,SQe),e(fs,PQe),e(fs,jx),e(jx,$Qe),e(fs,IQe),e(E,jQe),e(E,Jg),e(Jg,gJ),e(gJ,DQe),e(Jg,NQe),e(Jg,Dx),e(Dx,qQe),e(Jg,OQe),e(E,GQe),e(E,ms),e(ms,hJ),e(hJ,XQe),e(ms,VQe),e(ms,Nx),e(Nx,zQe),e(ms,WQe),e(ms,qx),e(qx,QQe),e(ms,HQe),e(E,UQe),e(E,Yg),e(Yg,pJ),e(pJ,JQe),e(Yg,YQe),e(Yg,Ox),e(Ox,KQe),e(Yg,ZQe),e(E,eHe),e(E,gs),e(gs,_J),e(_J,oHe),e(gs,rHe),e(gs,Gx),e(Gx,tHe),e(gs,aHe),e(gs,Xx),e(Xx,nHe),e(gs,sHe),e(E,lHe),e(E,hs),e(hs,uJ),e(uJ,iHe),e(hs,dHe),e(hs,Vx),e(Vx,cHe),e(hs,fHe),e(hs,zx),e(zx,mHe),e(hs,gHe),e(E,hHe),e(E,ps),e(ps,bJ),e(bJ,pHe),e(ps,_He),e(ps,Wx),e(Wx,uHe),e(ps,bHe),e(ps,Qx),e(Qx,vHe),e(ps,THe),e(E,FHe),e(E,_s),e(_s,vJ),e(vJ,CHe),e(_s,MHe),e(_s,Hx),e(Hx,EHe),e(_s,yHe),e(_s,Ux),e(Ux,wHe),e(_s,AHe),e(E,LHe),e(E,Kg),e(Kg,TJ),e(TJ,BHe),e(Kg,xHe),e(Kg,Jx),e(Jx,kHe),e(Kg,RHe),e(E,SHe),e(E,us),e(us,FJ),e(FJ,PHe),e(us,$He),e(us,Yx),e(Yx,IHe),e(us,jHe),e(us,Kx),e(Kx,DHe),e(us,NHe),e(E,qHe),e(E,bs),e(bs,CJ),e(CJ,OHe),e(bs,GHe),e(bs,Zx),e(Zx,XHe),e(bs,VHe),e(bs,ek),e(ek,zHe),e(bs,WHe),e(E,QHe),e(E,vs),e(vs,MJ),e(MJ,HHe),e(vs,UHe),e(vs,ok),e(ok,JHe),e(vs,YHe),e(vs,rk),e(rk,KHe),e(vs,ZHe),e(E,eUe),e(E,Ts),e(Ts,EJ),e(EJ,oUe),e(Ts,rUe),e(Ts,tk),e(tk,tUe),e(Ts,aUe),e(Ts,ak),e(ak,nUe),e(Ts,sUe),e(E,lUe),e(E,Fs),e(Fs,yJ),e(yJ,iUe),e(Fs,dUe),e(Fs,nk),e(nk,cUe),e(Fs,fUe),e(Fs,sk),e(sk,mUe),e(Fs,gUe),e(E,hUe),e(E,Cs),e(Cs,wJ),e(wJ,pUe),e(Cs,_Ue),e(Cs,lk),e(lk,uUe),e(Cs,bUe),e(Cs,ik),e(ik,vUe),e(Cs,TUe),e(E,FUe),e(E,Zg),e(Zg,AJ),e(AJ,CUe),e(Zg,MUe),e(Zg,dk),e(dk,EUe),e(Zg,yUe),e(E,wUe),e(E,Ms),e(Ms,LJ),e(LJ,AUe),e(Ms,LUe),e(Ms,ck),e(ck,BUe),e(Ms,xUe),e(Ms,fk),e(fk,kUe),e(Ms,RUe),e(E,SUe),e(E,eh),e(eh,BJ),e(BJ,PUe),e(eh,$Ue),e(eh,mk),e(mk,IUe),e(eh,jUe),e(E,DUe),e(E,oh),e(oh,xJ),e(xJ,NUe),e(oh,qUe),e(oh,gk),e(gk,OUe),e(oh,GUe),e(E,XUe),e(E,Es),e(Es,kJ),e(kJ,VUe),e(Es,zUe),e(Es,hk),e(hk,WUe),e(Es,QUe),e(Es,pk),e(pk,HUe),e(Es,UUe),e(E,JUe),e(E,ys),e(ys,RJ),e(RJ,YUe),e(ys,KUe),e(ys,_k),e(_k,ZUe),e(ys,eJe),e(ys,uk),e(uk,oJe),e(ys,rJe),e(E,tJe),e(E,rh),e(rh,SJ),e(SJ,aJe),e(rh,nJe),e(rh,bk),e(bk,sJe),e(rh,lJe),e(E,iJe),e(E,ws),e(ws,PJ),e(PJ,dJe),e(ws,cJe),e(ws,vk),e(vk,fJe),e(ws,mJe),e(ws,Tk),e(Tk,gJe),e(ws,hJe),e(E,pJe),e(E,As),e(As,$J),e($J,_Je),e(As,uJe),e(As,Fk),e(Fk,bJe),e(As,vJe),e(As,Ck),e(Ck,TJe),e(As,FJe),e(E,CJe),e(E,Ls),e(Ls,IJ),e(IJ,MJe),e(Ls,EJe),e(Ls,Mk),e(Mk,yJe),e(Ls,wJe),e(Ls,Ek),e(Ek,AJe),e(Ls,LJe),e(E,BJe),e(E,Bs),e(Bs,jJ),e(jJ,xJe),e(Bs,kJe),e(Bs,yk),e(yk,RJe),e(Bs,SJe),e(Bs,wk),e(wk,PJe),e(Bs,$Je),e(E,IJe),e(E,xs),e(xs,DJ),e(DJ,jJe),e(xs,DJe),e(xs,Ak),e(Ak,NJe),e(xs,qJe),e(xs,Lk),e(Lk,OJe),e(xs,GJe),e(E,XJe),e(E,th),e(th,NJ),e(NJ,VJe),e(th,zJe),e(th,Bk),e(Bk,WJe),e(th,QJe),e(E,HJe),e(E,ah),e(ah,qJ),e(qJ,UJe),e(ah,JJe),e(ah,xk),e(xk,YJe),e(ah,KJe),e(E,ZJe),e(E,nh),e(nh,OJ),e(OJ,eYe),e(nh,oYe),e(nh,kk),e(kk,rYe),e(nh,tYe),e(E,aYe),e(E,sh),e(sh,GJ),e(GJ,nYe),e(sh,sYe),e(sh,Rk),e(Rk,lYe),e(sh,iYe),e(E,dYe),e(E,ks),e(ks,XJ),e(XJ,cYe),e(ks,fYe),e(ks,Sk),e(Sk,mYe),e(ks,gYe),e(ks,Pk),e(Pk,hYe),e(ks,pYe),e(E,_Ye),e(E,lh),e(lh,VJ),e(VJ,uYe),e(lh,bYe),e(lh,$k),e($k,vYe),e(lh,TYe),e(E,FYe),e(E,Rs),e(Rs,zJ),e(zJ,CYe),e(Rs,MYe),e(Rs,Ik),e(Ik,EYe),e(Rs,yYe),e(Rs,jk),e(jk,wYe),e(Rs,AYe),e(E,LYe),e(E,Ss),e(Ss,WJ),e(WJ,BYe),e(Ss,xYe),e(Ss,Dk),e(Dk,kYe),e(Ss,RYe),e(Ss,Nk),e(Nk,SYe),e(Ss,PYe),e(E,$Ye),e(E,Ps),e(Ps,QJ),e(QJ,IYe),e(Ps,jYe),e(Ps,qk),e(qk,DYe),e(Ps,NYe),e(Ps,Ok),e(Ok,qYe),e(Ps,OYe),e(E,GYe),e(E,$s),e($s,HJ),e(HJ,XYe),e($s,VYe),e($s,Gk),e(Gk,zYe),e($s,WYe),e($s,Xk),e(Xk,QYe),e($s,HYe),e(E,UYe),e(E,Is),e(Is,UJ),e(UJ,JYe),e(Is,YYe),e(Is,Vk),e(Vk,KYe),e(Is,ZYe),e(Is,zk),e(zk,eKe),e(Is,oKe),e(E,rKe),e(E,js),e(js,JJ),e(JJ,tKe),e(js,aKe),e(js,Wk),e(Wk,nKe),e(js,sKe),e(js,Qk),e(Qk,lKe),e(js,iKe),e(E,dKe),e(E,ih),e(ih,YJ),e(YJ,cKe),e(ih,fKe),e(ih,Hk),e(Hk,mKe),e(ih,gKe),e(E,hKe),e(E,dh),e(dh,KJ),e(KJ,pKe),e(dh,_Ke),e(dh,Uk),e(Uk,uKe),e(dh,bKe),e(E,vKe),e(E,Ds),e(Ds,ZJ),e(ZJ,TKe),e(Ds,FKe),e(Ds,Jk),e(Jk,CKe),e(Ds,MKe),e(Ds,Yk),e(Yk,EKe),e(Ds,yKe),e(E,wKe),e(E,Ns),e(Ns,eY),e(eY,AKe),e(Ns,LKe),e(Ns,Kk),e(Kk,BKe),e(Ns,xKe),e(Ns,Zk),e(Zk,kKe),e(Ns,RKe),e(E,SKe),e(E,qs),e(qs,oY),e(oY,PKe),e(qs,$Ke),e(qs,eR),e(eR,IKe),e(qs,jKe),e(qs,oR),e(oR,DKe),e(qs,NKe),e(E,qKe),e(E,ch),e(ch,rY),e(rY,OKe),e(ch,GKe),e(ch,rR),e(rR,XKe),e(ch,VKe),e(E,zKe),e(E,fh),e(fh,tY),e(tY,WKe),e(fh,QKe),e(fh,tR),e(tR,HKe),e(fh,UKe),e(E,JKe),e(E,mh),e(mh,aY),e(aY,YKe),e(mh,KKe),e(mh,aR),e(aR,ZKe),e(mh,eZe),e(E,oZe),e(E,gh),e(gh,nY),e(nY,rZe),e(gh,tZe),e(gh,nR),e(nR,aZe),e(gh,nZe),e(E,sZe),e(E,Os),e(Os,sY),e(sY,lZe),e(Os,iZe),e(Os,sR),e(sR,dZe),e(Os,cZe),e(Os,lR),e(lR,fZe),e(Os,mZe),e(E,gZe),e(E,hh),e(hh,lY),e(lY,hZe),e(hh,pZe),e(hh,iR),e(iR,_Ze),e(hh,uZe),e(E,bZe),e(E,ph),e(ph,iY),e(iY,vZe),e(ph,TZe),e(ph,dR),e(dR,FZe),e(ph,CZe),e(E,MZe),e(E,Gs),e(Gs,dY),e(dY,EZe),e(Gs,yZe),e(Gs,cR),e(cR,wZe),e(Gs,AZe),e(Gs,fR),e(fR,LZe),e(Gs,BZe),e(E,xZe),e(E,Xs),e(Xs,cY),e(cY,kZe),e(Xs,RZe),e(Xs,mR),e(mR,SZe),e(Xs,PZe),e(Xs,gR),e(gR,$Ze),e(Xs,IZe),e(go,jZe),e(go,fY),e(fY,DZe),e(go,NZe),g(E4,go,null),e(Ho,qZe),e(Ho,_h),g(y4,_h,null),e(_h,OZe),e(_h,mY),e(mY,GZe),b(d,oke,u),b(d,od,u),e(od,uh),e(uh,gY),g(w4,gY,null),e(od,XZe),e(od,hY),e(hY,VZe),b(d,rke,u),b(d,Uo,u),g(A4,Uo,null),e(Uo,zZe),e(Uo,L4),e(L4,WZe),e(L4,hR),e(hR,QZe),e(L4,HZe),e(Uo,UZe),e(Uo,B4),e(B4,JZe),e(B4,pY),e(pY,YZe),e(B4,KZe),e(Uo,ZZe),e(Uo,$e),g(x4,$e,null),e($e,eeo),e($e,_Y),e(_Y,oeo),e($e,reo),e($e,Qa),e(Qa,teo),e(Qa,uY),e(uY,aeo),e(Qa,neo),e(Qa,bY),e(bY,seo),e(Qa,leo),e(Qa,vY),e(vY,ieo),e(Qa,deo),e($e,ceo),e($e,ae),e(ae,bh),e(bh,TY),e(TY,feo),e(bh,meo),e(bh,pR),e(pR,geo),e(bh,heo),e(ae,peo),e(ae,vh),e(vh,FY),e(FY,_eo),e(vh,ueo),e(vh,_R),e(_R,beo),e(vh,veo),e(ae,Teo),e(ae,Th),e(Th,CY),e(CY,Feo),e(Th,Ceo),e(Th,uR),e(uR,Meo),e(Th,Eeo),e(ae,yeo),e(ae,Fh),e(Fh,MY),e(MY,weo),e(Fh,Aeo),e(Fh,bR),e(bR,Leo),e(Fh,Beo),e(ae,xeo),e(ae,Ch),e(Ch,EY),e(EY,keo),e(Ch,Reo),e(Ch,vR),e(vR,Seo),e(Ch,Peo),e(ae,$eo),e(ae,Mh),e(Mh,yY),e(yY,Ieo),e(Mh,jeo),e(Mh,TR),e(TR,Deo),e(Mh,Neo),e(ae,qeo),e(ae,Eh),e(Eh,wY),e(wY,Oeo),e(Eh,Geo),e(Eh,FR),e(FR,Xeo),e(Eh,Veo),e(ae,zeo),e(ae,yh),e(yh,AY),e(AY,Weo),e(yh,Qeo),e(yh,CR),e(CR,Heo),e(yh,Ueo),e(ae,Jeo),e(ae,wh),e(wh,LY),e(LY,Yeo),e(wh,Keo),e(wh,MR),e(MR,Zeo),e(wh,eoo),e(ae,ooo),e(ae,Ah),e(Ah,BY),e(BY,roo),e(Ah,too),e(Ah,ER),e(ER,aoo),e(Ah,noo),e(ae,soo),e(ae,Lh),e(Lh,xY),e(xY,loo),e(Lh,ioo),e(Lh,yR),e(yR,doo),e(Lh,coo),e(ae,foo),e(ae,Bh),e(Bh,kY),e(kY,moo),e(Bh,goo),e(Bh,wR),e(wR,hoo),e(Bh,poo),e(ae,_oo),e(ae,xh),e(xh,RY),e(RY,uoo),e(xh,boo),e(xh,AR),e(AR,voo),e(xh,Too),e(ae,Foo),e(ae,kh),e(kh,SY),e(SY,Coo),e(kh,Moo),e(kh,LR),e(LR,Eoo),e(kh,yoo),e(ae,woo),e(ae,Rh),e(Rh,PY),e(PY,Aoo),e(Rh,Loo),e(Rh,BR),e(BR,Boo),e(Rh,xoo),e(ae,koo),e(ae,Sh),e(Sh,$Y),e($Y,Roo),e(Sh,Soo),e(Sh,xR),e(xR,Poo),e(Sh,$oo),e($e,Ioo),g(Ph,$e,null),e($e,joo),e($e,IY),e(IY,Doo),e($e,Noo),g(k4,$e,null),e(Uo,qoo),e(Uo,$h),g(R4,$h,null),e($h,Ooo),e($h,jY),e(jY,Goo),b(d,tke,u),b(d,rd,u),e(rd,Ih),e(Ih,DY),g(S4,DY,null),e(rd,Xoo),e(rd,NY),e(NY,Voo),b(d,ake,u),b(d,Jo,u),g(P4,Jo,null),e(Jo,zoo),e(Jo,$4),e($4,Woo),e($4,kR),e(kR,Qoo),e($4,Hoo),e(Jo,Uoo),e(Jo,I4),e(I4,Joo),e(I4,qY),e(qY,Yoo),e(I4,Koo),e(Jo,Zoo),e(Jo,Ie),g(j4,Ie,null),e(Ie,ero),e(Ie,OY),e(OY,oro),e(Ie,rro),e(Ie,td),e(td,tro),e(td,GY),e(GY,aro),e(td,nro),e(td,XY),e(XY,sro),e(td,lro),e(Ie,iro),e(Ie,Be),e(Be,jh),e(jh,VY),e(VY,dro),e(jh,cro),e(jh,RR),e(RR,fro),e(jh,mro),e(Be,gro),e(Be,Dh),e(Dh,zY),e(zY,hro),e(Dh,pro),e(Dh,SR),e(SR,_ro),e(Dh,uro),e(Be,bro),e(Be,Nh),e(Nh,WY),e(WY,vro),e(Nh,Tro),e(Nh,PR),e(PR,Fro),e(Nh,Cro),e(Be,Mro),e(Be,qh),e(qh,QY),e(QY,Ero),e(qh,yro),e(qh,$R),e($R,wro),e(qh,Aro),e(Be,Lro),e(Be,Oh),e(Oh,HY),e(HY,Bro),e(Oh,xro),e(Oh,IR),e(IR,kro),e(Oh,Rro),e(Be,Sro),e(Be,Gh),e(Gh,UY),e(UY,Pro),e(Gh,$ro),e(Gh,jR),e(jR,Iro),e(Gh,jro),e(Be,Dro),e(Be,Xh),e(Xh,JY),e(JY,Nro),e(Xh,qro),e(Xh,DR),e(DR,Oro),e(Xh,Gro),e(Be,Xro),e(Be,Vh),e(Vh,YY),e(YY,Vro),e(Vh,zro),e(Vh,NR),e(NR,Wro),e(Vh,Qro),e(Ie,Hro),g(zh,Ie,null),e(Ie,Uro),e(Ie,KY),e(KY,Jro),e(Ie,Yro),g(D4,Ie,null),e(Jo,Kro),e(Jo,Wh),g(N4,Wh,null),e(Wh,Zro),e(Wh,ZY),e(ZY,eto),b(d,nke,u),b(d,ad,u),e(ad,Qh),e(Qh,eK),g(q4,eK,null),e(ad,oto),e(ad,oK),e(oK,rto),b(d,ske,u),b(d,Yo,u),g(O4,Yo,null),e(Yo,tto),e(Yo,nd),e(nd,ato),e(nd,rK),e(rK,nto),e(nd,sto),e(nd,tK),e(tK,lto),e(nd,ito),e(Yo,dto),e(Yo,G4),e(G4,cto),e(G4,aK),e(aK,fto),e(G4,mto),e(Yo,gto),e(Yo,Wr),g(X4,Wr,null),e(Wr,hto),e(Wr,nK),e(nK,pto),e(Wr,_to),e(Wr,sd),e(sd,uto),e(sd,sK),e(sK,bto),e(sd,vto),e(sd,lK),e(lK,Tto),e(sd,Fto),e(Wr,Cto),e(Wr,iK),e(iK,Mto),e(Wr,Eto),g(V4,Wr,null),e(Yo,yto),e(Yo,je),g(z4,je,null),e(je,wto),e(je,dK),e(dK,Ato),e(je,Lto),e(je,Ha),e(Ha,Bto),e(Ha,cK),e(cK,xto),e(Ha,kto),e(Ha,fK),e(fK,Rto),e(Ha,Sto),e(Ha,mK),e(mK,Pto),e(Ha,$to),e(je,Ito),e(je,F),e(F,Hh),e(Hh,gK),e(gK,jto),e(Hh,Dto),e(Hh,qR),e(qR,Nto),e(Hh,qto),e(F,Oto),e(F,Uh),e(Uh,hK),e(hK,Gto),e(Uh,Xto),e(Uh,OR),e(OR,Vto),e(Uh,zto),e(F,Wto),e(F,Jh),e(Jh,pK),e(pK,Qto),e(Jh,Hto),e(Jh,GR),e(GR,Uto),e(Jh,Jto),e(F,Yto),e(F,Yh),e(Yh,_K),e(_K,Kto),e(Yh,Zto),e(Yh,XR),e(XR,eao),e(Yh,oao),e(F,rao),e(F,Kh),e(Kh,uK),e(uK,tao),e(Kh,aao),e(Kh,VR),e(VR,nao),e(Kh,sao),e(F,lao),e(F,Zh),e(Zh,bK),e(bK,iao),e(Zh,dao),e(Zh,zR),e(zR,cao),e(Zh,fao),e(F,mao),e(F,ep),e(ep,vK),e(vK,gao),e(ep,hao),e(ep,WR),e(WR,pao),e(ep,_ao),e(F,uao),e(F,op),e(op,TK),e(TK,bao),e(op,vao),e(op,QR),e(QR,Tao),e(op,Fao),e(F,Cao),e(F,rp),e(rp,FK),e(FK,Mao),e(rp,Eao),e(rp,HR),e(HR,yao),e(rp,wao),e(F,Aao),e(F,tp),e(tp,CK),e(CK,Lao),e(tp,Bao),e(tp,UR),e(UR,xao),e(tp,kao),e(F,Rao),e(F,ap),e(ap,MK),e(MK,Sao),e(ap,Pao),e(ap,JR),e(JR,$ao),e(ap,Iao),e(F,jao),e(F,np),e(np,EK),e(EK,Dao),e(np,Nao),e(np,YR),e(YR,qao),e(np,Oao),e(F,Gao),e(F,sp),e(sp,yK),e(yK,Xao),e(sp,Vao),e(sp,KR),e(KR,zao),e(sp,Wao),e(F,Qao),e(F,lp),e(lp,wK),e(wK,Hao),e(lp,Uao),e(lp,ZR),e(ZR,Jao),e(lp,Yao),e(F,Kao),e(F,ip),e(ip,AK),e(AK,Zao),e(ip,eno),e(ip,eS),e(eS,ono),e(ip,rno),e(F,tno),e(F,dp),e(dp,LK),e(LK,ano),e(dp,nno),e(dp,oS),e(oS,sno),e(dp,lno),e(F,ino),e(F,cp),e(cp,BK),e(BK,dno),e(cp,cno),e(cp,rS),e(rS,fno),e(cp,mno),e(F,gno),e(F,fp),e(fp,xK),e(xK,hno),e(fp,pno),e(fp,tS),e(tS,_no),e(fp,uno),e(F,bno),e(F,mp),e(mp,kK),e(kK,vno),e(mp,Tno),e(mp,aS),e(aS,Fno),e(mp,Cno),e(F,Mno),e(F,gp),e(gp,RK),e(RK,Eno),e(gp,yno),e(gp,nS),e(nS,wno),e(gp,Ano),e(F,Lno),e(F,hp),e(hp,SK),e(SK,Bno),e(hp,xno),e(hp,sS),e(sS,kno),e(hp,Rno),e(F,Sno),e(F,pp),e(pp,PK),e(PK,Pno),e(pp,$no),e(pp,lS),e(lS,Ino),e(pp,jno),e(F,Dno),e(F,_p),e(_p,$K),e($K,Nno),e(_p,qno),e(_p,iS),e(iS,Ono),e(_p,Gno),e(F,Xno),e(F,up),e(up,IK),e(IK,Vno),e(up,zno),e(up,dS),e(dS,Wno),e(up,Qno),e(F,Hno),e(F,bp),e(bp,jK),e(jK,Uno),e(bp,Jno),e(bp,cS),e(cS,Yno),e(bp,Kno),e(F,Zno),e(F,vp),e(vp,DK),e(DK,eso),e(vp,oso),e(vp,fS),e(fS,rso),e(vp,tso),e(F,aso),e(F,Tp),e(Tp,NK),e(NK,nso),e(Tp,sso),e(Tp,mS),e(mS,lso),e(Tp,iso),e(F,dso),e(F,Vs),e(Vs,qK),e(qK,cso),e(Vs,fso),e(Vs,gS),e(gS,mso),e(Vs,gso),e(Vs,hS),e(hS,hso),e(Vs,pso),e(F,_so),e(F,Fp),e(Fp,OK),e(OK,uso),e(Fp,bso),e(Fp,pS),e(pS,vso),e(Fp,Tso),e(F,Fso),e(F,Cp),e(Cp,GK),e(GK,Cso),e(Cp,Mso),e(Cp,_S),e(_S,Eso),e(Cp,yso),e(F,wso),e(F,Mp),e(Mp,XK),e(XK,Aso),e(Mp,Lso),e(Mp,uS),e(uS,Bso),e(Mp,xso),e(F,kso),e(F,Ep),e(Ep,VK),e(VK,Rso),e(Ep,Sso),e(Ep,bS),e(bS,Pso),e(Ep,$so),e(F,Iso),e(F,yp),e(yp,zK),e(zK,jso),e(yp,Dso),e(yp,vS),e(vS,Nso),e(yp,qso),e(F,Oso),e(F,wp),e(wp,WK),e(WK,Gso),e(wp,Xso),e(wp,TS),e(TS,Vso),e(wp,zso),e(F,Wso),e(F,Ap),e(Ap,QK),e(QK,Qso),e(Ap,Hso),e(Ap,FS),e(FS,Uso),e(Ap,Jso),e(F,Yso),e(F,Lp),e(Lp,HK),e(HK,Kso),e(Lp,Zso),e(Lp,CS),e(CS,elo),e(Lp,olo),e(F,rlo),e(F,Bp),e(Bp,UK),e(UK,tlo),e(Bp,alo),e(Bp,MS),e(MS,nlo),e(Bp,slo),e(F,llo),e(F,xp),e(xp,JK),e(JK,ilo),e(xp,dlo),e(xp,ES),e(ES,clo),e(xp,flo),e(F,mlo),e(F,kp),e(kp,YK),e(YK,glo),e(kp,hlo),e(kp,yS),e(yS,plo),e(kp,_lo),e(F,ulo),e(F,Rp),e(Rp,KK),e(KK,blo),e(Rp,vlo),e(Rp,wS),e(wS,Tlo),e(Rp,Flo),e(F,Clo),e(F,Sp),e(Sp,ZK),e(ZK,Mlo),e(Sp,Elo),e(Sp,AS),e(AS,ylo),e(Sp,wlo),e(F,Alo),e(F,Pp),e(Pp,eZ),e(eZ,Llo),e(Pp,Blo),e(Pp,LS),e(LS,xlo),e(Pp,klo),e(F,Rlo),e(F,$p),e($p,oZ),e(oZ,Slo),e($p,Plo),e($p,BS),e(BS,$lo),e($p,Ilo),e(F,jlo),e(F,Ip),e(Ip,rZ),e(rZ,Dlo),e(Ip,Nlo),e(Ip,xS),e(xS,qlo),e(Ip,Olo),e(F,Glo),e(F,jp),e(jp,tZ),e(tZ,Xlo),e(jp,Vlo),e(jp,kS),e(kS,zlo),e(jp,Wlo),e(F,Qlo),e(F,Dp),e(Dp,aZ),e(aZ,Hlo),e(Dp,Ulo),e(Dp,RS),e(RS,Jlo),e(Dp,Ylo),e(F,Klo),e(F,Np),e(Np,nZ),e(nZ,Zlo),e(Np,eio),e(Np,SS),e(SS,oio),e(Np,rio),e(F,tio),e(F,qp),e(qp,sZ),e(sZ,aio),e(qp,nio),e(qp,PS),e(PS,sio),e(qp,lio),e(F,iio),e(F,Op),e(Op,lZ),e(lZ,dio),e(Op,cio),e(Op,$S),e($S,fio),e(Op,mio),e(F,gio),e(F,Gp),e(Gp,iZ),e(iZ,hio),e(Gp,pio),e(Gp,IS),e(IS,_io),e(Gp,uio),e(F,bio),e(F,Xp),e(Xp,dZ),e(dZ,vio),e(Xp,Tio),e(Xp,jS),e(jS,Fio),e(Xp,Cio),e(F,Mio),e(F,Vp),e(Vp,cZ),e(cZ,Eio),e(Vp,yio),e(Vp,DS),e(DS,wio),e(Vp,Aio),e(F,Lio),e(F,zp),e(zp,fZ),e(fZ,Bio),e(zp,xio),e(zp,NS),e(NS,kio),e(zp,Rio),e(F,Sio),e(F,Wp),e(Wp,mZ),e(mZ,Pio),e(Wp,$io),e(Wp,qS),e(qS,Iio),e(Wp,jio),e(F,Dio),e(F,Qp),e(Qp,gZ),e(gZ,Nio),e(Qp,qio),e(Qp,OS),e(OS,Oio),e(Qp,Gio),e(F,Xio),e(F,Hp),e(Hp,hZ),e(hZ,Vio),e(Hp,zio),e(Hp,GS),e(GS,Wio),e(Hp,Qio),e(F,Hio),e(F,Up),e(Up,pZ),e(pZ,Uio),e(Up,Jio),e(Up,XS),e(XS,Yio),e(Up,Kio),e(F,Zio),e(F,Jp),e(Jp,_Z),e(_Z,edo),e(Jp,odo),e(Jp,VS),e(VS,rdo),e(Jp,tdo),e(F,ado),e(F,Yp),e(Yp,uZ),e(uZ,ndo),e(Yp,sdo),e(Yp,zS),e(zS,ldo),e(Yp,ido),e(F,ddo),e(F,Kp),e(Kp,bZ),e(bZ,cdo),e(Kp,fdo),e(Kp,WS),e(WS,mdo),e(Kp,gdo),e(F,hdo),e(F,Zp),e(Zp,vZ),e(vZ,pdo),e(Zp,_do),e(Zp,QS),e(QS,udo),e(Zp,bdo),e(F,vdo),e(F,e_),e(e_,TZ),e(TZ,Tdo),e(e_,Fdo),e(e_,HS),e(HS,Cdo),e(e_,Mdo),e(F,Edo),e(F,o_),e(o_,FZ),e(FZ,ydo),e(o_,wdo),e(o_,US),e(US,Ado),e(o_,Ldo),e(F,Bdo),e(F,r_),e(r_,CZ),e(CZ,xdo),e(r_,kdo),e(r_,JS),e(JS,Rdo),e(r_,Sdo),e(F,Pdo),e(F,t_),e(t_,MZ),e(MZ,$do),e(t_,Ido),e(t_,YS),e(YS,jdo),e(t_,Ddo),e(F,Ndo),e(F,a_),e(a_,EZ),e(EZ,qdo),e(a_,Odo),e(a_,KS),e(KS,Gdo),e(a_,Xdo),e(F,Vdo),e(F,n_),e(n_,yZ),e(yZ,zdo),e(n_,Wdo),e(n_,ZS),e(ZS,Qdo),e(n_,Hdo),e(F,Udo),e(F,s_),e(s_,wZ),e(wZ,Jdo),e(s_,Ydo),e(s_,eP),e(eP,Kdo),e(s_,Zdo),e(F,eco),e(F,l_),e(l_,AZ),e(AZ,oco),e(l_,rco),e(l_,oP),e(oP,tco),e(l_,aco),e(F,nco),e(F,i_),e(i_,LZ),e(LZ,sco),e(i_,lco),e(i_,rP),e(rP,ico),e(i_,dco),e(F,cco),e(F,d_),e(d_,BZ),e(BZ,fco),e(d_,mco),e(d_,tP),e(tP,gco),e(d_,hco),e(F,pco),e(F,c_),e(c_,xZ),e(xZ,_co),e(c_,uco),e(c_,aP),e(aP,bco),e(c_,vco),e(F,Tco),e(F,f_),e(f_,kZ),e(kZ,Fco),e(f_,Cco),e(f_,nP),e(nP,Mco),e(f_,Eco),e(F,yco),e(F,m_),e(m_,RZ),e(RZ,wco),e(m_,Aco),e(m_,sP),e(sP,Lco),e(m_,Bco),e(F,xco),e(F,g_),e(g_,SZ),e(SZ,kco),e(g_,Rco),e(g_,lP),e(lP,Sco),e(g_,Pco),e(F,$co),e(F,h_),e(h_,PZ),e(PZ,Ico),e(h_,jco),e(h_,iP),e(iP,Dco),e(h_,Nco),e(F,qco),e(F,p_),e(p_,$Z),e($Z,Oco),e(p_,Gco),e(p_,dP),e(dP,Xco),e(p_,Vco),e(F,zco),e(F,__),e(__,IZ),e(IZ,Wco),e(__,Qco),e(__,cP),e(cP,Hco),e(__,Uco),e(F,Jco),e(F,u_),e(u_,jZ),e(jZ,Yco),e(u_,Kco),e(u_,fP),e(fP,Zco),e(u_,efo),e(F,ofo),e(F,b_),e(b_,DZ),e(DZ,rfo),e(b_,tfo),e(b_,mP),e(mP,afo),e(b_,nfo),e(F,sfo),e(F,v_),e(v_,NZ),e(NZ,lfo),e(v_,ifo),e(v_,gP),e(gP,dfo),e(v_,cfo),e(F,ffo),e(F,T_),e(T_,qZ),e(qZ,mfo),e(T_,gfo),e(T_,hP),e(hP,hfo),e(T_,pfo),e(F,_fo),e(F,F_),e(F_,OZ),e(OZ,ufo),e(F_,bfo),e(F_,pP),e(pP,vfo),e(F_,Tfo),e(F,Ffo),e(F,C_),e(C_,GZ),e(GZ,Cfo),e(C_,Mfo),e(C_,_P),e(_P,Efo),e(C_,yfo),e(F,wfo),e(F,M_),e(M_,XZ),e(XZ,Afo),e(M_,Lfo),e(M_,uP),e(uP,Bfo),e(M_,xfo),e(F,kfo),e(F,E_),e(E_,VZ),e(VZ,Rfo),e(E_,Sfo),e(E_,bP),e(bP,Pfo),e(E_,$fo),e(F,Ifo),e(F,y_),e(y_,zZ),e(zZ,jfo),e(y_,Dfo),e(y_,vP),e(vP,Nfo),e(y_,qfo),e(je,Ofo),e(je,w_),e(w_,Gfo),e(w_,WZ),e(WZ,Xfo),e(w_,Vfo),e(w_,QZ),e(QZ,zfo),e(je,Wfo),e(je,HZ),e(HZ,Qfo),e(je,Hfo),g(W4,je,null),b(d,lke,u),b(d,ld,u),e(ld,A_),e(A_,UZ),g(Q4,UZ,null),e(ld,Ufo),e(ld,JZ),e(JZ,Jfo),b(d,ike,u),b(d,Ko,u),g(H4,Ko,null),e(Ko,Yfo),e(Ko,id),e(id,Kfo),e(id,YZ),e(YZ,Zfo),e(id,emo),e(id,KZ),e(KZ,omo),e(id,rmo),e(Ko,tmo),e(Ko,U4),e(U4,amo),e(U4,ZZ),e(ZZ,nmo),e(U4,smo),e(Ko,lmo),e(Ko,Qr),g(J4,Qr,null),e(Qr,imo),e(Qr,eee),e(eee,dmo),e(Qr,cmo),e(Qr,dd),e(dd,fmo),e(dd,oee),e(oee,mmo),e(dd,gmo),e(dd,ree),e(ree,hmo),e(dd,pmo),e(Qr,_mo),e(Qr,tee),e(tee,umo),e(Qr,bmo),g(Y4,Qr,null),e(Ko,vmo),e(Ko,De),g(K4,De,null),e(De,Tmo),e(De,aee),e(aee,Fmo),e(De,Cmo),e(De,Ua),e(Ua,Mmo),e(Ua,nee),e(nee,Emo),e(Ua,ymo),e(Ua,see),e(see,wmo),e(Ua,Amo),e(Ua,lee),e(lee,Lmo),e(Ua,Bmo),e(De,xmo),e(De,k),e(k,L_),e(L_,iee),e(iee,kmo),e(L_,Rmo),e(L_,TP),e(TP,Smo),e(L_,Pmo),e(k,$mo),e(k,B_),e(B_,dee),e(dee,Imo),e(B_,jmo),e(B_,FP),e(FP,Dmo),e(B_,Nmo),e(k,qmo),e(k,x_),e(x_,cee),e(cee,Omo),e(x_,Gmo),e(x_,CP),e(CP,Xmo),e(x_,Vmo),e(k,zmo),e(k,k_),e(k_,fee),e(fee,Wmo),e(k_,Qmo),e(k_,MP),e(MP,Hmo),e(k_,Umo),e(k,Jmo),e(k,R_),e(R_,mee),e(mee,Ymo),e(R_,Kmo),e(R_,EP),e(EP,Zmo),e(R_,ego),e(k,ogo),e(k,S_),e(S_,gee),e(gee,rgo),e(S_,tgo),e(S_,yP),e(yP,ago),e(S_,ngo),e(k,sgo),e(k,P_),e(P_,hee),e(hee,lgo),e(P_,igo),e(P_,wP),e(wP,dgo),e(P_,cgo),e(k,fgo),e(k,$_),e($_,pee),e(pee,mgo),e($_,ggo),e($_,AP),e(AP,hgo),e($_,pgo),e(k,_go),e(k,I_),e(I_,_ee),e(_ee,ugo),e(I_,bgo),e(I_,LP),e(LP,vgo),e(I_,Tgo),e(k,Fgo),e(k,j_),e(j_,uee),e(uee,Cgo),e(j_,Mgo),e(j_,BP),e(BP,Ego),e(j_,ygo),e(k,wgo),e(k,D_),e(D_,bee),e(bee,Ago),e(D_,Lgo),e(D_,xP),e(xP,Bgo),e(D_,xgo),e(k,kgo),e(k,N_),e(N_,vee),e(vee,Rgo),e(N_,Sgo),e(N_,kP),e(kP,Pgo),e(N_,$go),e(k,Igo),e(k,q_),e(q_,Tee),e(Tee,jgo),e(q_,Dgo),e(q_,RP),e(RP,Ngo),e(q_,qgo),e(k,Ogo),e(k,O_),e(O_,Fee),e(Fee,Ggo),e(O_,Xgo),e(O_,SP),e(SP,Vgo),e(O_,zgo),e(k,Wgo),e(k,G_),e(G_,Cee),e(Cee,Qgo),e(G_,Hgo),e(G_,PP),e(PP,Ugo),e(G_,Jgo),e(k,Ygo),e(k,X_),e(X_,Mee),e(Mee,Kgo),e(X_,Zgo),e(X_,$P),e($P,eho),e(X_,oho),e(k,rho),e(k,V_),e(V_,Eee),e(Eee,tho),e(V_,aho),e(V_,IP),e(IP,nho),e(V_,sho),e(k,lho),e(k,z_),e(z_,yee),e(yee,iho),e(z_,dho),e(z_,jP),e(jP,cho),e(z_,fho),e(k,mho),e(k,W_),e(W_,wee),e(wee,gho),e(W_,hho),e(W_,DP),e(DP,pho),e(W_,_ho),e(k,uho),e(k,Q_),e(Q_,Aee),e(Aee,bho),e(Q_,vho),e(Q_,NP),e(NP,Tho),e(Q_,Fho),e(k,Cho),e(k,H_),e(H_,Lee),e(Lee,Mho),e(H_,Eho),e(H_,qP),e(qP,yho),e(H_,who),e(k,Aho),e(k,U_),e(U_,Bee),e(Bee,Lho),e(U_,Bho),e(U_,OP),e(OP,xho),e(U_,kho),e(k,Rho),e(k,J_),e(J_,xee),e(xee,Sho),e(J_,Pho),e(J_,GP),e(GP,$ho),e(J_,Iho),e(k,jho),e(k,Y_),e(Y_,kee),e(kee,Dho),e(Y_,Nho),e(Y_,XP),e(XP,qho),e(Y_,Oho),e(k,Gho),e(k,K_),e(K_,Ree),e(Ree,Xho),e(K_,Vho),e(K_,VP),e(VP,zho),e(K_,Who),e(k,Qho),e(k,Z_),e(Z_,See),e(See,Hho),e(Z_,Uho),e(Z_,zP),e(zP,Jho),e(Z_,Yho),e(k,Kho),e(k,eu),e(eu,Pee),e(Pee,Zho),e(eu,epo),e(eu,WP),e(WP,opo),e(eu,rpo),e(k,tpo),e(k,ou),e(ou,$ee),e($ee,apo),e(ou,npo),e(ou,QP),e(QP,spo),e(ou,lpo),e(k,ipo),e(k,ru),e(ru,Iee),e(Iee,dpo),e(ru,cpo),e(ru,HP),e(HP,fpo),e(ru,mpo),e(k,gpo),e(k,tu),e(tu,jee),e(jee,hpo),e(tu,ppo),e(tu,UP),e(UP,_po),e(tu,upo),e(k,bpo),e(k,au),e(au,Dee),e(Dee,vpo),e(au,Tpo),e(au,JP),e(JP,Fpo),e(au,Cpo),e(k,Mpo),e(k,nu),e(nu,Nee),e(Nee,Epo),e(nu,ypo),e(nu,YP),e(YP,wpo),e(nu,Apo),e(k,Lpo),e(k,su),e(su,qee),e(qee,Bpo),e(su,xpo),e(su,KP),e(KP,kpo),e(su,Rpo),e(k,Spo),e(k,lu),e(lu,Oee),e(Oee,Ppo),e(lu,$po),e(lu,ZP),e(ZP,Ipo),e(lu,jpo),e(k,Dpo),e(k,iu),e(iu,Gee),e(Gee,Npo),e(iu,qpo),e(iu,e$),e(e$,Opo),e(iu,Gpo),e(k,Xpo),e(k,du),e(du,Xee),e(Xee,Vpo),e(du,zpo),e(du,o$),e(o$,Wpo),e(du,Qpo),e(k,Hpo),e(k,cu),e(cu,Vee),e(Vee,Upo),e(cu,Jpo),e(cu,r$),e(r$,Ypo),e(cu,Kpo),e(k,Zpo),e(k,fu),e(fu,zee),e(zee,e_o),e(fu,o_o),e(fu,t$),e(t$,r_o),e(fu,t_o),e(k,a_o),e(k,mu),e(mu,Wee),e(Wee,n_o),e(mu,s_o),e(mu,a$),e(a$,l_o),e(mu,i_o),e(De,d_o),e(De,gu),e(gu,c_o),e(gu,Qee),e(Qee,f_o),e(gu,m_o),e(gu,Hee),e(Hee,g_o),e(De,h_o),e(De,Uee),e(Uee,p_o),e(De,__o),g(Z4,De,null),b(d,dke,u),b(d,cd,u),e(cd,hu),e(hu,Jee),g(eE,Jee,null),e(cd,u_o),e(cd,Yee),e(Yee,b_o),b(d,cke,u),b(d,Zo,u),g(oE,Zo,null),e(Zo,v_o),e(Zo,fd),e(fd,T_o),e(fd,Kee),e(Kee,F_o),e(fd,C_o),e(fd,Zee),e(Zee,M_o),e(fd,E_o),e(Zo,y_o),e(Zo,rE),e(rE,w_o),e(rE,eoe),e(eoe,A_o),e(rE,L_o),e(Zo,B_o),e(Zo,Hr),g(tE,Hr,null),e(Hr,x_o),e(Hr,ooe),e(ooe,k_o),e(Hr,R_o),e(Hr,md),e(md,S_o),e(md,roe),e(roe,P_o),e(md,$_o),e(md,toe),e(toe,I_o),e(md,j_o),e(Hr,D_o),e(Hr,aoe),e(aoe,N_o),e(Hr,q_o),g(aE,Hr,null),e(Zo,O_o),e(Zo,Ne),g(nE,Ne,null),e(Ne,G_o),e(Ne,noe),e(noe,X_o),e(Ne,V_o),e(Ne,Ja),e(Ja,z_o),e(Ja,soe),e(soe,W_o),e(Ja,Q_o),e(Ja,loe),e(loe,H_o),e(Ja,U_o),e(Ja,ioe),e(ioe,J_o),e(Ja,Y_o),e(Ne,K_o),e(Ne,$),e($,pu),e(pu,doe),e(doe,Z_o),e(pu,euo),e(pu,n$),e(n$,ouo),e(pu,ruo),e($,tuo),e($,_u),e(_u,coe),e(coe,auo),e(_u,nuo),e(_u,s$),e(s$,suo),e(_u,luo),e($,iuo),e($,uu),e(uu,foe),e(foe,duo),e(uu,cuo),e(uu,l$),e(l$,fuo),e(uu,muo),e($,guo),e($,bu),e(bu,moe),e(moe,huo),e(bu,puo),e(bu,i$),e(i$,_uo),e(bu,uuo),e($,buo),e($,vu),e(vu,goe),e(goe,vuo),e(vu,Tuo),e(vu,d$),e(d$,Fuo),e(vu,Cuo),e($,Muo),e($,Tu),e(Tu,hoe),e(hoe,Euo),e(Tu,yuo),e(Tu,c$),e(c$,wuo),e(Tu,Auo),e($,Luo),e($,Fu),e(Fu,poe),e(poe,Buo),e(Fu,xuo),e(Fu,f$),e(f$,kuo),e(Fu,Ruo),e($,Suo),e($,Cu),e(Cu,_oe),e(_oe,Puo),e(Cu,$uo),e(Cu,m$),e(m$,Iuo),e(Cu,juo),e($,Duo),e($,Mu),e(Mu,uoe),e(uoe,Nuo),e(Mu,quo),e(Mu,g$),e(g$,Ouo),e(Mu,Guo),e($,Xuo),e($,Eu),e(Eu,boe),e(boe,Vuo),e(Eu,zuo),e(Eu,h$),e(h$,Wuo),e(Eu,Quo),e($,Huo),e($,yu),e(yu,voe),e(voe,Uuo),e(yu,Juo),e(yu,p$),e(p$,Yuo),e(yu,Kuo),e($,Zuo),e($,wu),e(wu,Toe),e(Toe,e1o),e(wu,o1o),e(wu,_$),e(_$,r1o),e(wu,t1o),e($,a1o),e($,Au),e(Au,Foe),e(Foe,n1o),e(Au,s1o),e(Au,u$),e(u$,l1o),e(Au,i1o),e($,d1o),e($,Lu),e(Lu,Coe),e(Coe,c1o),e(Lu,f1o),e(Lu,b$),e(b$,m1o),e(Lu,g1o),e($,h1o),e($,Bu),e(Bu,Moe),e(Moe,p1o),e(Bu,_1o),e(Bu,v$),e(v$,u1o),e(Bu,b1o),e($,v1o),e($,xu),e(xu,Eoe),e(Eoe,T1o),e(xu,F1o),e(xu,T$),e(T$,C1o),e(xu,M1o),e($,E1o),e($,ku),e(ku,yoe),e(yoe,y1o),e(ku,w1o),e(ku,F$),e(F$,A1o),e(ku,L1o),e($,B1o),e($,Ru),e(Ru,woe),e(woe,x1o),e(Ru,k1o),e(Ru,C$),e(C$,R1o),e(Ru,S1o),e($,P1o),e($,Su),e(Su,Aoe),e(Aoe,$1o),e(Su,I1o),e(Su,M$),e(M$,j1o),e(Su,D1o),e($,N1o),e($,Pu),e(Pu,Loe),e(Loe,q1o),e(Pu,O1o),e(Pu,E$),e(E$,G1o),e(Pu,X1o),e($,V1o),e($,$u),e($u,Boe),e(Boe,z1o),e($u,W1o),e($u,y$),e(y$,Q1o),e($u,H1o),e($,U1o),e($,Iu),e(Iu,xoe),e(xoe,J1o),e(Iu,Y1o),e(Iu,w$),e(w$,K1o),e(Iu,Z1o),e($,ebo),e($,ju),e(ju,koe),e(koe,obo),e(ju,rbo),e(ju,A$),e(A$,tbo),e(ju,abo),e($,nbo),e($,Du),e(Du,Roe),e(Roe,sbo),e(Du,lbo),e(Du,L$),e(L$,ibo),e(Du,dbo),e($,cbo),e($,Nu),e(Nu,Soe),e(Soe,fbo),e(Nu,mbo),e(Nu,B$),e(B$,gbo),e(Nu,hbo),e($,pbo),e($,qu),e(qu,Poe),e(Poe,_bo),e(qu,ubo),e(qu,x$),e(x$,bbo),e(qu,vbo),e($,Tbo),e($,Ou),e(Ou,$oe),e($oe,Fbo),e(Ou,Cbo),e(Ou,k$),e(k$,Mbo),e(Ou,Ebo),e($,ybo),e($,Gu),e(Gu,Ioe),e(Ioe,wbo),e(Gu,Abo),e(Gu,R$),e(R$,Lbo),e(Gu,Bbo),e($,xbo),e($,Xu),e(Xu,joe),e(joe,kbo),e(Xu,Rbo),e(Xu,S$),e(S$,Sbo),e(Xu,Pbo),e($,$bo),e($,Vu),e(Vu,Doe),e(Doe,Ibo),e(Vu,jbo),e(Vu,P$),e(P$,Dbo),e(Vu,Nbo),e($,qbo),e($,zu),e(zu,Noe),e(Noe,Obo),e(zu,Gbo),e(zu,$$),e($$,Xbo),e(zu,Vbo),e($,zbo),e($,Wu),e(Wu,qoe),e(qoe,Wbo),e(Wu,Qbo),e(Wu,I$),e(I$,Hbo),e(Wu,Ubo),e($,Jbo),e($,Qu),e(Qu,Ooe),e(Ooe,Ybo),e(Qu,Kbo),e(Qu,j$),e(j$,Zbo),e(Qu,e5o),e($,o5o),e($,Hu),e(Hu,Goe),e(Goe,r5o),e(Hu,t5o),e(Hu,D$),e(D$,a5o),e(Hu,n5o),e($,s5o),e($,Uu),e(Uu,Xoe),e(Xoe,l5o),e(Uu,i5o),e(Uu,N$),e(N$,d5o),e(Uu,c5o),e(Ne,f5o),e(Ne,Ju),e(Ju,m5o),e(Ju,Voe),e(Voe,g5o),e(Ju,h5o),e(Ju,zoe),e(zoe,p5o),e(Ne,_5o),e(Ne,Woe),e(Woe,u5o),e(Ne,b5o),g(sE,Ne,null),b(d,fke,u),b(d,gd,u),e(gd,Yu),e(Yu,Qoe),g(lE,Qoe,null),e(gd,v5o),e(gd,Hoe),e(Hoe,T5o),b(d,mke,u),b(d,er,u),g(iE,er,null),e(er,F5o),e(er,hd),e(hd,C5o),e(hd,Uoe),e(Uoe,M5o),e(hd,E5o),e(hd,Joe),e(Joe,y5o),e(hd,w5o),e(er,A5o),e(er,dE),e(dE,L5o),e(dE,Yoe),e(Yoe,B5o),e(dE,x5o),e(er,k5o),e(er,Ur),g(cE,Ur,null),e(Ur,R5o),e(Ur,Koe),e(Koe,S5o),e(Ur,P5o),e(Ur,pd),e(pd,$5o),e(pd,Zoe),e(Zoe,I5o),e(pd,j5o),e(pd,ere),e(ere,D5o),e(pd,N5o),e(Ur,q5o),e(Ur,ore),e(ore,O5o),e(Ur,G5o),g(fE,Ur,null),e(er,X5o),e(er,qe),g(mE,qe,null),e(qe,V5o),e(qe,rre),e(rre,z5o),e(qe,W5o),e(qe,Ya),e(Ya,Q5o),e(Ya,tre),e(tre,H5o),e(Ya,U5o),e(Ya,are),e(are,J5o),e(Ya,Y5o),e(Ya,nre),e(nre,K5o),e(Ya,Z5o),e(qe,e2o),e(qe,I),e(I,Ku),e(Ku,sre),e(sre,o2o),e(Ku,r2o),e(Ku,q$),e(q$,t2o),e(Ku,a2o),e(I,n2o),e(I,Zu),e(Zu,lre),e(lre,s2o),e(Zu,l2o),e(Zu,O$),e(O$,i2o),e(Zu,d2o),e(I,c2o),e(I,e1),e(e1,ire),e(ire,f2o),e(e1,m2o),e(e1,G$),e(G$,g2o),e(e1,h2o),e(I,p2o),e(I,o1),e(o1,dre),e(dre,_2o),e(o1,u2o),e(o1,X$),e(X$,b2o),e(o1,v2o),e(I,T2o),e(I,r1),e(r1,cre),e(cre,F2o),e(r1,C2o),e(r1,V$),e(V$,M2o),e(r1,E2o),e(I,y2o),e(I,t1),e(t1,fre),e(fre,w2o),e(t1,A2o),e(t1,z$),e(z$,L2o),e(t1,B2o),e(I,x2o),e(I,a1),e(a1,mre),e(mre,k2o),e(a1,R2o),e(a1,W$),e(W$,S2o),e(a1,P2o),e(I,$2o),e(I,n1),e(n1,gre),e(gre,I2o),e(n1,j2o),e(n1,Q$),e(Q$,D2o),e(n1,N2o),e(I,q2o),e(I,s1),e(s1,hre),e(hre,O2o),e(s1,G2o),e(s1,H$),e(H$,X2o),e(s1,V2o),e(I,z2o),e(I,l1),e(l1,pre),e(pre,W2o),e(l1,Q2o),e(l1,U$),e(U$,H2o),e(l1,U2o),e(I,J2o),e(I,i1),e(i1,_re),e(_re,Y2o),e(i1,K2o),e(i1,J$),e(J$,Z2o),e(i1,evo),e(I,ovo),e(I,d1),e(d1,ure),e(ure,rvo),e(d1,tvo),e(d1,Y$),e(Y$,avo),e(d1,nvo),e(I,svo),e(I,c1),e(c1,bre),e(bre,lvo),e(c1,ivo),e(c1,K$),e(K$,dvo),e(c1,cvo),e(I,fvo),e(I,f1),e(f1,vre),e(vre,mvo),e(f1,gvo),e(f1,Z$),e(Z$,hvo),e(f1,pvo),e(I,_vo),e(I,m1),e(m1,Tre),e(Tre,uvo),e(m1,bvo),e(m1,eI),e(eI,vvo),e(m1,Tvo),e(I,Fvo),e(I,g1),e(g1,Fre),e(Fre,Cvo),e(g1,Mvo),e(g1,oI),e(oI,Evo),e(g1,yvo),e(I,wvo),e(I,h1),e(h1,Cre),e(Cre,Avo),e(h1,Lvo),e(h1,rI),e(rI,Bvo),e(h1,xvo),e(I,kvo),e(I,p1),e(p1,Mre),e(Mre,Rvo),e(p1,Svo),e(p1,tI),e(tI,Pvo),e(p1,$vo),e(I,Ivo),e(I,_1),e(_1,Ere),e(Ere,jvo),e(_1,Dvo),e(_1,aI),e(aI,Nvo),e(_1,qvo),e(I,Ovo),e(I,u1),e(u1,yre),e(yre,Gvo),e(u1,Xvo),e(u1,nI),e(nI,Vvo),e(u1,zvo),e(I,Wvo),e(I,b1),e(b1,wre),e(wre,Qvo),e(b1,Hvo),e(b1,sI),e(sI,Uvo),e(b1,Jvo),e(I,Yvo),e(I,v1),e(v1,Are),e(Are,Kvo),e(v1,Zvo),e(v1,lI),e(lI,e6o),e(v1,o6o),e(I,r6o),e(I,T1),e(T1,Lre),e(Lre,t6o),e(T1,a6o),e(T1,iI),e(iI,n6o),e(T1,s6o),e(I,l6o),e(I,F1),e(F1,Bre),e(Bre,i6o),e(F1,d6o),e(F1,dI),e(dI,c6o),e(F1,f6o),e(I,m6o),e(I,C1),e(C1,xre),e(xre,g6o),e(C1,h6o),e(C1,cI),e(cI,p6o),e(C1,_6o),e(I,u6o),e(I,M1),e(M1,kre),e(kre,b6o),e(M1,v6o),e(M1,fI),e(fI,T6o),e(M1,F6o),e(I,C6o),e(I,E1),e(E1,Rre),e(Rre,M6o),e(E1,E6o),e(E1,mI),e(mI,y6o),e(E1,w6o),e(I,A6o),e(I,y1),e(y1,Sre),e(Sre,L6o),e(y1,B6o),e(y1,gI),e(gI,x6o),e(y1,k6o),e(I,R6o),e(I,w1),e(w1,Pre),e(Pre,S6o),e(w1,P6o),e(w1,hI),e(hI,$6o),e(w1,I6o),e(I,j6o),e(I,A1),e(A1,$re),e($re,D6o),e(A1,N6o),e(A1,pI),e(pI,q6o),e(A1,O6o),e(I,G6o),e(I,L1),e(L1,Ire),e(Ire,X6o),e(L1,V6o),e(L1,jre),e(jre,z6o),e(L1,W6o),e(I,Q6o),e(I,B1),e(B1,Dre),e(Dre,H6o),e(B1,U6o),e(B1,_I),e(_I,J6o),e(B1,Y6o),e(I,K6o),e(I,x1),e(x1,Nre),e(Nre,Z6o),e(x1,e0o),e(x1,uI),e(uI,o0o),e(x1,r0o),e(I,t0o),e(I,k1),e(k1,qre),e(qre,a0o),e(k1,n0o),e(k1,bI),e(bI,s0o),e(k1,l0o),e(I,i0o),e(I,R1),e(R1,Ore),e(Ore,d0o),e(R1,c0o),e(R1,vI),e(vI,f0o),e(R1,m0o),e(qe,g0o),e(qe,S1),e(S1,h0o),e(S1,Gre),e(Gre,p0o),e(S1,_0o),e(S1,Xre),e(Xre,u0o),e(qe,b0o),e(qe,Vre),e(Vre,v0o),e(qe,T0o),g(gE,qe,null),b(d,gke,u),b(d,_d,u),e(_d,P1),e(P1,zre),g(hE,zre,null),e(_d,F0o),e(_d,Wre),e(Wre,C0o),b(d,hke,u),b(d,or,u),g(pE,or,null),e(or,M0o),e(or,ud),e(ud,E0o),e(ud,Qre),e(Qre,y0o),e(ud,w0o),e(ud,Hre),e(Hre,A0o),e(ud,L0o),e(or,B0o),e(or,_E),e(_E,x0o),e(_E,Ure),e(Ure,k0o),e(_E,R0o),e(or,S0o),e(or,Jr),g(uE,Jr,null),e(Jr,P0o),e(Jr,Jre),e(Jre,$0o),e(Jr,I0o),e(Jr,bd),e(bd,j0o),e(bd,Yre),e(Yre,D0o),e(bd,N0o),e(bd,Kre),e(Kre,q0o),e(bd,O0o),e(Jr,G0o),e(Jr,Zre),e(Zre,X0o),e(Jr,V0o),g(bE,Jr,null),e(or,z0o),e(or,Oe),g(vE,Oe,null),e(Oe,W0o),e(Oe,ete),e(ete,Q0o),e(Oe,H0o),e(Oe,Ka),e(Ka,U0o),e(Ka,ote),e(ote,J0o),e(Ka,Y0o),e(Ka,rte),e(rte,K0o),e(Ka,Z0o),e(Ka,tte),e(tte,eTo),e(Ka,oTo),e(Oe,rTo),e(Oe,ne),e(ne,$1),e($1,ate),e(ate,tTo),e($1,aTo),e($1,TI),e(TI,nTo),e($1,sTo),e(ne,lTo),e(ne,I1),e(I1,nte),e(nte,iTo),e(I1,dTo),e(I1,FI),e(FI,cTo),e(I1,fTo),e(ne,mTo),e(ne,j1),e(j1,ste),e(ste,gTo),e(j1,hTo),e(j1,CI),e(CI,pTo),e(j1,_To),e(ne,uTo),e(ne,D1),e(D1,lte),e(lte,bTo),e(D1,vTo),e(D1,MI),e(MI,TTo),e(D1,FTo),e(ne,CTo),e(ne,N1),e(N1,ite),e(ite,MTo),e(N1,ETo),e(N1,EI),e(EI,yTo),e(N1,wTo),e(ne,ATo),e(ne,q1),e(q1,dte),e(dte,LTo),e(q1,BTo),e(q1,yI),e(yI,xTo),e(q1,kTo),e(ne,RTo),e(ne,O1),e(O1,cte),e(cte,STo),e(O1,PTo),e(O1,wI),e(wI,$To),e(O1,ITo),e(ne,jTo),e(ne,G1),e(G1,fte),e(fte,DTo),e(G1,NTo),e(G1,AI),e(AI,qTo),e(G1,OTo),e(ne,GTo),e(ne,X1),e(X1,mte),e(mte,XTo),e(X1,VTo),e(X1,LI),e(LI,zTo),e(X1,WTo),e(ne,QTo),e(ne,V1),e(V1,gte),e(gte,HTo),e(V1,UTo),e(V1,BI),e(BI,JTo),e(V1,YTo),e(ne,KTo),e(ne,z1),e(z1,hte),e(hte,ZTo),e(z1,e8o),e(z1,xI),e(xI,o8o),e(z1,r8o),e(ne,t8o),e(ne,W1),e(W1,pte),e(pte,a8o),e(W1,n8o),e(W1,kI),e(kI,s8o),e(W1,l8o),e(ne,i8o),e(ne,Q1),e(Q1,_te),e(_te,d8o),e(Q1,c8o),e(Q1,RI),e(RI,f8o),e(Q1,m8o),e(ne,g8o),e(ne,H1),e(H1,ute),e(ute,h8o),e(H1,p8o),e(H1,SI),e(SI,_8o),e(H1,u8o),e(ne,b8o),e(ne,U1),e(U1,bte),e(bte,v8o),e(U1,T8o),e(U1,PI),e(PI,F8o),e(U1,C8o),e(ne,M8o),e(ne,J1),e(J1,vte),e(vte,E8o),e(J1,y8o),e(J1,$I),e($I,w8o),e(J1,A8o),e(Oe,L8o),e(Oe,Y1),e(Y1,B8o),e(Y1,Tte),e(Tte,x8o),e(Y1,k8o),e(Y1,Fte),e(Fte,R8o),e(Oe,S8o),e(Oe,Cte),e(Cte,P8o),e(Oe,$8o),g(TE,Oe,null),b(d,pke,u),b(d,vd,u),e(vd,K1),e(K1,Mte),g(FE,Mte,null),e(vd,I8o),e(vd,Ete),e(Ete,j8o),b(d,_ke,u),b(d,rr,u),g(CE,rr,null),e(rr,D8o),e(rr,Td),e(Td,N8o),e(Td,yte),e(yte,q8o),e(Td,O8o),e(Td,wte),e(wte,G8o),e(Td,X8o),e(rr,V8o),e(rr,ME),e(ME,z8o),e(ME,Ate),e(Ate,W8o),e(ME,Q8o),e(rr,H8o),e(rr,Yr),g(EE,Yr,null),e(Yr,U8o),e(Yr,Lte),e(Lte,J8o),e(Yr,Y8o),e(Yr,Fd),e(Fd,K8o),e(Fd,Bte),e(Bte,Z8o),e(Fd,eFo),e(Fd,xte),e(xte,oFo),e(Fd,rFo),e(Yr,tFo),e(Yr,kte),e(kte,aFo),e(Yr,nFo),g(yE,Yr,null),e(rr,sFo),e(rr,Ge),g(wE,Ge,null),e(Ge,lFo),e(Ge,Rte),e(Rte,iFo),e(Ge,dFo),e(Ge,Za),e(Za,cFo),e(Za,Ste),e(Ste,fFo),e(Za,mFo),e(Za,Pte),e(Pte,gFo),e(Za,hFo),e(Za,$te),e($te,pFo),e(Za,_Fo),e(Ge,uFo),e(Ge,A),e(A,Z1),e(Z1,Ite),e(Ite,bFo),e(Z1,vFo),e(Z1,II),e(II,TFo),e(Z1,FFo),e(A,CFo),e(A,eb),e(eb,jte),e(jte,MFo),e(eb,EFo),e(eb,jI),e(jI,yFo),e(eb,wFo),e(A,AFo),e(A,ob),e(ob,Dte),e(Dte,LFo),e(ob,BFo),e(ob,DI),e(DI,xFo),e(ob,kFo),e(A,RFo),e(A,rb),e(rb,Nte),e(Nte,SFo),e(rb,PFo),e(rb,NI),e(NI,$Fo),e(rb,IFo),e(A,jFo),e(A,tb),e(tb,qte),e(qte,DFo),e(tb,NFo),e(tb,qI),e(qI,qFo),e(tb,OFo),e(A,GFo),e(A,ab),e(ab,Ote),e(Ote,XFo),e(ab,VFo),e(ab,OI),e(OI,zFo),e(ab,WFo),e(A,QFo),e(A,nb),e(nb,Gte),e(Gte,HFo),e(nb,UFo),e(nb,GI),e(GI,JFo),e(nb,YFo),e(A,KFo),e(A,sb),e(sb,Xte),e(Xte,ZFo),e(sb,eCo),e(sb,XI),e(XI,oCo),e(sb,rCo),e(A,tCo),e(A,lb),e(lb,Vte),e(Vte,aCo),e(lb,nCo),e(lb,VI),e(VI,sCo),e(lb,lCo),e(A,iCo),e(A,ib),e(ib,zte),e(zte,dCo),e(ib,cCo),e(ib,zI),e(zI,fCo),e(ib,mCo),e(A,gCo),e(A,db),e(db,Wte),e(Wte,hCo),e(db,pCo),e(db,WI),e(WI,_Co),e(db,uCo),e(A,bCo),e(A,cb),e(cb,Qte),e(Qte,vCo),e(cb,TCo),e(cb,QI),e(QI,FCo),e(cb,CCo),e(A,MCo),e(A,fb),e(fb,Hte),e(Hte,ECo),e(fb,yCo),e(fb,HI),e(HI,wCo),e(fb,ACo),e(A,LCo),e(A,mb),e(mb,Ute),e(Ute,BCo),e(mb,xCo),e(mb,UI),e(UI,kCo),e(mb,RCo),e(A,SCo),e(A,gb),e(gb,Jte),e(Jte,PCo),e(gb,$Co),e(gb,JI),e(JI,ICo),e(gb,jCo),e(A,DCo),e(A,hb),e(hb,Yte),e(Yte,NCo),e(hb,qCo),e(hb,YI),e(YI,OCo),e(hb,GCo),e(A,XCo),e(A,pb),e(pb,Kte),e(Kte,VCo),e(pb,zCo),e(pb,KI),e(KI,WCo),e(pb,QCo),e(A,HCo),e(A,_b),e(_b,Zte),e(Zte,UCo),e(_b,JCo),e(_b,ZI),e(ZI,YCo),e(_b,KCo),e(A,ZCo),e(A,ub),e(ub,eae),e(eae,eMo),e(ub,oMo),e(ub,ej),e(ej,rMo),e(ub,tMo),e(A,aMo),e(A,bb),e(bb,oae),e(oae,nMo),e(bb,sMo),e(bb,oj),e(oj,lMo),e(bb,iMo),e(A,dMo),e(A,vb),e(vb,rae),e(rae,cMo),e(vb,fMo),e(vb,rj),e(rj,mMo),e(vb,gMo),e(A,hMo),e(A,Tb),e(Tb,tae),e(tae,pMo),e(Tb,_Mo),e(Tb,tj),e(tj,uMo),e(Tb,bMo),e(A,vMo),e(A,Fb),e(Fb,aae),e(aae,TMo),e(Fb,FMo),e(Fb,aj),e(aj,CMo),e(Fb,MMo),e(A,EMo),e(A,Cb),e(Cb,nae),e(nae,yMo),e(Cb,wMo),e(Cb,nj),e(nj,AMo),e(Cb,LMo),e(A,BMo),e(A,Mb),e(Mb,sae),e(sae,xMo),e(Mb,kMo),e(Mb,sj),e(sj,RMo),e(Mb,SMo),e(A,PMo),e(A,Eb),e(Eb,lae),e(lae,$Mo),e(Eb,IMo),e(Eb,lj),e(lj,jMo),e(Eb,DMo),e(A,NMo),e(A,yb),e(yb,iae),e(iae,qMo),e(yb,OMo),e(yb,ij),e(ij,GMo),e(yb,XMo),e(A,VMo),e(A,wb),e(wb,dae),e(dae,zMo),e(wb,WMo),e(wb,dj),e(dj,QMo),e(wb,HMo),e(A,UMo),e(A,Ab),e(Ab,cae),e(cae,JMo),e(Ab,YMo),e(Ab,cj),e(cj,KMo),e(Ab,ZMo),e(A,e4o),e(A,Lb),e(Lb,fae),e(fae,o4o),e(Lb,r4o),e(Lb,fj),e(fj,t4o),e(Lb,a4o),e(A,n4o),e(A,Bb),e(Bb,mae),e(mae,s4o),e(Bb,l4o),e(Bb,mj),e(mj,i4o),e(Bb,d4o),e(A,c4o),e(A,xb),e(xb,gae),e(gae,f4o),e(xb,m4o),e(xb,gj),e(gj,g4o),e(xb,h4o),e(A,p4o),e(A,kb),e(kb,hae),e(hae,_4o),e(kb,u4o),e(kb,hj),e(hj,b4o),e(kb,v4o),e(A,T4o),e(A,Rb),e(Rb,pae),e(pae,F4o),e(Rb,C4o),e(Rb,pj),e(pj,M4o),e(Rb,E4o),e(A,y4o),e(A,Sb),e(Sb,_ae),e(_ae,w4o),e(Sb,A4o),e(Sb,_j),e(_j,L4o),e(Sb,B4o),e(A,x4o),e(A,Pb),e(Pb,uae),e(uae,k4o),e(Pb,R4o),e(Pb,uj),e(uj,S4o),e(Pb,P4o),e(A,$4o),e(A,$b),e($b,bae),e(bae,I4o),e($b,j4o),e($b,bj),e(bj,D4o),e($b,N4o),e(A,q4o),e(A,Ib),e(Ib,vae),e(vae,O4o),e(Ib,G4o),e(Ib,vj),e(vj,X4o),e(Ib,V4o),e(A,z4o),e(A,jb),e(jb,Tae),e(Tae,W4o),e(jb,Q4o),e(jb,Tj),e(Tj,H4o),e(jb,U4o),e(A,J4o),e(A,Db),e(Db,Fae),e(Fae,Y4o),e(Db,K4o),e(Db,Fj),e(Fj,Z4o),e(Db,eEo),e(A,oEo),e(A,Nb),e(Nb,Cae),e(Cae,rEo),e(Nb,tEo),e(Nb,Cj),e(Cj,aEo),e(Nb,nEo),e(A,sEo),e(A,qb),e(qb,Mae),e(Mae,lEo),e(qb,iEo),e(qb,Mj),e(Mj,dEo),e(qb,cEo),e(A,fEo),e(A,Ob),e(Ob,Eae),e(Eae,mEo),e(Ob,gEo),e(Ob,Ej),e(Ej,hEo),e(Ob,pEo),e(A,_Eo),e(A,Gb),e(Gb,yae),e(yae,uEo),e(Gb,bEo),e(Gb,yj),e(yj,vEo),e(Gb,TEo),e(A,FEo),e(A,Xb),e(Xb,wae),e(wae,CEo),e(Xb,MEo),e(Xb,wj),e(wj,EEo),e(Xb,yEo),e(A,wEo),e(A,Vb),e(Vb,Aae),e(Aae,AEo),e(Vb,LEo),e(Vb,Aj),e(Aj,BEo),e(Vb,xEo),e(Ge,kEo),e(Ge,zb),e(zb,REo),e(zb,Lae),e(Lae,SEo),e(zb,PEo),e(zb,Bae),e(Bae,$Eo),e(Ge,IEo),e(Ge,xae),e(xae,jEo),e(Ge,DEo),g(AE,Ge,null),b(d,uke,u),b(d,Cd,u),e(Cd,Wb),e(Wb,kae),g(LE,kae,null),e(Cd,NEo),e(Cd,Rae),e(Rae,qEo),b(d,bke,u),b(d,tr,u),g(BE,tr,null),e(tr,OEo),e(tr,Md),e(Md,GEo),e(Md,Sae),e(Sae,XEo),e(Md,VEo),e(Md,Pae),e(Pae,zEo),e(Md,WEo),e(tr,QEo),e(tr,xE),e(xE,HEo),e(xE,$ae),e($ae,UEo),e(xE,JEo),e(tr,YEo),e(tr,Kr),g(kE,Kr,null),e(Kr,KEo),e(Kr,Iae),e(Iae,ZEo),e(Kr,e3o),e(Kr,Ed),e(Ed,o3o),e(Ed,jae),e(jae,r3o),e(Ed,t3o),e(Ed,Dae),e(Dae,a3o),e(Ed,n3o),e(Kr,s3o),e(Kr,Nae),e(Nae,l3o),e(Kr,i3o),g(RE,Kr,null),e(tr,d3o),e(tr,Xe),g(SE,Xe,null),e(Xe,c3o),e(Xe,qae),e(qae,f3o),e(Xe,m3o),e(Xe,en),e(en,g3o),e(en,Oae),e(Oae,h3o),e(en,p3o),e(en,Gae),e(Gae,_3o),e(en,u3o),e(en,Xae),e(Xae,b3o),e(en,v3o),e(Xe,T3o),e(Xe,O),e(O,Qb),e(Qb,Vae),e(Vae,F3o),e(Qb,C3o),e(Qb,Lj),e(Lj,M3o),e(Qb,E3o),e(O,y3o),e(O,Hb),e(Hb,zae),e(zae,w3o),e(Hb,A3o),e(Hb,Bj),e(Bj,L3o),e(Hb,B3o),e(O,x3o),e(O,Ub),e(Ub,Wae),e(Wae,k3o),e(Ub,R3o),e(Ub,xj),e(xj,S3o),e(Ub,P3o),e(O,$3o),e(O,Jb),e(Jb,Qae),e(Qae,I3o),e(Jb,j3o),e(Jb,kj),e(kj,D3o),e(Jb,N3o),e(O,q3o),e(O,Yb),e(Yb,Hae),e(Hae,O3o),e(Yb,G3o),e(Yb,Rj),e(Rj,X3o),e(Yb,V3o),e(O,z3o),e(O,Kb),e(Kb,Uae),e(Uae,W3o),e(Kb,Q3o),e(Kb,Sj),e(Sj,H3o),e(Kb,U3o),e(O,J3o),e(O,Zb),e(Zb,Jae),e(Jae,Y3o),e(Zb,K3o),e(Zb,Pj),e(Pj,Z3o),e(Zb,eyo),e(O,oyo),e(O,e5),e(e5,Yae),e(Yae,ryo),e(e5,tyo),e(e5,$j),e($j,ayo),e(e5,nyo),e(O,syo),e(O,o5),e(o5,Kae),e(Kae,lyo),e(o5,iyo),e(o5,Ij),e(Ij,dyo),e(o5,cyo),e(O,fyo),e(O,r5),e(r5,Zae),e(Zae,myo),e(r5,gyo),e(r5,jj),e(jj,hyo),e(r5,pyo),e(O,_yo),e(O,t5),e(t5,ene),e(ene,uyo),e(t5,byo),e(t5,Dj),e(Dj,vyo),e(t5,Tyo),e(O,Fyo),e(O,a5),e(a5,one),e(one,Cyo),e(a5,Myo),e(a5,Nj),e(Nj,Eyo),e(a5,yyo),e(O,wyo),e(O,n5),e(n5,rne),e(rne,Ayo),e(n5,Lyo),e(n5,qj),e(qj,Byo),e(n5,xyo),e(O,kyo),e(O,s5),e(s5,tne),e(tne,Ryo),e(s5,Syo),e(s5,Oj),e(Oj,Pyo),e(s5,$yo),e(O,Iyo),e(O,l5),e(l5,ane),e(ane,jyo),e(l5,Dyo),e(l5,Gj),e(Gj,Nyo),e(l5,qyo),e(O,Oyo),e(O,i5),e(i5,nne),e(nne,Gyo),e(i5,Xyo),e(i5,Xj),e(Xj,Vyo),e(i5,zyo),e(O,Wyo),e(O,d5),e(d5,sne),e(sne,Qyo),e(d5,Hyo),e(d5,Vj),e(Vj,Uyo),e(d5,Jyo),e(O,Yyo),e(O,c5),e(c5,lne),e(lne,Kyo),e(c5,Zyo),e(c5,zj),e(zj,ewo),e(c5,owo),e(O,rwo),e(O,f5),e(f5,ine),e(ine,two),e(f5,awo),e(f5,Wj),e(Wj,nwo),e(f5,swo),e(O,lwo),e(O,m5),e(m5,dne),e(dne,iwo),e(m5,dwo),e(m5,Qj),e(Qj,cwo),e(m5,fwo),e(O,mwo),e(O,g5),e(g5,cne),e(cne,gwo),e(g5,hwo),e(g5,Hj),e(Hj,pwo),e(g5,_wo),e(O,uwo),e(O,h5),e(h5,fne),e(fne,bwo),e(h5,vwo),e(h5,Uj),e(Uj,Two),e(h5,Fwo),e(O,Cwo),e(O,p5),e(p5,mne),e(mne,Mwo),e(p5,Ewo),e(p5,Jj),e(Jj,ywo),e(p5,wwo),e(O,Awo),e(O,_5),e(_5,gne),e(gne,Lwo),e(_5,Bwo),e(_5,Yj),e(Yj,xwo),e(_5,kwo),e(O,Rwo),e(O,u5),e(u5,hne),e(hne,Swo),e(u5,Pwo),e(u5,Kj),e(Kj,$wo),e(u5,Iwo),e(O,jwo),e(O,b5),e(b5,pne),e(pne,Dwo),e(b5,Nwo),e(b5,Zj),e(Zj,qwo),e(b5,Owo),e(O,Gwo),e(O,v5),e(v5,_ne),e(_ne,Xwo),e(v5,Vwo),e(v5,eD),e(eD,zwo),e(v5,Wwo),e(O,Qwo),e(O,T5),e(T5,une),e(une,Hwo),e(T5,Uwo),e(T5,oD),e(oD,Jwo),e(T5,Ywo),e(Xe,Kwo),e(Xe,F5),e(F5,Zwo),e(F5,bne),e(bne,eAo),e(F5,oAo),e(F5,vne),e(vne,rAo),e(Xe,tAo),e(Xe,Tne),e(Tne,aAo),e(Xe,nAo),g(PE,Xe,null),b(d,vke,u),b(d,yd,u),e(yd,C5),e(C5,Fne),g($E,Fne,null),e(yd,sAo),e(yd,Cne),e(Cne,lAo),b(d,Tke,u),b(d,ar,u),g(IE,ar,null),e(ar,iAo),e(ar,wd),e(wd,dAo),e(wd,Mne),e(Mne,cAo),e(wd,fAo),e(wd,Ene),e(Ene,mAo),e(wd,gAo),e(ar,hAo),e(ar,jE),e(jE,pAo),e(jE,yne),e(yne,_Ao),e(jE,uAo),e(ar,bAo),e(ar,Zr),g(DE,Zr,null),e(Zr,vAo),e(Zr,wne),e(wne,TAo),e(Zr,FAo),e(Zr,Ad),e(Ad,CAo),e(Ad,Ane),e(Ane,MAo),e(Ad,EAo),e(Ad,Lne),e(Lne,yAo),e(Ad,wAo),e(Zr,AAo),e(Zr,Bne),e(Bne,LAo),e(Zr,BAo),g(NE,Zr,null),e(ar,xAo),e(ar,Ve),g(qE,Ve,null),e(Ve,kAo),e(Ve,xne),e(xne,RAo),e(Ve,SAo),e(Ve,on),e(on,PAo),e(on,kne),e(kne,$Ao),e(on,IAo),e(on,Rne),e(Rne,jAo),e(on,DAo),e(on,Sne),e(Sne,NAo),e(on,qAo),e(Ve,OAo),e(Ve,ma),e(ma,M5),e(M5,Pne),e(Pne,GAo),e(M5,XAo),e(M5,rD),e(rD,VAo),e(M5,zAo),e(ma,WAo),e(ma,E5),e(E5,$ne),e($ne,QAo),e(E5,HAo),e(E5,tD),e(tD,UAo),e(E5,JAo),e(ma,YAo),e(ma,y5),e(y5,Ine),e(Ine,KAo),e(y5,ZAo),e(y5,aD),e(aD,eLo),e(y5,oLo),e(ma,rLo),e(ma,w5),e(w5,jne),e(jne,tLo),e(w5,aLo),e(w5,nD),e(nD,nLo),e(w5,sLo),e(ma,lLo),e(ma,A5),e(A5,Dne),e(Dne,iLo),e(A5,dLo),e(A5,sD),e(sD,cLo),e(A5,fLo),e(Ve,mLo),e(Ve,L5),e(L5,gLo),e(L5,Nne),e(Nne,hLo),e(L5,pLo),e(L5,qne),e(qne,_Lo),e(Ve,uLo),e(Ve,One),e(One,bLo),e(Ve,vLo),g(OE,Ve,null),b(d,Fke,u),b(d,Ld,u),e(Ld,B5),e(B5,Gne),g(GE,Gne,null),e(Ld,TLo),e(Ld,Xne),e(Xne,FLo),b(d,Cke,u),b(d,nr,u),g(XE,nr,null),e(nr,CLo),e(nr,Bd),e(Bd,MLo),e(Bd,Vne),e(Vne,ELo),e(Bd,yLo),e(Bd,zne),e(zne,wLo),e(Bd,ALo),e(nr,LLo),e(nr,VE),e(VE,BLo),e(VE,Wne),e(Wne,xLo),e(VE,kLo),e(nr,RLo),e(nr,et),g(zE,et,null),e(et,SLo),e(et,Qne),e(Qne,PLo),e(et,$Lo),e(et,xd),e(xd,ILo),e(xd,Hne),e(Hne,jLo),e(xd,DLo),e(xd,Une),e(Une,NLo),e(xd,qLo),e(et,OLo),e(et,Jne),e(Jne,GLo),e(et,XLo),g(WE,et,null),e(nr,VLo),e(nr,ze),g(QE,ze,null),e(ze,zLo),e(ze,Yne),e(Yne,WLo),e(ze,QLo),e(ze,rn),e(rn,HLo),e(rn,Kne),e(Kne,ULo),e(rn,JLo),e(rn,Zne),e(Zne,YLo),e(rn,KLo),e(rn,ese),e(ese,ZLo),e(rn,e7o),e(ze,o7o),e(ze,N),e(N,x5),e(x5,ose),e(ose,r7o),e(x5,t7o),e(x5,lD),e(lD,a7o),e(x5,n7o),e(N,s7o),e(N,k5),e(k5,rse),e(rse,l7o),e(k5,i7o),e(k5,iD),e(iD,d7o),e(k5,c7o),e(N,f7o),e(N,R5),e(R5,tse),e(tse,m7o),e(R5,g7o),e(R5,dD),e(dD,h7o),e(R5,p7o),e(N,_7o),e(N,S5),e(S5,ase),e(ase,u7o),e(S5,b7o),e(S5,cD),e(cD,v7o),e(S5,T7o),e(N,F7o),e(N,P5),e(P5,nse),e(nse,C7o),e(P5,M7o),e(P5,fD),e(fD,E7o),e(P5,y7o),e(N,w7o),e(N,$5),e($5,sse),e(sse,A7o),e($5,L7o),e($5,mD),e(mD,B7o),e($5,x7o),e(N,k7o),e(N,I5),e(I5,lse),e(lse,R7o),e(I5,S7o),e(I5,gD),e(gD,P7o),e(I5,$7o),e(N,I7o),e(N,j5),e(j5,ise),e(ise,j7o),e(j5,D7o),e(j5,hD),e(hD,N7o),e(j5,q7o),e(N,O7o),e(N,D5),e(D5,dse),e(dse,G7o),e(D5,X7o),e(D5,pD),e(pD,V7o),e(D5,z7o),e(N,W7o),e(N,N5),e(N5,cse),e(cse,Q7o),e(N5,H7o),e(N5,_D),e(_D,U7o),e(N5,J7o),e(N,Y7o),e(N,q5),e(q5,fse),e(fse,K7o),e(q5,Z7o),e(q5,uD),e(uD,e9o),e(q5,o9o),e(N,r9o),e(N,O5),e(O5,mse),e(mse,t9o),e(O5,a9o),e(O5,bD),e(bD,n9o),e(O5,s9o),e(N,l9o),e(N,G5),e(G5,gse),e(gse,i9o),e(G5,d9o),e(G5,vD),e(vD,c9o),e(G5,f9o),e(N,m9o),e(N,X5),e(X5,hse),e(hse,g9o),e(X5,h9o),e(X5,TD),e(TD,p9o),e(X5,_9o),e(N,u9o),e(N,V5),e(V5,pse),e(pse,b9o),e(V5,v9o),e(V5,FD),e(FD,T9o),e(V5,F9o),e(N,C9o),e(N,z5),e(z5,_se),e(_se,M9o),e(z5,E9o),e(z5,CD),e(CD,y9o),e(z5,w9o),e(N,A9o),e(N,W5),e(W5,use),e(use,L9o),e(W5,B9o),e(W5,MD),e(MD,x9o),e(W5,k9o),e(N,R9o),e(N,Q5),e(Q5,bse),e(bse,S9o),e(Q5,P9o),e(Q5,ED),e(ED,$9o),e(Q5,I9o),e(N,j9o),e(N,H5),e(H5,vse),e(vse,D9o),e(H5,N9o),e(H5,yD),e(yD,q9o),e(H5,O9o),e(N,G9o),e(N,U5),e(U5,Tse),e(Tse,X9o),e(U5,V9o),e(U5,wD),e(wD,z9o),e(U5,W9o),e(N,Q9o),e(N,J5),e(J5,Fse),e(Fse,H9o),e(J5,U9o),e(J5,AD),e(AD,J9o),e(J5,Y9o),e(N,K9o),e(N,Y5),e(Y5,Cse),e(Cse,Z9o),e(Y5,eBo),e(Y5,LD),e(LD,oBo),e(Y5,rBo),e(N,tBo),e(N,K5),e(K5,Mse),e(Mse,aBo),e(K5,nBo),e(K5,BD),e(BD,sBo),e(K5,lBo),e(N,iBo),e(N,Z5),e(Z5,Ese),e(Ese,dBo),e(Z5,cBo),e(Z5,xD),e(xD,fBo),e(Z5,mBo),e(N,gBo),e(N,e2),e(e2,yse),e(yse,hBo),e(e2,pBo),e(e2,kD),e(kD,_Bo),e(e2,uBo),e(N,bBo),e(N,o2),e(o2,wse),e(wse,vBo),e(o2,TBo),e(o2,RD),e(RD,FBo),e(o2,CBo),e(N,MBo),e(N,r2),e(r2,Ase),e(Ase,EBo),e(r2,yBo),e(r2,SD),e(SD,wBo),e(r2,ABo),e(N,LBo),e(N,t2),e(t2,Lse),e(Lse,BBo),e(t2,xBo),e(t2,PD),e(PD,kBo),e(t2,RBo),e(N,SBo),e(N,a2),e(a2,Bse),e(Bse,PBo),e(a2,$Bo),e(a2,$D),e($D,IBo),e(a2,jBo),e(N,DBo),e(N,n2),e(n2,xse),e(xse,NBo),e(n2,qBo),e(n2,ID),e(ID,OBo),e(n2,GBo),e(N,XBo),e(N,s2),e(s2,kse),e(kse,VBo),e(s2,zBo),e(s2,jD),e(jD,WBo),e(s2,QBo),e(N,HBo),e(N,l2),e(l2,Rse),e(Rse,UBo),e(l2,JBo),e(l2,DD),e(DD,YBo),e(l2,KBo),e(N,ZBo),e(N,i2),e(i2,Sse),e(Sse,exo),e(i2,oxo),e(i2,ND),e(ND,rxo),e(i2,txo),e(ze,axo),e(ze,d2),e(d2,nxo),e(d2,Pse),e(Pse,sxo),e(d2,lxo),e(d2,$se),e($se,ixo),e(ze,dxo),e(ze,Ise),e(Ise,cxo),e(ze,fxo),g(HE,ze,null),b(d,Mke,u),b(d,kd,u),e(kd,c2),e(c2,jse),g(UE,jse,null),e(kd,mxo),e(kd,Dse),e(Dse,gxo),b(d,Eke,u),b(d,sr,u),g(JE,sr,null),e(sr,hxo),e(sr,Rd),e(Rd,pxo),e(Rd,Nse),e(Nse,_xo),e(Rd,uxo),e(Rd,qse),e(qse,bxo),e(Rd,vxo),e(sr,Txo),e(sr,YE),e(YE,Fxo),e(YE,Ose),e(Ose,Cxo),e(YE,Mxo),e(sr,Exo),e(sr,ot),g(KE,ot,null),e(ot,yxo),e(ot,Gse),e(Gse,wxo),e(ot,Axo),e(ot,Sd),e(Sd,Lxo),e(Sd,Xse),e(Xse,Bxo),e(Sd,xxo),e(Sd,Vse),e(Vse,kxo),e(Sd,Rxo),e(ot,Sxo),e(ot,zse),e(zse,Pxo),e(ot,$xo),g(ZE,ot,null),e(sr,Ixo),e(sr,We),g(e3,We,null),e(We,jxo),e(We,Wse),e(Wse,Dxo),e(We,Nxo),e(We,tn),e(tn,qxo),e(tn,Qse),e(Qse,Oxo),e(tn,Gxo),e(tn,Hse),e(Hse,Xxo),e(tn,Vxo),e(tn,Use),e(Use,zxo),e(tn,Wxo),e(We,Qxo),e(We,R),e(R,f2),e(f2,Jse),e(Jse,Hxo),e(f2,Uxo),e(f2,qD),e(qD,Jxo),e(f2,Yxo),e(R,Kxo),e(R,m2),e(m2,Yse),e(Yse,Zxo),e(m2,eko),e(m2,OD),e(OD,oko),e(m2,rko),e(R,tko),e(R,g2),e(g2,Kse),e(Kse,ako),e(g2,nko),e(g2,GD),e(GD,sko),e(g2,lko),e(R,iko),e(R,h2),e(h2,Zse),e(Zse,dko),e(h2,cko),e(h2,XD),e(XD,fko),e(h2,mko),e(R,gko),e(R,p2),e(p2,ele),e(ele,hko),e(p2,pko),e(p2,VD),e(VD,_ko),e(p2,uko),e(R,bko),e(R,_2),e(_2,ole),e(ole,vko),e(_2,Tko),e(_2,zD),e(zD,Fko),e(_2,Cko),e(R,Mko),e(R,u2),e(u2,rle),e(rle,Eko),e(u2,yko),e(u2,WD),e(WD,wko),e(u2,Ako),e(R,Lko),e(R,b2),e(b2,tle),e(tle,Bko),e(b2,xko),e(b2,QD),e(QD,kko),e(b2,Rko),e(R,Sko),e(R,v2),e(v2,ale),e(ale,Pko),e(v2,$ko),e(v2,HD),e(HD,Iko),e(v2,jko),e(R,Dko),e(R,T2),e(T2,nle),e(nle,Nko),e(T2,qko),e(T2,UD),e(UD,Oko),e(T2,Gko),e(R,Xko),e(R,F2),e(F2,sle),e(sle,Vko),e(F2,zko),e(F2,JD),e(JD,Wko),e(F2,Qko),e(R,Hko),e(R,C2),e(C2,lle),e(lle,Uko),e(C2,Jko),e(C2,YD),e(YD,Yko),e(C2,Kko),e(R,Zko),e(R,M2),e(M2,ile),e(ile,eRo),e(M2,oRo),e(M2,KD),e(KD,rRo),e(M2,tRo),e(R,aRo),e(R,E2),e(E2,dle),e(dle,nRo),e(E2,sRo),e(E2,ZD),e(ZD,lRo),e(E2,iRo),e(R,dRo),e(R,y2),e(y2,cle),e(cle,cRo),e(y2,fRo),e(y2,eN),e(eN,mRo),e(y2,gRo),e(R,hRo),e(R,w2),e(w2,fle),e(fle,pRo),e(w2,_Ro),e(w2,oN),e(oN,uRo),e(w2,bRo),e(R,vRo),e(R,A2),e(A2,mle),e(mle,TRo),e(A2,FRo),e(A2,rN),e(rN,CRo),e(A2,MRo),e(R,ERo),e(R,L2),e(L2,gle),e(gle,yRo),e(L2,wRo),e(L2,tN),e(tN,ARo),e(L2,LRo),e(R,BRo),e(R,B2),e(B2,hle),e(hle,xRo),e(B2,kRo),e(B2,aN),e(aN,RRo),e(B2,SRo),e(R,PRo),e(R,x2),e(x2,ple),e(ple,$Ro),e(x2,IRo),e(x2,nN),e(nN,jRo),e(x2,DRo),e(R,NRo),e(R,k2),e(k2,_le),e(_le,qRo),e(k2,ORo),e(k2,sN),e(sN,GRo),e(k2,XRo),e(R,VRo),e(R,R2),e(R2,ule),e(ule,zRo),e(R2,WRo),e(R2,lN),e(lN,QRo),e(R2,HRo),e(R,URo),e(R,S2),e(S2,ble),e(ble,JRo),e(S2,YRo),e(S2,iN),e(iN,KRo),e(S2,ZRo),e(R,eSo),e(R,P2),e(P2,vle),e(vle,oSo),e(P2,rSo),e(P2,dN),e(dN,tSo),e(P2,aSo),e(R,nSo),e(R,$2),e($2,Tle),e(Tle,sSo),e($2,lSo),e($2,cN),e(cN,iSo),e($2,dSo),e(R,cSo),e(R,I2),e(I2,Fle),e(Fle,fSo),e(I2,mSo),e(I2,fN),e(fN,gSo),e(I2,hSo),e(R,pSo),e(R,j2),e(j2,Cle),e(Cle,_So),e(j2,uSo),e(j2,mN),e(mN,bSo),e(j2,vSo),e(R,TSo),e(R,D2),e(D2,Mle),e(Mle,FSo),e(D2,CSo),e(D2,gN),e(gN,MSo),e(D2,ESo),e(R,ySo),e(R,N2),e(N2,Ele),e(Ele,wSo),e(N2,ASo),e(N2,hN),e(hN,LSo),e(N2,BSo),e(R,xSo),e(R,q2),e(q2,yle),e(yle,kSo),e(q2,RSo),e(q2,pN),e(pN,SSo),e(q2,PSo),e(R,$So),e(R,O2),e(O2,wle),e(wle,ISo),e(O2,jSo),e(O2,_N),e(_N,DSo),e(O2,NSo),e(R,qSo),e(R,G2),e(G2,Ale),e(Ale,OSo),e(G2,GSo),e(G2,uN),e(uN,XSo),e(G2,VSo),e(R,zSo),e(R,X2),e(X2,Lle),e(Lle,WSo),e(X2,QSo),e(X2,bN),e(bN,HSo),e(X2,USo),e(R,JSo),e(R,V2),e(V2,Ble),e(Ble,YSo),e(V2,KSo),e(V2,vN),e(vN,ZSo),e(V2,ePo),e(R,oPo),e(R,z2),e(z2,xle),e(xle,rPo),e(z2,tPo),e(z2,TN),e(TN,aPo),e(z2,nPo),e(R,sPo),e(R,W2),e(W2,kle),e(kle,lPo),e(W2,iPo),e(W2,FN),e(FN,dPo),e(W2,cPo),e(R,fPo),e(R,Q2),e(Q2,Rle),e(Rle,mPo),e(Q2,gPo),e(Q2,CN),e(CN,hPo),e(Q2,pPo),e(R,_Po),e(R,H2),e(H2,Sle),e(Sle,uPo),e(H2,bPo),e(H2,MN),e(MN,vPo),e(H2,TPo),e(R,FPo),e(R,U2),e(U2,Ple),e(Ple,CPo),e(U2,MPo),e(U2,EN),e(EN,EPo),e(U2,yPo),e(We,wPo),e(We,J2),e(J2,APo),e(J2,$le),e($le,LPo),e(J2,BPo),e(J2,Ile),e(Ile,xPo),e(We,kPo),e(We,jle),e(jle,RPo),e(We,SPo),g(o3,We,null),b(d,yke,u),b(d,Pd,u),e(Pd,Y2),e(Y2,Dle),g(r3,Dle,null),e(Pd,PPo),e(Pd,Nle),e(Nle,$Po),b(d,wke,u),b(d,lr,u),g(t3,lr,null),e(lr,IPo),e(lr,$d),e($d,jPo),e($d,qle),e(qle,DPo),e($d,NPo),e($d,Ole),e(Ole,qPo),e($d,OPo),e(lr,GPo),e(lr,a3),e(a3,XPo),e(a3,Gle),e(Gle,VPo),e(a3,zPo),e(lr,WPo),e(lr,rt),g(n3,rt,null),e(rt,QPo),e(rt,Xle),e(Xle,HPo),e(rt,UPo),e(rt,Id),e(Id,JPo),e(Id,Vle),e(Vle,YPo),e(Id,KPo),e(Id,zle),e(zle,ZPo),e(Id,e$o),e(rt,o$o),e(rt,Wle),e(Wle,r$o),e(rt,t$o),g(s3,rt,null),e(lr,a$o),e(lr,Qe),g(l3,Qe,null),e(Qe,n$o),e(Qe,Qle),e(Qle,s$o),e(Qe,l$o),e(Qe,an),e(an,i$o),e(an,Hle),e(Hle,d$o),e(an,c$o),e(an,Ule),e(Ule,f$o),e(an,m$o),e(an,Jle),e(Jle,g$o),e(an,h$o),e(Qe,p$o),e(Qe,Yle),e(Yle,K2),e(K2,Kle),e(Kle,_$o),e(K2,u$o),e(K2,yN),e(yN,b$o),e(K2,v$o),e(Qe,T$o),e(Qe,Z2),e(Z2,F$o),e(Z2,Zle),e(Zle,C$o),e(Z2,M$o),e(Z2,eie),e(eie,E$o),e(Qe,y$o),e(Qe,oie),e(oie,w$o),e(Qe,A$o),g(i3,Qe,null),b(d,Ake,u),b(d,jd,u),e(jd,ev),e(ev,rie),g(d3,rie,null),e(jd,L$o),e(jd,tie),e(tie,B$o),b(d,Lke,u),b(d,ir,u),g(c3,ir,null),e(ir,x$o),e(ir,Dd),e(Dd,k$o),e(Dd,aie),e(aie,R$o),e(Dd,S$o),e(Dd,nie),e(nie,P$o),e(Dd,$$o),e(ir,I$o),e(ir,f3),e(f3,j$o),e(f3,sie),e(sie,D$o),e(f3,N$o),e(ir,q$o),e(ir,tt),g(m3,tt,null),e(tt,O$o),e(tt,lie),e(lie,G$o),e(tt,X$o),e(tt,Nd),e(Nd,V$o),e(Nd,iie),e(iie,z$o),e(Nd,W$o),e(Nd,die),e(die,Q$o),e(Nd,H$o),e(tt,U$o),e(tt,cie),e(cie,J$o),e(tt,Y$o),g(g3,tt,null),e(ir,K$o),e(ir,He),g(h3,He,null),e(He,Z$o),e(He,fie),e(fie,eIo),e(He,oIo),e(He,nn),e(nn,rIo),e(nn,mie),e(mie,tIo),e(nn,aIo),e(nn,gie),e(gie,nIo),e(nn,sIo),e(nn,hie),e(hie,lIo),e(nn,iIo),e(He,dIo),e(He,Ce),e(Ce,ov),e(ov,pie),e(pie,cIo),e(ov,fIo),e(ov,wN),e(wN,mIo),e(ov,gIo),e(Ce,hIo),e(Ce,rv),e(rv,_ie),e(_ie,pIo),e(rv,_Io),e(rv,AN),e(AN,uIo),e(rv,bIo),e(Ce,vIo),e(Ce,zs),e(zs,uie),e(uie,TIo),e(zs,FIo),e(zs,LN),e(LN,CIo),e(zs,MIo),e(zs,BN),e(BN,EIo),e(zs,yIo),e(Ce,wIo),e(Ce,tv),e(tv,bie),e(bie,AIo),e(tv,LIo),e(tv,xN),e(xN,BIo),e(tv,xIo),e(Ce,kIo),e(Ce,pa),e(pa,vie),e(vie,RIo),e(pa,SIo),e(pa,kN),e(kN,PIo),e(pa,$Io),e(pa,RN),e(RN,IIo),e(pa,jIo),e(pa,SN),e(SN,DIo),e(pa,NIo),e(Ce,qIo),e(Ce,av),e(av,Tie),e(Tie,OIo),e(av,GIo),e(av,PN),e(PN,XIo),e(av,VIo),e(Ce,zIo),e(Ce,nv),e(nv,Fie),e(Fie,WIo),e(nv,QIo),e(nv,$N),e($N,HIo),e(nv,UIo),e(Ce,JIo),e(Ce,sv),e(sv,Cie),e(Cie,YIo),e(sv,KIo),e(sv,IN),e(IN,ZIo),e(sv,ejo),e(Ce,ojo),e(Ce,lv),e(lv,Mie),e(Mie,rjo),e(lv,tjo),e(lv,jN),e(jN,ajo),e(lv,njo),e(He,sjo),e(He,iv),e(iv,ljo),e(iv,Eie),e(Eie,ijo),e(iv,djo),e(iv,yie),e(yie,cjo),e(He,fjo),e(He,wie),e(wie,mjo),e(He,gjo),g(p3,He,null),b(d,Bke,u),b(d,qd,u),e(qd,dv),e(dv,Aie),g(_3,Aie,null),e(qd,hjo),e(qd,Lie),e(Lie,pjo),b(d,xke,u),b(d,dr,u),g(u3,dr,null),e(dr,_jo),e(dr,Od),e(Od,ujo),e(Od,Bie),e(Bie,bjo),e(Od,vjo),e(Od,xie),e(xie,Tjo),e(Od,Fjo),e(dr,Cjo),e(dr,b3),e(b3,Mjo),e(b3,kie),e(kie,Ejo),e(b3,yjo),e(dr,wjo),e(dr,at),g(v3,at,null),e(at,Ajo),e(at,Rie),e(Rie,Ljo),e(at,Bjo),e(at,Gd),e(Gd,xjo),e(Gd,Sie),e(Sie,kjo),e(Gd,Rjo),e(Gd,Pie),e(Pie,Sjo),e(Gd,Pjo),e(at,$jo),e(at,$ie),e($ie,Ijo),e(at,jjo),g(T3,at,null),e(dr,Djo),e(dr,Ue),g(F3,Ue,null),e(Ue,Njo),e(Ue,Iie),e(Iie,qjo),e(Ue,Ojo),e(Ue,sn),e(sn,Gjo),e(sn,jie),e(jie,Xjo),e(sn,Vjo),e(sn,Die),e(Die,zjo),e(sn,Wjo),e(sn,Nie),e(Nie,Qjo),e(sn,Hjo),e(Ue,Ujo),e(Ue,qie),e(qie,cv),e(cv,Oie),e(Oie,Jjo),e(cv,Yjo),e(cv,DN),e(DN,Kjo),e(cv,Zjo),e(Ue,eDo),e(Ue,fv),e(fv,oDo),e(fv,Gie),e(Gie,rDo),e(fv,tDo),e(fv,Xie),e(Xie,aDo),e(Ue,nDo),e(Ue,Vie),e(Vie,sDo),e(Ue,lDo),g(C3,Ue,null),b(d,kke,u),b(d,Xd,u),e(Xd,mv),e(mv,zie),g(M3,zie,null),e(Xd,iDo),e(Xd,Wie),e(Wie,dDo),b(d,Rke,u),b(d,cr,u),g(E3,cr,null),e(cr,cDo),e(cr,Vd),e(Vd,fDo),e(Vd,Qie),e(Qie,mDo),e(Vd,gDo),e(Vd,Hie),e(Hie,hDo),e(Vd,pDo),e(cr,_Do),e(cr,y3),e(y3,uDo),e(y3,Uie),e(Uie,bDo),e(y3,vDo),e(cr,TDo),e(cr,nt),g(w3,nt,null),e(nt,FDo),e(nt,Jie),e(Jie,CDo),e(nt,MDo),e(nt,zd),e(zd,EDo),e(zd,Yie),e(Yie,yDo),e(zd,wDo),e(zd,Kie),e(Kie,ADo),e(zd,LDo),e(nt,BDo),e(nt,Zie),e(Zie,xDo),e(nt,kDo),g(A3,nt,null),e(cr,RDo),e(cr,Je),g(L3,Je,null),e(Je,SDo),e(Je,ede),e(ede,PDo),e(Je,$Do),e(Je,ln),e(ln,IDo),e(ln,ode),e(ode,jDo),e(ln,DDo),e(ln,rde),e(rde,NDo),e(ln,qDo),e(ln,tde),e(tde,ODo),e(ln,GDo),e(Je,XDo),e(Je,xe),e(xe,gv),e(gv,ade),e(ade,VDo),e(gv,zDo),e(gv,NN),e(NN,WDo),e(gv,QDo),e(xe,HDo),e(xe,hv),e(hv,nde),e(nde,UDo),e(hv,JDo),e(hv,qN),e(qN,YDo),e(hv,KDo),e(xe,ZDo),e(xe,pv),e(pv,sde),e(sde,eNo),e(pv,oNo),e(pv,ON),e(ON,rNo),e(pv,tNo),e(xe,aNo),e(xe,_v),e(_v,lde),e(lde,nNo),e(_v,sNo),e(_v,GN),e(GN,lNo),e(_v,iNo),e(xe,dNo),e(xe,uv),e(uv,ide),e(ide,cNo),e(uv,fNo),e(uv,XN),e(XN,mNo),e(uv,gNo),e(xe,hNo),e(xe,bv),e(bv,dde),e(dde,pNo),e(bv,_No),e(bv,VN),e(VN,uNo),e(bv,bNo),e(xe,vNo),e(xe,vv),e(vv,cde),e(cde,TNo),e(vv,FNo),e(vv,zN),e(zN,CNo),e(vv,MNo),e(xe,ENo),e(xe,Tv),e(Tv,fde),e(fde,yNo),e(Tv,wNo),e(Tv,WN),e(WN,ANo),e(Tv,LNo),e(Je,BNo),e(Je,Fv),e(Fv,xNo),e(Fv,mde),e(mde,kNo),e(Fv,RNo),e(Fv,gde),e(gde,SNo),e(Je,PNo),e(Je,hde),e(hde,$No),e(Je,INo),g(B3,Je,null),b(d,Ske,u),b(d,Wd,u),e(Wd,Cv),e(Cv,pde),g(x3,pde,null),e(Wd,jNo),e(Wd,_de),e(_de,DNo),b(d,Pke,u),b(d,fr,u),g(k3,fr,null),e(fr,NNo),e(fr,Qd),e(Qd,qNo),e(Qd,ude),e(ude,ONo),e(Qd,GNo),e(Qd,bde),e(bde,XNo),e(Qd,VNo),e(fr,zNo),e(fr,R3),e(R3,WNo),e(R3,vde),e(vde,QNo),e(R3,HNo),e(fr,UNo),e(fr,st),g(S3,st,null),e(st,JNo),e(st,Tde),e(Tde,YNo),e(st,KNo),e(st,Hd),e(Hd,ZNo),e(Hd,Fde),e(Fde,eqo),e(Hd,oqo),e(Hd,Cde),e(Cde,rqo),e(Hd,tqo),e(st,aqo),e(st,Mde),e(Mde,nqo),e(st,sqo),g(P3,st,null),e(fr,lqo),e(fr,Ye),g($3,Ye,null),e(Ye,iqo),e(Ye,Ede),e(Ede,dqo),e(Ye,cqo),e(Ye,dn),e(dn,fqo),e(dn,yde),e(yde,mqo),e(dn,gqo),e(dn,wde),e(wde,hqo),e(dn,pqo),e(dn,Ade),e(Ade,_qo),e(dn,uqo),e(Ye,bqo),e(Ye,cn),e(cn,Mv),e(Mv,Lde),e(Lde,vqo),e(Mv,Tqo),e(Mv,QN),e(QN,Fqo),e(Mv,Cqo),e(cn,Mqo),e(cn,Ev),e(Ev,Bde),e(Bde,Eqo),e(Ev,yqo),e(Ev,HN),e(HN,wqo),e(Ev,Aqo),e(cn,Lqo),e(cn,yv),e(yv,xde),e(xde,Bqo),e(yv,xqo),e(yv,UN),e(UN,kqo),e(yv,Rqo),e(cn,Sqo),e(cn,wv),e(wv,kde),e(kde,Pqo),e(wv,$qo),e(wv,JN),e(JN,Iqo),e(wv,jqo),e(Ye,Dqo),e(Ye,Av),e(Av,Nqo),e(Av,Rde),e(Rde,qqo),e(Av,Oqo),e(Av,Sde),e(Sde,Gqo),e(Ye,Xqo),e(Ye,Pde),e(Pde,Vqo),e(Ye,zqo),g(I3,Ye,null),b(d,$ke,u),b(d,Ud,u),e(Ud,Lv),e(Lv,$de),g(j3,$de,null),e(Ud,Wqo),e(Ud,Ide),e(Ide,Qqo),b(d,Ike,u),b(d,mr,u),g(D3,mr,null),e(mr,Hqo),e(mr,Jd),e(Jd,Uqo),e(Jd,jde),e(jde,Jqo),e(Jd,Yqo),e(Jd,Dde),e(Dde,Kqo),e(Jd,Zqo),e(mr,eOo),e(mr,N3),e(N3,oOo),e(N3,Nde),e(Nde,rOo),e(N3,tOo),e(mr,aOo),e(mr,lt),g(q3,lt,null),e(lt,nOo),e(lt,qde),e(qde,sOo),e(lt,lOo),e(lt,Yd),e(Yd,iOo),e(Yd,Ode),e(Ode,dOo),e(Yd,cOo),e(Yd,Gde),e(Gde,fOo),e(Yd,mOo),e(lt,gOo),e(lt,Xde),e(Xde,hOo),e(lt,pOo),g(O3,lt,null),e(mr,_Oo),e(mr,Ke),g(G3,Ke,null),e(Ke,uOo),e(Ke,Vde),e(Vde,bOo),e(Ke,vOo),e(Ke,fn),e(fn,TOo),e(fn,zde),e(zde,FOo),e(fn,COo),e(fn,Wde),e(Wde,MOo),e(fn,EOo),e(fn,Qde),e(Qde,yOo),e(fn,wOo),e(Ke,AOo),e(Ke,ke),e(ke,Bv),e(Bv,Hde),e(Hde,LOo),e(Bv,BOo),e(Bv,YN),e(YN,xOo),e(Bv,kOo),e(ke,ROo),e(ke,xv),e(xv,Ude),e(Ude,SOo),e(xv,POo),e(xv,KN),e(KN,$Oo),e(xv,IOo),e(ke,jOo),e(ke,kv),e(kv,Jde),e(Jde,DOo),e(kv,NOo),e(kv,ZN),e(ZN,qOo),e(kv,OOo),e(ke,GOo),e(ke,Rv),e(Rv,Yde),e(Yde,XOo),e(Rv,VOo),e(Rv,eq),e(eq,zOo),e(Rv,WOo),e(ke,QOo),e(ke,Sv),e(Sv,Kde),e(Kde,HOo),e(Sv,UOo),e(Sv,oq),e(oq,JOo),e(Sv,YOo),e(ke,KOo),e(ke,Pv),e(Pv,Zde),e(Zde,ZOo),e(Pv,eGo),e(Pv,rq),e(rq,oGo),e(Pv,rGo),e(ke,tGo),e(ke,$v),e($v,ece),e(ece,aGo),e($v,nGo),e($v,tq),e(tq,sGo),e($v,lGo),e(ke,iGo),e(ke,Iv),e(Iv,oce),e(oce,dGo),e(Iv,cGo),e(Iv,aq),e(aq,fGo),e(Iv,mGo),e(Ke,gGo),e(Ke,jv),e(jv,hGo),e(jv,rce),e(rce,pGo),e(jv,_Go),e(jv,tce),e(tce,uGo),e(Ke,bGo),e(Ke,ace),e(ace,vGo),e(Ke,TGo),g(X3,Ke,null),b(d,jke,u),b(d,Kd,u),e(Kd,Dv),e(Dv,nce),g(V3,nce,null),e(Kd,FGo),e(Kd,sce),e(sce,CGo),b(d,Dke,u),b(d,gr,u),g(z3,gr,null),e(gr,MGo),e(gr,Zd),e(Zd,EGo),e(Zd,lce),e(lce,yGo),e(Zd,wGo),e(Zd,ice),e(ice,AGo),e(Zd,LGo),e(gr,BGo),e(gr,W3),e(W3,xGo),e(W3,dce),e(dce,kGo),e(W3,RGo),e(gr,SGo),e(gr,it),g(Q3,it,null),e(it,PGo),e(it,cce),e(cce,$Go),e(it,IGo),e(it,ec),e(ec,jGo),e(ec,fce),e(fce,DGo),e(ec,NGo),e(ec,mce),e(mce,qGo),e(ec,OGo),e(it,GGo),e(it,gce),e(gce,XGo),e(it,VGo),g(H3,it,null),e(gr,zGo),e(gr,Ze),g(U3,Ze,null),e(Ze,WGo),e(Ze,hce),e(hce,QGo),e(Ze,HGo),e(Ze,mn),e(mn,UGo),e(mn,pce),e(pce,JGo),e(mn,YGo),e(mn,_ce),e(_ce,KGo),e(mn,ZGo),e(mn,uce),e(uce,eXo),e(mn,oXo),e(Ze,rXo),e(Ze,J3),e(J3,Nv),e(Nv,bce),e(bce,tXo),e(Nv,aXo),e(Nv,nq),e(nq,nXo),e(Nv,sXo),e(J3,lXo),e(J3,qv),e(qv,vce),e(vce,iXo),e(qv,dXo),e(qv,sq),e(sq,cXo),e(qv,fXo),e(Ze,mXo),e(Ze,Ov),e(Ov,gXo),e(Ov,Tce),e(Tce,hXo),e(Ov,pXo),e(Ov,Fce),e(Fce,_Xo),e(Ze,uXo),e(Ze,Cce),e(Cce,bXo),e(Ze,vXo),g(Y3,Ze,null),b(d,Nke,u),b(d,oc,u),e(oc,Gv),e(Gv,Mce),g(K3,Mce,null),e(oc,TXo),e(oc,Ece),e(Ece,FXo),b(d,qke,u),b(d,hr,u),g(Z3,hr,null),e(hr,CXo),e(hr,rc),e(rc,MXo),e(rc,yce),e(yce,EXo),e(rc,yXo),e(rc,wce),e(wce,wXo),e(rc,AXo),e(hr,LXo),e(hr,ey),e(ey,BXo),e(ey,Ace),e(Ace,xXo),e(ey,kXo),e(hr,RXo),e(hr,dt),g(oy,dt,null),e(dt,SXo),e(dt,Lce),e(Lce,PXo),e(dt,$Xo),e(dt,tc),e(tc,IXo),e(tc,Bce),e(Bce,jXo),e(tc,DXo),e(tc,xce),e(xce,NXo),e(tc,qXo),e(dt,OXo),e(dt,kce),e(kce,GXo),e(dt,XXo),g(ry,dt,null),e(hr,VXo),e(hr,eo),g(ty,eo,null),e(eo,zXo),e(eo,Rce),e(Rce,WXo),e(eo,QXo),e(eo,gn),e(gn,HXo),e(gn,Sce),e(Sce,UXo),e(gn,JXo),e(gn,Pce),e(Pce,YXo),e(gn,KXo),e(gn,$ce),e($ce,ZXo),e(gn,eVo),e(eo,oVo),e(eo,hn),e(hn,Xv),e(Xv,Ice),e(Ice,rVo),e(Xv,tVo),e(Xv,lq),e(lq,aVo),e(Xv,nVo),e(hn,sVo),e(hn,Vv),e(Vv,jce),e(jce,lVo),e(Vv,iVo),e(Vv,iq),e(iq,dVo),e(Vv,cVo),e(hn,fVo),e(hn,zv),e(zv,Dce),e(Dce,mVo),e(zv,gVo),e(zv,dq),e(dq,hVo),e(zv,pVo),e(hn,_Vo),e(hn,Wv),e(Wv,Nce),e(Nce,uVo),e(Wv,bVo),e(Wv,cq),e(cq,vVo),e(Wv,TVo),e(eo,FVo),e(eo,Qv),e(Qv,CVo),e(Qv,qce),e(qce,MVo),e(Qv,EVo),e(Qv,Oce),e(Oce,yVo),e(eo,wVo),e(eo,Gce),e(Gce,AVo),e(eo,LVo),g(ay,eo,null),b(d,Oke,u),b(d,ac,u),e(ac,Hv),e(Hv,Xce),g(ny,Xce,null),e(ac,BVo),e(ac,Vce),e(Vce,xVo),b(d,Gke,u),b(d,pr,u),g(sy,pr,null),e(pr,kVo),e(pr,nc),e(nc,RVo),e(nc,zce),e(zce,SVo),e(nc,PVo),e(nc,Wce),e(Wce,$Vo),e(nc,IVo),e(pr,jVo),e(pr,ly),e(ly,DVo),e(ly,Qce),e(Qce,NVo),e(ly,qVo),e(pr,OVo),e(pr,ct),g(iy,ct,null),e(ct,GVo),e(ct,Hce),e(Hce,XVo),e(ct,VVo),e(ct,sc),e(sc,zVo),e(sc,Uce),e(Uce,WVo),e(sc,QVo),e(sc,Jce),e(Jce,HVo),e(sc,UVo),e(ct,JVo),e(ct,Yce),e(Yce,YVo),e(ct,KVo),g(dy,ct,null),e(pr,ZVo),e(pr,oo),g(cy,oo,null),e(oo,ezo),e(oo,Kce),e(Kce,ozo),e(oo,rzo),e(oo,pn),e(pn,tzo),e(pn,Zce),e(Zce,azo),e(pn,nzo),e(pn,efe),e(efe,szo),e(pn,lzo),e(pn,ofe),e(ofe,izo),e(pn,dzo),e(oo,czo),e(oo,lc),e(lc,Uv),e(Uv,rfe),e(rfe,fzo),e(Uv,mzo),e(Uv,fq),e(fq,gzo),e(Uv,hzo),e(lc,pzo),e(lc,Jv),e(Jv,tfe),e(tfe,_zo),e(Jv,uzo),e(Jv,mq),e(mq,bzo),e(Jv,vzo),e(lc,Tzo),e(lc,Yv),e(Yv,afe),e(afe,Fzo),e(Yv,Czo),e(Yv,gq),e(gq,Mzo),e(Yv,Ezo),e(oo,yzo),e(oo,Kv),e(Kv,wzo),e(Kv,nfe),e(nfe,Azo),e(Kv,Lzo),e(Kv,sfe),e(sfe,Bzo),e(oo,xzo),e(oo,lfe),e(lfe,kzo),e(oo,Rzo),g(fy,oo,null),b(d,Xke,u),b(d,ic,u),e(ic,Zv),e(Zv,ife),g(my,ife,null),e(ic,Szo),e(ic,dfe),e(dfe,Pzo),b(d,Vke,u),b(d,_r,u),g(gy,_r,null),e(_r,$zo),e(_r,dc),e(dc,Izo),e(dc,cfe),e(cfe,jzo),e(dc,Dzo),e(dc,ffe),e(ffe,Nzo),e(dc,qzo),e(_r,Ozo),e(_r,hy),e(hy,Gzo),e(hy,mfe),e(mfe,Xzo),e(hy,Vzo),e(_r,zzo),e(_r,ft),g(py,ft,null),e(ft,Wzo),e(ft,gfe),e(gfe,Qzo),e(ft,Hzo),e(ft,cc),e(cc,Uzo),e(cc,hfe),e(hfe,Jzo),e(cc,Yzo),e(cc,pfe),e(pfe,Kzo),e(cc,Zzo),e(ft,eWo),e(ft,_fe),e(_fe,oWo),e(ft,rWo),g(_y,ft,null),e(_r,tWo),e(_r,ro),g(uy,ro,null),e(ro,aWo),e(ro,ufe),e(ufe,nWo),e(ro,sWo),e(ro,_n),e(_n,lWo),e(_n,bfe),e(bfe,iWo),e(_n,dWo),e(_n,vfe),e(vfe,cWo),e(_n,fWo),e(_n,Tfe),e(Tfe,mWo),e(_n,gWo),e(ro,hWo),e(ro,Ffe),e(Ffe,e6),e(e6,Cfe),e(Cfe,pWo),e(e6,_Wo),e(e6,hq),e(hq,uWo),e(e6,bWo),e(ro,vWo),e(ro,o6),e(o6,TWo),e(o6,Mfe),e(Mfe,FWo),e(o6,CWo),e(o6,Efe),e(Efe,MWo),e(ro,EWo),e(ro,yfe),e(yfe,yWo),e(ro,wWo),g(by,ro,null),b(d,zke,u),b(d,fc,u),e(fc,r6),e(r6,wfe),g(vy,wfe,null),e(fc,AWo),e(fc,Afe),e(Afe,LWo),b(d,Wke,u),b(d,ur,u),g(Ty,ur,null),e(ur,BWo),e(ur,mc),e(mc,xWo),e(mc,Lfe),e(Lfe,kWo),e(mc,RWo),e(mc,Bfe),e(Bfe,SWo),e(mc,PWo),e(ur,$Wo),e(ur,Fy),e(Fy,IWo),e(Fy,xfe),e(xfe,jWo),e(Fy,DWo),e(ur,NWo),e(ur,mt),g(Cy,mt,null),e(mt,qWo),e(mt,kfe),e(kfe,OWo),e(mt,GWo),e(mt,gc),e(gc,XWo),e(gc,Rfe),e(Rfe,VWo),e(gc,zWo),e(gc,Sfe),e(Sfe,WWo),e(gc,QWo),e(mt,HWo),e(mt,Pfe),e(Pfe,UWo),e(mt,JWo),g(My,mt,null),e(ur,YWo),e(ur,to),g(Ey,to,null),e(to,KWo),e(to,$fe),e($fe,ZWo),e(to,eQo),e(to,un),e(un,oQo),e(un,Ife),e(Ife,rQo),e(un,tQo),e(un,jfe),e(jfe,aQo),e(un,nQo),e(un,Dfe),e(Dfe,sQo),e(un,lQo),e(to,iQo),e(to,Nfe),e(Nfe,t6),e(t6,qfe),e(qfe,dQo),e(t6,cQo),e(t6,pq),e(pq,fQo),e(t6,mQo),e(to,gQo),e(to,a6),e(a6,hQo),e(a6,Ofe),e(Ofe,pQo),e(a6,_Qo),e(a6,Gfe),e(Gfe,uQo),e(to,bQo),e(to,Xfe),e(Xfe,vQo),e(to,TQo),g(yy,to,null),b(d,Qke,u),b(d,hc,u),e(hc,n6),e(n6,Vfe),g(wy,Vfe,null),e(hc,FQo),e(hc,zfe),e(zfe,CQo),b(d,Hke,u),b(d,br,u),g(Ay,br,null),e(br,MQo),e(br,pc),e(pc,EQo),e(pc,Wfe),e(Wfe,yQo),e(pc,wQo),e(pc,Qfe),e(Qfe,AQo),e(pc,LQo),e(br,BQo),e(br,Ly),e(Ly,xQo),e(Ly,Hfe),e(Hfe,kQo),e(Ly,RQo),e(br,SQo),e(br,gt),g(By,gt,null),e(gt,PQo),e(gt,Ufe),e(Ufe,$Qo),e(gt,IQo),e(gt,_c),e(_c,jQo),e(_c,Jfe),e(Jfe,DQo),e(_c,NQo),e(_c,Yfe),e(Yfe,qQo),e(_c,OQo),e(gt,GQo),e(gt,Kfe),e(Kfe,XQo),e(gt,VQo),g(xy,gt,null),e(br,zQo),e(br,ao),g(ky,ao,null),e(ao,WQo),e(ao,Zfe),e(Zfe,QQo),e(ao,HQo),e(ao,bn),e(bn,UQo),e(bn,eme),e(eme,JQo),e(bn,YQo),e(bn,ome),e(ome,KQo),e(bn,ZQo),e(bn,rme),e(rme,eHo),e(bn,oHo),e(ao,rHo),e(ao,Ry),e(Ry,s6),e(s6,tme),e(tme,tHo),e(s6,aHo),e(s6,_q),e(_q,nHo),e(s6,sHo),e(Ry,lHo),e(Ry,l6),e(l6,ame),e(ame,iHo),e(l6,dHo),e(l6,uq),e(uq,cHo),e(l6,fHo),e(ao,mHo),e(ao,i6),e(i6,gHo),e(i6,nme),e(nme,hHo),e(i6,pHo),e(i6,sme),e(sme,_Ho),e(ao,uHo),e(ao,lme),e(lme,bHo),e(ao,vHo),g(Sy,ao,null),b(d,Uke,u),b(d,uc,u),e(uc,d6),e(d6,ime),g(Py,ime,null),e(uc,THo),e(uc,dme),e(dme,FHo),b(d,Jke,u),b(d,vr,u),g($y,vr,null),e(vr,CHo),e(vr,bc),e(bc,MHo),e(bc,cme),e(cme,EHo),e(bc,yHo),e(bc,fme),e(fme,wHo),e(bc,AHo),e(vr,LHo),e(vr,Iy),e(Iy,BHo),e(Iy,mme),e(mme,xHo),e(Iy,kHo),e(vr,RHo),e(vr,ht),g(jy,ht,null),e(ht,SHo),e(ht,gme),e(gme,PHo),e(ht,$Ho),e(ht,vc),e(vc,IHo),e(vc,hme),e(hme,jHo),e(vc,DHo),e(vc,pme),e(pme,NHo),e(vc,qHo),e(ht,OHo),e(ht,_me),e(_me,GHo),e(ht,XHo),g(Dy,ht,null),e(vr,VHo),e(vr,no),g(Ny,no,null),e(no,zHo),e(no,ume),e(ume,WHo),e(no,QHo),e(no,vn),e(vn,HHo),e(vn,bme),e(bme,UHo),e(vn,JHo),e(vn,vme),e(vme,YHo),e(vn,KHo),e(vn,Tme),e(Tme,ZHo),e(vn,eUo),e(no,oUo),e(no,Fme),e(Fme,c6),e(c6,Cme),e(Cme,rUo),e(c6,tUo),e(c6,bq),e(bq,aUo),e(c6,nUo),e(no,sUo),e(no,f6),e(f6,lUo),e(f6,Mme),e(Mme,iUo),e(f6,dUo),e(f6,Eme),e(Eme,cUo),e(no,fUo),e(no,yme),e(yme,mUo),e(no,gUo),g(qy,no,null),b(d,Yke,u),b(d,Tc,u),e(Tc,m6),e(m6,wme),g(Oy,wme,null),e(Tc,hUo),e(Tc,Ame),e(Ame,pUo),b(d,Kke,u),b(d,Tr,u),g(Gy,Tr,null),e(Tr,_Uo),e(Tr,Fc),e(Fc,uUo),e(Fc,Lme),e(Lme,bUo),e(Fc,vUo),e(Fc,Bme),e(Bme,TUo),e(Fc,FUo),e(Tr,CUo),e(Tr,Xy),e(Xy,MUo),e(Xy,xme),e(xme,EUo),e(Xy,yUo),e(Tr,wUo),e(Tr,pt),g(Vy,pt,null),e(pt,AUo),e(pt,kme),e(kme,LUo),e(pt,BUo),e(pt,Cc),e(Cc,xUo),e(Cc,Rme),e(Rme,kUo),e(Cc,RUo),e(Cc,Sme),e(Sme,SUo),e(Cc,PUo),e(pt,$Uo),e(pt,Pme),e(Pme,IUo),e(pt,jUo),g(zy,pt,null),e(Tr,DUo),e(Tr,ho),g(Wy,ho,null),e(ho,NUo),e(ho,$me),e($me,qUo),e(ho,OUo),e(ho,Tn),e(Tn,GUo),e(Tn,Ime),e(Ime,XUo),e(Tn,VUo),e(Tn,jme),e(jme,zUo),e(Tn,WUo),e(Tn,Dme),e(Dme,QUo),e(Tn,HUo),e(ho,UUo),e(ho,B),e(B,g6),e(g6,Nme),e(Nme,JUo),e(g6,YUo),e(g6,vq),e(vq,KUo),e(g6,ZUo),e(B,eJo),e(B,h6),e(h6,qme),e(qme,oJo),e(h6,rJo),e(h6,Tq),e(Tq,tJo),e(h6,aJo),e(B,nJo),e(B,p6),e(p6,Ome),e(Ome,sJo),e(p6,lJo),e(p6,Fq),e(Fq,iJo),e(p6,dJo),e(B,cJo),e(B,_6),e(_6,Gme),e(Gme,fJo),e(_6,mJo),e(_6,Cq),e(Cq,gJo),e(_6,hJo),e(B,pJo),e(B,u6),e(u6,Xme),e(Xme,_Jo),e(u6,uJo),e(u6,Mq),e(Mq,bJo),e(u6,vJo),e(B,TJo),e(B,b6),e(b6,Vme),e(Vme,FJo),e(b6,CJo),e(b6,Eq),e(Eq,MJo),e(b6,EJo),e(B,yJo),e(B,v6),e(v6,zme),e(zme,wJo),e(v6,AJo),e(v6,yq),e(yq,LJo),e(v6,BJo),e(B,xJo),e(B,T6),e(T6,Wme),e(Wme,kJo),e(T6,RJo),e(T6,wq),e(wq,SJo),e(T6,PJo),e(B,$Jo),e(B,F6),e(F6,Qme),e(Qme,IJo),e(F6,jJo),e(F6,Aq),e(Aq,DJo),e(F6,NJo),e(B,qJo),e(B,C6),e(C6,Hme),e(Hme,OJo),e(C6,GJo),e(C6,Lq),e(Lq,XJo),e(C6,VJo),e(B,zJo),e(B,M6),e(M6,Ume),e(Ume,WJo),e(M6,QJo),e(M6,Bq),e(Bq,HJo),e(M6,UJo),e(B,JJo),e(B,E6),e(E6,Jme),e(Jme,YJo),e(E6,KJo),e(E6,xq),e(xq,ZJo),e(E6,eYo),e(B,oYo),e(B,y6),e(y6,Yme),e(Yme,rYo),e(y6,tYo),e(y6,kq),e(kq,aYo),e(y6,nYo),e(B,sYo),e(B,w6),e(w6,Kme),e(Kme,lYo),e(w6,iYo),e(w6,Rq),e(Rq,dYo),e(w6,cYo),e(B,fYo),e(B,A6),e(A6,Zme),e(Zme,mYo),e(A6,gYo),e(A6,Sq),e(Sq,hYo),e(A6,pYo),e(B,_Yo),e(B,L6),e(L6,ege),e(ege,uYo),e(L6,bYo),e(L6,Pq),e(Pq,vYo),e(L6,TYo),e(B,FYo),e(B,Ws),e(Ws,oge),e(oge,CYo),e(Ws,MYo),e(Ws,$q),e($q,EYo),e(Ws,yYo),e(Ws,Iq),e(Iq,wYo),e(Ws,AYo),e(B,LYo),e(B,B6),e(B6,rge),e(rge,BYo),e(B6,xYo),e(B6,jq),e(jq,kYo),e(B6,RYo),e(B,SYo),e(B,x6),e(x6,tge),e(tge,PYo),e(x6,$Yo),e(x6,Dq),e(Dq,IYo),e(x6,jYo),e(B,DYo),e(B,k6),e(k6,age),e(age,NYo),e(k6,qYo),e(k6,Nq),e(Nq,OYo),e(k6,GYo),e(B,XYo),e(B,R6),e(R6,nge),e(nge,VYo),e(R6,zYo),e(R6,qq),e(qq,WYo),e(R6,QYo),e(B,HYo),e(B,S6),e(S6,sge),e(sge,UYo),e(S6,JYo),e(S6,Oq),e(Oq,YYo),e(S6,KYo),e(B,ZYo),e(B,P6),e(P6,lge),e(lge,eKo),e(P6,oKo),e(P6,Gq),e(Gq,rKo),e(P6,tKo),e(B,aKo),e(B,$6),e($6,ige),e(ige,nKo),e($6,sKo),e($6,Xq),e(Xq,lKo),e($6,iKo),e(B,dKo),e(B,I6),e(I6,dge),e(dge,cKo),e(I6,fKo),e(I6,Vq),e(Vq,mKo),e(I6,gKo),e(B,hKo),e(B,j6),e(j6,cge),e(cge,pKo),e(j6,_Ko),e(j6,zq),e(zq,uKo),e(j6,bKo),e(B,vKo),e(B,D6),e(D6,fge),e(fge,TKo),e(D6,FKo),e(D6,Wq),e(Wq,CKo),e(D6,MKo),e(B,EKo),e(B,N6),e(N6,mge),e(mge,yKo),e(N6,wKo),e(N6,Qq),e(Qq,AKo),e(N6,LKo),e(B,BKo),e(B,q6),e(q6,gge),e(gge,xKo),e(q6,kKo),e(q6,Hq),e(Hq,RKo),e(q6,SKo),e(B,PKo),e(B,O6),e(O6,hge),e(hge,$Ko),e(O6,IKo),e(O6,Uq),e(Uq,jKo),e(O6,DKo),e(B,NKo),e(B,G6),e(G6,pge),e(pge,qKo),e(G6,OKo),e(G6,Jq),e(Jq,GKo),e(G6,XKo),e(B,VKo),e(B,X6),e(X6,_ge),e(_ge,zKo),e(X6,WKo),e(X6,Yq),e(Yq,QKo),e(X6,HKo),e(B,UKo),e(B,V6),e(V6,uge),e(uge,JKo),e(V6,YKo),e(V6,Kq),e(Kq,KKo),e(V6,ZKo),e(B,eZo),e(B,z6),e(z6,bge),e(bge,oZo),e(z6,rZo),e(z6,Zq),e(Zq,tZo),e(z6,aZo),e(B,nZo),e(B,W6),e(W6,vge),e(vge,sZo),e(W6,lZo),e(W6,eO),e(eO,iZo),e(W6,dZo),e(B,cZo),e(B,Q6),e(Q6,Tge),e(Tge,fZo),e(Q6,mZo),e(Q6,oO),e(oO,gZo),e(Q6,hZo),e(B,pZo),e(B,H6),e(H6,Fge),e(Fge,_Zo),e(H6,uZo),e(H6,rO),e(rO,bZo),e(H6,vZo),e(B,TZo),e(B,U6),e(U6,Cge),e(Cge,FZo),e(U6,CZo),e(U6,tO),e(tO,MZo),e(U6,EZo),e(B,yZo),e(B,J6),e(J6,Mge),e(Mge,wZo),e(J6,AZo),e(J6,aO),e(aO,LZo),e(J6,BZo),e(B,xZo),e(B,Y6),e(Y6,Ege),e(Ege,kZo),e(Y6,RZo),e(Y6,nO),e(nO,SZo),e(Y6,PZo),e(B,$Zo),e(B,K6),e(K6,yge),e(yge,IZo),e(K6,jZo),e(K6,sO),e(sO,DZo),e(K6,NZo),e(B,qZo),e(B,Z6),e(Z6,wge),e(wge,OZo),e(Z6,GZo),e(Z6,lO),e(lO,XZo),e(Z6,VZo),e(ho,zZo),e(ho,Age),e(Age,WZo),e(ho,QZo),g(Qy,ho,null),b(d,Zke,u),b(d,Mc,u),e(Mc,e0),e(e0,Lge),g(Hy,Lge,null),e(Mc,HZo),e(Mc,Bge),e(Bge,UZo),b(d,eRe,u),b(d,Fr,u),g(Uy,Fr,null),e(Fr,JZo),e(Fr,Ec),e(Ec,YZo),e(Ec,xge),e(xge,KZo),e(Ec,ZZo),e(Ec,kge),e(kge,eer),e(Ec,oer),e(Fr,rer),e(Fr,Jy),e(Jy,ter),e(Jy,Rge),e(Rge,aer),e(Jy,ner),e(Fr,ser),e(Fr,_t),g(Yy,_t,null),e(_t,ler),e(_t,Sge),e(Sge,ier),e(_t,der),e(_t,yc),e(yc,cer),e(yc,Pge),e(Pge,fer),e(yc,mer),e(yc,$ge),e($ge,ger),e(yc,her),e(_t,per),e(_t,Ige),e(Ige,_er),e(_t,uer),g(Ky,_t,null),e(Fr,ber),e(Fr,po),g(Zy,po,null),e(po,ver),e(po,jge),e(jge,Ter),e(po,Fer),e(po,Fn),e(Fn,Cer),e(Fn,Dge),e(Dge,Mer),e(Fn,Eer),e(Fn,Nge),e(Nge,yer),e(Fn,wer),e(Fn,qge),e(qge,Aer),e(Fn,Ler),e(po,Ber),e(po,H),e(H,o0),e(o0,Oge),e(Oge,xer),e(o0,ker),e(o0,iO),e(iO,Rer),e(o0,Ser),e(H,Per),e(H,r0),e(r0,Gge),e(Gge,$er),e(r0,Ier),e(r0,dO),e(dO,jer),e(r0,Der),e(H,Ner),e(H,t0),e(t0,Xge),e(Xge,qer),e(t0,Oer),e(t0,cO),e(cO,Ger),e(t0,Xer),e(H,Ver),e(H,a0),e(a0,Vge),e(Vge,zer),e(a0,Wer),e(a0,fO),e(fO,Qer),e(a0,Her),e(H,Uer),e(H,n0),e(n0,zge),e(zge,Jer),e(n0,Yer),e(n0,mO),e(mO,Ker),e(n0,Zer),e(H,eor),e(H,s0),e(s0,Wge),e(Wge,oor),e(s0,ror),e(s0,gO),e(gO,tor),e(s0,aor),e(H,nor),e(H,l0),e(l0,Qge),e(Qge,sor),e(l0,lor),e(l0,hO),e(hO,ior),e(l0,dor),e(H,cor),e(H,i0),e(i0,Hge),e(Hge,mor),e(i0,gor),e(i0,pO),e(pO,hor),e(i0,por),e(H,_or),e(H,d0),e(d0,Uge),e(Uge,uor),e(d0,bor),e(d0,_O),e(_O,vor),e(d0,Tor),e(H,For),e(H,c0),e(c0,Jge),e(Jge,Cor),e(c0,Mor),e(c0,uO),e(uO,Eor),e(c0,yor),e(H,wor),e(H,f0),e(f0,Yge),e(Yge,Aor),e(f0,Lor),e(f0,bO),e(bO,Bor),e(f0,xor),e(H,kor),e(H,m0),e(m0,Kge),e(Kge,Ror),e(m0,Sor),e(m0,vO),e(vO,Por),e(m0,$or),e(H,Ior),e(H,g0),e(g0,Zge),e(Zge,jor),e(g0,Dor),e(g0,TO),e(TO,Nor),e(g0,qor),e(H,Oor),e(H,h0),e(h0,ehe),e(ehe,Gor),e(h0,Xor),e(h0,FO),e(FO,Vor),e(h0,zor),e(H,Wor),e(H,p0),e(p0,ohe),e(ohe,Qor),e(p0,Hor),e(p0,CO),e(CO,Uor),e(p0,Jor),e(H,Yor),e(H,_0),e(_0,rhe),e(rhe,Kor),e(_0,Zor),e(_0,MO),e(MO,err),e(_0,orr),e(H,rrr),e(H,u0),e(u0,the),e(the,trr),e(u0,arr),e(u0,EO),e(EO,nrr),e(u0,srr),e(H,lrr),e(H,b0),e(b0,ahe),e(ahe,irr),e(b0,drr),e(b0,yO),e(yO,crr),e(b0,frr),e(H,mrr),e(H,v0),e(v0,nhe),e(nhe,grr),e(v0,hrr),e(v0,wO),e(wO,prr),e(v0,_rr),e(H,urr),e(H,T0),e(T0,she),e(she,brr),e(T0,vrr),e(T0,AO),e(AO,Trr),e(T0,Frr),e(H,Crr),e(H,F0),e(F0,lhe),e(lhe,Mrr),e(F0,Err),e(F0,LO),e(LO,yrr),e(F0,wrr),e(H,Arr),e(H,C0),e(C0,ihe),e(ihe,Lrr),e(C0,Brr),e(C0,BO),e(BO,xrr),e(C0,krr),e(po,Rrr),e(po,dhe),e(dhe,Srr),e(po,Prr),g(ew,po,null),b(d,oRe,u),b(d,wc,u),e(wc,M0),e(M0,che),g(ow,che,null),e(wc,$rr),e(wc,fhe),e(fhe,Irr),b(d,rRe,u),b(d,Cr,u),g(rw,Cr,null),e(Cr,jrr),e(Cr,Ac),e(Ac,Drr),e(Ac,mhe),e(mhe,Nrr),e(Ac,qrr),e(Ac,ghe),e(ghe,Orr),e(Ac,Grr),e(Cr,Xrr),e(Cr,tw),e(tw,Vrr),e(tw,hhe),e(hhe,zrr),e(tw,Wrr),e(Cr,Qrr),e(Cr,ut),g(aw,ut,null),e(ut,Hrr),e(ut,phe),e(phe,Urr),e(ut,Jrr),e(ut,Lc),e(Lc,Yrr),e(Lc,_he),e(_he,Krr),e(Lc,Zrr),e(Lc,uhe),e(uhe,etr),e(Lc,otr),e(ut,rtr),e(ut,bhe),e(bhe,ttr),e(ut,atr),g(nw,ut,null),e(Cr,ntr),e(Cr,_o),g(sw,_o,null),e(_o,str),e(_o,vhe),e(vhe,ltr),e(_o,itr),e(_o,Cn),e(Cn,dtr),e(Cn,The),e(The,ctr),e(Cn,ftr),e(Cn,Fhe),e(Fhe,mtr),e(Cn,gtr),e(Cn,Che),e(Che,htr),e(Cn,ptr),e(_o,_tr),e(_o,me),e(me,E0),e(E0,Mhe),e(Mhe,utr),e(E0,btr),e(E0,xO),e(xO,vtr),e(E0,Ttr),e(me,Ftr),e(me,y0),e(y0,Ehe),e(Ehe,Ctr),e(y0,Mtr),e(y0,kO),e(kO,Etr),e(y0,ytr),e(me,wtr),e(me,w0),e(w0,yhe),e(yhe,Atr),e(w0,Ltr),e(w0,RO),e(RO,Btr),e(w0,xtr),e(me,ktr),e(me,A0),e(A0,whe),e(whe,Rtr),e(A0,Str),e(A0,SO),e(SO,Ptr),e(A0,$tr),e(me,Itr),e(me,L0),e(L0,Ahe),e(Ahe,jtr),e(L0,Dtr),e(L0,PO),e(PO,Ntr),e(L0,qtr),e(me,Otr),e(me,B0),e(B0,Lhe),e(Lhe,Gtr),e(B0,Xtr),e(B0,$O),e($O,Vtr),e(B0,ztr),e(me,Wtr),e(me,x0),e(x0,Bhe),e(Bhe,Qtr),e(x0,Htr),e(x0,IO),e(IO,Utr),e(x0,Jtr),e(me,Ytr),e(me,k0),e(k0,xhe),e(xhe,Ktr),e(k0,Ztr),e(k0,jO),e(jO,ear),e(k0,oar),e(me,rar),e(me,R0),e(R0,khe),e(khe,tar),e(R0,aar),e(R0,DO),e(DO,nar),e(R0,sar),e(me,lar),e(me,S0),e(S0,Rhe),e(Rhe,iar),e(S0,dar),e(S0,NO),e(NO,car),e(S0,far),e(me,mar),e(me,P0),e(P0,She),e(She,gar),e(P0,har),e(P0,qO),e(qO,par),e(P0,_ar),e(_o,uar),e(_o,Phe),e(Phe,bar),e(_o,Tar),g(lw,_o,null),b(d,tRe,u),b(d,Bc,u),e(Bc,$0),e($0,$he),g(iw,$he,null),e(Bc,Far),e(Bc,Ihe),e(Ihe,Car),b(d,aRe,u),b(d,Mr,u),g(dw,Mr,null),e(Mr,Mar),e(Mr,xc),e(xc,Ear),e(xc,jhe),e(jhe,yar),e(xc,war),e(xc,Dhe),e(Dhe,Aar),e(xc,Lar),e(Mr,Bar),e(Mr,cw),e(cw,xar),e(cw,Nhe),e(Nhe,kar),e(cw,Rar),e(Mr,Sar),e(Mr,bt),g(fw,bt,null),e(bt,Par),e(bt,qhe),e(qhe,$ar),e(bt,Iar),e(bt,kc),e(kc,jar),e(kc,Ohe),e(Ohe,Dar),e(kc,Nar),e(kc,Ghe),e(Ghe,qar),e(kc,Oar),e(bt,Gar),e(bt,Xhe),e(Xhe,Xar),e(bt,Var),g(mw,bt,null),e(Mr,zar),e(Mr,uo),g(gw,uo,null),e(uo,War),e(uo,Vhe),e(Vhe,Qar),e(uo,Har),e(uo,Mn),e(Mn,Uar),e(Mn,zhe),e(zhe,Jar),e(Mn,Yar),e(Mn,Whe),e(Whe,Kar),e(Mn,Zar),e(Mn,Qhe),e(Qhe,enr),e(Mn,onr),e(uo,rnr),e(uo,hw),e(hw,I0),e(I0,Hhe),e(Hhe,tnr),e(I0,anr),e(I0,OO),e(OO,nnr),e(I0,snr),e(hw,lnr),e(hw,j0),e(j0,Uhe),e(Uhe,inr),e(j0,dnr),e(j0,GO),e(GO,cnr),e(j0,fnr),e(uo,mnr),e(uo,Jhe),e(Jhe,gnr),e(uo,hnr),g(pw,uo,null),b(d,nRe,u),b(d,Rc,u),e(Rc,D0),e(D0,Yhe),g(_w,Yhe,null),e(Rc,pnr),e(Rc,Khe),e(Khe,_nr),b(d,sRe,u),b(d,Er,u),g(uw,Er,null),e(Er,unr),e(Er,Sc),e(Sc,bnr),e(Sc,Zhe),e(Zhe,vnr),e(Sc,Tnr),e(Sc,epe),e(epe,Fnr),e(Sc,Cnr),e(Er,Mnr),e(Er,bw),e(bw,Enr),e(bw,ope),e(ope,ynr),e(bw,wnr),e(Er,Anr),e(Er,vt),g(vw,vt,null),e(vt,Lnr),e(vt,rpe),e(rpe,Bnr),e(vt,xnr),e(vt,Pc),e(Pc,knr),e(Pc,tpe),e(tpe,Rnr),e(Pc,Snr),e(Pc,ape),e(ape,Pnr),e(Pc,$nr),e(vt,Inr),e(vt,npe),e(npe,jnr),e(vt,Dnr),g(Tw,vt,null),e(Er,Nnr),e(Er,bo),g(Fw,bo,null),e(bo,qnr),e(bo,spe),e(spe,Onr),e(bo,Gnr),e(bo,En),e(En,Xnr),e(En,lpe),e(lpe,Vnr),e(En,znr),e(En,ipe),e(ipe,Wnr),e(En,Qnr),e(En,dpe),e(dpe,Hnr),e(En,Unr),e(bo,Jnr),e(bo,Y),e(Y,N0),e(N0,cpe),e(cpe,Ynr),e(N0,Knr),e(N0,XO),e(XO,Znr),e(N0,esr),e(Y,osr),e(Y,q0),e(q0,fpe),e(fpe,rsr),e(q0,tsr),e(q0,VO),e(VO,asr),e(q0,nsr),e(Y,ssr),e(Y,O0),e(O0,mpe),e(mpe,lsr),e(O0,isr),e(O0,zO),e(zO,dsr),e(O0,csr),e(Y,fsr),e(Y,G0),e(G0,gpe),e(gpe,msr),e(G0,gsr),e(G0,WO),e(WO,hsr),e(G0,psr),e(Y,_sr),e(Y,X0),e(X0,hpe),e(hpe,usr),e(X0,bsr),e(X0,QO),e(QO,vsr),e(X0,Tsr),e(Y,Fsr),e(Y,V0),e(V0,ppe),e(ppe,Csr),e(V0,Msr),e(V0,HO),e(HO,Esr),e(V0,ysr),e(Y,wsr),e(Y,z0),e(z0,_pe),e(_pe,Asr),e(z0,Lsr),e(z0,UO),e(UO,Bsr),e(z0,xsr),e(Y,ksr),e(Y,W0),e(W0,upe),e(upe,Rsr),e(W0,Ssr),e(W0,JO),e(JO,Psr),e(W0,$sr),e(Y,Isr),e(Y,Q0),e(Q0,bpe),e(bpe,jsr),e(Q0,Dsr),e(Q0,YO),e(YO,Nsr),e(Q0,qsr),e(Y,Osr),e(Y,H0),e(H0,vpe),e(vpe,Gsr),e(H0,Xsr),e(H0,KO),e(KO,Vsr),e(H0,zsr),e(Y,Wsr),e(Y,U0),e(U0,Tpe),e(Tpe,Qsr),e(U0,Hsr),e(U0,ZO),e(ZO,Usr),e(U0,Jsr),e(Y,Ysr),e(Y,J0),e(J0,Fpe),e(Fpe,Ksr),e(J0,Zsr),e(J0,eG),e(eG,elr),e(J0,olr),e(Y,rlr),e(Y,Y0),e(Y0,Cpe),e(Cpe,tlr),e(Y0,alr),e(Y0,oG),e(oG,nlr),e(Y0,slr),e(Y,llr),e(Y,K0),e(K0,Mpe),e(Mpe,ilr),e(K0,dlr),e(K0,rG),e(rG,clr),e(K0,flr),e(Y,mlr),e(Y,Z0),e(Z0,Epe),e(Epe,glr),e(Z0,hlr),e(Z0,tG),e(tG,plr),e(Z0,_lr),e(Y,ulr),e(Y,eT),e(eT,ype),e(ype,blr),e(eT,vlr),e(eT,aG),e(aG,Tlr),e(eT,Flr),e(Y,Clr),e(Y,oT),e(oT,wpe),e(wpe,Mlr),e(oT,Elr),e(oT,nG),e(nG,ylr),e(oT,wlr),e(Y,Alr),e(Y,rT),e(rT,Ape),e(Ape,Llr),e(rT,Blr),e(rT,sG),e(sG,xlr),e(rT,klr),e(Y,Rlr),e(Y,tT),e(tT,Lpe),e(Lpe,Slr),e(tT,Plr),e(tT,lG),e(lG,$lr),e(tT,Ilr),e(Y,jlr),e(Y,aT),e(aT,Bpe),e(Bpe,Dlr),e(aT,Nlr),e(aT,iG),e(iG,qlr),e(aT,Olr),e(bo,Glr),e(bo,xpe),e(xpe,Xlr),e(bo,Vlr),g(Cw,bo,null),b(d,lRe,u),b(d,$c,u),e($c,nT),e(nT,kpe),g(Mw,kpe,null),e($c,zlr),e($c,Rpe),e(Rpe,Wlr),b(d,iRe,u),b(d,yr,u),g(Ew,yr,null),e(yr,Qlr),e(yr,Ic),e(Ic,Hlr),e(Ic,Spe),e(Spe,Ulr),e(Ic,Jlr),e(Ic,Ppe),e(Ppe,Ylr),e(Ic,Klr),e(yr,Zlr),e(yr,yw),e(yw,eir),e(yw,$pe),e($pe,oir),e(yw,rir),e(yr,tir),e(yr,Tt),g(ww,Tt,null),e(Tt,air),e(Tt,Ipe),e(Ipe,nir),e(Tt,sir),e(Tt,jc),e(jc,lir),e(jc,jpe),e(jpe,iir),e(jc,dir),e(jc,Dpe),e(Dpe,cir),e(jc,fir),e(Tt,mir),e(Tt,Npe),e(Npe,gir),e(Tt,hir),g(Aw,Tt,null),e(yr,pir),e(yr,vo),g(Lw,vo,null),e(vo,_ir),e(vo,qpe),e(qpe,uir),e(vo,bir),e(vo,yn),e(yn,vir),e(yn,Ope),e(Ope,Tir),e(yn,Fir),e(yn,Gpe),e(Gpe,Cir),e(yn,Mir),e(yn,Xpe),e(Xpe,Eir),e(yn,yir),e(vo,wir),e(vo,_e),e(_e,sT),e(sT,Vpe),e(Vpe,Air),e(sT,Lir),e(sT,dG),e(dG,Bir),e(sT,xir),e(_e,kir),e(_e,lT),e(lT,zpe),e(zpe,Rir),e(lT,Sir),e(lT,cG),e(cG,Pir),e(lT,$ir),e(_e,Iir),e(_e,iT),e(iT,Wpe),e(Wpe,jir),e(iT,Dir),e(iT,fG),e(fG,Nir),e(iT,qir),e(_e,Oir),e(_e,dT),e(dT,Qpe),e(Qpe,Gir),e(dT,Xir),e(dT,mG),e(mG,Vir),e(dT,zir),e(_e,Wir),e(_e,cT),e(cT,Hpe),e(Hpe,Qir),e(cT,Hir),e(cT,gG),e(gG,Uir),e(cT,Jir),e(_e,Yir),e(_e,fT),e(fT,Upe),e(Upe,Kir),e(fT,Zir),e(fT,hG),e(hG,edr),e(fT,odr),e(_e,rdr),e(_e,mT),e(mT,Jpe),e(Jpe,tdr),e(mT,adr),e(mT,pG),e(pG,ndr),e(mT,sdr),e(_e,ldr),e(_e,gT),e(gT,Ype),e(Ype,idr),e(gT,ddr),e(gT,_G),e(_G,cdr),e(gT,fdr),e(_e,mdr),e(_e,hT),e(hT,Kpe),e(Kpe,gdr),e(hT,hdr),e(hT,uG),e(uG,pdr),e(hT,_dr),e(_e,udr),e(_e,pT),e(pT,Zpe),e(Zpe,bdr),e(pT,vdr),e(pT,bG),e(bG,Tdr),e(pT,Fdr),e(vo,Cdr),e(vo,e_e),e(e_e,Mdr),e(vo,Edr),g(Bw,vo,null),b(d,dRe,u),b(d,Dc,u),e(Dc,_T),e(_T,o_e),g(xw,o_e,null),e(Dc,ydr),e(Dc,r_e),e(r_e,wdr),b(d,cRe,u),b(d,wr,u),g(kw,wr,null),e(wr,Adr),e(wr,Nc),e(Nc,Ldr),e(Nc,t_e),e(t_e,Bdr),e(Nc,xdr),e(Nc,a_e),e(a_e,kdr),e(Nc,Rdr),e(wr,Sdr),e(wr,Rw),e(Rw,Pdr),e(Rw,n_e),e(n_e,$dr),e(Rw,Idr),e(wr,jdr),e(wr,Ft),g(Sw,Ft,null),e(Ft,Ddr),e(Ft,s_e),e(s_e,Ndr),e(Ft,qdr),e(Ft,qc),e(qc,Odr),e(qc,l_e),e(l_e,Gdr),e(qc,Xdr),e(qc,i_e),e(i_e,Vdr),e(qc,zdr),e(Ft,Wdr),e(Ft,d_e),e(d_e,Qdr),e(Ft,Hdr),g(Pw,Ft,null),e(wr,Udr),e(wr,To),g($w,To,null),e(To,Jdr),e(To,c_e),e(c_e,Ydr),e(To,Kdr),e(To,wn),e(wn,Zdr),e(wn,f_e),e(f_e,ecr),e(wn,ocr),e(wn,m_e),e(m_e,rcr),e(wn,tcr),e(wn,g_e),e(g_e,acr),e(wn,ncr),e(To,scr),e(To,V),e(V,uT),e(uT,h_e),e(h_e,lcr),e(uT,icr),e(uT,vG),e(vG,dcr),e(uT,ccr),e(V,fcr),e(V,bT),e(bT,p_e),e(p_e,mcr),e(bT,gcr),e(bT,TG),e(TG,hcr),e(bT,pcr),e(V,_cr),e(V,vT),e(vT,__e),e(__e,ucr),e(vT,bcr),e(vT,FG),e(FG,vcr),e(vT,Tcr),e(V,Fcr),e(V,TT),e(TT,u_e),e(u_e,Ccr),e(TT,Mcr),e(TT,CG),e(CG,Ecr),e(TT,ycr),e(V,wcr),e(V,FT),e(FT,b_e),e(b_e,Acr),e(FT,Lcr),e(FT,MG),e(MG,Bcr),e(FT,xcr),e(V,kcr),e(V,CT),e(CT,v_e),e(v_e,Rcr),e(CT,Scr),e(CT,EG),e(EG,Pcr),e(CT,$cr),e(V,Icr),e(V,MT),e(MT,T_e),e(T_e,jcr),e(MT,Dcr),e(MT,yG),e(yG,Ncr),e(MT,qcr),e(V,Ocr),e(V,ET),e(ET,F_e),e(F_e,Gcr),e(ET,Xcr),e(ET,wG),e(wG,Vcr),e(ET,zcr),e(V,Wcr),e(V,yT),e(yT,C_e),e(C_e,Qcr),e(yT,Hcr),e(yT,AG),e(AG,Ucr),e(yT,Jcr),e(V,Ycr),e(V,wT),e(wT,M_e),e(M_e,Kcr),e(wT,Zcr),e(wT,LG),e(LG,efr),e(wT,ofr),e(V,rfr),e(V,AT),e(AT,E_e),e(E_e,tfr),e(AT,afr),e(AT,BG),e(BG,nfr),e(AT,sfr),e(V,lfr),e(V,LT),e(LT,y_e),e(y_e,ifr),e(LT,dfr),e(LT,xG),e(xG,cfr),e(LT,ffr),e(V,mfr),e(V,BT),e(BT,w_e),e(w_e,gfr),e(BT,hfr),e(BT,kG),e(kG,pfr),e(BT,_fr),e(V,ufr),e(V,xT),e(xT,A_e),e(A_e,bfr),e(xT,vfr),e(xT,RG),e(RG,Tfr),e(xT,Ffr),e(V,Cfr),e(V,kT),e(kT,L_e),e(L_e,Mfr),e(kT,Efr),e(kT,SG),e(SG,yfr),e(kT,wfr),e(V,Afr),e(V,RT),e(RT,B_e),e(B_e,Lfr),e(RT,Bfr),e(RT,PG),e(PG,xfr),e(RT,kfr),e(V,Rfr),e(V,ST),e(ST,x_e),e(x_e,Sfr),e(ST,Pfr),e(ST,$G),e($G,$fr),e(ST,Ifr),e(V,jfr),e(V,PT),e(PT,k_e),e(k_e,Dfr),e(PT,Nfr),e(PT,IG),e(IG,qfr),e(PT,Ofr),e(V,Gfr),e(V,$T),e($T,R_e),e(R_e,Xfr),e($T,Vfr),e($T,jG),e(jG,zfr),e($T,Wfr),e(V,Qfr),e(V,IT),e(IT,S_e),e(S_e,Hfr),e(IT,Ufr),e(IT,DG),e(DG,Jfr),e(IT,Yfr),e(V,Kfr),e(V,jT),e(jT,P_e),e(P_e,Zfr),e(jT,emr),e(jT,NG),e(NG,omr),e(jT,rmr),e(V,tmr),e(V,DT),e(DT,$_e),e($_e,amr),e(DT,nmr),e(DT,qG),e(qG,smr),e(DT,lmr),e(V,imr),e(V,NT),e(NT,I_e),e(I_e,dmr),e(NT,cmr),e(NT,OG),e(OG,fmr),e(NT,mmr),e(V,gmr),e(V,qT),e(qT,j_e),e(j_e,hmr),e(qT,pmr),e(qT,GG),e(GG,_mr),e(qT,umr),e(V,bmr),e(V,OT),e(OT,D_e),e(D_e,vmr),e(OT,Tmr),e(OT,XG),e(XG,Fmr),e(OT,Cmr),e(To,Mmr),e(To,N_e),e(N_e,Emr),e(To,ymr),g(Iw,To,null),b(d,fRe,u),b(d,Oc,u),e(Oc,GT),e(GT,q_e),g(jw,q_e,null),e(Oc,wmr),e(Oc,O_e),e(O_e,Amr),b(d,mRe,u),b(d,Ar,u),g(Dw,Ar,null),e(Ar,Lmr),e(Ar,Gc),e(Gc,Bmr),e(Gc,G_e),e(G_e,xmr),e(Gc,kmr),e(Gc,X_e),e(X_e,Rmr),e(Gc,Smr),e(Ar,Pmr),e(Ar,Nw),e(Nw,$mr),e(Nw,V_e),e(V_e,Imr),e(Nw,jmr),e(Ar,Dmr),e(Ar,Ct),g(qw,Ct,null),e(Ct,Nmr),e(Ct,z_e),e(z_e,qmr),e(Ct,Omr),e(Ct,Xc),e(Xc,Gmr),e(Xc,W_e),e(W_e,Xmr),e(Xc,Vmr),e(Xc,Q_e),e(Q_e,zmr),e(Xc,Wmr),e(Ct,Qmr),e(Ct,H_e),e(H_e,Hmr),e(Ct,Umr),g(Ow,Ct,null),e(Ar,Jmr),e(Ar,Fo),g(Gw,Fo,null),e(Fo,Ymr),e(Fo,U_e),e(U_e,Kmr),e(Fo,Zmr),e(Fo,An),e(An,egr),e(An,J_e),e(J_e,ogr),e(An,rgr),e(An,Y_e),e(Y_e,tgr),e(An,agr),e(An,K_e),e(K_e,ngr),e(An,sgr),e(Fo,lgr),e(Fo,te),e(te,XT),e(XT,Z_e),e(Z_e,igr),e(XT,dgr),e(XT,VG),e(VG,cgr),e(XT,fgr),e(te,mgr),e(te,VT),e(VT,eue),e(eue,ggr),e(VT,hgr),e(VT,zG),e(zG,pgr),e(VT,_gr),e(te,ugr),e(te,zT),e(zT,oue),e(oue,bgr),e(zT,vgr),e(zT,WG),e(WG,Tgr),e(zT,Fgr),e(te,Cgr),e(te,WT),e(WT,rue),e(rue,Mgr),e(WT,Egr),e(WT,QG),e(QG,ygr),e(WT,wgr),e(te,Agr),e(te,QT),e(QT,tue),e(tue,Lgr),e(QT,Bgr),e(QT,HG),e(HG,xgr),e(QT,kgr),e(te,Rgr),e(te,HT),e(HT,aue),e(aue,Sgr),e(HT,Pgr),e(HT,UG),e(UG,$gr),e(HT,Igr),e(te,jgr),e(te,UT),e(UT,nue),e(nue,Dgr),e(UT,Ngr),e(UT,JG),e(JG,qgr),e(UT,Ogr),e(te,Ggr),e(te,JT),e(JT,sue),e(sue,Xgr),e(JT,Vgr),e(JT,YG),e(YG,zgr),e(JT,Wgr),e(te,Qgr),e(te,YT),e(YT,lue),e(lue,Hgr),e(YT,Ugr),e(YT,KG),e(KG,Jgr),e(YT,Ygr),e(te,Kgr),e(te,KT),e(KT,iue),e(iue,Zgr),e(KT,ehr),e(KT,ZG),e(ZG,ohr),e(KT,rhr),e(te,thr),e(te,ZT),e(ZT,due),e(due,ahr),e(ZT,nhr),e(ZT,eX),e(eX,shr),e(ZT,lhr),e(te,ihr),e(te,e8),e(e8,cue),e(cue,dhr),e(e8,chr),e(e8,oX),e(oX,fhr),e(e8,mhr),e(te,ghr),e(te,o8),e(o8,fue),e(fue,hhr),e(o8,phr),e(o8,rX),e(rX,_hr),e(o8,uhr),e(te,bhr),e(te,r8),e(r8,mue),e(mue,vhr),e(r8,Thr),e(r8,tX),e(tX,Fhr),e(r8,Chr),e(te,Mhr),e(te,t8),e(t8,gue),e(gue,Ehr),e(t8,yhr),e(t8,aX),e(aX,whr),e(t8,Ahr),e(te,Lhr),e(te,a8),e(a8,hue),e(hue,Bhr),e(a8,xhr),e(a8,nX),e(nX,khr),e(a8,Rhr),e(te,Shr),e(te,n8),e(n8,pue),e(pue,Phr),e(n8,$hr),e(n8,sX),e(sX,Ihr),e(n8,jhr),e(Fo,Dhr),e(Fo,_ue),e(_ue,Nhr),e(Fo,qhr),g(Xw,Fo,null),b(d,gRe,u),b(d,Vc,u),e(Vc,s8),e(s8,uue),g(Vw,uue,null),e(Vc,Ohr),e(Vc,bue),e(bue,Ghr),b(d,hRe,u),b(d,Lr,u),g(zw,Lr,null),e(Lr,Xhr),e(Lr,zc),e(zc,Vhr),e(zc,vue),e(vue,zhr),e(zc,Whr),e(zc,Tue),e(Tue,Qhr),e(zc,Hhr),e(Lr,Uhr),e(Lr,Ww),e(Ww,Jhr),e(Ww,Fue),e(Fue,Yhr),e(Ww,Khr),e(Lr,Zhr),e(Lr,Mt),g(Qw,Mt,null),e(Mt,epr),e(Mt,Cue),e(Cue,opr),e(Mt,rpr),e(Mt,Wc),e(Wc,tpr),e(Wc,Mue),e(Mue,apr),e(Wc,npr),e(Wc,Eue),e(Eue,spr),e(Wc,lpr),e(Mt,ipr),e(Mt,yue),e(yue,dpr),e(Mt,cpr),g(Hw,Mt,null),e(Lr,fpr),e(Lr,Co),g(Uw,Co,null),e(Co,mpr),e(Co,wue),e(wue,gpr),e(Co,hpr),e(Co,Ln),e(Ln,ppr),e(Ln,Aue),e(Aue,_pr),e(Ln,upr),e(Ln,Lue),e(Lue,bpr),e(Ln,vpr),e(Ln,Bue),e(Bue,Tpr),e(Ln,Fpr),e(Co,Cpr),e(Co,xue),e(xue,l8),e(l8,kue),e(kue,Mpr),e(l8,Epr),e(l8,lX),e(lX,ypr),e(l8,wpr),e(Co,Apr),e(Co,Rue),e(Rue,Lpr),e(Co,Bpr),g(Jw,Co,null),b(d,pRe,u),b(d,Qc,u),e(Qc,i8),e(i8,Sue),g(Yw,Sue,null),e(Qc,xpr),e(Qc,Pue),e(Pue,kpr),b(d,_Re,u),b(d,Br,u),g(Kw,Br,null),e(Br,Rpr),e(Br,Hc),e(Hc,Spr),e(Hc,$ue),e($ue,Ppr),e(Hc,$pr),e(Hc,Iue),e(Iue,Ipr),e(Hc,jpr),e(Br,Dpr),e(Br,Zw),e(Zw,Npr),e(Zw,jue),e(jue,qpr),e(Zw,Opr),e(Br,Gpr),e(Br,Et),g(eA,Et,null),e(Et,Xpr),e(Et,Due),e(Due,Vpr),e(Et,zpr),e(Et,Uc),e(Uc,Wpr),e(Uc,Nue),e(Nue,Qpr),e(Uc,Hpr),e(Uc,que),e(que,Upr),e(Uc,Jpr),e(Et,Ypr),e(Et,Oue),e(Oue,Kpr),e(Et,Zpr),g(oA,Et,null),e(Br,e_r),e(Br,Mo),g(rA,Mo,null),e(Mo,o_r),e(Mo,Gue),e(Gue,r_r),e(Mo,t_r),e(Mo,Bn),e(Bn,a_r),e(Bn,Xue),e(Xue,n_r),e(Bn,s_r),e(Bn,Vue),e(Vue,l_r),e(Bn,i_r),e(Bn,zue),e(zue,d_r),e(Bn,c_r),e(Mo,f_r),e(Mo,K),e(K,d8),e(d8,Wue),e(Wue,m_r),e(d8,g_r),e(d8,iX),e(iX,h_r),e(d8,p_r),e(K,__r),e(K,c8),e(c8,Que),e(Que,u_r),e(c8,b_r),e(c8,dX),e(dX,v_r),e(c8,T_r),e(K,F_r),e(K,f8),e(f8,Hue),e(Hue,C_r),e(f8,M_r),e(f8,cX),e(cX,E_r),e(f8,y_r),e(K,w_r),e(K,m8),e(m8,Uue),e(Uue,A_r),e(m8,L_r),e(m8,fX),e(fX,B_r),e(m8,x_r),e(K,k_r),e(K,g8),e(g8,Jue),e(Jue,R_r),e(g8,S_r),e(g8,mX),e(mX,P_r),e(g8,$_r),e(K,I_r),e(K,h8),e(h8,Yue),e(Yue,j_r),e(h8,D_r),e(h8,gX),e(gX,N_r),e(h8,q_r),e(K,O_r),e(K,p8),e(p8,Kue),e(Kue,G_r),e(p8,X_r),e(p8,hX),e(hX,V_r),e(p8,z_r),e(K,W_r),e(K,_8),e(_8,Zue),e(Zue,Q_r),e(_8,H_r),e(_8,pX),e(pX,U_r),e(_8,J_r),e(K,Y_r),e(K,u8),e(u8,e1e),e(e1e,K_r),e(u8,Z_r),e(u8,_X),e(_X,eur),e(u8,our),e(K,rur),e(K,b8),e(b8,o1e),e(o1e,tur),e(b8,aur),e(b8,uX),e(uX,nur),e(b8,sur),e(K,lur),e(K,v8),e(v8,r1e),e(r1e,iur),e(v8,dur),e(v8,bX),e(bX,cur),e(v8,fur),e(K,mur),e(K,T8),e(T8,t1e),e(t1e,gur),e(T8,hur),e(T8,vX),e(vX,pur),e(T8,_ur),e(K,uur),e(K,F8),e(F8,a1e),e(a1e,bur),e(F8,vur),e(F8,TX),e(TX,Tur),e(F8,Fur),e(K,Cur),e(K,C8),e(C8,n1e),e(n1e,Mur),e(C8,Eur),e(C8,FX),e(FX,yur),e(C8,wur),e(K,Aur),e(K,M8),e(M8,s1e),e(s1e,Lur),e(M8,Bur),e(M8,CX),e(CX,xur),e(M8,kur),e(K,Rur),e(K,E8),e(E8,l1e),e(l1e,Sur),e(E8,Pur),e(E8,MX),e(MX,$ur),e(E8,Iur),e(K,jur),e(K,y8),e(y8,i1e),e(i1e,Dur),e(y8,Nur),e(y8,EX),e(EX,qur),e(y8,Our),e(K,Gur),e(K,w8),e(w8,d1e),e(d1e,Xur),e(w8,Vur),e(w8,yX),e(yX,zur),e(w8,Wur),e(K,Qur),e(K,A8),e(A8,c1e),e(c1e,Hur),e(A8,Uur),e(A8,wX),e(wX,Jur),e(A8,Yur),e(K,Kur),e(K,L8),e(L8,f1e),e(f1e,Zur),e(L8,e1r),e(L8,AX),e(AX,o1r),e(L8,r1r),e(Mo,t1r),e(Mo,m1e),e(m1e,a1r),e(Mo,n1r),g(tA,Mo,null),b(d,uRe,u),b(d,Jc,u),e(Jc,B8),e(B8,g1e),g(aA,g1e,null),e(Jc,s1r),e(Jc,h1e),e(h1e,l1r),b(d,bRe,u),b(d,xr,u),g(nA,xr,null),e(xr,i1r),e(xr,Yc),e(Yc,d1r),e(Yc,p1e),e(p1e,c1r),e(Yc,f1r),e(Yc,_1e),e(_1e,m1r),e(Yc,g1r),e(xr,h1r),e(xr,sA),e(sA,p1r),e(sA,u1e),e(u1e,_1r),e(sA,u1r),e(xr,b1r),e(xr,yt),g(lA,yt,null),e(yt,v1r),e(yt,b1e),e(b1e,T1r),e(yt,F1r),e(yt,Kc),e(Kc,C1r),e(Kc,v1e),e(v1e,M1r),e(Kc,E1r),e(Kc,T1e),e(T1e,y1r),e(Kc,w1r),e(yt,A1r),e(yt,F1e),e(F1e,L1r),e(yt,B1r),g(iA,yt,null),e(xr,x1r),e(xr,Eo),g(dA,Eo,null),e(Eo,k1r),e(Eo,C1e),e(C1e,R1r),e(Eo,S1r),e(Eo,xn),e(xn,P1r),e(xn,M1e),e(M1e,$1r),e(xn,I1r),e(xn,E1e),e(E1e,j1r),e(xn,D1r),e(xn,y1e),e(y1e,N1r),e(xn,q1r),e(Eo,O1r),e(Eo,Z),e(Z,x8),e(x8,w1e),e(w1e,G1r),e(x8,X1r),e(x8,LX),e(LX,V1r),e(x8,z1r),e(Z,W1r),e(Z,k8),e(k8,A1e),e(A1e,Q1r),e(k8,H1r),e(k8,BX),e(BX,U1r),e(k8,J1r),e(Z,Y1r),e(Z,R8),e(R8,L1e),e(L1e,K1r),e(R8,Z1r),e(R8,xX),e(xX,ebr),e(R8,obr),e(Z,rbr),e(Z,S8),e(S8,B1e),e(B1e,tbr),e(S8,abr),e(S8,kX),e(kX,nbr),e(S8,sbr),e(Z,lbr),e(Z,P8),e(P8,x1e),e(x1e,ibr),e(P8,dbr),e(P8,RX),e(RX,cbr),e(P8,fbr),e(Z,mbr),e(Z,$8),e($8,k1e),e(k1e,gbr),e($8,hbr),e($8,SX),e(SX,pbr),e($8,_br),e(Z,ubr),e(Z,I8),e(I8,R1e),e(R1e,bbr),e(I8,vbr),e(I8,PX),e(PX,Tbr),e(I8,Fbr),e(Z,Cbr),e(Z,j8),e(j8,S1e),e(S1e,Mbr),e(j8,Ebr),e(j8,$X),e($X,ybr),e(j8,wbr),e(Z,Abr),e(Z,D8),e(D8,P1e),e(P1e,Lbr),e(D8,Bbr),e(D8,IX),e(IX,xbr),e(D8,kbr),e(Z,Rbr),e(Z,N8),e(N8,$1e),e($1e,Sbr),e(N8,Pbr),e(N8,jX),e(jX,$br),e(N8,Ibr),e(Z,jbr),e(Z,q8),e(q8,I1e),e(I1e,Dbr),e(q8,Nbr),e(q8,DX),e(DX,qbr),e(q8,Obr),e(Z,Gbr),e(Z,O8),e(O8,j1e),e(j1e,Xbr),e(O8,Vbr),e(O8,NX),e(NX,zbr),e(O8,Wbr),e(Z,Qbr),e(Z,G8),e(G8,D1e),e(D1e,Hbr),e(G8,Ubr),e(G8,qX),e(qX,Jbr),e(G8,Ybr),e(Z,Kbr),e(Z,X8),e(X8,N1e),e(N1e,Zbr),e(X8,e5r),e(X8,OX),e(OX,o5r),e(X8,r5r),e(Z,t5r),e(Z,V8),e(V8,q1e),e(q1e,a5r),e(V8,n5r),e(V8,GX),e(GX,s5r),e(V8,l5r),e(Z,i5r),e(Z,z8),e(z8,O1e),e(O1e,d5r),e(z8,c5r),e(z8,XX),e(XX,f5r),e(z8,m5r),e(Z,g5r),e(Z,W8),e(W8,G1e),e(G1e,h5r),e(W8,p5r),e(W8,VX),e(VX,_5r),e(W8,u5r),e(Z,b5r),e(Z,Q8),e(Q8,X1e),e(X1e,v5r),e(Q8,T5r),e(Q8,zX),e(zX,F5r),e(Q8,C5r),e(Z,M5r),e(Z,H8),e(H8,V1e),e(V1e,E5r),e(H8,y5r),e(H8,WX),e(WX,w5r),e(H8,A5r),e(Eo,L5r),e(Eo,z1e),e(z1e,B5r),e(Eo,x5r),g(cA,Eo,null),b(d,vRe,u),b(d,Zc,u),e(Zc,U8),e(U8,W1e),g(fA,W1e,null),e(Zc,k5r),e(Zc,Q1e),e(Q1e,R5r),b(d,TRe,u),b(d,kr,u),g(mA,kr,null),e(kr,S5r),e(kr,ef),e(ef,P5r),e(ef,H1e),e(H1e,$5r),e(ef,I5r),e(ef,U1e),e(U1e,j5r),e(ef,D5r),e(kr,N5r),e(kr,gA),e(gA,q5r),e(gA,J1e),e(J1e,O5r),e(gA,G5r),e(kr,X5r),e(kr,wt),g(hA,wt,null),e(wt,V5r),e(wt,Y1e),e(Y1e,z5r),e(wt,W5r),e(wt,of),e(of,Q5r),e(of,K1e),e(K1e,H5r),e(of,U5r),e(of,Z1e),e(Z1e,J5r),e(of,Y5r),e(wt,K5r),e(wt,ebe),e(ebe,Z5r),e(wt,e2r),g(pA,wt,null),e(kr,o2r),e(kr,yo),g(_A,yo,null),e(yo,r2r),e(yo,obe),e(obe,t2r),e(yo,a2r),e(yo,kn),e(kn,n2r),e(kn,rbe),e(rbe,s2r),e(kn,l2r),e(kn,tbe),e(tbe,i2r),e(kn,d2r),e(kn,abe),e(abe,c2r),e(kn,f2r),e(yo,m2r),e(yo,nbe),e(nbe,J8),e(J8,sbe),e(sbe,g2r),e(J8,h2r),e(J8,QX),e(QX,p2r),e(J8,_2r),e(yo,u2r),e(yo,lbe),e(lbe,b2r),e(yo,v2r),g(uA,yo,null),b(d,FRe,u),b(d,rf,u),e(rf,Y8),e(Y8,ibe),g(bA,ibe,null),e(rf,T2r),e(rf,dbe),e(dbe,F2r),b(d,CRe,u),b(d,Rr,u),g(vA,Rr,null),e(Rr,C2r),e(Rr,tf),e(tf,M2r),e(tf,cbe),e(cbe,E2r),e(tf,y2r),e(tf,fbe),e(fbe,w2r),e(tf,A2r),e(Rr,L2r),e(Rr,TA),e(TA,B2r),e(TA,mbe),e(mbe,x2r),e(TA,k2r),e(Rr,R2r),e(Rr,At),g(FA,At,null),e(At,S2r),e(At,gbe),e(gbe,P2r),e(At,$2r),e(At,af),e(af,I2r),e(af,hbe),e(hbe,j2r),e(af,D2r),e(af,pbe),e(pbe,N2r),e(af,q2r),e(At,O2r),e(At,_be),e(_be,G2r),e(At,X2r),g(CA,At,null),e(Rr,V2r),e(Rr,wo),g(MA,wo,null),e(wo,z2r),e(wo,ube),e(ube,W2r),e(wo,Q2r),e(wo,Rn),e(Rn,H2r),e(Rn,bbe),e(bbe,U2r),e(Rn,J2r),e(Rn,vbe),e(vbe,Y2r),e(Rn,K2r),e(Rn,Tbe),e(Tbe,Z2r),e(Rn,evr),e(wo,ovr),e(wo,Fbe),e(Fbe,K8),e(K8,Cbe),e(Cbe,rvr),e(K8,tvr),e(K8,HX),e(HX,avr),e(K8,nvr),e(wo,svr),e(wo,Mbe),e(Mbe,lvr),e(wo,ivr),g(EA,wo,null),b(d,MRe,u),b(d,nf,u),e(nf,Z8),e(Z8,Ebe),g(yA,Ebe,null),e(nf,dvr),e(nf,ybe),e(ybe,cvr),b(d,ERe,u),b(d,Sr,u),g(wA,Sr,null),e(Sr,fvr),e(Sr,sf),e(sf,mvr),e(sf,wbe),e(wbe,gvr),e(sf,hvr),e(sf,Abe),e(Abe,pvr),e(sf,_vr),e(Sr,uvr),e(Sr,AA),e(AA,bvr),e(AA,Lbe),e(Lbe,vvr),e(AA,Tvr),e(Sr,Fvr),e(Sr,Lt),g(LA,Lt,null),e(Lt,Cvr),e(Lt,Bbe),e(Bbe,Mvr),e(Lt,Evr),e(Lt,lf),e(lf,yvr),e(lf,xbe),e(xbe,wvr),e(lf,Avr),e(lf,kbe),e(kbe,Lvr),e(lf,Bvr),e(Lt,xvr),e(Lt,Rbe),e(Rbe,kvr),e(Lt,Rvr),g(BA,Lt,null),e(Sr,Svr),e(Sr,Ao),g(xA,Ao,null),e(Ao,Pvr),e(Ao,Sbe),e(Sbe,$vr),e(Ao,Ivr),e(Ao,Sn),e(Sn,jvr),e(Sn,Pbe),e(Pbe,Dvr),e(Sn,Nvr),e(Sn,$be),e($be,qvr),e(Sn,Ovr),e(Sn,Ibe),e(Ibe,Gvr),e(Sn,Xvr),e(Ao,Vvr),e(Ao,z),e(z,eF),e(eF,jbe),e(jbe,zvr),e(eF,Wvr),e(eF,UX),e(UX,Qvr),e(eF,Hvr),e(z,Uvr),e(z,oF),e(oF,Dbe),e(Dbe,Jvr),e(oF,Yvr),e(oF,JX),e(JX,Kvr),e(oF,Zvr),e(z,e6r),e(z,rF),e(rF,Nbe),e(Nbe,o6r),e(rF,r6r),e(rF,YX),e(YX,t6r),e(rF,a6r),e(z,n6r),e(z,tF),e(tF,qbe),e(qbe,s6r),e(tF,l6r),e(tF,KX),e(KX,i6r),e(tF,d6r),e(z,c6r),e(z,aF),e(aF,Obe),e(Obe,f6r),e(aF,m6r),e(aF,ZX),e(ZX,g6r),e(aF,h6r),e(z,p6r),e(z,nF),e(nF,Gbe),e(Gbe,_6r),e(nF,u6r),e(nF,eV),e(eV,b6r),e(nF,v6r),e(z,T6r),e(z,sF),e(sF,Xbe),e(Xbe,F6r),e(sF,C6r),e(sF,oV),e(oV,M6r),e(sF,E6r),e(z,y6r),e(z,lF),e(lF,Vbe),e(Vbe,w6r),e(lF,A6r),e(lF,rV),e(rV,L6r),e(lF,B6r),e(z,x6r),e(z,iF),e(iF,zbe),e(zbe,k6r),e(iF,R6r),e(iF,tV),e(tV,S6r),e(iF,P6r),e(z,$6r),e(z,dF),e(dF,Wbe),e(Wbe,I6r),e(dF,j6r),e(dF,aV),e(aV,D6r),e(dF,N6r),e(z,q6r),e(z,cF),e(cF,Qbe),e(Qbe,O6r),e(cF,G6r),e(cF,nV),e(nV,X6r),e(cF,V6r),e(z,z6r),e(z,fF),e(fF,Hbe),e(Hbe,W6r),e(fF,Q6r),e(fF,sV),e(sV,H6r),e(fF,U6r),e(z,J6r),e(z,mF),e(mF,Ube),e(Ube,Y6r),e(mF,K6r),e(mF,lV),e(lV,Z6r),e(mF,e0r),e(z,o0r),e(z,gF),e(gF,Jbe),e(Jbe,r0r),e(gF,t0r),e(gF,iV),e(iV,a0r),e(gF,n0r),e(z,s0r),e(z,hF),e(hF,Ybe),e(Ybe,l0r),e(hF,i0r),e(hF,dV),e(dV,d0r),e(hF,c0r),e(z,f0r),e(z,pF),e(pF,Kbe),e(Kbe,m0r),e(pF,g0r),e(pF,cV),e(cV,h0r),e(pF,p0r),e(z,_0r),e(z,_F),e(_F,Zbe),e(Zbe,u0r),e(_F,b0r),e(_F,fV),e(fV,v0r),e(_F,T0r),e(z,F0r),e(z,uF),e(uF,e5e),e(e5e,C0r),e(uF,M0r),e(uF,mV),e(mV,E0r),e(uF,y0r),e(z,w0r),e(z,bF),e(bF,o5e),e(o5e,A0r),e(bF,L0r),e(bF,gV),e(gV,B0r),e(bF,x0r),e(z,k0r),e(z,vF),e(vF,r5e),e(r5e,R0r),e(vF,S0r),e(vF,hV),e(hV,P0r),e(vF,$0r),e(z,I0r),e(z,TF),e(TF,t5e),e(t5e,j0r),e(TF,D0r),e(TF,pV),e(pV,N0r),e(TF,q0r),e(z,O0r),e(z,FF),e(FF,a5e),e(a5e,G0r),e(FF,X0r),e(FF,_V),e(_V,V0r),e(FF,z0r),e(z,W0r),e(z,CF),e(CF,n5e),e(n5e,Q0r),e(CF,H0r),e(CF,uV),e(uV,U0r),e(CF,J0r),e(z,Y0r),e(z,MF),e(MF,s5e),e(s5e,K0r),e(MF,Z0r),e(MF,bV),e(bV,eTr),e(MF,oTr),e(z,rTr),e(z,EF),e(EF,l5e),e(l5e,tTr),e(EF,aTr),e(EF,vV),e(vV,nTr),e(EF,sTr),e(Ao,lTr),e(Ao,i5e),e(i5e,iTr),e(Ao,dTr),g(kA,Ao,null),b(d,yRe,u),b(d,df,u),e(df,yF),e(yF,d5e),g(RA,d5e,null),e(df,cTr),e(df,c5e),e(c5e,fTr),b(d,wRe,u),b(d,Pr,u),g(SA,Pr,null),e(Pr,mTr),e(Pr,cf),e(cf,gTr),e(cf,f5e),e(f5e,hTr),e(cf,pTr),e(cf,m5e),e(m5e,_Tr),e(cf,uTr),e(Pr,bTr),e(Pr,PA),e(PA,vTr),e(PA,g5e),e(g5e,TTr),e(PA,FTr),e(Pr,CTr),e(Pr,Bt),g($A,Bt,null),e(Bt,MTr),e(Bt,h5e),e(h5e,ETr),e(Bt,yTr),e(Bt,ff),e(ff,wTr),e(ff,p5e),e(p5e,ATr),e(ff,LTr),e(ff,_5e),e(_5e,BTr),e(ff,xTr),e(Bt,kTr),e(Bt,u5e),e(u5e,RTr),e(Bt,STr),g(IA,Bt,null),e(Pr,PTr),e(Pr,Lo),g(jA,Lo,null),e(Lo,$Tr),e(Lo,b5e),e(b5e,ITr),e(Lo,jTr),e(Lo,Pn),e(Pn,DTr),e(Pn,v5e),e(v5e,NTr),e(Pn,qTr),e(Pn,T5e),e(T5e,OTr),e(Pn,GTr),e(Pn,F5e),e(F5e,XTr),e(Pn,VTr),e(Lo,zTr),e(Lo,ga),e(ga,wF),e(wF,C5e),e(C5e,WTr),e(wF,QTr),e(wF,TV),e(TV,HTr),e(wF,UTr),e(ga,JTr),e(ga,AF),e(AF,M5e),e(M5e,YTr),e(AF,KTr),e(AF,FV),e(FV,ZTr),e(AF,e8r),e(ga,o8r),e(ga,LF),e(LF,E5e),e(E5e,r8r),e(LF,t8r),e(LF,CV),e(CV,a8r),e(LF,n8r),e(ga,s8r),e(ga,BF),e(BF,y5e),e(y5e,l8r),e(BF,i8r),e(BF,MV),e(MV,d8r),e(BF,c8r),e(ga,f8r),e(ga,xF),e(xF,w5e),e(w5e,m8r),e(xF,g8r),e(xF,EV),e(EV,h8r),e(xF,p8r),e(Lo,_8r),e(Lo,A5e),e(A5e,u8r),e(Lo,b8r),g(DA,Lo,null),b(d,ARe,u),b(d,mf,u),e(mf,kF),e(kF,L5e),g(NA,L5e,null),e(mf,v8r),e(mf,B5e),e(B5e,T8r),b(d,LRe,u),b(d,$r,u),g(qA,$r,null),e($r,F8r),e($r,gf),e(gf,C8r),e(gf,x5e),e(x5e,M8r),e(gf,E8r),e(gf,k5e),e(k5e,y8r),e(gf,w8r),e($r,A8r),e($r,OA),e(OA,L8r),e(OA,R5e),e(R5e,B8r),e(OA,x8r),e($r,k8r),e($r,xt),g(GA,xt,null),e(xt,R8r),e(xt,S5e),e(S5e,S8r),e(xt,P8r),e(xt,hf),e(hf,$8r),e(hf,P5e),e(P5e,I8r),e(hf,j8r),e(hf,$5e),e($5e,D8r),e(hf,N8r),e(xt,q8r),e(xt,I5e),e(I5e,O8r),e(xt,G8r),g(XA,xt,null),e($r,X8r),e($r,Bo),g(VA,Bo,null),e(Bo,V8r),e(Bo,j5e),e(j5e,z8r),e(Bo,W8r),e(Bo,$n),e($n,Q8r),e($n,D5e),e(D5e,H8r),e($n,U8r),e($n,N5e),e(N5e,J8r),e($n,Y8r),e($n,q5e),e(q5e,K8r),e($n,Z8r),e(Bo,eFr),e(Bo,ce),e(ce,RF),e(RF,O5e),e(O5e,oFr),e(RF,rFr),e(RF,yV),e(yV,tFr),e(RF,aFr),e(ce,nFr),e(ce,SF),e(SF,G5e),e(G5e,sFr),e(SF,lFr),e(SF,wV),e(wV,iFr),e(SF,dFr),e(ce,cFr),e(ce,PF),e(PF,X5e),e(X5e,fFr),e(PF,mFr),e(PF,AV),e(AV,gFr),e(PF,hFr),e(ce,pFr),e(ce,$F),e($F,V5e),e(V5e,_Fr),e($F,uFr),e($F,LV),e(LV,bFr),e($F,vFr),e(ce,TFr),e(ce,IF),e(IF,z5e),e(z5e,FFr),e(IF,CFr),e(IF,BV),e(BV,MFr),e(IF,EFr),e(ce,yFr),e(ce,jF),e(jF,W5e),e(W5e,wFr),e(jF,AFr),e(jF,xV),e(xV,LFr),e(jF,BFr),e(ce,xFr),e(ce,DF),e(DF,Q5e),e(Q5e,kFr),e(DF,RFr),e(DF,kV),e(kV,SFr),e(DF,PFr),e(ce,$Fr),e(ce,NF),e(NF,H5e),e(H5e,IFr),e(NF,jFr),e(NF,RV),e(RV,DFr),e(NF,NFr),e(ce,qFr),e(ce,qF),e(qF,U5e),e(U5e,OFr),e(qF,GFr),e(qF,SV),e(SV,XFr),e(qF,VFr),e(ce,zFr),e(ce,OF),e(OF,J5e),e(J5e,WFr),e(OF,QFr),e(OF,PV),e(PV,HFr),e(OF,UFr),e(ce,JFr),e(ce,GF),e(GF,Y5e),e(Y5e,YFr),e(GF,KFr),e(GF,$V),e($V,ZFr),e(GF,eCr),e(ce,oCr),e(ce,XF),e(XF,K5e),e(K5e,rCr),e(XF,tCr),e(XF,IV),e(IV,aCr),e(XF,nCr),e(Bo,sCr),e(Bo,Z5e),e(Z5e,lCr),e(Bo,iCr),g(zA,Bo,null),b(d,BRe,u),b(d,pf,u),e(pf,VF),e(VF,e2e),g(WA,e2e,null),e(pf,dCr),e(pf,o2e),e(o2e,cCr),b(d,xRe,u),b(d,Ir,u),g(QA,Ir,null),e(Ir,fCr),e(Ir,_f),e(_f,mCr),e(_f,r2e),e(r2e,gCr),e(_f,hCr),e(_f,t2e),e(t2e,pCr),e(_f,_Cr),e(Ir,uCr),e(Ir,HA),e(HA,bCr),e(HA,a2e),e(a2e,vCr),e(HA,TCr),e(Ir,FCr),e(Ir,kt),g(UA,kt,null),e(kt,CCr),e(kt,n2e),e(n2e,MCr),e(kt,ECr),e(kt,uf),e(uf,yCr),e(uf,s2e),e(s2e,wCr),e(uf,ACr),e(uf,l2e),e(l2e,LCr),e(uf,BCr),e(kt,xCr),e(kt,i2e),e(i2e,kCr),e(kt,RCr),g(JA,kt,null),e(Ir,SCr),e(Ir,xo),g(YA,xo,null),e(xo,PCr),e(xo,d2e),e(d2e,$Cr),e(xo,ICr),e(xo,In),e(In,jCr),e(In,c2e),e(c2e,DCr),e(In,NCr),e(In,f2e),e(f2e,qCr),e(In,OCr),e(In,m2e),e(m2e,GCr),e(In,XCr),e(xo,VCr),e(xo,ue),e(ue,zF),e(zF,g2e),e(g2e,zCr),e(zF,WCr),e(zF,jV),e(jV,QCr),e(zF,HCr),e(ue,UCr),e(ue,WF),e(WF,h2e),e(h2e,JCr),e(WF,YCr),e(WF,DV),e(DV,KCr),e(WF,ZCr),e(ue,eMr),e(ue,QF),e(QF,p2e),e(p2e,oMr),e(QF,rMr),e(QF,NV),e(NV,tMr),e(QF,aMr),e(ue,nMr),e(ue,HF),e(HF,_2e),e(_2e,sMr),e(HF,lMr),e(HF,qV),e(qV,iMr),e(HF,dMr),e(ue,cMr),e(ue,UF),e(UF,u2e),e(u2e,fMr),e(UF,mMr),e(UF,OV),e(OV,gMr),e(UF,hMr),e(ue,pMr),e(ue,JF),e(JF,b2e),e(b2e,_Mr),e(JF,uMr),e(JF,GV),e(GV,bMr),e(JF,vMr),e(ue,TMr),e(ue,YF),e(YF,v2e),e(v2e,FMr),e(YF,CMr),e(YF,XV),e(XV,MMr),e(YF,EMr),e(ue,yMr),e(ue,KF),e(KF,T2e),e(T2e,wMr),e(KF,AMr),e(KF,VV),e(VV,LMr),e(KF,BMr),e(ue,xMr),e(ue,ZF),e(ZF,F2e),e(F2e,kMr),e(ZF,RMr),e(ZF,zV),e(zV,SMr),e(ZF,PMr),e(ue,$Mr),e(ue,eC),e(eC,C2e),e(C2e,IMr),e(eC,jMr),e(eC,WV),e(WV,DMr),e(eC,NMr),e(xo,qMr),e(xo,M2e),e(M2e,OMr),e(xo,GMr),g(KA,xo,null),b(d,kRe,u),b(d,bf,u),e(bf,oC),e(oC,E2e),g(ZA,E2e,null),e(bf,XMr),e(bf,y2e),e(y2e,VMr),b(d,RRe,u),b(d,jr,u),g(eL,jr,null),e(jr,zMr),e(jr,vf),e(vf,WMr),e(vf,w2e),e(w2e,QMr),e(vf,HMr),e(vf,A2e),e(A2e,UMr),e(vf,JMr),e(jr,YMr),e(jr,oL),e(oL,KMr),e(oL,L2e),e(L2e,ZMr),e(oL,e4r),e(jr,o4r),e(jr,Rt),g(rL,Rt,null),e(Rt,r4r),e(Rt,B2e),e(B2e,t4r),e(Rt,a4r),e(Rt,Tf),e(Tf,n4r),e(Tf,x2e),e(x2e,s4r),e(Tf,l4r),e(Tf,k2e),e(k2e,i4r),e(Tf,d4r),e(Rt,c4r),e(Rt,R2e),e(R2e,f4r),e(Rt,m4r),g(tL,Rt,null),e(jr,g4r),e(jr,ko),g(aL,ko,null),e(ko,h4r),e(ko,S2e),e(S2e,p4r),e(ko,_4r),e(ko,jn),e(jn,u4r),e(jn,P2e),e(P2e,b4r),e(jn,v4r),e(jn,$2e),e($2e,T4r),e(jn,F4r),e(jn,I2e),e(I2e,C4r),e(jn,M4r),e(ko,E4r),e(ko,Me),e(Me,rC),e(rC,j2e),e(j2e,y4r),e(rC,w4r),e(rC,QV),e(QV,A4r),e(rC,L4r),e(Me,B4r),e(Me,tC),e(tC,D2e),e(D2e,x4r),e(tC,k4r),e(tC,HV),e(HV,R4r),e(tC,S4r),e(Me,P4r),e(Me,aC),e(aC,N2e),e(N2e,$4r),e(aC,I4r),e(aC,UV),e(UV,j4r),e(aC,D4r),e(Me,N4r),e(Me,nC),e(nC,q2e),e(q2e,q4r),e(nC,O4r),e(nC,JV),e(JV,G4r),e(nC,X4r),e(Me,V4r),e(Me,sC),e(sC,O2e),e(O2e,z4r),e(sC,W4r),e(sC,YV),e(YV,Q4r),e(sC,H4r),e(Me,U4r),e(Me,lC),e(lC,G2e),e(G2e,J4r),e(lC,Y4r),e(lC,KV),e(KV,K4r),e(lC,Z4r),e(Me,eEr),e(Me,iC),e(iC,X2e),e(X2e,oEr),e(iC,rEr),e(iC,ZV),e(ZV,tEr),e(iC,aEr),e(Me,nEr),e(Me,dC),e(dC,V2e),e(V2e,sEr),e(dC,lEr),e(dC,ez),e(ez,iEr),e(dC,dEr),e(Me,cEr),e(Me,cC),e(cC,z2e),e(z2e,fEr),e(cC,mEr),e(cC,oz),e(oz,gEr),e(cC,hEr),e(ko,pEr),e(ko,W2e),e(W2e,_Er),e(ko,uEr),g(nL,ko,null),b(d,SRe,u),b(d,Ff,u),e(Ff,fC),e(fC,Q2e),g(sL,Q2e,null),e(Ff,bEr),e(Ff,H2e),e(H2e,vEr),b(d,PRe,u),b(d,Dr,u),g(lL,Dr,null),e(Dr,TEr),e(Dr,Cf),e(Cf,FEr),e(Cf,U2e),e(U2e,CEr),e(Cf,MEr),e(Cf,J2e),e(J2e,EEr),e(Cf,yEr),e(Dr,wEr),e(Dr,iL),e(iL,AEr),e(iL,Y2e),e(Y2e,LEr),e(iL,BEr),e(Dr,xEr),e(Dr,St),g(dL,St,null),e(St,kEr),e(St,K2e),e(K2e,REr),e(St,SEr),e(St,Mf),e(Mf,PEr),e(Mf,Z2e),e(Z2e,$Er),e(Mf,IEr),e(Mf,eve),e(eve,jEr),e(Mf,DEr),e(St,NEr),e(St,ove),e(ove,qEr),e(St,OEr),g(cL,St,null),e(Dr,GEr),e(Dr,Ro),g(fL,Ro,null),e(Ro,XEr),e(Ro,rve),e(rve,VEr),e(Ro,zEr),e(Ro,Dn),e(Dn,WEr),e(Dn,tve),e(tve,QEr),e(Dn,HEr),e(Dn,ave),e(ave,UEr),e(Dn,JEr),e(Dn,nve),e(nve,YEr),e(Dn,KEr),e(Ro,ZEr),e(Ro,be),e(be,mC),e(mC,sve),e(sve,e3r),e(mC,o3r),e(mC,rz),e(rz,r3r),e(mC,t3r),e(be,a3r),e(be,gC),e(gC,lve),e(lve,n3r),e(gC,s3r),e(gC,tz),e(tz,l3r),e(gC,i3r),e(be,d3r),e(be,hC),e(hC,ive),e(ive,c3r),e(hC,f3r),e(hC,az),e(az,m3r),e(hC,g3r),e(be,h3r),e(be,pC),e(pC,dve),e(dve,p3r),e(pC,_3r),e(pC,nz),e(nz,u3r),e(pC,b3r),e(be,v3r),e(be,_C),e(_C,cve),e(cve,T3r),e(_C,F3r),e(_C,sz),e(sz,C3r),e(_C,M3r),e(be,E3r),e(be,uC),e(uC,fve),e(fve,y3r),e(uC,w3r),e(uC,lz),e(lz,A3r),e(uC,L3r),e(be,B3r),e(be,bC),e(bC,mve),e(mve,x3r),e(bC,k3r),e(bC,iz),e(iz,R3r),e(bC,S3r),e(be,P3r),e(be,vC),e(vC,gve),e(gve,$3r),e(vC,I3r),e(vC,dz),e(dz,j3r),e(vC,D3r),e(be,N3r),e(be,TC),e(TC,hve),e(hve,q3r),e(TC,O3r),e(TC,cz),e(cz,G3r),e(TC,X3r),e(be,V3r),e(be,FC),e(FC,pve),e(pve,z3r),e(FC,W3r),e(FC,fz),e(fz,Q3r),e(FC,H3r),e(Ro,U3r),e(Ro,_ve),e(_ve,J3r),e(Ro,Y3r),g(mL,Ro,null),b(d,$Re,u),b(d,Ef,u),e(Ef,CC),e(CC,uve),g(gL,uve,null),e(Ef,K3r),e(Ef,bve),e(bve,Z3r),b(d,IRe,u),b(d,Nr,u),g(hL,Nr,null),e(Nr,eyr),e(Nr,yf),e(yf,oyr),e(yf,vve),e(vve,ryr),e(yf,tyr),e(yf,Tve),e(Tve,ayr),e(yf,nyr),e(Nr,syr),e(Nr,pL),e(pL,lyr),e(pL,Fve),e(Fve,iyr),e(pL,dyr),e(Nr,cyr),e(Nr,Pt),g(_L,Pt,null),e(Pt,fyr),e(Pt,Cve),e(Cve,myr),e(Pt,gyr),e(Pt,wf),e(wf,hyr),e(wf,Mve),e(Mve,pyr),e(wf,_yr),e(wf,Eve),e(Eve,uyr),e(wf,byr),e(Pt,vyr),e(Pt,yve),e(yve,Tyr),e(Pt,Fyr),g(uL,Pt,null),e(Nr,Cyr),e(Nr,So),g(bL,So,null),e(So,Myr),e(So,wve),e(wve,Eyr),e(So,yyr),e(So,Nn),e(Nn,wyr),e(Nn,Ave),e(Ave,Ayr),e(Nn,Lyr),e(Nn,Lve),e(Lve,Byr),e(Nn,xyr),e(Nn,Bve),e(Bve,kyr),e(Nn,Ryr),e(So,Syr),e(So,xve),e(xve,MC),e(MC,kve),e(kve,Pyr),e(MC,$yr),e(MC,mz),e(mz,Iyr),e(MC,jyr),e(So,Dyr),e(So,Rve),e(Rve,Nyr),e(So,qyr),g(vL,So,null),b(d,jRe,u),b(d,Af,u),e(Af,EC),e(EC,Sve),g(TL,Sve,null),e(Af,Oyr),e(Af,Pve),e(Pve,Gyr),b(d,DRe,u),b(d,qr,u),g(FL,qr,null),e(qr,Xyr),e(qr,Lf),e(Lf,Vyr),e(Lf,$ve),e($ve,zyr),e(Lf,Wyr),e(Lf,Ive),e(Ive,Qyr),e(Lf,Hyr),e(qr,Uyr),e(qr,CL),e(CL,Jyr),e(CL,jve),e(jve,Yyr),e(CL,Kyr),e(qr,Zyr),e(qr,$t),g(ML,$t,null),e($t,ewr),e($t,Dve),e(Dve,owr),e($t,rwr),e($t,Bf),e(Bf,twr),e(Bf,Nve),e(Nve,awr),e(Bf,nwr),e(Bf,qve),e(qve,swr),e(Bf,lwr),e($t,iwr),e($t,Ove),e(Ove,dwr),e($t,cwr),g(EL,$t,null),e(qr,fwr),e(qr,Po),g(yL,Po,null),e(Po,mwr),e(Po,Gve),e(Gve,gwr),e(Po,hwr),e(Po,qn),e(qn,pwr),e(qn,Xve),e(Xve,_wr),e(qn,uwr),e(qn,Vve),e(Vve,bwr),e(qn,vwr),e(qn,zve),e(zve,Twr),e(qn,Fwr),e(Po,Cwr),e(Po,ve),e(ve,yC),e(yC,Wve),e(Wve,Mwr),e(yC,Ewr),e(yC,gz),e(gz,ywr),e(yC,wwr),e(ve,Awr),e(ve,wC),e(wC,Qve),e(Qve,Lwr),e(wC,Bwr),e(wC,hz),e(hz,xwr),e(wC,kwr),e(ve,Rwr),e(ve,AC),e(AC,Hve),e(Hve,Swr),e(AC,Pwr),e(AC,pz),e(pz,$wr),e(AC,Iwr),e(ve,jwr),e(ve,LC),e(LC,Uve),e(Uve,Dwr),e(LC,Nwr),e(LC,_z),e(_z,qwr),e(LC,Owr),e(ve,Gwr),e(ve,BC),e(BC,Jve),e(Jve,Xwr),e(BC,Vwr),e(BC,uz),e(uz,zwr),e(BC,Wwr),e(ve,Qwr),e(ve,xC),e(xC,Yve),e(Yve,Hwr),e(xC,Uwr),e(xC,bz),e(bz,Jwr),e(xC,Ywr),e(ve,Kwr),e(ve,kC),e(kC,Kve),e(Kve,Zwr),e(kC,eAr),e(kC,vz),e(vz,oAr),e(kC,rAr),e(ve,tAr),e(ve,RC),e(RC,Zve),e(Zve,aAr),e(RC,nAr),e(RC,Tz),e(Tz,sAr),e(RC,lAr),e(ve,iAr),e(ve,SC),e(SC,e6e),e(e6e,dAr),e(SC,cAr),e(SC,Fz),e(Fz,fAr),e(SC,mAr),e(ve,gAr),e(ve,PC),e(PC,o6e),e(o6e,hAr),e(PC,pAr),e(PC,Cz),e(Cz,_Ar),e(PC,uAr),e(Po,bAr),e(Po,r6e),e(r6e,vAr),e(Po,TAr),g(wL,Po,null),b(d,NRe,u),b(d,xf,u),e(xf,$C),e($C,t6e),g(AL,t6e,null),e(xf,FAr),e(xf,a6e),e(a6e,CAr),b(d,qRe,u),b(d,Or,u),g(LL,Or,null),e(Or,MAr),e(Or,kf),e(kf,EAr),e(kf,n6e),e(n6e,yAr),e(kf,wAr),e(kf,s6e),e(s6e,AAr),e(kf,LAr),e(Or,BAr),e(Or,BL),e(BL,xAr),e(BL,l6e),e(l6e,kAr),e(BL,RAr),e(Or,SAr),e(Or,It),g(xL,It,null),e(It,PAr),e(It,i6e),e(i6e,$Ar),e(It,IAr),e(It,Rf),e(Rf,jAr),e(Rf,d6e),e(d6e,DAr),e(Rf,NAr),e(Rf,c6e),e(c6e,qAr),e(Rf,OAr),e(It,GAr),e(It,f6e),e(f6e,XAr),e(It,VAr),g(kL,It,null),e(Or,zAr),e(Or,$o),g(RL,$o,null),e($o,WAr),e($o,m6e),e(m6e,QAr),e($o,HAr),e($o,On),e(On,UAr),e(On,g6e),e(g6e,JAr),e(On,YAr),e(On,h6e),e(h6e,KAr),e(On,ZAr),e(On,p6e),e(p6e,eLr),e(On,oLr),e($o,rLr),e($o,Re),e(Re,IC),e(IC,_6e),e(_6e,tLr),e(IC,aLr),e(IC,Mz),e(Mz,nLr),e(IC,sLr),e(Re,lLr),e(Re,jC),e(jC,u6e),e(u6e,iLr),e(jC,dLr),e(jC,Ez),e(Ez,cLr),e(jC,fLr),e(Re,mLr),e(Re,DC),e(DC,b6e),e(b6e,gLr),e(DC,hLr),e(DC,yz),e(yz,pLr),e(DC,_Lr),e(Re,uLr),e(Re,NC),e(NC,v6e),e(v6e,bLr),e(NC,vLr),e(NC,wz),e(wz,TLr),e(NC,FLr),e(Re,CLr),e(Re,qC),e(qC,T6e),e(T6e,MLr),e(qC,ELr),e(qC,Az),e(Az,yLr),e(qC,wLr),e(Re,ALr),e(Re,OC),e(OC,F6e),e(F6e,LLr),e(OC,BLr),e(OC,Lz),e(Lz,xLr),e(OC,kLr),e(Re,RLr),e(Re,GC),e(GC,C6e),e(C6e,SLr),e(GC,PLr),e(GC,Bz),e(Bz,$Lr),e(GC,ILr),e(Re,jLr),e(Re,XC),e(XC,M6e),e(M6e,DLr),e(XC,NLr),e(XC,xz),e(xz,qLr),e(XC,OLr),e($o,GLr),e($o,E6e),e(E6e,XLr),e($o,VLr),g(SL,$o,null),b(d,ORe,u),b(d,Sf,u),e(Sf,VC),e(VC,y6e),g(PL,y6e,null),e(Sf,zLr),e(Sf,w6e),e(w6e,WLr),b(d,GRe,u),b(d,Gr,u),g($L,Gr,null),e(Gr,QLr),e(Gr,Pf),e(Pf,HLr),e(Pf,A6e),e(A6e,ULr),e(Pf,JLr),e(Pf,L6e),e(L6e,YLr),e(Pf,KLr),e(Gr,ZLr),e(Gr,IL),e(IL,e7r),e(IL,B6e),e(B6e,o7r),e(IL,r7r),e(Gr,t7r),e(Gr,jt),g(jL,jt,null),e(jt,a7r),e(jt,x6e),e(x6e,n7r),e(jt,s7r),e(jt,$f),e($f,l7r),e($f,k6e),e(k6e,i7r),e($f,d7r),e($f,R6e),e(R6e,c7r),e($f,f7r),e(jt,m7r),e(jt,S6e),e(S6e,g7r),e(jt,h7r),g(DL,jt,null),e(Gr,p7r),e(Gr,Io),g(NL,Io,null),e(Io,_7r),e(Io,P6e),e(P6e,u7r),e(Io,b7r),e(Io,Gn),e(Gn,v7r),e(Gn,$6e),e($6e,T7r),e(Gn,F7r),e(Gn,I6e),e(I6e,C7r),e(Gn,M7r),e(Gn,j6e),e(j6e,E7r),e(Gn,y7r),e(Io,w7r),e(Io,Se),e(Se,zC),e(zC,D6e),e(D6e,A7r),e(zC,L7r),e(zC,kz),e(kz,B7r),e(zC,x7r),e(Se,k7r),e(Se,WC),e(WC,N6e),e(N6e,R7r),e(WC,S7r),e(WC,Rz),e(Rz,P7r),e(WC,$7r),e(Se,I7r),e(Se,QC),e(QC,q6e),e(q6e,j7r),e(QC,D7r),e(QC,Sz),e(Sz,N7r),e(QC,q7r),e(Se,O7r),e(Se,HC),e(HC,O6e),e(O6e,G7r),e(HC,X7r),e(HC,Pz),e(Pz,V7r),e(HC,z7r),e(Se,W7r),e(Se,UC),e(UC,G6e),e(G6e,Q7r),e(UC,H7r),e(UC,$z),e($z,U7r),e(UC,J7r),e(Se,Y7r),e(Se,JC),e(JC,X6e),e(X6e,K7r),e(JC,Z7r),e(JC,Iz),e(Iz,e9r),e(JC,o9r),e(Se,r9r),e(Se,YC),e(YC,V6e),e(V6e,t9r),e(YC,a9r),e(YC,jz),e(jz,n9r),e(YC,s9r),e(Se,l9r),e(Se,KC),e(KC,z6e),e(z6e,i9r),e(KC,d9r),e(KC,Dz),e(Dz,c9r),e(KC,f9r),e(Io,m9r),e(Io,W6e),e(W6e,g9r),e(Io,h9r),g(qL,Io,null),b(d,XRe,u),b(d,If,u),e(If,ZC),e(ZC,Q6e),g(OL,Q6e,null),e(If,p9r),e(If,H6e),e(H6e,_9r),b(d,VRe,u),b(d,Xr,u),g(GL,Xr,null),e(Xr,u9r),e(Xr,jf),e(jf,b9r),e(jf,U6e),e(U6e,v9r),e(jf,T9r),e(jf,J6e),e(J6e,F9r),e(jf,C9r),e(Xr,M9r),e(Xr,XL),e(XL,E9r),e(XL,Y6e),e(Y6e,y9r),e(XL,w9r),e(Xr,A9r),e(Xr,Dt),g(VL,Dt,null),e(Dt,L9r),e(Dt,K6e),e(K6e,B9r),e(Dt,x9r),e(Dt,Df),e(Df,k9r),e(Df,Z6e),e(Z6e,R9r),e(Df,S9r),e(Df,e0e),e(e0e,P9r),e(Df,$9r),e(Dt,I9r),e(Dt,o0e),e(o0e,j9r),e(Dt,D9r),g(zL,Dt,null),e(Xr,N9r),e(Xr,jo),g(WL,jo,null),e(jo,q9r),e(jo,r0e),e(r0e,O9r),e(jo,G9r),e(jo,Xn),e(Xn,X9r),e(Xn,t0e),e(t0e,V9r),e(Xn,z9r),e(Xn,a0e),e(a0e,W9r),e(Xn,Q9r),e(Xn,n0e),e(n0e,H9r),e(Xn,U9r),e(jo,J9r),e(jo,s0e),e(s0e,eM),e(eM,l0e),e(l0e,Y9r),e(eM,K9r),e(eM,Nz),e(Nz,Z9r),e(eM,eBr),e(jo,oBr),e(jo,i0e),e(i0e,rBr),e(jo,tBr),g(QL,jo,null),b(d,zRe,u),b(d,Nf,u),e(Nf,oM),e(oM,d0e),g(HL,d0e,null),e(Nf,aBr),e(Nf,c0e),e(c0e,nBr),b(d,WRe,u),b(d,Vr,u),g(UL,Vr,null),e(Vr,sBr),e(Vr,qf),e(qf,lBr),e(qf,f0e),e(f0e,iBr),e(qf,dBr),e(qf,m0e),e(m0e,cBr),e(qf,fBr),e(Vr,mBr),e(Vr,JL),e(JL,gBr),e(JL,g0e),e(g0e,hBr),e(JL,pBr),e(Vr,_Br),e(Vr,Nt),g(YL,Nt,null),e(Nt,uBr),e(Nt,h0e),e(h0e,bBr),e(Nt,vBr),e(Nt,Of),e(Of,TBr),e(Of,p0e),e(p0e,FBr),e(Of,CBr),e(Of,_0e),e(_0e,MBr),e(Of,EBr),e(Nt,yBr),e(Nt,u0e),e(u0e,wBr),e(Nt,ABr),g(KL,Nt,null),e(Vr,LBr),e(Vr,Do),g(ZL,Do,null),e(Do,BBr),e(Do,b0e),e(b0e,xBr),e(Do,kBr),e(Do,Vn),e(Vn,RBr),e(Vn,v0e),e(v0e,SBr),e(Vn,PBr),e(Vn,T0e),e(T0e,$Br),e(Vn,IBr),e(Vn,F0e),e(F0e,jBr),e(Vn,DBr),e(Do,NBr),e(Do,e7),e(e7,rM),e(rM,C0e),e(C0e,qBr),e(rM,OBr),e(rM,qz),e(qz,GBr),e(rM,XBr),e(e7,VBr),e(e7,tM),e(tM,M0e),e(M0e,zBr),e(tM,WBr),e(tM,Oz),e(Oz,QBr),e(tM,HBr),e(Do,UBr),e(Do,E0e),e(E0e,JBr),e(Do,YBr),g(o7,Do,null),b(d,QRe,u),b(d,Gf,u),e(Gf,aM),e(aM,y0e),g(r7,y0e,null),e(Gf,KBr),e(Gf,w0e),e(w0e,ZBr),b(d,HRe,u),b(d,zr,u),g(t7,zr,null),e(zr,exr),e(zr,Xf),e(Xf,oxr),e(Xf,A0e),e(A0e,rxr),e(Xf,txr),e(Xf,L0e),e(L0e,axr),e(Xf,nxr),e(zr,sxr),e(zr,a7),e(a7,lxr),e(a7,B0e),e(B0e,ixr),e(a7,dxr),e(zr,cxr),e(zr,qt),g(n7,qt,null),e(qt,fxr),e(qt,x0e),e(x0e,mxr),e(qt,gxr),e(qt,Vf),e(Vf,hxr),e(Vf,k0e),e(k0e,pxr),e(Vf,_xr),e(Vf,R0e),e(R0e,uxr),e(Vf,bxr),e(qt,vxr),e(qt,S0e),e(S0e,Txr),e(qt,Fxr),g(s7,qt,null),e(zr,Cxr),e(zr,No),g(l7,No,null),e(No,Mxr),e(No,P0e),e(P0e,Exr),e(No,yxr),e(No,zn),e(zn,wxr),e(zn,$0e),e($0e,Axr),e(zn,Lxr),e(zn,I0e),e(I0e,Bxr),e(zn,xxr),e(zn,j0e),e(j0e,kxr),e(zn,Rxr),e(No,Sxr),e(No,D0e),e(D0e,nM),e(nM,N0e),e(N0e,Pxr),e(nM,$xr),e(nM,Gz),e(Gz,Ixr),e(nM,jxr),e(No,Dxr),e(No,q0e),e(q0e,Nxr),e(No,qxr),g(i7,No,null),URe=!0},p(d,[u]){const d7={};u&2&&(d7.$$scope={dirty:u,ctx:d}),Yf.$set(d7);const O0e={};u&2&&(O0e.$$scope={dirty:u,ctx:d}),Ph.$set(O0e);const G0e={};u&2&&(G0e.$$scope={dirty:u,ctx:d}),zh.$set(G0e)},i(d){URe||(h(fe.$$.fragment,d),h(Va.$$.fragment,d),h(c4.$$.fragment,d),h(f4.$$.fragment,d),h(Yf.$$.fragment,d),h(m4.$$.fragment,d),h(g4.$$.fragment,d),h(_4.$$.fragment,d),h(u4.$$.fragment,d),h(b4.$$.fragment,d),h(v4.$$.fragment,d),h(T4.$$.fragment,d),h(M4.$$.fragment,d),h(E4.$$.fragment,d),h(y4.$$.fragment,d),h(w4.$$.fragment,d),h(A4.$$.fragment,d),h(x4.$$.fragment,d),h(Ph.$$.fragment,d),h(k4.$$.fragment,d),h(R4.$$.fragment,d),h(S4.$$.fragment,d),h(P4.$$.fragment,d),h(j4.$$.fragment,d),h(zh.$$.fragment,d),h(D4.$$.fragment,d),h(N4.$$.fragment,d),h(q4.$$.fragment,d),h(O4.$$.fragment,d),h(X4.$$.fragment,d),h(V4.$$.fragment,d),h(z4.$$.fragment,d),h(W4.$$.fragment,d),h(Q4.$$.fragment,d),h(H4.$$.fragment,d),h(J4.$$.fragment,d),h(Y4.$$.fragment,d),h(K4.$$.fragment,d),h(Z4.$$.fragment,d),h(eE.$$.fragment,d),h(oE.$$.fragment,d),h(tE.$$.fragment,d),h(aE.$$.fragment,d),h(nE.$$.fragment,d),h(sE.$$.fragment,d),h(lE.$$.fragment,d),h(iE.$$.fragment,d),h(cE.$$.fragment,d),h(fE.$$.fragment,d),h(mE.$$.fragment,d),h(gE.$$.fragment,d),h(hE.$$.fragment,d),h(pE.$$.fragment,d),h(uE.$$.fragment,d),h(bE.$$.fragment,d),h(vE.$$.fragment,d),h(TE.$$.fragment,d),h(FE.$$.fragment,d),h(CE.$$.fragment,d),h(EE.$$.fragment,d),h(yE.$$.fragment,d),h(wE.$$.fragment,d),h(AE.$$.fragment,d),h(LE.$$.fragment,d),h(BE.$$.fragment,d),h(kE.$$.fragment,d),h(RE.$$.fragment,d),h(SE.$$.fragment,d),h(PE.$$.fragment,d),h($E.$$.fragment,d),h(IE.$$.fragment,d),h(DE.$$.fragment,d),h(NE.$$.fragment,d),h(qE.$$.fragment,d),h(OE.$$.fragment,d),h(GE.$$.fragment,d),h(XE.$$.fragment,d),h(zE.$$.fragment,d),h(WE.$$.fragment,d),h(QE.$$.fragment,d),h(HE.$$.fragment,d),h(UE.$$.fragment,d),h(JE.$$.fragment,d),h(KE.$$.fragment,d),h(ZE.$$.fragment,d),h(e3.$$.fragment,d),h(o3.$$.fragment,d),h(r3.$$.fragment,d),h(t3.$$.fragment,d),h(n3.$$.fragment,d),h(s3.$$.fragment,d),h(l3.$$.fragment,d),h(i3.$$.fragment,d),h(d3.$$.fragment,d),h(c3.$$.fragment,d),h(m3.$$.fragment,d),h(g3.$$.fragment,d),h(h3.$$.fragment,d),h(p3.$$.fragment,d),h(_3.$$.fragment,d),h(u3.$$.fragment,d),h(v3.$$.fragment,d),h(T3.$$.fragment,d),h(F3.$$.fragment,d),h(C3.$$.fragment,d),h(M3.$$.fragment,d),h(E3.$$.fragment,d),h(w3.$$.fragment,d),h(A3.$$.fragment,d),h(L3.$$.fragment,d),h(B3.$$.fragment,d),h(x3.$$.fragment,d),h(k3.$$.fragment,d),h(S3.$$.fragment,d),h(P3.$$.fragment,d),h($3.$$.fragment,d),h(I3.$$.fragment,d),h(j3.$$.fragment,d),h(D3.$$.fragment,d),h(q3.$$.fragment,d),h(O3.$$.fragment,d),h(G3.$$.fragment,d),h(X3.$$.fragment,d),h(V3.$$.fragment,d),h(z3.$$.fragment,d),h(Q3.$$.fragment,d),h(H3.$$.fragment,d),h(U3.$$.fragment,d),h(Y3.$$.fragment,d),h(K3.$$.fragment,d),h(Z3.$$.fragment,d),h(oy.$$.fragment,d),h(ry.$$.fragment,d),h(ty.$$.fragment,d),h(ay.$$.fragment,d),h(ny.$$.fragment,d),h(sy.$$.fragment,d),h(iy.$$.fragment,d),h(dy.$$.fragment,d),h(cy.$$.fragment,d),h(fy.$$.fragment,d),h(my.$$.fragment,d),h(gy.$$.fragment,d),h(py.$$.fragment,d),h(_y.$$.fragment,d),h(uy.$$.fragment,d),h(by.$$.fragment,d),h(vy.$$.fragment,d),h(Ty.$$.fragment,d),h(Cy.$$.fragment,d),h(My.$$.fragment,d),h(Ey.$$.fragment,d),h(yy.$$.fragment,d),h(wy.$$.fragment,d),h(Ay.$$.fragment,d),h(By.$$.fragment,d),h(xy.$$.fragment,d),h(ky.$$.fragment,d),h(Sy.$$.fragment,d),h(Py.$$.fragment,d),h($y.$$.fragment,d),h(jy.$$.fragment,d),h(Dy.$$.fragment,d),h(Ny.$$.fragment,d),h(qy.$$.fragment,d),h(Oy.$$.fragment,d),h(Gy.$$.fragment,d),h(Vy.$$.fragment,d),h(zy.$$.fragment,d),h(Wy.$$.fragment,d),h(Qy.$$.fragment,d),h(Hy.$$.fragment,d),h(Uy.$$.fragment,d),h(Yy.$$.fragment,d),h(Ky.$$.fragment,d),h(Zy.$$.fragment,d),h(ew.$$.fragment,d),h(ow.$$.fragment,d),h(rw.$$.fragment,d),h(aw.$$.fragment,d),h(nw.$$.fragment,d),h(sw.$$.fragment,d),h(lw.$$.fragment,d),h(iw.$$.fragment,d),h(dw.$$.fragment,d),h(fw.$$.fragment,d),h(mw.$$.fragment,d),h(gw.$$.fragment,d),h(pw.$$.fragment,d),h(_w.$$.fragment,d),h(uw.$$.fragment,d),h(vw.$$.fragment,d),h(Tw.$$.fragment,d),h(Fw.$$.fragment,d),h(Cw.$$.fragment,d),h(Mw.$$.fragment,d),h(Ew.$$.fragment,d),h(ww.$$.fragment,d),h(Aw.$$.fragment,d),h(Lw.$$.fragment,d),h(Bw.$$.fragment,d),h(xw.$$.fragment,d),h(kw.$$.fragment,d),h(Sw.$$.fragment,d),h(Pw.$$.fragment,d),h($w.$$.fragment,d),h(Iw.$$.fragment,d),h(jw.$$.fragment,d),h(Dw.$$.fragment,d),h(qw.$$.fragment,d),h(Ow.$$.fragment,d),h(Gw.$$.fragment,d),h(Xw.$$.fragment,d),h(Vw.$$.fragment,d),h(zw.$$.fragment,d),h(Qw.$$.fragment,d),h(Hw.$$.fragment,d),h(Uw.$$.fragment,d),h(Jw.$$.fragment,d),h(Yw.$$.fragment,d),h(Kw.$$.fragment,d),h(eA.$$.fragment,d),h(oA.$$.fragment,d),h(rA.$$.fragment,d),h(tA.$$.fragment,d),h(aA.$$.fragment,d),h(nA.$$.fragment,d),h(lA.$$.fragment,d),h(iA.$$.fragment,d),h(dA.$$.fragment,d),h(cA.$$.fragment,d),h(fA.$$.fragment,d),h(mA.$$.fragment,d),h(hA.$$.fragment,d),h(pA.$$.fragment,d),h(_A.$$.fragment,d),h(uA.$$.fragment,d),h(bA.$$.fragment,d),h(vA.$$.fragment,d),h(FA.$$.fragment,d),h(CA.$$.fragment,d),h(MA.$$.fragment,d),h(EA.$$.fragment,d),h(yA.$$.fragment,d),h(wA.$$.fragment,d),h(LA.$$.fragment,d),h(BA.$$.fragment,d),h(xA.$$.fragment,d),h(kA.$$.fragment,d),h(RA.$$.fragment,d),h(SA.$$.fragment,d),h($A.$$.fragment,d),h(IA.$$.fragment,d),h(jA.$$.fragment,d),h(DA.$$.fragment,d),h(NA.$$.fragment,d),h(qA.$$.fragment,d),h(GA.$$.fragment,d),h(XA.$$.fragment,d),h(VA.$$.fragment,d),h(zA.$$.fragment,d),h(WA.$$.fragment,d),h(QA.$$.fragment,d),h(UA.$$.fragment,d),h(JA.$$.fragment,d),h(YA.$$.fragment,d),h(KA.$$.fragment,d),h(ZA.$$.fragment,d),h(eL.$$.fragment,d),h(rL.$$.fragment,d),h(tL.$$.fragment,d),h(aL.$$.fragment,d),h(nL.$$.fragment,d),h(sL.$$.fragment,d),h(lL.$$.fragment,d),h(dL.$$.fragment,d),h(cL.$$.fragment,d),h(fL.$$.fragment,d),h(mL.$$.fragment,d),h(gL.$$.fragment,d),h(hL.$$.fragment,d),h(_L.$$.fragment,d),h(uL.$$.fragment,d),h(bL.$$.fragment,d),h(vL.$$.fragment,d),h(TL.$$.fragment,d),h(FL.$$.fragment,d),h(ML.$$.fragment,d),h(EL.$$.fragment,d),h(yL.$$.fragment,d),h(wL.$$.fragment,d),h(AL.$$.fragment,d),h(LL.$$.fragment,d),h(xL.$$.fragment,d),h(kL.$$.fragment,d),h(RL.$$.fragment,d),h(SL.$$.fragment,d),h(PL.$$.fragment,d),h($L.$$.fragment,d),h(jL.$$.fragment,d),h(DL.$$.fragment,d),h(NL.$$.fragment,d),h(qL.$$.fragment,d),h(OL.$$.fragment,d),h(GL.$$.fragment,d),h(VL.$$.fragment,d),h(zL.$$.fragment,d),h(WL.$$.fragment,d),h(QL.$$.fragment,d),h(HL.$$.fragment,d),h(UL.$$.fragment,d),h(YL.$$.fragment,d),h(KL.$$.fragment,d),h(ZL.$$.fragment,d),h(o7.$$.fragment,d),h(r7.$$.fragment,d),h(t7.$$.fragment,d),h(n7.$$.fragment,d),h(s7.$$.fragment,d),h(l7.$$.fragment,d),h(i7.$$.fragment,d),URe=!0)},o(d){p(fe.$$.fragment,d),p(Va.$$.fragment,d),p(c4.$$.fragment,d),p(f4.$$.fragment,d),p(Yf.$$.fragment,d),p(m4.$$.fragment,d),p(g4.$$.fragment,d),p(_4.$$.fragment,d),p(u4.$$.fragment,d),p(b4.$$.fragment,d),p(v4.$$.fragment,d),p(T4.$$.fragment,d),p(M4.$$.fragment,d),p(E4.$$.fragment,d),p(y4.$$.fragment,d),p(w4.$$.fragment,d),p(A4.$$.fragment,d),p(x4.$$.fragment,d),p(Ph.$$.fragment,d),p(k4.$$.fragment,d),p(R4.$$.fragment,d),p(S4.$$.fragment,d),p(P4.$$.fragment,d),p(j4.$$.fragment,d),p(zh.$$.fragment,d),p(D4.$$.fragment,d),p(N4.$$.fragment,d),p(q4.$$.fragment,d),p(O4.$$.fragment,d),p(X4.$$.fragment,d),p(V4.$$.fragment,d),p(z4.$$.fragment,d),p(W4.$$.fragment,d),p(Q4.$$.fragment,d),p(H4.$$.fragment,d),p(J4.$$.fragment,d),p(Y4.$$.fragment,d),p(K4.$$.fragment,d),p(Z4.$$.fragment,d),p(eE.$$.fragment,d),p(oE.$$.fragment,d),p(tE.$$.fragment,d),p(aE.$$.fragment,d),p(nE.$$.fragment,d),p(sE.$$.fragment,d),p(lE.$$.fragment,d),p(iE.$$.fragment,d),p(cE.$$.fragment,d),p(fE.$$.fragment,d),p(mE.$$.fragment,d),p(gE.$$.fragment,d),p(hE.$$.fragment,d),p(pE.$$.fragment,d),p(uE.$$.fragment,d),p(bE.$$.fragment,d),p(vE.$$.fragment,d),p(TE.$$.fragment,d),p(FE.$$.fragment,d),p(CE.$$.fragment,d),p(EE.$$.fragment,d),p(yE.$$.fragment,d),p(wE.$$.fragment,d),p(AE.$$.fragment,d),p(LE.$$.fragment,d),p(BE.$$.fragment,d),p(kE.$$.fragment,d),p(RE.$$.fragment,d),p(SE.$$.fragment,d),p(PE.$$.fragment,d),p($E.$$.fragment,d),p(IE.$$.fragment,d),p(DE.$$.fragment,d),p(NE.$$.fragment,d),p(qE.$$.fragment,d),p(OE.$$.fragment,d),p(GE.$$.fragment,d),p(XE.$$.fragment,d),p(zE.$$.fragment,d),p(WE.$$.fragment,d),p(QE.$$.fragment,d),p(HE.$$.fragment,d),p(UE.$$.fragment,d),p(JE.$$.fragment,d),p(KE.$$.fragment,d),p(ZE.$$.fragment,d),p(e3.$$.fragment,d),p(o3.$$.fragment,d),p(r3.$$.fragment,d),p(t3.$$.fragment,d),p(n3.$$.fragment,d),p(s3.$$.fragment,d),p(l3.$$.fragment,d),p(i3.$$.fragment,d),p(d3.$$.fragment,d),p(c3.$$.fragment,d),p(m3.$$.fragment,d),p(g3.$$.fragment,d),p(h3.$$.fragment,d),p(p3.$$.fragment,d),p(_3.$$.fragment,d),p(u3.$$.fragment,d),p(v3.$$.fragment,d),p(T3.$$.fragment,d),p(F3.$$.fragment,d),p(C3.$$.fragment,d),p(M3.$$.fragment,d),p(E3.$$.fragment,d),p(w3.$$.fragment,d),p(A3.$$.fragment,d),p(L3.$$.fragment,d),p(B3.$$.fragment,d),p(x3.$$.fragment,d),p(k3.$$.fragment,d),p(S3.$$.fragment,d),p(P3.$$.fragment,d),p($3.$$.fragment,d),p(I3.$$.fragment,d),p(j3.$$.fragment,d),p(D3.$$.fragment,d),p(q3.$$.fragment,d),p(O3.$$.fragment,d),p(G3.$$.fragment,d),p(X3.$$.fragment,d),p(V3.$$.fragment,d),p(z3.$$.fragment,d),p(Q3.$$.fragment,d),p(H3.$$.fragment,d),p(U3.$$.fragment,d),p(Y3.$$.fragment,d),p(K3.$$.fragment,d),p(Z3.$$.fragment,d),p(oy.$$.fragment,d),p(ry.$$.fragment,d),p(ty.$$.fragment,d),p(ay.$$.fragment,d),p(ny.$$.fragment,d),p(sy.$$.fragment,d),p(iy.$$.fragment,d),p(dy.$$.fragment,d),p(cy.$$.fragment,d),p(fy.$$.fragment,d),p(my.$$.fragment,d),p(gy.$$.fragment,d),p(py.$$.fragment,d),p(_y.$$.fragment,d),p(uy.$$.fragment,d),p(by.$$.fragment,d),p(vy.$$.fragment,d),p(Ty.$$.fragment,d),p(Cy.$$.fragment,d),p(My.$$.fragment,d),p(Ey.$$.fragment,d),p(yy.$$.fragment,d),p(wy.$$.fragment,d),p(Ay.$$.fragment,d),p(By.$$.fragment,d),p(xy.$$.fragment,d),p(ky.$$.fragment,d),p(Sy.$$.fragment,d),p(Py.$$.fragment,d),p($y.$$.fragment,d),p(jy.$$.fragment,d),p(Dy.$$.fragment,d),p(Ny.$$.fragment,d),p(qy.$$.fragment,d),p(Oy.$$.fragment,d),p(Gy.$$.fragment,d),p(Vy.$$.fragment,d),p(zy.$$.fragment,d),p(Wy.$$.fragment,d),p(Qy.$$.fragment,d),p(Hy.$$.fragment,d),p(Uy.$$.fragment,d),p(Yy.$$.fragment,d),p(Ky.$$.fragment,d),p(Zy.$$.fragment,d),p(ew.$$.fragment,d),p(ow.$$.fragment,d),p(rw.$$.fragment,d),p(aw.$$.fragment,d),p(nw.$$.fragment,d),p(sw.$$.fragment,d),p(lw.$$.fragment,d),p(iw.$$.fragment,d),p(dw.$$.fragment,d),p(fw.$$.fragment,d),p(mw.$$.fragment,d),p(gw.$$.fragment,d),p(pw.$$.fragment,d),p(_w.$$.fragment,d),p(uw.$$.fragment,d),p(vw.$$.fragment,d),p(Tw.$$.fragment,d),p(Fw.$$.fragment,d),p(Cw.$$.fragment,d),p(Mw.$$.fragment,d),p(Ew.$$.fragment,d),p(ww.$$.fragment,d),p(Aw.$$.fragment,d),p(Lw.$$.fragment,d),p(Bw.$$.fragment,d),p(xw.$$.fragment,d),p(kw.$$.fragment,d),p(Sw.$$.fragment,d),p(Pw.$$.fragment,d),p($w.$$.fragment,d),p(Iw.$$.fragment,d),p(jw.$$.fragment,d),p(Dw.$$.fragment,d),p(qw.$$.fragment,d),p(Ow.$$.fragment,d),p(Gw.$$.fragment,d),p(Xw.$$.fragment,d),p(Vw.$$.fragment,d),p(zw.$$.fragment,d),p(Qw.$$.fragment,d),p(Hw.$$.fragment,d),p(Uw.$$.fragment,d),p(Jw.$$.fragment,d),p(Yw.$$.fragment,d),p(Kw.$$.fragment,d),p(eA.$$.fragment,d),p(oA.$$.fragment,d),p(rA.$$.fragment,d),p(tA.$$.fragment,d),p(aA.$$.fragment,d),p(nA.$$.fragment,d),p(lA.$$.fragment,d),p(iA.$$.fragment,d),p(dA.$$.fragment,d),p(cA.$$.fragment,d),p(fA.$$.fragment,d),p(mA.$$.fragment,d),p(hA.$$.fragment,d),p(pA.$$.fragment,d),p(_A.$$.fragment,d),p(uA.$$.fragment,d),p(bA.$$.fragment,d),p(vA.$$.fragment,d),p(FA.$$.fragment,d),p(CA.$$.fragment,d),p(MA.$$.fragment,d),p(EA.$$.fragment,d),p(yA.$$.fragment,d),p(wA.$$.fragment,d),p(LA.$$.fragment,d),p(BA.$$.fragment,d),p(xA.$$.fragment,d),p(kA.$$.fragment,d),p(RA.$$.fragment,d),p(SA.$$.fragment,d),p($A.$$.fragment,d),p(IA.$$.fragment,d),p(jA.$$.fragment,d),p(DA.$$.fragment,d),p(NA.$$.fragment,d),p(qA.$$.fragment,d),p(GA.$$.fragment,d),p(XA.$$.fragment,d),p(VA.$$.fragment,d),p(zA.$$.fragment,d),p(WA.$$.fragment,d),p(QA.$$.fragment,d),p(UA.$$.fragment,d),p(JA.$$.fragment,d),p(YA.$$.fragment,d),p(KA.$$.fragment,d),p(ZA.$$.fragment,d),p(eL.$$.fragment,d),p(rL.$$.fragment,d),p(tL.$$.fragment,d),p(aL.$$.fragment,d),p(nL.$$.fragment,d),p(sL.$$.fragment,d),p(lL.$$.fragment,d),p(dL.$$.fragment,d),p(cL.$$.fragment,d),p(fL.$$.fragment,d),p(mL.$$.fragment,d),p(gL.$$.fragment,d),p(hL.$$.fragment,d),p(_L.$$.fragment,d),p(uL.$$.fragment,d),p(bL.$$.fragment,d),p(vL.$$.fragment,d),p(TL.$$.fragment,d),p(FL.$$.fragment,d),p(ML.$$.fragment,d),p(EL.$$.fragment,d),p(yL.$$.fragment,d),p(wL.$$.fragment,d),p(AL.$$.fragment,d),p(LL.$$.fragment,d),p(xL.$$.fragment,d),p(kL.$$.fragment,d),p(RL.$$.fragment,d),p(SL.$$.fragment,d),p(PL.$$.fragment,d),p($L.$$.fragment,d),p(jL.$$.fragment,d),p(DL.$$.fragment,d),p(NL.$$.fragment,d),p(qL.$$.fragment,d),p(OL.$$.fragment,d),p(GL.$$.fragment,d),p(VL.$$.fragment,d),p(zL.$$.fragment,d),p(WL.$$.fragment,d),p(QL.$$.fragment,d),p(HL.$$.fragment,d),p(UL.$$.fragment,d),p(YL.$$.fragment,d),p(KL.$$.fragment,d),p(ZL.$$.fragment,d),p(o7.$$.fragment,d),p(r7.$$.fragment,d),p(t7.$$.fragment,d),p(n7.$$.fragment,d),p(s7.$$.fragment,d),p(l7.$$.fragment,d),p(i7.$$.fragment,d),URe=!1},d(d){t(J),d&&t(Pe),d&&t(de),_(fe),d&&t(Wf),d&&t(ha),d&&t(Le),d&&t(co),d&&t(Hf),_(Va,d),d&&t(fo),d&&t(pe),d&&t(Wo),d&&t(za),d&&t(Wxe),d&&t(Yi),_(c4),d&&t(Qxe),d&&t(Jn),d&&t(Hxe),_(f4,d),d&&t(Uxe),d&&t(f9),d&&t(Jxe),_(Yf,d),d&&t(Yxe),d&&t(Ki),_(m4),d&&t(Kxe),d&&t(Qo),_(g4),_(_4),_(u4),_(b4),d&&t(Zxe),d&&t(ed),_(v4),d&&t(eke),d&&t(Ho),_(T4),_(M4),_(E4),_(y4),d&&t(oke),d&&t(od),_(w4),d&&t(rke),d&&t(Uo),_(A4),_(x4),_(Ph),_(k4),_(R4),d&&t(tke),d&&t(rd),_(S4),d&&t(ake),d&&t(Jo),_(P4),_(j4),_(zh),_(D4),_(N4),d&&t(nke),d&&t(ad),_(q4),d&&t(ske),d&&t(Yo),_(O4),_(X4),_(V4),_(z4),_(W4),d&&t(lke),d&&t(ld),_(Q4),d&&t(ike),d&&t(Ko),_(H4),_(J4),_(Y4),_(K4),_(Z4),d&&t(dke),d&&t(cd),_(eE),d&&t(cke),d&&t(Zo),_(oE),_(tE),_(aE),_(nE),_(sE),d&&t(fke),d&&t(gd),_(lE),d&&t(mke),d&&t(er),_(iE),_(cE),_(fE),_(mE),_(gE),d&&t(gke),d&&t(_d),_(hE),d&&t(hke),d&&t(or),_(pE),_(uE),_(bE),_(vE),_(TE),d&&t(pke),d&&t(vd),_(FE),d&&t(_ke),d&&t(rr),_(CE),_(EE),_(yE),_(wE),_(AE),d&&t(uke),d&&t(Cd),_(LE),d&&t(bke),d&&t(tr),_(BE),_(kE),_(RE),_(SE),_(PE),d&&t(vke),d&&t(yd),_($E),d&&t(Tke),d&&t(ar),_(IE),_(DE),_(NE),_(qE),_(OE),d&&t(Fke),d&&t(Ld),_(GE),d&&t(Cke),d&&t(nr),_(XE),_(zE),_(WE),_(QE),_(HE),d&&t(Mke),d&&t(kd),_(UE),d&&t(Eke),d&&t(sr),_(JE),_(KE),_(ZE),_(e3),_(o3),d&&t(yke),d&&t(Pd),_(r3),d&&t(wke),d&&t(lr),_(t3),_(n3),_(s3),_(l3),_(i3),d&&t(Ake),d&&t(jd),_(d3),d&&t(Lke),d&&t(ir),_(c3),_(m3),_(g3),_(h3),_(p3),d&&t(Bke),d&&t(qd),_(_3),d&&t(xke),d&&t(dr),_(u3),_(v3),_(T3),_(F3),_(C3),d&&t(kke),d&&t(Xd),_(M3),d&&t(Rke),d&&t(cr),_(E3),_(w3),_(A3),_(L3),_(B3),d&&t(Ske),d&&t(Wd),_(x3),d&&t(Pke),d&&t(fr),_(k3),_(S3),_(P3),_($3),_(I3),d&&t($ke),d&&t(Ud),_(j3),d&&t(Ike),d&&t(mr),_(D3),_(q3),_(O3),_(G3),_(X3),d&&t(jke),d&&t(Kd),_(V3),d&&t(Dke),d&&t(gr),_(z3),_(Q3),_(H3),_(U3),_(Y3),d&&t(Nke),d&&t(oc),_(K3),d&&t(qke),d&&t(hr),_(Z3),_(oy),_(ry),_(ty),_(ay),d&&t(Oke),d&&t(ac),_(ny),d&&t(Gke),d&&t(pr),_(sy),_(iy),_(dy),_(cy),_(fy),d&&t(Xke),d&&t(ic),_(my),d&&t(Vke),d&&t(_r),_(gy),_(py),_(_y),_(uy),_(by),d&&t(zke),d&&t(fc),_(vy),d&&t(Wke),d&&t(ur),_(Ty),_(Cy),_(My),_(Ey),_(yy),d&&t(Qke),d&&t(hc),_(wy),d&&t(Hke),d&&t(br),_(Ay),_(By),_(xy),_(ky),_(Sy),d&&t(Uke),d&&t(uc),_(Py),d&&t(Jke),d&&t(vr),_($y),_(jy),_(Dy),_(Ny),_(qy),d&&t(Yke),d&&t(Tc),_(Oy),d&&t(Kke),d&&t(Tr),_(Gy),_(Vy),_(zy),_(Wy),_(Qy),d&&t(Zke),d&&t(Mc),_(Hy),d&&t(eRe),d&&t(Fr),_(Uy),_(Yy),_(Ky),_(Zy),_(ew),d&&t(oRe),d&&t(wc),_(ow),d&&t(rRe),d&&t(Cr),_(rw),_(aw),_(nw),_(sw),_(lw),d&&t(tRe),d&&t(Bc),_(iw),d&&t(aRe),d&&t(Mr),_(dw),_(fw),_(mw),_(gw),_(pw),d&&t(nRe),d&&t(Rc),_(_w),d&&t(sRe),d&&t(Er),_(uw),_(vw),_(Tw),_(Fw),_(Cw),d&&t(lRe),d&&t($c),_(Mw),d&&t(iRe),d&&t(yr),_(Ew),_(ww),_(Aw),_(Lw),_(Bw),d&&t(dRe),d&&t(Dc),_(xw),d&&t(cRe),d&&t(wr),_(kw),_(Sw),_(Pw),_($w),_(Iw),d&&t(fRe),d&&t(Oc),_(jw),d&&t(mRe),d&&t(Ar),_(Dw),_(qw),_(Ow),_(Gw),_(Xw),d&&t(gRe),d&&t(Vc),_(Vw),d&&t(hRe),d&&t(Lr),_(zw),_(Qw),_(Hw),_(Uw),_(Jw),d&&t(pRe),d&&t(Qc),_(Yw),d&&t(_Re),d&&t(Br),_(Kw),_(eA),_(oA),_(rA),_(tA),d&&t(uRe),d&&t(Jc),_(aA),d&&t(bRe),d&&t(xr),_(nA),_(lA),_(iA),_(dA),_(cA),d&&t(vRe),d&&t(Zc),_(fA),d&&t(TRe),d&&t(kr),_(mA),_(hA),_(pA),_(_A),_(uA),d&&t(FRe),d&&t(rf),_(bA),d&&t(CRe),d&&t(Rr),_(vA),_(FA),_(CA),_(MA),_(EA),d&&t(MRe),d&&t(nf),_(yA),d&&t(ERe),d&&t(Sr),_(wA),_(LA),_(BA),_(xA),_(kA),d&&t(yRe),d&&t(df),_(RA),d&&t(wRe),d&&t(Pr),_(SA),_($A),_(IA),_(jA),_(DA),d&&t(ARe),d&&t(mf),_(NA),d&&t(LRe),d&&t($r),_(qA),_(GA),_(XA),_(VA),_(zA),d&&t(BRe),d&&t(pf),_(WA),d&&t(xRe),d&&t(Ir),_(QA),_(UA),_(JA),_(YA),_(KA),d&&t(kRe),d&&t(bf),_(ZA),d&&t(RRe),d&&t(jr),_(eL),_(rL),_(tL),_(aL),_(nL),d&&t(SRe),d&&t(Ff),_(sL),d&&t(PRe),d&&t(Dr),_(lL),_(dL),_(cL),_(fL),_(mL),d&&t($Re),d&&t(Ef),_(gL),d&&t(IRe),d&&t(Nr),_(hL),_(_L),_(uL),_(bL),_(vL),d&&t(jRe),d&&t(Af),_(TL),d&&t(DRe),d&&t(qr),_(FL),_(ML),_(EL),_(yL),_(wL),d&&t(NRe),d&&t(xf),_(AL),d&&t(qRe),d&&t(Or),_(LL),_(xL),_(kL),_(RL),_(SL),d&&t(ORe),d&&t(Sf),_(PL),d&&t(GRe),d&&t(Gr),_($L),_(jL),_(DL),_(NL),_(qL),d&&t(XRe),d&&t(If),_(OL),d&&t(VRe),d&&t(Xr),_(GL),_(VL),_(zL),_(WL),_(QL),d&&t(zRe),d&&t(Nf),_(HL),d&&t(WRe),d&&t(Vr),_(UL),_(YL),_(KL),_(ZL),_(o7),d&&t(QRe),d&&t(Gf),_(r7),d&&t(HRe),d&&t(zr),_(t7),_(n7),_(s7),_(l7),_(i7)}}}const q8t={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForSpeechSeq2Seq",title:"FlaxAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function O8t(Xi,J,Pe){let{fw:de}=J;return Xi.$$set=he=>{"fw"in he&&Pe(0,de=he.fw)},[de]}class H8t extends R8t{constructor(J){super();S8t(this,J,O8t,N8t,P8t,{fw:0})}}export{H8t as default,q8t as metadata};
