import{S as Gs,i as Ys,s as Vs,e as l,k as h,w as E,t as r,M as Ws,c as s,d as t,m,a as i,x as T,h as a,b as c,N as Lr,F as o,g as f,y as P,q as A,o as j,B as H,L as bo}from"../chunks/vendor-6b77c823.js";import{T as Js}from"../chunks/Tip-39098574.js";import{Y as Ks}from"../chunks/Youtube-5c6e11e6.js";import{I as Je}from"../chunks/IconCopyLink-7a11ce68.js";import{C as B}from"../chunks/CodeBlock-3a8b25a8.js";import{F as Us,M as ko}from"../chunks/Markdown-4489c441.js";function Xs(x){let p,y,n,d,g;return{c(){p=l("p"),y=r("To share a model with the community, you need an account on "),n=l("a"),d=r("huggingface.co"),g=r(". You can also join an existing organization or create a new one."),this.h()},l($){p=s($,"P",{});var b=i(p);y=a(b,"To share a model with the community, you need an account on "),n=s(b,"A",{href:!0,rel:!0});var w=i(n);d=a(w,"huggingface.co"),w.forEach(t),g=a(b,". You can also join an existing organization or create a new one."),b.forEach(t),this.h()},h(){c(n,"href","https://huggingface.co/join"),c(n,"rel","nofollow")},m($,b){f($,p,b),o(p,y),o(p,n),o(n,d),o(p,g)},d($){$&&t(p)}}}function Zs(x){let p,y,n,d,g,$,b,w;return b=new B({props:{code:`pt_model = DistilBertForSequenceClassification.from_pretrained("path/to/awesome-name-you-picked", from_tf=True)
pt_model.save_pretrained("path/to/awesome-name-you-picked")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = DistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;path/to/awesome-name-you-picked&quot;</span>, from_tf=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(<span class="hljs-string">&quot;path/to/awesome-name-you-picked&quot;</span>)`}}),{c(){p=l("p"),y=r("Similarly, specify "),n=l("code"),d=r("from_tf=True"),g=r(" to convert a checkpoint from TensorFlow to PyTorch:"),$=h(),E(b.$$.fragment)},l(k){p=s(k,"P",{});var C=i(p);y=a(C,"Similarly, specify "),n=s(C,"CODE",{});var D=i(n);d=a(D,"from_tf=True"),D.forEach(t),g=a(C," to convert a checkpoint from TensorFlow to PyTorch:"),C.forEach(t),$=m(k),T(b.$$.fragment,k)},m(k,C){f(k,p,C),o(p,y),o(p,n),o(n,d),o(p,g),f(k,$,C),P(b,k,C),w=!0},p:bo,i(k){w||(A(b.$$.fragment,k),w=!0)},o(k){j(b.$$.fragment,k),w=!1},d(k){k&&t(p),k&&t($),H(b,k)}}}function Qs(x){let p,y;return p=new ko({props:{$$slots:{default:[Zs]},$$scope:{ctx:x}}}),{c(){E(p.$$.fragment)},l(n){T(p.$$.fragment,n)},m(n,d){P(p,n,d),y=!0},p(n,d){const g={};d&2&&(g.$$scope={dirty:d,ctx:n}),p.$set(g)},i(n){y||(A(p.$$.fragment,n),y=!0)},o(n){j(p.$$.fragment,n),y=!1},d(n){H(p,n)}}}function ei(x){let p,y,n,d,g,$,b;return p=new B({props:{code:'tf_model = TFDistilBertForSequenceClassification.from_pretrained("path/to/awesome-name-you-picked", from_pt=True)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;path/to/awesome-name-you-picked&quot;</span>, from_pt=<span class="hljs-literal">True</span>)'}}),$=new B({props:{code:'tf_model.save_pretrained("path/to/awesome-name-you-picked")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(<span class="hljs-string">&quot;path/to/awesome-name-you-picked&quot;</span>)'}}),{c(){E(p.$$.fragment),y=h(),n=l("p"),d=r("Then save your new TensorFlow model with it\u2019s new checkpoint:"),g=h(),E($.$$.fragment)},l(w){T(p.$$.fragment,w),y=m(w),n=s(w,"P",{});var k=i(n);d=a(k,"Then save your new TensorFlow model with it\u2019s new checkpoint:"),k.forEach(t),g=m(w),T($.$$.fragment,w)},m(w,k){P(p,w,k),f(w,y,k),f(w,n,k),o(n,d),f(w,g,k),P($,w,k),b=!0},p:bo,i(w){b||(A(p.$$.fragment,w),A($.$$.fragment,w),b=!0)},o(w){j(p.$$.fragment,w),j($.$$.fragment,w),b=!1},d(w){H(p,w),w&&t(y),w&&t(n),w&&t(g),H($,w)}}}function ti(x){let p,y;return p=new ko({props:{$$slots:{default:[ei]},$$scope:{ctx:x}}}),{c(){E(p.$$.fragment)},l(n){T(p.$$.fragment,n)},m(n,d){P(p,n,d),y=!0},p(n,d){const g={};d&2&&(g.$$scope={dirty:d,ctx:n}),p.$set(g)},i(n){y||(A(p.$$.fragment,n),y=!0)},o(n){j(p.$$.fragment,n),y=!1},d(n){H(p,n)}}}function oi(x){let p,y,n,d,g;return d=new B({props:{code:`flax_model = FlaxDistilBertForSequenceClassification.from_pretrained(
    "path/to/awesome-name-you-picked", from_pt=True
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>flax_model = FlaxDistilBertForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;path/to/awesome-name-you-picked&quot;</span>, from_pt=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)`}}),{c(){p=l("p"),y=r("If a model is available in Flax, you can also convert a checkpoint from PyTorch to Flax:"),n=h(),E(d.$$.fragment)},l($){p=s($,"P",{});var b=i(p);y=a(b,"If a model is available in Flax, you can also convert a checkpoint from PyTorch to Flax:"),b.forEach(t),n=m($),T(d.$$.fragment,$)},m($,b){f($,p,b),o(p,y),f($,n,b),P(d,$,b),g=!0},p:bo,i($){g||(A(d.$$.fragment,$),g=!0)},o($){j(d.$$.fragment,$),g=!1},d($){$&&t(p),$&&t(n),H(d,$)}}}function ri(x){let p,y;return p=new ko({props:{$$slots:{default:[oi]},$$scope:{ctx:x}}}),{c(){E(p.$$.fragment)},l(n){T(p.$$.fragment,n)},m(n,d){P(p,n,d),y=!0},p(n,d){const g={};d&2&&(g.$$scope={dirty:d,ctx:n}),p.$set(g)},i(n){y||(A(p.$$.fragment,n),y=!0)},o(n){j(p.$$.fragment,n),y=!1},d(n){H(p,n)}}}function ai(x){let p,y,n,d,g,$,b,w,k,C,D,ne,ae,M,fe,W,G,J,K,I,oe,X,Z,te,U,Y,q,z,le,L,re,O,N,v,S,ue,V,Q;return p=new Ks({props:{id:"Z1-XMy-GNLQ"}}),J=new B({props:{code:'training_args = TrainingArguments(output_dir="my-awesome-model", push_to_hub=True)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;my-awesome-model&quot;</span>, push_to_hub=<span class="hljs-literal">True</span>)'}}),Y=new B({props:{code:`trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=small_train_dataset,
<span class="hljs-meta">... </span>    eval_dataset=small_eval_dataset,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)`}}),V=new B({props:{code:"trainer.push_to_hub()",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()'}}),{c(){E(p.$$.fragment),y=h(),n=l("p"),d=r("Sharing a model to the Hub is as simple as adding an extra parameter or callback. Remember from the "),g=l("a"),$=r("fine-tuning tutorial"),b=r(", the "),w=l("a"),k=r("TrainingArguments"),C=r(" class is where you specify hyperparameters and additional training options. One of these training options includes the ability to push a model directly to the Hub. Set "),D=l("code"),ne=r("push_to_hub=True"),ae=r(" in your "),M=l("a"),fe=r("TrainingArguments"),W=r(":"),G=h(),E(J.$$.fragment),K=h(),I=l("p"),oe=r("Pass your training arguments as usual to "),X=l("a"),Z=r("Trainer"),te=r(":"),U=h(),E(Y.$$.fragment),q=h(),z=l("p"),le=r("After you fine-tune your model, call "),L=l("a"),re=r("push_to_hub()"),O=r(" on "),N=l("a"),v=r("Trainer"),S=r(" to push the trained model to the Hub. \u{1F917} Transformers will even automatically add training hyperparameters, training results and framework versions to your model card!"),ue=h(),E(V.$$.fragment),this.h()},l(_){T(p.$$.fragment,_),y=m(_),n=s(_,"P",{});var F=i(n);d=a(F,"Sharing a model to the Hub is as simple as adding an extra parameter or callback. Remember from the "),g=s(F,"A",{href:!0});var pe=i(g);$=a(pe,"fine-tuning tutorial"),pe.forEach(t),b=a(F,", the "),w=s(F,"A",{href:!0});var he=i(w);k=a(he,"TrainingArguments"),he.forEach(t),C=a(F," class is where you specify hyperparameters and additional training options. One of these training options includes the ability to push a model directly to the Hub. Set "),D=s(F,"CODE",{});var R=i(D);ne=a(R,"push_to_hub=True"),R.forEach(t),ae=a(F," in your "),M=s(F,"A",{href:!0});var ye=i(M);fe=a(ye,"TrainingArguments"),ye.forEach(t),W=a(F,":"),F.forEach(t),G=m(_),T(J.$$.fragment,_),K=m(_),I=s(_,"P",{});var ee=i(I);oe=a(ee,"Pass your training arguments as usual to "),X=s(ee,"A",{href:!0});var bt=i(X);Z=a(bt,"Trainer"),bt.forEach(t),te=a(ee,":"),ee.forEach(t),U=m(_),T(Y.$$.fragment,_),q=m(_),z=s(_,"P",{});var me=i(z);le=a(me,"After you fine-tune your model, call "),L=s(me,"A",{href:!0});var Ee=i(L);re=a(Ee,"push_to_hub()"),Ee.forEach(t),O=a(me," on "),N=s(me,"A",{href:!0});var kt=i(N);v=a(kt,"Trainer"),kt.forEach(t),S=a(me," to push the trained model to the Hub. \u{1F917} Transformers will even automatically add training hyperparameters, training results and framework versions to your model card!"),me.forEach(t),ue=m(_),T(V.$$.fragment,_),this.h()},h(){c(g,"href","training"),c(w,"href","/docs/transformers/pr_16342/en/main_classes/trainer#transformers.TrainingArguments"),c(M,"href","/docs/transformers/pr_16342/en/main_classes/trainer#transformers.TrainingArguments"),c(X,"href","/docs/transformers/pr_16342/en/main_classes/trainer#transformers.Trainer"),c(L,"href","/docs/transformers/pr_16342/en/main_classes/trainer#transformers.Trainer.push_to_hub"),c(N,"href","/docs/transformers/pr_16342/en/main_classes/trainer#transformers.Trainer")},m(_,F){P(p,_,F),f(_,y,F),f(_,n,F),o(n,d),o(n,g),o(g,$),o(n,b),o(n,w),o(w,k),o(n,C),o(n,D),o(D,ne),o(n,ae),o(n,M),o(M,fe),o(n,W),f(_,G,F),P(J,_,F),f(_,K,F),f(_,I,F),o(I,oe),o(I,X),o(X,Z),o(I,te),f(_,U,F),P(Y,_,F),f(_,q,F),f(_,z,F),o(z,le),o(z,L),o(L,re),o(z,O),o(z,N),o(N,v),o(z,S),f(_,ue,F),P(V,_,F),Q=!0},p:bo,i(_){Q||(A(p.$$.fragment,_),A(J.$$.fragment,_),A(Y.$$.fragment,_),A(V.$$.fragment,_),Q=!0)},o(_){j(p.$$.fragment,_),j(J.$$.fragment,_),j(Y.$$.fragment,_),j(V.$$.fragment,_),Q=!1},d(_){H(p,_),_&&t(y),_&&t(n),_&&t(G),H(J,_),_&&t(K),_&&t(I),_&&t(U),H(Y,_),_&&t(q),_&&t(z),_&&t(ue),H(V,_)}}}function li(x){let p,y;return p=new ko({props:{$$slots:{default:[ai]},$$scope:{ctx:x}}}),{c(){E(p.$$.fragment)},l(n){T(p.$$.fragment,n)},m(n,d){P(p,n,d),y=!0},p(n,d){const g={};d&2&&(g.$$scope={dirty:d,ctx:n}),p.$set(g)},i(n){y||(A(p.$$.fragment,n),y=!0)},o(n){j(p.$$.fragment,n),y=!1},d(n){H(p,n)}}}function si(x){let p,y,n,d,g,$,b,w,k,C,D,ne,ae,M,fe,W,G,J,K,I,oe,X,Z,te,U,Y,q,z,le,L,re,O,N;return Z=new B({props:{code:`from transformers.keras.callbacks import PushToHubCallback

push_to_hub_callback = PushToHubCallback(
    output_dir="./your_model_save_path", tokenizer=tokenizer, hub_model_id="your-username/my-awesome-model"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras.callbacks <span class="hljs-keyword">import</span> PushToHubCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>push_to_hub_callback = PushToHubCallback(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;./your_model_save_path&quot;</span>, tokenizer=tokenizer, hub_model_id=<span class="hljs-string">&quot;your-username/my-awesome-model&quot;</span>
<span class="hljs-meta">... </span>)`}}),O=new B({props:{code:"model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3, callbacks=push_to_hub_callback)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=<span class="hljs-number">3</span>, callbacks=push_to_hub_callback)'}}),{c(){p=l("p"),y=r("Share a model to the Hub with "),n=l("a"),d=r("PushToHubCallback"),g=r(". In the "),$=l("a"),b=r("PushToHubCallback"),w=r(" function, add:"),k=h(),C=l("ul"),D=l("li"),ne=r("An output directory for your model."),ae=h(),M=l("li"),fe=r("A tokenizer."),W=h(),G=l("li"),J=r("The "),K=l("code"),I=r("hub_model_id"),oe=r(", which is your Hub username and model name."),X=h(),E(Z.$$.fragment),te=h(),U=l("p"),Y=r("Add the callback to "),q=l("a"),z=l("code"),le=r("fit"),L=r(", and \u{1F917} Transformers will push the trained model to the Hub:"),re=h(),E(O.$$.fragment),this.h()},l(v){p=s(v,"P",{});var S=i(p);y=a(S,"Share a model to the Hub with "),n=s(S,"A",{href:!0});var ue=i(n);d=a(ue,"PushToHubCallback"),ue.forEach(t),g=a(S,". In the "),$=s(S,"A",{href:!0});var V=i($);b=a(V,"PushToHubCallback"),V.forEach(t),w=a(S," function, add:"),S.forEach(t),k=m(v),C=s(v,"UL",{});var Q=i(C);D=s(Q,"LI",{});var _=i(D);ne=a(_,"An output directory for your model."),_.forEach(t),ae=m(Q),M=s(Q,"LI",{});var F=i(M);fe=a(F,"A tokenizer."),F.forEach(t),W=m(Q),G=s(Q,"LI",{});var pe=i(G);J=a(pe,"The "),K=s(pe,"CODE",{});var he=i(K);I=a(he,"hub_model_id"),he.forEach(t),oe=a(pe,", which is your Hub username and model name."),pe.forEach(t),Q.forEach(t),X=m(v),T(Z.$$.fragment,v),te=m(v),U=s(v,"P",{});var R=i(U);Y=a(R,"Add the callback to "),q=s(R,"A",{href:!0,rel:!0});var ye=i(q);z=s(ye,"CODE",{});var ee=i(z);le=a(ee,"fit"),ee.forEach(t),ye.forEach(t),L=a(R,", and \u{1F917} Transformers will push the trained model to the Hub:"),R.forEach(t),re=m(v),T(O.$$.fragment,v),this.h()},h(){c(n,"href","/docs/transformers/pr_16342/en/main_classes/keras_callbacks#transformers.PushToHubCallback"),c($,"href","/docs/transformers/pr_16342/en/main_classes/keras_callbacks#transformers.PushToHubCallback"),c(q,"href","https://keras.io/api/models/model_training_apis/"),c(q,"rel","nofollow")},m(v,S){f(v,p,S),o(p,y),o(p,n),o(n,d),o(p,g),o(p,$),o($,b),o(p,w),f(v,k,S),f(v,C,S),o(C,D),o(D,ne),o(C,ae),o(C,M),o(M,fe),o(C,W),o(C,G),o(G,J),o(G,K),o(K,I),o(G,oe),f(v,X,S),P(Z,v,S),f(v,te,S),f(v,U,S),o(U,Y),o(U,q),o(q,z),o(z,le),o(U,L),f(v,re,S),P(O,v,S),N=!0},p:bo,i(v){N||(A(Z.$$.fragment,v),A(O.$$.fragment,v),N=!0)},o(v){j(Z.$$.fragment,v),j(O.$$.fragment,v),N=!1},d(v){v&&t(p),v&&t(k),v&&t(C),v&&t(X),H(Z,v),v&&t(te),v&&t(U),v&&t(re),H(O,v)}}}function ii(x){let p,y;return p=new ko({props:{$$slots:{default:[si]},$$scope:{ctx:x}}}),{c(){E(p.$$.fragment)},l(n){T(p.$$.fragment,n)},m(n,d){P(p,n,d),y=!0},p(n,d){const g={};d&2&&(g.$$scope={dirty:d,ctx:n}),p.$set(g)},i(n){y||(A(p.$$.fragment,n),y=!0)},o(n){j(p.$$.fragment,n),y=!1},d(n){H(p,n)}}}function ni(x){let p,y,n,d,g,$,b,w,k,C,D,ne,ae,M,fe,W,G,J,K,I,oe,X,Z,te,U,Y,q,z,le,L,re,O,N,v,S,ue,V,Q,_,F,pe,he,R,ye,ee,bt,me,Ee,kt,Rr,Eo,Te,Br,Nt,Ur,Gr,To,Ke,Po,Et,Yr,Ao,Tt,Pt,Fl,jo,$e,Pe,zt,Xe,Vr,Lt,Wr,Ho,Ae,Jr,Rt,Kr,Xr,Fo,Ze,Co,je,Zr,Qe,Bt,Qr,ea,So,et,qo,ce,ta,Ut,oa,ra,tt,aa,la,xo,ot,Do,ge,He,Gt,rt,sa,Yt,ia,Mo,At,na,Io,Fe,fa,jt,ua,pa,Oo,Ce,ha,Vt,ma,ca,No,Se,zo,we,qe,Wt,at,da,Jt,_a,Lo,xe,Ro,ve,De,Kt,lt,ya,st,$a,Xt,ga,wa,Bo,Me,va,Zt,ba,ka,Uo,Ie,Ea,Qt,Ta,Pa,Go,it,Yo,de,Aa,eo,ja,Ha,to,Fa,Ca,Vo,nt,Wo,Oe,Sa,oo,qa,xa,Jo,ft,Ko,Ne,Da,ro,Ma,Ia,Xo,ut,Zo,Ht,Oa,Qo,pt,er,ze,Na,ao,za,La,tr,Le,Ra,ht,Ba,Ua,or,be,Re,lo,mt,Ga,so,Ya,rr,Be,Va,ct,Wa,Ja,ar,Ft,Ct,Cl,lr,St,Ka,sr,se,dt,Xa,io,Za,Qa,el,no,tl,ol,fo,rl,al,uo,ll,ir,_e,sl,po,il,nl,ho,fl,ul,nr,qt,xt,Sl,fr,ke,Ue,mo,_t,pl,co,hl,ur,Ge,ml,_o,cl,dl,pr,Ye,yt,_l,yo,yl,$l,gl,$t,wl,$o,vl,bl,hr,ie,kl,gt,El,Tl,go,Pl,Al,wt,jl,Hl,mr;return $=new Je({}),L=new Js({props:{$$slots:{default:[Xs]},$$scope:{ctx:x}}}),S=new Je({}),Ke=new B({props:{code:`model = AutoModel.from_pretrained(
    "julien-c/EsperBERTo-small", revision="v2.0.1"  # tag name, or branch name, or commit hash
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;julien-c/EsperBERTo-small&quot;</span>, revision=<span class="hljs-string">&quot;v2.0.1&quot;</span>  <span class="hljs-comment"># tag name, or branch name, or commit hash</span>
<span class="hljs-meta">... </span>)`}}),Xe=new Je({}),Ze=new B({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),et=new B({props:{code:"pip install huggingface_hub",highlighted:"pip install huggingface_hub"}}),ot=new B({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`}}),rt=new Je({}),Se=new Us({props:{pytorch:!0,tensorflow:!0,jax:!0,$$slots:{jax:[ri],tensorflow:[ti],pytorch:[Qs]},$$scope:{ctx:x}}}),at=new Je({}),xe=new Us({props:{pytorch:!0,tensorflow:!0,jax:!0,$$slots:{tensorflow:[ii],pytorch:[li]},$$scope:{ctx:x}}}),lt=new Je({}),it=new B({props:{code:'pt_model.push_to_hub("my-awesome-model")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>)'}}),nt=new B({props:{code:`from transformers import AutoModel

model = AutoModel.from_pretrained("your_username/my-awesome-model")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;your_username/my-awesome-model&quot;</span>)`}}),ft=new B({props:{code:'pt_model.push_to_hub("my-awesome-model", organization="my-awesome-org")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>, organization=<span class="hljs-string">&quot;my-awesome-org&quot;</span>)'}}),ut=new B({props:{code:'tokenizer.push_to_hub("my-awesome-model")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>)'}}),pt=new B({props:{code:'tf_model.push_to_hub("my-awesome-model")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>)'}}),mt=new Je({}),_t=new Je({}),{c(){p=l("meta"),y=h(),n=l("h1"),d=l("a"),g=l("span"),E($.$$.fragment),b=h(),w=l("span"),k=r("Share a model"),C=h(),D=l("p"),ne=r("The last two tutorials showed how you can fine-tune a model with PyTorch, Keras, and \u{1F917} Accelerate for distributed setups. The next step is to share your model with the community! At Hugging Face, we believe in openly sharing knowledge and resources to democratize artificial intelligence for everyone. We encourage you to consider sharing your model with the community to help others save time and resources."),ae=h(),M=l("p"),fe=r("In this tutorial, you will learn two methods for sharing a trained or fine-tuned model on the "),W=l("a"),G=r("Model Hub"),J=r(":"),K=h(),I=l("ul"),oe=l("li"),X=r("Programmatically push your files to the Hub."),Z=h(),te=l("li"),U=r("Drag-and-drop your files to the Hub with the web interface."),Y=h(),q=l("iframe"),le=h(),E(L.$$.fragment),re=h(),O=l("h2"),N=l("a"),v=l("span"),E(S.$$.fragment),ue=h(),V=l("span"),Q=r("Repository features"),_=h(),F=l("p"),pe=r("Each repository on the Model Hub behaves like a typical GitHub repository. Our repositories offer versioning, commit history, and the ability to visualize differences."),he=h(),R=l("p"),ye=r("The Model Hub\u2019s built-in versioning is based on git and "),ee=l("a"),bt=r("git-lfs"),me=r(". In other words, you can treat one model as one repository, enabling greater access control and scalability. Version control allows "),Ee=l("em"),kt=r("revisions"),Rr=r(", a method for pinning a specific version of a model with a commit hash, tag or branch."),Eo=h(),Te=l("p"),Br=r("As a result, you can load a specific model version with the "),Nt=l("code"),Ur=r("revision"),Gr=r(" parameter:"),To=h(),E(Ke.$$.fragment),Po=h(),Et=l("p"),Yr=r("Files are also easily edited in a repository, and you can view the commit history as well as the difference:"),Ao=h(),Tt=l("p"),Pt=l("img"),jo=h(),$e=l("h2"),Pe=l("a"),zt=l("span"),E(Xe.$$.fragment),Vr=h(),Lt=l("span"),Wr=r("Setup"),Ho=h(),Ae=l("p"),Jr=r("Before sharing a model to the Hub, you will need your Hugging Face credentials. If you have access to a terminal, run the following command in the virtual environment where \u{1F917} Transformers is installed. This will store your access token in your Hugging Face cache folder ("),Rt=l("code"),Kr=r("~/.cache/"),Xr=r(" by default):"),Fo=h(),E(Ze.$$.fragment),Co=h(),je=l("p"),Zr=r("If you are using a notebook like Jupyter or Colaboratory, make sure you have the "),Qe=l("a"),Bt=l("code"),Qr=r("huggingface_hub"),ea=r(" library installed. This library allows you to programmatically interact with the Hub."),So=h(),E(et.$$.fragment),qo=h(),ce=l("p"),ta=r("Then use "),Ut=l("code"),oa=r("notebook_login"),ra=r(" to sign-in to the Hub, and follow the link "),tt=l("a"),aa=r("here"),la=r(" to generate a token to login with:"),xo=h(),E(ot.$$.fragment),Do=h(),ge=l("h2"),He=l("a"),Gt=l("span"),E(rt.$$.fragment),sa=h(),Yt=l("span"),ia=r("Convert a model for all frameworks"),Mo=h(),At=l("p"),na=r("To ensure your model can be used by someone working with a different framework, we recommend you convert and upload your model with both PyTorch and TensorFlow checkpoints. While users are still able to load your model from a different framework if you skip this step, it will be slower because \u{1F917} Transformers will need to convert the checkpoint on-the-fly."),Io=h(),Fe=l("p"),fa=r("Converting a checkpoint for another framework is easy. Make sure you have PyTorch and TensorFlow installed (see "),jt=l("a"),ua=r("here"),pa=r(" for installation instructions), and then find the specific model for your task in the other framework."),Oo=h(),Ce=l("p"),ha=r("For example, suppose you trained DistilBert for sequence classification in PyTorch and want to convert it to it\u2019s TensorFlow equivalent. Load the TensorFlow equivalent of your model for your task, and specify "),Vt=l("code"),ma=r("from_pt=True"),ca=r(" so \u{1F917} Transformers will convert the PyTorch checkpoint to a TensorFlow checkpoint:"),No=h(),E(Se.$$.fragment),zo=h(),we=l("h2"),qe=l("a"),Wt=l("span"),E(at.$$.fragment),da=h(),Jt=l("span"),_a=r("Push a model during training"),Lo=h(),E(xe.$$.fragment),Ro=h(),ve=l("h2"),De=l("a"),Kt=l("span"),E(lt.$$.fragment),ya=h(),st=l("span"),$a=r("Use the "),Xt=l("code"),ga=r("push_to_hub"),wa=r(" function"),Bo=h(),Me=l("p"),va=r("You can also call "),Zt=l("code"),ba=r("push_to_hub"),ka=r(" directly on your model to upload it to the Hub."),Uo=h(),Ie=l("p"),Ea=r("Specify your model name in "),Qt=l("code"),Ta=r("push_to_hub"),Pa=r(":"),Go=h(),E(it.$$.fragment),Yo=h(),de=l("p"),Aa=r("This creates a repository under your username with the model name "),eo=l("code"),ja=r("my-awesome-model"),Ha=r(". Users can now load your model with the "),to=l("code"),Fa=r("from_pretrained"),Ca=r(" function:"),Vo=h(),E(nt.$$.fragment),Wo=h(),Oe=l("p"),Sa=r("If you belong to an organization and want to push your model under the organization name instead, add the "),oo=l("code"),qa=r("organization"),xa=r(" parameter:"),Jo=h(),E(ft.$$.fragment),Ko=h(),Ne=l("p"),Da=r("The "),ro=l("code"),Ma=r("push_to_hub"),Ia=r(" function can also be used to add other files to a model repository. For example, add a tokenizer to a model repository:"),Xo=h(),E(ut.$$.fragment),Zo=h(),Ht=l("p"),Oa=r("Or perhaps you\u2019d like to add the TensorFlow version of your fine-tuned PyTorch model:"),Qo=h(),E(pt.$$.fragment),er=h(),ze=l("p"),Na=r("Now when you navigate to the your Hugging Face profile, you should see your newly created model repository. Clicking on the "),ao=l("strong"),za=r("Files"),La=r(" tab will display all the files you\u2019ve uploaded to the repository."),tr=h(),Le=l("p"),Ra=r("For more details on how to create and upload files to a repository, refer to the Hub documentation "),ht=l("a"),Ba=r("here"),Ua=r("."),or=h(),be=l("h2"),Re=l("a"),lo=l("span"),E(mt.$$.fragment),Ga=h(),so=l("span"),Ya=r("Upload with the web interface"),rr=h(),Be=l("p"),Va=r("Users who prefer a no-code approach are able to upload a model through the Hub\u2019s web interface. Visit "),ct=l("a"),Wa=r("huggingface.co/new"),Ja=r(" to create a new repository:"),ar=h(),Ft=l("p"),Ct=l("img"),lr=h(),St=l("p"),Ka=r("From here, add some information about your model:"),sr=h(),se=l("ul"),dt=l("li"),Xa=r("Select the "),io=l("strong"),Za=r("owner"),Qa=r(" of the repository. This can be yourself or any of the organizations you belong to."),el=h(),no=l("li"),tl=r("Pick a name for your model, which will also be the repository name."),ol=h(),fo=l("li"),rl=r("Choose whether your model is public or private."),al=h(),uo=l("li"),ll=r("Specify the license usage for your model."),ir=h(),_e=l("p"),sl=r("Now click on the "),po=l("strong"),il=r("Files"),nl=r(" tab and click on the "),ho=l("strong"),fl=r("Add file"),ul=r(" button to upload a new file to your repository. Then drag-and-drop a file to upload and add a commit message."),nr=h(),qt=l("p"),xt=l("img"),fr=h(),ke=l("h2"),Ue=l("a"),mo=l("span"),E(_t.$$.fragment),pl=h(),co=l("span"),hl=r("Add a model card"),ur=h(),Ge=l("p"),ml=r("To make sure users understand your model\u2019s capabilities, limitations, potential biases and ethical considerations, please add a model card to your repository. The model card is defined in the "),_o=l("code"),cl=r("README.md"),dl=r(" file. You can add a model card by:"),pr=h(),Ye=l("ul"),yt=l("li"),_l=r("Manually creating and uploading a "),yo=l("code"),yl=r("README.md"),$l=r(" file."),gl=h(),$t=l("li"),wl=r("Clicking on the "),$o=l("strong"),vl=r("Edit model card"),bl=r(" button in your model repository."),hr=h(),ie=l("p"),kl=r("Take a look at the DistilBert "),gt=l("a"),El=r("model card"),Tl=r(" for a good example of the type of information a model card should include. For more details about other options you can control in the "),go=l("code"),Pl=r("README.md"),Al=r(" file such as a model\u2019s carbon footprint or widget examples, refer to the documentation "),wt=l("a"),jl=r("here"),Hl=r("."),this.h()},l(e){const u=Ws('[data-svelte="svelte-1phssyn"]',document.head);p=s(u,"META",{name:!0,content:!0}),u.forEach(t),y=m(e),n=s(e,"H1",{class:!0});var vt=i(n);d=s(vt,"A",{id:!0,class:!0,href:!0});var wo=i(d);g=s(wo,"SPAN",{});var vo=i(g);T($.$$.fragment,vo),vo.forEach(t),wo.forEach(t),b=m(vt),w=s(vt,"SPAN",{});var ql=i(w);k=a(ql,"Share a model"),ql.forEach(t),vt.forEach(t),C=m(e),D=s(e,"P",{});var xl=i(D);ne=a(xl,"The last two tutorials showed how you can fine-tune a model with PyTorch, Keras, and \u{1F917} Accelerate for distributed setups. The next step is to share your model with the community! At Hugging Face, we believe in openly sharing knowledge and resources to democratize artificial intelligence for everyone. We encourage you to consider sharing your model with the community to help others save time and resources."),xl.forEach(t),ae=m(e),M=s(e,"P",{});var cr=i(M);fe=a(cr,"In this tutorial, you will learn two methods for sharing a trained or fine-tuned model on the "),W=s(cr,"A",{href:!0,rel:!0});var Dl=i(W);G=a(Dl,"Model Hub"),Dl.forEach(t),J=a(cr,":"),cr.forEach(t),K=m(e),I=s(e,"UL",{});var dr=i(I);oe=s(dr,"LI",{});var Ml=i(oe);X=a(Ml,"Programmatically push your files to the Hub."),Ml.forEach(t),Z=m(dr),te=s(dr,"LI",{});var Il=i(te);U=a(Il,"Drag-and-drop your files to the Hub with the web interface."),Il.forEach(t),dr.forEach(t),Y=m(e),q=s(e,"IFRAME",{width:!0,height:!0,src:!0,title:!0,frameborder:!0,allow:!0}),i(q).forEach(t),le=m(e),T(L.$$.fragment,e),re=m(e),O=s(e,"H2",{class:!0});var _r=i(O);N=s(_r,"A",{id:!0,class:!0,href:!0});var Ol=i(N);v=s(Ol,"SPAN",{});var Nl=i(v);T(S.$$.fragment,Nl),Nl.forEach(t),Ol.forEach(t),ue=m(_r),V=s(_r,"SPAN",{});var zl=i(V);Q=a(zl,"Repository features"),zl.forEach(t),_r.forEach(t),_=m(e),F=s(e,"P",{});var Ll=i(F);pe=a(Ll,"Each repository on the Model Hub behaves like a typical GitHub repository. Our repositories offer versioning, commit history, and the ability to visualize differences."),Ll.forEach(t),he=m(e),R=s(e,"P",{});var Dt=i(R);ye=a(Dt,"The Model Hub\u2019s built-in versioning is based on git and "),ee=s(Dt,"A",{href:!0,rel:!0});var Rl=i(ee);bt=a(Rl,"git-lfs"),Rl.forEach(t),me=a(Dt,". In other words, you can treat one model as one repository, enabling greater access control and scalability. Version control allows "),Ee=s(Dt,"EM",{});var Bl=i(Ee);kt=a(Bl,"revisions"),Bl.forEach(t),Rr=a(Dt,", a method for pinning a specific version of a model with a commit hash, tag or branch."),Dt.forEach(t),Eo=m(e),Te=s(e,"P",{});var yr=i(Te);Br=a(yr,"As a result, you can load a specific model version with the "),Nt=s(yr,"CODE",{});var Ul=i(Nt);Ur=a(Ul,"revision"),Ul.forEach(t),Gr=a(yr," parameter:"),yr.forEach(t),To=m(e),T(Ke.$$.fragment,e),Po=m(e),Et=s(e,"P",{});var Gl=i(Et);Yr=a(Gl,"Files are also easily edited in a repository, and you can view the commit history as well as the difference:"),Gl.forEach(t),Ao=m(e),Tt=s(e,"P",{});var Yl=i(Tt);Pt=s(Yl,"IMG",{src:!0,alt:!0}),Yl.forEach(t),jo=m(e),$e=s(e,"H2",{class:!0});var $r=i($e);Pe=s($r,"A",{id:!0,class:!0,href:!0});var Vl=i(Pe);zt=s(Vl,"SPAN",{});var Wl=i(zt);T(Xe.$$.fragment,Wl),Wl.forEach(t),Vl.forEach(t),Vr=m($r),Lt=s($r,"SPAN",{});var Jl=i(Lt);Wr=a(Jl,"Setup"),Jl.forEach(t),$r.forEach(t),Ho=m(e),Ae=s(e,"P",{});var gr=i(Ae);Jr=a(gr,"Before sharing a model to the Hub, you will need your Hugging Face credentials. If you have access to a terminal, run the following command in the virtual environment where \u{1F917} Transformers is installed. This will store your access token in your Hugging Face cache folder ("),Rt=s(gr,"CODE",{});var Kl=i(Rt);Kr=a(Kl,"~/.cache/"),Kl.forEach(t),Xr=a(gr," by default):"),gr.forEach(t),Fo=m(e),T(Ze.$$.fragment,e),Co=m(e),je=s(e,"P",{});var wr=i(je);Zr=a(wr,"If you are using a notebook like Jupyter or Colaboratory, make sure you have the "),Qe=s(wr,"A",{href:!0,rel:!0});var Xl=i(Qe);Bt=s(Xl,"CODE",{});var Zl=i(Bt);Qr=a(Zl,"huggingface_hub"),Zl.forEach(t),Xl.forEach(t),ea=a(wr," library installed. This library allows you to programmatically interact with the Hub."),wr.forEach(t),So=m(e),T(et.$$.fragment,e),qo=m(e),ce=s(e,"P",{});var Mt=i(ce);ta=a(Mt,"Then use "),Ut=s(Mt,"CODE",{});var Ql=i(Ut);oa=a(Ql,"notebook_login"),Ql.forEach(t),ra=a(Mt," to sign-in to the Hub, and follow the link "),tt=s(Mt,"A",{href:!0,rel:!0});var es=i(tt);aa=a(es,"here"),es.forEach(t),la=a(Mt," to generate a token to login with:"),Mt.forEach(t),xo=m(e),T(ot.$$.fragment,e),Do=m(e),ge=s(e,"H2",{class:!0});var vr=i(ge);He=s(vr,"A",{id:!0,class:!0,href:!0});var ts=i(He);Gt=s(ts,"SPAN",{});var os=i(Gt);T(rt.$$.fragment,os),os.forEach(t),ts.forEach(t),sa=m(vr),Yt=s(vr,"SPAN",{});var rs=i(Yt);ia=a(rs,"Convert a model for all frameworks"),rs.forEach(t),vr.forEach(t),Mo=m(e),At=s(e,"P",{});var as=i(At);na=a(as,"To ensure your model can be used by someone working with a different framework, we recommend you convert and upload your model with both PyTorch and TensorFlow checkpoints. While users are still able to load your model from a different framework if you skip this step, it will be slower because \u{1F917} Transformers will need to convert the checkpoint on-the-fly."),as.forEach(t),Io=m(e),Fe=s(e,"P",{});var br=i(Fe);fa=a(br,"Converting a checkpoint for another framework is easy. Make sure you have PyTorch and TensorFlow installed (see "),jt=s(br,"A",{href:!0});var ls=i(jt);ua=a(ls,"here"),ls.forEach(t),pa=a(br," for installation instructions), and then find the specific model for your task in the other framework."),br.forEach(t),Oo=m(e),Ce=s(e,"P",{});var kr=i(Ce);ha=a(kr,"For example, suppose you trained DistilBert for sequence classification in PyTorch and want to convert it to it\u2019s TensorFlow equivalent. Load the TensorFlow equivalent of your model for your task, and specify "),Vt=s(kr,"CODE",{});var ss=i(Vt);ma=a(ss,"from_pt=True"),ss.forEach(t),ca=a(kr," so \u{1F917} Transformers will convert the PyTorch checkpoint to a TensorFlow checkpoint:"),kr.forEach(t),No=m(e),T(Se.$$.fragment,e),zo=m(e),we=s(e,"H2",{class:!0});var Er=i(we);qe=s(Er,"A",{id:!0,class:!0,href:!0});var is=i(qe);Wt=s(is,"SPAN",{});var ns=i(Wt);T(at.$$.fragment,ns),ns.forEach(t),is.forEach(t),da=m(Er),Jt=s(Er,"SPAN",{});var fs=i(Jt);_a=a(fs,"Push a model during training"),fs.forEach(t),Er.forEach(t),Lo=m(e),T(xe.$$.fragment,e),Ro=m(e),ve=s(e,"H2",{class:!0});var Tr=i(ve);De=s(Tr,"A",{id:!0,class:!0,href:!0});var us=i(De);Kt=s(us,"SPAN",{});var ps=i(Kt);T(lt.$$.fragment,ps),ps.forEach(t),us.forEach(t),ya=m(Tr),st=s(Tr,"SPAN",{});var Pr=i(st);$a=a(Pr,"Use the "),Xt=s(Pr,"CODE",{});var hs=i(Xt);ga=a(hs,"push_to_hub"),hs.forEach(t),wa=a(Pr," function"),Pr.forEach(t),Tr.forEach(t),Bo=m(e),Me=s(e,"P",{});var Ar=i(Me);va=a(Ar,"You can also call "),Zt=s(Ar,"CODE",{});var ms=i(Zt);ba=a(ms,"push_to_hub"),ms.forEach(t),ka=a(Ar," directly on your model to upload it to the Hub."),Ar.forEach(t),Uo=m(e),Ie=s(e,"P",{});var jr=i(Ie);Ea=a(jr,"Specify your model name in "),Qt=s(jr,"CODE",{});var cs=i(Qt);Ta=a(cs,"push_to_hub"),cs.forEach(t),Pa=a(jr,":"),jr.forEach(t),Go=m(e),T(it.$$.fragment,e),Yo=m(e),de=s(e,"P",{});var It=i(de);Aa=a(It,"This creates a repository under your username with the model name "),eo=s(It,"CODE",{});var ds=i(eo);ja=a(ds,"my-awesome-model"),ds.forEach(t),Ha=a(It,". Users can now load your model with the "),to=s(It,"CODE",{});var _s=i(to);Fa=a(_s,"from_pretrained"),_s.forEach(t),Ca=a(It," function:"),It.forEach(t),Vo=m(e),T(nt.$$.fragment,e),Wo=m(e),Oe=s(e,"P",{});var Hr=i(Oe);Sa=a(Hr,"If you belong to an organization and want to push your model under the organization name instead, add the "),oo=s(Hr,"CODE",{});var ys=i(oo);qa=a(ys,"organization"),ys.forEach(t),xa=a(Hr," parameter:"),Hr.forEach(t),Jo=m(e),T(ft.$$.fragment,e),Ko=m(e),Ne=s(e,"P",{});var Fr=i(Ne);Da=a(Fr,"The "),ro=s(Fr,"CODE",{});var $s=i(ro);Ma=a($s,"push_to_hub"),$s.forEach(t),Ia=a(Fr," function can also be used to add other files to a model repository. For example, add a tokenizer to a model repository:"),Fr.forEach(t),Xo=m(e),T(ut.$$.fragment,e),Zo=m(e),Ht=s(e,"P",{});var gs=i(Ht);Oa=a(gs,"Or perhaps you\u2019d like to add the TensorFlow version of your fine-tuned PyTorch model:"),gs.forEach(t),Qo=m(e),T(pt.$$.fragment,e),er=m(e),ze=s(e,"P",{});var Cr=i(ze);Na=a(Cr,"Now when you navigate to the your Hugging Face profile, you should see your newly created model repository. Clicking on the "),ao=s(Cr,"STRONG",{});var ws=i(ao);za=a(ws,"Files"),ws.forEach(t),La=a(Cr," tab will display all the files you\u2019ve uploaded to the repository."),Cr.forEach(t),tr=m(e),Le=s(e,"P",{});var Sr=i(Le);Ra=a(Sr,"For more details on how to create and upload files to a repository, refer to the Hub documentation "),ht=s(Sr,"A",{href:!0,rel:!0});var vs=i(ht);Ba=a(vs,"here"),vs.forEach(t),Ua=a(Sr,"."),Sr.forEach(t),or=m(e),be=s(e,"H2",{class:!0});var qr=i(be);Re=s(qr,"A",{id:!0,class:!0,href:!0});var bs=i(Re);lo=s(bs,"SPAN",{});var ks=i(lo);T(mt.$$.fragment,ks),ks.forEach(t),bs.forEach(t),Ga=m(qr),so=s(qr,"SPAN",{});var Es=i(so);Ya=a(Es,"Upload with the web interface"),Es.forEach(t),qr.forEach(t),rr=m(e),Be=s(e,"P",{});var xr=i(Be);Va=a(xr,"Users who prefer a no-code approach are able to upload a model through the Hub\u2019s web interface. Visit "),ct=s(xr,"A",{href:!0,rel:!0});var Ts=i(ct);Wa=a(Ts,"huggingface.co/new"),Ts.forEach(t),Ja=a(xr," to create a new repository:"),xr.forEach(t),ar=m(e),Ft=s(e,"P",{});var Ps=i(Ft);Ct=s(Ps,"IMG",{src:!0,alt:!0}),Ps.forEach(t),lr=m(e),St=s(e,"P",{});var As=i(St);Ka=a(As,"From here, add some information about your model:"),As.forEach(t),sr=m(e),se=s(e,"UL",{});var Ve=i(se);dt=s(Ve,"LI",{});var Dr=i(dt);Xa=a(Dr,"Select the "),io=s(Dr,"STRONG",{});var js=i(io);Za=a(js,"owner"),js.forEach(t),Qa=a(Dr," of the repository. This can be yourself or any of the organizations you belong to."),Dr.forEach(t),el=m(Ve),no=s(Ve,"LI",{});var Hs=i(no);tl=a(Hs,"Pick a name for your model, which will also be the repository name."),Hs.forEach(t),ol=m(Ve),fo=s(Ve,"LI",{});var Fs=i(fo);rl=a(Fs,"Choose whether your model is public or private."),Fs.forEach(t),al=m(Ve),uo=s(Ve,"LI",{});var Cs=i(uo);ll=a(Cs,"Specify the license usage for your model."),Cs.forEach(t),Ve.forEach(t),ir=m(e),_e=s(e,"P",{});var Ot=i(_e);sl=a(Ot,"Now click on the "),po=s(Ot,"STRONG",{});var Ss=i(po);il=a(Ss,"Files"),Ss.forEach(t),nl=a(Ot," tab and click on the "),ho=s(Ot,"STRONG",{});var qs=i(ho);fl=a(qs,"Add file"),qs.forEach(t),ul=a(Ot," button to upload a new file to your repository. Then drag-and-drop a file to upload and add a commit message."),Ot.forEach(t),nr=m(e),qt=s(e,"P",{});var xs=i(qt);xt=s(xs,"IMG",{src:!0,alt:!0}),xs.forEach(t),fr=m(e),ke=s(e,"H2",{class:!0});var Mr=i(ke);Ue=s(Mr,"A",{id:!0,class:!0,href:!0});var Ds=i(Ue);mo=s(Ds,"SPAN",{});var Ms=i(mo);T(_t.$$.fragment,Ms),Ms.forEach(t),Ds.forEach(t),pl=m(Mr),co=s(Mr,"SPAN",{});var Is=i(co);hl=a(Is,"Add a model card"),Is.forEach(t),Mr.forEach(t),ur=m(e),Ge=s(e,"P",{});var Ir=i(Ge);ml=a(Ir,"To make sure users understand your model\u2019s capabilities, limitations, potential biases and ethical considerations, please add a model card to your repository. The model card is defined in the "),_o=s(Ir,"CODE",{});var Os=i(_o);cl=a(Os,"README.md"),Os.forEach(t),dl=a(Ir," file. You can add a model card by:"),Ir.forEach(t),pr=m(e),Ye=s(e,"UL",{});var Or=i(Ye);yt=s(Or,"LI",{});var Nr=i(yt);_l=a(Nr,"Manually creating and uploading a "),yo=s(Nr,"CODE",{});var Ns=i(yo);yl=a(Ns,"README.md"),Ns.forEach(t),$l=a(Nr," file."),Nr.forEach(t),gl=m(Or),$t=s(Or,"LI",{});var zr=i($t);wl=a(zr,"Clicking on the "),$o=s(zr,"STRONG",{});var zs=i($o);vl=a(zs,"Edit model card"),zs.forEach(t),bl=a(zr," button in your model repository."),zr.forEach(t),Or.forEach(t),hr=m(e),ie=s(e,"P",{});var We=i(ie);kl=a(We,"Take a look at the DistilBert "),gt=s(We,"A",{href:!0,rel:!0});var Ls=i(gt);El=a(Ls,"model card"),Ls.forEach(t),Tl=a(We," for a good example of the type of information a model card should include. For more details about other options you can control in the "),go=s(We,"CODE",{});var Rs=i(go);Pl=a(Rs,"README.md"),Rs.forEach(t),Al=a(We," file such as a model\u2019s carbon footprint or widget examples, refer to the documentation "),wt=s(We,"A",{href:!0,rel:!0});var Bs=i(wt);jl=a(Bs,"here"),Bs.forEach(t),Hl=a(We,"."),We.forEach(t),this.h()},h(){c(p,"name","hf:doc:metadata"),c(p,"content",JSON.stringify(fi)),c(d,"id","share-a-model"),c(d,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d,"href","#share-a-model"),c(n,"class","relative group"),c(W,"href","https://huggingface.co/models"),c(W,"rel","nofollow"),c(q,"width","560"),c(q,"height","315"),Lr(q.src,z="https://www.youtube.com/embed/XvSGPZFEjDY")||c(q,"src",z),c(q,"title","YouTube video player"),c(q,"frameborder","0"),c(q,"allow",`accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;
picture-in-picture`),q.allowFullscreen=!0,c(N,"id","repository-features"),c(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N,"href","#repository-features"),c(O,"class","relative group"),c(ee,"href","https://git-lfs.github.com/"),c(ee,"rel","nofollow"),Lr(Pt.src,Fl="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vis_diff.png")||c(Pt,"src",Fl),c(Pt,"alt","vis_diff"),c(Pe,"id","setup"),c(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Pe,"href","#setup"),c($e,"class","relative group"),c(Qe,"href","https://huggingface.co/docs/hub/adding-a-library"),c(Qe,"rel","nofollow"),c(tt,"href","https://huggingface.co/settings/token"),c(tt,"rel","nofollow"),c(He,"id","convert-a-model-for-all-frameworks"),c(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(He,"href","#convert-a-model-for-all-frameworks"),c(ge,"class","relative group"),c(jt,"href","installation"),c(qe,"id","push-a-model-during-training"),c(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qe,"href","#push-a-model-during-training"),c(we,"class","relative group"),c(De,"id","use-the-pushtohub-function"),c(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(De,"href","#use-the-pushtohub-function"),c(ve,"class","relative group"),c(ht,"href","https://huggingface.co/docs/hub/how-to-upstream"),c(ht,"rel","nofollow"),c(Re,"id","upload-with-the-web-interface"),c(Re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Re,"href","#upload-with-the-web-interface"),c(be,"class","relative group"),c(ct,"href","https://huggingface.co/new"),c(ct,"rel","nofollow"),Lr(Ct.src,Cl="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/new_model_repo.png")||c(Ct,"src",Cl),c(Ct,"alt","new_model_repo"),Lr(xt.src,Sl="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/upload_file.png")||c(xt,"src",Sl),c(xt,"alt","upload_file"),c(Ue,"id","add-a-model-card"),c(Ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ue,"href","#add-a-model-card"),c(ke,"class","relative group"),c(gt,"href","https://huggingface.co/distilbert-base-uncased"),c(gt,"rel","nofollow"),c(wt,"href","https://huggingface.co/docs/hub/model-repos"),c(wt,"rel","nofollow")},m(e,u){o(document.head,p),f(e,y,u),f(e,n,u),o(n,d),o(d,g),P($,g,null),o(n,b),o(n,w),o(w,k),f(e,C,u),f(e,D,u),o(D,ne),f(e,ae,u),f(e,M,u),o(M,fe),o(M,W),o(W,G),o(M,J),f(e,K,u),f(e,I,u),o(I,oe),o(oe,X),o(I,Z),o(I,te),o(te,U),f(e,Y,u),f(e,q,u),f(e,le,u),P(L,e,u),f(e,re,u),f(e,O,u),o(O,N),o(N,v),P(S,v,null),o(O,ue),o(O,V),o(V,Q),f(e,_,u),f(e,F,u),o(F,pe),f(e,he,u),f(e,R,u),o(R,ye),o(R,ee),o(ee,bt),o(R,me),o(R,Ee),o(Ee,kt),o(R,Rr),f(e,Eo,u),f(e,Te,u),o(Te,Br),o(Te,Nt),o(Nt,Ur),o(Te,Gr),f(e,To,u),P(Ke,e,u),f(e,Po,u),f(e,Et,u),o(Et,Yr),f(e,Ao,u),f(e,Tt,u),o(Tt,Pt),f(e,jo,u),f(e,$e,u),o($e,Pe),o(Pe,zt),P(Xe,zt,null),o($e,Vr),o($e,Lt),o(Lt,Wr),f(e,Ho,u),f(e,Ae,u),o(Ae,Jr),o(Ae,Rt),o(Rt,Kr),o(Ae,Xr),f(e,Fo,u),P(Ze,e,u),f(e,Co,u),f(e,je,u),o(je,Zr),o(je,Qe),o(Qe,Bt),o(Bt,Qr),o(je,ea),f(e,So,u),P(et,e,u),f(e,qo,u),f(e,ce,u),o(ce,ta),o(ce,Ut),o(Ut,oa),o(ce,ra),o(ce,tt),o(tt,aa),o(ce,la),f(e,xo,u),P(ot,e,u),f(e,Do,u),f(e,ge,u),o(ge,He),o(He,Gt),P(rt,Gt,null),o(ge,sa),o(ge,Yt),o(Yt,ia),f(e,Mo,u),f(e,At,u),o(At,na),f(e,Io,u),f(e,Fe,u),o(Fe,fa),o(Fe,jt),o(jt,ua),o(Fe,pa),f(e,Oo,u),f(e,Ce,u),o(Ce,ha),o(Ce,Vt),o(Vt,ma),o(Ce,ca),f(e,No,u),P(Se,e,u),f(e,zo,u),f(e,we,u),o(we,qe),o(qe,Wt),P(at,Wt,null),o(we,da),o(we,Jt),o(Jt,_a),f(e,Lo,u),P(xe,e,u),f(e,Ro,u),f(e,ve,u),o(ve,De),o(De,Kt),P(lt,Kt,null),o(ve,ya),o(ve,st),o(st,$a),o(st,Xt),o(Xt,ga),o(st,wa),f(e,Bo,u),f(e,Me,u),o(Me,va),o(Me,Zt),o(Zt,ba),o(Me,ka),f(e,Uo,u),f(e,Ie,u),o(Ie,Ea),o(Ie,Qt),o(Qt,Ta),o(Ie,Pa),f(e,Go,u),P(it,e,u),f(e,Yo,u),f(e,de,u),o(de,Aa),o(de,eo),o(eo,ja),o(de,Ha),o(de,to),o(to,Fa),o(de,Ca),f(e,Vo,u),P(nt,e,u),f(e,Wo,u),f(e,Oe,u),o(Oe,Sa),o(Oe,oo),o(oo,qa),o(Oe,xa),f(e,Jo,u),P(ft,e,u),f(e,Ko,u),f(e,Ne,u),o(Ne,Da),o(Ne,ro),o(ro,Ma),o(Ne,Ia),f(e,Xo,u),P(ut,e,u),f(e,Zo,u),f(e,Ht,u),o(Ht,Oa),f(e,Qo,u),P(pt,e,u),f(e,er,u),f(e,ze,u),o(ze,Na),o(ze,ao),o(ao,za),o(ze,La),f(e,tr,u),f(e,Le,u),o(Le,Ra),o(Le,ht),o(ht,Ba),o(Le,Ua),f(e,or,u),f(e,be,u),o(be,Re),o(Re,lo),P(mt,lo,null),o(be,Ga),o(be,so),o(so,Ya),f(e,rr,u),f(e,Be,u),o(Be,Va),o(Be,ct),o(ct,Wa),o(Be,Ja),f(e,ar,u),f(e,Ft,u),o(Ft,Ct),f(e,lr,u),f(e,St,u),o(St,Ka),f(e,sr,u),f(e,se,u),o(se,dt),o(dt,Xa),o(dt,io),o(io,Za),o(dt,Qa),o(se,el),o(se,no),o(no,tl),o(se,ol),o(se,fo),o(fo,rl),o(se,al),o(se,uo),o(uo,ll),f(e,ir,u),f(e,_e,u),o(_e,sl),o(_e,po),o(po,il),o(_e,nl),o(_e,ho),o(ho,fl),o(_e,ul),f(e,nr,u),f(e,qt,u),o(qt,xt),f(e,fr,u),f(e,ke,u),o(ke,Ue),o(Ue,mo),P(_t,mo,null),o(ke,pl),o(ke,co),o(co,hl),f(e,ur,u),f(e,Ge,u),o(Ge,ml),o(Ge,_o),o(_o,cl),o(Ge,dl),f(e,pr,u),f(e,Ye,u),o(Ye,yt),o(yt,_l),o(yt,yo),o(yo,yl),o(yt,$l),o(Ye,gl),o(Ye,$t),o($t,wl),o($t,$o),o($o,vl),o($t,bl),f(e,hr,u),f(e,ie,u),o(ie,kl),o(ie,gt),o(gt,El),o(ie,Tl),o(ie,go),o(go,Pl),o(ie,Al),o(ie,wt),o(wt,jl),o(ie,Hl),mr=!0},p(e,[u]){const vt={};u&2&&(vt.$$scope={dirty:u,ctx:e}),L.$set(vt);const wo={};u&2&&(wo.$$scope={dirty:u,ctx:e}),Se.$set(wo);const vo={};u&2&&(vo.$$scope={dirty:u,ctx:e}),xe.$set(vo)},i(e){mr||(A($.$$.fragment,e),A(L.$$.fragment,e),A(S.$$.fragment,e),A(Ke.$$.fragment,e),A(Xe.$$.fragment,e),A(Ze.$$.fragment,e),A(et.$$.fragment,e),A(ot.$$.fragment,e),A(rt.$$.fragment,e),A(Se.$$.fragment,e),A(at.$$.fragment,e),A(xe.$$.fragment,e),A(lt.$$.fragment,e),A(it.$$.fragment,e),A(nt.$$.fragment,e),A(ft.$$.fragment,e),A(ut.$$.fragment,e),A(pt.$$.fragment,e),A(mt.$$.fragment,e),A(_t.$$.fragment,e),mr=!0)},o(e){j($.$$.fragment,e),j(L.$$.fragment,e),j(S.$$.fragment,e),j(Ke.$$.fragment,e),j(Xe.$$.fragment,e),j(Ze.$$.fragment,e),j(et.$$.fragment,e),j(ot.$$.fragment,e),j(rt.$$.fragment,e),j(Se.$$.fragment,e),j(at.$$.fragment,e),j(xe.$$.fragment,e),j(lt.$$.fragment,e),j(it.$$.fragment,e),j(nt.$$.fragment,e),j(ft.$$.fragment,e),j(ut.$$.fragment,e),j(pt.$$.fragment,e),j(mt.$$.fragment,e),j(_t.$$.fragment,e),mr=!1},d(e){t(p),e&&t(y),e&&t(n),H($),e&&t(C),e&&t(D),e&&t(ae),e&&t(M),e&&t(K),e&&t(I),e&&t(Y),e&&t(q),e&&t(le),H(L,e),e&&t(re),e&&t(O),H(S),e&&t(_),e&&t(F),e&&t(he),e&&t(R),e&&t(Eo),e&&t(Te),e&&t(To),H(Ke,e),e&&t(Po),e&&t(Et),e&&t(Ao),e&&t(Tt),e&&t(jo),e&&t($e),H(Xe),e&&t(Ho),e&&t(Ae),e&&t(Fo),H(Ze,e),e&&t(Co),e&&t(je),e&&t(So),H(et,e),e&&t(qo),e&&t(ce),e&&t(xo),H(ot,e),e&&t(Do),e&&t(ge),H(rt),e&&t(Mo),e&&t(At),e&&t(Io),e&&t(Fe),e&&t(Oo),e&&t(Ce),e&&t(No),H(Se,e),e&&t(zo),e&&t(we),H(at),e&&t(Lo),H(xe,e),e&&t(Ro),e&&t(ve),H(lt),e&&t(Bo),e&&t(Me),e&&t(Uo),e&&t(Ie),e&&t(Go),H(it,e),e&&t(Yo),e&&t(de),e&&t(Vo),H(nt,e),e&&t(Wo),e&&t(Oe),e&&t(Jo),H(ft,e),e&&t(Ko),e&&t(Ne),e&&t(Xo),H(ut,e),e&&t(Zo),e&&t(Ht),e&&t(Qo),H(pt,e),e&&t(er),e&&t(ze),e&&t(tr),e&&t(Le),e&&t(or),e&&t(be),H(mt),e&&t(rr),e&&t(Be),e&&t(ar),e&&t(Ft),e&&t(lr),e&&t(St),e&&t(sr),e&&t(se),e&&t(ir),e&&t(_e),e&&t(nr),e&&t(qt),e&&t(fr),e&&t(ke),H(_t),e&&t(ur),e&&t(Ge),e&&t(pr),e&&t(Ye),e&&t(hr),e&&t(ie)}}}const fi={local:"share-a-model",sections:[{local:"repository-features",title:"Repository features"},{local:"setup",title:"Setup"},{local:"convert-a-model-for-all-frameworks",title:"Convert a model for all frameworks"},{local:"push-a-model-during-training",title:"Push a model during training"},{local:"use-the-pushtohub-function",title:"Use the `push_to_hub` function"},{local:"upload-with-the-web-interface",title:"Upload with the web interface"},{local:"add-a-model-card",title:"Add a model card"}],title:"Share a model"};function ui(x,p,y){let{fw:n}=p;return x.$$set=d=>{"fw"in d&&y(0,n=d.fw)},[n]}class yi extends Gs{constructor(p){super();Ys(this,p,ui,ni,Vs,{fw:0})}}export{yi as default,fi as metadata};
