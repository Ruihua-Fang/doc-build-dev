import{S as yn,i as xn,s as wn,e as r,k as h,w as u,t,M as bn,c as i,d as a,m as c,a as o,x as d,h as n,b as f,N as En,F as s,g as p,y as g,q as _,o as v,B as k,v as qn}from"../chunks/vendor-6b77c823.js";import{T as An}from"../chunks/Tip-39098574.js";import{I as is}from"../chunks/IconCopyLink-7a11ce68.js";import{C as q}from"../chunks/CodeBlock-3a8b25a8.js";function Pn(os){let m,N,$,w,z;return{c(){m=r("p"),N=t("Take a look at the "),$=r("a"),w=t("pipeline()"),z=t(" documentation for a complete list of supported taska."),this.h()},l(x){m=i(x,"P",{});var A=o(m);N=n(A,"Take a look at the "),$=i(A,"A",{href:!0});var H=o($);w=n(H,"pipeline()"),H.forEach(a),z=n(A," documentation for a complete list of supported taska."),A.forEach(a),this.h()},h(){f($,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline")},m(x,A){p(x,m,A),s(m,N),s(m,$),s($,w),s(m,z)},d(x){x&&a(m)}}}function Tn(os){let m,N,$,w,z,x,A,H,aa,ps,b,ta,ye,na,la,Y,ra,ia,xe,oa,pa,fs,P,Z,fa,we,ha,ca,ma,Ke,ua,da,ee,ga,be,_a,va,hs,I,cs,F,R,Qe,se,ka,Xe,$a,ms,E,ja,Ee,ya,xa,qe,wa,ba,Ae,Ea,qa,us,Pe,ae,Aa,Te,Pa,Ta,ds,te,gs,ne,le,Ma,Me,Sa,za,_s,re,vs,Se,Fa,ks,ie,$s,j,La,ze,Ca,Da,Ye,Na,Ha,Fe,Ia,Ra,Ze,Oa,Ua,js,oe,ys,L,O,es,pe,Va,ss,Ba,xs,y,Ga,Le,Wa,Ja,fe,Ka,Qa,as,Xa,Ya,Ce,Za,et,ws,he,bs,U,st,De,at,tt,Es,ce,qs,V,nt,Ne,lt,rt,As,me,Ps,C,B,ts,ue,it,ns,ot,Ts,G,pt,He,ft,ht,Ms,Ie,ct,Ss,de,zs,T,mt,ge,ut,dt,Re,gt,_t,Fs,_e,Ls,W,vt,Oe,kt,$t,Cs,ve,Ds,D,J,ls,ke,jt,rs,yt,Ns,K,xt,Ue,wt,bt,Hs,Ve,Et,Is,Be,Ge,qt,Rs,$e,Os;return x=new is({}),I=new An({props:{$$slots:{default:[Pn]},$$scope:{ctx:os}}}),se=new is({}),te=new q({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>)`}}),re=new q({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>)
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Iron-priests at the door to the east, and thirteen for the Lord Kings at the end of the mountain&#x27;</span>}]`}}),ie=new q({props:{code:`generator(
    [
        "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
        "Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne",
    ]
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne&quot;</span>,
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">&gt;&gt;&gt; </span>)`}}),oe=new q({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
    num_return_sequences=2,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>    num_return_sequences=<span class="hljs-number">2</span>,
<span class="hljs-meta">&gt;&gt;&gt; </span>)`}}),pe=new is({}),he=new q({props:{code:`from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
model = AutoModelForCausalLM.from_pretrained("distilgpt2")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)`}}),ce=new q({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation", model=model, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>, model=model, tokenizer=tokenizer)`}}),me=new q({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>)
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Dragon-lords (for them to rule in a world ruled by their rulers, and all who live within the realm&#x27;</span>}]`}}),ue=new is({}),de=new q({props:{code:`from datasets import load_dataset
import torch

torch.manual_seed(42)
ds = load_dataset("hf-internal-testing/librispeech_asr_demo", "clean", split="validation")
audio_file = ds[0]["audio"]["path"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>torch.manual_seed(<span class="hljs-number">42</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;hf-internal-testing/librispeech_asr_demo&quot;</span>, <span class="hljs-string">&quot;clean&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>audio_file = ds[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;path&quot;</span>]`}}),_e=new q({props:{code:`from transformers import pipeline

audio_classifier = pipeline(
    task="audio-classification", model="ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>audio_classifier = pipeline(
<span class="hljs-meta">... </span>    task=<span class="hljs-string">&quot;audio-classification&quot;</span>, model=<span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`}}),ve=new q({props:{code:`preds = audio_classifier(audio_file)
preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>preds = audio_classifier(audio_file)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;label&quot;</span>: pred[<span class="hljs-string">&quot;label&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;calm&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1315</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;neutral&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1307</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;sad&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1274</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;fearful&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1261</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;happy&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1242</span>}]`}}),ke=new is({}),$e=new q({props:{code:`from transformers import pipeline

vision_classifier = pipeline(task="image-classification")
preds = vision_classifier(
    images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
)
preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
print(preds)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>vision_classifier = pipeline(task=<span class="hljs-string">&quot;image-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = vision_classifier(
<span class="hljs-meta">... </span>    images=<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;label&quot;</span>: pred[<span class="hljs-string">&quot;label&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(preds)
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.4403</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;lynx, catamount&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0343</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;cougar, puma, catamount, mountain lion, painter, panther, Felis concolor&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0321</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;snow leopard, ounce, Panthera uncia&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0235</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;Egyptian cat&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.023</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;tiger cat&#x27;</span>}]`}}),{c(){m=r("meta"),N=h(),$=r("h1"),w=r("a"),z=r("span"),u(x.$$.fragment),A=h(),H=r("span"),aa=t("Pipelines for inference"),ps=h(),b=r("p"),ta=t("The "),ye=r("a"),na=t("pipeline()"),la=t(" makes it simple to use any model from the "),Y=r("a"),ra=t("Model Hub"),ia=t(" for inference on a variety of tasks such as text generation, image segmentation and audio classification. Even if you don\u2019t have experience with a specific modality or understand the code powering the models, you can still use them with the "),xe=r("a"),oa=t("pipeline()"),pa=t("! This tutorial will teach you to:"),fs=h(),P=r("ul"),Z=r("li"),fa=t("Use a "),we=r("a"),ha=t("pipeline()"),ca=t(" for inference."),ma=h(),Ke=r("li"),ua=t("Use a specific tokenizer or model."),da=h(),ee=r("li"),ga=t("Use a "),be=r("a"),_a=t("pipeline()"),va=t(" for audio and vision tasks."),hs=h(),u(I.$$.fragment),cs=h(),F=r("h2"),R=r("a"),Qe=r("span"),u(se.$$.fragment),ka=h(),Xe=r("span"),$a=t("Pipeline usage"),ms=h(),E=r("p"),ja=t("While each task has an associated "),Ee=r("a"),ya=t("pipeline()"),xa=t(", it is simpler to use the general "),qe=r("a"),wa=t("pipeline()"),ba=t(" abstraction which contains all the specific task pipelines. The "),Ae=r("a"),Ea=t("pipeline()"),qa=t(" automatically loads a default model and tokenizer capable of inference for your task."),us=h(),Pe=r("ol"),ae=r("li"),Aa=t("Start by creating a "),Te=r("a"),Pa=t("pipeline()"),Ta=t(" and specify an inference task:"),ds=h(),u(te.$$.fragment),gs=h(),ne=r("ol"),le=r("li"),Ma=t("Pass your input text to the "),Me=r("a"),Sa=t("pipeline()"),za=t(":"),_s=h(),u(re.$$.fragment),vs=h(),Se=r("p"),Fa=t("If you have more than one input, pass your input as a list:"),ks=h(),u(ie.$$.fragment),$s=h(),j=r("p"),La=t("Any additional parameters for your task can also be included in the "),ze=r("a"),Ca=t("pipeline()"),Da=t(". The "),Ye=r("code"),Na=t("text-generation"),Ha=t(" task has a "),Fe=r("a"),Ia=t("generate()"),Ra=t(" method with several parameters for controlling the output. For example, if you want to generate more than one output, set the "),Ze=r("code"),Oa=t("num_return_sequences"),Ua=t(" parameter:"),js=h(),u(oe.$$.fragment),ys=h(),L=r("h3"),O=r("a"),es=r("span"),u(pe.$$.fragment),Va=h(),ss=r("span"),Ba=t("Choose a model and tokenizer"),xs=h(),y=r("p"),Ga=t("The "),Le=r("a"),Wa=t("pipeline()"),Ja=t(" accepts any model from the "),fe=r("a"),Ka=t("Model Hub"),Qa=t(". There are tags on the Model Hub that allow you to filter for a model you\u2019d like to use for your task. Once you\u2019ve picked an appropriate model, load it with the corresponding "),as=r("code"),Xa=t("AutoModelFor"),Ya=t(" and [`AutoTokenizer\u2019] class. For example, load the "),Ce=r("a"),Za=t("AutoModelForCausalLM"),et=t(" class for a causal language modeling task:"),ws=h(),u(he.$$.fragment),bs=h(),U=r("p"),st=t("Create a "),De=r("a"),at=t("pipeline()"),tt=t(" for your task, and specify the model and tokenizer you\u2019ve loaded:"),Es=h(),u(ce.$$.fragment),qs=h(),V=r("p"),nt=t("Pass your input text to the "),Ne=r("a"),lt=t("pipeline()"),rt=t(" to generate some text:"),As=h(),u(me.$$.fragment),Ps=h(),C=r("h2"),B=r("a"),ts=r("span"),u(ue.$$.fragment),it=h(),ns=r("span"),ot=t("Audio pipeline"),Ts=h(),G=r("p"),pt=t("The flexibility of the "),He=r("a"),ft=t("pipeline()"),ht=t(" means it can also be extended to audio tasks."),Ms=h(),Ie=r("p"),ct=t("For example, let\u2019s classify the emotion in this audio clip:"),Ss=h(),u(de.$$.fragment),zs=h(),T=r("p"),mt=t("Find an "),ge=r("a"),ut=t("audio classification"),dt=t(" model on the Model Hub for emotion recognition and load it in the "),Re=r("a"),gt=t("pipeline()"),_t=t(":"),Fs=h(),u(_e.$$.fragment),Ls=h(),W=r("p"),vt=t("Pass the audio file to the "),Oe=r("a"),kt=t("pipeline()"),$t=t(":"),Cs=h(),u(ve.$$.fragment),Ds=h(),D=r("h2"),J=r("a"),ls=r("span"),u(ke.$$.fragment),jt=h(),rs=r("span"),yt=t("Vision pipeline"),Ns=h(),K=r("p"),xt=t("Finally, using a "),Ue=r("a"),wt=t("pipeline()"),bt=t(" for vision tasks is practically identical."),Hs=h(),Ve=r("p"),Et=t("Specify your vision task and pass your image to the classifier. The imaage can be a link or a local path to the image. For example, what species of cat is shown below?"),Is=h(),Be=r("p"),Ge=r("img"),Rs=h(),u($e.$$.fragment),this.h()},l(e){const l=bn('[data-svelte="svelte-1phssyn"]',document.head);m=i(l,"META",{name:!0,content:!0}),l.forEach(a),N=c(e),$=i(e,"H1",{class:!0});var je=o($);w=i(je,"A",{id:!0,class:!0,href:!0});var At=o(w);z=i(At,"SPAN",{});var Pt=o(z);d(x.$$.fragment,Pt),Pt.forEach(a),At.forEach(a),A=c(je),H=i(je,"SPAN",{});var Tt=o(H);aa=n(Tt,"Pipelines for inference"),Tt.forEach(a),je.forEach(a),ps=c(e),b=i(e,"P",{});var Q=o(b);ta=n(Q,"The "),ye=i(Q,"A",{href:!0});var Mt=o(ye);na=n(Mt,"pipeline()"),Mt.forEach(a),la=n(Q," makes it simple to use any model from the "),Y=i(Q,"A",{href:!0,rel:!0});var St=o(Y);ra=n(St,"Model Hub"),St.forEach(a),ia=n(Q," for inference on a variety of tasks such as text generation, image segmentation and audio classification. Even if you don\u2019t have experience with a specific modality or understand the code powering the models, you can still use them with the "),xe=i(Q,"A",{href:!0});var zt=o(xe);oa=n(zt,"pipeline()"),zt.forEach(a),pa=n(Q,"! This tutorial will teach you to:"),Q.forEach(a),fs=c(e),P=i(e,"UL",{});var We=o(P);Z=i(We,"LI",{});var Us=o(Z);fa=n(Us,"Use a "),we=i(Us,"A",{href:!0});var Ft=o(we);ha=n(Ft,"pipeline()"),Ft.forEach(a),ca=n(Us," for inference."),Us.forEach(a),ma=c(We),Ke=i(We,"LI",{});var Lt=o(Ke);ua=n(Lt,"Use a specific tokenizer or model."),Lt.forEach(a),da=c(We),ee=i(We,"LI",{});var Vs=o(ee);ga=n(Vs,"Use a "),be=i(Vs,"A",{href:!0});var Ct=o(be);_a=n(Ct,"pipeline()"),Ct.forEach(a),va=n(Vs," for audio and vision tasks."),Vs.forEach(a),We.forEach(a),hs=c(e),d(I.$$.fragment,e),cs=c(e),F=i(e,"H2",{class:!0});var Bs=o(F);R=i(Bs,"A",{id:!0,class:!0,href:!0});var Dt=o(R);Qe=i(Dt,"SPAN",{});var Nt=o(Qe);d(se.$$.fragment,Nt),Nt.forEach(a),Dt.forEach(a),ka=c(Bs),Xe=i(Bs,"SPAN",{});var Ht=o(Xe);$a=n(Ht,"Pipeline usage"),Ht.forEach(a),Bs.forEach(a),ms=c(e),E=i(e,"P",{});var X=o(E);ja=n(X,"While each task has an associated "),Ee=i(X,"A",{href:!0});var It=o(Ee);ya=n(It,"pipeline()"),It.forEach(a),xa=n(X,", it is simpler to use the general "),qe=i(X,"A",{href:!0});var Rt=o(qe);wa=n(Rt,"pipeline()"),Rt.forEach(a),ba=n(X," abstraction which contains all the specific task pipelines. The "),Ae=i(X,"A",{href:!0});var Ot=o(Ae);Ea=n(Ot,"pipeline()"),Ot.forEach(a),qa=n(X," automatically loads a default model and tokenizer capable of inference for your task."),X.forEach(a),us=c(e),Pe=i(e,"OL",{});var Ut=o(Pe);ae=i(Ut,"LI",{});var Gs=o(ae);Aa=n(Gs,"Start by creating a "),Te=i(Gs,"A",{href:!0});var Vt=o(Te);Pa=n(Vt,"pipeline()"),Vt.forEach(a),Ta=n(Gs," and specify an inference task:"),Gs.forEach(a),Ut.forEach(a),ds=c(e),d(te.$$.fragment,e),gs=c(e),ne=i(e,"OL",{start:!0});var Bt=o(ne);le=i(Bt,"LI",{});var Ws=o(le);Ma=n(Ws,"Pass your input text to the "),Me=i(Ws,"A",{href:!0});var Gt=o(Me);Sa=n(Gt,"pipeline()"),Gt.forEach(a),za=n(Ws,":"),Ws.forEach(a),Bt.forEach(a),_s=c(e),d(re.$$.fragment,e),vs=c(e),Se=i(e,"P",{});var Wt=o(Se);Fa=n(Wt,"If you have more than one input, pass your input as a list:"),Wt.forEach(a),ks=c(e),d(ie.$$.fragment,e),$s=c(e),j=i(e,"P",{});var M=o(j);La=n(M,"Any additional parameters for your task can also be included in the "),ze=i(M,"A",{href:!0});var Jt=o(ze);Ca=n(Jt,"pipeline()"),Jt.forEach(a),Da=n(M,". The "),Ye=i(M,"CODE",{});var Kt=o(Ye);Na=n(Kt,"text-generation"),Kt.forEach(a),Ha=n(M," task has a "),Fe=i(M,"A",{href:!0});var Qt=o(Fe);Ia=n(Qt,"generate()"),Qt.forEach(a),Ra=n(M," method with several parameters for controlling the output. For example, if you want to generate more than one output, set the "),Ze=i(M,"CODE",{});var Xt=o(Ze);Oa=n(Xt,"num_return_sequences"),Xt.forEach(a),Ua=n(M," parameter:"),M.forEach(a),js=c(e),d(oe.$$.fragment,e),ys=c(e),L=i(e,"H3",{class:!0});var Js=o(L);O=i(Js,"A",{id:!0,class:!0,href:!0});var Yt=o(O);es=i(Yt,"SPAN",{});var Zt=o(es);d(pe.$$.fragment,Zt),Zt.forEach(a),Yt.forEach(a),Va=c(Js),ss=i(Js,"SPAN",{});var en=o(ss);Ba=n(en,"Choose a model and tokenizer"),en.forEach(a),Js.forEach(a),xs=c(e),y=i(e,"P",{});var S=o(y);Ga=n(S,"The "),Le=i(S,"A",{href:!0});var sn=o(Le);Wa=n(sn,"pipeline()"),sn.forEach(a),Ja=n(S," accepts any model from the "),fe=i(S,"A",{href:!0,rel:!0});var an=o(fe);Ka=n(an,"Model Hub"),an.forEach(a),Qa=n(S,". There are tags on the Model Hub that allow you to filter for a model you\u2019d like to use for your task. Once you\u2019ve picked an appropriate model, load it with the corresponding "),as=i(S,"CODE",{});var tn=o(as);Xa=n(tn,"AutoModelFor"),tn.forEach(a),Ya=n(S," and [`AutoTokenizer\u2019] class. For example, load the "),Ce=i(S,"A",{href:!0});var nn=o(Ce);Za=n(nn,"AutoModelForCausalLM"),nn.forEach(a),et=n(S," class for a causal language modeling task:"),S.forEach(a),ws=c(e),d(he.$$.fragment,e),bs=c(e),U=i(e,"P",{});var Ks=o(U);st=n(Ks,"Create a "),De=i(Ks,"A",{href:!0});var ln=o(De);at=n(ln,"pipeline()"),ln.forEach(a),tt=n(Ks," for your task, and specify the model and tokenizer you\u2019ve loaded:"),Ks.forEach(a),Es=c(e),d(ce.$$.fragment,e),qs=c(e),V=i(e,"P",{});var Qs=o(V);nt=n(Qs,"Pass your input text to the "),Ne=i(Qs,"A",{href:!0});var rn=o(Ne);lt=n(rn,"pipeline()"),rn.forEach(a),rt=n(Qs," to generate some text:"),Qs.forEach(a),As=c(e),d(me.$$.fragment,e),Ps=c(e),C=i(e,"H2",{class:!0});var Xs=o(C);B=i(Xs,"A",{id:!0,class:!0,href:!0});var on=o(B);ts=i(on,"SPAN",{});var pn=o(ts);d(ue.$$.fragment,pn),pn.forEach(a),on.forEach(a),it=c(Xs),ns=i(Xs,"SPAN",{});var fn=o(ns);ot=n(fn,"Audio pipeline"),fn.forEach(a),Xs.forEach(a),Ts=c(e),G=i(e,"P",{});var Ys=o(G);pt=n(Ys,"The flexibility of the "),He=i(Ys,"A",{href:!0});var hn=o(He);ft=n(hn,"pipeline()"),hn.forEach(a),ht=n(Ys," means it can also be extended to audio tasks."),Ys.forEach(a),Ms=c(e),Ie=i(e,"P",{});var cn=o(Ie);ct=n(cn,"For example, let\u2019s classify the emotion in this audio clip:"),cn.forEach(a),Ss=c(e),d(de.$$.fragment,e),zs=c(e),T=i(e,"P",{});var Je=o(T);mt=n(Je,"Find an "),ge=i(Je,"A",{href:!0,rel:!0});var mn=o(ge);ut=n(mn,"audio classification"),mn.forEach(a),dt=n(Je," model on the Model Hub for emotion recognition and load it in the "),Re=i(Je,"A",{href:!0});var un=o(Re);gt=n(un,"pipeline()"),un.forEach(a),_t=n(Je,":"),Je.forEach(a),Fs=c(e),d(_e.$$.fragment,e),Ls=c(e),W=i(e,"P",{});var Zs=o(W);vt=n(Zs,"Pass the audio file to the "),Oe=i(Zs,"A",{href:!0});var dn=o(Oe);kt=n(dn,"pipeline()"),dn.forEach(a),$t=n(Zs,":"),Zs.forEach(a),Cs=c(e),d(ve.$$.fragment,e),Ds=c(e),D=i(e,"H2",{class:!0});var ea=o(D);J=i(ea,"A",{id:!0,class:!0,href:!0});var gn=o(J);ls=i(gn,"SPAN",{});var _n=o(ls);d(ke.$$.fragment,_n),_n.forEach(a),gn.forEach(a),jt=c(ea),rs=i(ea,"SPAN",{});var vn=o(rs);yt=n(vn,"Vision pipeline"),vn.forEach(a),ea.forEach(a),Ns=c(e),K=i(e,"P",{});var sa=o(K);xt=n(sa,"Finally, using a "),Ue=i(sa,"A",{href:!0});var kn=o(Ue);wt=n(kn,"pipeline()"),kn.forEach(a),bt=n(sa," for vision tasks is practically identical."),sa.forEach(a),Hs=c(e),Ve=i(e,"P",{});var $n=o(Ve);Et=n($n,"Specify your vision task and pass your image to the classifier. The imaage can be a link or a local path to the image. For example, what species of cat is shown below?"),$n.forEach(a),Is=c(e),Be=i(e,"P",{});var jn=o(Be);Ge=i(jn,"IMG",{src:!0,alt:!0}),jn.forEach(a),Rs=c(e),d($e.$$.fragment,e),this.h()},h(){f(m,"name","hf:doc:metadata"),f(m,"content",JSON.stringify(Mn)),f(w,"id","pipelines-for-inference"),f(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(w,"href","#pipelines-for-inference"),f($,"class","relative group"),f(ye,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(Y,"href","https://huggingface.co/models"),f(Y,"rel","nofollow"),f(xe,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(we,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(be,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(R,"id","pipeline-usage"),f(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(R,"href","#pipeline-usage"),f(F,"class","relative group"),f(Ee,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(qe,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(Ae,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(Te,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(Me,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(ne,"start","2"),f(ze,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(Fe,"href","/docs/transformers/pr_17013/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate"),f(O,"id","choose-a-model-and-tokenizer"),f(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(O,"href","#choose-a-model-and-tokenizer"),f(L,"class","relative group"),f(Le,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(fe,"href","https://huggingface.co/models"),f(fe,"rel","nofollow"),f(Ce,"href","/docs/transformers/pr_17013/en/model_doc/auto#transformers.AutoModelForCausalLM"),f(De,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(Ne,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(B,"id","audio-pipeline"),f(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(B,"href","#audio-pipeline"),f(C,"class","relative group"),f(He,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(ge,"href","https://huggingface.co/models?pipeline_tag=audio-classification"),f(ge,"rel","nofollow"),f(Re,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(Oe,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),f(J,"id","vision-pipeline"),f(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(J,"href","#vision-pipeline"),f(D,"class","relative group"),f(Ue,"href","/docs/transformers/pr_17013/en/main_classes/pipelines#transformers.pipeline"),En(Ge.src,qt="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg")||f(Ge,"src",qt),f(Ge,"alt","pipeline-cat-chonk")},m(e,l){s(document.head,m),p(e,N,l),p(e,$,l),s($,w),s(w,z),g(x,z,null),s($,A),s($,H),s(H,aa),p(e,ps,l),p(e,b,l),s(b,ta),s(b,ye),s(ye,na),s(b,la),s(b,Y),s(Y,ra),s(b,ia),s(b,xe),s(xe,oa),s(b,pa),p(e,fs,l),p(e,P,l),s(P,Z),s(Z,fa),s(Z,we),s(we,ha),s(Z,ca),s(P,ma),s(P,Ke),s(Ke,ua),s(P,da),s(P,ee),s(ee,ga),s(ee,be),s(be,_a),s(ee,va),p(e,hs,l),g(I,e,l),p(e,cs,l),p(e,F,l),s(F,R),s(R,Qe),g(se,Qe,null),s(F,ka),s(F,Xe),s(Xe,$a),p(e,ms,l),p(e,E,l),s(E,ja),s(E,Ee),s(Ee,ya),s(E,xa),s(E,qe),s(qe,wa),s(E,ba),s(E,Ae),s(Ae,Ea),s(E,qa),p(e,us,l),p(e,Pe,l),s(Pe,ae),s(ae,Aa),s(ae,Te),s(Te,Pa),s(ae,Ta),p(e,ds,l),g(te,e,l),p(e,gs,l),p(e,ne,l),s(ne,le),s(le,Ma),s(le,Me),s(Me,Sa),s(le,za),p(e,_s,l),g(re,e,l),p(e,vs,l),p(e,Se,l),s(Se,Fa),p(e,ks,l),g(ie,e,l),p(e,$s,l),p(e,j,l),s(j,La),s(j,ze),s(ze,Ca),s(j,Da),s(j,Ye),s(Ye,Na),s(j,Ha),s(j,Fe),s(Fe,Ia),s(j,Ra),s(j,Ze),s(Ze,Oa),s(j,Ua),p(e,js,l),g(oe,e,l),p(e,ys,l),p(e,L,l),s(L,O),s(O,es),g(pe,es,null),s(L,Va),s(L,ss),s(ss,Ba),p(e,xs,l),p(e,y,l),s(y,Ga),s(y,Le),s(Le,Wa),s(y,Ja),s(y,fe),s(fe,Ka),s(y,Qa),s(y,as),s(as,Xa),s(y,Ya),s(y,Ce),s(Ce,Za),s(y,et),p(e,ws,l),g(he,e,l),p(e,bs,l),p(e,U,l),s(U,st),s(U,De),s(De,at),s(U,tt),p(e,Es,l),g(ce,e,l),p(e,qs,l),p(e,V,l),s(V,nt),s(V,Ne),s(Ne,lt),s(V,rt),p(e,As,l),g(me,e,l),p(e,Ps,l),p(e,C,l),s(C,B),s(B,ts),g(ue,ts,null),s(C,it),s(C,ns),s(ns,ot),p(e,Ts,l),p(e,G,l),s(G,pt),s(G,He),s(He,ft),s(G,ht),p(e,Ms,l),p(e,Ie,l),s(Ie,ct),p(e,Ss,l),g(de,e,l),p(e,zs,l),p(e,T,l),s(T,mt),s(T,ge),s(ge,ut),s(T,dt),s(T,Re),s(Re,gt),s(T,_t),p(e,Fs,l),g(_e,e,l),p(e,Ls,l),p(e,W,l),s(W,vt),s(W,Oe),s(Oe,kt),s(W,$t),p(e,Cs,l),g(ve,e,l),p(e,Ds,l),p(e,D,l),s(D,J),s(J,ls),g(ke,ls,null),s(D,jt),s(D,rs),s(rs,yt),p(e,Ns,l),p(e,K,l),s(K,xt),s(K,Ue),s(Ue,wt),s(K,bt),p(e,Hs,l),p(e,Ve,l),s(Ve,Et),p(e,Is,l),p(e,Be,l),s(Be,Ge),p(e,Rs,l),g($e,e,l),Os=!0},p(e,[l]){const je={};l&2&&(je.$$scope={dirty:l,ctx:e}),I.$set(je)},i(e){Os||(_(x.$$.fragment,e),_(I.$$.fragment,e),_(se.$$.fragment,e),_(te.$$.fragment,e),_(re.$$.fragment,e),_(ie.$$.fragment,e),_(oe.$$.fragment,e),_(pe.$$.fragment,e),_(he.$$.fragment,e),_(ce.$$.fragment,e),_(me.$$.fragment,e),_(ue.$$.fragment,e),_(de.$$.fragment,e),_(_e.$$.fragment,e),_(ve.$$.fragment,e),_(ke.$$.fragment,e),_($e.$$.fragment,e),Os=!0)},o(e){v(x.$$.fragment,e),v(I.$$.fragment,e),v(se.$$.fragment,e),v(te.$$.fragment,e),v(re.$$.fragment,e),v(ie.$$.fragment,e),v(oe.$$.fragment,e),v(pe.$$.fragment,e),v(he.$$.fragment,e),v(ce.$$.fragment,e),v(me.$$.fragment,e),v(ue.$$.fragment,e),v(de.$$.fragment,e),v(_e.$$.fragment,e),v(ve.$$.fragment,e),v(ke.$$.fragment,e),v($e.$$.fragment,e),Os=!1},d(e){a(m),e&&a(N),e&&a($),k(x),e&&a(ps),e&&a(b),e&&a(fs),e&&a(P),e&&a(hs),k(I,e),e&&a(cs),e&&a(F),k(se),e&&a(ms),e&&a(E),e&&a(us),e&&a(Pe),e&&a(ds),k(te,e),e&&a(gs),e&&a(ne),e&&a(_s),k(re,e),e&&a(vs),e&&a(Se),e&&a(ks),k(ie,e),e&&a($s),e&&a(j),e&&a(js),k(oe,e),e&&a(ys),e&&a(L),k(pe),e&&a(xs),e&&a(y),e&&a(ws),k(he,e),e&&a(bs),e&&a(U),e&&a(Es),k(ce,e),e&&a(qs),e&&a(V),e&&a(As),k(me,e),e&&a(Ps),e&&a(C),k(ue),e&&a(Ts),e&&a(G),e&&a(Ms),e&&a(Ie),e&&a(Ss),k(de,e),e&&a(zs),e&&a(T),e&&a(Fs),k(_e,e),e&&a(Ls),e&&a(W),e&&a(Cs),k(ve,e),e&&a(Ds),e&&a(D),k(ke),e&&a(Ns),e&&a(K),e&&a(Hs),e&&a(Ve),e&&a(Is),e&&a(Be),e&&a(Rs),k($e,e)}}}const Mn={local:"pipelines-for-inference",sections:[{local:"pipeline-usage",sections:[{local:"choose-a-model-and-tokenizer",title:"Choose a model and tokenizer"}],title:"Pipeline usage"},{local:"audio-pipeline",title:"Audio pipeline"},{local:"vision-pipeline",title:"Vision pipeline"}],title:"Pipelines for inference"};function Sn(os){return qn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Dn extends yn{constructor(m){super();xn(this,m,Sn,Tn,wn,{})}}export{Dn as default,Mn as metadata};
