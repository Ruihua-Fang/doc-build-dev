import{S as qi,i as Si,s as Ii,e as a,k as i,w as d,t as l,M as Li,c as r,d as s,m as p,a as o,x as u,h as n,b as c,F as t,g as m,y as h,L as ki,q as _,o as v,B as g}from"../../chunks/vendor-22ad994f.js";import{D as w}from"../../chunks/Docstring-3bc3620c.js";import{C as Ja}from"../../chunks/CodeBlock-03069293.js";import{I as nt}from"../../chunks/IconCopyLink-2eb9a001.js";import"../../chunks/CopyButton-f539c482.js";function Ai(Wa){let N,it,S,L,Lt,_e,Ka,kt,Ya,Vs,pt,Za,Cs,C,F,At,ve,er,Dt,tr,Qs,y,sr,ft,ar,rr,ct,or,lr,mt,nr,ir,dt,pr,fr,Os,E,ge,cr,Nt,mr,dr,R,$e,ur,Ee,hr,ut,_r,vr,gr,X,xe,$r,Tt,Er,xr,H,we,wr,Vt,br,Pr,B,be,yr,Pe,qr,ht,Sr,Ir,Lr,J,ye,kr,qe,Ar,_t,Dr,Nr,Tr,W,Se,Vr,Ct,Cr,js,k,Ie,Qr,Qt,Or,jr,K,Le,Mr,Ot,Ur,Ms,A,ke,zr,jt,Gr,Fr,Y,Ae,Rr,Mt,Xr,Us,Q,Z,Ut,De,Hr,zt,Br,zs,ee,Ne,Jr,Wr,Te,Kr,Gs,vt,Yr,Fs,gt,Zr,Rs,$,Gt,Ft,eo,to,Rt,Xt,so,ao,Ht,Bt,ro,oo,Jt,Wt,lo,no,Kt,Yt,io,po,Zt,es,fo,co,ts,ss,mo,uo,as,rs,ho,_o,os,ls,vo,Xs,te,go,$t,$o,Eo,Hs,O,Ve,xo,Et,wo,ns,bo,Bs,j,se,is,Ce,Po,ps,yo,Js,M,Qe,qo,So,Oe,fs,Io,Lo,Ws,je,ko,Me,Ao,Ks,xt,Do,Ys,wt,cs,ms,No,Zs,bt,To,ea,ae,Vo,Ue,Co,Qo,ta,U,re,ds,ze,Oo,us,jo,sa,D,Ge,Mo,Uo,Fe,zo,Go,Re,Fo,Ro,aa,Pt,Xo,ra,z,oe,hs,Xe,Ho,_s,Bo,oa,yt,Jo,la,le,vs,gs,Wo,Ko,$s,Es,Yo,na,He,Zo,xs,el,ia,P,Be,tl,ws,sl,al,ne,Je,rl,bs,ol,ll,I,We,nl,Ke,il,Ps,pl,fl,cl,ys,ml,dl,Ye,ul,ie,Ze,hl,qs,_l,pa,pe,vl,Ss,gl,$l,fa,q,et,El,Is,xl,wl,Ls,bl,Pl,tt,ca,fe,yl,ks,ql,Sl,ma,G,ce,As,st,Il,Ds,Ll,da,qt,kl,ua,at,ha,me,Al,Ns,Dl,Nl,_a,rt,va,de,Tl,ot,Vl,Cl,ga;return _e=new nt({}),ve=new nt({}),ge=new w({props:{name:"class transformers.DataProcessor",anchor:"transformers.DataProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L81"}}),$e=new w({props:{name:"get_dev_examples",anchor:"transformers.DataProcessor.get_dev_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L98"}}),xe=new w({props:{name:"get_example_from_tensor_dict",anchor:"transformers.DataProcessor.get_example_from_tensor_dict",parameters:[{name:"tensor_dict",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L84"}}),we=new w({props:{name:"get_labels",anchor:"transformers.DataProcessor.get_labels",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L106"}}),be=new w({props:{name:"get_test_examples",anchor:"transformers.DataProcessor.get_test_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L102"}}),ye=new w({props:{name:"get_train_examples",anchor:"transformers.DataProcessor.get_train_examples",parameters:[{name:"data_dir",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L94"}}),Se=new w({props:{name:"tfds_map",anchor:"transformers.DataProcessor.tfds_map",parameters:[{name:"example",val:""}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L110"}}),Ie=new w({props:{name:"class transformers.InputExample",anchor:"transformers.InputExample",parameters:[{name:"guid",val:": str"},{name:"text_a",val:": str"},{name:"text_b",val:": typing.Optional[str] = None"},{name:"label",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L31"}}),Le=new w({props:{name:"to_json_string",anchor:"transformers.InputExample.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L50"}}),ke=new w({props:{name:"class transformers.InputFeatures",anchor:"transformers.InputFeatures",parameters:[{name:"input_ids",val:": typing.List[int]"},{name:"attention_mask",val:": typing.Optional[typing.List[int]] = None"},{name:"token_type_ids",val:": typing.Optional[typing.List[int]] = None"},{name:"label",val:": typing.Union[int, float, NoneType] = None"}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L56"}}),Ae=new w({props:{name:"to_json_string",anchor:"transformers.InputFeatures.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/utils.py#L76"}}),De=new nt({}),Ve=new w({props:{name:"transformers.glue_convert_examples_to_features",anchor:"transformers.glue_convert_examples_to_features",parameters:[{name:"examples",val:": typing.Union[typing.List[transformers.data.processors.utils.InputExample], ForwardRef('tf.data.Dataset')]"},{name:"tokenizer",val:": PreTrainedTokenizer"},{name:"max_length",val:": typing.Optional[int] = None"},{name:"task",val:" = None"},{name:"label_list",val:" = None"},{name:"output_mode",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/glue.py#L42",returnDescription:`
<p>If the <code>examples</code> input is a <code>tf.data.Dataset</code>, will return a <code>tf.data.Dataset</code> containing the task-specific
features. If the input is a list of <code>InputExamples</code>, will return a list of task-specific <code>InputFeatures</code> which
can be fed to the model.</p>
`}}),Ce=new nt({}),ze=new nt({}),Xe=new nt({}),Be=new w({props:{name:"class transformers.data.processors.squad.SquadProcessor",anchor:"transformers.data.processors.squad.SquadProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/squad.py#L543"}}),Je=new w({props:{name:"get_dev_examples",anchor:"transformers.data.processors.squad.SquadProcessor.get_dev_examples",parameters:[{name:"data_dir",val:""},{name:"filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/squad.py#L631"}}),We=new w({props:{name:"get_examples_from_dataset",anchor:"transformers.data.processors.squad.SquadProcessor.get_examples_from_dataset",parameters:[{name:"dataset",val:""},{name:"evaluate",val:" = False"}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/squad.py#L576",returnDescription:`
<p>List of SquadExample</p>
`}}),Ye=new Ja({props:{code:`import tensorflow_datasets as tfds

dataset = tfds.load("squad")

training_examples = get_examples_from_dataset(dataset, evaluate=False)
evaluation_examples = get_examples_from_dataset(dataset, evaluate=True),`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow_datasets <span class="hljs-keyword">as</span> tfds

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = tfds.load(<span class="hljs-string">&quot;squad&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>training_examples = get_examples_from_dataset(dataset, evaluate=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>evaluation_examples = get_examples_from_dataset(dataset, evaluate=<span class="hljs-literal">True</span>)`}}),Ze=new w({props:{name:"get_train_examples",anchor:"transformers.data.processors.squad.SquadProcessor.get_train_examples",parameters:[{name:"data_dir",val:""},{name:"filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/squad.py#L609"}}),et=new w({props:{name:"transformers.squad_convert_examples_to_features",anchor:"transformers.squad_convert_examples_to_features",parameters:[{name:"examples",val:""},{name:"tokenizer",val:""},{name:"max_seq_length",val:""},{name:"doc_stride",val:""},{name:"max_query_length",val:""},{name:"is_training",val:""},{name:"padding_strategy",val:" = 'max_length'"},{name:"return_dataset",val:" = False"},{name:"threads",val:" = 1"},{name:"tqdm_enabled",val:" = True"}],source:"https://github.com/huggingface/transformers/blob/pr_15794/src/transformers/data/processors/squad.py#L318"}}),tt=new Ja({props:{code:`processor = SquadV2Processor()
examples = processor.get_dev_examples(data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=args.max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=args.max_query_length,
    is_training=not evaluate,
),`,highlighted:`processor = SquadV2Processor()
examples = processor.get_dev_examples(data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=args.max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=args.max_query_length,
    is_training=<span class="hljs-keyword">not</span> evaluate,
)`}}),st=new nt({}),at=new Ja({props:{code:`# Loading a V2 processor
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

# Loading a V1 processor
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
),`,highlighted:`<span class="hljs-comment"># Loading a V2 processor</span>
processor = SquadV2Processor()
examples = processor.get_dev_examples(squad_v2_data_dir)

<span class="hljs-comment"># Loading a V1 processor</span>
processor = SquadV1Processor()
examples = processor.get_dev_examples(squad_v1_data_dir)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=<span class="hljs-keyword">not</span> evaluate,
)`}}),rt=new Ja({props:{code:`# tensorflow_datasets only handle Squad V1.
tfds_examples = tfds.load("squad")
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=not evaluate,
),`,highlighted:`<span class="hljs-comment"># tensorflow_datasets only handle Squad V1.</span>
tfds_examples = tfds.load(<span class="hljs-string">&quot;squad&quot;</span>)
examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate)

features = squad_convert_examples_to_features(
    examples=examples,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length,
    doc_stride=args.doc_stride,
    max_query_length=max_query_length,
    is_training=<span class="hljs-keyword">not</span> evaluate,
)`}}),{c(){N=a("meta"),it=i(),S=a("h1"),L=a("a"),Lt=a("span"),d(_e.$$.fragment),Ka=i(),kt=a("span"),Ya=l("Processors"),Vs=i(),pt=a("p"),Za=l(`This library includes processors for several traditional tasks. These processors can be used to process a dataset into
examples that can be fed to a model.`),Cs=i(),C=a("h2"),F=a("a"),At=a("span"),d(ve.$$.fragment),er=i(),Dt=a("span"),tr=l("Processors"),Qs=i(),y=a("p"),sr=l(`All processors follow the same architecture which is that of the
`),ft=a("a"),ar=l("DataProcessor"),rr=l(`. The processor returns a list of
`),ct=a("a"),or=l("InputExample"),lr=l(`. These
`),mt=a("a"),nr=l("InputExample"),ir=l(` can be converted to
`),dt=a("a"),pr=l("InputFeatures"),fr=l(" in order to be fed to the model."),Os=i(),E=a("div"),d(ge.$$.fragment),cr=i(),Nt=a("p"),mr=l("Base class for data converters for sequence classification data sets."),dr=i(),R=a("div"),d($e.$$.fragment),ur=i(),Ee=a("p"),hr=l("Gets a collection of "),ut=a("a"),_r=l("InputExample"),vr=l(" for the dev set."),gr=i(),X=a("div"),d(xe.$$.fragment),$r=i(),Tt=a("p"),Er=l("Gets an example from a dict with tensorflow tensors."),xr=i(),H=a("div"),d(we.$$.fragment),wr=i(),Vt=a("p"),br=l("Gets the list of labels for this data set."),Pr=i(),B=a("div"),d(be.$$.fragment),yr=i(),Pe=a("p"),qr=l("Gets a collection of "),ht=a("a"),Sr=l("InputExample"),Ir=l(" for the test set."),Lr=i(),J=a("div"),d(ye.$$.fragment),kr=i(),qe=a("p"),Ar=l("Gets a collection of "),_t=a("a"),Dr=l("InputExample"),Nr=l(" for the train set."),Tr=i(),W=a("div"),d(Se.$$.fragment),Vr=i(),Ct=a("p"),Cr=l(`Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts
examples to the correct format.`),js=i(),k=a("div"),d(Ie.$$.fragment),Qr=i(),Qt=a("p"),Or=l("A single training/test example for simple sequence classification."),jr=i(),K=a("div"),d(Le.$$.fragment),Mr=i(),Ot=a("p"),Ur=l("Serializes this instance to a JSON string."),Ms=i(),A=a("div"),d(ke.$$.fragment),zr=i(),jt=a("p"),Gr=l("A single set of features of data. Property names are the same names as the corresponding inputs to a model."),Fr=i(),Y=a("div"),d(Ae.$$.fragment),Rr=i(),Mt=a("p"),Xr=l("Serializes this instance to a JSON string."),Us=i(),Q=a("h2"),Z=a("a"),Ut=a("span"),d(De.$$.fragment),Hr=i(),zt=a("span"),Br=l("GLUE"),zs=i(),ee=a("p"),Ne=a("a"),Jr=l("General Language Understanding Evaluation (GLUE)"),Wr=l(` is a benchmark that evaluates the
performance of models across a diverse set of existing NLU tasks. It was released together with the paper `),Te=a("a"),Kr=l(`GLUE: A
multi-task benchmark and analysis platform for natural language understanding`),Gs=i(),vt=a("p"),Yr=l(`This library hosts a total of 10 processors for the following tasks: MRPC, MNLI, MNLI (mismatched), CoLA, SST2, STSB,
QQP, QNLI, RTE and WNLI.`),Fs=i(),gt=a("p"),Zr=l("Those processors are:"),Rs=i(),$=a("ul"),Gt=a("li"),Ft=a("code"),eo=l("MrpcProcessor"),to=i(),Rt=a("li"),Xt=a("code"),so=l("MnliProcessor"),ao=i(),Ht=a("li"),Bt=a("code"),ro=l("MnliMismatchedProcessor"),oo=i(),Jt=a("li"),Wt=a("code"),lo=l("Sst2Processor"),no=i(),Kt=a("li"),Yt=a("code"),io=l("StsbProcessor"),po=i(),Zt=a("li"),es=a("code"),fo=l("QqpProcessor"),co=i(),ts=a("li"),ss=a("code"),mo=l("QnliProcessor"),uo=i(),as=a("li"),rs=a("code"),ho=l("RteProcessor"),_o=i(),os=a("li"),ls=a("code"),vo=l("WnliProcessor"),Xs=i(),te=a("p"),go=l(`Additionally, the following method can be used to load values from a data file and convert them to a list of
`),$t=a("a"),$o=l("InputExample"),Eo=l("."),Hs=i(),O=a("div"),d(Ve.$$.fragment),xo=i(),Et=a("p"),wo=l("Loads a data file into a list of "),ns=a("code"),bo=l("InputFeatures"),Bs=i(),j=a("h2"),se=a("a"),is=a("span"),d(Ce.$$.fragment),Po=i(),ps=a("span"),yo=l("XNLI"),Js=i(),M=a("p"),Qe=a("a"),qo=l("The Cross-Lingual NLI Corpus (XNLI)"),So=l(` is a benchmark that evaluates the
quality of cross-lingual text representations. XNLI is crowd-sourced dataset based on `),Oe=a("a"),fs=a("em"),Io=l("MultiNLI"),Lo=l(`: pairs of text are labeled with textual entailment annotations for 15
different languages (including both high-resource language such as English and low-resource languages such as Swahili).`),Ws=i(),je=a("p"),ko=l("It was released together with the paper "),Me=a("a"),Ao=l("XNLI: Evaluating Cross-lingual Sentence Representations"),Ks=i(),xt=a("p"),Do=l("This library hosts the processor to load the XNLI data:"),Ys=i(),wt=a("ul"),cs=a("li"),ms=a("code"),No=l("XnliProcessor"),Zs=i(),bt=a("p"),To=l("Please note that since the gold labels are available on the test set, evaluation is performed on the test set."),ea=i(),ae=a("p"),Vo=l("An example using these processors is given in the "),Ue=a("a"),Co=l("run_xnli.py"),Qo=l(" script."),ta=i(),U=a("h2"),re=a("a"),ds=a("span"),d(ze.$$.fragment),Oo=i(),us=a("span"),jo=l("SQuAD"),sa=i(),D=a("p"),Ge=a("a"),Mo=l("The Stanford Question Answering Dataset (SQuAD)"),Uo=l(` is a benchmark that
evaluates the performance of models on question answering. Two versions are available, v1.1 and v2.0. The first version
(v1.1) was released together with the paper `),Fe=a("a"),zo=l("SQuAD: 100,000+ Questions for Machine Comprehension of Text"),Go=l(". The second version (v2.0) was released alongside the paper "),Re=a("a"),Fo=l(`Know What You Don\u2019t
Know: Unanswerable Questions for SQuAD`),Ro=l("."),aa=i(),Pt=a("p"),Xo=l("This library hosts a processor for each of the two versions:"),ra=i(),z=a("h3"),oe=a("a"),hs=a("span"),d(Xe.$$.fragment),Ho=i(),_s=a("span"),Bo=l("Processors"),oa=i(),yt=a("p"),Jo=l("Those processors are:"),la=i(),le=a("ul"),vs=a("li"),gs=a("code"),Wo=l("SquadV1Processor"),Ko=i(),$s=a("li"),Es=a("code"),Yo=l("SquadV2Processor"),na=i(),He=a("p"),Zo=l("They both inherit from the abstract class "),xs=a("code"),el=l("SquadProcessor"),ia=i(),P=a("div"),d(Be.$$.fragment),tl=i(),ws=a("p"),sl=l(`Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor, used by the version 1.1 and
version 2.0 of SQuAD, respectively.`),al=i(),ne=a("div"),d(Je.$$.fragment),rl=i(),bs=a("p"),ol=l("Returns the evaluation example from the data directory."),ll=i(),I=a("div"),d(We.$$.fragment),nl=i(),Ke=a("p"),il=l("Creates a list of "),Ps=a("code"),pl=l("SquadExample"),fl=l("using a TFDS dataset."),cl=i(),ys=a("p"),ml=l("Examples:"),dl=i(),d(Ye.$$.fragment),ul=i(),ie=a("div"),d(Ze.$$.fragment),hl=i(),qs=a("p"),_l=l("Returns the training examples from the data directory."),pa=i(),pe=a("p"),vl=l(`Additionally, the following method can be used to convert SQuAD examples into
`),Ss=a("code"),gl=l("SquadFeatures"),$l=l(" that can be used as model inputs."),fa=i(),q=a("div"),d(et.$$.fragment),El=i(),Is=a("p"),xl=l(`Converts a list of examples into a list of features that can be directly given as input to a model. It is
model-dependant and takes advantage of many of the tokenizer\u2019s features to create the model\u2019s inputs.`),wl=i(),Ls=a("p"),bl=l("Example:"),Pl=i(),d(tt.$$.fragment),ca=i(),fe=a("p"),yl=l(`These processors as well as the aforementionned method can be used with files containing the data as well as with the
`),ks=a("em"),ql=l("tensorflow_datasets"),Sl=l(" package. Examples are given below."),ma=i(),G=a("h3"),ce=a("a"),As=a("span"),d(st.$$.fragment),Il=i(),Ds=a("span"),Ll=l("Example usage"),da=i(),qt=a("p"),kl=l("Here is an example using the processors as well as the conversion method using data files:"),ua=i(),d(at.$$.fragment),ha=i(),me=a("p"),Al=l("Using "),Ns=a("em"),Dl=l("tensorflow_datasets"),Nl=l(" is as easy as using a data file:"),_a=i(),d(rt.$$.fragment),va=i(),de=a("p"),Tl=l("Another example using these processors is given in the "),ot=a("a"),Vl=l("run_squad.py"),Cl=l(" script."),this.h()},l(e){const f=Li('[data-svelte="svelte-1phssyn"]',document.head);N=r(f,"META",{name:!0,content:!0}),f.forEach(s),it=p(e),S=r(e,"H1",{class:!0});var $a=o(S);L=r($a,"A",{id:!0,class:!0,href:!0});var Ml=o(L);Lt=r(Ml,"SPAN",{});var Ul=o(Lt);u(_e.$$.fragment,Ul),Ul.forEach(s),Ml.forEach(s),Ka=p($a),kt=r($a,"SPAN",{});var zl=o(kt);Ya=n(zl,"Processors"),zl.forEach(s),$a.forEach(s),Vs=p(e),pt=r(e,"P",{});var Gl=o(pt);Za=n(Gl,`This library includes processors for several traditional tasks. These processors can be used to process a dataset into
examples that can be fed to a model.`),Gl.forEach(s),Cs=p(e),C=r(e,"H2",{class:!0});var Ea=o(C);F=r(Ea,"A",{id:!0,class:!0,href:!0});var Fl=o(F);At=r(Fl,"SPAN",{});var Rl=o(At);u(ve.$$.fragment,Rl),Rl.forEach(s),Fl.forEach(s),er=p(Ea),Dt=r(Ea,"SPAN",{});var Xl=o(Dt);tr=n(Xl,"Processors"),Xl.forEach(s),Ea.forEach(s),Qs=p(e),y=r(e,"P",{});var T=o(y);sr=n(T,`All processors follow the same architecture which is that of the
`),ft=r(T,"A",{href:!0});var Hl=o(ft);ar=n(Hl,"DataProcessor"),Hl.forEach(s),rr=n(T,`. The processor returns a list of
`),ct=r(T,"A",{href:!0});var Bl=o(ct);or=n(Bl,"InputExample"),Bl.forEach(s),lr=n(T,`. These
`),mt=r(T,"A",{href:!0});var Jl=o(mt);nr=n(Jl,"InputExample"),Jl.forEach(s),ir=n(T,` can be converted to
`),dt=r(T,"A",{href:!0});var Wl=o(dt);pr=n(Wl,"InputFeatures"),Wl.forEach(s),fr=n(T," in order to be fed to the model."),T.forEach(s),Os=p(e),E=r(e,"DIV",{class:!0});var b=o(E);u(ge.$$.fragment,b),cr=p(b),Nt=r(b,"P",{});var Kl=o(Nt);mr=n(Kl,"Base class for data converters for sequence classification data sets."),Kl.forEach(s),dr=p(b),R=r(b,"DIV",{class:!0});var xa=o(R);u($e.$$.fragment,xa),ur=p(xa),Ee=r(xa,"P",{});var wa=o(Ee);hr=n(wa,"Gets a collection of "),ut=r(wa,"A",{href:!0});var Yl=o(ut);_r=n(Yl,"InputExample"),Yl.forEach(s),vr=n(wa," for the dev set."),wa.forEach(s),xa.forEach(s),gr=p(b),X=r(b,"DIV",{class:!0});var ba=o(X);u(xe.$$.fragment,ba),$r=p(ba),Tt=r(ba,"P",{});var Zl=o(Tt);Er=n(Zl,"Gets an example from a dict with tensorflow tensors."),Zl.forEach(s),ba.forEach(s),xr=p(b),H=r(b,"DIV",{class:!0});var Pa=o(H);u(we.$$.fragment,Pa),wr=p(Pa),Vt=r(Pa,"P",{});var en=o(Vt);br=n(en,"Gets the list of labels for this data set."),en.forEach(s),Pa.forEach(s),Pr=p(b),B=r(b,"DIV",{class:!0});var ya=o(B);u(be.$$.fragment,ya),yr=p(ya),Pe=r(ya,"P",{});var qa=o(Pe);qr=n(qa,"Gets a collection of "),ht=r(qa,"A",{href:!0});var tn=o(ht);Sr=n(tn,"InputExample"),tn.forEach(s),Ir=n(qa," for the test set."),qa.forEach(s),ya.forEach(s),Lr=p(b),J=r(b,"DIV",{class:!0});var Sa=o(J);u(ye.$$.fragment,Sa),kr=p(Sa),qe=r(Sa,"P",{});var Ia=o(qe);Ar=n(Ia,"Gets a collection of "),_t=r(Ia,"A",{href:!0});var sn=o(_t);Dr=n(sn,"InputExample"),sn.forEach(s),Nr=n(Ia," for the train set."),Ia.forEach(s),Sa.forEach(s),Tr=p(b),W=r(b,"DIV",{class:!0});var La=o(W);u(Se.$$.fragment,La),Vr=p(La),Ct=r(La,"P",{});var an=o(Ct);Cr=n(an,`Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts
examples to the correct format.`),an.forEach(s),La.forEach(s),b.forEach(s),js=p(e),k=r(e,"DIV",{class:!0});var St=o(k);u(Ie.$$.fragment,St),Qr=p(St),Qt=r(St,"P",{});var rn=o(Qt);Or=n(rn,"A single training/test example for simple sequence classification."),rn.forEach(s),jr=p(St),K=r(St,"DIV",{class:!0});var ka=o(K);u(Le.$$.fragment,ka),Mr=p(ka),Ot=r(ka,"P",{});var on=o(Ot);Ur=n(on,"Serializes this instance to a JSON string."),on.forEach(s),ka.forEach(s),St.forEach(s),Ms=p(e),A=r(e,"DIV",{class:!0});var It=o(A);u(ke.$$.fragment,It),zr=p(It),jt=r(It,"P",{});var ln=o(jt);Gr=n(ln,"A single set of features of data. Property names are the same names as the corresponding inputs to a model."),ln.forEach(s),Fr=p(It),Y=r(It,"DIV",{class:!0});var Aa=o(Y);u(Ae.$$.fragment,Aa),Rr=p(Aa),Mt=r(Aa,"P",{});var nn=o(Mt);Xr=n(nn,"Serializes this instance to a JSON string."),nn.forEach(s),Aa.forEach(s),It.forEach(s),Us=p(e),Q=r(e,"H2",{class:!0});var Da=o(Q);Z=r(Da,"A",{id:!0,class:!0,href:!0});var pn=o(Z);Ut=r(pn,"SPAN",{});var fn=o(Ut);u(De.$$.fragment,fn),fn.forEach(s),pn.forEach(s),Hr=p(Da),zt=r(Da,"SPAN",{});var cn=o(zt);Br=n(cn,"GLUE"),cn.forEach(s),Da.forEach(s),zs=p(e),ee=r(e,"P",{});var Na=o(ee);Ne=r(Na,"A",{href:!0,rel:!0});var mn=o(Ne);Jr=n(mn,"General Language Understanding Evaluation (GLUE)"),mn.forEach(s),Wr=n(Na,` is a benchmark that evaluates the
performance of models across a diverse set of existing NLU tasks. It was released together with the paper `),Te=r(Na,"A",{href:!0,rel:!0});var dn=o(Te);Kr=n(dn,`GLUE: A
multi-task benchmark and analysis platform for natural language understanding`),dn.forEach(s),Na.forEach(s),Gs=p(e),vt=r(e,"P",{});var un=o(vt);Yr=n(un,`This library hosts a total of 10 processors for the following tasks: MRPC, MNLI, MNLI (mismatched), CoLA, SST2, STSB,
QQP, QNLI, RTE and WNLI.`),un.forEach(s),Fs=p(e),gt=r(e,"P",{});var hn=o(gt);Zr=n(hn,"Those processors are:"),hn.forEach(s),Rs=p(e),$=r(e,"UL",{});var x=o($);Gt=r(x,"LI",{});var _n=o(Gt);Ft=r(_n,"CODE",{});var vn=o(Ft);eo=n(vn,"MrpcProcessor"),vn.forEach(s),_n.forEach(s),to=p(x),Rt=r(x,"LI",{});var gn=o(Rt);Xt=r(gn,"CODE",{});var $n=o(Xt);so=n($n,"MnliProcessor"),$n.forEach(s),gn.forEach(s),ao=p(x),Ht=r(x,"LI",{});var En=o(Ht);Bt=r(En,"CODE",{});var xn=o(Bt);ro=n(xn,"MnliMismatchedProcessor"),xn.forEach(s),En.forEach(s),oo=p(x),Jt=r(x,"LI",{});var wn=o(Jt);Wt=r(wn,"CODE",{});var bn=o(Wt);lo=n(bn,"Sst2Processor"),bn.forEach(s),wn.forEach(s),no=p(x),Kt=r(x,"LI",{});var Pn=o(Kt);Yt=r(Pn,"CODE",{});var yn=o(Yt);io=n(yn,"StsbProcessor"),yn.forEach(s),Pn.forEach(s),po=p(x),Zt=r(x,"LI",{});var qn=o(Zt);es=r(qn,"CODE",{});var Sn=o(es);fo=n(Sn,"QqpProcessor"),Sn.forEach(s),qn.forEach(s),co=p(x),ts=r(x,"LI",{});var In=o(ts);ss=r(In,"CODE",{});var Ln=o(ss);mo=n(Ln,"QnliProcessor"),Ln.forEach(s),In.forEach(s),uo=p(x),as=r(x,"LI",{});var kn=o(as);rs=r(kn,"CODE",{});var An=o(rs);ho=n(An,"RteProcessor"),An.forEach(s),kn.forEach(s),_o=p(x),os=r(x,"LI",{});var Dn=o(os);ls=r(Dn,"CODE",{});var Nn=o(ls);vo=n(Nn,"WnliProcessor"),Nn.forEach(s),Dn.forEach(s),x.forEach(s),Xs=p(e),te=r(e,"P",{});var Ta=o(te);go=n(Ta,`Additionally, the following method can be used to load values from a data file and convert them to a list of
`),$t=r(Ta,"A",{href:!0});var Tn=o($t);$o=n(Tn,"InputExample"),Tn.forEach(s),Eo=n(Ta,"."),Ta.forEach(s),Hs=p(e),O=r(e,"DIV",{class:!0});var Va=o(O);u(Ve.$$.fragment,Va),xo=p(Va),Et=r(Va,"P",{});var Ql=o(Et);wo=n(Ql,"Loads a data file into a list of "),ns=r(Ql,"CODE",{});var Vn=o(ns);bo=n(Vn,"InputFeatures"),Vn.forEach(s),Ql.forEach(s),Va.forEach(s),Bs=p(e),j=r(e,"H2",{class:!0});var Ca=o(j);se=r(Ca,"A",{id:!0,class:!0,href:!0});var Cn=o(se);is=r(Cn,"SPAN",{});var Qn=o(is);u(Ce.$$.fragment,Qn),Qn.forEach(s),Cn.forEach(s),Po=p(Ca),ps=r(Ca,"SPAN",{});var On=o(ps);yo=n(On,"XNLI"),On.forEach(s),Ca.forEach(s),Js=p(e),M=r(e,"P",{});var Ts=o(M);Qe=r(Ts,"A",{href:!0,rel:!0});var jn=o(Qe);qo=n(jn,"The Cross-Lingual NLI Corpus (XNLI)"),jn.forEach(s),So=n(Ts,` is a benchmark that evaluates the
quality of cross-lingual text representations. XNLI is crowd-sourced dataset based on `),Oe=r(Ts,"A",{href:!0,rel:!0});var Mn=o(Oe);fs=r(Mn,"EM",{});var Un=o(fs);Io=n(Un,"MultiNLI"),Un.forEach(s),Mn.forEach(s),Lo=n(Ts,`: pairs of text are labeled with textual entailment annotations for 15
different languages (including both high-resource language such as English and low-resource languages such as Swahili).`),Ts.forEach(s),Ws=p(e),je=r(e,"P",{});var Ol=o(je);ko=n(Ol,"It was released together with the paper "),Me=r(Ol,"A",{href:!0,rel:!0});var zn=o(Me);Ao=n(zn,"XNLI: Evaluating Cross-lingual Sentence Representations"),zn.forEach(s),Ol.forEach(s),Ks=p(e),xt=r(e,"P",{});var Gn=o(xt);Do=n(Gn,"This library hosts the processor to load the XNLI data:"),Gn.forEach(s),Ys=p(e),wt=r(e,"UL",{});var Fn=o(wt);cs=r(Fn,"LI",{});var Rn=o(cs);ms=r(Rn,"CODE",{});var Xn=o(ms);No=n(Xn,"XnliProcessor"),Xn.forEach(s),Rn.forEach(s),Fn.forEach(s),Zs=p(e),bt=r(e,"P",{});var Hn=o(bt);To=n(Hn,"Please note that since the gold labels are available on the test set, evaluation is performed on the test set."),Hn.forEach(s),ea=p(e),ae=r(e,"P",{});var Qa=o(ae);Vo=n(Qa,"An example using these processors is given in the "),Ue=r(Qa,"A",{href:!0,rel:!0});var Bn=o(Ue);Co=n(Bn,"run_xnli.py"),Bn.forEach(s),Qo=n(Qa," script."),Qa.forEach(s),ta=p(e),U=r(e,"H2",{class:!0});var Oa=o(U);re=r(Oa,"A",{id:!0,class:!0,href:!0});var Jn=o(re);ds=r(Jn,"SPAN",{});var Wn=o(ds);u(ze.$$.fragment,Wn),Wn.forEach(s),Jn.forEach(s),Oo=p(Oa),us=r(Oa,"SPAN",{});var Kn=o(us);jo=n(Kn,"SQuAD"),Kn.forEach(s),Oa.forEach(s),sa=p(e),D=r(e,"P",{});var lt=o(D);Ge=r(lt,"A",{href:!0,rel:!0});var Yn=o(Ge);Mo=n(Yn,"The Stanford Question Answering Dataset (SQuAD)"),Yn.forEach(s),Uo=n(lt,` is a benchmark that
evaluates the performance of models on question answering. Two versions are available, v1.1 and v2.0. The first version
(v1.1) was released together with the paper `),Fe=r(lt,"A",{href:!0,rel:!0});var Zn=o(Fe);zo=n(Zn,"SQuAD: 100,000+ Questions for Machine Comprehension of Text"),Zn.forEach(s),Go=n(lt,". The second version (v2.0) was released alongside the paper "),Re=r(lt,"A",{href:!0,rel:!0});var ei=o(Re);Fo=n(ei,`Know What You Don\u2019t
Know: Unanswerable Questions for SQuAD`),ei.forEach(s),Ro=n(lt,"."),lt.forEach(s),aa=p(e),Pt=r(e,"P",{});var ti=o(Pt);Xo=n(ti,"This library hosts a processor for each of the two versions:"),ti.forEach(s),ra=p(e),z=r(e,"H3",{class:!0});var ja=o(z);oe=r(ja,"A",{id:!0,class:!0,href:!0});var si=o(oe);hs=r(si,"SPAN",{});var ai=o(hs);u(Xe.$$.fragment,ai),ai.forEach(s),si.forEach(s),Ho=p(ja),_s=r(ja,"SPAN",{});var ri=o(_s);Bo=n(ri,"Processors"),ri.forEach(s),ja.forEach(s),oa=p(e),yt=r(e,"P",{});var oi=o(yt);Jo=n(oi,"Those processors are:"),oi.forEach(s),la=p(e),le=r(e,"UL",{});var Ma=o(le);vs=r(Ma,"LI",{});var li=o(vs);gs=r(li,"CODE",{});var ni=o(gs);Wo=n(ni,"SquadV1Processor"),ni.forEach(s),li.forEach(s),Ko=p(Ma),$s=r(Ma,"LI",{});var ii=o($s);Es=r(ii,"CODE",{});var pi=o(Es);Yo=n(pi,"SquadV2Processor"),pi.forEach(s),ii.forEach(s),Ma.forEach(s),na=p(e),He=r(e,"P",{});var jl=o(He);Zo=n(jl,"They both inherit from the abstract class "),xs=r(jl,"CODE",{});var fi=o(xs);el=n(fi,"SquadProcessor"),fi.forEach(s),jl.forEach(s),ia=p(e),P=r(e,"DIV",{class:!0});var V=o(P);u(Be.$$.fragment,V),tl=p(V),ws=r(V,"P",{});var ci=o(ws);sl=n(ci,`Processor for the SQuAD data set. overridden by SquadV1Processor and SquadV2Processor, used by the version 1.1 and
version 2.0 of SQuAD, respectively.`),ci.forEach(s),al=p(V),ne=r(V,"DIV",{class:!0});var Ua=o(ne);u(Je.$$.fragment,Ua),rl=p(Ua),bs=r(Ua,"P",{});var mi=o(bs);ol=n(mi,"Returns the evaluation example from the data directory."),mi.forEach(s),Ua.forEach(s),ll=p(V),I=r(V,"DIV",{class:!0});var ue=o(I);u(We.$$.fragment,ue),nl=p(ue),Ke=r(ue,"P",{});var za=o(Ke);il=n(za,"Creates a list of "),Ps=r(za,"CODE",{});var di=o(Ps);pl=n(di,"SquadExample"),di.forEach(s),fl=n(za,"using a TFDS dataset."),za.forEach(s),cl=p(ue),ys=r(ue,"P",{});var ui=o(ys);ml=n(ui,"Examples:"),ui.forEach(s),dl=p(ue),u(Ye.$$.fragment,ue),ue.forEach(s),ul=p(V),ie=r(V,"DIV",{class:!0});var Ga=o(ie);u(Ze.$$.fragment,Ga),hl=p(Ga),qs=r(Ga,"P",{});var hi=o(qs);_l=n(hi,"Returns the training examples from the data directory."),hi.forEach(s),Ga.forEach(s),V.forEach(s),pa=p(e),pe=r(e,"P",{});var Fa=o(pe);vl=n(Fa,`Additionally, the following method can be used to convert SQuAD examples into
`),Ss=r(Fa,"CODE",{});var _i=o(Ss);gl=n(_i,"SquadFeatures"),_i.forEach(s),$l=n(Fa," that can be used as model inputs."),Fa.forEach(s),fa=p(e),q=r(e,"DIV",{class:!0});var he=o(q);u(et.$$.fragment,he),El=p(he),Is=r(he,"P",{});var vi=o(Is);xl=n(vi,`Converts a list of examples into a list of features that can be directly given as input to a model. It is
model-dependant and takes advantage of many of the tokenizer\u2019s features to create the model\u2019s inputs.`),vi.forEach(s),wl=p(he),Ls=r(he,"P",{});var gi=o(Ls);bl=n(gi,"Example:"),gi.forEach(s),Pl=p(he),u(tt.$$.fragment,he),he.forEach(s),ca=p(e),fe=r(e,"P",{});var Ra=o(fe);yl=n(Ra,`These processors as well as the aforementionned method can be used with files containing the data as well as with the
`),ks=r(Ra,"EM",{});var $i=o(ks);ql=n($i,"tensorflow_datasets"),$i.forEach(s),Sl=n(Ra," package. Examples are given below."),Ra.forEach(s),ma=p(e),G=r(e,"H3",{class:!0});var Xa=o(G);ce=r(Xa,"A",{id:!0,class:!0,href:!0});var Ei=o(ce);As=r(Ei,"SPAN",{});var xi=o(As);u(st.$$.fragment,xi),xi.forEach(s),Ei.forEach(s),Il=p(Xa),Ds=r(Xa,"SPAN",{});var wi=o(Ds);Ll=n(wi,"Example usage"),wi.forEach(s),Xa.forEach(s),da=p(e),qt=r(e,"P",{});var bi=o(qt);kl=n(bi,"Here is an example using the processors as well as the conversion method using data files:"),bi.forEach(s),ua=p(e),u(at.$$.fragment,e),ha=p(e),me=r(e,"P",{});var Ha=o(me);Al=n(Ha,"Using "),Ns=r(Ha,"EM",{});var Pi=o(Ns);Dl=n(Pi,"tensorflow_datasets"),Pi.forEach(s),Nl=n(Ha," is as easy as using a data file:"),Ha.forEach(s),_a=p(e),u(rt.$$.fragment,e),va=p(e),de=r(e,"P",{});var Ba=o(de);Tl=n(Ba,"Another example using these processors is given in the "),ot=r(Ba,"A",{href:!0,rel:!0});var yi=o(ot);Vl=n(yi,"run_squad.py"),yi.forEach(s),Cl=n(Ba," script."),Ba.forEach(s),this.h()},h(){c(N,"name","hf:doc:metadata"),c(N,"content",JSON.stringify(Di)),c(L,"id","processors"),c(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L,"href","#processors"),c(S,"class","relative group"),c(F,"id","transformers.DataProcessor"),c(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(F,"href","#transformers.DataProcessor"),c(C,"class","relative group"),c(ft,"href","/docs/transformers/pr_15794/en/main_classes/processors#transformers.DataProcessor"),c(ct,"href","/docs/transformers/pr_15794/en/main_classes/processors#transformers.InputExample"),c(mt,"href","/docs/transformers/pr_15794/en/main_classes/processors#transformers.InputExample"),c(dt,"href","/docs/transformers/pr_15794/en/main_classes/processors#transformers.InputFeatures"),c(ut,"href","/docs/transformers/pr_15794/en/main_classes/processors#transformers.InputExample"),c(R,"class","docstring"),c(X,"class","docstring"),c(H,"class","docstring"),c(ht,"href","/docs/transformers/pr_15794/en/main_classes/processors#transformers.InputExample"),c(B,"class","docstring"),c(_t,"href","/docs/transformers/pr_15794/en/main_classes/processors#transformers.InputExample"),c(J,"class","docstring"),c(W,"class","docstring"),c(E,"class","docstring"),c(K,"class","docstring"),c(k,"class","docstring"),c(Y,"class","docstring"),c(A,"class","docstring"),c(Z,"id","transformers.glue_convert_examples_to_features"),c(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z,"href","#transformers.glue_convert_examples_to_features"),c(Q,"class","relative group"),c(Ne,"href","https://gluebenchmark.com/"),c(Ne,"rel","nofollow"),c(Te,"href","https://openreview.net/pdf?id=rJ4km2R5t7"),c(Te,"rel","nofollow"),c($t,"href","/docs/transformers/pr_15794/en/main_classes/processors#transformers.InputExample"),c(O,"class","docstring"),c(se,"id","xnli"),c(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(se,"href","#xnli"),c(j,"class","relative group"),c(Qe,"href","https://www.nyu.edu/projects/bowman/xnli/"),c(Qe,"rel","nofollow"),c(Oe,"href","http://www.nyu.edu/projects/bowman/multinli/"),c(Oe,"rel","nofollow"),c(Me,"href","https://arxiv.org/abs/1809.05053"),c(Me,"rel","nofollow"),c(Ue,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/text-classification/run_xnli.py"),c(Ue,"rel","nofollow"),c(re,"id","squad"),c(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(re,"href","#squad"),c(U,"class","relative group"),c(Ge,"href","https://rajpurkar.github.io/SQuAD-explorer//"),c(Ge,"rel","nofollow"),c(Fe,"href","https://arxiv.org/abs/1606.05250"),c(Fe,"rel","nofollow"),c(Re,"href","https://arxiv.org/abs/1806.03822"),c(Re,"rel","nofollow"),c(oe,"id","transformers.data.processors.squad.SquadProcessor"),c(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oe,"href","#transformers.data.processors.squad.SquadProcessor"),c(z,"class","relative group"),c(ne,"class","docstring"),c(I,"class","docstring"),c(ie,"class","docstring"),c(P,"class","docstring"),c(q,"class","docstring"),c(ce,"id","example-usage"),c(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ce,"href","#example-usage"),c(G,"class","relative group"),c(ot,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy/question-answering/run_squad.py"),c(ot,"rel","nofollow")},m(e,f){t(document.head,N),m(e,it,f),m(e,S,f),t(S,L),t(L,Lt),h(_e,Lt,null),t(S,Ka),t(S,kt),t(kt,Ya),m(e,Vs,f),m(e,pt,f),t(pt,Za),m(e,Cs,f),m(e,C,f),t(C,F),t(F,At),h(ve,At,null),t(C,er),t(C,Dt),t(Dt,tr),m(e,Qs,f),m(e,y,f),t(y,sr),t(y,ft),t(ft,ar),t(y,rr),t(y,ct),t(ct,or),t(y,lr),t(y,mt),t(mt,nr),t(y,ir),t(y,dt),t(dt,pr),t(y,fr),m(e,Os,f),m(e,E,f),h(ge,E,null),t(E,cr),t(E,Nt),t(Nt,mr),t(E,dr),t(E,R),h($e,R,null),t(R,ur),t(R,Ee),t(Ee,hr),t(Ee,ut),t(ut,_r),t(Ee,vr),t(E,gr),t(E,X),h(xe,X,null),t(X,$r),t(X,Tt),t(Tt,Er),t(E,xr),t(E,H),h(we,H,null),t(H,wr),t(H,Vt),t(Vt,br),t(E,Pr),t(E,B),h(be,B,null),t(B,yr),t(B,Pe),t(Pe,qr),t(Pe,ht),t(ht,Sr),t(Pe,Ir),t(E,Lr),t(E,J),h(ye,J,null),t(J,kr),t(J,qe),t(qe,Ar),t(qe,_t),t(_t,Dr),t(qe,Nr),t(E,Tr),t(E,W),h(Se,W,null),t(W,Vr),t(W,Ct),t(Ct,Cr),m(e,js,f),m(e,k,f),h(Ie,k,null),t(k,Qr),t(k,Qt),t(Qt,Or),t(k,jr),t(k,K),h(Le,K,null),t(K,Mr),t(K,Ot),t(Ot,Ur),m(e,Ms,f),m(e,A,f),h(ke,A,null),t(A,zr),t(A,jt),t(jt,Gr),t(A,Fr),t(A,Y),h(Ae,Y,null),t(Y,Rr),t(Y,Mt),t(Mt,Xr),m(e,Us,f),m(e,Q,f),t(Q,Z),t(Z,Ut),h(De,Ut,null),t(Q,Hr),t(Q,zt),t(zt,Br),m(e,zs,f),m(e,ee,f),t(ee,Ne),t(Ne,Jr),t(ee,Wr),t(ee,Te),t(Te,Kr),m(e,Gs,f),m(e,vt,f),t(vt,Yr),m(e,Fs,f),m(e,gt,f),t(gt,Zr),m(e,Rs,f),m(e,$,f),t($,Gt),t(Gt,Ft),t(Ft,eo),t($,to),t($,Rt),t(Rt,Xt),t(Xt,so),t($,ao),t($,Ht),t(Ht,Bt),t(Bt,ro),t($,oo),t($,Jt),t(Jt,Wt),t(Wt,lo),t($,no),t($,Kt),t(Kt,Yt),t(Yt,io),t($,po),t($,Zt),t(Zt,es),t(es,fo),t($,co),t($,ts),t(ts,ss),t(ss,mo),t($,uo),t($,as),t(as,rs),t(rs,ho),t($,_o),t($,os),t(os,ls),t(ls,vo),m(e,Xs,f),m(e,te,f),t(te,go),t(te,$t),t($t,$o),t(te,Eo),m(e,Hs,f),m(e,O,f),h(Ve,O,null),t(O,xo),t(O,Et),t(Et,wo),t(Et,ns),t(ns,bo),m(e,Bs,f),m(e,j,f),t(j,se),t(se,is),h(Ce,is,null),t(j,Po),t(j,ps),t(ps,yo),m(e,Js,f),m(e,M,f),t(M,Qe),t(Qe,qo),t(M,So),t(M,Oe),t(Oe,fs),t(fs,Io),t(M,Lo),m(e,Ws,f),m(e,je,f),t(je,ko),t(je,Me),t(Me,Ao),m(e,Ks,f),m(e,xt,f),t(xt,Do),m(e,Ys,f),m(e,wt,f),t(wt,cs),t(cs,ms),t(ms,No),m(e,Zs,f),m(e,bt,f),t(bt,To),m(e,ea,f),m(e,ae,f),t(ae,Vo),t(ae,Ue),t(Ue,Co),t(ae,Qo),m(e,ta,f),m(e,U,f),t(U,re),t(re,ds),h(ze,ds,null),t(U,Oo),t(U,us),t(us,jo),m(e,sa,f),m(e,D,f),t(D,Ge),t(Ge,Mo),t(D,Uo),t(D,Fe),t(Fe,zo),t(D,Go),t(D,Re),t(Re,Fo),t(D,Ro),m(e,aa,f),m(e,Pt,f),t(Pt,Xo),m(e,ra,f),m(e,z,f),t(z,oe),t(oe,hs),h(Xe,hs,null),t(z,Ho),t(z,_s),t(_s,Bo),m(e,oa,f),m(e,yt,f),t(yt,Jo),m(e,la,f),m(e,le,f),t(le,vs),t(vs,gs),t(gs,Wo),t(le,Ko),t(le,$s),t($s,Es),t(Es,Yo),m(e,na,f),m(e,He,f),t(He,Zo),t(He,xs),t(xs,el),m(e,ia,f),m(e,P,f),h(Be,P,null),t(P,tl),t(P,ws),t(ws,sl),t(P,al),t(P,ne),h(Je,ne,null),t(ne,rl),t(ne,bs),t(bs,ol),t(P,ll),t(P,I),h(We,I,null),t(I,nl),t(I,Ke),t(Ke,il),t(Ke,Ps),t(Ps,pl),t(Ke,fl),t(I,cl),t(I,ys),t(ys,ml),t(I,dl),h(Ye,I,null),t(P,ul),t(P,ie),h(Ze,ie,null),t(ie,hl),t(ie,qs),t(qs,_l),m(e,pa,f),m(e,pe,f),t(pe,vl),t(pe,Ss),t(Ss,gl),t(pe,$l),m(e,fa,f),m(e,q,f),h(et,q,null),t(q,El),t(q,Is),t(Is,xl),t(q,wl),t(q,Ls),t(Ls,bl),t(q,Pl),h(tt,q,null),m(e,ca,f),m(e,fe,f),t(fe,yl),t(fe,ks),t(ks,ql),t(fe,Sl),m(e,ma,f),m(e,G,f),t(G,ce),t(ce,As),h(st,As,null),t(G,Il),t(G,Ds),t(Ds,Ll),m(e,da,f),m(e,qt,f),t(qt,kl),m(e,ua,f),h(at,e,f),m(e,ha,f),m(e,me,f),t(me,Al),t(me,Ns),t(Ns,Dl),t(me,Nl),m(e,_a,f),h(rt,e,f),m(e,va,f),m(e,de,f),t(de,Tl),t(de,ot),t(ot,Vl),t(de,Cl),ga=!0},p:ki,i(e){ga||(_(_e.$$.fragment,e),_(ve.$$.fragment,e),_(ge.$$.fragment,e),_($e.$$.fragment,e),_(xe.$$.fragment,e),_(we.$$.fragment,e),_(be.$$.fragment,e),_(ye.$$.fragment,e),_(Se.$$.fragment,e),_(Ie.$$.fragment,e),_(Le.$$.fragment,e),_(ke.$$.fragment,e),_(Ae.$$.fragment,e),_(De.$$.fragment,e),_(Ve.$$.fragment,e),_(Ce.$$.fragment,e),_(ze.$$.fragment,e),_(Xe.$$.fragment,e),_(Be.$$.fragment,e),_(Je.$$.fragment,e),_(We.$$.fragment,e),_(Ye.$$.fragment,e),_(Ze.$$.fragment,e),_(et.$$.fragment,e),_(tt.$$.fragment,e),_(st.$$.fragment,e),_(at.$$.fragment,e),_(rt.$$.fragment,e),ga=!0)},o(e){v(_e.$$.fragment,e),v(ve.$$.fragment,e),v(ge.$$.fragment,e),v($e.$$.fragment,e),v(xe.$$.fragment,e),v(we.$$.fragment,e),v(be.$$.fragment,e),v(ye.$$.fragment,e),v(Se.$$.fragment,e),v(Ie.$$.fragment,e),v(Le.$$.fragment,e),v(ke.$$.fragment,e),v(Ae.$$.fragment,e),v(De.$$.fragment,e),v(Ve.$$.fragment,e),v(Ce.$$.fragment,e),v(ze.$$.fragment,e),v(Xe.$$.fragment,e),v(Be.$$.fragment,e),v(Je.$$.fragment,e),v(We.$$.fragment,e),v(Ye.$$.fragment,e),v(Ze.$$.fragment,e),v(et.$$.fragment,e),v(tt.$$.fragment,e),v(st.$$.fragment,e),v(at.$$.fragment,e),v(rt.$$.fragment,e),ga=!1},d(e){s(N),e&&s(it),e&&s(S),g(_e),e&&s(Vs),e&&s(pt),e&&s(Cs),e&&s(C),g(ve),e&&s(Qs),e&&s(y),e&&s(Os),e&&s(E),g(ge),g($e),g(xe),g(we),g(be),g(ye),g(Se),e&&s(js),e&&s(k),g(Ie),g(Le),e&&s(Ms),e&&s(A),g(ke),g(Ae),e&&s(Us),e&&s(Q),g(De),e&&s(zs),e&&s(ee),e&&s(Gs),e&&s(vt),e&&s(Fs),e&&s(gt),e&&s(Rs),e&&s($),e&&s(Xs),e&&s(te),e&&s(Hs),e&&s(O),g(Ve),e&&s(Bs),e&&s(j),g(Ce),e&&s(Js),e&&s(M),e&&s(Ws),e&&s(je),e&&s(Ks),e&&s(xt),e&&s(Ys),e&&s(wt),e&&s(Zs),e&&s(bt),e&&s(ea),e&&s(ae),e&&s(ta),e&&s(U),g(ze),e&&s(sa),e&&s(D),e&&s(aa),e&&s(Pt),e&&s(ra),e&&s(z),g(Xe),e&&s(oa),e&&s(yt),e&&s(la),e&&s(le),e&&s(na),e&&s(He),e&&s(ia),e&&s(P),g(Be),g(Je),g(We),g(Ye),g(Ze),e&&s(pa),e&&s(pe),e&&s(fa),e&&s(q),g(et),g(tt),e&&s(ca),e&&s(fe),e&&s(ma),e&&s(G),g(st),e&&s(da),e&&s(qt),e&&s(ua),g(at,e),e&&s(ha),e&&s(me),e&&s(_a),g(rt,e),e&&s(va),e&&s(de)}}}const Di={local:"processors",sections:[{local:"transformers.DataProcessor",title:"Processors"},{local:"transformers.glue_convert_examples_to_features",title:"GLUE"},{local:"xnli",title:"XNLI"},{local:"squad",sections:[{local:"transformers.data.processors.squad.SquadProcessor",title:"Processors"},{local:"example-usage",title:"Example usage"}],title:"SQuAD"}],title:"Processors"};function Ni(Wa,N,it){let{fw:S}=N;return Wa.$$set=L=>{"fw"in L&&it(0,S=L.fw)},[S]}class ji extends qi{constructor(N){super();Si(this,N,Ni,Ai,Ii,{fw:0})}}export{ji as default,Di as metadata};
