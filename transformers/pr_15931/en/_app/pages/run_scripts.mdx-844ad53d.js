import{S as Fm,i as Rm,s as Hm,e as a,k as m,w as _,t as s,M as Mm,c as o,d as r,m as h,a as i,x as d,h as l,b as p,F as t,g as u,y as v,L as Gm,q as g,o as y,B as w}from"../chunks/vendor-4833417e.js";import{I as R}from"../chunks/IconCopyLink-4b81c553.js";import{C as $}from"../chunks/CodeBlock-6a3d1b46.js";import{C as jm}from"../chunks/CodeBlockFw-27a176a0.js";import"../chunks/CopyButton-dacfbfaf.js";function Bm(pi){let q,ft,z,P,pr,ge,ui,ur,mi,Ua,b,hi,ct,fi,ci,ye,_i,di,we,vi,gi,Ee,yi,wi,Da,I,Ei,$e,$i,bi,be,xi,zi,Oa,_t,ki,Na,L,Ti,xe,Ai,Pi,ze,qi,Ii,ja,S,Li,ke,Si,Ci,Te,Ui,Di,Fa,H,K,mr,Ae,Oi,hr,Ni,Ra,Q,ji,fr,Fi,Ri,Ha,Pe,Ma,dt,Hi,Ga,Z,cr,Mi,Gi,f,_r,vt,Bi,Ji,dr,gt,Yi,Xi,vr,yt,Vi,Wi,gr,wt,Ki,Qi,yr,Et,Zi,es,wr,$t,ts,rs,Er,bt,as,os,$r,xt,is,ss,br,zt,ls,ns,xr,kt,ps,us,zr,Tt,ms,hs,kr,At,fs,cs,Tr,Pt,_s,ds,Ar,qt,vs,gs,Pr,It,ys,ws,qr,Lt,Es,$s,Ir,St,bs,xs,Lr,Ct,zs,ks,Sr,Ut,Ts,As,Cr,Dt,Ps,qs,Ur,Ot,Is,Ls,Dr,Nt,Ss,Cs,Or,jt,Us,Ds,Nr,Ft,Os,Ns,jr,Rt,js,Fs,Fr,Ht,Rs,Hs,Rr,Mt,Ms,Ba,Gt,Gs,Ja,qe,Ya,Bt,Bs,Xa,Ie,Va,M,ee,Hr,Le,Js,Mr,Ys,Wa,E,Xs,Se,Vs,Ws,Ce,Ks,Qs,Ue,Zs,el,De,tl,rl,Gr,al,ol,Ka,Oe,Qa,G,te,Br,Ne,il,Jr,sl,Za,re,ll,je,nl,pl,eo,ae,Fe,ul,Yr,ml,hl,fl,Re,cl,Xr,_l,dl,to,He,ro,oe,vl,Me,Vr,gl,yl,ao,B,ie,Wr,Ge,wl,Kr,El,oo,x,$l,Be,bl,xl,Je,zl,kl,Qr,Tl,Al,Zr,Pl,ql,io,C,Il,Ye,ea,Ll,Sl,ta,Cl,Ul,so,Xe,lo,J,se,ra,Ve,Dl,aa,Ol,no,le,Nl,We,jl,Fl,po,Ke,uo,k,Rl,oa,Hl,Ml,ia,Gl,Bl,sa,Jl,Yl,mo,Qe,ho,Jt,Xl,fo,Ze,co,Yt,Vl,_o,et,vo,Y,ne,la,tt,Wl,na,Kl,go,Xt,Ql,yo,U,pe,pa,Zl,en,ua,tn,rn,an,Vt,ma,on,sn,ln,Wt,ha,nn,pn,wo,Kt,un,Eo,rt,$o,X,ue,fa,at,mn,ca,hn,bo,Qt,fn,xo,D,_a,da,cn,_n,va,ga,dn,vn,ya,wa,gn,zo,ot,ko,O,yn,Ea,wn,En,$a,$n,bn,To,it,Ao,V,me,ba,st,xn,xa,zn,Po,Zt,kn,qo,T,Tn,za,An,Pn,ka,qn,In,Ta,Ln,Sn,Io,lt,Lo,he,Cn,Aa,Un,Dn,So,nt,Co,W,fe,Pa,pt,On,qa,Nn,Uo,ce,jn,ut,Fn,Rn,Do,mt,Oo,N,Hn,Ia,Mn,Gn,La,Bn,Jn,No,_e,Yn,Sa,Xn,Vn,jo,er,Wn,Fo,ht,Ro;return ge=new R({}),Ae=new R({}),Pe=new $({props:{code:`git clone https://github.com/huggingface/transformers
cd transformers
pip install .`,highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/huggingface/transformers
<span class="hljs-built_in">cd</span> transformers
pip install .`}}),qe=new $({props:{code:"git checkout tags/v3.5.1",highlighted:"git checkout tags/v3.5.1"}}),Ie=new $({props:{code:"pip install -r requirements.txt",highlighted:"pip install -r requirements.txt"}}),Le=new R({}),Oe=new jm({props:{group1:{id:"pt",code:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`},group2:{id:"tf",code:`python examples/tensorflow/summarization/run_summarization.py  \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`,highlighted:`python examples/tensorflow/summarization/run_summarization.py  \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`}}}),Ne=new R({}),He=new $({props:{code:`python -m torch.distributed.launch \\
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \\
    --fp16 \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,highlighted:`python -m torch.distributed.launch \\
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \\
    --fp16 \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`}}),Ge=new R({}),Xe=new jm({props:{group1:{id:"pt",code:`python xla_spawn.py --num_cores 8 \\
    summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,highlighted:`python xla_spawn.py --num_cores 8 \\
    summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`},group2:{id:"tf",code:`python run_summarization.py  \\
    --tpu name_of_tpu_resource \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`,highlighted:`python run_summarization.py  \\
    --tpu name_of_tpu_resource \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`}}}),Ve=new R({}),Ke=new $({props:{code:"pip install accelerate",highlighted:"pip install accelerate"}}),Qe=new $({props:{code:"accelerate config",highlighted:"accelerate config"}}),Ze=new $({props:{code:"accelerate test",highlighted:'accelerate <span class="hljs-built_in">test</span>'}}),et=new $({props:{code:`accelerate launch run_summarization_no_trainer.py \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir ~/tmp/tst-summarization`,highlighted:`accelerate launch run_summarization_no_trainer.py \\
    --model_name_or_path t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir ~/tmp/tst-summarization`}}),tt=new R({}),rt=new $({props:{code:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --train_file path_to_csv_or_jsonlines_file \\
    --validation_file path_to_csv_or_jsonlines_file \\
    --text_column text_column_name \\
    --summary_column summary_column_name \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --overwrite_output_dir \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --train_file path_to_csv_or_jsonlines_file \\
    --validation_file path_to_csv_or_jsonlines_file \\
    --text_column text_column_name \\
    --summary_column summary_column_name \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --overwrite_output_dir \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --predict_with_generate`}}),at=new R({}),ot=new $({props:{code:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --max_train_samples 50 \\
    --max_eval_samples 50 \\
    --max_predict_samples 50 \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path t5-small \\
    --max_train_samples 50 \\
    --max_eval_samples 50 \\
    --max_predict_samples 50 \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`}}),it=new $({props:{code:"examples/pytorch/summarization/run_summarization.py -h",highlighted:"examples/pytorch/summarization/run_summarization.py -h"}}),st=new R({}),lt=new $({props:{code:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --output_dir previous_output_dir \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --output_dir previous_output_dir \\
    --predict_with_generate`}}),nt=new $({props:{code:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --resume_from_checkpoint path_to_specific_checkpoint \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --resume_from_checkpoint path_to_specific_checkpoint \\
    --predict_with_generate`}}),pt=new R({}),mt=new $({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),ht=new $({props:{code:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config "3.0.0" \\
    --source_prefix "summarize: " \\
    --push_to_hub \\
    --push_to_hub_model_id sgugger/finetuned-t5-cnn_dailymail \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --push_to_hub \\
    --push_to_hub_model_id sgugger/finetuned-t5-cnn_dailymail \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`}}),{c(){q=a("meta"),ft=m(),z=a("h1"),P=a("a"),pr=a("span"),_(ge.$$.fragment),ui=m(),ur=a("span"),mi=s("Run a training script"),Ua=m(),b=a("p"),hi=s("Along with the \u{1F917} Transformers "),ct=a("a"),fi=s("notebooks"),ci=s(", there are also example scripts demonstrating how to train a model for a task with "),ye=a("a"),_i=s("PyTorch"),di=s(", "),we=a("a"),vi=s("TensorFlow"),gi=s(", or "),Ee=a("a"),yi=s("JAX/Flax"),wi=s("."),Da=m(),I=a("p"),Ei=s("You will also find scripts we\u2019ve used in our "),$e=a("a"),$i=s("research projects"),bi=s(" and "),be=a("a"),xi=s("legacy examples"),zi=s(" which are mostly community contributed. These scripts are not actively maintained and require a specific version of \u{1F917} Transformers that will most likely be incompatible with the most recent version of the library. Most of the scripts fully expose how data is preprocessed to help you adapt your script and edit it as necessary for your use case."),Oa=m(),_t=a("p"),ki=s("The example scripts are not expected to work out-of-the-box on a specific problem, and you may need to adapt the script to the problem you\u2019re trying to solve. To help you with this, most of the scripts fully expose how data is preprocessed, allowing you to edit it as necessary for your use-case."),Na=m(),L=a("p"),Ti=s("For any feature you\u2019d like to implement in an example, please discuss it on the "),xe=a("a"),Ai=s("forum"),Pi=s(" or in an "),ze=a("a"),qi=s("issue"),Ii=s(" before submitting a Pull Request. While we welcome bug fixes, it is unlikely we will merge a Pull Request that adds more functionality at the cost of readability."),ja=m(),S=a("p"),Li=s("This guide will show you how to run an example summarization training script in "),ke=a("a"),Si=s("PyTorch"),Ci=s(" and "),Te=a("a"),Ui=s("TensorFlow"),Di=s(". All examples are expected to work with both frameworks unless otherwise specified."),Fa=m(),H=a("h2"),K=a("a"),mr=a("span"),_(Ae.$$.fragment),Oi=m(),hr=a("span"),Ni=s("Setup"),Ra=m(),Q=a("p"),ji=s("To successfully run the latest versions of the example scripts, you have to "),fr=a("strong"),Fi=s("install \u{1F917} Transformers from source"),Ri=s(" in a new virtual environment:"),Ha=m(),_(Pe.$$.fragment),Ma=m(),dt=a("p"),Hi=s("For older versions of the example scripts, click on the toggle below:"),Ga=m(),Z=a("details"),cr=a("summary"),Mi=s("Examples for older versions of \u{1F917} Transformers"),Gi=m(),f=a("ul"),_r=a("li"),vt=a("a"),Bi=s("v4.5.1"),Ji=m(),dr=a("li"),gt=a("a"),Yi=s("v4.4.2"),Xi=m(),vr=a("li"),yt=a("a"),Vi=s("v4.3.3"),Wi=m(),gr=a("li"),wt=a("a"),Ki=s("v4.2.2"),Qi=m(),yr=a("li"),Et=a("a"),Zi=s("v4.1.1"),es=m(),wr=a("li"),$t=a("a"),ts=s("v4.0.1"),rs=m(),Er=a("li"),bt=a("a"),as=s("v3.5.1"),os=m(),$r=a("li"),xt=a("a"),is=s("v3.4.0"),ss=m(),br=a("li"),zt=a("a"),ls=s("v3.3.1"),ns=m(),xr=a("li"),kt=a("a"),ps=s("v3.2.0"),us=m(),zr=a("li"),Tt=a("a"),ms=s("v3.1.0"),hs=m(),kr=a("li"),At=a("a"),fs=s("v3.0.2"),cs=m(),Tr=a("li"),Pt=a("a"),_s=s("v2.11.0"),ds=m(),Ar=a("li"),qt=a("a"),vs=s("v2.10.0"),gs=m(),Pr=a("li"),It=a("a"),ys=s("v2.9.1"),ws=m(),qr=a("li"),Lt=a("a"),Es=s("v2.8.0"),$s=m(),Ir=a("li"),St=a("a"),bs=s("v2.7.0"),xs=m(),Lr=a("li"),Ct=a("a"),zs=s("v2.6.0"),ks=m(),Sr=a("li"),Ut=a("a"),Ts=s("v2.5.1"),As=m(),Cr=a("li"),Dt=a("a"),Ps=s("v2.4.0"),qs=m(),Ur=a("li"),Ot=a("a"),Is=s("v2.3.0"),Ls=m(),Dr=a("li"),Nt=a("a"),Ss=s("v2.2.0"),Cs=m(),Or=a("li"),jt=a("a"),Us=s("v2.1.1"),Ds=m(),Nr=a("li"),Ft=a("a"),Os=s("v2.0.0"),Ns=m(),jr=a("li"),Rt=a("a"),js=s("v1.2.0"),Fs=m(),Fr=a("li"),Ht=a("a"),Rs=s("v1.1.0"),Hs=m(),Rr=a("li"),Mt=a("a"),Ms=s("v1.0.0"),Ba=m(),Gt=a("p"),Gs=s("Then switch your current clone of \u{1F917} Transformers to a specific version, like v3.5.1 for example:"),Ja=m(),_(qe.$$.fragment),Ya=m(),Bt=a("p"),Bs=s("After you\u2019ve setup the correct version of the library, navigate to the example folder of your choice and install the example specific requirements:"),Xa=m(),_(Ie.$$.fragment),Va=m(),M=a("h2"),ee=a("a"),Hr=a("span"),_(Le.$$.fragment),Js=m(),Mr=a("span"),Ys=s("Run a script"),Wa=m(),E=a("p"),Xs=s("The summarization example script downloads and preprocesses a dataset from the \u{1F917} "),Se=a("a"),Vs=s("Datasets"),Ws=s(" library and then fine-tunes it with the "),Ce=a("a"),Ks=s("Trainer"),Qs=s(" on an architecture that supports summarization. For example, this script setup fine-tunes "),Ue=a("a"),Zs=s("T5-small"),el=s(" on the "),De=a("a"),tl=s("CNN/DailyMail"),rl=s(" dataset. The T5 model requires an additional "),Gr=a("code"),al=s("source_prefix"),ol=s(" argument due to how it was trained. This prompt lets T5 know this is a summarization task."),Ka=m(),_(Oe.$$.fragment),Qa=m(),G=a("h2"),te=a("a"),Br=a("span"),_(Ne.$$.fragment),il=m(),Jr=a("span"),sl=s("Distributed training and mixed precision"),Za=m(),re=a("p"),ll=s("The "),je=a("a"),nl=s("Trainer"),pl=s(" supports distributed training and mixed precision, which means you can also use it in a script. To enable both of these features:"),eo=m(),ae=a("ul"),Fe=a("li"),ul=s("Add the "),Yr=a("code"),ml=s("fp16"),hl=s(" argument to enable mixed precision."),fl=m(),Re=a("li"),cl=s("Set the number of GPUs to use with the "),Xr=a("code"),_l=s("nproc_per_node"),dl=s(" argument."),to=m(),_(He.$$.fragment),ro=m(),oe=a("p"),vl=s("TensorFlow scripts utilize "),Me=a("a"),Vr=a("code"),gl=s("tf.distribute.MirroredStrategy"),yl=s(" for distributed training, and you don\u2019t need to add any additional arguments to the training script. The TensorFlow script will use multiple GPUs by default if they are available."),ao=m(),B=a("h2"),ie=a("a"),Wr=a("span"),_(Ge.$$.fragment),wl=m(),Kr=a("span"),El=s("Run a script on a TPU"),oo=m(),x=a("p"),$l=s("Tensor Processing Units (TPUs) are specifically designed to accelerate performance. PyTorch supports TPUs with the "),Be=a("a"),bl=s("XLA"),xl=s(" deep learning compiler (see "),Je=a("a"),zl=s("here"),kl=s(" for more details). To use a TPU, launch the "),Qr=a("code"),Tl=s("xla_spawn.py"),Al=s(" script and use the "),Zr=a("code"),Pl=s("num_cores"),ql=s(" argument to set the number of TPU cores you want to use."),io=m(),C=a("p"),Il=s("TensorFlow scripts utilize "),Ye=a("a"),ea=a("code"),Ll=s("tf.distribute.TPUStrategy"),Sl=s(" for training on TPUs. You need to pass the name of the TPU resource to the "),ta=a("code"),Cl=s("tpu"),Ul=s(" argument."),so=m(),_(Xe.$$.fragment),lo=m(),J=a("h2"),se=a("a"),ra=a("span"),_(Ve.$$.fragment),Dl=m(),aa=a("span"),Ol=s("Run a script with \u{1F917} Accelerate"),no=m(),le=a("p"),Nl=s("\u{1F917} "),We=a("a"),jl=s("Accelerate"),Fl=s(" offers a unified method for training a model on several types of setups (CPU-only, multiple GPUs, TPUs) while maintaining complete visibility into the PyTorch training loop. Make sure you have \u{1F917} Accelerate installed, if you don\u2019t already have it:"),po=m(),_(Ke.$$.fragment),uo=m(),k=a("p"),Rl=s("Instead of the "),oa=a("code"),Hl=s("run_summarization.py"),Ml=s(" script, you need to use the "),ia=a("code"),Gl=s("run_summarization_no_trainer.py"),Bl=s(" script. \u{1F917} Accelerate supported scripts will have a "),sa=a("code"),Jl=s("task_no_trainer.py"),Yl=s(" file in the folder. Begin by running the following command to create and save a configuration file:"),mo=m(),_(Qe.$$.fragment),ho=m(),Jt=a("p"),Xl=s("Test your setup to make sure it is configured correctly:"),fo=m(),_(Ze.$$.fragment),co=m(),Yt=a("p"),Vl=s("Then you are ready to launch the training:"),_o=m(),_(et.$$.fragment),vo=m(),Y=a("h2"),ne=a("a"),la=a("span"),_(tt.$$.fragment),Wl=m(),na=a("span"),Kl=s("Use a custom dataset"),go=m(),Xt=a("p"),Ql=s("The summarization script supports custom datasets as long as they are a CSV or JSON Line file. In this case, you need to specify several additional arguments:"),yo=m(),U=a("ul"),pe=a("li"),pa=a("code"),Zl=s("train_file"),en=s(" and "),ua=a("code"),tn=s("validation_file"),rn=s(" specify the path to your training and validation files."),an=m(),Vt=a("li"),ma=a("code"),on=s("text_column"),sn=s(" is the input text to summarize."),ln=m(),Wt=a("li"),ha=a("code"),nn=s("summary_column"),pn=s(" is the target text to output."),wo=m(),Kt=a("p"),un=s("A summarization script with a custom dataset would look like this:"),Eo=m(),_(rt.$$.fragment),$o=m(),X=a("h2"),ue=a("a"),fa=a("span"),_(at.$$.fragment),mn=m(),ca=a("span"),hn=s("Test a script"),bo=m(),Qt=a("p"),fn=s("It is often a good idea to run your script on a smaller number of dataset examples to ensure everything works as expected before committing to an entire dataset which may take hours to complete. Use the following arguments to truncate the maximum number of samples to fifty:"),xo=m(),D=a("ul"),_a=a("li"),da=a("code"),cn=s("max_train_samples"),_n=m(),va=a("li"),ga=a("code"),dn=s("max_eval_samples"),vn=m(),ya=a("li"),wa=a("code"),gn=s("max_predict_samples"),zo=m(),_(ot.$$.fragment),ko=m(),O=a("p"),yn=s("Not all example scripts support the "),Ea=a("code"),wn=s("max_predict_samples"),En=s(" argument. Add the "),$a=a("code"),$n=s("-h"),bn=s(" argument to check whether the script supports it:"),To=m(),_(it.$$.fragment),Ao=m(),V=a("h2"),me=a("a"),ba=a("span"),_(st.$$.fragment),xn=m(),xa=a("span"),zn=s("Resume training from checkpoint"),Po=m(),Zt=a("p"),kn=s("Another helpful option to enable is resuming training from a previous checkpoint. This option ensures you can pick up where you left off without starting over if your training gets interrupted. There are two methods to resume training from a checkpoint."),qo=m(),T=a("p"),Tn=s("The first method uses the "),za=a("code"),An=s("output_dir previous_output_dir"),Pn=s(" argument to resume training from the latest checkpoint stored in "),ka=a("code"),qn=s("output_dir"),In=s(". In this case, you should remove "),Ta=a("code"),Ln=s("overwrite_output_dir"),Sn=s(":"),Io=m(),_(lt.$$.fragment),Lo=m(),he=a("p"),Cn=s("The second method uses the "),Aa=a("code"),Un=s("resume_from_checkpoint path_to_specific_checkpoint"),Dn=s(" argument to resume training from a specific checkpoint folder."),So=m(),_(nt.$$.fragment),Co=m(),W=a("h2"),fe=a("a"),Pa=a("span"),_(pt.$$.fragment),On=m(),qa=a("span"),Nn=s("Share your model"),Uo=m(),ce=a("p"),jn=s("All scripts can upload your final model to the "),ut=a("a"),Fn=s("Model Hub"),Rn=s(". Make sure you are logged into Hugging Face before you begin:"),Do=m(),_(mt.$$.fragment),Oo=m(),N=a("p"),Hn=s("Then add the "),Ia=a("code"),Mn=s("push_to_hub"),Gn=s(" argument to the script. This argument will create a repository with your Hugging Face username and the folder name specified in "),La=a("code"),Bn=s("output_dir"),Jn=s("."),No=m(),_e=a("p"),Yn=s("To give your repository a specific name, add the "),Sa=a("code"),Xn=s("push_to_hub_model_id"),Vn=s(" argument. This argument accepts your Hugging Face username - or organization if you\u2019d like to upload to an organization - and the specific repository name."),jo=m(),er=a("p"),Wn=s("The following example shows how to upload a model with a specific repository name:"),Fo=m(),_(ht.$$.fragment),this.h()},l(e){const n=Mm('[data-svelte="svelte-1phssyn"]',document.head);q=o(n,"META",{name:!0,content:!0}),n.forEach(r),ft=h(e),z=o(e,"H1",{class:!0});var Ho=i(z);P=o(Ho,"A",{id:!0,class:!0,href:!0});var Zn=i(P);pr=o(Zn,"SPAN",{});var ep=i(pr);d(ge.$$.fragment,ep),ep.forEach(r),Zn.forEach(r),ui=h(Ho),ur=o(Ho,"SPAN",{});var tp=i(ur);mi=l(tp,"Run a training script"),tp.forEach(r),Ho.forEach(r),Ua=h(e),b=o(e,"P",{});var j=i(b);hi=l(j,"Along with the \u{1F917} Transformers "),ct=o(j,"A",{href:!0});var rp=i(ct);fi=l(rp,"notebooks"),rp.forEach(r),ci=l(j,", there are also example scripts demonstrating how to train a model for a task with "),ye=o(j,"A",{href:!0,rel:!0});var ap=i(ye);_i=l(ap,"PyTorch"),ap.forEach(r),di=l(j,", "),we=o(j,"A",{href:!0,rel:!0});var op=i(we);vi=l(op,"TensorFlow"),op.forEach(r),gi=l(j,", or "),Ee=o(j,"A",{href:!0,rel:!0});var ip=i(Ee);yi=l(ip,"JAX/Flax"),ip.forEach(r),wi=l(j,"."),j.forEach(r),Da=h(e),I=o(e,"P",{});var tr=i(I);Ei=l(tr,"You will also find scripts we\u2019ve used in our "),$e=o(tr,"A",{href:!0,rel:!0});var sp=i($e);$i=l(sp,"research projects"),sp.forEach(r),bi=l(tr," and "),be=o(tr,"A",{href:!0,rel:!0});var lp=i(be);xi=l(lp,"legacy examples"),lp.forEach(r),zi=l(tr," which are mostly community contributed. These scripts are not actively maintained and require a specific version of \u{1F917} Transformers that will most likely be incompatible with the most recent version of the library. Most of the scripts fully expose how data is preprocessed to help you adapt your script and edit it as necessary for your use case."),tr.forEach(r),Oa=h(e),_t=o(e,"P",{});var np=i(_t);ki=l(np,"The example scripts are not expected to work out-of-the-box on a specific problem, and you may need to adapt the script to the problem you\u2019re trying to solve. To help you with this, most of the scripts fully expose how data is preprocessed, allowing you to edit it as necessary for your use-case."),np.forEach(r),Na=h(e),L=o(e,"P",{});var rr=i(L);Ti=l(rr,"For any feature you\u2019d like to implement in an example, please discuss it on the "),xe=o(rr,"A",{href:!0,rel:!0});var pp=i(xe);Ai=l(pp,"forum"),pp.forEach(r),Pi=l(rr," or in an "),ze=o(rr,"A",{href:!0,rel:!0});var up=i(ze);qi=l(up,"issue"),up.forEach(r),Ii=l(rr," before submitting a Pull Request. While we welcome bug fixes, it is unlikely we will merge a Pull Request that adds more functionality at the cost of readability."),rr.forEach(r),ja=h(e),S=o(e,"P",{});var ar=i(S);Li=l(ar,"This guide will show you how to run an example summarization training script in "),ke=o(ar,"A",{href:!0,rel:!0});var mp=i(ke);Si=l(mp,"PyTorch"),mp.forEach(r),Ci=l(ar," and "),Te=o(ar,"A",{href:!0,rel:!0});var hp=i(Te);Ui=l(hp,"TensorFlow"),hp.forEach(r),Di=l(ar,". All examples are expected to work with both frameworks unless otherwise specified."),ar.forEach(r),Fa=h(e),H=o(e,"H2",{class:!0});var Mo=i(H);K=o(Mo,"A",{id:!0,class:!0,href:!0});var fp=i(K);mr=o(fp,"SPAN",{});var cp=i(mr);d(Ae.$$.fragment,cp),cp.forEach(r),fp.forEach(r),Oi=h(Mo),hr=o(Mo,"SPAN",{});var _p=i(hr);Ni=l(_p,"Setup"),_p.forEach(r),Mo.forEach(r),Ra=h(e),Q=o(e,"P",{});var Go=i(Q);ji=l(Go,"To successfully run the latest versions of the example scripts, you have to "),fr=o(Go,"STRONG",{});var dp=i(fr);Fi=l(dp,"install \u{1F917} Transformers from source"),dp.forEach(r),Ri=l(Go," in a new virtual environment:"),Go.forEach(r),Ha=h(e),d(Pe.$$.fragment,e),Ma=h(e),dt=o(e,"P",{});var vp=i(dt);Hi=l(vp,"For older versions of the example scripts, click on the toggle below:"),vp.forEach(r),Ga=h(e),Z=o(e,"DETAILS",{});var Bo=i(Z);cr=o(Bo,"SUMMARY",{});var gp=i(cr);Mi=l(gp,"Examples for older versions of \u{1F917} Transformers"),gp.forEach(r),Gi=h(Bo),f=o(Bo,"UL",{});var c=i(f);_r=o(c,"LI",{});var yp=i(_r);vt=o(yp,"A",{href:!0});var wp=i(vt);Bi=l(wp,"v4.5.1"),wp.forEach(r),yp.forEach(r),Ji=h(c),dr=o(c,"LI",{});var Ep=i(dr);gt=o(Ep,"A",{href:!0});var $p=i(gt);Yi=l($p,"v4.4.2"),$p.forEach(r),Ep.forEach(r),Xi=h(c),vr=o(c,"LI",{});var bp=i(vr);yt=o(bp,"A",{href:!0});var xp=i(yt);Vi=l(xp,"v4.3.3"),xp.forEach(r),bp.forEach(r),Wi=h(c),gr=o(c,"LI",{});var zp=i(gr);wt=o(zp,"A",{href:!0});var kp=i(wt);Ki=l(kp,"v4.2.2"),kp.forEach(r),zp.forEach(r),Qi=h(c),yr=o(c,"LI",{});var Tp=i(yr);Et=o(Tp,"A",{href:!0});var Ap=i(Et);Zi=l(Ap,"v4.1.1"),Ap.forEach(r),Tp.forEach(r),es=h(c),wr=o(c,"LI",{});var Pp=i(wr);$t=o(Pp,"A",{href:!0});var qp=i($t);ts=l(qp,"v4.0.1"),qp.forEach(r),Pp.forEach(r),rs=h(c),Er=o(c,"LI",{});var Ip=i(Er);bt=o(Ip,"A",{href:!0});var Lp=i(bt);as=l(Lp,"v3.5.1"),Lp.forEach(r),Ip.forEach(r),os=h(c),$r=o(c,"LI",{});var Sp=i($r);xt=o(Sp,"A",{href:!0});var Cp=i(xt);is=l(Cp,"v3.4.0"),Cp.forEach(r),Sp.forEach(r),ss=h(c),br=o(c,"LI",{});var Up=i(br);zt=o(Up,"A",{href:!0});var Dp=i(zt);ls=l(Dp,"v3.3.1"),Dp.forEach(r),Up.forEach(r),ns=h(c),xr=o(c,"LI",{});var Op=i(xr);kt=o(Op,"A",{href:!0});var Np=i(kt);ps=l(Np,"v3.2.0"),Np.forEach(r),Op.forEach(r),us=h(c),zr=o(c,"LI",{});var jp=i(zr);Tt=o(jp,"A",{href:!0});var Fp=i(Tt);ms=l(Fp,"v3.1.0"),Fp.forEach(r),jp.forEach(r),hs=h(c),kr=o(c,"LI",{});var Rp=i(kr);At=o(Rp,"A",{href:!0});var Hp=i(At);fs=l(Hp,"v3.0.2"),Hp.forEach(r),Rp.forEach(r),cs=h(c),Tr=o(c,"LI",{});var Mp=i(Tr);Pt=o(Mp,"A",{href:!0});var Gp=i(Pt);_s=l(Gp,"v2.11.0"),Gp.forEach(r),Mp.forEach(r),ds=h(c),Ar=o(c,"LI",{});var Bp=i(Ar);qt=o(Bp,"A",{href:!0});var Jp=i(qt);vs=l(Jp,"v2.10.0"),Jp.forEach(r),Bp.forEach(r),gs=h(c),Pr=o(c,"LI",{});var Yp=i(Pr);It=o(Yp,"A",{href:!0});var Xp=i(It);ys=l(Xp,"v2.9.1"),Xp.forEach(r),Yp.forEach(r),ws=h(c),qr=o(c,"LI",{});var Vp=i(qr);Lt=o(Vp,"A",{href:!0});var Wp=i(Lt);Es=l(Wp,"v2.8.0"),Wp.forEach(r),Vp.forEach(r),$s=h(c),Ir=o(c,"LI",{});var Kp=i(Ir);St=o(Kp,"A",{href:!0});var Qp=i(St);bs=l(Qp,"v2.7.0"),Qp.forEach(r),Kp.forEach(r),xs=h(c),Lr=o(c,"LI",{});var Zp=i(Lr);Ct=o(Zp,"A",{href:!0});var eu=i(Ct);zs=l(eu,"v2.6.0"),eu.forEach(r),Zp.forEach(r),ks=h(c),Sr=o(c,"LI",{});var tu=i(Sr);Ut=o(tu,"A",{href:!0});var ru=i(Ut);Ts=l(ru,"v2.5.1"),ru.forEach(r),tu.forEach(r),As=h(c),Cr=o(c,"LI",{});var au=i(Cr);Dt=o(au,"A",{href:!0});var ou=i(Dt);Ps=l(ou,"v2.4.0"),ou.forEach(r),au.forEach(r),qs=h(c),Ur=o(c,"LI",{});var iu=i(Ur);Ot=o(iu,"A",{href:!0});var su=i(Ot);Is=l(su,"v2.3.0"),su.forEach(r),iu.forEach(r),Ls=h(c),Dr=o(c,"LI",{});var lu=i(Dr);Nt=o(lu,"A",{href:!0});var nu=i(Nt);Ss=l(nu,"v2.2.0"),nu.forEach(r),lu.forEach(r),Cs=h(c),Or=o(c,"LI",{});var pu=i(Or);jt=o(pu,"A",{href:!0});var uu=i(jt);Us=l(uu,"v2.1.1"),uu.forEach(r),pu.forEach(r),Ds=h(c),Nr=o(c,"LI",{});var mu=i(Nr);Ft=o(mu,"A",{href:!0});var hu=i(Ft);Os=l(hu,"v2.0.0"),hu.forEach(r),mu.forEach(r),Ns=h(c),jr=o(c,"LI",{});var fu=i(jr);Rt=o(fu,"A",{href:!0});var cu=i(Rt);js=l(cu,"v1.2.0"),cu.forEach(r),fu.forEach(r),Fs=h(c),Fr=o(c,"LI",{});var _u=i(Fr);Ht=o(_u,"A",{href:!0});var du=i(Ht);Rs=l(du,"v1.1.0"),du.forEach(r),_u.forEach(r),Hs=h(c),Rr=o(c,"LI",{});var vu=i(Rr);Mt=o(vu,"A",{href:!0});var gu=i(Mt);Ms=l(gu,"v1.0.0"),gu.forEach(r),vu.forEach(r),c.forEach(r),Bo.forEach(r),Ba=h(e),Gt=o(e,"P",{});var yu=i(Gt);Gs=l(yu,"Then switch your current clone of \u{1F917} Transformers to a specific version, like v3.5.1 for example:"),yu.forEach(r),Ja=h(e),d(qe.$$.fragment,e),Ya=h(e),Bt=o(e,"P",{});var wu=i(Bt);Bs=l(wu,"After you\u2019ve setup the correct version of the library, navigate to the example folder of your choice and install the example specific requirements:"),wu.forEach(r),Xa=h(e),d(Ie.$$.fragment,e),Va=h(e),M=o(e,"H2",{class:!0});var Jo=i(M);ee=o(Jo,"A",{id:!0,class:!0,href:!0});var Eu=i(ee);Hr=o(Eu,"SPAN",{});var $u=i(Hr);d(Le.$$.fragment,$u),$u.forEach(r),Eu.forEach(r),Js=h(Jo),Mr=o(Jo,"SPAN",{});var bu=i(Mr);Ys=l(bu,"Run a script"),bu.forEach(r),Jo.forEach(r),Wa=h(e),E=o(e,"P",{});var A=i(E);Xs=l(A,"The summarization example script downloads and preprocesses a dataset from the \u{1F917} "),Se=o(A,"A",{href:!0,rel:!0});var xu=i(Se);Vs=l(xu,"Datasets"),xu.forEach(r),Ws=l(A," library and then fine-tunes it with the "),Ce=o(A,"A",{href:!0,rel:!0});var zu=i(Ce);Ks=l(zu,"Trainer"),zu.forEach(r),Qs=l(A," on an architecture that supports summarization. For example, this script setup fine-tunes "),Ue=o(A,"A",{href:!0,rel:!0});var ku=i(Ue);Zs=l(ku,"T5-small"),ku.forEach(r),el=l(A," on the "),De=o(A,"A",{href:!0,rel:!0});var Tu=i(De);tl=l(Tu,"CNN/DailyMail"),Tu.forEach(r),rl=l(A," dataset. The T5 model requires an additional "),Gr=o(A,"CODE",{});var Au=i(Gr);al=l(Au,"source_prefix"),Au.forEach(r),ol=l(A," argument due to how it was trained. This prompt lets T5 know this is a summarization task."),A.forEach(r),Ka=h(e),d(Oe.$$.fragment,e),Qa=h(e),G=o(e,"H2",{class:!0});var Yo=i(G);te=o(Yo,"A",{id:!0,class:!0,href:!0});var Pu=i(te);Br=o(Pu,"SPAN",{});var qu=i(Br);d(Ne.$$.fragment,qu),qu.forEach(r),Pu.forEach(r),il=h(Yo),Jr=o(Yo,"SPAN",{});var Iu=i(Jr);sl=l(Iu,"Distributed training and mixed precision"),Iu.forEach(r),Yo.forEach(r),Za=h(e),re=o(e,"P",{});var Xo=i(re);ll=l(Xo,"The "),je=o(Xo,"A",{href:!0,rel:!0});var Lu=i(je);nl=l(Lu,"Trainer"),Lu.forEach(r),pl=l(Xo," supports distributed training and mixed precision, which means you can also use it in a script. To enable both of these features:"),Xo.forEach(r),eo=h(e),ae=o(e,"UL",{});var Vo=i(ae);Fe=o(Vo,"LI",{});var Wo=i(Fe);ul=l(Wo,"Add the "),Yr=o(Wo,"CODE",{});var Su=i(Yr);ml=l(Su,"fp16"),Su.forEach(r),hl=l(Wo," argument to enable mixed precision."),Wo.forEach(r),fl=h(Vo),Re=o(Vo,"LI",{});var Ko=i(Re);cl=l(Ko,"Set the number of GPUs to use with the "),Xr=o(Ko,"CODE",{});var Cu=i(Xr);_l=l(Cu,"nproc_per_node"),Cu.forEach(r),dl=l(Ko," argument."),Ko.forEach(r),Vo.forEach(r),to=h(e),d(He.$$.fragment,e),ro=h(e),oe=o(e,"P",{});var Qo=i(oe);vl=l(Qo,"TensorFlow scripts utilize "),Me=o(Qo,"A",{href:!0,rel:!0});var Uu=i(Me);Vr=o(Uu,"CODE",{});var Du=i(Vr);gl=l(Du,"tf.distribute.MirroredStrategy"),Du.forEach(r),Uu.forEach(r),yl=l(Qo," for distributed training, and you don\u2019t need to add any additional arguments to the training script. The TensorFlow script will use multiple GPUs by default if they are available."),Qo.forEach(r),ao=h(e),B=o(e,"H2",{class:!0});var Zo=i(B);ie=o(Zo,"A",{id:!0,class:!0,href:!0});var Ou=i(ie);Wr=o(Ou,"SPAN",{});var Nu=i(Wr);d(Ge.$$.fragment,Nu),Nu.forEach(r),Ou.forEach(r),wl=h(Zo),Kr=o(Zo,"SPAN",{});var ju=i(Kr);El=l(ju,"Run a script on a TPU"),ju.forEach(r),Zo.forEach(r),oo=h(e),x=o(e,"P",{});var F=i(x);$l=l(F,"Tensor Processing Units (TPUs) are specifically designed to accelerate performance. PyTorch supports TPUs with the "),Be=o(F,"A",{href:!0,rel:!0});var Fu=i(Be);bl=l(Fu,"XLA"),Fu.forEach(r),xl=l(F," deep learning compiler (see "),Je=o(F,"A",{href:!0,rel:!0});var Ru=i(Je);zl=l(Ru,"here"),Ru.forEach(r),kl=l(F," for more details). To use a TPU, launch the "),Qr=o(F,"CODE",{});var Hu=i(Qr);Tl=l(Hu,"xla_spawn.py"),Hu.forEach(r),Al=l(F," script and use the "),Zr=o(F,"CODE",{});var Mu=i(Zr);Pl=l(Mu,"num_cores"),Mu.forEach(r),ql=l(F," argument to set the number of TPU cores you want to use."),F.forEach(r),io=h(e),C=o(e,"P",{});var or=i(C);Il=l(or,"TensorFlow scripts utilize "),Ye=o(or,"A",{href:!0,rel:!0});var Gu=i(Ye);ea=o(Gu,"CODE",{});var Bu=i(ea);Ll=l(Bu,"tf.distribute.TPUStrategy"),Bu.forEach(r),Gu.forEach(r),Sl=l(or," for training on TPUs. You need to pass the name of the TPU resource to the "),ta=o(or,"CODE",{});var Ju=i(ta);Cl=l(Ju,"tpu"),Ju.forEach(r),Ul=l(or," argument."),or.forEach(r),so=h(e),d(Xe.$$.fragment,e),lo=h(e),J=o(e,"H2",{class:!0});var ei=i(J);se=o(ei,"A",{id:!0,class:!0,href:!0});var Yu=i(se);ra=o(Yu,"SPAN",{});var Xu=i(ra);d(Ve.$$.fragment,Xu),Xu.forEach(r),Yu.forEach(r),Dl=h(ei),aa=o(ei,"SPAN",{});var Vu=i(aa);Ol=l(Vu,"Run a script with \u{1F917} Accelerate"),Vu.forEach(r),ei.forEach(r),no=h(e),le=o(e,"P",{});var ti=i(le);Nl=l(ti,"\u{1F917} "),We=o(ti,"A",{href:!0,rel:!0});var Wu=i(We);jl=l(Wu,"Accelerate"),Wu.forEach(r),Fl=l(ti," offers a unified method for training a model on several types of setups (CPU-only, multiple GPUs, TPUs) while maintaining complete visibility into the PyTorch training loop. Make sure you have \u{1F917} Accelerate installed, if you don\u2019t already have it:"),ti.forEach(r),po=h(e),d(Ke.$$.fragment,e),uo=h(e),k=o(e,"P",{});var de=i(k);Rl=l(de,"Instead of the "),oa=o(de,"CODE",{});var Ku=i(oa);Hl=l(Ku,"run_summarization.py"),Ku.forEach(r),Ml=l(de," script, you need to use the "),ia=o(de,"CODE",{});var Qu=i(ia);Gl=l(Qu,"run_summarization_no_trainer.py"),Qu.forEach(r),Bl=l(de," script. \u{1F917} Accelerate supported scripts will have a "),sa=o(de,"CODE",{});var Zu=i(sa);Jl=l(Zu,"task_no_trainer.py"),Zu.forEach(r),Yl=l(de," file in the folder. Begin by running the following command to create and save a configuration file:"),de.forEach(r),mo=h(e),d(Qe.$$.fragment,e),ho=h(e),Jt=o(e,"P",{});var em=i(Jt);Xl=l(em,"Test your setup to make sure it is configured correctly:"),em.forEach(r),fo=h(e),d(Ze.$$.fragment,e),co=h(e),Yt=o(e,"P",{});var tm=i(Yt);Vl=l(tm,"Then you are ready to launch the training:"),tm.forEach(r),_o=h(e),d(et.$$.fragment,e),vo=h(e),Y=o(e,"H2",{class:!0});var ri=i(Y);ne=o(ri,"A",{id:!0,class:!0,href:!0});var rm=i(ne);la=o(rm,"SPAN",{});var am=i(la);d(tt.$$.fragment,am),am.forEach(r),rm.forEach(r),Wl=h(ri),na=o(ri,"SPAN",{});var om=i(na);Kl=l(om,"Use a custom dataset"),om.forEach(r),ri.forEach(r),go=h(e),Xt=o(e,"P",{});var im=i(Xt);Ql=l(im,"The summarization script supports custom datasets as long as they are a CSV or JSON Line file. In this case, you need to specify several additional arguments:"),im.forEach(r),yo=h(e),U=o(e,"UL",{});var ir=i(U);pe=o(ir,"LI",{});var Ca=i(pe);pa=o(Ca,"CODE",{});var sm=i(pa);Zl=l(sm,"train_file"),sm.forEach(r),en=l(Ca," and "),ua=o(Ca,"CODE",{});var lm=i(ua);tn=l(lm,"validation_file"),lm.forEach(r),rn=l(Ca," specify the path to your training and validation files."),Ca.forEach(r),an=h(ir),Vt=o(ir,"LI",{});var Kn=i(Vt);ma=o(Kn,"CODE",{});var nm=i(ma);on=l(nm,"text_column"),nm.forEach(r),sn=l(Kn," is the input text to summarize."),Kn.forEach(r),ln=h(ir),Wt=o(ir,"LI",{});var Qn=i(Wt);ha=o(Qn,"CODE",{});var pm=i(ha);nn=l(pm,"summary_column"),pm.forEach(r),pn=l(Qn," is the target text to output."),Qn.forEach(r),ir.forEach(r),wo=h(e),Kt=o(e,"P",{});var um=i(Kt);un=l(um,"A summarization script with a custom dataset would look like this:"),um.forEach(r),Eo=h(e),d(rt.$$.fragment,e),$o=h(e),X=o(e,"H2",{class:!0});var ai=i(X);ue=o(ai,"A",{id:!0,class:!0,href:!0});var mm=i(ue);fa=o(mm,"SPAN",{});var hm=i(fa);d(at.$$.fragment,hm),hm.forEach(r),mm.forEach(r),mn=h(ai),ca=o(ai,"SPAN",{});var fm=i(ca);hn=l(fm,"Test a script"),fm.forEach(r),ai.forEach(r),bo=h(e),Qt=o(e,"P",{});var cm=i(Qt);fn=l(cm,"It is often a good idea to run your script on a smaller number of dataset examples to ensure everything works as expected before committing to an entire dataset which may take hours to complete. Use the following arguments to truncate the maximum number of samples to fifty:"),cm.forEach(r),xo=h(e),D=o(e,"UL",{});var sr=i(D);_a=o(sr,"LI",{});var _m=i(_a);da=o(_m,"CODE",{});var dm=i(da);cn=l(dm,"max_train_samples"),dm.forEach(r),_m.forEach(r),_n=h(sr),va=o(sr,"LI",{});var vm=i(va);ga=o(vm,"CODE",{});var gm=i(ga);dn=l(gm,"max_eval_samples"),gm.forEach(r),vm.forEach(r),vn=h(sr),ya=o(sr,"LI",{});var ym=i(ya);wa=o(ym,"CODE",{});var wm=i(wa);gn=l(wm,"max_predict_samples"),wm.forEach(r),ym.forEach(r),sr.forEach(r),zo=h(e),d(ot.$$.fragment,e),ko=h(e),O=o(e,"P",{});var lr=i(O);yn=l(lr,"Not all example scripts support the "),Ea=o(lr,"CODE",{});var Em=i(Ea);wn=l(Em,"max_predict_samples"),Em.forEach(r),En=l(lr," argument. Add the "),$a=o(lr,"CODE",{});var $m=i($a);$n=l($m,"-h"),$m.forEach(r),bn=l(lr," argument to check whether the script supports it:"),lr.forEach(r),To=h(e),d(it.$$.fragment,e),Ao=h(e),V=o(e,"H2",{class:!0});var oi=i(V);me=o(oi,"A",{id:!0,class:!0,href:!0});var bm=i(me);ba=o(bm,"SPAN",{});var xm=i(ba);d(st.$$.fragment,xm),xm.forEach(r),bm.forEach(r),xn=h(oi),xa=o(oi,"SPAN",{});var zm=i(xa);zn=l(zm,"Resume training from checkpoint"),zm.forEach(r),oi.forEach(r),Po=h(e),Zt=o(e,"P",{});var km=i(Zt);kn=l(km,"Another helpful option to enable is resuming training from a previous checkpoint. This option ensures you can pick up where you left off without starting over if your training gets interrupted. There are two methods to resume training from a checkpoint."),km.forEach(r),qo=h(e),T=o(e,"P",{});var ve=i(T);Tn=l(ve,"The first method uses the "),za=o(ve,"CODE",{});var Tm=i(za);An=l(Tm,"output_dir previous_output_dir"),Tm.forEach(r),Pn=l(ve," argument to resume training from the latest checkpoint stored in "),ka=o(ve,"CODE",{});var Am=i(ka);qn=l(Am,"output_dir"),Am.forEach(r),In=l(ve,". In this case, you should remove "),Ta=o(ve,"CODE",{});var Pm=i(Ta);Ln=l(Pm,"overwrite_output_dir"),Pm.forEach(r),Sn=l(ve,":"),ve.forEach(r),Io=h(e),d(lt.$$.fragment,e),Lo=h(e),he=o(e,"P",{});var ii=i(he);Cn=l(ii,"The second method uses the "),Aa=o(ii,"CODE",{});var qm=i(Aa);Un=l(qm,"resume_from_checkpoint path_to_specific_checkpoint"),qm.forEach(r),Dn=l(ii," argument to resume training from a specific checkpoint folder."),ii.forEach(r),So=h(e),d(nt.$$.fragment,e),Co=h(e),W=o(e,"H2",{class:!0});var si=i(W);fe=o(si,"A",{id:!0,class:!0,href:!0});var Im=i(fe);Pa=o(Im,"SPAN",{});var Lm=i(Pa);d(pt.$$.fragment,Lm),Lm.forEach(r),Im.forEach(r),On=h(si),qa=o(si,"SPAN",{});var Sm=i(qa);Nn=l(Sm,"Share your model"),Sm.forEach(r),si.forEach(r),Uo=h(e),ce=o(e,"P",{});var li=i(ce);jn=l(li,"All scripts can upload your final model to the "),ut=o(li,"A",{href:!0,rel:!0});var Cm=i(ut);Fn=l(Cm,"Model Hub"),Cm.forEach(r),Rn=l(li,". Make sure you are logged into Hugging Face before you begin:"),li.forEach(r),Do=h(e),d(mt.$$.fragment,e),Oo=h(e),N=o(e,"P",{});var nr=i(N);Hn=l(nr,"Then add the "),Ia=o(nr,"CODE",{});var Um=i(Ia);Mn=l(Um,"push_to_hub"),Um.forEach(r),Gn=l(nr," argument to the script. This argument will create a repository with your Hugging Face username and the folder name specified in "),La=o(nr,"CODE",{});var Dm=i(La);Bn=l(Dm,"output_dir"),Dm.forEach(r),Jn=l(nr,"."),nr.forEach(r),No=h(e),_e=o(e,"P",{});var ni=i(_e);Yn=l(ni,"To give your repository a specific name, add the "),Sa=o(ni,"CODE",{});var Om=i(Sa);Xn=l(Om,"push_to_hub_model_id"),Om.forEach(r),Vn=l(ni," argument. This argument accepts your Hugging Face username - or organization if you\u2019d like to upload to an organization - and the specific repository name."),ni.forEach(r),jo=h(e),er=o(e,"P",{});var Nm=i(er);Wn=l(Nm,"The following example shows how to upload a model with a specific repository name:"),Nm.forEach(r),Fo=h(e),d(ht.$$.fragment,e),this.h()},h(){p(q,"name","hf:doc:metadata"),p(q,"content",JSON.stringify(Jm)),p(P,"id","run-a-training-script"),p(P,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(P,"href","#run-a-training-script"),p(z,"class","relative group"),p(ct,"href","./noteboks/README"),p(ye,"href","https://github.com/huggingface/transformers/tree/master/examples/pytorch"),p(ye,"rel","nofollow"),p(we,"href","https://github.com/huggingface/transformers/tree/master/examples/tensorflow"),p(we,"rel","nofollow"),p(Ee,"href","https://github.com/huggingface/transformers/tree/master/examples/flax"),p(Ee,"rel","nofollow"),p($e,"href","https://github.com/huggingface/transformers/tree/master/examples/research_projects"),p($e,"rel","nofollow"),p(be,"href","https://github.com/huggingface/transformers/tree/master/examples/legacy"),p(be,"rel","nofollow"),p(xe,"href","https://discuss.huggingface.co/"),p(xe,"rel","nofollow"),p(ze,"href","https://github.com/huggingface/transformers/issues"),p(ze,"rel","nofollow"),p(ke,"href","https://github.com/huggingface/transformers/tree/master/examples/pytorch/summarization"),p(ke,"rel","nofollow"),p(Te,"href","https://github.com/huggingface/transformers/tree/master/examples/tensorflow/summarization"),p(Te,"rel","nofollow"),p(K,"id","setup"),p(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(K,"href","#setup"),p(H,"class","relative group"),p(vt,"href","https://github.com/huggingface/transformers/tree/v4.5.1/examples"),p(gt,"href","https://github.com/huggingface/transformers/tree/v4.4.2/examples"),p(yt,"href","https://github.com/huggingface/transformers/tree/v4.3.3/examples"),p(wt,"href","https://github.com/huggingface/transformers/tree/v4.2.2/examples"),p(Et,"href","https://github.com/huggingface/transformers/tree/v4.1.1/examples"),p($t,"href","https://github.com/huggingface/transformers/tree/v4.0.1/examples"),p(bt,"href","https://github.com/huggingface/transformers/tree/v3.5.1/examples"),p(xt,"href","https://github.com/huggingface/transformers/tree/v3.4.0/examples"),p(zt,"href","https://github.com/huggingface/transformers/tree/v3.3.1/examples"),p(kt,"href","https://github.com/huggingface/transformers/tree/v3.2.0/examples"),p(Tt,"href","https://github.com/huggingface/transformers/tree/v3.1.0/examples"),p(At,"href","https://github.com/huggingface/transformers/tree/v3.0.2/examples"),p(Pt,"href","https://github.com/huggingface/transformers/tree/v2.11.0/examples"),p(qt,"href","https://github.com/huggingface/transformers/tree/v2.10.0/examples"),p(It,"href","https://github.com/huggingface/transformers/tree/v2.9.1/examples"),p(Lt,"href","https://github.com/huggingface/transformers/tree/v2.8.0/examples"),p(St,"href","https://github.com/huggingface/transformers/tree/v2.7.0/examples"),p(Ct,"href","https://github.com/huggingface/transformers/tree/v2.6.0/examples"),p(Ut,"href","https://github.com/huggingface/transformers/tree/v2.5.1/examples"),p(Dt,"href","https://github.com/huggingface/transformers/tree/v2.4.0/examples"),p(Ot,"href","https://github.com/huggingface/transformers/tree/v2.3.0/examples"),p(Nt,"href","https://github.com/huggingface/transformers/tree/v2.2.0/examples"),p(jt,"href","https://github.com/huggingface/transformers/tree/v2.1.0/examples"),p(Ft,"href","https://github.com/huggingface/transformers/tree/v2.0.0/examples"),p(Rt,"href","https://github.com/huggingface/transformers/tree/v1.2.0/examples"),p(Ht,"href","https://github.com/huggingface/transformers/tree/v1.1.0/examples"),p(Mt,"href","https://github.com/huggingface/transformers/tree/v1.0.0/examples"),p(ee,"id","run-a-script"),p(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ee,"href","#run-a-script"),p(M,"class","relative group"),p(Se,"href","https://huggingface.co/docs/datasets/"),p(Se,"rel","nofollow"),p(Ce,"href","https://huggingface.co/docs/transformers/main_classes/trainer"),p(Ce,"rel","nofollow"),p(Ue,"href","https://huggingface.co/t5-small"),p(Ue,"rel","nofollow"),p(De,"href","https://huggingface.co/datasets/cnn_dailymail"),p(De,"rel","nofollow"),p(te,"id","distributed-training-and-mixed-precision"),p(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(te,"href","#distributed-training-and-mixed-precision"),p(G,"class","relative group"),p(je,"href","https://huggingface.co/docs/transformers/main_classes/trainer"),p(je,"rel","nofollow"),p(Me,"href","https://www.tensorflow.org/guide/distributed_training#mirroredstrategy"),p(Me,"rel","nofollow"),p(ie,"id","run-a-script-on-a-tpu"),p(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ie,"href","#run-a-script-on-a-tpu"),p(B,"class","relative group"),p(Be,"href","https://www.tensorflow.org/xla"),p(Be,"rel","nofollow"),p(Je,"href","https://github.com/pytorch/xla/blob/master/README.md"),p(Je,"rel","nofollow"),p(Ye,"href","https://www.tensorflow.org/guide/distributed_training#tpustrategy"),p(Ye,"rel","nofollow"),p(se,"id","run-a-script-with-accelerate"),p(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(se,"href","#run-a-script-with-accelerate"),p(J,"class","relative group"),p(We,"href","https://huggingface.co/docs/accelerate/index.html"),p(We,"rel","nofollow"),p(ne,"id","use-a-custom-dataset"),p(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ne,"href","#use-a-custom-dataset"),p(Y,"class","relative group"),p(ue,"id","test-a-script"),p(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ue,"href","#test-a-script"),p(X,"class","relative group"),p(me,"id","resume-training-from-checkpoint"),p(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(me,"href","#resume-training-from-checkpoint"),p(V,"class","relative group"),p(fe,"id","share-your-model"),p(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(fe,"href","#share-your-model"),p(W,"class","relative group"),p(ut,"href","https://huggingface.co/models"),p(ut,"rel","nofollow")},m(e,n){t(document.head,q),u(e,ft,n),u(e,z,n),t(z,P),t(P,pr),v(ge,pr,null),t(z,ui),t(z,ur),t(ur,mi),u(e,Ua,n),u(e,b,n),t(b,hi),t(b,ct),t(ct,fi),t(b,ci),t(b,ye),t(ye,_i),t(b,di),t(b,we),t(we,vi),t(b,gi),t(b,Ee),t(Ee,yi),t(b,wi),u(e,Da,n),u(e,I,n),t(I,Ei),t(I,$e),t($e,$i),t(I,bi),t(I,be),t(be,xi),t(I,zi),u(e,Oa,n),u(e,_t,n),t(_t,ki),u(e,Na,n),u(e,L,n),t(L,Ti),t(L,xe),t(xe,Ai),t(L,Pi),t(L,ze),t(ze,qi),t(L,Ii),u(e,ja,n),u(e,S,n),t(S,Li),t(S,ke),t(ke,Si),t(S,Ci),t(S,Te),t(Te,Ui),t(S,Di),u(e,Fa,n),u(e,H,n),t(H,K),t(K,mr),v(Ae,mr,null),t(H,Oi),t(H,hr),t(hr,Ni),u(e,Ra,n),u(e,Q,n),t(Q,ji),t(Q,fr),t(fr,Fi),t(Q,Ri),u(e,Ha,n),v(Pe,e,n),u(e,Ma,n),u(e,dt,n),t(dt,Hi),u(e,Ga,n),u(e,Z,n),t(Z,cr),t(cr,Mi),t(Z,Gi),t(Z,f),t(f,_r),t(_r,vt),t(vt,Bi),t(f,Ji),t(f,dr),t(dr,gt),t(gt,Yi),t(f,Xi),t(f,vr),t(vr,yt),t(yt,Vi),t(f,Wi),t(f,gr),t(gr,wt),t(wt,Ki),t(f,Qi),t(f,yr),t(yr,Et),t(Et,Zi),t(f,es),t(f,wr),t(wr,$t),t($t,ts),t(f,rs),t(f,Er),t(Er,bt),t(bt,as),t(f,os),t(f,$r),t($r,xt),t(xt,is),t(f,ss),t(f,br),t(br,zt),t(zt,ls),t(f,ns),t(f,xr),t(xr,kt),t(kt,ps),t(f,us),t(f,zr),t(zr,Tt),t(Tt,ms),t(f,hs),t(f,kr),t(kr,At),t(At,fs),t(f,cs),t(f,Tr),t(Tr,Pt),t(Pt,_s),t(f,ds),t(f,Ar),t(Ar,qt),t(qt,vs),t(f,gs),t(f,Pr),t(Pr,It),t(It,ys),t(f,ws),t(f,qr),t(qr,Lt),t(Lt,Es),t(f,$s),t(f,Ir),t(Ir,St),t(St,bs),t(f,xs),t(f,Lr),t(Lr,Ct),t(Ct,zs),t(f,ks),t(f,Sr),t(Sr,Ut),t(Ut,Ts),t(f,As),t(f,Cr),t(Cr,Dt),t(Dt,Ps),t(f,qs),t(f,Ur),t(Ur,Ot),t(Ot,Is),t(f,Ls),t(f,Dr),t(Dr,Nt),t(Nt,Ss),t(f,Cs),t(f,Or),t(Or,jt),t(jt,Us),t(f,Ds),t(f,Nr),t(Nr,Ft),t(Ft,Os),t(f,Ns),t(f,jr),t(jr,Rt),t(Rt,js),t(f,Fs),t(f,Fr),t(Fr,Ht),t(Ht,Rs),t(f,Hs),t(f,Rr),t(Rr,Mt),t(Mt,Ms),u(e,Ba,n),u(e,Gt,n),t(Gt,Gs),u(e,Ja,n),v(qe,e,n),u(e,Ya,n),u(e,Bt,n),t(Bt,Bs),u(e,Xa,n),v(Ie,e,n),u(e,Va,n),u(e,M,n),t(M,ee),t(ee,Hr),v(Le,Hr,null),t(M,Js),t(M,Mr),t(Mr,Ys),u(e,Wa,n),u(e,E,n),t(E,Xs),t(E,Se),t(Se,Vs),t(E,Ws),t(E,Ce),t(Ce,Ks),t(E,Qs),t(E,Ue),t(Ue,Zs),t(E,el),t(E,De),t(De,tl),t(E,rl),t(E,Gr),t(Gr,al),t(E,ol),u(e,Ka,n),v(Oe,e,n),u(e,Qa,n),u(e,G,n),t(G,te),t(te,Br),v(Ne,Br,null),t(G,il),t(G,Jr),t(Jr,sl),u(e,Za,n),u(e,re,n),t(re,ll),t(re,je),t(je,nl),t(re,pl),u(e,eo,n),u(e,ae,n),t(ae,Fe),t(Fe,ul),t(Fe,Yr),t(Yr,ml),t(Fe,hl),t(ae,fl),t(ae,Re),t(Re,cl),t(Re,Xr),t(Xr,_l),t(Re,dl),u(e,to,n),v(He,e,n),u(e,ro,n),u(e,oe,n),t(oe,vl),t(oe,Me),t(Me,Vr),t(Vr,gl),t(oe,yl),u(e,ao,n),u(e,B,n),t(B,ie),t(ie,Wr),v(Ge,Wr,null),t(B,wl),t(B,Kr),t(Kr,El),u(e,oo,n),u(e,x,n),t(x,$l),t(x,Be),t(Be,bl),t(x,xl),t(x,Je),t(Je,zl),t(x,kl),t(x,Qr),t(Qr,Tl),t(x,Al),t(x,Zr),t(Zr,Pl),t(x,ql),u(e,io,n),u(e,C,n),t(C,Il),t(C,Ye),t(Ye,ea),t(ea,Ll),t(C,Sl),t(C,ta),t(ta,Cl),t(C,Ul),u(e,so,n),v(Xe,e,n),u(e,lo,n),u(e,J,n),t(J,se),t(se,ra),v(Ve,ra,null),t(J,Dl),t(J,aa),t(aa,Ol),u(e,no,n),u(e,le,n),t(le,Nl),t(le,We),t(We,jl),t(le,Fl),u(e,po,n),v(Ke,e,n),u(e,uo,n),u(e,k,n),t(k,Rl),t(k,oa),t(oa,Hl),t(k,Ml),t(k,ia),t(ia,Gl),t(k,Bl),t(k,sa),t(sa,Jl),t(k,Yl),u(e,mo,n),v(Qe,e,n),u(e,ho,n),u(e,Jt,n),t(Jt,Xl),u(e,fo,n),v(Ze,e,n),u(e,co,n),u(e,Yt,n),t(Yt,Vl),u(e,_o,n),v(et,e,n),u(e,vo,n),u(e,Y,n),t(Y,ne),t(ne,la),v(tt,la,null),t(Y,Wl),t(Y,na),t(na,Kl),u(e,go,n),u(e,Xt,n),t(Xt,Ql),u(e,yo,n),u(e,U,n),t(U,pe),t(pe,pa),t(pa,Zl),t(pe,en),t(pe,ua),t(ua,tn),t(pe,rn),t(U,an),t(U,Vt),t(Vt,ma),t(ma,on),t(Vt,sn),t(U,ln),t(U,Wt),t(Wt,ha),t(ha,nn),t(Wt,pn),u(e,wo,n),u(e,Kt,n),t(Kt,un),u(e,Eo,n),v(rt,e,n),u(e,$o,n),u(e,X,n),t(X,ue),t(ue,fa),v(at,fa,null),t(X,mn),t(X,ca),t(ca,hn),u(e,bo,n),u(e,Qt,n),t(Qt,fn),u(e,xo,n),u(e,D,n),t(D,_a),t(_a,da),t(da,cn),t(D,_n),t(D,va),t(va,ga),t(ga,dn),t(D,vn),t(D,ya),t(ya,wa),t(wa,gn),u(e,zo,n),v(ot,e,n),u(e,ko,n),u(e,O,n),t(O,yn),t(O,Ea),t(Ea,wn),t(O,En),t(O,$a),t($a,$n),t(O,bn),u(e,To,n),v(it,e,n),u(e,Ao,n),u(e,V,n),t(V,me),t(me,ba),v(st,ba,null),t(V,xn),t(V,xa),t(xa,zn),u(e,Po,n),u(e,Zt,n),t(Zt,kn),u(e,qo,n),u(e,T,n),t(T,Tn),t(T,za),t(za,An),t(T,Pn),t(T,ka),t(ka,qn),t(T,In),t(T,Ta),t(Ta,Ln),t(T,Sn),u(e,Io,n),v(lt,e,n),u(e,Lo,n),u(e,he,n),t(he,Cn),t(he,Aa),t(Aa,Un),t(he,Dn),u(e,So,n),v(nt,e,n),u(e,Co,n),u(e,W,n),t(W,fe),t(fe,Pa),v(pt,Pa,null),t(W,On),t(W,qa),t(qa,Nn),u(e,Uo,n),u(e,ce,n),t(ce,jn),t(ce,ut),t(ut,Fn),t(ce,Rn),u(e,Do,n),v(mt,e,n),u(e,Oo,n),u(e,N,n),t(N,Hn),t(N,Ia),t(Ia,Mn),t(N,Gn),t(N,La),t(La,Bn),t(N,Jn),u(e,No,n),u(e,_e,n),t(_e,Yn),t(_e,Sa),t(Sa,Xn),t(_e,Vn),u(e,jo,n),u(e,er,n),t(er,Wn),u(e,Fo,n),v(ht,e,n),Ro=!0},p:Gm,i(e){Ro||(g(ge.$$.fragment,e),g(Ae.$$.fragment,e),g(Pe.$$.fragment,e),g(qe.$$.fragment,e),g(Ie.$$.fragment,e),g(Le.$$.fragment,e),g(Oe.$$.fragment,e),g(Ne.$$.fragment,e),g(He.$$.fragment,e),g(Ge.$$.fragment,e),g(Xe.$$.fragment,e),g(Ve.$$.fragment,e),g(Ke.$$.fragment,e),g(Qe.$$.fragment,e),g(Ze.$$.fragment,e),g(et.$$.fragment,e),g(tt.$$.fragment,e),g(rt.$$.fragment,e),g(at.$$.fragment,e),g(ot.$$.fragment,e),g(it.$$.fragment,e),g(st.$$.fragment,e),g(lt.$$.fragment,e),g(nt.$$.fragment,e),g(pt.$$.fragment,e),g(mt.$$.fragment,e),g(ht.$$.fragment,e),Ro=!0)},o(e){y(ge.$$.fragment,e),y(Ae.$$.fragment,e),y(Pe.$$.fragment,e),y(qe.$$.fragment,e),y(Ie.$$.fragment,e),y(Le.$$.fragment,e),y(Oe.$$.fragment,e),y(Ne.$$.fragment,e),y(He.$$.fragment,e),y(Ge.$$.fragment,e),y(Xe.$$.fragment,e),y(Ve.$$.fragment,e),y(Ke.$$.fragment,e),y(Qe.$$.fragment,e),y(Ze.$$.fragment,e),y(et.$$.fragment,e),y(tt.$$.fragment,e),y(rt.$$.fragment,e),y(at.$$.fragment,e),y(ot.$$.fragment,e),y(it.$$.fragment,e),y(st.$$.fragment,e),y(lt.$$.fragment,e),y(nt.$$.fragment,e),y(pt.$$.fragment,e),y(mt.$$.fragment,e),y(ht.$$.fragment,e),Ro=!1},d(e){r(q),e&&r(ft),e&&r(z),w(ge),e&&r(Ua),e&&r(b),e&&r(Da),e&&r(I),e&&r(Oa),e&&r(_t),e&&r(Na),e&&r(L),e&&r(ja),e&&r(S),e&&r(Fa),e&&r(H),w(Ae),e&&r(Ra),e&&r(Q),e&&r(Ha),w(Pe,e),e&&r(Ma),e&&r(dt),e&&r(Ga),e&&r(Z),e&&r(Ba),e&&r(Gt),e&&r(Ja),w(qe,e),e&&r(Ya),e&&r(Bt),e&&r(Xa),w(Ie,e),e&&r(Va),e&&r(M),w(Le),e&&r(Wa),e&&r(E),e&&r(Ka),w(Oe,e),e&&r(Qa),e&&r(G),w(Ne),e&&r(Za),e&&r(re),e&&r(eo),e&&r(ae),e&&r(to),w(He,e),e&&r(ro),e&&r(oe),e&&r(ao),e&&r(B),w(Ge),e&&r(oo),e&&r(x),e&&r(io),e&&r(C),e&&r(so),w(Xe,e),e&&r(lo),e&&r(J),w(Ve),e&&r(no),e&&r(le),e&&r(po),w(Ke,e),e&&r(uo),e&&r(k),e&&r(mo),w(Qe,e),e&&r(ho),e&&r(Jt),e&&r(fo),w(Ze,e),e&&r(co),e&&r(Yt),e&&r(_o),w(et,e),e&&r(vo),e&&r(Y),w(tt),e&&r(go),e&&r(Xt),e&&r(yo),e&&r(U),e&&r(wo),e&&r(Kt),e&&r(Eo),w(rt,e),e&&r($o),e&&r(X),w(at),e&&r(bo),e&&r(Qt),e&&r(xo),e&&r(D),e&&r(zo),w(ot,e),e&&r(ko),e&&r(O),e&&r(To),w(it,e),e&&r(Ao),e&&r(V),w(st),e&&r(Po),e&&r(Zt),e&&r(qo),e&&r(T),e&&r(Io),w(lt,e),e&&r(Lo),e&&r(he),e&&r(So),w(nt,e),e&&r(Co),e&&r(W),w(pt),e&&r(Uo),e&&r(ce),e&&r(Do),w(mt,e),e&&r(Oo),e&&r(N),e&&r(No),e&&r(_e),e&&r(jo),e&&r(er),e&&r(Fo),w(ht,e)}}}const Jm={local:"run-a-training-script",sections:[{local:"setup",title:"Setup"},{local:"run-a-script",title:"Run a script"},{local:"distributed-training-and-mixed-precision",title:"Distributed training and mixed precision"},{local:"run-a-script-on-a-tpu",title:"Run a script on a TPU"},{local:"run-a-script-with-accelerate",title:"Run a script with \u{1F917} Accelerate"},{local:"use-a-custom-dataset",title:"Use a custom dataset"},{local:"test-a-script",title:"Test a script"},{local:"resume-training-from-checkpoint",title:"Resume training from checkpoint"},{local:"share-your-model",title:"Share your model"}],title:"Run a training script"};function Ym(pi,q,ft){let{fw:z}=q;return pi.$$set=P=>{"fw"in P&&ft(0,z=P.fw)},[z]}class Zm extends Fm{constructor(q){super();Rm(this,q,Ym,Bm,Hm,{fw:0})}}export{Zm as default,Jm as metadata};
