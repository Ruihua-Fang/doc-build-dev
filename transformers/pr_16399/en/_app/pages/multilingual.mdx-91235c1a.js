import{S as Zr,i as ei,s as ti,e as l,k as d,w as u,t as s,M as ai,c as o,d as a,m as g,a as n,x as h,h as r,b as f,F as t,g as m,y as c,L as li,q as p,o as _,B as b,v as oi}from"../chunks/vendor-6b77c823.js";import{I as re}from"../chunks/IconCopyLink-7a11ce68.js";import{C as x}from"../chunks/CodeBlock-3a8b25a8.js";import{D as ni}from"../chunks/DocNotebookDropdown-f2b55cd8.js";function si(xs){let z,ua,q,A,dt,ie,jl,gt,zl,ha,me,ca,T,ql,ft,Cl,Dl,de,Pl,Ol,pa,C,N,ut,ge,Xl,ht,Il,_a,ze,Sl,ba,D,B,ct,fe,Al,pt,Nl,ka,qe,Bl,va,k,Ce,_t,Rl,Fl,Hl,De,bt,Gl,Wl,Ul,Pe,kt,Yl,Jl,Kl,Oe,vt,Ql,Vl,Zl,Xe,Et,eo,to,ao,Ie,$t,lo,oo,no,Se,wt,so,ro,Ea,$,io,Mt,mo,go,yt,fo,uo,xt,ho,co,$a,R,po,Tt,_o,bo,wa,ue,Ma,F,ko,Lt,vo,Eo,ya,he,xa,Ae,$o,Ta,ce,La,w,wo,jt,Mo,yo,zt,xo,To,qt,Lo,jo,ja,pe,za,H,zo,Ct,qo,Co,qa,_e,Ca,L,Do,be,Po,Oo,Dt,Xo,Io,Da,P,G,Pt,ke,So,Ot,Ao,Pa,Ne,No,Oa,W,Be,Xt,Bo,Ro,Fo,Re,It,Ho,Go,Xa,Fe,Wo,Ia,O,U,St,ve,Uo,At,Yo,Sa,He,Jo,Aa,Y,Ge,Nt,Ko,Qo,Vo,We,Bt,Zo,en,Na,Ue,tn,Ba,X,J,Rt,Ee,an,Ft,ln,Ra,Ye,on,Fa,K,Je,Ht,nn,sn,rn,Ke,Gt,mn,dn,Ha,Qe,gn,Ga,I,Q,Wt,$e,fn,Ut,un,Wa,Ve,hn,Ua,V,Ze,Yt,cn,pn,_n,et,Jt,bn,kn,Ya,Z,vn,Kt,En,$n,Ja,we,Ka,tt,wn,Qa,Me,Va,M,Mn,Qt,yn,xn,Vt,Tn,Ln,Zt,jn,zn,Za,ye,el,S,ee,ea,xe,qn,ta,Cn,tl,at,Dn,al,v,lt,aa,Pn,On,Xn,ot,la,In,Sn,An,nt,oa,Nn,Bn,Rn,st,na,Fn,Hn,Gn,sa,ra,Wn,ll,te,Un,ia,Yn,Jn,ol,Te,nl,rt,Kn,sl,Le,rl,y,Qn,ma,Vn,Zn,da,es,ts,ga,as,ls,il,je,ml,ae,os,fa,ns,ss,dl;return ie=new re({}),me=new ni({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/multilingual.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/pytorch/multilingual.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/tensorflow/multilingual.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/transformers_doc/multilingual.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/transformers_doc/pytorch/multilingual.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/transformers_doc/tensorflow/multilingual.ipynb"}]}}),ge=new re({}),fe=new re({}),ue=new x({props:{code:`import torch
from transformers import XLMTokenizer, XLMWithLMHeadModel

tokenizer = XLMTokenizer.from_pretrained("xlm-clm-enfr-1024")
model = XLMWithLMHeadModel.from_pretrained("xlm-clm-enfr-1024")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMTokenizer, XLMWithLMHeadModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMTokenizer.from_pretrained(<span class="hljs-string">&quot;xlm-clm-enfr-1024&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMWithLMHeadModel.from_pretrained(<span class="hljs-string">&quot;xlm-clm-enfr-1024&quot;</span>)`}}),he=new x({props:{code:"print(tokenizer.lang2id)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer.lang2id)
{<span class="hljs-string">&#x27;en&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;fr&#x27;</span>: <span class="hljs-number">1</span>}`}}),ce=new x({props:{code:'input_ids = torch.tensor([tokenizer.encode("Wikipedia was used to")])  # batch size of 1',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = torch.tensor([tokenizer.encode(<span class="hljs-string">&quot;Wikipedia was used to&quot;</span>)])  <span class="hljs-comment"># batch size of 1</span>'}}),pe=new x({props:{code:`language_id = tokenizer.lang2id["en"]  # 0
langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])

# We reshape it to be of size (batch_size, sequence_length)
langs = langs.view(1, -1)  # is now of shape [1, sequence_length] (we have a batch size of 1)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>language_id = tokenizer.lang2id[<span class="hljs-string">&quot;en&quot;</span>]  <span class="hljs-comment"># 0</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>langs = torch.tensor([language_id] * input_ids.shape[<span class="hljs-number">1</span>])  <span class="hljs-comment"># torch.tensor([0, 0, 0, ..., 0])</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># We reshape it to be of size (batch_size, sequence_length)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>langs = langs.view(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># is now of shape [1, sequence_length] (we have a batch size of 1)</span>`}}),_e=new x({props:{code:"outputs = model(input_ids, langs=langs)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(input_ids, langs=langs)'}}),ke=new re({}),ve=new re({}),Ee=new re({}),$e=new re({}),we=new x({props:{code:`from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer

en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
chinese_text = "\u4E0D\u8981\u63D2\u624B\u5DEB\u5E2B\u7684\u4E8B\u52D9, \u56E0\u70BA\u4ED6\u5011\u662F\u5FAE\u5999\u7684, \u5F88\u5FEB\u5C31\u6703\u767C\u6012."

tokenizer = M2M100Tokenizer.from_pretrained("facebook/m2m100_418M", src_lang="zh")
model = M2M100ForConditionalGeneration.from_pretrained("facebook/m2m100_418M")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> M2M100ForConditionalGeneration, M2M100Tokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>en_text = <span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>chinese_text = <span class="hljs-string">&quot;\u4E0D\u8981\u63D2\u624B\u5DEB\u5E2B\u7684\u4E8B\u52D9, \u56E0\u70BA\u4ED6\u5011\u662F\u5FAE\u5999\u7684, \u5F88\u5FEB\u5C31\u6703\u767C\u6012.&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = M2M100Tokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/m2m100_418M&quot;</span>, src_lang=<span class="hljs-string">&quot;zh&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = M2M100ForConditionalGeneration.from_pretrained(<span class="hljs-string">&quot;facebook/m2m100_418M&quot;</span>)`}}),Me=new x({props:{code:'encoded_zh = tokenizer(chinese_text, return_tensors="pt")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_zh = tokenizer(chinese_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)'}}),ye=new x({props:{code:`generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id("en"))
tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id(<span class="hljs-string">&quot;en&quot;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_tokens, skip_special_tokens=<span class="hljs-literal">True</span>)
<span class="hljs-string">&#x27;Do not interfere with the matters of the witches, because they are delicate and will soon be angry.&#x27;</span>`}}),xe=new re({}),Te=new x({props:{code:`from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
fi_text = "\xC4l\xE4 sekaannu velhojen asioihin, sill\xE4 ne ovat hienovaraisia ja nopeasti vihaisia."

tokenizer = AutoTokenizer.from_pretrained("facebook/mbart-large-50-many-to-many-mmt", src_lang="fi_FI")
model = AutoModelForSeq2SeqLM.from_pretrained("facebook/mbart-large-50-many-to-many-mmt")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span>en_text = <span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>fi_text = <span class="hljs-string">&quot;\xC4l\xE4 sekaannu velhojen asioihin, sill\xE4 ne ovat hienovaraisia ja nopeasti vihaisia.&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/mbart-large-50-many-to-many-mmt&quot;</span>, src_lang=<span class="hljs-string">&quot;fi_FI&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;facebook/mbart-large-50-many-to-many-mmt&quot;</span>)`}}),Le=new x({props:{code:'encoded_en = tokenizer(en_text, return_tensors="pt")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_en = tokenizer(en_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)'}}),je=new x({props:{code:`generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id("en_XX"))
tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id(<span class="hljs-string">&quot;en_XX&quot;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_tokens, skip_special_tokens=<span class="hljs-literal">True</span>)
<span class="hljs-string">&quot;Don&#x27;t interfere with the wizard&#x27;s affairs, because they are subtle, will soon get angry.&quot;</span>`}}),{c(){z=l("meta"),ua=d(),q=l("h1"),A=l("a"),dt=l("span"),u(ie.$$.fragment),jl=d(),gt=l("span"),zl=s("Multilingual models for inference"),ha=d(),u(me.$$.fragment),ca=d(),T=l("p"),ql=s("There are several multilingual models in \u{1F917} Transformers, and their inference usage differs from monolingual models. Not "),ft=l("em"),Cl=s("all"),Dl=s(" multilingual model usage is different though. Some models, like "),de=l("a"),Pl=s("bert-base-multilingual-uncased"),Ol=s(", can be used just like a monolingual model. This guide will show you how to use multilingual models whose usage differs for inference."),pa=d(),C=l("h2"),N=l("a"),ut=l("span"),u(ge.$$.fragment),Xl=d(),ht=l("span"),Il=s("XLM"),_a=d(),ze=l("p"),Sl=s("XLM has ten different checkpoints, only one of which is monolingual. The nine remaining model checkpoints can be split into two categories: the checkpoints that use language embeddings and those that don\u2019t."),ba=d(),D=l("h3"),B=l("a"),ct=l("span"),u(fe.$$.fragment),Al=d(),pt=l("span"),Nl=s("XLM with language embeddings"),ka=d(),qe=l("p"),Bl=s("The following XLM models use language embeddings to specify the language used at inference:"),va=d(),k=l("ul"),Ce=l("li"),_t=l("code"),Rl=s("xlm-mlm-ende-1024"),Fl=s(" (Masked language modeling, English-German)"),Hl=d(),De=l("li"),bt=l("code"),Gl=s("xlm-mlm-enfr-1024"),Wl=s(" (Masked language modeling, English-French)"),Ul=d(),Pe=l("li"),kt=l("code"),Yl=s("xlm-mlm-enro-1024"),Jl=s(" (Masked language modeling, English-Romanian)"),Kl=d(),Oe=l("li"),vt=l("code"),Ql=s("xlm-mlm-xnli15-1024"),Vl=s(" (Masked language modeling, XNLI languages)"),Zl=d(),Xe=l("li"),Et=l("code"),eo=s("xlm-mlm-tlm-xnli15-1024"),to=s(" (Masked language modeling + translation, XNLI languages)"),ao=d(),Ie=l("li"),$t=l("code"),lo=s("xlm-clm-enfr-1024"),oo=s(" (Causal language modeling, English-French)"),no=d(),Se=l("li"),wt=l("code"),so=s("xlm-clm-ende-1024"),ro=s(" (Causal language modeling, English-German)"),Ea=d(),$=l("p"),io=s("Language embeddings are represented as a tensor of the same shape as the "),Mt=l("code"),mo=s("input_ids"),go=s(" passed to the model. The values in these tensors depend on the language used and are identified by the tokenizer\u2019s "),yt=l("code"),fo=s("lang2id"),uo=s(" and "),xt=l("code"),ho=s("id2lang"),co=s(" attributes."),$a=d(),R=l("p"),po=s("In this example, load the "),Tt=l("code"),_o=s("xlm-clm-enfr-1024"),bo=s(" checkpoint (Causal language modeling, English-French):"),wa=d(),u(ue.$$.fragment),Ma=d(),F=l("p"),ko=s("The "),Lt=l("code"),vo=s("lang2id"),Eo=s(" attribute of the tokenizer displays this model\u2019s languages and their ids:"),ya=d(),u(he.$$.fragment),xa=d(),Ae=l("p"),$o=s("Next, create an example input:"),Ta=d(),u(ce.$$.fragment),La=d(),w=l("p"),wo=s("Set the language id as "),jt=l("code"),Mo=s('"en"'),yo=s(" and use it to define the language embedding. The language embedding is a tensor filled with "),zt=l("code"),xo=s("0"),To=s(" since that is the language id for English. This tensor should be the same size as "),qt=l("code"),Lo=s("input_ids"),jo=s("."),ja=d(),u(pe.$$.fragment),za=d(),H=l("p"),zo=s("Now you can pass the "),Ct=l("code"),qo=s("input_ids"),Co=s(" and language embedding to the model:"),qa=d(),u(_e.$$.fragment),Ca=d(),L=l("p"),Do=s("The "),be=l("a"),Po=s("run_generation.py"),Oo=s(" script can generate text with language embeddings using the "),Dt=l("code"),Xo=s("xlm-clm"),Io=s(" checkpoints."),Da=d(),P=l("h3"),G=l("a"),Pt=l("span"),u(ke.$$.fragment),So=d(),Ot=l("span"),Ao=s("XLM without language embeddings"),Pa=d(),Ne=l("p"),No=s("The following XLM models do not require language embeddings during inference:"),Oa=d(),W=l("ul"),Be=l("li"),Xt=l("code"),Bo=s("xlm-mlm-17-1280"),Ro=s(" (Masked language modeling, 17 languages)"),Fo=d(),Re=l("li"),It=l("code"),Ho=s("xlm-mlm-100-1280"),Go=s(" (Masked language modeling, 100 languages)"),Xa=d(),Fe=l("p"),Wo=s("These models are used for generic sentence representations, unlike the previous XLM checkpoints."),Ia=d(),O=l("h2"),U=l("a"),St=l("span"),u(ve.$$.fragment),Uo=d(),At=l("span"),Yo=s("BERT"),Sa=d(),He=l("p"),Jo=s("The following BERT models can be used for multilingual tasks:"),Aa=d(),Y=l("ul"),Ge=l("li"),Nt=l("code"),Ko=s("bert-base-multilingual-uncased"),Qo=s(" (Masked language modeling + Next sentence prediction, 102 languages)"),Vo=d(),We=l("li"),Bt=l("code"),Zo=s("bert-base-multilingual-cased"),en=s(" (Masked language modeling + Next sentence prediction, 104 languages)"),Na=d(),Ue=l("p"),tn=s(`These models do not require language embeddings during inference. They should identify the language from the
context and infer accordingly.`),Ba=d(),X=l("h2"),J=l("a"),Rt=l("span"),u(Ee.$$.fragment),an=d(),Ft=l("span"),ln=s("XLM-RoBERTa"),Ra=d(),Ye=l("p"),on=s("The following XLM-RoBERTa models can be used for multilingual tasks:"),Fa=d(),K=l("ul"),Je=l("li"),Ht=l("code"),nn=s("xlm-roberta-base"),sn=s(" (Masked language modeling, 100 languages)"),rn=d(),Ke=l("li"),Gt=l("code"),mn=s("xlm-roberta-large"),dn=s(" (Masked language modeling, 100 languages)"),Ha=d(),Qe=l("p"),gn=s("XLM-RoBERTa was trained on 2.5TB of newly created and cleaned CommonCrawl data in 100 languages. It provides strong gains over previously released multilingual models like mBERT or XLM on downstream tasks like classification, sequence labeling, and question answering."),Ga=d(),I=l("h2"),Q=l("a"),Wt=l("span"),u($e.$$.fragment),fn=d(),Ut=l("span"),un=s("M2M100"),Wa=d(),Ve=l("p"),hn=s("The following M2M100 models can be used for multilingual translation:"),Ua=d(),V=l("ul"),Ze=l("li"),Yt=l("code"),cn=s("facebook/m2m100_418M"),pn=s(" (Translation)"),_n=d(),et=l("li"),Jt=l("code"),bn=s("facebook/m2m100_1.2B"),kn=s(" (Translation)"),Ya=d(),Z=l("p"),vn=s("In this example, load the "),Kt=l("code"),En=s("facebook/m2m100_418M"),$n=s(" checkpoint to translate from Chinese to English. You can set the source language in the tokenizer:"),Ja=d(),u(we.$$.fragment),Ka=d(),tt=l("p"),wn=s("Tokenize the text:"),Qa=d(),u(Me.$$.fragment),Va=d(),M=l("p"),Mn=s("M2M100 forces the target language id as the first generated token to translate to the target language. Set the "),Qt=l("code"),yn=s("forced_bos_token_id"),xn=s(" to "),Vt=l("code"),Tn=s("en"),Ln=s(" in the "),Zt=l("code"),jn=s("generate"),zn=s(" method to translate to English:"),Za=d(),u(ye.$$.fragment),el=d(),S=l("h2"),ee=l("a"),ea=l("span"),u(xe.$$.fragment),qn=d(),ta=l("span"),Cn=s("MBart"),tl=d(),at=l("p"),Dn=s("The following MBart models can be used for multilingual translation:"),al=d(),v=l("ul"),lt=l("li"),aa=l("code"),Pn=s("facebook/mbart-large-50-one-to-many-mmt"),On=s(" (One-to-many multilingual machine translation, 50 languages)"),Xn=d(),ot=l("li"),la=l("code"),In=s("facebook/mbart-large-50-many-to-many-mmt"),Sn=s(" (Many-to-many multilingual machine translation, 50 languages)"),An=d(),nt=l("li"),oa=l("code"),Nn=s("facebook/mbart-large-50-many-to-one-mmt"),Bn=s(" (Many-to-one multilingual machine translation, 50 languages)"),Rn=d(),st=l("li"),na=l("code"),Fn=s("facebook/mbart-large-50"),Hn=s(" (Multilingual translation, 50 languages)"),Gn=d(),sa=l("li"),ra=l("code"),Wn=s("facebook/mbart-large-cc25"),ll=d(),te=l("p"),Un=s("In this example, load the "),ia=l("code"),Yn=s("facebook/mbart-large-50-many-to-many-mmt"),Jn=s(" checkpoint to translate Finnish to English. You can set the source language in the tokenizer:"),ol=d(),u(Te.$$.fragment),nl=d(),rt=l("p"),Kn=s("Tokenize the text:"),sl=d(),u(Le.$$.fragment),rl=d(),y=l("p"),Qn=s("MBart forces the target language id as the first generated token to translate to the target language. Set the "),ma=l("code"),Vn=s("forced_bos_token_id"),Zn=s(" to "),da=l("code"),es=s("en"),ts=s(" in the "),ga=l("code"),as=s("generate"),ls=s(" method to translate to English:"),il=d(),u(je.$$.fragment),ml=d(),ae=l("p"),os=s("If you are using the "),fa=l("code"),ns=s("facebook/mbart-large-50-many-to-one-mmt"),ss=s(" checkpoint, you don\u2019t need to force the target language id as the first generated token otherwise the usage is the same."),this.h()},l(e){const i=ai('[data-svelte="svelte-1phssyn"]',document.head);z=o(i,"META",{name:!0,content:!0}),i.forEach(a),ua=g(e),q=o(e,"H1",{class:!0});var gl=n(q);A=o(gl,"A",{id:!0,class:!0,href:!0});var Ts=n(A);dt=o(Ts,"SPAN",{});var Ls=n(dt);h(ie.$$.fragment,Ls),Ls.forEach(a),Ts.forEach(a),jl=g(gl),gt=o(gl,"SPAN",{});var js=n(gt);zl=r(js,"Multilingual models for inference"),js.forEach(a),gl.forEach(a),ha=g(e),h(me.$$.fragment,e),ca=g(e),T=o(e,"P",{});var it=n(T);ql=r(it,"There are several multilingual models in \u{1F917} Transformers, and their inference usage differs from monolingual models. Not "),ft=o(it,"EM",{});var zs=n(ft);Cl=r(zs,"all"),zs.forEach(a),Dl=r(it," multilingual model usage is different though. Some models, like "),de=o(it,"A",{href:!0,rel:!0});var qs=n(de);Pl=r(qs,"bert-base-multilingual-uncased"),qs.forEach(a),Ol=r(it,", can be used just like a monolingual model. This guide will show you how to use multilingual models whose usage differs for inference."),it.forEach(a),pa=g(e),C=o(e,"H2",{class:!0});var fl=n(C);N=o(fl,"A",{id:!0,class:!0,href:!0});var Cs=n(N);ut=o(Cs,"SPAN",{});var Ds=n(ut);h(ge.$$.fragment,Ds),Ds.forEach(a),Cs.forEach(a),Xl=g(fl),ht=o(fl,"SPAN",{});var Ps=n(ht);Il=r(Ps,"XLM"),Ps.forEach(a),fl.forEach(a),_a=g(e),ze=o(e,"P",{});var Os=n(ze);Sl=r(Os,"XLM has ten different checkpoints, only one of which is monolingual. The nine remaining model checkpoints can be split into two categories: the checkpoints that use language embeddings and those that don\u2019t."),Os.forEach(a),ba=g(e),D=o(e,"H3",{class:!0});var ul=n(D);B=o(ul,"A",{id:!0,class:!0,href:!0});var Xs=n(B);ct=o(Xs,"SPAN",{});var Is=n(ct);h(fe.$$.fragment,Is),Is.forEach(a),Xs.forEach(a),Al=g(ul),pt=o(ul,"SPAN",{});var Ss=n(pt);Nl=r(Ss,"XLM with language embeddings"),Ss.forEach(a),ul.forEach(a),ka=g(e),qe=o(e,"P",{});var As=n(qe);Bl=r(As,"The following XLM models use language embeddings to specify the language used at inference:"),As.forEach(a),va=g(e),k=o(e,"UL",{});var E=n(k);Ce=o(E,"LI",{});var rs=n(Ce);_t=o(rs,"CODE",{});var Ns=n(_t);Rl=r(Ns,"xlm-mlm-ende-1024"),Ns.forEach(a),Fl=r(rs," (Masked language modeling, English-German)"),rs.forEach(a),Hl=g(E),De=o(E,"LI",{});var is=n(De);bt=o(is,"CODE",{});var Bs=n(bt);Gl=r(Bs,"xlm-mlm-enfr-1024"),Bs.forEach(a),Wl=r(is," (Masked language modeling, English-French)"),is.forEach(a),Ul=g(E),Pe=o(E,"LI",{});var ms=n(Pe);kt=o(ms,"CODE",{});var Rs=n(kt);Yl=r(Rs,"xlm-mlm-enro-1024"),Rs.forEach(a),Jl=r(ms," (Masked language modeling, English-Romanian)"),ms.forEach(a),Kl=g(E),Oe=o(E,"LI",{});var ds=n(Oe);vt=o(ds,"CODE",{});var Fs=n(vt);Ql=r(Fs,"xlm-mlm-xnli15-1024"),Fs.forEach(a),Vl=r(ds," (Masked language modeling, XNLI languages)"),ds.forEach(a),Zl=g(E),Xe=o(E,"LI",{});var gs=n(Xe);Et=o(gs,"CODE",{});var Hs=n(Et);eo=r(Hs,"xlm-mlm-tlm-xnli15-1024"),Hs.forEach(a),to=r(gs," (Masked language modeling + translation, XNLI languages)"),gs.forEach(a),ao=g(E),Ie=o(E,"LI",{});var fs=n(Ie);$t=o(fs,"CODE",{});var Gs=n($t);lo=r(Gs,"xlm-clm-enfr-1024"),Gs.forEach(a),oo=r(fs," (Causal language modeling, English-French)"),fs.forEach(a),no=g(E),Se=o(E,"LI",{});var us=n(Se);wt=o(us,"CODE",{});var Ws=n(wt);so=r(Ws,"xlm-clm-ende-1024"),Ws.forEach(a),ro=r(us," (Causal language modeling, English-German)"),us.forEach(a),E.forEach(a),Ea=g(e),$=o(e,"P",{});var le=n($);io=r(le,"Language embeddings are represented as a tensor of the same shape as the "),Mt=o(le,"CODE",{});var Us=n(Mt);mo=r(Us,"input_ids"),Us.forEach(a),go=r(le," passed to the model. The values in these tensors depend on the language used and are identified by the tokenizer\u2019s "),yt=o(le,"CODE",{});var Ys=n(yt);fo=r(Ys,"lang2id"),Ys.forEach(a),uo=r(le," and "),xt=o(le,"CODE",{});var Js=n(xt);ho=r(Js,"id2lang"),Js.forEach(a),co=r(le," attributes."),le.forEach(a),$a=g(e),R=o(e,"P",{});var hl=n(R);po=r(hl,"In this example, load the "),Tt=o(hl,"CODE",{});var Ks=n(Tt);_o=r(Ks,"xlm-clm-enfr-1024"),Ks.forEach(a),bo=r(hl," checkpoint (Causal language modeling, English-French):"),hl.forEach(a),wa=g(e),h(ue.$$.fragment,e),Ma=g(e),F=o(e,"P",{});var cl=n(F);ko=r(cl,"The "),Lt=o(cl,"CODE",{});var Qs=n(Lt);vo=r(Qs,"lang2id"),Qs.forEach(a),Eo=r(cl," attribute of the tokenizer displays this model\u2019s languages and their ids:"),cl.forEach(a),ya=g(e),h(he.$$.fragment,e),xa=g(e),Ae=o(e,"P",{});var Vs=n(Ae);$o=r(Vs,"Next, create an example input:"),Vs.forEach(a),Ta=g(e),h(ce.$$.fragment,e),La=g(e),w=o(e,"P",{});var oe=n(w);wo=r(oe,"Set the language id as "),jt=o(oe,"CODE",{});var Zs=n(jt);Mo=r(Zs,'"en"'),Zs.forEach(a),yo=r(oe," and use it to define the language embedding. The language embedding is a tensor filled with "),zt=o(oe,"CODE",{});var er=n(zt);xo=r(er,"0"),er.forEach(a),To=r(oe," since that is the language id for English. This tensor should be the same size as "),qt=o(oe,"CODE",{});var tr=n(qt);Lo=r(tr,"input_ids"),tr.forEach(a),jo=r(oe,"."),oe.forEach(a),ja=g(e),h(pe.$$.fragment,e),za=g(e),H=o(e,"P",{});var pl=n(H);zo=r(pl,"Now you can pass the "),Ct=o(pl,"CODE",{});var ar=n(Ct);qo=r(ar,"input_ids"),ar.forEach(a),Co=r(pl," and language embedding to the model:"),pl.forEach(a),qa=g(e),h(_e.$$.fragment,e),Ca=g(e),L=o(e,"P",{});var mt=n(L);Do=r(mt,"The "),be=o(mt,"A",{href:!0,rel:!0});var lr=n(be);Po=r(lr,"run_generation.py"),lr.forEach(a),Oo=r(mt," script can generate text with language embeddings using the "),Dt=o(mt,"CODE",{});var or=n(Dt);Xo=r(or,"xlm-clm"),or.forEach(a),Io=r(mt," checkpoints."),mt.forEach(a),Da=g(e),P=o(e,"H3",{class:!0});var _l=n(P);G=o(_l,"A",{id:!0,class:!0,href:!0});var nr=n(G);Pt=o(nr,"SPAN",{});var sr=n(Pt);h(ke.$$.fragment,sr),sr.forEach(a),nr.forEach(a),So=g(_l),Ot=o(_l,"SPAN",{});var rr=n(Ot);Ao=r(rr,"XLM without language embeddings"),rr.forEach(a),_l.forEach(a),Pa=g(e),Ne=o(e,"P",{});var ir=n(Ne);No=r(ir,"The following XLM models do not require language embeddings during inference:"),ir.forEach(a),Oa=g(e),W=o(e,"UL",{});var bl=n(W);Be=o(bl,"LI",{});var hs=n(Be);Xt=o(hs,"CODE",{});var mr=n(Xt);Bo=r(mr,"xlm-mlm-17-1280"),mr.forEach(a),Ro=r(hs," (Masked language modeling, 17 languages)"),hs.forEach(a),Fo=g(bl),Re=o(bl,"LI",{});var cs=n(Re);It=o(cs,"CODE",{});var dr=n(It);Ho=r(dr,"xlm-mlm-100-1280"),dr.forEach(a),Go=r(cs," (Masked language modeling, 100 languages)"),cs.forEach(a),bl.forEach(a),Xa=g(e),Fe=o(e,"P",{});var gr=n(Fe);Wo=r(gr,"These models are used for generic sentence representations, unlike the previous XLM checkpoints."),gr.forEach(a),Ia=g(e),O=o(e,"H2",{class:!0});var kl=n(O);U=o(kl,"A",{id:!0,class:!0,href:!0});var fr=n(U);St=o(fr,"SPAN",{});var ur=n(St);h(ve.$$.fragment,ur),ur.forEach(a),fr.forEach(a),Uo=g(kl),At=o(kl,"SPAN",{});var hr=n(At);Yo=r(hr,"BERT"),hr.forEach(a),kl.forEach(a),Sa=g(e),He=o(e,"P",{});var cr=n(He);Jo=r(cr,"The following BERT models can be used for multilingual tasks:"),cr.forEach(a),Aa=g(e),Y=o(e,"UL",{});var vl=n(Y);Ge=o(vl,"LI",{});var ps=n(Ge);Nt=o(ps,"CODE",{});var pr=n(Nt);Ko=r(pr,"bert-base-multilingual-uncased"),pr.forEach(a),Qo=r(ps," (Masked language modeling + Next sentence prediction, 102 languages)"),ps.forEach(a),Vo=g(vl),We=o(vl,"LI",{});var _s=n(We);Bt=o(_s,"CODE",{});var _r=n(Bt);Zo=r(_r,"bert-base-multilingual-cased"),_r.forEach(a),en=r(_s," (Masked language modeling + Next sentence prediction, 104 languages)"),_s.forEach(a),vl.forEach(a),Na=g(e),Ue=o(e,"P",{});var br=n(Ue);tn=r(br,`These models do not require language embeddings during inference. They should identify the language from the
context and infer accordingly.`),br.forEach(a),Ba=g(e),X=o(e,"H2",{class:!0});var El=n(X);J=o(El,"A",{id:!0,class:!0,href:!0});var kr=n(J);Rt=o(kr,"SPAN",{});var vr=n(Rt);h(Ee.$$.fragment,vr),vr.forEach(a),kr.forEach(a),an=g(El),Ft=o(El,"SPAN",{});var Er=n(Ft);ln=r(Er,"XLM-RoBERTa"),Er.forEach(a),El.forEach(a),Ra=g(e),Ye=o(e,"P",{});var $r=n(Ye);on=r($r,"The following XLM-RoBERTa models can be used for multilingual tasks:"),$r.forEach(a),Fa=g(e),K=o(e,"UL",{});var $l=n(K);Je=o($l,"LI",{});var bs=n(Je);Ht=o(bs,"CODE",{});var wr=n(Ht);nn=r(wr,"xlm-roberta-base"),wr.forEach(a),sn=r(bs," (Masked language modeling, 100 languages)"),bs.forEach(a),rn=g($l),Ke=o($l,"LI",{});var ks=n(Ke);Gt=o(ks,"CODE",{});var Mr=n(Gt);mn=r(Mr,"xlm-roberta-large"),Mr.forEach(a),dn=r(ks," (Masked language modeling, 100 languages)"),ks.forEach(a),$l.forEach(a),Ha=g(e),Qe=o(e,"P",{});var yr=n(Qe);gn=r(yr,"XLM-RoBERTa was trained on 2.5TB of newly created and cleaned CommonCrawl data in 100 languages. It provides strong gains over previously released multilingual models like mBERT or XLM on downstream tasks like classification, sequence labeling, and question answering."),yr.forEach(a),Ga=g(e),I=o(e,"H2",{class:!0});var wl=n(I);Q=o(wl,"A",{id:!0,class:!0,href:!0});var xr=n(Q);Wt=o(xr,"SPAN",{});var Tr=n(Wt);h($e.$$.fragment,Tr),Tr.forEach(a),xr.forEach(a),fn=g(wl),Ut=o(wl,"SPAN",{});var Lr=n(Ut);un=r(Lr,"M2M100"),Lr.forEach(a),wl.forEach(a),Wa=g(e),Ve=o(e,"P",{});var jr=n(Ve);hn=r(jr,"The following M2M100 models can be used for multilingual translation:"),jr.forEach(a),Ua=g(e),V=o(e,"UL",{});var Ml=n(V);Ze=o(Ml,"LI",{});var vs=n(Ze);Yt=o(vs,"CODE",{});var zr=n(Yt);cn=r(zr,"facebook/m2m100_418M"),zr.forEach(a),pn=r(vs," (Translation)"),vs.forEach(a),_n=g(Ml),et=o(Ml,"LI",{});var Es=n(et);Jt=o(Es,"CODE",{});var qr=n(Jt);bn=r(qr,"facebook/m2m100_1.2B"),qr.forEach(a),kn=r(Es," (Translation)"),Es.forEach(a),Ml.forEach(a),Ya=g(e),Z=o(e,"P",{});var yl=n(Z);vn=r(yl,"In this example, load the "),Kt=o(yl,"CODE",{});var Cr=n(Kt);En=r(Cr,"facebook/m2m100_418M"),Cr.forEach(a),$n=r(yl," checkpoint to translate from Chinese to English. You can set the source language in the tokenizer:"),yl.forEach(a),Ja=g(e),h(we.$$.fragment,e),Ka=g(e),tt=o(e,"P",{});var Dr=n(tt);wn=r(Dr,"Tokenize the text:"),Dr.forEach(a),Qa=g(e),h(Me.$$.fragment,e),Va=g(e),M=o(e,"P",{});var ne=n(M);Mn=r(ne,"M2M100 forces the target language id as the first generated token to translate to the target language. Set the "),Qt=o(ne,"CODE",{});var Pr=n(Qt);yn=r(Pr,"forced_bos_token_id"),Pr.forEach(a),xn=r(ne," to "),Vt=o(ne,"CODE",{});var Or=n(Vt);Tn=r(Or,"en"),Or.forEach(a),Ln=r(ne," in the "),Zt=o(ne,"CODE",{});var Xr=n(Zt);jn=r(Xr,"generate"),Xr.forEach(a),zn=r(ne," method to translate to English:"),ne.forEach(a),Za=g(e),h(ye.$$.fragment,e),el=g(e),S=o(e,"H2",{class:!0});var xl=n(S);ee=o(xl,"A",{id:!0,class:!0,href:!0});var Ir=n(ee);ea=o(Ir,"SPAN",{});var Sr=n(ea);h(xe.$$.fragment,Sr),Sr.forEach(a),Ir.forEach(a),qn=g(xl),ta=o(xl,"SPAN",{});var Ar=n(ta);Cn=r(Ar,"MBart"),Ar.forEach(a),xl.forEach(a),tl=g(e),at=o(e,"P",{});var Nr=n(at);Dn=r(Nr,"The following MBart models can be used for multilingual translation:"),Nr.forEach(a),al=g(e),v=o(e,"UL",{});var j=n(v);lt=o(j,"LI",{});var $s=n(lt);aa=o($s,"CODE",{});var Br=n(aa);Pn=r(Br,"facebook/mbart-large-50-one-to-many-mmt"),Br.forEach(a),On=r($s," (One-to-many multilingual machine translation, 50 languages)"),$s.forEach(a),Xn=g(j),ot=o(j,"LI",{});var ws=n(ot);la=o(ws,"CODE",{});var Rr=n(la);In=r(Rr,"facebook/mbart-large-50-many-to-many-mmt"),Rr.forEach(a),Sn=r(ws," (Many-to-many multilingual machine translation, 50 languages)"),ws.forEach(a),An=g(j),nt=o(j,"LI",{});var Ms=n(nt);oa=o(Ms,"CODE",{});var Fr=n(oa);Nn=r(Fr,"facebook/mbart-large-50-many-to-one-mmt"),Fr.forEach(a),Bn=r(Ms," (Many-to-one multilingual machine translation, 50 languages)"),Ms.forEach(a),Rn=g(j),st=o(j,"LI",{});var ys=n(st);na=o(ys,"CODE",{});var Hr=n(na);Fn=r(Hr,"facebook/mbart-large-50"),Hr.forEach(a),Hn=r(ys," (Multilingual translation, 50 languages)"),ys.forEach(a),Gn=g(j),sa=o(j,"LI",{});var Gr=n(sa);ra=o(Gr,"CODE",{});var Wr=n(ra);Wn=r(Wr,"facebook/mbart-large-cc25"),Wr.forEach(a),Gr.forEach(a),j.forEach(a),ll=g(e),te=o(e,"P",{});var Tl=n(te);Un=r(Tl,"In this example, load the "),ia=o(Tl,"CODE",{});var Ur=n(ia);Yn=r(Ur,"facebook/mbart-large-50-many-to-many-mmt"),Ur.forEach(a),Jn=r(Tl," checkpoint to translate Finnish to English. You can set the source language in the tokenizer:"),Tl.forEach(a),ol=g(e),h(Te.$$.fragment,e),nl=g(e),rt=o(e,"P",{});var Yr=n(rt);Kn=r(Yr,"Tokenize the text:"),Yr.forEach(a),sl=g(e),h(Le.$$.fragment,e),rl=g(e),y=o(e,"P",{});var se=n(y);Qn=r(se,"MBart forces the target language id as the first generated token to translate to the target language. Set the "),ma=o(se,"CODE",{});var Jr=n(ma);Vn=r(Jr,"forced_bos_token_id"),Jr.forEach(a),Zn=r(se," to "),da=o(se,"CODE",{});var Kr=n(da);es=r(Kr,"en"),Kr.forEach(a),ts=r(se," in the "),ga=o(se,"CODE",{});var Qr=n(ga);as=r(Qr,"generate"),Qr.forEach(a),ls=r(se," method to translate to English:"),se.forEach(a),il=g(e),h(je.$$.fragment,e),ml=g(e),ae=o(e,"P",{});var Ll=n(ae);os=r(Ll,"If you are using the "),fa=o(Ll,"CODE",{});var Vr=n(fa);ns=r(Vr,"facebook/mbart-large-50-many-to-one-mmt"),Vr.forEach(a),ss=r(Ll," checkpoint, you don\u2019t need to force the target language id as the first generated token otherwise the usage is the same."),Ll.forEach(a),this.h()},h(){f(z,"name","hf:doc:metadata"),f(z,"content",JSON.stringify(ri)),f(A,"id","multilingual-models-for-inference"),f(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(A,"href","#multilingual-models-for-inference"),f(q,"class","relative group"),f(de,"href","https://huggingface.co/bert-base-multilingual-uncased"),f(de,"rel","nofollow"),f(N,"id","xlm"),f(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(N,"href","#xlm"),f(C,"class","relative group"),f(B,"id","xlm-with-language-embeddings"),f(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(B,"href","#xlm-with-language-embeddings"),f(D,"class","relative group"),f(be,"href","https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation/run_generation.py"),f(be,"rel","nofollow"),f(G,"id","xlm-without-language-embeddings"),f(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(G,"href","#xlm-without-language-embeddings"),f(P,"class","relative group"),f(U,"id","bert"),f(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(U,"href","#bert"),f(O,"class","relative group"),f(J,"id","xlmroberta"),f(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(J,"href","#xlmroberta"),f(X,"class","relative group"),f(Q,"id","m2m100"),f(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Q,"href","#m2m100"),f(I,"class","relative group"),f(ee,"id","mbart"),f(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ee,"href","#mbart"),f(S,"class","relative group")},m(e,i){t(document.head,z),m(e,ua,i),m(e,q,i),t(q,A),t(A,dt),c(ie,dt,null),t(q,jl),t(q,gt),t(gt,zl),m(e,ha,i),c(me,e,i),m(e,ca,i),m(e,T,i),t(T,ql),t(T,ft),t(ft,Cl),t(T,Dl),t(T,de),t(de,Pl),t(T,Ol),m(e,pa,i),m(e,C,i),t(C,N),t(N,ut),c(ge,ut,null),t(C,Xl),t(C,ht),t(ht,Il),m(e,_a,i),m(e,ze,i),t(ze,Sl),m(e,ba,i),m(e,D,i),t(D,B),t(B,ct),c(fe,ct,null),t(D,Al),t(D,pt),t(pt,Nl),m(e,ka,i),m(e,qe,i),t(qe,Bl),m(e,va,i),m(e,k,i),t(k,Ce),t(Ce,_t),t(_t,Rl),t(Ce,Fl),t(k,Hl),t(k,De),t(De,bt),t(bt,Gl),t(De,Wl),t(k,Ul),t(k,Pe),t(Pe,kt),t(kt,Yl),t(Pe,Jl),t(k,Kl),t(k,Oe),t(Oe,vt),t(vt,Ql),t(Oe,Vl),t(k,Zl),t(k,Xe),t(Xe,Et),t(Et,eo),t(Xe,to),t(k,ao),t(k,Ie),t(Ie,$t),t($t,lo),t(Ie,oo),t(k,no),t(k,Se),t(Se,wt),t(wt,so),t(Se,ro),m(e,Ea,i),m(e,$,i),t($,io),t($,Mt),t(Mt,mo),t($,go),t($,yt),t(yt,fo),t($,uo),t($,xt),t(xt,ho),t($,co),m(e,$a,i),m(e,R,i),t(R,po),t(R,Tt),t(Tt,_o),t(R,bo),m(e,wa,i),c(ue,e,i),m(e,Ma,i),m(e,F,i),t(F,ko),t(F,Lt),t(Lt,vo),t(F,Eo),m(e,ya,i),c(he,e,i),m(e,xa,i),m(e,Ae,i),t(Ae,$o),m(e,Ta,i),c(ce,e,i),m(e,La,i),m(e,w,i),t(w,wo),t(w,jt),t(jt,Mo),t(w,yo),t(w,zt),t(zt,xo),t(w,To),t(w,qt),t(qt,Lo),t(w,jo),m(e,ja,i),c(pe,e,i),m(e,za,i),m(e,H,i),t(H,zo),t(H,Ct),t(Ct,qo),t(H,Co),m(e,qa,i),c(_e,e,i),m(e,Ca,i),m(e,L,i),t(L,Do),t(L,be),t(be,Po),t(L,Oo),t(L,Dt),t(Dt,Xo),t(L,Io),m(e,Da,i),m(e,P,i),t(P,G),t(G,Pt),c(ke,Pt,null),t(P,So),t(P,Ot),t(Ot,Ao),m(e,Pa,i),m(e,Ne,i),t(Ne,No),m(e,Oa,i),m(e,W,i),t(W,Be),t(Be,Xt),t(Xt,Bo),t(Be,Ro),t(W,Fo),t(W,Re),t(Re,It),t(It,Ho),t(Re,Go),m(e,Xa,i),m(e,Fe,i),t(Fe,Wo),m(e,Ia,i),m(e,O,i),t(O,U),t(U,St),c(ve,St,null),t(O,Uo),t(O,At),t(At,Yo),m(e,Sa,i),m(e,He,i),t(He,Jo),m(e,Aa,i),m(e,Y,i),t(Y,Ge),t(Ge,Nt),t(Nt,Ko),t(Ge,Qo),t(Y,Vo),t(Y,We),t(We,Bt),t(Bt,Zo),t(We,en),m(e,Na,i),m(e,Ue,i),t(Ue,tn),m(e,Ba,i),m(e,X,i),t(X,J),t(J,Rt),c(Ee,Rt,null),t(X,an),t(X,Ft),t(Ft,ln),m(e,Ra,i),m(e,Ye,i),t(Ye,on),m(e,Fa,i),m(e,K,i),t(K,Je),t(Je,Ht),t(Ht,nn),t(Je,sn),t(K,rn),t(K,Ke),t(Ke,Gt),t(Gt,mn),t(Ke,dn),m(e,Ha,i),m(e,Qe,i),t(Qe,gn),m(e,Ga,i),m(e,I,i),t(I,Q),t(Q,Wt),c($e,Wt,null),t(I,fn),t(I,Ut),t(Ut,un),m(e,Wa,i),m(e,Ve,i),t(Ve,hn),m(e,Ua,i),m(e,V,i),t(V,Ze),t(Ze,Yt),t(Yt,cn),t(Ze,pn),t(V,_n),t(V,et),t(et,Jt),t(Jt,bn),t(et,kn),m(e,Ya,i),m(e,Z,i),t(Z,vn),t(Z,Kt),t(Kt,En),t(Z,$n),m(e,Ja,i),c(we,e,i),m(e,Ka,i),m(e,tt,i),t(tt,wn),m(e,Qa,i),c(Me,e,i),m(e,Va,i),m(e,M,i),t(M,Mn),t(M,Qt),t(Qt,yn),t(M,xn),t(M,Vt),t(Vt,Tn),t(M,Ln),t(M,Zt),t(Zt,jn),t(M,zn),m(e,Za,i),c(ye,e,i),m(e,el,i),m(e,S,i),t(S,ee),t(ee,ea),c(xe,ea,null),t(S,qn),t(S,ta),t(ta,Cn),m(e,tl,i),m(e,at,i),t(at,Dn),m(e,al,i),m(e,v,i),t(v,lt),t(lt,aa),t(aa,Pn),t(lt,On),t(v,Xn),t(v,ot),t(ot,la),t(la,In),t(ot,Sn),t(v,An),t(v,nt),t(nt,oa),t(oa,Nn),t(nt,Bn),t(v,Rn),t(v,st),t(st,na),t(na,Fn),t(st,Hn),t(v,Gn),t(v,sa),t(sa,ra),t(ra,Wn),m(e,ll,i),m(e,te,i),t(te,Un),t(te,ia),t(ia,Yn),t(te,Jn),m(e,ol,i),c(Te,e,i),m(e,nl,i),m(e,rt,i),t(rt,Kn),m(e,sl,i),c(Le,e,i),m(e,rl,i),m(e,y,i),t(y,Qn),t(y,ma),t(ma,Vn),t(y,Zn),t(y,da),t(da,es),t(y,ts),t(y,ga),t(ga,as),t(y,ls),m(e,il,i),c(je,e,i),m(e,ml,i),m(e,ae,i),t(ae,os),t(ae,fa),t(fa,ns),t(ae,ss),dl=!0},p:li,i(e){dl||(p(ie.$$.fragment,e),p(me.$$.fragment,e),p(ge.$$.fragment,e),p(fe.$$.fragment,e),p(ue.$$.fragment,e),p(he.$$.fragment,e),p(ce.$$.fragment,e),p(pe.$$.fragment,e),p(_e.$$.fragment,e),p(ke.$$.fragment,e),p(ve.$$.fragment,e),p(Ee.$$.fragment,e),p($e.$$.fragment,e),p(we.$$.fragment,e),p(Me.$$.fragment,e),p(ye.$$.fragment,e),p(xe.$$.fragment,e),p(Te.$$.fragment,e),p(Le.$$.fragment,e),p(je.$$.fragment,e),dl=!0)},o(e){_(ie.$$.fragment,e),_(me.$$.fragment,e),_(ge.$$.fragment,e),_(fe.$$.fragment,e),_(ue.$$.fragment,e),_(he.$$.fragment,e),_(ce.$$.fragment,e),_(pe.$$.fragment,e),_(_e.$$.fragment,e),_(ke.$$.fragment,e),_(ve.$$.fragment,e),_(Ee.$$.fragment,e),_($e.$$.fragment,e),_(we.$$.fragment,e),_(Me.$$.fragment,e),_(ye.$$.fragment,e),_(xe.$$.fragment,e),_(Te.$$.fragment,e),_(Le.$$.fragment,e),_(je.$$.fragment,e),dl=!1},d(e){a(z),e&&a(ua),e&&a(q),b(ie),e&&a(ha),b(me,e),e&&a(ca),e&&a(T),e&&a(pa),e&&a(C),b(ge),e&&a(_a),e&&a(ze),e&&a(ba),e&&a(D),b(fe),e&&a(ka),e&&a(qe),e&&a(va),e&&a(k),e&&a(Ea),e&&a($),e&&a($a),e&&a(R),e&&a(wa),b(ue,e),e&&a(Ma),e&&a(F),e&&a(ya),b(he,e),e&&a(xa),e&&a(Ae),e&&a(Ta),b(ce,e),e&&a(La),e&&a(w),e&&a(ja),b(pe,e),e&&a(za),e&&a(H),e&&a(qa),b(_e,e),e&&a(Ca),e&&a(L),e&&a(Da),e&&a(P),b(ke),e&&a(Pa),e&&a(Ne),e&&a(Oa),e&&a(W),e&&a(Xa),e&&a(Fe),e&&a(Ia),e&&a(O),b(ve),e&&a(Sa),e&&a(He),e&&a(Aa),e&&a(Y),e&&a(Na),e&&a(Ue),e&&a(Ba),e&&a(X),b(Ee),e&&a(Ra),e&&a(Ye),e&&a(Fa),e&&a(K),e&&a(Ha),e&&a(Qe),e&&a(Ga),e&&a(I),b($e),e&&a(Wa),e&&a(Ve),e&&a(Ua),e&&a(V),e&&a(Ya),e&&a(Z),e&&a(Ja),b(we,e),e&&a(Ka),e&&a(tt),e&&a(Qa),b(Me,e),e&&a(Va),e&&a(M),e&&a(Za),b(ye,e),e&&a(el),e&&a(S),b(xe),e&&a(tl),e&&a(at),e&&a(al),e&&a(v),e&&a(ll),e&&a(te),e&&a(ol),b(Te,e),e&&a(nl),e&&a(rt),e&&a(sl),b(Le,e),e&&a(rl),e&&a(y),e&&a(il),b(je,e),e&&a(ml),e&&a(ae)}}}const ri={local:"multilingual-models-for-inference",sections:[{local:"xlm",sections:[{local:"xlm-with-language-embeddings",title:"XLM with language embeddings"},{local:"xlm-without-language-embeddings",title:"XLM without language embeddings"}],title:"XLM"},{local:"bert",title:"BERT"},{local:"xlmroberta",title:"XLM-RoBERTa"},{local:"m2m100",title:"M2M100"},{local:"mbart",title:"MBart"}],title:"Multilingual models for inference"};function ii(xs){return oi(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ui extends Zr{constructor(z){super();ei(this,z,ii,si,ti,{})}}export{ui as default,ri as metadata};
