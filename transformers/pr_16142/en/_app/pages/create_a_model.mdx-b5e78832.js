import{S as ul,i as cl,s as ml,e as n,k as f,w as _,t as a,M as dl,c as i,d as s,m as u,a as l,x as g,h as r,b as c,F as t,g as p,y as v,q as b,o as y,B as $}from"../chunks/vendor-4833417e.js";import{T as ir}from"../chunks/Tip-fffd6df1.js";import{I as nt}from"../chunks/IconCopyLink-4b81c553.js";import{C}from"../chunks/CodeBlock-6a3d1b46.js";import{C as xs}from"../chunks/CodeBlockFw-27a176a0.js";import"../chunks/CopyButton-dacfbfaf.js";function hl(M){let m,j,d,k,q;return{c(){m=n("p"),j=a("You can also save your configuration file as a dictionary or even just the difference between your custom configuration attributes and the default configuration attributes! See the "),d=n("a"),k=a("configuration"),q=a(" documentation for more details."),this.h()},l(h){m=i(h,"P",{});var w=l(m);j=r(w,"You can also save your configuration file as a dictionary or even just the difference between your custom configuration attributes and the default configuration attributes! See the "),d=i(w,"A",{href:!0});var E=l(d);k=r(E,"configuration"),E.forEach(s),q=r(w," documentation for more details."),w.forEach(s),this.h()},h(){c(d,"href","main_classes/configuration")},m(h,w){p(h,m,w),t(m,j),t(m,d),t(d,k),t(m,q)},d(h){h&&s(m)}}}function _l(M){let m,j,d,k,q;return{c(){m=n("p"),j=a("Not every model supports a fast tokenizer. Take a look at this "),d=n("a"),k=a("table"),q=a(" to check if a model has fast tokenizer support."),this.h()},l(h){m=i(h,"P",{});var w=l(m);j=r(w,"Not every model supports a fast tokenizer. Take a look at this "),d=i(w,"A",{href:!0});var E=l(d);k=r(E,"table"),E.forEach(s),q=r(w," to check if a model has fast tokenizer support."),w.forEach(s),this.h()},h(){c(d,"href","index#supported-frameworks")},m(h,w){p(h,m,w),t(m,j),t(m,d),t(d,k),t(m,q)},d(h){h&&s(m)}}}function gl(M){let m,j,d,k,q,h,w,E,L,J,z;return{c(){m=n("p"),j=a("By default, "),d=n("a"),k=a("AutoTokenizer"),q=a(" will try to load a fast tokenizer. You can disable this behavior by setting "),h=n("code"),w=a("use_fast=False"),E=a(" in "),L=n("code"),J=a("from_pretrained"),z=a("."),this.h()},l(O){m=i(O,"P",{});var x=l(m);j=r(x,"By default, "),d=i(x,"A",{href:!0});var X=l(d);k=r(X,"AutoTokenizer"),X.forEach(s),q=r(x," will try to load a fast tokenizer. You can disable this behavior by setting "),h=i(x,"CODE",{});var it=l(h);w=r(it,"use_fast=False"),it.forEach(s),E=r(x," in "),L=i(x,"CODE",{});var lt=l(L);J=r(lt,"from_pretrained"),lt.forEach(s),z=r(x,"."),x.forEach(s),this.h()},h(){c(d,"href","/docs/transformers/pr_16142/en/model_doc/auto#transformers.AutoTokenizer")},m(O,x){p(O,m,x),t(m,j),t(m,d),t(d,k),t(m,q),t(m,h),t(h,w),t(m,E),t(m,L),t(L,J),t(m,z)},d(O){O&&s(m)}}}function vl(M){let m,j,d,k,q;return{c(){m=n("p"),j=a("If you aren\u2019t looking for any customization, just use the "),d=n("code"),k=a("from_pretrained"),q=a(" method to load a model\u2019s default feature extractor parameters.")},l(h){m=i(h,"P",{});var w=l(m);j=r(w,"If you aren\u2019t looking for any customization, just use the "),d=i(w,"CODE",{});var E=l(d);k=r(E,"from_pretrained"),E.forEach(s),q=r(w," method to load a model\u2019s default feature extractor parameters."),w.forEach(s)},m(h,w){p(h,m,w),t(m,j),t(m,d),t(d,k),t(m,q)},d(h){h&&s(m)}}}function bl(M){let m,j,d,k,q,h,w,E,L,J,z,O,x,X,it,lt,Qt,lr,pr,Ht,fr,ur,zs,D,Ut,cr,mr,Gt,dr,hr,Jt,_r,gr,Xt,vr,br,Kt,yr,Fs,N,K,Zt,Te,$r,es,wr,Ds,F,kr,pt,jr,qr,ts,Er,Tr,ss,xr,zr,as,Fr,Dr,rs,Br,Cr,Bs,V,Ar,ft,Pr,Mr,ut,Vr,Sr,Cs,xe,As,R,ct,Ir,Wr,mt,Lr,Or,Ps,Z,ze,Nr,os,Rr,Yr,Qr,Fe,Hr,ns,Ur,Gr,Ms,De,Vs,ee,Jr,dt,Xr,Kr,Ss,Be,Is,te,Zr,ht,eo,to,Ws,Ce,Ls,se,so,_t,ao,ro,Os,Ae,Ns,ae,Rs,Y,re,is,Pe,oo,ls,no,Ys,T,io,gt,lo,po,ps,fo,uo,vt,co,mo,Me,fs,ho,_o,Ve,us,go,vo,Se,cs,bo,yo,Qs,bt,$o,Hs,Ie,Us,yt,wo,Gs,oe,ko,$t,jo,qo,Js,We,Xs,wt,Eo,Ks,Le,Zs,Q,ne,ms,Oe,To,ds,xo,ea,ie,zo,hs,Fo,Do,ta,le,Bo,kt,Co,Ao,sa,Ne,aa,pe,Po,jt,Mo,Vo,ra,Re,oa,H,fe,_s,Ye,So,gs,Io,na,ue,Wo,qt,Lo,Oo,ia,ce,Et,Tt,No,Ro,Yo,S,xt,Qo,Ho,Qe,Uo,Go,vs,Jo,Xo,la,zt,Ko,pa,me,fa,de,Zo,bs,en,tn,ua,He,ca,he,sn,Ft,an,rn,ma,Ue,da,_e,on,Dt,nn,ln,ha,Ge,_a,ge,ga,U,ve,ys,Je,pn,$s,fn,va,A,un,Bt,cn,mn,Ct,dn,hn,At,_n,gn,ba,I,vn,Pt,bn,yn,Mt,$n,wn,ya,Xe,$a,be,wa,ye,kn,Vt,jn,qn,ka,Ke,ja,$e,En,St,Tn,xn,qa,Ze,Ea,G,we,ws,et,zn,ks,Fn,Ta,ke,Dn,It,Bn,Cn,xa,Wt,An,za,tt,Fa,Lt,Pn,Da,st,Ba,je,Mn,Ot,Vn,Sn,Ca,at,Aa,Nt,In,Pa;return h=new nt({}),Te=new nt({}),xe=new C({props:{code:`from transformers import DistilBertConfig

config = DistilBertConfig()
print(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;gelu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),De=new C({props:{code:`my_config = DistilBertConfig(activation="relu", attention_dropout=0.4)
print(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig(activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;relu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.4</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Be=new C({props:{code:'my_config = DistilBertConfig.from_pretrained("distilbert-base-uncased", activation="relu", attention_dropout=0.4)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)'}}),Ce=new C({props:{code:'my_config.save_pretrained(save_directory="./your_model_save_path")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config.save_pretrained(save_directory=<span class="hljs-string">&quot;./your_model_save_path&quot;</span>)'}}),Ae=new C({props:{code:'my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)'}}),ae=new ir({props:{$$slots:{default:[hl]},$$scope:{ctx:M}}}),Pe=new nt({}),Ie=new xs({props:{group1:{id:"pt",code:`from transformers import DistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
model = DistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel(my_config)`},group2:{id:"tf",code:`from transformers import TFDistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
tf_model = TFDistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel(my_config)`}}}),We=new xs({props:{group1:{id:"pt",code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'},group2:{id:"tf",code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}}),Le=new xs({props:{group1:{id:"pt",code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'},group2:{id:"tf",code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}}),Oe=new nt({}),Ne=new xs({props:{group1:{id:"pt",code:`from transformers import DistilBertForSequenceClassification

model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`},group2:{id:"tf",code:`from transformers import TFDistilBertForSequenceClassification

tf_model = TFDistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}}),Re=new xs({props:{group1:{id:"pt",code:`from transformers import DistilBertForQuestionAnswering

model = DistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`},group2:{id:"tf",code:`from transformers import TFDistilBertForQuestionAnswering

tf_model = TFDistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}}),Ye=new nt({}),me=new ir({props:{warning:"&lcub;true}",$$slots:{default:[_l]},$$scope:{ctx:M}}}),He=new C({props:{code:`from transformers import DistilBertTokenizer

my_tokenizer = DistilBertTokenizer(vocab_file="my_vocab_file.txt", do_lower_case=False, padding_side="left")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>my_tokenizer = DistilBertTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>, do_lower_case=<span class="hljs-literal">False</span>, padding_side=<span class="hljs-string">&quot;left&quot;</span>)`}}),Ue=new C({props:{code:`from transformers import DistilBertTokenizer

slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>slow_tokenizer = DistilBertTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),Ge=new C({props:{code:`from transformers import DistilBertTokenizerFast

fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizerFast

<span class="hljs-meta">&gt;&gt;&gt; </span>fast_tokenizer = DistilBertTokenizerFast.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),ge=new ir({props:{$$slots:{default:[gl]},$$scope:{ctx:M}}}),Je=new nt({}),Xe=new C({props:{code:`from transformers import ViTFeatureExtractor

vit_extractor = ViTFeatureExtractor()
print(vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>vit_extractor = ViTFeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-number">2</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),be=new ir({props:{$$slots:{default:[vl]},$$scope:{ctx:M}}}),Ke=new C({props:{code:`from transformers import ViTFeatureExtractor

my_vit_extractor = ViTFeatureExtractor(resample="PIL.Image.BOX", do_normalize=False, image_mean=[0.3, 0.3, 0.3])
print(my_vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>my_vit_extractor = ViTFeatureExtractor(resample=<span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>, do_normalize=<span class="hljs-literal">False</span>, image_mean=[<span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: false,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),Ze=new C({props:{code:`from transformers import Wav2Vec2FeatureExtractor

w2v2_extractor = Wav2Vec2FeatureExtractor()
print(w2v2_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>w2v2_extractor = Wav2Vec2FeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;Wav2Vec2FeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;feature_size&quot;</span>: <span class="hljs-number">1</span>,
  <span class="hljs-string">&quot;padding_side&quot;</span>: <span class="hljs-string">&quot;right&quot;</span>,
  <span class="hljs-string">&quot;padding_value&quot;</span>: <span class="hljs-number">0.0</span>,
  <span class="hljs-string">&quot;return_attention_mask&quot;</span>: false,
  <span class="hljs-string">&quot;sampling_rate&quot;</span>: <span class="hljs-number">16000</span>
}`}}),et=new nt({}),tt=new C({props:{code:`from transformers import Wav2Vec2FeatureExtractor

feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = Wav2Vec2FeatureExtractor(padding_value=<span class="hljs-number">1.0</span>, do_normalize=<span class="hljs-literal">True</span>)`}}),st=new C({props:{code:`from transformers import Wav2Vec2CTCTokenizer

tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2CTCTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = Wav2Vec2CTCTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>)`}}),at=new C({props:{code:`from transformers import Wav2Vec2Processor

processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2Processor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`}}),{c(){m=n("meta"),j=f(),d=n("h1"),k=n("a"),q=n("span"),_(h.$$.fragment),w=f(),E=n("span"),L=a("Create a custom model"),J=f(),z=n("p"),O=a("An "),x=n("a"),X=n("code"),it=a("AutoClass"),lt=a(" automatically infers the model architecture and downloads pretrained configuration and weights. Generally, we recommend using an "),Qt=n("code"),lr=a("AutoClass"),pr=a(" to produce checkpoint-agnostic code. But users who want more control over specific model parameters can create a custom \u{1F917} Transformers model from just a few base classes. This could be particularly useful for anyone who is interested in studying, training or experimenting with a \u{1F917} Transformers model. In this guide, dive deeper into creating a custom model without an "),Ht=n("code"),fr=a("AutoClass"),ur=a(". Learn how to:"),zs=f(),D=n("ul"),Ut=n("li"),cr=a("Load and customize a model configuration."),mr=f(),Gt=n("li"),dr=a("Create a model architecture."),hr=f(),Jt=n("li"),_r=a("Create a slow and fast tokenizer for text."),gr=f(),Xt=n("li"),vr=a("Create a feature extractor for audio or image tasks."),br=f(),Kt=n("li"),yr=a("Create a processor for multimodal tasks."),Fs=f(),N=n("h2"),K=n("a"),Zt=n("span"),_(Te.$$.fragment),$r=f(),es=n("span"),wr=a("Configuration"),Ds=f(),F=n("p"),kr=a("A "),pt=n("a"),jr=a("configuration"),qr=a(" refers to a model\u2019s specific attributes. Each model configuration has different attributes; for instance, all NLP models have the "),ts=n("code"),Er=a("hidden_size"),Tr=a(", "),ss=n("code"),xr=a("num_attention_heads"),zr=a(", "),as=n("code"),Fr=a("num_hidden_layers"),Dr=a(" and "),rs=n("code"),Br=a("vocab_size"),Cr=a(" attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with."),Bs=f(),V=n("p"),Ar=a("Get a closer look at "),ft=n("a"),Pr=a("DistilBERT"),Mr=a(" by accessing "),ut=n("a"),Vr=a("DistilBertConfig"),Sr=a(" to inspect it\u2019s attributes:"),Cs=f(),_(xe.$$.fragment),As=f(),R=n("p"),ct=n("a"),Ir=a("DistilBertConfig"),Wr=a(" displays all the default attributes used to build a base "),mt=n("a"),Lr=a("DistilBertModel"),Or=a(". All attributes are customizable, creating space for experimentation. For example, you can customize a default model to:"),Ps=f(),Z=n("ul"),ze=n("li"),Nr=a("Try a different activation function with the "),os=n("code"),Rr=a("activation"),Yr=a(" parameter."),Qr=f(),Fe=n("li"),Hr=a("Use a higher dropout ratio for the attention probabilities with the "),ns=n("code"),Ur=a("attention_dropout"),Gr=a(" parameter."),Ms=f(),_(De.$$.fragment),Vs=f(),ee=n("p"),Jr=a("Pretrained model attributes can be modified in the "),dt=n("a"),Xr=a("from_pretrained()"),Kr=a(" function:"),Ss=f(),_(Be.$$.fragment),Is=f(),te=n("p"),Zr=a("Once you are satisfied with your model configuration, you can save it with "),ht=n("a"),eo=a("save_pretrained()"),to=a(". Your configuration file is stored as a JSON file in the specified save directory:"),Ws=f(),_(Ce.$$.fragment),Ls=f(),se=n("p"),so=a("To reuse the configuration file, load it with "),_t=n("a"),ao=a("from_pretrained()"),ro=a(":"),Os=f(),_(Ae.$$.fragment),Ns=f(),_(ae.$$.fragment),Rs=f(),Y=n("h2"),re=n("a"),is=n("span"),_(Pe.$$.fragment),oo=f(),ls=n("span"),no=a("Model"),Ys=f(),T=n("p"),io=a("The next step is to create a "),gt=n("a"),lo=a("model"),po=a(". The model - also loosely referred to as the architecture - defines what each layer is doing and what operations are happening. Attributes like "),ps=n("code"),fo=a("num_hidden_layers"),uo=a(" from the configuration are used to define the architecture. Every model shares the base class "),vt=n("a"),co=a("PreTrainedModel"),mo=a(" and a few common methods like resizing input embeddings and pruning self-attention heads. In addition, all models are also either a "),Me=n("a"),fs=n("code"),ho=a("torch.nn.Module"),_o=a(", "),Ve=n("a"),us=n("code"),go=a("tf.keras.Model"),vo=a(" or "),Se=n("a"),cs=n("code"),bo=a("flax.linen.Module"),yo=a(" subclass. This means models are compatible with each of their respective framework\u2019s usage."),Qs=f(),bt=n("p"),$o=a("Load your custom configuration attributes into the model:"),Hs=f(),_(Ie.$$.fragment),Us=f(),yt=n("p"),wo=a("This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),Gs=f(),oe=n("p"),ko=a("Create a pretrained model with "),$t=n("a"),jo=a("from_pretrained()"),qo=a(":"),Js=f(),_(We.$$.fragment),Xs=f(),wt=n("p"),Eo=a("When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),Ks=f(),_(Le.$$.fragment),Zs=f(),Q=n("h3"),ne=n("a"),ms=n("span"),_(Oe.$$.fragment),To=f(),ds=n("span"),xo=a("Model heads"),ea=f(),ie=n("p"),zo=a("At this point, you have a base DistilBERT model which outputs the "),hs=n("em"),Fo=a("hidden states"),Do=a(". The hidden states are passed as inputs to a model head to produce the final output. \u{1F917} Transformers provides a different model head for each task as long as a model supports the task (i.e., you can\u2019t use DistilBERT for a sequence-to-sequence task like translation)."),ta=f(),le=n("p"),Bo=a("For example, "),kt=n("a"),Co=a("DistilBertForSequenceClassification"),Ao=a(" is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),sa=f(),_(Ne.$$.fragment),aa=f(),pe=n("p"),Po=a("Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),jt=n("a"),Mo=a("DistilBertForQuestionAnswering"),Vo=a(" model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),ra=f(),_(Re.$$.fragment),oa=f(),H=n("h2"),fe=n("a"),_s=n("span"),_(Ye.$$.fragment),So=f(),gs=n("span"),Io=a("Tokenizer"),na=f(),ue=n("p"),Wo=a("The last base class you need before using a model for textual data is a "),qt=n("a"),Lo=a("tokenizer"),Oo=a(" to convert raw text to tensors. There are two types of tokenizers you can use with \u{1F917} Transformers:"),ia=f(),ce=n("ul"),Et=n("li"),Tt=n("a"),No=a("PreTrainedTokenizer"),Ro=a(": a Python implementation of a tokenizer."),Yo=f(),S=n("li"),xt=n("a"),Qo=a("PreTrainedTokenizerFast"),Ho=a(": a tokenizer from our Rust-based "),Qe=n("a"),Uo=a("\u{1F917} Tokenizer"),Go=a(" library. This tokenizer type is significantly faster - especially during batch tokenization - due to it\u2019s Rust implementation. The fast tokenizer also offers additional methods like "),vs=n("em"),Jo=a("offset mapping"),Xo=a(" which maps tokens to their original words or characters."),la=f(),zt=n("p"),Ko=a("Both tokenizers support common methods such as encoding and decoding, adding new tokens, and managing special tokens."),pa=f(),_(me.$$.fragment),fa=f(),de=n("p"),Zo=a("If you trained your own tokenizer, you can create one from your "),bs=n("em"),en=a("vocabulary"),tn=a(" file:"),ua=f(),_(He.$$.fragment),ca=f(),he=n("p"),sn=a("It is important to remember the vocabulary from a custom tokenizer will be different from the vocabulary generated by a pretrained model\u2019s tokenizer. You need to use a pretrained model\u2019s vocabulary if you are using a pretrained model, otherwise the inputs won\u2019t make sense. Create a tokenizer with a pretrained model\u2019s vocabulary with the "),Ft=n("a"),an=a("DistilBertTokenizer"),rn=a(" class:"),ma=f(),_(Ue.$$.fragment),da=f(),_e=n("p"),on=a("Create a fast tokenizer with the "),Dt=n("a"),nn=a("DistilBertTokenizerFast"),ln=a(" class:"),ha=f(),_(Ge.$$.fragment),_a=f(),_(ge.$$.fragment),ga=f(),U=n("h2"),ve=n("a"),ys=n("span"),_(Je.$$.fragment),pn=f(),$s=n("span"),fn=a("Feature Extractor"),va=f(),A=n("p"),un=a("A feature extractor processes audio or image inputs. It inherits from the base "),Bt=n("a"),cn=a("FeatureExtractionMixin"),mn=a(" class, and may also inherit from the "),Ct=n("a"),dn=a("ImageFeatureExtractionMixin"),hn=a(" class for processing image features or the "),At=n("a"),_n=a("SequenceFeatureExtractor"),gn=a(" class for processing audio inputs."),ba=f(),I=n("p"),vn=a("Depending on whether you are working on an audio or vision task, create a feature extractor associated with the model you\u2019re using. For example, create a default "),Pt=n("a"),bn=a("ViTFeatureExtractor"),yn=a(" if you are using "),Mt=n("a"),$n=a("ViT"),wn=a(" for image classification:"),ya=f(),_(Xe.$$.fragment),$a=f(),_(be.$$.fragment),wa=f(),ye=n("p"),kn=a("Modify any of the "),Vt=n("a"),jn=a("ViTFeatureExtractor"),qn=a(" parameters to create your custom feature extractor:"),ka=f(),_(Ke.$$.fragment),ja=f(),$e=n("p"),En=a("For audio inputs, you can create a "),St=n("a"),Tn=a("Wav2Vec2FeatureExtractor"),xn=a(" and customize the parameters in a similar way:"),qa=f(),_(Ze.$$.fragment),Ea=f(),G=n("h2"),we=n("a"),ws=n("span"),_(et.$$.fragment),zn=f(),ks=n("span"),Fn=a("Processor"),Ta=f(),ke=n("p"),Dn=a("For models that support multimodal tasks, \u{1F917} Transformers offers a processor class that conveniently wraps a feature extractor and tokenizer into a single object. For example, let\u2019s use the "),It=n("a"),Bn=a("Wav2Vec2Processor"),Cn=a(" for an automatic speech recognition task (ASR). ASR transcribes audio to text, so you will need a feature extractor and a tokenizer."),xa=f(),Wt=n("p"),An=a("Create a feature extractor to handle the audio inputs:"),za=f(),_(tt.$$.fragment),Fa=f(),Lt=n("p"),Pn=a("Create a tokenizer to handle the text inputs:"),Da=f(),_(st.$$.fragment),Ba=f(),je=n("p"),Mn=a("Combine the feature extractor and tokenizer in "),Ot=n("a"),Vn=a("Wav2Vec2Processor"),Sn=a(":"),Ca=f(),_(at.$$.fragment),Aa=f(),Nt=n("p"),In=a("With two basic classes - configuration and model - and an additional preprocessing class (tokenizer, feature extractor, or processor), you can create any of the models supported by \u{1F917} Transformers. Each of these base classes are configurable, allowing you to use the specific attributes you want. You can easily setup a model for training or modify an existing pretrained model to fine-tune."),this.h()},l(e){const o=dl('[data-svelte="svelte-1phssyn"]',document.head);m=i(o,"META",{name:!0,content:!0}),o.forEach(s),j=u(e),d=i(e,"H1",{class:!0});var rt=l(d);k=i(rt,"A",{id:!0,class:!0,href:!0});var js=l(k);q=i(js,"SPAN",{});var qs=l(q);g(h.$$.fragment,qs),qs.forEach(s),js.forEach(s),w=u(rt),E=i(rt,"SPAN",{});var Es=l(E);L=r(Es,"Create a custom model"),Es.forEach(s),rt.forEach(s),J=u(e),z=i(e,"P",{});var qe=l(z);O=r(qe,"An "),x=i(qe,"A",{href:!0});var Ln=l(x);X=i(Ln,"CODE",{});var On=l(X);it=r(On,"AutoClass"),On.forEach(s),Ln.forEach(s),lt=r(qe," automatically infers the model architecture and downloads pretrained configuration and weights. Generally, we recommend using an "),Qt=i(qe,"CODE",{});var Nn=l(Qt);lr=r(Nn,"AutoClass"),Nn.forEach(s),pr=r(qe," to produce checkpoint-agnostic code. But users who want more control over specific model parameters can create a custom \u{1F917} Transformers model from just a few base classes. This could be particularly useful for anyone who is interested in studying, training or experimenting with a \u{1F917} Transformers model. In this guide, dive deeper into creating a custom model without an "),Ht=i(qe,"CODE",{});var Rn=l(Ht);fr=r(Rn,"AutoClass"),Rn.forEach(s),ur=r(qe,". Learn how to:"),qe.forEach(s),zs=u(e),D=i(e,"UL",{});var W=l(D);Ut=i(W,"LI",{});var Yn=l(Ut);cr=r(Yn,"Load and customize a model configuration."),Yn.forEach(s),mr=u(W),Gt=i(W,"LI",{});var Qn=l(Gt);dr=r(Qn,"Create a model architecture."),Qn.forEach(s),hr=u(W),Jt=i(W,"LI",{});var Hn=l(Jt);_r=r(Hn,"Create a slow and fast tokenizer for text."),Hn.forEach(s),gr=u(W),Xt=i(W,"LI",{});var Un=l(Xt);vr=r(Un,"Create a feature extractor for audio or image tasks."),Un.forEach(s),br=u(W),Kt=i(W,"LI",{});var Gn=l(Kt);yr=r(Gn,"Create a processor for multimodal tasks."),Gn.forEach(s),W.forEach(s),Fs=u(e),N=i(e,"H2",{class:!0});var Ma=l(N);K=i(Ma,"A",{id:!0,class:!0,href:!0});var Jn=l(K);Zt=i(Jn,"SPAN",{});var Xn=l(Zt);g(Te.$$.fragment,Xn),Xn.forEach(s),Jn.forEach(s),$r=u(Ma),es=i(Ma,"SPAN",{});var Kn=l(es);wr=r(Kn,"Configuration"),Kn.forEach(s),Ma.forEach(s),Ds=u(e),F=i(e,"P",{});var P=l(F);kr=r(P,"A "),pt=i(P,"A",{href:!0});var Zn=l(pt);jr=r(Zn,"configuration"),Zn.forEach(s),qr=r(P," refers to a model\u2019s specific attributes. Each model configuration has different attributes; for instance, all NLP models have the "),ts=i(P,"CODE",{});var ei=l(ts);Er=r(ei,"hidden_size"),ei.forEach(s),Tr=r(P,", "),ss=i(P,"CODE",{});var ti=l(ss);xr=r(ti,"num_attention_heads"),ti.forEach(s),zr=r(P,", "),as=i(P,"CODE",{});var si=l(as);Fr=r(si,"num_hidden_layers"),si.forEach(s),Dr=r(P," and "),rs=i(P,"CODE",{});var ai=l(rs);Br=r(ai,"vocab_size"),ai.forEach(s),Cr=r(P," attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with."),P.forEach(s),Bs=u(e),V=i(e,"P",{});var Rt=l(V);Ar=r(Rt,"Get a closer look at "),ft=i(Rt,"A",{href:!0});var ri=l(ft);Pr=r(ri,"DistilBERT"),ri.forEach(s),Mr=r(Rt," by accessing "),ut=i(Rt,"A",{href:!0});var oi=l(ut);Vr=r(oi,"DistilBertConfig"),oi.forEach(s),Sr=r(Rt," to inspect it\u2019s attributes:"),Rt.forEach(s),Cs=u(e),g(xe.$$.fragment,e),As=u(e),R=i(e,"P",{});var Ts=l(R);ct=i(Ts,"A",{href:!0});var ni=l(ct);Ir=r(ni,"DistilBertConfig"),ni.forEach(s),Wr=r(Ts," displays all the default attributes used to build a base "),mt=i(Ts,"A",{href:!0});var ii=l(mt);Lr=r(ii,"DistilBertModel"),ii.forEach(s),Or=r(Ts,". All attributes are customizable, creating space for experimentation. For example, you can customize a default model to:"),Ts.forEach(s),Ps=u(e),Z=i(e,"UL",{});var Va=l(Z);ze=i(Va,"LI",{});var Sa=l(ze);Nr=r(Sa,"Try a different activation function with the "),os=i(Sa,"CODE",{});var li=l(os);Rr=r(li,"activation"),li.forEach(s),Yr=r(Sa," parameter."),Sa.forEach(s),Qr=u(Va),Fe=i(Va,"LI",{});var Ia=l(Fe);Hr=r(Ia,"Use a higher dropout ratio for the attention probabilities with the "),ns=i(Ia,"CODE",{});var pi=l(ns);Ur=r(pi,"attention_dropout"),pi.forEach(s),Gr=r(Ia," parameter."),Ia.forEach(s),Va.forEach(s),Ms=u(e),g(De.$$.fragment,e),Vs=u(e),ee=i(e,"P",{});var Wa=l(ee);Jr=r(Wa,"Pretrained model attributes can be modified in the "),dt=i(Wa,"A",{href:!0});var fi=l(dt);Xr=r(fi,"from_pretrained()"),fi.forEach(s),Kr=r(Wa," function:"),Wa.forEach(s),Ss=u(e),g(Be.$$.fragment,e),Is=u(e),te=i(e,"P",{});var La=l(te);Zr=r(La,"Once you are satisfied with your model configuration, you can save it with "),ht=i(La,"A",{href:!0});var ui=l(ht);eo=r(ui,"save_pretrained()"),ui.forEach(s),to=r(La,". Your configuration file is stored as a JSON file in the specified save directory:"),La.forEach(s),Ws=u(e),g(Ce.$$.fragment,e),Ls=u(e),se=i(e,"P",{});var Oa=l(se);so=r(Oa,"To reuse the configuration file, load it with "),_t=i(Oa,"A",{href:!0});var ci=l(_t);ao=r(ci,"from_pretrained()"),ci.forEach(s),ro=r(Oa,":"),Oa.forEach(s),Os=u(e),g(Ae.$$.fragment,e),Ns=u(e),g(ae.$$.fragment,e),Rs=u(e),Y=i(e,"H2",{class:!0});var Na=l(Y);re=i(Na,"A",{id:!0,class:!0,href:!0});var mi=l(re);is=i(mi,"SPAN",{});var di=l(is);g(Pe.$$.fragment,di),di.forEach(s),mi.forEach(s),oo=u(Na),ls=i(Na,"SPAN",{});var hi=l(ls);no=r(hi,"Model"),hi.forEach(s),Na.forEach(s),Ys=u(e),T=i(e,"P",{});var B=l(T);io=r(B,"The next step is to create a "),gt=i(B,"A",{href:!0});var _i=l(gt);lo=r(_i,"model"),_i.forEach(s),po=r(B,". The model - also loosely referred to as the architecture - defines what each layer is doing and what operations are happening. Attributes like "),ps=i(B,"CODE",{});var gi=l(ps);fo=r(gi,"num_hidden_layers"),gi.forEach(s),uo=r(B," from the configuration are used to define the architecture. Every model shares the base class "),vt=i(B,"A",{href:!0});var vi=l(vt);co=r(vi,"PreTrainedModel"),vi.forEach(s),mo=r(B," and a few common methods like resizing input embeddings and pruning self-attention heads. In addition, all models are also either a "),Me=i(B,"A",{href:!0,rel:!0});var bi=l(Me);fs=i(bi,"CODE",{});var yi=l(fs);ho=r(yi,"torch.nn.Module"),yi.forEach(s),bi.forEach(s),_o=r(B,", "),Ve=i(B,"A",{href:!0,rel:!0});var $i=l(Ve);us=i($i,"CODE",{});var wi=l(us);go=r(wi,"tf.keras.Model"),wi.forEach(s),$i.forEach(s),vo=r(B," or "),Se=i(B,"A",{href:!0,rel:!0});var ki=l(Se);cs=i(ki,"CODE",{});var ji=l(cs);bo=r(ji,"flax.linen.Module"),ji.forEach(s),ki.forEach(s),yo=r(B," subclass. This means models are compatible with each of their respective framework\u2019s usage."),B.forEach(s),Qs=u(e),bt=i(e,"P",{});var qi=l(bt);$o=r(qi,"Load your custom configuration attributes into the model:"),qi.forEach(s),Hs=u(e),g(Ie.$$.fragment,e),Us=u(e),yt=i(e,"P",{});var Ei=l(yt);wo=r(Ei,"This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),Ei.forEach(s),Gs=u(e),oe=i(e,"P",{});var Ra=l(oe);ko=r(Ra,"Create a pretrained model with "),$t=i(Ra,"A",{href:!0});var Ti=l($t);jo=r(Ti,"from_pretrained()"),Ti.forEach(s),qo=r(Ra,":"),Ra.forEach(s),Js=u(e),g(We.$$.fragment,e),Xs=u(e),wt=i(e,"P",{});var xi=l(wt);Eo=r(xi,"When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),xi.forEach(s),Ks=u(e),g(Le.$$.fragment,e),Zs=u(e),Q=i(e,"H3",{class:!0});var Ya=l(Q);ne=i(Ya,"A",{id:!0,class:!0,href:!0});var zi=l(ne);ms=i(zi,"SPAN",{});var Fi=l(ms);g(Oe.$$.fragment,Fi),Fi.forEach(s),zi.forEach(s),To=u(Ya),ds=i(Ya,"SPAN",{});var Di=l(ds);xo=r(Di,"Model heads"),Di.forEach(s),Ya.forEach(s),ea=u(e),ie=i(e,"P",{});var Qa=l(ie);zo=r(Qa,"At this point, you have a base DistilBERT model which outputs the "),hs=i(Qa,"EM",{});var Bi=l(hs);Fo=r(Bi,"hidden states"),Bi.forEach(s),Do=r(Qa,". The hidden states are passed as inputs to a model head to produce the final output. \u{1F917} Transformers provides a different model head for each task as long as a model supports the task (i.e., you can\u2019t use DistilBERT for a sequence-to-sequence task like translation)."),Qa.forEach(s),ta=u(e),le=i(e,"P",{});var Ha=l(le);Bo=r(Ha,"For example, "),kt=i(Ha,"A",{href:!0});var Ci=l(kt);Co=r(Ci,"DistilBertForSequenceClassification"),Ci.forEach(s),Ao=r(Ha," is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),Ha.forEach(s),sa=u(e),g(Ne.$$.fragment,e),aa=u(e),pe=i(e,"P",{});var Ua=l(pe);Po=r(Ua,"Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),jt=i(Ua,"A",{href:!0});var Ai=l(jt);Mo=r(Ai,"DistilBertForQuestionAnswering"),Ai.forEach(s),Vo=r(Ua," model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),Ua.forEach(s),ra=u(e),g(Re.$$.fragment,e),oa=u(e),H=i(e,"H2",{class:!0});var Ga=l(H);fe=i(Ga,"A",{id:!0,class:!0,href:!0});var Pi=l(fe);_s=i(Pi,"SPAN",{});var Mi=l(_s);g(Ye.$$.fragment,Mi),Mi.forEach(s),Pi.forEach(s),So=u(Ga),gs=i(Ga,"SPAN",{});var Vi=l(gs);Io=r(Vi,"Tokenizer"),Vi.forEach(s),Ga.forEach(s),na=u(e),ue=i(e,"P",{});var Ja=l(ue);Wo=r(Ja,"The last base class you need before using a model for textual data is a "),qt=i(Ja,"A",{href:!0});var Si=l(qt);Lo=r(Si,"tokenizer"),Si.forEach(s),Oo=r(Ja," to convert raw text to tensors. There are two types of tokenizers you can use with \u{1F917} Transformers:"),Ja.forEach(s),ia=u(e),ce=i(e,"UL",{});var Xa=l(ce);Et=i(Xa,"LI",{});var Wn=l(Et);Tt=i(Wn,"A",{href:!0});var Ii=l(Tt);No=r(Ii,"PreTrainedTokenizer"),Ii.forEach(s),Ro=r(Wn,": a Python implementation of a tokenizer."),Wn.forEach(s),Yo=u(Xa),S=i(Xa,"LI",{});var ot=l(S);xt=i(ot,"A",{href:!0});var Wi=l(xt);Qo=r(Wi,"PreTrainedTokenizerFast"),Wi.forEach(s),Ho=r(ot,": a tokenizer from our Rust-based "),Qe=i(ot,"A",{href:!0,rel:!0});var Li=l(Qe);Uo=r(Li,"\u{1F917} Tokenizer"),Li.forEach(s),Go=r(ot," library. This tokenizer type is significantly faster - especially during batch tokenization - due to it\u2019s Rust implementation. The fast tokenizer also offers additional methods like "),vs=i(ot,"EM",{});var Oi=l(vs);Jo=r(Oi,"offset mapping"),Oi.forEach(s),Xo=r(ot," which maps tokens to their original words or characters."),ot.forEach(s),Xa.forEach(s),la=u(e),zt=i(e,"P",{});var Ni=l(zt);Ko=r(Ni,"Both tokenizers support common methods such as encoding and decoding, adding new tokens, and managing special tokens."),Ni.forEach(s),pa=u(e),g(me.$$.fragment,e),fa=u(e),de=i(e,"P",{});var Ka=l(de);Zo=r(Ka,"If you trained your own tokenizer, you can create one from your "),bs=i(Ka,"EM",{});var Ri=l(bs);en=r(Ri,"vocabulary"),Ri.forEach(s),tn=r(Ka," file:"),Ka.forEach(s),ua=u(e),g(He.$$.fragment,e),ca=u(e),he=i(e,"P",{});var Za=l(he);sn=r(Za,"It is important to remember the vocabulary from a custom tokenizer will be different from the vocabulary generated by a pretrained model\u2019s tokenizer. You need to use a pretrained model\u2019s vocabulary if you are using a pretrained model, otherwise the inputs won\u2019t make sense. Create a tokenizer with a pretrained model\u2019s vocabulary with the "),Ft=i(Za,"A",{href:!0});var Yi=l(Ft);an=r(Yi,"DistilBertTokenizer"),Yi.forEach(s),rn=r(Za," class:"),Za.forEach(s),ma=u(e),g(Ue.$$.fragment,e),da=u(e),_e=i(e,"P",{});var er=l(_e);on=r(er,"Create a fast tokenizer with the "),Dt=i(er,"A",{href:!0});var Qi=l(Dt);nn=r(Qi,"DistilBertTokenizerFast"),Qi.forEach(s),ln=r(er," class:"),er.forEach(s),ha=u(e),g(Ge.$$.fragment,e),_a=u(e),g(ge.$$.fragment,e),ga=u(e),U=i(e,"H2",{class:!0});var tr=l(U);ve=i(tr,"A",{id:!0,class:!0,href:!0});var Hi=l(ve);ys=i(Hi,"SPAN",{});var Ui=l(ys);g(Je.$$.fragment,Ui),Ui.forEach(s),Hi.forEach(s),pn=u(tr),$s=i(tr,"SPAN",{});var Gi=l($s);fn=r(Gi,"Feature Extractor"),Gi.forEach(s),tr.forEach(s),va=u(e),A=i(e,"P",{});var Ee=l(A);un=r(Ee,"A feature extractor processes audio or image inputs. It inherits from the base "),Bt=i(Ee,"A",{href:!0});var Ji=l(Bt);cn=r(Ji,"FeatureExtractionMixin"),Ji.forEach(s),mn=r(Ee," class, and may also inherit from the "),Ct=i(Ee,"A",{href:!0});var Xi=l(Ct);dn=r(Xi,"ImageFeatureExtractionMixin"),Xi.forEach(s),hn=r(Ee," class for processing image features or the "),At=i(Ee,"A",{href:!0});var Ki=l(At);_n=r(Ki,"SequenceFeatureExtractor"),Ki.forEach(s),gn=r(Ee," class for processing audio inputs."),Ee.forEach(s),ba=u(e),I=i(e,"P",{});var Yt=l(I);vn=r(Yt,"Depending on whether you are working on an audio or vision task, create a feature extractor associated with the model you\u2019re using. For example, create a default "),Pt=i(Yt,"A",{href:!0});var Zi=l(Pt);bn=r(Zi,"ViTFeatureExtractor"),Zi.forEach(s),yn=r(Yt," if you are using "),Mt=i(Yt,"A",{href:!0});var el=l(Mt);$n=r(el,"ViT"),el.forEach(s),wn=r(Yt," for image classification:"),Yt.forEach(s),ya=u(e),g(Xe.$$.fragment,e),$a=u(e),g(be.$$.fragment,e),wa=u(e),ye=i(e,"P",{});var sr=l(ye);kn=r(sr,"Modify any of the "),Vt=i(sr,"A",{href:!0});var tl=l(Vt);jn=r(tl,"ViTFeatureExtractor"),tl.forEach(s),qn=r(sr," parameters to create your custom feature extractor:"),sr.forEach(s),ka=u(e),g(Ke.$$.fragment,e),ja=u(e),$e=i(e,"P",{});var ar=l($e);En=r(ar,"For audio inputs, you can create a "),St=i(ar,"A",{href:!0});var sl=l(St);Tn=r(sl,"Wav2Vec2FeatureExtractor"),sl.forEach(s),xn=r(ar," and customize the parameters in a similar way:"),ar.forEach(s),qa=u(e),g(Ze.$$.fragment,e),Ea=u(e),G=i(e,"H2",{class:!0});var rr=l(G);we=i(rr,"A",{id:!0,class:!0,href:!0});var al=l(we);ws=i(al,"SPAN",{});var rl=l(ws);g(et.$$.fragment,rl),rl.forEach(s),al.forEach(s),zn=u(rr),ks=i(rr,"SPAN",{});var ol=l(ks);Fn=r(ol,"Processor"),ol.forEach(s),rr.forEach(s),Ta=u(e),ke=i(e,"P",{});var or=l(ke);Dn=r(or,"For models that support multimodal tasks, \u{1F917} Transformers offers a processor class that conveniently wraps a feature extractor and tokenizer into a single object. For example, let\u2019s use the "),It=i(or,"A",{href:!0});var nl=l(It);Bn=r(nl,"Wav2Vec2Processor"),nl.forEach(s),Cn=r(or," for an automatic speech recognition task (ASR). ASR transcribes audio to text, so you will need a feature extractor and a tokenizer."),or.forEach(s),xa=u(e),Wt=i(e,"P",{});var il=l(Wt);An=r(il,"Create a feature extractor to handle the audio inputs:"),il.forEach(s),za=u(e),g(tt.$$.fragment,e),Fa=u(e),Lt=i(e,"P",{});var ll=l(Lt);Pn=r(ll,"Create a tokenizer to handle the text inputs:"),ll.forEach(s),Da=u(e),g(st.$$.fragment,e),Ba=u(e),je=i(e,"P",{});var nr=l(je);Mn=r(nr,"Combine the feature extractor and tokenizer in "),Ot=i(nr,"A",{href:!0});var pl=l(Ot);Vn=r(pl,"Wav2Vec2Processor"),pl.forEach(s),Sn=r(nr,":"),nr.forEach(s),Ca=u(e),g(at.$$.fragment,e),Aa=u(e),Nt=i(e,"P",{});var fl=l(Nt);In=r(fl,"With two basic classes - configuration and model - and an additional preprocessing class (tokenizer, feature extractor, or processor), you can create any of the models supported by \u{1F917} Transformers. Each of these base classes are configurable, allowing you to use the specific attributes you want. You can easily setup a model for training or modify an existing pretrained model to fine-tune."),fl.forEach(s),this.h()},h(){c(m,"name","hf:doc:metadata"),c(m,"content",JSON.stringify(yl)),c(k,"id","create-a-custom-model"),c(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(k,"href","#create-a-custom-model"),c(d,"class","relative group"),c(x,"href","model_doc/auto"),c(K,"id","configuration"),c(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K,"href","#configuration"),c(N,"class","relative group"),c(pt,"href","main_classes/configuration"),c(ft,"href","model_doc/distilbert"),c(ut,"href","/docs/transformers/pr_16142/en/model_doc/distilbert#transformers.DistilBertConfig"),c(ct,"href","/docs/transformers/pr_16142/en/model_doc/distilbert#transformers.DistilBertConfig"),c(mt,"href","/docs/transformers/pr_16142/en/model_doc/distilbert#transformers.DistilBertModel"),c(dt,"href","/docs/transformers/pr_16142/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained"),c(ht,"href","/docs/transformers/pr_16142/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained"),c(_t,"href","/docs/transformers/pr_16142/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained"),c(re,"id","model"),c(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(re,"href","#model"),c(Y,"class","relative group"),c(gt,"href","main_classes/models"),c(vt,"href","/docs/transformers/pr_16142/en/main_classes/model#transformers.PreTrainedModel"),c(Me,"href","https://pytorch.org/docs/stable/generated/torch.nn.Module.html"),c(Me,"rel","nofollow"),c(Ve,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),c(Ve,"rel","nofollow"),c(Se,"href","https://flax.readthedocs.io/en/latest/flax.linen.html#module"),c(Se,"rel","nofollow"),c($t,"href","/docs/transformers/pr_16142/en/main_classes/model#transformers.PreTrainedModel.from_pretrained"),c(ne,"id","model-heads"),c(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ne,"href","#model-heads"),c(Q,"class","relative group"),c(kt,"href","/docs/transformers/pr_16142/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(jt,"href","/docs/transformers/pr_16142/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(fe,"id","tokenizer"),c(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fe,"href","#tokenizer"),c(H,"class","relative group"),c(qt,"href","main_classes/tokenizer"),c(Tt,"href","/docs/transformers/pr_16142/en/main_classes/tokenizer#transformers.PreTrainedTokenizer"),c(xt,"href","/docs/transformers/pr_16142/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"),c(Qe,"href","https://huggingface.co/docs/tokenizers/python/latest/"),c(Qe,"rel","nofollow"),c(Ft,"href","/docs/transformers/pr_16142/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(Dt,"href","/docs/transformers/pr_16142/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(ve,"id","feature-extractor"),c(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ve,"href","#feature-extractor"),c(U,"class","relative group"),c(Bt,"href","/docs/transformers/pr_16142/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"),c(Ct,"href","/docs/transformers/pr_16142/en/main_classes/feature_extractor#transformers.ImageFeatureExtractionMixin"),c(At,"href","/docs/transformers/pr_16142/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor"),c(Pt,"href","/docs/transformers/pr_16142/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Mt,"href","model_doc/vit"),c(Vt,"href","/docs/transformers/pr_16142/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(St,"href","/docs/transformers/pr_16142/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(we,"id","processor"),c(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(we,"href","#processor"),c(G,"class","relative group"),c(It,"href","/docs/transformers/pr_16142/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ot,"href","/docs/transformers/pr_16142/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor")},m(e,o){t(document.head,m),p(e,j,o),p(e,d,o),t(d,k),t(k,q),v(h,q,null),t(d,w),t(d,E),t(E,L),p(e,J,o),p(e,z,o),t(z,O),t(z,x),t(x,X),t(X,it),t(z,lt),t(z,Qt),t(Qt,lr),t(z,pr),t(z,Ht),t(Ht,fr),t(z,ur),p(e,zs,o),p(e,D,o),t(D,Ut),t(Ut,cr),t(D,mr),t(D,Gt),t(Gt,dr),t(D,hr),t(D,Jt),t(Jt,_r),t(D,gr),t(D,Xt),t(Xt,vr),t(D,br),t(D,Kt),t(Kt,yr),p(e,Fs,o),p(e,N,o),t(N,K),t(K,Zt),v(Te,Zt,null),t(N,$r),t(N,es),t(es,wr),p(e,Ds,o),p(e,F,o),t(F,kr),t(F,pt),t(pt,jr),t(F,qr),t(F,ts),t(ts,Er),t(F,Tr),t(F,ss),t(ss,xr),t(F,zr),t(F,as),t(as,Fr),t(F,Dr),t(F,rs),t(rs,Br),t(F,Cr),p(e,Bs,o),p(e,V,o),t(V,Ar),t(V,ft),t(ft,Pr),t(V,Mr),t(V,ut),t(ut,Vr),t(V,Sr),p(e,Cs,o),v(xe,e,o),p(e,As,o),p(e,R,o),t(R,ct),t(ct,Ir),t(R,Wr),t(R,mt),t(mt,Lr),t(R,Or),p(e,Ps,o),p(e,Z,o),t(Z,ze),t(ze,Nr),t(ze,os),t(os,Rr),t(ze,Yr),t(Z,Qr),t(Z,Fe),t(Fe,Hr),t(Fe,ns),t(ns,Ur),t(Fe,Gr),p(e,Ms,o),v(De,e,o),p(e,Vs,o),p(e,ee,o),t(ee,Jr),t(ee,dt),t(dt,Xr),t(ee,Kr),p(e,Ss,o),v(Be,e,o),p(e,Is,o),p(e,te,o),t(te,Zr),t(te,ht),t(ht,eo),t(te,to),p(e,Ws,o),v(Ce,e,o),p(e,Ls,o),p(e,se,o),t(se,so),t(se,_t),t(_t,ao),t(se,ro),p(e,Os,o),v(Ae,e,o),p(e,Ns,o),v(ae,e,o),p(e,Rs,o),p(e,Y,o),t(Y,re),t(re,is),v(Pe,is,null),t(Y,oo),t(Y,ls),t(ls,no),p(e,Ys,o),p(e,T,o),t(T,io),t(T,gt),t(gt,lo),t(T,po),t(T,ps),t(ps,fo),t(T,uo),t(T,vt),t(vt,co),t(T,mo),t(T,Me),t(Me,fs),t(fs,ho),t(T,_o),t(T,Ve),t(Ve,us),t(us,go),t(T,vo),t(T,Se),t(Se,cs),t(cs,bo),t(T,yo),p(e,Qs,o),p(e,bt,o),t(bt,$o),p(e,Hs,o),v(Ie,e,o),p(e,Us,o),p(e,yt,o),t(yt,wo),p(e,Gs,o),p(e,oe,o),t(oe,ko),t(oe,$t),t($t,jo),t(oe,qo),p(e,Js,o),v(We,e,o),p(e,Xs,o),p(e,wt,o),t(wt,Eo),p(e,Ks,o),v(Le,e,o),p(e,Zs,o),p(e,Q,o),t(Q,ne),t(ne,ms),v(Oe,ms,null),t(Q,To),t(Q,ds),t(ds,xo),p(e,ea,o),p(e,ie,o),t(ie,zo),t(ie,hs),t(hs,Fo),t(ie,Do),p(e,ta,o),p(e,le,o),t(le,Bo),t(le,kt),t(kt,Co),t(le,Ao),p(e,sa,o),v(Ne,e,o),p(e,aa,o),p(e,pe,o),t(pe,Po),t(pe,jt),t(jt,Mo),t(pe,Vo),p(e,ra,o),v(Re,e,o),p(e,oa,o),p(e,H,o),t(H,fe),t(fe,_s),v(Ye,_s,null),t(H,So),t(H,gs),t(gs,Io),p(e,na,o),p(e,ue,o),t(ue,Wo),t(ue,qt),t(qt,Lo),t(ue,Oo),p(e,ia,o),p(e,ce,o),t(ce,Et),t(Et,Tt),t(Tt,No),t(Et,Ro),t(ce,Yo),t(ce,S),t(S,xt),t(xt,Qo),t(S,Ho),t(S,Qe),t(Qe,Uo),t(S,Go),t(S,vs),t(vs,Jo),t(S,Xo),p(e,la,o),p(e,zt,o),t(zt,Ko),p(e,pa,o),v(me,e,o),p(e,fa,o),p(e,de,o),t(de,Zo),t(de,bs),t(bs,en),t(de,tn),p(e,ua,o),v(He,e,o),p(e,ca,o),p(e,he,o),t(he,sn),t(he,Ft),t(Ft,an),t(he,rn),p(e,ma,o),v(Ue,e,o),p(e,da,o),p(e,_e,o),t(_e,on),t(_e,Dt),t(Dt,nn),t(_e,ln),p(e,ha,o),v(Ge,e,o),p(e,_a,o),v(ge,e,o),p(e,ga,o),p(e,U,o),t(U,ve),t(ve,ys),v(Je,ys,null),t(U,pn),t(U,$s),t($s,fn),p(e,va,o),p(e,A,o),t(A,un),t(A,Bt),t(Bt,cn),t(A,mn),t(A,Ct),t(Ct,dn),t(A,hn),t(A,At),t(At,_n),t(A,gn),p(e,ba,o),p(e,I,o),t(I,vn),t(I,Pt),t(Pt,bn),t(I,yn),t(I,Mt),t(Mt,$n),t(I,wn),p(e,ya,o),v(Xe,e,o),p(e,$a,o),v(be,e,o),p(e,wa,o),p(e,ye,o),t(ye,kn),t(ye,Vt),t(Vt,jn),t(ye,qn),p(e,ka,o),v(Ke,e,o),p(e,ja,o),p(e,$e,o),t($e,En),t($e,St),t(St,Tn),t($e,xn),p(e,qa,o),v(Ze,e,o),p(e,Ea,o),p(e,G,o),t(G,we),t(we,ws),v(et,ws,null),t(G,zn),t(G,ks),t(ks,Fn),p(e,Ta,o),p(e,ke,o),t(ke,Dn),t(ke,It),t(It,Bn),t(ke,Cn),p(e,xa,o),p(e,Wt,o),t(Wt,An),p(e,za,o),v(tt,e,o),p(e,Fa,o),p(e,Lt,o),t(Lt,Pn),p(e,Da,o),v(st,e,o),p(e,Ba,o),p(e,je,o),t(je,Mn),t(je,Ot),t(Ot,Vn),t(je,Sn),p(e,Ca,o),v(at,e,o),p(e,Aa,o),p(e,Nt,o),t(Nt,In),Pa=!0},p(e,[o]){const rt={};o&2&&(rt.$$scope={dirty:o,ctx:e}),ae.$set(rt);const js={};o&2&&(js.$$scope={dirty:o,ctx:e}),me.$set(js);const qs={};o&2&&(qs.$$scope={dirty:o,ctx:e}),ge.$set(qs);const Es={};o&2&&(Es.$$scope={dirty:o,ctx:e}),be.$set(Es)},i(e){Pa||(b(h.$$.fragment,e),b(Te.$$.fragment,e),b(xe.$$.fragment,e),b(De.$$.fragment,e),b(Be.$$.fragment,e),b(Ce.$$.fragment,e),b(Ae.$$.fragment,e),b(ae.$$.fragment,e),b(Pe.$$.fragment,e),b(Ie.$$.fragment,e),b(We.$$.fragment,e),b(Le.$$.fragment,e),b(Oe.$$.fragment,e),b(Ne.$$.fragment,e),b(Re.$$.fragment,e),b(Ye.$$.fragment,e),b(me.$$.fragment,e),b(He.$$.fragment,e),b(Ue.$$.fragment,e),b(Ge.$$.fragment,e),b(ge.$$.fragment,e),b(Je.$$.fragment,e),b(Xe.$$.fragment,e),b(be.$$.fragment,e),b(Ke.$$.fragment,e),b(Ze.$$.fragment,e),b(et.$$.fragment,e),b(tt.$$.fragment,e),b(st.$$.fragment,e),b(at.$$.fragment,e),Pa=!0)},o(e){y(h.$$.fragment,e),y(Te.$$.fragment,e),y(xe.$$.fragment,e),y(De.$$.fragment,e),y(Be.$$.fragment,e),y(Ce.$$.fragment,e),y(Ae.$$.fragment,e),y(ae.$$.fragment,e),y(Pe.$$.fragment,e),y(Ie.$$.fragment,e),y(We.$$.fragment,e),y(Le.$$.fragment,e),y(Oe.$$.fragment,e),y(Ne.$$.fragment,e),y(Re.$$.fragment,e),y(Ye.$$.fragment,e),y(me.$$.fragment,e),y(He.$$.fragment,e),y(Ue.$$.fragment,e),y(Ge.$$.fragment,e),y(ge.$$.fragment,e),y(Je.$$.fragment,e),y(Xe.$$.fragment,e),y(be.$$.fragment,e),y(Ke.$$.fragment,e),y(Ze.$$.fragment,e),y(et.$$.fragment,e),y(tt.$$.fragment,e),y(st.$$.fragment,e),y(at.$$.fragment,e),Pa=!1},d(e){s(m),e&&s(j),e&&s(d),$(h),e&&s(J),e&&s(z),e&&s(zs),e&&s(D),e&&s(Fs),e&&s(N),$(Te),e&&s(Ds),e&&s(F),e&&s(Bs),e&&s(V),e&&s(Cs),$(xe,e),e&&s(As),e&&s(R),e&&s(Ps),e&&s(Z),e&&s(Ms),$(De,e),e&&s(Vs),e&&s(ee),e&&s(Ss),$(Be,e),e&&s(Is),e&&s(te),e&&s(Ws),$(Ce,e),e&&s(Ls),e&&s(se),e&&s(Os),$(Ae,e),e&&s(Ns),$(ae,e),e&&s(Rs),e&&s(Y),$(Pe),e&&s(Ys),e&&s(T),e&&s(Qs),e&&s(bt),e&&s(Hs),$(Ie,e),e&&s(Us),e&&s(yt),e&&s(Gs),e&&s(oe),e&&s(Js),$(We,e),e&&s(Xs),e&&s(wt),e&&s(Ks),$(Le,e),e&&s(Zs),e&&s(Q),$(Oe),e&&s(ea),e&&s(ie),e&&s(ta),e&&s(le),e&&s(sa),$(Ne,e),e&&s(aa),e&&s(pe),e&&s(ra),$(Re,e),e&&s(oa),e&&s(H),$(Ye),e&&s(na),e&&s(ue),e&&s(ia),e&&s(ce),e&&s(la),e&&s(zt),e&&s(pa),$(me,e),e&&s(fa),e&&s(de),e&&s(ua),$(He,e),e&&s(ca),e&&s(he),e&&s(ma),$(Ue,e),e&&s(da),e&&s(_e),e&&s(ha),$(Ge,e),e&&s(_a),$(ge,e),e&&s(ga),e&&s(U),$(Je),e&&s(va),e&&s(A),e&&s(ba),e&&s(I),e&&s(ya),$(Xe,e),e&&s($a),$(be,e),e&&s(wa),e&&s(ye),e&&s(ka),$(Ke,e),e&&s(ja),e&&s($e),e&&s(qa),$(Ze,e),e&&s(Ea),e&&s(G),$(et),e&&s(Ta),e&&s(ke),e&&s(xa),e&&s(Wt),e&&s(za),$(tt,e),e&&s(Fa),e&&s(Lt),e&&s(Da),$(st,e),e&&s(Ba),e&&s(je),e&&s(Ca),$(at,e),e&&s(Aa),e&&s(Nt)}}}const yl={local:"create-a-custom-model",sections:[{local:"configuration",title:"Configuration"},{local:"model",sections:[{local:"model-heads",title:"Model heads"}],title:"Model"},{local:"tokenizer",title:"Tokenizer"},{local:"feature-extractor",title:"Feature Extractor"},{local:"processor",title:"Processor"}],title:"Create a custom model"};function $l(M,m,j){let{fw:d}=m;return M.$$set=k=>{"fw"in k&&j(0,d=k.fw)},[d]}class xl extends ul{constructor(m){super();cl(this,m,$l,bl,ml,{fw:0})}}export{xl as default,yl as metadata};
