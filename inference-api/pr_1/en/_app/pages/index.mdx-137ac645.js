import{S as Yn,i as es,s as ts,e as r,k as c,w as dt,t as n,M as rs,c as a,d as t,m as f,a as l,x as pt,h as s,b as o,N as zo,F as e,g as p,y as gt,q as mt,o as vt,B as _t,v as as}from"../chunks/vendor-7c454903.js";import{T as ls}from"../chunks/Tip-735285fc.js";import{I as xt}from"../chunks/IconCopyLink-5457534b.js";function os(Ur){let v,z,E,P,M,$,b,q,re,B,T,ae,D,y,S;return{c(){v=r("p"),z=n("Please note however, that these models will not allow you ("),E=r("a"),P=n("tracking issue"),M=n("):"),$=c(),b=r("ul"),q=r("li"),re=n("To get full optimization"),B=c(),T=r("li"),ae=n("To run private models"),D=c(),y=r("li"),S=n("To get access to GPU inference"),this.h()},l(w){v=a(w,"P",{});var k=l(v);z=s(k,"Please note however, that these models will not allow you ("),E=a(k,"A",{href:!0,rel:!0});var Et=l(E);P=s(Et,"tracking issue"),Et.forEach(t),M=s(k,"):"),k.forEach(t),$=f(w),b=a(w,"UL",{});var x=l(b);q=a(x,"LI",{});var wt=l(q);re=s(wt,"To get full optimization"),wt.forEach(t),B=f(x),T=a(x,"LI",{});var le=l(T);ae=s(le,"To run private models"),le.forEach(t),D=f(x),y=a(x,"LI",{});var U=l(y);S=s(U,"To get access to GPU inference"),U.forEach(t),x.forEach(t),this.h()},h(){o(E,"href","https://github.com/huggingface/huggingface_hub/issues/85"),o(E,"rel","nofollow")},m(w,k){p(w,v,k),e(v,z),e(v,E),e(E,P),e(v,M),p(w,$,k),p(w,b,k),e(b,q),e(q,re),e(b,B),e(b,T),e(T,ae),e(b,D),e(b,y),e(y,S)},d(w){w&&t(v),w&&t($),w&&t(b)}}}function is(Ur){let v,z,E,P,M,$,b,q,re,B,T,ae,D,y,S,w,k,Et,x,wt,le,U,Bo,Rr,Q,Do,Gr,H,W,Nt,oe,na,qt,sa,Mr,g,ie,ca,Ut,fa,ha,ua,kt,da,Rt,pa,ga,Gt,ma,va,ne,_a,Mt,Ea,wa,ka,R,Aa,Ht,ya,Ia,Ot,ba,La,se,Pa,$a,Ta,ce,Sa,Ct,xa,Na,qa,fe,Ua,Ft,Ra,Ga,Ma,At,jt,Ha,Oa,Ca,zt,Fa,Hr,O,Z,Bt,he,ja,Dt,za,Or,ue,Qo,Cr,C,J,Qt,de,Ba,Wt,Da,Fr,K,pe,ge,Qa,me,Wa,Za,Ja,F,V,ve,Ka,Va,_e,Xa,Ya,el,yt,Ee,tl,rl,al,X,we,ll,ol,ke,il,nl,sl,Zt,Ae,cl,ye,fl,hl,jr,Y,zr,j,ee,Jt,Ie,ul,Kt,dl,Br,L,It,be,pl,m,Vt,Le,gl,ml,Xt,Pe,vl,_l,Yt,$e,El,wl,er,Te,kl,Al,tr,Se,yl,Il,rr,xe,bl,Ll,ar,Ne,Pl,$l,lr,qe,Tl,Sl,bt,Ue,xl,h,or,Re,Nl,ql,ir,Ge,Ul,Rl,nr,Me,Gl,Ml,sr,He,Hl,Ol,cr,Oe,Cl,Fl,fr,Ce,jl,zl,hr,Fe,Bl,Dl,ur,je,Ql,Wl,dr,Lt,Zl,Jl,pr,ze,Kl,Vl,gr,Be,Xl,Yl,mr,De,eo,to,vr,Qe,ro,ao,_r,We,lo,oo,Er,Ze,io,no,wr,Je,so,co,kr,Ke,fo,ho,Pt,Ve,uo,Xe,Ar,Ye,po,go,yr,et,mo,vo,$t,tt,_o,rt,Ir,at,Eo,wo,br,lt,ko,Ao,Tt,ot,yo,I,Lr,it,Io,bo,Pr,nt,Lo,Po,$r,st,$o,To,Tr,ct,So,xo,Sr,ft,No,qo,xr,ht,Uo,Dr;return $=new xt({}),k=new xt({}),oe=new xt({}),he=new xt({}),de=new xt({}),Y=new ls({props:{warning:!0,$$slots:{default:[os]},$$scope:{ctx:Ur}}}),Ie=new xt({}),{c(){v=r("meta"),z=c(),E=r("h1"),P=r("a"),M=r("span"),dt($.$$.fragment),b=c(),q=r("span"),re=n("\u{1F917} Accelerated Inference API"),B=c(),T=r("p"),ae=n(`Integrate into your apps over 20,000 pre-trained state of the art
models, or your own private models, via simple HTTP requests, with 2x to
10x faster inference than out of the box deployment, and scalability
built-in.`),D=c(),y=r("h2"),S=r("a"),w=r("span"),dt(k.$$.fragment),Et=c(),x=r("span"),wt=n("Hugging Face is trusted in production by over 5,000 companies"),le=c(),U=r("img"),Rr=c(),Q=r("img"),Gr=c(),H=r("h2"),W=r("a"),Nt=r("span"),dt(oe.$$.fragment),na=c(),qt=r("span"),sa=n("Main features:"),Mr=c(),g=r("ul"),ie=r("li"),ca=n("Leverage "),Ut=r("strong"),fa=n("20,000+ Transformer models"),ha=n(" (T5, Blenderbot, Bart, GPT-2, Pegasus...)"),ua=c(),kt=r("li"),da=n("Upload, manage and serve your "),Rt=r("strong"),pa=n("own models privately"),ga=c(),Gt=r("li"),ma=n("Run Classification, NER, Conversational, Summarization, Translation, Question-Answering, Embeddings Extraction tasks"),va=c(),ne=r("li"),_a=n("Get up to "),Mt=r("strong"),Ea=n("10x inference speedup"),wa=n(" to reduce user latency"),ka=c(),R=r("li"),Aa=n("Accelerated inference on "),Ht=r("strong"),ya=n("CPU"),Ia=n(" and "),Ot=r("strong"),ba=n("GPU"),La=n(" (GPU requires a "),se=r("a"),Pa=n("Startup or Enterprise plan"),$a=n(")"),Ta=c(),ce=r("li"),Sa=n("Run "),Ct=r("strong"),xa=n("large models"),Na=n(" that are challenging to deploy in production"),qa=c(),fe=r("li"),Ua=n("Scale to 1,000 requests per second with "),Ft=r("strong"),Ra=n("automatic scaling"),Ga=n(" built-in"),Ma=c(),At=r("li"),jt=r("strong"),Ha=n("Ship new NLP features faster"),Oa=n(" as new models become available"),Ca=c(),zt=r("li"),Fa=n("Build your business on a platform powered by the reference open source project in NLP"),Hr=c(),O=r("h2"),Z=r("a"),Bt=r("span"),dt(he.$$.fragment),ja=c(),Dt=r("span"),za=n("If you are looking for custom support from the Hugging Face team"),Or=c(),ue=r("img"),Cr=c(),C=r("h2"),J=r("a"),Qt=r("span"),dt(de.$$.fragment),Ba=c(),Wt=r("span"),Da=n("Third-party library models:"),Fr=c(),K=r("ul"),pe=r("li"),ge=r("p"),Qa=n("The "),me=r("a"),Wa=n("Hub"),Za=n(" now supports many new libraries:"),Ja=c(),F=r("ul"),V=r("li"),ve=r("a"),Ka=n("SpaCy"),Va=n(", "),_e=r("a"),Xa=n("AllenNLP"),Ya=n(","),el=c(),yt=r("li"),Ee=r("a"),tl=n("Speechbrain"),rl=n(","),al=c(),X=r("li"),we=r("a"),ll=n("Timm"),ol=n(" and "),ke=r("a"),il=n("many others"),nl=n("\u2026"),sl=c(),Zt=r("li"),Ae=r("p"),cl=n("Those models are enabled on the API thanks to some docker integration "),ye=r("a"),fl=n("api-inference-community"),hl=n("."),jr=c(),dt(Y.$$.fragment),zr=c(),j=r("h2"),ee=r("a"),Jt=r("span"),dt(Ie.$$.fragment),ul=c(),Kt=r("span"),dl=n("Getting Started:"),Br=c(),L=r("ul"),It=r("li"),be=r("a"),pl=n("Overview"),m=r("ul"),Vt=r("li"),Le=r("a"),gl=n("Main features:"),ml=c(),Xt=r("li"),Pe=r("a"),vl=n("Get your API Token"),_l=c(),Yt=r("li"),$e=r("a"),El=n("Running Inference with API Requests"),wl=c(),er=r("li"),Te=r("a"),kl=n("API Options and Parameters"),Al=c(),tr=r("li"),Se=r("a"),yl=n("Using CPU-Accelerated Inference (~up to 10x speedup)"),Il=c(),rr=r("li"),xe=r("a"),bl=n("Using GPU-Accelerated Inference"),Ll=c(),ar=r("li"),Ne=r("a"),Pl=n("Using Large Models (>10 Go)"),$l=c(),lr=r("li"),qe=r("a"),Tl=n("Model Pinning / Preloading"),Sl=c(),bt=r("li"),Ue=r("a"),xl=n("Detailed parameters"),h=r("ul"),or=r("li"),Re=r("a"),Nl=n("Which task is used by this model ?"),ql=c(),ir=r("li"),Ge=r("a"),Ul=n("Zero-shot classification task"),Rl=c(),nr=r("li"),Me=r("a"),Gl=n("Translation task"),Ml=c(),sr=r("li"),He=r("a"),Hl=n("Summarization task"),Ol=c(),cr=r("li"),Oe=r("a"),Cl=n("Conversational task"),Fl=c(),fr=r("li"),Ce=r("a"),jl=n("Table question answering task"),zl=c(),hr=r("li"),Fe=r("a"),Bl=n("Question answering task"),Dl=c(),ur=r("li"),je=r("a"),Ql=n("Text-classification task"),Wl=c(),dr=r("li"),Lt=r("a"),Zl=n("Named Entity Recognition (https://huggingface.co/docs/inference-api/NER) task"),Jl=c(),pr=r("li"),ze=r("a"),Kl=n("Token-classification task"),Vl=c(),gr=r("li"),Be=r("a"),Xl=n("Text-generation task"),Yl=c(),mr=r("li"),De=r("a"),eo=n("Text2text-generation task"),to=c(),vr=r("li"),Qe=r("a"),ro=n("Fill mask task"),ao=c(),_r=r("li"),We=r("a"),lo=n("Automatic speech recognition task"),oo=c(),Er=r("li"),Ze=r("a"),io=n("Feature-extraction task"),no=c(),wr=r("li"),Je=r("a"),so=n("Audio-classification task"),co=c(),kr=r("li"),Ke=r("a"),fo=n("Object-detection task"),ho=c(),Pt=r("li"),Ve=r("a"),uo=n("Parallelism and batch jobs"),Xe=r("ul"),Ar=r("li"),Ye=r("a"),po=n("Streaming"),go=c(),yr=r("li"),et=r("a"),mo=n("Dataset"),vo=c(),$t=r("li"),tt=r("a"),_o=n("Detailed usage and pinned models"),rt=r("ul"),Ir=r("li"),at=r("a"),Eo=n("API Usage dashboard"),wo=c(),br=r("li"),lt=r("a"),ko=n("Pinned models"),Ao=c(),Tt=r("li"),ot=r("a"),yo=n("More information about the API"),I=r("ul"),Lr=r("li"),it=r("a"),Io=n("Rate limits"),bo=c(),Pr=r("li"),nt=r("a"),Lo=n("Running private models"),Po=c(),$r=r("li"),st=r("a"),$o=n("Running a public model that I do not own"),To=c(),Tr=r("li"),ct=r("a"),So=n("Finetuning a public model"),xo=c(),Sr=r("li"),ft=r("a"),No=n("Tracking metrics"),qo=c(),xr=r("li"),ht=r("a"),Uo=n("Running the inference on my infrastructure"),this.h()},l(i){const u=rs('[data-svelte="svelte-1phssyn"]',document.head);v=a(u,"META",{name:!0,content:!0}),u.forEach(t),z=f(i),E=a(i,"H1",{class:!0});var ut=l(E);P=a(ut,"A",{id:!0,class:!0,href:!0});var Wo=l(P);M=a(Wo,"SPAN",{});var Zo=l(M);pt($.$$.fragment,Zo),Zo.forEach(t),Wo.forEach(t),b=f(ut),q=a(ut,"SPAN",{});var Jo=l(q);re=s(Jo,"\u{1F917} Accelerated Inference API"),Jo.forEach(t),ut.forEach(t),B=f(i),T=a(i,"P",{});var Ko=l(T);ae=s(Ko,`Integrate into your apps over 20,000 pre-trained state of the art
models, or your own private models, via simple HTTP requests, with 2x to
10x faster inference than out of the box deployment, and scalability
built-in.`),Ko.forEach(t),D=f(i),y=a(i,"H2",{class:!0});var Qr=l(y);S=a(Qr,"A",{id:!0,class:!0,href:!0});var Vo=l(S);w=a(Vo,"SPAN",{});var Xo=l(w);pt(k.$$.fragment,Xo),Xo.forEach(t),Vo.forEach(t),Et=f(Qr),x=a(Qr,"SPAN",{});var Yo=l(x);wt=s(Yo,"Hugging Face is trusted in production by over 5,000 companies"),Yo.forEach(t),Qr.forEach(t),le=f(i),U=a(i,"IMG",{class:!0,src:!0,width:!0}),Rr=f(i),Q=a(i,"IMG",{class:!0,src:!0,width:!0}),Gr=f(i),H=a(i,"H2",{class:!0});var Wr=l(H);W=a(Wr,"A",{id:!0,class:!0,href:!0});var ei=l(W);Nt=a(ei,"SPAN",{});var ti=l(Nt);pt(oe.$$.fragment,ti),ti.forEach(t),ei.forEach(t),na=f(Wr),qt=a(Wr,"SPAN",{});var ri=l(qt);sa=s(ri,"Main features:"),ri.forEach(t),Wr.forEach(t),Mr=f(i),g=a(i,"UL",{});var _=l(g);ie=a(_,"LI",{});var Zr=l(ie);ca=s(Zr,"Leverage "),Ut=a(Zr,"STRONG",{});var ai=l(Ut);fa=s(ai,"20,000+ Transformer models"),ai.forEach(t),ha=s(Zr," (T5, Blenderbot, Bart, GPT-2, Pegasus...)"),Zr.forEach(t),ua=f(_),kt=a(_,"LI",{});var Ro=l(kt);da=s(Ro,"Upload, manage and serve your "),Rt=a(Ro,"STRONG",{});var li=l(Rt);pa=s(li,"own models privately"),li.forEach(t),Ro.forEach(t),ga=f(_),Gt=a(_,"LI",{});var oi=l(Gt);ma=s(oi,"Run Classification, NER, Conversational, Summarization, Translation, Question-Answering, Embeddings Extraction tasks"),oi.forEach(t),va=f(_),ne=a(_,"LI",{});var Jr=l(ne);_a=s(Jr,"Get up to "),Mt=a(Jr,"STRONG",{});var ii=l(Mt);Ea=s(ii,"10x inference speedup"),ii.forEach(t),wa=s(Jr," to reduce user latency"),Jr.forEach(t),ka=f(_),R=a(_,"LI",{});var te=l(R);Aa=s(te,"Accelerated inference on "),Ht=a(te,"STRONG",{});var ni=l(Ht);ya=s(ni,"CPU"),ni.forEach(t),Ia=s(te," and "),Ot=a(te,"STRONG",{});var si=l(Ot);ba=s(si,"GPU"),si.forEach(t),La=s(te," (GPU requires a "),se=a(te,"A",{href:!0,rel:!0});var ci=l(se);Pa=s(ci,"Startup or Enterprise plan"),ci.forEach(t),$a=s(te,")"),te.forEach(t),Ta=f(_),ce=a(_,"LI",{});var Kr=l(ce);Sa=s(Kr,"Run "),Ct=a(Kr,"STRONG",{});var fi=l(Ct);xa=s(fi,"large models"),fi.forEach(t),Na=s(Kr," that are challenging to deploy in production"),Kr.forEach(t),qa=f(_),fe=a(_,"LI",{});var Vr=l(fe);Ua=s(Vr,"Scale to 1,000 requests per second with "),Ft=a(Vr,"STRONG",{});var hi=l(Ft);Ra=s(hi,"automatic scaling"),hi.forEach(t),Ga=s(Vr," built-in"),Vr.forEach(t),Ma=f(_),At=a(_,"LI",{});var Go=l(At);jt=a(Go,"STRONG",{});var ui=l(jt);Ha=s(ui,"Ship new NLP features faster"),ui.forEach(t),Oa=s(Go," as new models become available"),Go.forEach(t),Ca=f(_),zt=a(_,"LI",{});var di=l(zt);Fa=s(di,"Build your business on a platform powered by the reference open source project in NLP"),di.forEach(t),_.forEach(t),Hr=f(i),O=a(i,"H2",{class:!0});var Xr=l(O);Z=a(Xr,"A",{id:!0,class:!0,href:!0});var pi=l(Z);Bt=a(pi,"SPAN",{});var gi=l(Bt);pt(he.$$.fragment,gi),gi.forEach(t),pi.forEach(t),ja=f(Xr),Dt=a(Xr,"SPAN",{});var mi=l(Dt);za=s(mi,"If you are looking for custom support from the Hugging Face team"),mi.forEach(t),Xr.forEach(t),Or=f(i),ue=a(i,"IMG",{src:!0,width:!0}),Cr=f(i),C=a(i,"H2",{class:!0});var Yr=l(C);J=a(Yr,"A",{id:!0,class:!0,href:!0});var vi=l(J);Qt=a(vi,"SPAN",{});var _i=l(Qt);pt(de.$$.fragment,_i),_i.forEach(t),vi.forEach(t),Ba=f(Yr),Wt=a(Yr,"SPAN",{});var Ei=l(Wt);Da=s(Ei,"Third-party library models:"),Ei.forEach(t),Yr.forEach(t),Fr=f(i),K=a(i,"UL",{});var ea=l(K);pe=a(ea,"LI",{});var ta=l(pe);ge=a(ta,"P",{});var ra=l(ge);Qa=s(ra,"The "),me=a(ra,"A",{href:!0,rel:!0});var wi=l(me);Wa=s(wi,"Hub"),wi.forEach(t),Za=s(ra," now supports many new libraries:"),ra.forEach(t),Ja=f(ta),F=a(ta,"UL",{});var St=l(F);V=a(St,"LI",{});var Nr=l(V);ve=a(Nr,"A",{href:!0,rel:!0});var ki=l(ve);Ka=s(ki,"SpaCy"),ki.forEach(t),Va=s(Nr,", "),_e=a(Nr,"A",{href:!0,rel:!0});var Ai=l(_e);Xa=s(Ai,"AllenNLP"),Ai.forEach(t),Ya=s(Nr,","),Nr.forEach(t),el=f(St),yt=a(St,"LI",{});var Mo=l(yt);Ee=a(Mo,"A",{href:!0,rel:!0});var yi=l(Ee);tl=s(yi,"Speechbrain"),yi.forEach(t),rl=s(Mo,","),Mo.forEach(t),al=f(St),X=a(St,"LI",{});var qr=l(X);we=a(qr,"A",{href:!0,rel:!0});var Ii=l(we);ll=s(Ii,"Timm"),Ii.forEach(t),ol=s(qr," and "),ke=a(qr,"A",{href:!0,rel:!0});var bi=l(ke);il=s(bi,"many others"),bi.forEach(t),nl=s(qr,"\u2026"),qr.forEach(t),St.forEach(t),ta.forEach(t),sl=f(ea),Zt=a(ea,"LI",{});var Li=l(Zt);Ae=a(Li,"P",{});var aa=l(Ae);cl=s(aa,"Those models are enabled on the API thanks to some docker integration "),ye=a(aa,"A",{href:!0,rel:!0});var Pi=l(ye);fl=s(Pi,"api-inference-community"),Pi.forEach(t),hl=s(aa,"."),aa.forEach(t),Li.forEach(t),ea.forEach(t),jr=f(i),pt(Y.$$.fragment,i),zr=f(i),j=a(i,"H2",{class:!0});var la=l(j);ee=a(la,"A",{id:!0,class:!0,href:!0});var $i=l(ee);Jt=a($i,"SPAN",{});var Ti=l(Jt);pt(Ie.$$.fragment,Ti),Ti.forEach(t),$i.forEach(t),ul=f(la),Kt=a(la,"SPAN",{});var Si=l(Kt);dl=s(Si,"Getting Started:"),Si.forEach(t),la.forEach(t),Br=f(i),L=a(i,"UL",{});var G=l(L);It=a(G,"LI",{});var Ho=l(It);be=a(Ho,"A",{href:!0,rel:!0});var xi=l(be);pl=s(xi,"Overview"),xi.forEach(t),m=a(Ho,"UL",{});var A=l(m);Vt=a(A,"LI",{});var Ni=l(Vt);Le=a(Ni,"A",{href:!0,rel:!0});var qi=l(Le);gl=s(qi,"Main features:"),qi.forEach(t),Ni.forEach(t),ml=f(A),Xt=a(A,"LI",{});var Ui=l(Xt);Pe=a(Ui,"A",{href:!0,rel:!0});var Ri=l(Pe);vl=s(Ri,"Get your API Token"),Ri.forEach(t),Ui.forEach(t),_l=f(A),Yt=a(A,"LI",{});var Gi=l(Yt);$e=a(Gi,"A",{href:!0,rel:!0});var Mi=l($e);El=s(Mi,"Running Inference with API Requests"),Mi.forEach(t),Gi.forEach(t),wl=f(A),er=a(A,"LI",{});var Hi=l(er);Te=a(Hi,"A",{href:!0,rel:!0});var Oi=l(Te);kl=s(Oi,"API Options and Parameters"),Oi.forEach(t),Hi.forEach(t),Al=f(A),tr=a(A,"LI",{});var Ci=l(tr);Se=a(Ci,"A",{href:!0,rel:!0});var Fi=l(Se);yl=s(Fi,"Using CPU-Accelerated Inference (~up to 10x speedup)"),Fi.forEach(t),Ci.forEach(t),Il=f(A),rr=a(A,"LI",{});var ji=l(rr);xe=a(ji,"A",{href:!0,rel:!0});var zi=l(xe);bl=s(zi,"Using GPU-Accelerated Inference"),zi.forEach(t),ji.forEach(t),Ll=f(A),ar=a(A,"LI",{});var Bi=l(ar);Ne=a(Bi,"A",{href:!0,rel:!0});var Di=l(Ne);Pl=s(Di,"Using Large Models (>10 Go)"),Di.forEach(t),Bi.forEach(t),$l=f(A),lr=a(A,"LI",{});var Qi=l(lr);qe=a(Qi,"A",{href:!0,rel:!0});var Wi=l(qe);Tl=s(Wi,"Model Pinning / Preloading"),Wi.forEach(t),Qi.forEach(t),A.forEach(t),Ho.forEach(t),Sl=f(G),bt=a(G,"LI",{});var Oo=l(bt);Ue=a(Oo,"A",{href:!0,rel:!0});var Zi=l(Ue);xl=s(Zi,"Detailed parameters"),Zi.forEach(t),h=a(Oo,"UL",{});var d=l(h);or=a(d,"LI",{});var Ji=l(or);Re=a(Ji,"A",{href:!0,rel:!0});var Ki=l(Re);Nl=s(Ki,"Which task is used by this model ?"),Ki.forEach(t),Ji.forEach(t),ql=f(d),ir=a(d,"LI",{});var Vi=l(ir);Ge=a(Vi,"A",{href:!0,rel:!0});var Xi=l(Ge);Ul=s(Xi,"Zero-shot classification task"),Xi.forEach(t),Vi.forEach(t),Rl=f(d),nr=a(d,"LI",{});var Yi=l(nr);Me=a(Yi,"A",{href:!0,rel:!0});var en=l(Me);Gl=s(en,"Translation task"),en.forEach(t),Yi.forEach(t),Ml=f(d),sr=a(d,"LI",{});var tn=l(sr);He=a(tn,"A",{href:!0,rel:!0});var rn=l(He);Hl=s(rn,"Summarization task"),rn.forEach(t),tn.forEach(t),Ol=f(d),cr=a(d,"LI",{});var an=l(cr);Oe=a(an,"A",{href:!0,rel:!0});var ln=l(Oe);Cl=s(ln,"Conversational task"),ln.forEach(t),an.forEach(t),Fl=f(d),fr=a(d,"LI",{});var on=l(fr);Ce=a(on,"A",{href:!0,rel:!0});var nn=l(Ce);jl=s(nn,"Table question answering task"),nn.forEach(t),on.forEach(t),zl=f(d),hr=a(d,"LI",{});var sn=l(hr);Fe=a(sn,"A",{href:!0,rel:!0});var cn=l(Fe);Bl=s(cn,"Question answering task"),cn.forEach(t),sn.forEach(t),Dl=f(d),ur=a(d,"LI",{});var fn=l(ur);je=a(fn,"A",{href:!0,rel:!0});var hn=l(je);Ql=s(hn,"Text-classification task"),hn.forEach(t),fn.forEach(t),Wl=f(d),dr=a(d,"LI",{});var un=l(dr);Lt=a(un,"A",{href:!0});var dn=l(Lt);Zl=s(dn,"Named Entity Recognition (https://huggingface.co/docs/inference-api/NER) task"),dn.forEach(t),un.forEach(t),Jl=f(d),pr=a(d,"LI",{});var pn=l(pr);ze=a(pn,"A",{href:!0,rel:!0});var gn=l(ze);Kl=s(gn,"Token-classification task"),gn.forEach(t),pn.forEach(t),Vl=f(d),gr=a(d,"LI",{});var mn=l(gr);Be=a(mn,"A",{href:!0,rel:!0});var vn=l(Be);Xl=s(vn,"Text-generation task"),vn.forEach(t),mn.forEach(t),Yl=f(d),mr=a(d,"LI",{});var _n=l(mr);De=a(_n,"A",{href:!0,rel:!0});var En=l(De);eo=s(En,"Text2text-generation task"),En.forEach(t),_n.forEach(t),to=f(d),vr=a(d,"LI",{});var wn=l(vr);Qe=a(wn,"A",{href:!0,rel:!0});var kn=l(Qe);ro=s(kn,"Fill mask task"),kn.forEach(t),wn.forEach(t),ao=f(d),_r=a(d,"LI",{});var An=l(_r);We=a(An,"A",{href:!0,rel:!0});var yn=l(We);lo=s(yn,"Automatic speech recognition task"),yn.forEach(t),An.forEach(t),oo=f(d),Er=a(d,"LI",{});var In=l(Er);Ze=a(In,"A",{href:!0,rel:!0});var bn=l(Ze);io=s(bn,"Feature-extraction task"),bn.forEach(t),In.forEach(t),no=f(d),wr=a(d,"LI",{});var Ln=l(wr);Je=a(Ln,"A",{href:!0,rel:!0});var Pn=l(Je);so=s(Pn,"Audio-classification task"),Pn.forEach(t),Ln.forEach(t),co=f(d),kr=a(d,"LI",{});var $n=l(kr);Ke=a($n,"A",{href:!0,rel:!0});var Tn=l(Ke);fo=s(Tn,"Object-detection task"),Tn.forEach(t),$n.forEach(t),d.forEach(t),Oo.forEach(t),ho=f(G),Pt=a(G,"LI",{});var Co=l(Pt);Ve=a(Co,"A",{href:!0,rel:!0});var Sn=l(Ve);uo=s(Sn,"Parallelism and batch jobs"),Sn.forEach(t),Xe=a(Co,"UL",{});var oa=l(Xe);Ar=a(oa,"LI",{});var xn=l(Ar);Ye=a(xn,"A",{href:!0,rel:!0});var Nn=l(Ye);po=s(Nn,"Streaming"),Nn.forEach(t),xn.forEach(t),go=f(oa),yr=a(oa,"LI",{});var qn=l(yr);et=a(qn,"A",{href:!0,rel:!0});var Un=l(et);mo=s(Un,"Dataset"),Un.forEach(t),qn.forEach(t),oa.forEach(t),Co.forEach(t),vo=f(G),$t=a(G,"LI",{});var Fo=l($t);tt=a(Fo,"A",{href:!0,rel:!0});var Rn=l(tt);_o=s(Rn,"Detailed usage and pinned models"),Rn.forEach(t),rt=a(Fo,"UL",{});var ia=l(rt);Ir=a(ia,"LI",{});var Gn=l(Ir);at=a(Gn,"A",{href:!0,rel:!0});var Mn=l(at);Eo=s(Mn,"API Usage dashboard"),Mn.forEach(t),Gn.forEach(t),wo=f(ia),br=a(ia,"LI",{});var Hn=l(br);lt=a(Hn,"A",{href:!0,rel:!0});var On=l(lt);ko=s(On,"Pinned models"),On.forEach(t),Hn.forEach(t),ia.forEach(t),Fo.forEach(t),Ao=f(G),Tt=a(G,"LI",{});var jo=l(Tt);ot=a(jo,"A",{href:!0,rel:!0});var Cn=l(ot);yo=s(Cn,"More information about the API"),Cn.forEach(t),I=a(jo,"UL",{});var N=l(I);Lr=a(N,"LI",{});var Fn=l(Lr);it=a(Fn,"A",{href:!0,rel:!0});var jn=l(it);Io=s(jn,"Rate limits"),jn.forEach(t),Fn.forEach(t),bo=f(N),Pr=a(N,"LI",{});var zn=l(Pr);nt=a(zn,"A",{href:!0,rel:!0});var Bn=l(nt);Lo=s(Bn,"Running private models"),Bn.forEach(t),zn.forEach(t),Po=f(N),$r=a(N,"LI",{});var Dn=l($r);st=a(Dn,"A",{href:!0,rel:!0});var Qn=l(st);$o=s(Qn,"Running a public model that I do not own"),Qn.forEach(t),Dn.forEach(t),To=f(N),Tr=a(N,"LI",{});var Wn=l(Tr);ct=a(Wn,"A",{href:!0,rel:!0});var Zn=l(ct);So=s(Zn,"Finetuning a public model"),Zn.forEach(t),Wn.forEach(t),xo=f(N),Sr=a(N,"LI",{});var Jn=l(Sr);ft=a(Jn,"A",{href:!0,rel:!0});var Kn=l(ft);No=s(Kn,"Tracking metrics"),Kn.forEach(t),Jn.forEach(t),qo=f(N),xr=a(N,"LI",{});var Vn=l(xr);ht=a(Vn,"A",{href:!0,rel:!0});var Xn=l(ht);Uo=s(Xn,"Running the inference on my infrastructure"),Xn.forEach(t),Vn.forEach(t),N.forEach(t),jo.forEach(t),G.forEach(t),this.h()},h(){o(v,"name","hf:doc:metadata"),o(v,"content",JSON.stringify(ns)),o(P,"id","accelerated-inference-api"),o(P,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(P,"href","#accelerated-inference-api"),o(E,"class","relative group"),o(S,"id","hugging-face-is-trusted-in-production-by-over-5000-companies"),o(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(S,"href","#hugging-face-is-trusted-in-production-by-over-5000-companies"),o(y,"class","relative group"),o(U,"class","block dark:hidden"),zo(U.src,Bo="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/inference-api/companies-light.png")||o(U,"src",Bo),o(U,"width","600"),o(Q,"class","hidden dark:block invert"),zo(Q.src,Do="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/inference-api/companies-light.png")||o(Q,"src",Do),o(Q,"width","600"),o(W,"id","main-features"),o(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(W,"href","#main-features"),o(H,"class","relative group"),o(se,"href","https://huggingface.co/pricing"),o(se,"rel","nofollow"),o(Z,"id","if-you-are-looking-for-custom-support-from-the-hugging-face-team"),o(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(Z,"href","#if-you-are-looking-for-custom-support-from-the-hugging-face-team"),o(O,"class","relative group"),zo(ue.src,Qo="https://huggingface.co/front/thumbnails/support.png")||o(ue,"src",Qo),o(ue,"width","400"),o(J,"id","thirdparty-library-models"),o(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(J,"href","#thirdparty-library-models"),o(C,"class","relative group"),o(me,"href","https://huggingface.co"),o(me,"rel","nofollow"),o(ve,"href","https://spacy.io/"),o(ve,"rel","nofollow"),o(_e,"href","https://allennlp.org/"),o(_e,"rel","nofollow"),o(Ee,"href","https://speechbrain.github.io/"),o(Ee,"rel","nofollow"),o(we,"href","https://pypi.org/project/timm/"),o(we,"rel","nofollow"),o(ke,"href","https://huggingface.co/docs/hub/libraries"),o(ke,"rel","nofollow"),o(ye,"href","https://github.com/huggingface/huggingface_hub/tree/main/api-inference-community"),o(ye,"rel","nofollow"),o(ee,"id","getting-started"),o(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(ee,"href","#getting-started"),o(j,"class","relative group"),o(be,"href","https://huggingface.co/docs/inference-api/quicktour"),o(be,"rel","nofollow"),o(Le,"href","https://huggingface.co/docs/inference-api/quicktour#main-features"),o(Le,"rel","nofollow"),o(Pe,"href","https://huggingface.co/docs/inference-api/quicktour#get-your-api-token"),o(Pe,"rel","nofollow"),o($e,"href","https://huggingface.co/docs/inference-api/quicktour#running-inference-with-api-requests"),o($e,"rel","nofollow"),o(Te,"href","https://huggingface.co/docs/inference-api/quicktour#api-options-and-parameters"),o(Te,"rel","nofollow"),o(Se,"href","https://huggingface.co/docs/inference-api/quicktour#using-cpu-accelerated-inference-up-to-10x-speedup"),o(Se,"rel","nofollow"),o(xe,"href","https://huggingface.co/docs/inference-api/quicktour#using-gpu-accelerated-inference"),o(xe,"rel","nofollow"),o(Ne,"href","https://huggingface.co/docs/inference-api/quicktour#using-large-models-10-go"),o(Ne,"rel","nofollow"),o(qe,"href","https://huggingface.co/docs/inference-api/quicktour#model-pinning-preloading"),o(qe,"rel","nofollow"),o(Ue,"href","https://huggingface.co/docs/inference-api/detailed_parameters"),o(Ue,"rel","nofollow"),o(Re,"href","https://huggingface.co/docs/inference-api/detailed_parameters#which-task-is-used-by-this-model"),o(Re,"rel","nofollow"),o(Ge,"href","https://huggingface.co/docs/inference-api/detailed_parameters#zero-shot-classification-task"),o(Ge,"rel","nofollow"),o(Me,"href","https://huggingface.co/docs/inference-api/detailed_parameters#translation-task"),o(Me,"rel","nofollow"),o(He,"href","https://huggingface.co/docs/inference-api/detailed_parameters#summarization-task"),o(He,"rel","nofollow"),o(Oe,"href","https://huggingface.co/docs/inference-api/detailed_parameters#conversational-task"),o(Oe,"rel","nofollow"),o(Ce,"href","https://huggingface.co/docs/inference-api/detailed_parameters#table-question-answering-task"),o(Ce,"rel","nofollow"),o(Fe,"href","https://huggingface.co/docs/inference-api/detailed_parameters#question-answering-task"),o(Fe,"rel","nofollow"),o(je,"href","https://huggingface.co/docs/inference-api/detailed_parameters#text-classification-task"),o(je,"rel","nofollow"),o(Lt,"href","detailed_parameters#named-entity-recognition-ner-task"),o(ze,"href","https://huggingface.co/docs/inference-api/detailed_parameters#token-classification-task"),o(ze,"rel","nofollow"),o(Be,"href","https://huggingface.co/docs/inference-api/detailed_parameters#text-generation-task"),o(Be,"rel","nofollow"),o(De,"href","https://huggingface.co/docs/inference-api/detailed_parameters#text2text-generation-task"),o(De,"rel","nofollow"),o(Qe,"href","https://huggingface.co/docs/inference-api/detailed_parameters#fill-mask-task"),o(Qe,"rel","nofollow"),o(We,"href","https://huggingface.co/docs/inference-api/detailed_parameters#automatic-speech-recognition-task"),o(We,"rel","nofollow"),o(Ze,"href","https://huggingface.co/docs/inference-api/detailed_parameters#feature-extraction-task"),o(Ze,"rel","nofollow"),o(Je,"href","https://huggingface.co/docs/inference-api/detailed_parameters#audio-classification-task"),o(Je,"rel","nofollow"),o(Ke,"href","https://huggingface.co/docs/inference-api/detailed_parameters#object-detection-task"),o(Ke,"rel","nofollow"),o(Ve,"href","https://huggingface.co/docs/inference-api/parallelism"),o(Ve,"rel","nofollow"),o(Ye,"href","https://huggingface.co/docs/inference-api/parallelism#streaming"),o(Ye,"rel","nofollow"),o(et,"href","https://huggingface.co/docs/inference-api/parallelism#dataset"),o(et,"rel","nofollow"),o(tt,"href","https://huggingface.co/docs/inference-api/usage"),o(tt,"rel","nofollow"),o(at,"href","https://huggingface.co/docs/inference-api/usage#api-usage-dashboard"),o(at,"rel","nofollow"),o(lt,"href","https://huggingface.co/docs/inference-api/usage#pinned-models"),o(lt,"rel","nofollow"),o(ot,"href","https://huggingface.co/docs/inference-api/faq"),o(ot,"rel","nofollow"),o(it,"href","https://huggingface.co/docs/inference-api/faq#rate-limits"),o(it,"rel","nofollow"),o(nt,"href","https://huggingface.co/docs/inference-api/faq#running-private-models"),o(nt,"rel","nofollow"),o(st,"href","https://huggingface.co/docs/inference-api/faq#running-a-public-model-that-i-do-not-own"),o(st,"rel","nofollow"),o(ct,"href","https://huggingface.co/docs/inference-api/faq#finetuning-a-public-model"),o(ct,"rel","nofollow"),o(ft,"href","https://huggingface.co/docs/inference-api/faq#tracking-metrics"),o(ft,"rel","nofollow"),o(ht,"href","https://huggingface.co/docs/inference-api/faq#running-the-inference-on-my-infrastructure"),o(ht,"rel","nofollow")},m(i,u){e(document.head,v),p(i,z,u),p(i,E,u),e(E,P),e(P,M),gt($,M,null),e(E,b),e(E,q),e(q,re),p(i,B,u),p(i,T,u),e(T,ae),p(i,D,u),p(i,y,u),e(y,S),e(S,w),gt(k,w,null),e(y,Et),e(y,x),e(x,wt),p(i,le,u),p(i,U,u),p(i,Rr,u),p(i,Q,u),p(i,Gr,u),p(i,H,u),e(H,W),e(W,Nt),gt(oe,Nt,null),e(H,na),e(H,qt),e(qt,sa),p(i,Mr,u),p(i,g,u),e(g,ie),e(ie,ca),e(ie,Ut),e(Ut,fa),e(ie,ha),e(g,ua),e(g,kt),e(kt,da),e(kt,Rt),e(Rt,pa),e(g,ga),e(g,Gt),e(Gt,ma),e(g,va),e(g,ne),e(ne,_a),e(ne,Mt),e(Mt,Ea),e(ne,wa),e(g,ka),e(g,R),e(R,Aa),e(R,Ht),e(Ht,ya),e(R,Ia),e(R,Ot),e(Ot,ba),e(R,La),e(R,se),e(se,Pa),e(R,$a),e(g,Ta),e(g,ce),e(ce,Sa),e(ce,Ct),e(Ct,xa),e(ce,Na),e(g,qa),e(g,fe),e(fe,Ua),e(fe,Ft),e(Ft,Ra),e(fe,Ga),e(g,Ma),e(g,At),e(At,jt),e(jt,Ha),e(At,Oa),e(g,Ca),e(g,zt),e(zt,Fa),p(i,Hr,u),p(i,O,u),e(O,Z),e(Z,Bt),gt(he,Bt,null),e(O,ja),e(O,Dt),e(Dt,za),p(i,Or,u),p(i,ue,u),p(i,Cr,u),p(i,C,u),e(C,J),e(J,Qt),gt(de,Qt,null),e(C,Ba),e(C,Wt),e(Wt,Da),p(i,Fr,u),p(i,K,u),e(K,pe),e(pe,ge),e(ge,Qa),e(ge,me),e(me,Wa),e(ge,Za),e(pe,Ja),e(pe,F),e(F,V),e(V,ve),e(ve,Ka),e(V,Va),e(V,_e),e(_e,Xa),e(V,Ya),e(F,el),e(F,yt),e(yt,Ee),e(Ee,tl),e(yt,rl),e(F,al),e(F,X),e(X,we),e(we,ll),e(X,ol),e(X,ke),e(ke,il),e(X,nl),e(K,sl),e(K,Zt),e(Zt,Ae),e(Ae,cl),e(Ae,ye),e(ye,fl),e(Ae,hl),p(i,jr,u),gt(Y,i,u),p(i,zr,u),p(i,j,u),e(j,ee),e(ee,Jt),gt(Ie,Jt,null),e(j,ul),e(j,Kt),e(Kt,dl),p(i,Br,u),p(i,L,u),e(L,It),e(It,be),e(be,pl),e(It,m),e(m,Vt),e(Vt,Le),e(Le,gl),e(m,ml),e(m,Xt),e(Xt,Pe),e(Pe,vl),e(m,_l),e(m,Yt),e(Yt,$e),e($e,El),e(m,wl),e(m,er),e(er,Te),e(Te,kl),e(m,Al),e(m,tr),e(tr,Se),e(Se,yl),e(m,Il),e(m,rr),e(rr,xe),e(xe,bl),e(m,Ll),e(m,ar),e(ar,Ne),e(Ne,Pl),e(m,$l),e(m,lr),e(lr,qe),e(qe,Tl),e(L,Sl),e(L,bt),e(bt,Ue),e(Ue,xl),e(bt,h),e(h,or),e(or,Re),e(Re,Nl),e(h,ql),e(h,ir),e(ir,Ge),e(Ge,Ul),e(h,Rl),e(h,nr),e(nr,Me),e(Me,Gl),e(h,Ml),e(h,sr),e(sr,He),e(He,Hl),e(h,Ol),e(h,cr),e(cr,Oe),e(Oe,Cl),e(h,Fl),e(h,fr),e(fr,Ce),e(Ce,jl),e(h,zl),e(h,hr),e(hr,Fe),e(Fe,Bl),e(h,Dl),e(h,ur),e(ur,je),e(je,Ql),e(h,Wl),e(h,dr),e(dr,Lt),e(Lt,Zl),e(h,Jl),e(h,pr),e(pr,ze),e(ze,Kl),e(h,Vl),e(h,gr),e(gr,Be),e(Be,Xl),e(h,Yl),e(h,mr),e(mr,De),e(De,eo),e(h,to),e(h,vr),e(vr,Qe),e(Qe,ro),e(h,ao),e(h,_r),e(_r,We),e(We,lo),e(h,oo),e(h,Er),e(Er,Ze),e(Ze,io),e(h,no),e(h,wr),e(wr,Je),e(Je,so),e(h,co),e(h,kr),e(kr,Ke),e(Ke,fo),e(L,ho),e(L,Pt),e(Pt,Ve),e(Ve,uo),e(Pt,Xe),e(Xe,Ar),e(Ar,Ye),e(Ye,po),e(Xe,go),e(Xe,yr),e(yr,et),e(et,mo),e(L,vo),e(L,$t),e($t,tt),e(tt,_o),e($t,rt),e(rt,Ir),e(Ir,at),e(at,Eo),e(rt,wo),e(rt,br),e(br,lt),e(lt,ko),e(L,Ao),e(L,Tt),e(Tt,ot),e(ot,yo),e(Tt,I),e(I,Lr),e(Lr,it),e(it,Io),e(I,bo),e(I,Pr),e(Pr,nt),e(nt,Lo),e(I,Po),e(I,$r),e($r,st),e(st,$o),e(I,To),e(I,Tr),e(Tr,ct),e(ct,So),e(I,xo),e(I,Sr),e(Sr,ft),e(ft,No),e(I,qo),e(I,xr),e(xr,ht),e(ht,Uo),Dr=!0},p(i,[u]){const ut={};u&2&&(ut.$$scope={dirty:u,ctx:i}),Y.$set(ut)},i(i){Dr||(mt($.$$.fragment,i),mt(k.$$.fragment,i),mt(oe.$$.fragment,i),mt(he.$$.fragment,i),mt(de.$$.fragment,i),mt(Y.$$.fragment,i),mt(Ie.$$.fragment,i),Dr=!0)},o(i){vt($.$$.fragment,i),vt(k.$$.fragment,i),vt(oe.$$.fragment,i),vt(he.$$.fragment,i),vt(de.$$.fragment,i),vt(Y.$$.fragment,i),vt(Ie.$$.fragment,i),Dr=!1},d(i){t(v),i&&t(z),i&&t(E),_t($),i&&t(B),i&&t(T),i&&t(D),i&&t(y),_t(k),i&&t(le),i&&t(U),i&&t(Rr),i&&t(Q),i&&t(Gr),i&&t(H),_t(oe),i&&t(Mr),i&&t(g),i&&t(Hr),i&&t(O),_t(he),i&&t(Or),i&&t(ue),i&&t(Cr),i&&t(C),_t(de),i&&t(Fr),i&&t(K),i&&t(jr),_t(Y,i),i&&t(zr),i&&t(j),_t(Ie),i&&t(Br),i&&t(L)}}}const ns={local:"accelerated-inference-api",sections:[{local:"hugging-face-is-trusted-in-production-by-over-5000-companies",title:"Hugging Face is trusted in production by over 5,000 companies"},{local:"main-features",title:"Main features:"},{local:"if-you-are-looking-for-custom-support-from-the-hugging-face-team",title:"If you are looking for custom support from the Hugging Face team"},{local:"thirdparty-library-models",title:"Third-party library models:"},{local:"getting-started",title:"Getting Started:"}],title:"\u{1F917} Accelerated Inference API"};function ss(Ur){return as(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class us extends Yn{constructor(v){super();es(this,v,ss,is,ts,{})}}export{us as default,ns as metadata};
