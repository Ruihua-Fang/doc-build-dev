import{S as Ya,i as Ka,s as Xa,e as a,k as p,w as Be,t as n,M as Za,c as s,d as t,m as d,a as l,x as Oe,h as o,b as i,N as Wa,F as r,g as c,y as Qe,L as es,q as Ue,o as Je,B as Ve,v as rs}from"../../chunks/vendor-1e8b365d.js";import{Y as ts}from"../../chunks/Youtube-c2a8cc39.js";import{I as Nr}from"../../chunks/IconCopyLink-483c28ba.js";function as(ea){let b,We,E,$,_e,H,Tr,be,Ar,Ye,w,z,Ee,M,$r,we,zr,Ke,k,Xe,m,Ir,D,Sr,xr,F,Hr,Mr,C,kr,Dr,G,Fr,Cr,R,Gr,Rr,j,jr,Br,Ze,L,I,Le,B,Or,Pe,Qr,er,ce,Ur,rr,P,O,ra,Jr,Q,ta,tr,h,U,Vr,J,Wr,Yr,Kr,ye,Xr,Zr,qe,et,ar,pe,rt,sr,v,Ne,tt,at,g,st,V,lt,nt,W,ot,it,Y,ut,ct,y,pt,K,dt,mt,X,ft,ht,lr,S,vt,Z,gt,_t,nr,q,x,Te,ee,bt,Ae,Et,or,de,wt,ir,re,$e,Lt,Pt,ur,te,ze,yt,qt,cr,N,Ie,Nt,Tt,Se,ae,At,$t,pr,se,xe,zt,It,dr,le,He,St,xt,mr,T,Me,Ht,Mt,ne,kt,Dt,fr,A,ke,Ft,Ct,oe,Gt,Rt,hr,me,jt,vr,_,ie,Bt,De,Ot,Qt,Ut,Fe,Jt,Vt,Ce,Wt,gr;return H=new Nr({}),M=new Nr({}),k=new ts({props:{id:"00GKzGyWFEs"}}),B=new Nr({}),ee=new Nr({}),{c(){b=a("meta"),We=p(),E=a("h1"),$=a("a"),_e=a("span"),Be(H.$$.fragment),Tr=p(),be=a("span"),Ar=n("Introduction"),Ye=p(),w=a("h2"),z=a("a"),Ee=a("span"),Be(M.$$.fragment),$r=p(),we=a("span"),zr=n("Bienvenue sur le cours \u{1F917} !"),Ke=p(),Be(k.$$.fragment),Xe=p(),m=a("p"),Ir=n("Ce cours vous apprendra \xE0 utiliser les librairies de NLP de l\u2019\xE9cosyst\xE8me "),D=a("a"),Sr=n("Hugging Face"),xr=n(" \u2014 "),F=a("a"),Hr=n("\u{1F917} Transformers"),Mr=n(", "),C=a("a"),kr=n("\u{1F917} Datasets"),Dr=n(", "),G=a("a"),Fr=n("\u{1F917} Tokenizers"),Cr=n(", et "),R=a("a"),Gr=n("\u{1F917} Accelerate"),Rr=n(" \u2014 ainsi que le "),j=a("a"),jr=n("Hub de Hugging Face"),Br=n(". C\u2019est totalement gratuit et sans publicit\xE9."),Ze=p(),L=a("h2"),I=a("a"),Le=a("span"),Be(B.$$.fragment),Or=p(),Pe=a("span"),Qr=n("\xC0 quoi s'attendre ?"),er=p(),ce=a("p"),Ur=n("Voici un bref aper\xE7u du cours:"),rr=p(),P=a("div"),O=a("img"),Jr=p(),Q=a("img"),tr=p(),h=a("ul"),U=a("li"),Vr=n("Les chapitres 1 \xE0 4 pr\xE9sentent les principaux concepts de la librairie \u{1F917} Transformers. \xC0 la fin de ce chapitre, vous serez familier du fonctionnement des mod\xE8les Transformers et vous saurez comment utiliser un mod\xE8le du "),J=a("a"),Wr=n("Hub de Hugging Face"),Yr=n(", le finetuner sur un jeu de donn\xE9es, et partager vos r\xE9sultats sur le Hub!"),Kr=p(),ye=a("li"),Xr=n("Les chapitres 5 \xE0 8 pr\xE9sentent les bases de \u{1F917} Datasets et \u{1F917} Tokenizers ainsi qu\u2019une d\xE9couverte des probl\xE8mes classiques de NLP. \xC0 la fin de ce chapitre, vous serez capable de r\xE9soudre les probl\xE8mes de NLP les plus communs par vous-m\xEAme."),Zr=p(),qe=a("li"),et=n("Les chapitres 9 \xE0 12 proposent d\u2019aller plus loin et d\u2019explorer comment les mod\xE8les Transformers peuvent \xEAtre utilis\xE9s pour r\xE9soudre des probl\xE8mes de traitement de la parole et de la vision par ordinateur. En suivant ces chapitres, vous apprendrez \xE0 construire et \xE0 partager vos mod\xE8les via des d\xE9monstrateurs, et vous serez capable d\u2019optimiser ces mod\xE8les pour les environnements de production. Enfin, vous serez pr\xEAt \xE0 appliquer \u{1F917} Transformers \xE0 (presque) n\u2019importe quel probl\xE8me de machine learning!"),ar=p(),pe=a("p"),rt=n("Ce cours:"),sr=p(),v=a("ul"),Ne=a("li"),tt=n("Requiert un bon niveau en Python"),at=p(),g=a("li"),st=n("Se comprend mieux si vous avez d\xE9j\xE0 suivi un cours d\u2019introduction au deep learning, comme "),V=a("a"),lt=n("fast.ai\u2019s"),nt=p(),W=a("a"),ot=n("Practical Deep Learning for Coders"),it=n(" ou un des cours d\xE9velopp\xE9s par "),Y=a("a"),ut=n("DeepLearning.AI"),ct=p(),y=a("li"),pt=n("N\u2019attend pas une connaissance appronfondie de "),K=a("a"),dt=n("PyTorch"),mt=n(" ou de "),X=a("a"),ft=n("TensorFlow"),ht=n(", bien qu\u2019\xEAtre familiaris\xE9 avec l\u2019un d\u2019entre eux peut aider"),lr=p(),S=a("p"),vt=n("Apr\xE8s avoir termin\xE9 ce cours, nous vous recommandons de suivre la "),Z=a("a"),gt=n("Sp\xE9cialisation en NLP"),_t=n(" dispens\xE9e par DeepLearning.AI, qui couvre une grande gamme de mod\xE8les traditionnels de NLP comme les Na\xEFves Bayes et les LSTMs qui sont importants \xE0 conna\xEEtre!"),nr=p(),q=a("h2"),x=a("a"),Te=a("span"),Be(ee.$$.fragment),bt=p(),Ae=a("span"),Et=n("Qui sommes-nous ?"),or=p(),de=a("p"),wt=n("\xC0 propos des auteurs de ce cours:"),ir=p(),re=a("p"),$e=a("strong"),Lt=n("Matthew Carrigan"),Pt=n(" est Machine Learning Engineer chez Hugging Face. Il vit \xE0 Dublin, en Irlande et \xE0 travaill\xE9 auparavant comme ing\xE9nieur en ML chez Parse.ly et avant cela comme chercheur postdoctoral \xE0 Trinity College Dublin. Il ne croit pas que nous arrivions \xE0 AGI en mettant \xE0 l\u2019\xE9chelle les architectures existantes, mais il a tout de m\xEAme beaucoup d\u2019espoir dans l\u2019immortalit\xE9 des robots."),ur=p(),te=a("p"),ze=a("strong"),yt=n("Lysandre Debut"),qt=n(" est Machine Learning Engineer chez Hugging Face et a travaill\xE9 sur la librairie \u{1F917} Transformers depuis les premi\xE8res phases de d\xE9veloppement. Son but est de rendre NLP accessible pour tout le monde en d\xE9veloppant des outils disposant d\u2019une API tr\xE8s simple."),cr=p(),N=a("p"),Ie=a("strong"),Nt=n("Sylvain Gugger"),Tt=n(" est Research Engineer chez Hugging Face et un des principaux responsable de la librairie \u{1F917} Transformers. Pr\xE9c\xE9demment, Il a \xE9t\xE9 chercheur en ML chez fast.ai et a \xE9crit "),Se=a("em"),ae=a("a"),At=n("Deep Learning for Coders with fastai and PyTorch"),$t=n(" avec Jeremy Howard. Son but ultime est de rendre le deep learning plus accessible, en d\xE9veloppant et en am\xE9liorant des techniques permettant aux mod\xE8les d\u2019apprendre rapidement sur des ressources limit\xE9es."),pr=p(),se=a("p"),xe=a("strong"),zt=n("Merve Noyan"),It=n(" est Developer Advocate chez Hugging Face et travaille \xE0 la cr\xE9ation d\u2019outils et de contenu visant \xE0 d\xE9mocratiser le machine learning pour tous."),dr=p(),le=a("p"),He=a("strong"),St=n("Lucile Saulnier"),xt=n(" est Machine Learning Engineer chez Hugging Face qui travaille au d\xE9veloppement et \xE0 l\u2019impl\xE9mentation de nombreux outils open source. Elle est \xE9galement activement impliqu\xE9e dans de nombreux projets de recherche dans le domaine de NLP comme l\u2019entra\xEEnement collaboratif de mod\xE8les et le projet BigScience."),mr=p(),T=a("p"),Me=a("strong"),Ht=n("Lewis Tunstall"),Mt=n(" est Machine Learning Engineer chez Hugging Face d\xE9vou\xE9 au d\xE9veloppement d\u2019outils open source avec la volont\xE9 de les rendre accessibles \xE0 une communaut\xE9 plus large. Il est \xE9galement co-auteur d\u2019un livre qui va bient\xF4t para\xEEtre, "),ne=a("a"),kt=n("Natural Language Processing with Transformers"),Dt=n("."),fr=p(),A=a("p"),ke=a("strong"),Ft=n("Leandro von Werra"),Ct=n(" est Machine Learning Engineer dans l\u2019\xE9quipe open-source chez Hugging Face et \xE9galement co-auteur du livre qui va bient\xF4t para\xEEtre, "),oe=a("a"),Gt=n("Natural Language Processing with Transformers"),Rt=n(". Il a plusieurs ann\xE9es d\u2019exp\xE9rience dans l\u2019industrie du machine learning, o\xF9 il a pu d\xE9ployer des projets de NLP en production en travaillant sur toutes les \xE9tapes clefs du d\xE9ploiement."),hr=p(),me=a("p"),jt=n("\xCAtes-vous pr\xEAt \xE0 commencer ? Dans ce chapitre, vous apprendrez:"),vr=p(),_=a("ul"),ie=a("li"),Bt=n("\xC0 utiliser la fonction "),De=a("code"),Ot=n("pipeline()"),Qt=n(" pour r\xE9soudre des probl\xE8mes de NLP comme la g\xE9n\xE9ration de texte et la classification"),Ut=p(),Fe=a("li"),Jt=n("Quelle est l\u2019architecture d\u2019un mod\xE8le Transformer"),Vt=p(),Ce=a("li"),Wt=n("Comment faire la distinction entre les diff\xE9rentes architectures d\u2019encodeur, de d\xE9codeur et d\u2019encodeur-d\xE9codeur et leurs condition d\u2019utilisation"),this.h()},l(e){const u=Za('[data-svelte="svelte-1phssyn"]',document.head);b=s(u,"META",{name:!0,content:!0}),u.forEach(t),We=d(e),E=s(e,"H1",{class:!0});var _r=l(E);$=s(_r,"A",{id:!0,class:!0,href:!0});var aa=l($);_e=s(aa,"SPAN",{});var sa=l(_e);Oe(H.$$.fragment,sa),sa.forEach(t),aa.forEach(t),Tr=d(_r),be=s(_r,"SPAN",{});var la=l(be);Ar=o(la,"Introduction"),la.forEach(t),_r.forEach(t),Ye=d(e),w=s(e,"H2",{class:!0});var br=l(w);z=s(br,"A",{id:!0,class:!0,href:!0});var na=l(z);Ee=s(na,"SPAN",{});var oa=l(Ee);Oe(M.$$.fragment,oa),oa.forEach(t),na.forEach(t),$r=d(br),we=s(br,"SPAN",{});var ia=l(we);zr=o(ia,"Bienvenue sur le cours \u{1F917} !"),ia.forEach(t),br.forEach(t),Ke=d(e),Oe(k.$$.fragment,e),Xe=d(e),m=s(e,"P",{});var f=l(m);Ir=o(f,"Ce cours vous apprendra \xE0 utiliser les librairies de NLP de l\u2019\xE9cosyst\xE8me "),D=s(f,"A",{href:!0,rel:!0});var ua=l(D);Sr=o(ua,"Hugging Face"),ua.forEach(t),xr=o(f," \u2014 "),F=s(f,"A",{href:!0,rel:!0});var ca=l(F);Hr=o(ca,"\u{1F917} Transformers"),ca.forEach(t),Mr=o(f,", "),C=s(f,"A",{href:!0,rel:!0});var pa=l(C);kr=o(pa,"\u{1F917} Datasets"),pa.forEach(t),Dr=o(f,", "),G=s(f,"A",{href:!0,rel:!0});var da=l(G);Fr=o(da,"\u{1F917} Tokenizers"),da.forEach(t),Cr=o(f,", et "),R=s(f,"A",{href:!0,rel:!0});var ma=l(R);Gr=o(ma,"\u{1F917} Accelerate"),ma.forEach(t),Rr=o(f," \u2014 ainsi que le "),j=s(f,"A",{href:!0,rel:!0});var fa=l(j);jr=o(fa,"Hub de Hugging Face"),fa.forEach(t),Br=o(f,". C\u2019est totalement gratuit et sans publicit\xE9."),f.forEach(t),Ze=d(e),L=s(e,"H2",{class:!0});var Er=l(L);I=s(Er,"A",{id:!0,class:!0,href:!0});var ha=l(I);Le=s(ha,"SPAN",{});var va=l(Le);Oe(B.$$.fragment,va),va.forEach(t),ha.forEach(t),Or=d(Er),Pe=s(Er,"SPAN",{});var ga=l(Pe);Qr=o(ga,"\xC0 quoi s'attendre ?"),ga.forEach(t),Er.forEach(t),er=d(e),ce=s(e,"P",{});var _a=l(ce);Ur=o(_a,"Voici un bref aper\xE7u du cours:"),_a.forEach(t),rr=d(e),P=s(e,"DIV",{class:!0});var wr=l(P);O=s(wr,"IMG",{class:!0,src:!0,alt:!0}),Jr=d(wr),Q=s(wr,"IMG",{class:!0,src:!0,alt:!0}),wr.forEach(t),tr=d(e),h=s(e,"UL",{});var fe=l(h);U=s(fe,"LI",{});var Lr=l(U);Vr=o(Lr,"Les chapitres 1 \xE0 4 pr\xE9sentent les principaux concepts de la librairie \u{1F917} Transformers. \xC0 la fin de ce chapitre, vous serez familier du fonctionnement des mod\xE8les Transformers et vous saurez comment utiliser un mod\xE8le du "),J=s(Lr,"A",{href:!0,rel:!0});var ba=l(J);Wr=o(ba,"Hub de Hugging Face"),ba.forEach(t),Yr=o(Lr,", le finetuner sur un jeu de donn\xE9es, et partager vos r\xE9sultats sur le Hub!"),Lr.forEach(t),Kr=d(fe),ye=s(fe,"LI",{});var Ea=l(ye);Xr=o(Ea,"Les chapitres 5 \xE0 8 pr\xE9sentent les bases de \u{1F917} Datasets et \u{1F917} Tokenizers ainsi qu\u2019une d\xE9couverte des probl\xE8mes classiques de NLP. \xC0 la fin de ce chapitre, vous serez capable de r\xE9soudre les probl\xE8mes de NLP les plus communs par vous-m\xEAme."),Ea.forEach(t),Zr=d(fe),qe=s(fe,"LI",{});var wa=l(qe);et=o(wa,"Les chapitres 9 \xE0 12 proposent d\u2019aller plus loin et d\u2019explorer comment les mod\xE8les Transformers peuvent \xEAtre utilis\xE9s pour r\xE9soudre des probl\xE8mes de traitement de la parole et de la vision par ordinateur. En suivant ces chapitres, vous apprendrez \xE0 construire et \xE0 partager vos mod\xE8les via des d\xE9monstrateurs, et vous serez capable d\u2019optimiser ces mod\xE8les pour les environnements de production. Enfin, vous serez pr\xEAt \xE0 appliquer \u{1F917} Transformers \xE0 (presque) n\u2019importe quel probl\xE8me de machine learning!"),wa.forEach(t),fe.forEach(t),ar=d(e),pe=s(e,"P",{});var La=l(pe);rt=o(La,"Ce cours:"),La.forEach(t),sr=d(e),v=s(e,"UL",{});var he=l(v);Ne=s(he,"LI",{});var Pa=l(Ne);tt=o(Pa,"Requiert un bon niveau en Python"),Pa.forEach(t),at=d(he),g=s(he,"LI",{});var ue=l(g);st=o(ue,"Se comprend mieux si vous avez d\xE9j\xE0 suivi un cours d\u2019introduction au deep learning, comme "),V=s(ue,"A",{href:!0,rel:!0});var ya=l(V);lt=o(ya,"fast.ai\u2019s"),ya.forEach(t),nt=d(ue),W=s(ue,"A",{href:!0,rel:!0});var qa=l(W);ot=o(qa,"Practical Deep Learning for Coders"),qa.forEach(t),it=o(ue," ou un des cours d\xE9velopp\xE9s par "),Y=s(ue,"A",{href:!0,rel:!0});var Na=l(Y);ut=o(Na,"DeepLearning.AI"),Na.forEach(t),ue.forEach(t),ct=d(he),y=s(he,"LI",{});var ve=l(y);pt=o(ve,"N\u2019attend pas une connaissance appronfondie de "),K=s(ve,"A",{href:!0,rel:!0});var Ta=l(K);dt=o(Ta,"PyTorch"),Ta.forEach(t),mt=o(ve," ou de "),X=s(ve,"A",{href:!0,rel:!0});var Aa=l(X);ft=o(Aa,"TensorFlow"),Aa.forEach(t),ht=o(ve,", bien qu\u2019\xEAtre familiaris\xE9 avec l\u2019un d\u2019entre eux peut aider"),ve.forEach(t),he.forEach(t),lr=d(e),S=s(e,"P",{});var Pr=l(S);vt=o(Pr,"Apr\xE8s avoir termin\xE9 ce cours, nous vous recommandons de suivre la "),Z=s(Pr,"A",{href:!0,rel:!0});var $a=l(Z);gt=o($a,"Sp\xE9cialisation en NLP"),$a.forEach(t),_t=o(Pr," dispens\xE9e par DeepLearning.AI, qui couvre une grande gamme de mod\xE8les traditionnels de NLP comme les Na\xEFves Bayes et les LSTMs qui sont importants \xE0 conna\xEEtre!"),Pr.forEach(t),nr=d(e),q=s(e,"H2",{class:!0});var yr=l(q);x=s(yr,"A",{id:!0,class:!0,href:!0});var za=l(x);Te=s(za,"SPAN",{});var Ia=l(Te);Oe(ee.$$.fragment,Ia),Ia.forEach(t),za.forEach(t),bt=d(yr),Ae=s(yr,"SPAN",{});var Sa=l(Ae);Et=o(Sa,"Qui sommes-nous ?"),Sa.forEach(t),yr.forEach(t),or=d(e),de=s(e,"P",{});var xa=l(de);wt=o(xa,"\xC0 propos des auteurs de ce cours:"),xa.forEach(t),ir=d(e),re=s(e,"P",{});var Yt=l(re);$e=s(Yt,"STRONG",{});var Ha=l($e);Lt=o(Ha,"Matthew Carrigan"),Ha.forEach(t),Pt=o(Yt," est Machine Learning Engineer chez Hugging Face. Il vit \xE0 Dublin, en Irlande et \xE0 travaill\xE9 auparavant comme ing\xE9nieur en ML chez Parse.ly et avant cela comme chercheur postdoctoral \xE0 Trinity College Dublin. Il ne croit pas que nous arrivions \xE0 AGI en mettant \xE0 l\u2019\xE9chelle les architectures existantes, mais il a tout de m\xEAme beaucoup d\u2019espoir dans l\u2019immortalit\xE9 des robots."),Yt.forEach(t),ur=d(e),te=s(e,"P",{});var Kt=l(te);ze=s(Kt,"STRONG",{});var Ma=l(ze);yt=o(Ma,"Lysandre Debut"),Ma.forEach(t),qt=o(Kt," est Machine Learning Engineer chez Hugging Face et a travaill\xE9 sur la librairie \u{1F917} Transformers depuis les premi\xE8res phases de d\xE9veloppement. Son but est de rendre NLP accessible pour tout le monde en d\xE9veloppant des outils disposant d\u2019une API tr\xE8s simple."),Kt.forEach(t),cr=d(e),N=s(e,"P",{});var Ge=l(N);Ie=s(Ge,"STRONG",{});var ka=l(Ie);Nt=o(ka,"Sylvain Gugger"),ka.forEach(t),Tt=o(Ge," est Research Engineer chez Hugging Face et un des principaux responsable de la librairie \u{1F917} Transformers. Pr\xE9c\xE9demment, Il a \xE9t\xE9 chercheur en ML chez fast.ai et a \xE9crit "),Se=s(Ge,"EM",{});var Da=l(Se);ae=s(Da,"A",{href:!0,rel:!0});var Fa=l(ae);At=o(Fa,"Deep Learning for Coders with fastai and PyTorch"),Fa.forEach(t),Da.forEach(t),$t=o(Ge," avec Jeremy Howard. Son but ultime est de rendre le deep learning plus accessible, en d\xE9veloppant et en am\xE9liorant des techniques permettant aux mod\xE8les d\u2019apprendre rapidement sur des ressources limit\xE9es."),Ge.forEach(t),pr=d(e),se=s(e,"P",{});var Xt=l(se);xe=s(Xt,"STRONG",{});var Ca=l(xe);zt=o(Ca,"Merve Noyan"),Ca.forEach(t),It=o(Xt," est Developer Advocate chez Hugging Face et travaille \xE0 la cr\xE9ation d\u2019outils et de contenu visant \xE0 d\xE9mocratiser le machine learning pour tous."),Xt.forEach(t),dr=d(e),le=s(e,"P",{});var Zt=l(le);He=s(Zt,"STRONG",{});var Ga=l(He);St=o(Ga,"Lucile Saulnier"),Ga.forEach(t),xt=o(Zt," est Machine Learning Engineer chez Hugging Face qui travaille au d\xE9veloppement et \xE0 l\u2019impl\xE9mentation de nombreux outils open source. Elle est \xE9galement activement impliqu\xE9e dans de nombreux projets de recherche dans le domaine de NLP comme l\u2019entra\xEEnement collaboratif de mod\xE8les et le projet BigScience."),Zt.forEach(t),mr=d(e),T=s(e,"P",{});var Re=l(T);Me=s(Re,"STRONG",{});var Ra=l(Me);Ht=o(Ra,"Lewis Tunstall"),Ra.forEach(t),Mt=o(Re," est Machine Learning Engineer chez Hugging Face d\xE9vou\xE9 au d\xE9veloppement d\u2019outils open source avec la volont\xE9 de les rendre accessibles \xE0 une communaut\xE9 plus large. Il est \xE9galement co-auteur d\u2019un livre qui va bient\xF4t para\xEEtre, "),ne=s(Re,"A",{href:!0,rel:!0});var ja=l(ne);kt=o(ja,"Natural Language Processing with Transformers"),ja.forEach(t),Dt=o(Re,"."),Re.forEach(t),fr=d(e),A=s(e,"P",{});var je=l(A);ke=s(je,"STRONG",{});var Ba=l(ke);Ft=o(Ba,"Leandro von Werra"),Ba.forEach(t),Ct=o(je," est Machine Learning Engineer dans l\u2019\xE9quipe open-source chez Hugging Face et \xE9galement co-auteur du livre qui va bient\xF4t para\xEEtre, "),oe=s(je,"A",{href:!0,rel:!0});var Oa=l(oe);Gt=o(Oa,"Natural Language Processing with Transformers"),Oa.forEach(t),Rt=o(je,". Il a plusieurs ann\xE9es d\u2019exp\xE9rience dans l\u2019industrie du machine learning, o\xF9 il a pu d\xE9ployer des projets de NLP en production en travaillant sur toutes les \xE9tapes clefs du d\xE9ploiement."),je.forEach(t),hr=d(e),me=s(e,"P",{});var Qa=l(me);jt=o(Qa,"\xCAtes-vous pr\xEAt \xE0 commencer ? Dans ce chapitre, vous apprendrez:"),Qa.forEach(t),vr=d(e),_=s(e,"UL",{});var ge=l(_);ie=s(ge,"LI",{});var qr=l(ie);Bt=o(qr,"\xC0 utiliser la fonction "),De=s(qr,"CODE",{});var Ua=l(De);Ot=o(Ua,"pipeline()"),Ua.forEach(t),Qt=o(qr," pour r\xE9soudre des probl\xE8mes de NLP comme la g\xE9n\xE9ration de texte et la classification"),qr.forEach(t),Ut=d(ge),Fe=s(ge,"LI",{});var Ja=l(Fe);Jt=o(Ja,"Quelle est l\u2019architecture d\u2019un mod\xE8le Transformer"),Ja.forEach(t),Vt=d(ge),Ce=s(ge,"LI",{});var Va=l(Ce);Wt=o(Va,"Comment faire la distinction entre les diff\xE9rentes architectures d\u2019encodeur, de d\xE9codeur et d\u2019encodeur-d\xE9codeur et leurs condition d\u2019utilisation"),Va.forEach(t),ge.forEach(t),this.h()},h(){i(b,"name","hf:doc:metadata"),i(b,"content",JSON.stringify(ss)),i($,"id","introduction"),i($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i($,"href","#introduction"),i(E,"class","relative group"),i(z,"id","bienvenue-sur-le-cours"),i(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(z,"href","#bienvenue-sur-le-cours"),i(w,"class","relative group"),i(D,"href","https://huggingface.co/"),i(D,"rel","nofollow"),i(F,"href","https://github.com/huggingface/transformers"),i(F,"rel","nofollow"),i(C,"href","https://github.com/huggingface/datasets"),i(C,"rel","nofollow"),i(G,"href","https://github.com/huggingface/tokenizers"),i(G,"rel","nofollow"),i(R,"href","https://github.com/huggingface/accelerate"),i(R,"rel","nofollow"),i(j,"href","https://huggingface.co/models"),i(j,"rel","nofollow"),i(I,"id","quoi-sattendre"),i(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(I,"href","#quoi-sattendre"),i(L,"class","relative group"),i(O,"class","block dark:hidden"),Wa(O.src,ra="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg")||i(O,"src",ra),i(O,"alt","Bref aper\xE7u du contenu du cours."),i(Q,"class","hidden dark:block"),Wa(Q.src,ta="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg")||i(Q,"src",ta),i(Q,"alt","Bref aper\xE7u des diff\xE9rents chapitres du cours."),i(P,"class","flex justify-center"),i(J,"href","https://huggingface.co/models"),i(J,"rel","nofollow"),i(V,"href","https://www.fast.ai/"),i(V,"rel","nofollow"),i(W,"href","https://course.fast.ai/"),i(W,"rel","nofollow"),i(Y,"href","https://www.deeplearning.ai/"),i(Y,"rel","nofollow"),i(K,"href","https://pytorch.org/"),i(K,"rel","nofollow"),i(X,"href","https://www.tensorflow.org/"),i(X,"rel","nofollow"),i(Z,"href","https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh"),i(Z,"rel","nofollow"),i(x,"id","qui-sommesnous"),i(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(x,"href","#qui-sommesnous"),i(q,"class","relative group"),i(ae,"href","https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/"),i(ae,"rel","nofollow"),i(ne,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(ne,"rel","nofollow"),i(oe,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(oe,"rel","nofollow")},m(e,u){r(document.head,b),c(e,We,u),c(e,E,u),r(E,$),r($,_e),Qe(H,_e,null),r(E,Tr),r(E,be),r(be,Ar),c(e,Ye,u),c(e,w,u),r(w,z),r(z,Ee),Qe(M,Ee,null),r(w,$r),r(w,we),r(we,zr),c(e,Ke,u),Qe(k,e,u),c(e,Xe,u),c(e,m,u),r(m,Ir),r(m,D),r(D,Sr),r(m,xr),r(m,F),r(F,Hr),r(m,Mr),r(m,C),r(C,kr),r(m,Dr),r(m,G),r(G,Fr),r(m,Cr),r(m,R),r(R,Gr),r(m,Rr),r(m,j),r(j,jr),r(m,Br),c(e,Ze,u),c(e,L,u),r(L,I),r(I,Le),Qe(B,Le,null),r(L,Or),r(L,Pe),r(Pe,Qr),c(e,er,u),c(e,ce,u),r(ce,Ur),c(e,rr,u),c(e,P,u),r(P,O),r(P,Jr),r(P,Q),c(e,tr,u),c(e,h,u),r(h,U),r(U,Vr),r(U,J),r(J,Wr),r(U,Yr),r(h,Kr),r(h,ye),r(ye,Xr),r(h,Zr),r(h,qe),r(qe,et),c(e,ar,u),c(e,pe,u),r(pe,rt),c(e,sr,u),c(e,v,u),r(v,Ne),r(Ne,tt),r(v,at),r(v,g),r(g,st),r(g,V),r(V,lt),r(g,nt),r(g,W),r(W,ot),r(g,it),r(g,Y),r(Y,ut),r(v,ct),r(v,y),r(y,pt),r(y,K),r(K,dt),r(y,mt),r(y,X),r(X,ft),r(y,ht),c(e,lr,u),c(e,S,u),r(S,vt),r(S,Z),r(Z,gt),r(S,_t),c(e,nr,u),c(e,q,u),r(q,x),r(x,Te),Qe(ee,Te,null),r(q,bt),r(q,Ae),r(Ae,Et),c(e,or,u),c(e,de,u),r(de,wt),c(e,ir,u),c(e,re,u),r(re,$e),r($e,Lt),r(re,Pt),c(e,ur,u),c(e,te,u),r(te,ze),r(ze,yt),r(te,qt),c(e,cr,u),c(e,N,u),r(N,Ie),r(Ie,Nt),r(N,Tt),r(N,Se),r(Se,ae),r(ae,At),r(N,$t),c(e,pr,u),c(e,se,u),r(se,xe),r(xe,zt),r(se,It),c(e,dr,u),c(e,le,u),r(le,He),r(He,St),r(le,xt),c(e,mr,u),c(e,T,u),r(T,Me),r(Me,Ht),r(T,Mt),r(T,ne),r(ne,kt),r(T,Dt),c(e,fr,u),c(e,A,u),r(A,ke),r(ke,Ft),r(A,Ct),r(A,oe),r(oe,Gt),r(A,Rt),c(e,hr,u),c(e,me,u),r(me,jt),c(e,vr,u),c(e,_,u),r(_,ie),r(ie,Bt),r(ie,De),r(De,Ot),r(ie,Qt),r(_,Ut),r(_,Fe),r(Fe,Jt),r(_,Vt),r(_,Ce),r(Ce,Wt),gr=!0},p:es,i(e){gr||(Ue(H.$$.fragment,e),Ue(M.$$.fragment,e),Ue(k.$$.fragment,e),Ue(B.$$.fragment,e),Ue(ee.$$.fragment,e),gr=!0)},o(e){Je(H.$$.fragment,e),Je(M.$$.fragment,e),Je(k.$$.fragment,e),Je(B.$$.fragment,e),Je(ee.$$.fragment,e),gr=!1},d(e){t(b),e&&t(We),e&&t(E),Ve(H),e&&t(Ye),e&&t(w),Ve(M),e&&t(Ke),Ve(k,e),e&&t(Xe),e&&t(m),e&&t(Ze),e&&t(L),Ve(B),e&&t(er),e&&t(ce),e&&t(rr),e&&t(P),e&&t(tr),e&&t(h),e&&t(ar),e&&t(pe),e&&t(sr),e&&t(v),e&&t(lr),e&&t(S),e&&t(nr),e&&t(q),Ve(ee),e&&t(or),e&&t(de),e&&t(ir),e&&t(re),e&&t(ur),e&&t(te),e&&t(cr),e&&t(N),e&&t(pr),e&&t(se),e&&t(dr),e&&t(le),e&&t(mr),e&&t(T),e&&t(fr),e&&t(A),e&&t(hr),e&&t(me),e&&t(vr),e&&t(_)}}}const ss={local:"introduction",sections:[{local:"bienvenue-sur-le-cours",title:"Bienvenue sur le cours \u{1F917} !"},{local:"quoi-sattendre",title:"\xC0 quoi s'attendre ?"},{local:"qui-sommesnous",title:"Qui sommes-nous ?"}],title:"Introduction"};function ls(ea){return rs(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class us extends Ya{constructor(b){super();Ka(this,b,ls,as,Xa,{})}}export{us as default,ss as metadata};
