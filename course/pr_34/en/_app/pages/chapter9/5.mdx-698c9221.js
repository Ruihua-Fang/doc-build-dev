import{S as ya,i as xa,s as _a,e as s,k as m,w as M,t as c,M as $a,c as l,d as a,m as u,a as i,x as R,h as p,b as o,N as Xe,F as t,g as n,y as C,L as ka,q as N,o as z,B as O,v as Ha}from"../../chunks/vendor-1e8b365d.js";import{I as Ye}from"../../chunks/IconCopyLink-483c28ba.js";import{C as Ke}from"../../chunks/CodeBlock-e5764662.js";function Ea(Qe){let v,te,y,$,D,T,_e,U,$e,oe,b,ke,W,He,Ee,X,Te,qe,re,x,k,Y,q,Pe,K,Ae,se,h,Fe,Q,Ie,je,V,Se,Be,Z,Ge,Je,P,Le,Me,le,A,ie,B,Re,ne,f,Ve,ce,H,Ce,F,Ne,ze,pe,_,E,ee,I,Oe,ae,De,me,G,Ue,ue,j,he,g,Ze,fe,J,We,ge,S,de,d,ea,be;return T=new Ye({}),q=new Ye({}),A=new Ke({props:{code:`import gradio as gr

title = "GPT-J-6B"
description = "Gradio Demo for GPT-J 6B, a transformer model trained using Ben Wang's Mesh Transformer JAX. 'GPT-J' refers to the class of model, while '6B' represents the number of trainable parameters. To use it, simply add your text, or click one of the examples to load them. Read more at the links below."
article = "<p style='text-align: center'><a href='https://github.com/kingoflolz/mesh-transformer-jax' target='_blank'>GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model</a></p>"
examples = [
    ["The tower is 324 metres (1,063 ft) tall,"],
    ["The Moon's orbit around Earth has"],
    ["The smooth Borealis basin in the Northern Hemisphere covers 40%"],
]
gr.Interface.load(
    "huggingface/EleutherAI/gpt-j-6B",
    inputs=gr.inputs.Textbox(lines=5, label="Input Text"),
    title=title,
    description=description,
    article=article,
    examples=examples,
    enable_queue=True,
).launch()`,highlighted:`<span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr

title = <span class="hljs-string">&quot;GPT-J-6B&quot;</span>
description = <span class="hljs-string">&quot;Gradio Demo for GPT-J 6B, a transformer model trained using Ben Wang&#x27;s Mesh Transformer JAX. &#x27;GPT-J&#x27; refers to the class of model, while &#x27;6B&#x27; represents the number of trainable parameters. To use it, simply add your text, or click one of the examples to load them. Read more at the links below.&quot;</span>
article = <span class="hljs-string">&quot;&lt;p style=&#x27;text-align: center&#x27;&gt;&lt;a href=&#x27;https://github.com/kingoflolz/mesh-transformer-jax&#x27; target=&#x27;_blank&#x27;&gt;GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model&lt;/a&gt;&lt;/p&gt;&quot;</span>
examples = [
    [<span class="hljs-string">&quot;The tower is 324 metres (1,063 ft) tall,&quot;</span>],
    [<span class="hljs-string">&quot;The Moon&#x27;s orbit around Earth has&quot;</span>],
    [<span class="hljs-string">&quot;The smooth Borealis basin in the Northern Hemisphere covers 40%&quot;</span>],
]
gr.Interface.load(
    <span class="hljs-string">&quot;huggingface/EleutherAI/gpt-j-6B&quot;</span>,
    inputs=gr.inputs.Textbox(lines=<span class="hljs-number">5</span>, label=<span class="hljs-string">&quot;Input Text&quot;</span>),
    title=title,
    description=description,
    article=article,
    examples=examples,
    enable_queue=<span class="hljs-literal">True</span>,
).launch()`}}),I=new Ye({}),j=new Ke({props:{code:'gr.Interface.load("spaces/abidlabs/remove-bg").launch()',highlighted:'gr.Interface.load(<span class="hljs-string">&quot;spaces/abidlabs/remove-bg&quot;</span>).launch()'}}),S=new Ke({props:{code:`gr.Interface.load(
    "spaces/abidlabs/remove-bg", inputs="webcam", title="Remove your webcam background!"
).launch()`,highlighted:`gr.Interface.load(
    <span class="hljs-string">&quot;spaces/abidlabs/remove-bg&quot;</span>, inputs=<span class="hljs-string">&quot;webcam&quot;</span>, title=<span class="hljs-string">&quot;Remove your webcam background!&quot;</span>
).launch()`}}),{c(){v=s("meta"),te=m(),y=s("h1"),$=s("a"),D=s("span"),M(T.$$.fragment),_e=m(),U=s("span"),$e=c("Integrations with the Hugging Face Hub"),oe=m(),b=s("p"),ke=c("To make your life even easier, "),W=s("code"),He=c("gradio"),Ee=c(` integrates directly with Hugging Face Hub and Hugging Face Spaces.
You can load demos from the Hub and Spaces with only `),X=s("em"),Te=c("one line of code"),qe=c("."),re=m(),x=s("h3"),k=s("a"),Y=s("span"),M(q.$$.fragment),Pe=m(),K=s("span"),Ae=c("Load models from the Hugging Face Hub"),se=c(`

To start with, choose one of the thousands of models Hugging Face offers through the Hub, as described in [Chapter 4](/course/chapter4/section2).
`),h=s("p"),Fe=c("Using the special "),Q=s("code"),Ie=c("gr.Interface.load()"),je=c(" method, you pass "),V=s("code"),Se=c('"model/"'),Be=c(" (or, equivalently, "),Z=s("code"),Ge=c('"huggingface/"'),Je=c(`)
followed by the model name.
For example, here is the code to build a demo for `),P=s("a"),Le=c("GPT-J"),Me=c(", a large language model & add a couple of examples inputs:"),le=m(),M(A.$$.fragment),ie=m(),B=s("p"),Re=c("The code above will produce the interface below:"),ne=m(),f=s("iframe"),ce=m(),H=s("p"),Ce=c("Loading a model in this way uses Hugging Face\u2019s "),F=s("a"),Ne=c("Inference API"),ze=c(`,
instead of loading the model in memory. This is ideal for huge models like GPT-J or T0pp which
require lots of RAM.`),pe=m(),_=s("h3"),E=s("a"),ee=s("span"),M(I.$$.fragment),Oe=m(),ae=s("span"),De=c("Loading from Hugging Face Spaces"),me=c(`

To load any Space from the Hugging Face Hub and recreate it locally, you pass \`spaces/\` followed by the model name.
`),G=s("p"),Ue=c("Remember the demo from section 1 that removes the background of an image? Let\u2019s load it from Hugging Face spaces:"),ue=m(),M(j.$$.fragment),he=m(),g=s("iframe"),fe=m(),J=s("p"),We=c(`One of the cool things about loading demos from the Hub or Spaces is that you customize them
by overriding any of the
parameters. Here, we add a title and get it to work with a webcam instead:`),ge=m(),M(S.$$.fragment),de=m(),d=s("iframe"),this.h()},l(e){const r=$a('[data-svelte="svelte-1phssyn"]',document.head);v=l(r,"META",{name:!0,content:!0}),r.forEach(a),te=u(e),y=l(e,"H1",{class:!0});var we=i(y);$=l(we,"A",{id:!0,class:!0,href:!0});var aa=i($);D=l(aa,"SPAN",{});var ta=i(D);R(T.$$.fragment,ta),ta.forEach(a),aa.forEach(a),_e=u(we),U=l(we,"SPAN",{});var oa=i(U);$e=p(oa,"Integrations with the Hugging Face Hub"),oa.forEach(a),we.forEach(a),oe=u(e),b=l(e,"P",{});var L=i(b);ke=p(L,"To make your life even easier, "),W=l(L,"CODE",{});var ra=i(W);He=p(ra,"gradio"),ra.forEach(a),Ee=p(L,` integrates directly with Hugging Face Hub and Hugging Face Spaces.
You can load demos from the Hub and Spaces with only `),X=l(L,"EM",{});var sa=i(X);Te=p(sa,"one line of code"),sa.forEach(a),qe=p(L,"."),L.forEach(a),re=u(e),x=l(e,"H3",{class:!0});var ve=i(x);k=l(ve,"A",{id:!0,class:!0,href:!0});var la=i(k);Y=l(la,"SPAN",{});var ia=i(Y);R(q.$$.fragment,ia),ia.forEach(a),la.forEach(a),Pe=u(ve),K=l(ve,"SPAN",{});var na=i(K);Ae=p(na,"Load models from the Hugging Face Hub"),na.forEach(a),ve.forEach(a),se=p(e,`

To start with, choose one of the thousands of models Hugging Face offers through the Hub, as described in [Chapter 4](/course/chapter4/section2).
`),h=l(e,"P",{});var w=i(h);Fe=p(w,"Using the special "),Q=l(w,"CODE",{});var ca=i(Q);Ie=p(ca,"gr.Interface.load()"),ca.forEach(a),je=p(w," method, you pass "),V=l(w,"CODE",{});var pa=i(V);Se=p(pa,'"model/"'),pa.forEach(a),Be=p(w," (or, equivalently, "),Z=l(w,"CODE",{});var ma=i(Z);Ge=p(ma,'"huggingface/"'),ma.forEach(a),Je=p(w,`)
followed by the model name.
For example, here is the code to build a demo for `),P=l(w,"A",{href:!0,rel:!0});var ua=i(P);Le=p(ua,"GPT-J"),ua.forEach(a),Me=p(w,", a large language model & add a couple of examples inputs:"),w.forEach(a),le=u(e),R(A.$$.fragment,e),ie=u(e),B=l(e,"P",{});var ha=i(B);Re=p(ha,"The code above will produce the interface below:"),ha.forEach(a),ne=u(e),f=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),i(f).forEach(a),ce=u(e),H=l(e,"P",{});var ye=i(H);Ce=p(ye,"Loading a model in this way uses Hugging Face\u2019s "),F=l(ye,"A",{href:!0,rel:!0});var fa=i(F);Ne=p(fa,"Inference API"),fa.forEach(a),ze=p(ye,`,
instead of loading the model in memory. This is ideal for huge models like GPT-J or T0pp which
require lots of RAM.`),ye.forEach(a),pe=u(e),_=l(e,"H3",{class:!0});var xe=i(_);E=l(xe,"A",{id:!0,class:!0,href:!0});var ga=i(E);ee=l(ga,"SPAN",{});var da=i(ee);R(I.$$.fragment,da),da.forEach(a),ga.forEach(a),Oe=u(xe),ae=l(xe,"SPAN",{});var ba=i(ae);De=p(ba,"Loading from Hugging Face Spaces"),ba.forEach(a),xe.forEach(a),me=p(e,`

To load any Space from the Hugging Face Hub and recreate it locally, you pass \`spaces/\` followed by the model name.
`),G=l(e,"P",{});var wa=i(G);Ue=p(wa,"Remember the demo from section 1 that removes the background of an image? Let\u2019s load it from Hugging Face spaces:"),wa.forEach(a),ue=u(e),R(j.$$.fragment,e),he=u(e),g=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),i(g).forEach(a),fe=u(e),J=l(e,"P",{});var va=i(J);We=p(va,`One of the cool things about loading demos from the Hub or Spaces is that you customize them
by overriding any of the
parameters. Here, we add a title and get it to work with a webcam instead:`),va.forEach(a),ge=u(e),R(S.$$.fragment,e),de=u(e),d=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),i(d).forEach(a),this.h()},h(){o(v,"name","hf:doc:metadata"),o(v,"content",JSON.stringify(Ta)),o($,"id","integrations-with-the-hugging-face-hub"),o($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o($,"href","#integrations-with-the-hugging-face-hub"),o(y,"class","relative group"),o(k,"id","load-models-from-the-hugging-face-hub"),o(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(k,"href","#load-models-from-the-hugging-face-hub"),o(x,"class","relative group"),o(P,"href","https://huggingface.co/EleutherAI/gpt-j-6B"),o(P,"rel","nofollow"),Xe(f.src,Ve="https://hf.space/gradioiframe/akhaliq/gpt-j-6B/+")||o(f,"src",Ve),o(f,"frameborder","0"),o(f,"height","750"),o(f,"title","Gradio app"),o(f,"class","container p-0 flex-grow space-iframe"),o(f,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),o(f,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),o(F,"href","https://huggingface.co/inference-api"),o(F,"rel","nofollow"),o(E,"id","loading-from-hugging-face-spaces"),o(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(E,"href","#loading-from-hugging-face-spaces"),o(_,"class","relative group"),Xe(g.src,Ze="https://hf.space/gradioiframe/abidlabs/remove-bg/+")||o(g,"src",Ze),o(g,"frameborder","0"),o(g,"height","650"),o(g,"title","Gradio app"),o(g,"class","container p-0 flex-grow space-iframe"),o(g,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),o(g,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),Xe(d.src,ea="https://hf.space/gradioiframe/dawood/Remove-bg/+")||o(d,"src",ea),o(d,"frameborder","0"),o(d,"height","550"),o(d,"title","Gradio app"),o(d,"class","container p-0 flex-grow space-iframe"),o(d,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),o(d,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads")},m(e,r){t(document.head,v),n(e,te,r),n(e,y,r),t(y,$),t($,D),C(T,D,null),t(y,_e),t(y,U),t(U,$e),n(e,oe,r),n(e,b,r),t(b,ke),t(b,W),t(W,He),t(b,Ee),t(b,X),t(X,Te),t(b,qe),n(e,re,r),n(e,x,r),t(x,k),t(k,Y),C(q,Y,null),t(x,Pe),t(x,K),t(K,Ae),n(e,se,r),n(e,h,r),t(h,Fe),t(h,Q),t(Q,Ie),t(h,je),t(h,V),t(V,Se),t(h,Be),t(h,Z),t(Z,Ge),t(h,Je),t(h,P),t(P,Le),t(h,Me),n(e,le,r),C(A,e,r),n(e,ie,r),n(e,B,r),t(B,Re),n(e,ne,r),n(e,f,r),n(e,ce,r),n(e,H,r),t(H,Ce),t(H,F),t(F,Ne),t(H,ze),n(e,pe,r),n(e,_,r),t(_,E),t(E,ee),C(I,ee,null),t(_,Oe),t(_,ae),t(ae,De),n(e,me,r),n(e,G,r),t(G,Ue),n(e,ue,r),C(j,e,r),n(e,he,r),n(e,g,r),n(e,fe,r),n(e,J,r),t(J,We),n(e,ge,r),C(S,e,r),n(e,de,r),n(e,d,r),be=!0},p:ka,i(e){be||(N(T.$$.fragment,e),N(q.$$.fragment,e),N(A.$$.fragment,e),N(I.$$.fragment,e),N(j.$$.fragment,e),N(S.$$.fragment,e),be=!0)},o(e){z(T.$$.fragment,e),z(q.$$.fragment,e),z(A.$$.fragment,e),z(I.$$.fragment,e),z(j.$$.fragment,e),z(S.$$.fragment,e),be=!1},d(e){a(v),e&&a(te),e&&a(y),O(T),e&&a(oe),e&&a(b),e&&a(re),e&&a(x),O(q),e&&a(se),e&&a(h),e&&a(le),O(A,e),e&&a(ie),e&&a(B),e&&a(ne),e&&a(f),e&&a(ce),e&&a(H),e&&a(pe),e&&a(_),O(I),e&&a(me),e&&a(G),e&&a(ue),O(j,e),e&&a(he),e&&a(g),e&&a(fe),e&&a(J),e&&a(ge),O(S,e),e&&a(de),e&&a(d)}}}const Ta={local:"integrations-with-the-hugging-face-hub",sections:[{local:"load-models-from-the-hugging-face-hub",title:"Load models from the Hugging Face Hub"},{local:"loading-from-hugging-face-spaces",title:"Loading from Hugging Face Spaces"}],title:"Integrations with the Hugging Face Hub"};function qa(Qe){return Ha(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ia extends ya{constructor(v){super();xa(this,v,qa,Ea,_a,{})}}export{Ia as default,Ta as metadata};
