import{S as wr,i as vr,s as yr,e as l,k as c,w as F,t as o,M as _r,c as n,d as a,m as h,a as r,x as H,h as s,b as u,N as Yl,F as t,g as p,y as Y,L as br,q as z,o as U,B as W,v as Er}from"../../chunks/vendor-1e8b365d.js";import{I as Ue}from"../../chunks/IconCopyLink-483c28ba.js";import{C as zl}from"../../chunks/CodeBlock-e5764662.js";function kr(Ul){let D,Jt,P,M,We,ue,ao,Me,oo,Rt,B,so,Be,lo,no,Kt,O,J,Je,ce,ro,Re,io,Qt,R,po,Ke,uo,co,Vt,je,Qe,ho,Xt,xe,fo,Zt,g,$e,Ve,mo,wo,vo,j,Xe,yo,_o,Ze,bo,Eo,et,ko,go,jo,b,tt,xo,$o,at,qo,Ao,ot,Io,Co,st,Do,Po,ea,K,Oo,he,To,So,ta,m,No,qe,Lo,Go,lt,Fo,Ho,nt,Yo,zo,rt,Uo,Wo,aa,Q,Mo,it,Bo,Jo,oa,T,V,pt,de,Ro,ut,Ko,sa,X,Qo,ct,Vo,Xo,la,Ae,Zo,na,d,es,ht,ts,as,dt,os,ss,ft,ls,ns,mt,rs,is,wt,ps,us,ra,w,cs,vt,hs,ds,yt,fs,ms,_t,ws,vs,bt,ys,_s,ia,x,bs,Et,Es,ks,kt,gs,js,pa,fe,ua,Z,xs,me,$s,qs,ca,v,Wl,ha,Ie,As,da,S,ee,gt,we,Is,jt,Cs,fa,Ce,Ds,ma,De,Ps,wa,Pe,Os,va,te,xt,Ts,Ss,$t,Ns,ya,ae,Ls,qt,Gs,Fs,_a,ve,ba,y,Ml,Ea,N,oe,At,ye,Hs,_e,Ys,It,zs,Us,ka,se,Ws,Ct,Ms,Bs,ga,le,Js,Dt,Rs,Ks,ja,ne,Qs,Pt,Vs,Xs,xa,$,Oe,Ot,Zs,el,tl,Te,Tt,al,ol,sl,Se,St,ll,nl,$a,re,rl,Nt,il,pl,qa,L,ie,Lt,be,ul,Gt,cl,Aa,q,hl,Ft,dl,fl,Ht,ml,wl,Ia,f,vl,Yt,yl,_l,Ne,bl,El,zt,kl,gl,Ut,jl,xl,Wt,$l,ql,Ca,Ee,Da,pe,Al,ke,Il,Cl,Pa,_,Bl,Oa,A,Dl,Mt,Pl,Ol,Bt,Tl,Sl,Ta,Le,Nl,Sa;return ue=new Ue({}),ce=new Ue({}),de=new Ue({}),fe=new zl({props:{code:`import numpy as np
import gradio as gr


def reverse_audio(audio):
    sr, data = audio
    reversed_audio = (sr, np.flipud(data))
    return reversed_audio


mic = gr.inputs.Audio(source="microphone", type="numpy", label="Speak here...")
gr.Interface(reverse_audio, mic, "audio").launch()`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr


<span class="hljs-keyword">def</span> <span class="hljs-title function_">reverse_audio</span>(<span class="hljs-params">audio</span>):
    sr, data = audio
    reversed_audio = (sr, np.flipud(data))
    <span class="hljs-keyword">return</span> reversed_audio


mic = gr.inputs.Audio(source=<span class="hljs-string">&quot;microphone&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;numpy&quot;</span>, label=<span class="hljs-string">&quot;Speak here...&quot;</span>)
gr.Interface(reverse_audio, mic, <span class="hljs-string">&quot;audio&quot;</span>).launch()`}}),we=new Ue({}),ve=new zl({props:{code:`import numpy as np
import gradio as gr

notes = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]


def generate_tone(note, octave, duration):
    sr = 48000
    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)
    frequency = a4_freq * 2 ** (tones_from_a4 / 12)
    duration = int(duration)
    audio = np.linspace(0, duration, duration * sr)
    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)
    return (sr, audio)


gr.Interface(
    generate_tone,
    [
        gr.inputs.Dropdown(notes, type="index"),
        gr.inputs.Slider(4, 6, step=1),
        gr.inputs.Textbox(type="number", default=1, label="Duration in seconds"),
    ],
    "audio",
).launch()`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr

notes = [<span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-string">&quot;C#&quot;</span>, <span class="hljs-string">&quot;D&quot;</span>, <span class="hljs-string">&quot;D#&quot;</span>, <span class="hljs-string">&quot;E&quot;</span>, <span class="hljs-string">&quot;F&quot;</span>, <span class="hljs-string">&quot;F#&quot;</span>, <span class="hljs-string">&quot;G&quot;</span>, <span class="hljs-string">&quot;G#&quot;</span>, <span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-string">&quot;A#&quot;</span>, <span class="hljs-string">&quot;B&quot;</span>]


<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_tone</span>(<span class="hljs-params">note, octave, duration</span>):
    sr = <span class="hljs-number">48000</span>
    a4_freq, tones_from_a4 = <span class="hljs-number">440</span>, <span class="hljs-number">12</span> * (octave - <span class="hljs-number">4</span>) + (note - <span class="hljs-number">9</span>)
    frequency = a4_freq * <span class="hljs-number">2</span> ** (tones_from_a4 / <span class="hljs-number">12</span>)
    duration = <span class="hljs-built_in">int</span>(duration)
    audio = np.linspace(<span class="hljs-number">0</span>, duration, duration * sr)
    audio = (<span class="hljs-number">20000</span> * np.sin(audio * (<span class="hljs-number">2</span> * np.pi * frequency))).astype(np.int16)
    <span class="hljs-keyword">return</span> (sr, audio)


gr.Interface(
    generate_tone,
    [
        gr.inputs.Dropdown(notes, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;index&quot;</span>),
        gr.inputs.Slider(<span class="hljs-number">4</span>, <span class="hljs-number">6</span>, step=<span class="hljs-number">1</span>),
        gr.inputs.Textbox(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;number&quot;</span>, default=<span class="hljs-number">1</span>, label=<span class="hljs-string">&quot;Duration in seconds&quot;</span>),
    ],
    <span class="hljs-string">&quot;audio&quot;</span>,
).launch()`}}),ye=new Ue({}),be=new Ue({}),Ee=new zl({props:{code:`from transformers import pipeline
import gradio as gr

model = pipeline("automatic-speech-recognition")


def transcribe_audio(mic=None, file=None):
    if mic is not None:
        audio = mic
    elif file is not None:
        audio = file
    else:
        return "You must either provide a mic recording or a file"
    transcription = model(audio)["text"]
    return transcription


gr.Interface(
    fn=transcribe_audio,
    inputs=[
        gr.inputs.Audio(source="microphone", type="filepath", optional=True),
        gr.inputs.Audio(source="upload", type="filepath", optional=True),
    ],
    outputs="text",
).launch()`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr

model = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">transcribe_audio</span>(<span class="hljs-params">mic=<span class="hljs-literal">None</span>, file=<span class="hljs-literal">None</span></span>):
    <span class="hljs-keyword">if</span> mic <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
        audio = mic
    <span class="hljs-keyword">elif</span> file <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
        audio = file
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;You must either provide a mic recording or a file&quot;</span>
    transcription = model(audio)[<span class="hljs-string">&quot;text&quot;</span>]
    <span class="hljs-keyword">return</span> transcription


gr.Interface(
    fn=transcribe_audio,
    inputs=[
        gr.inputs.Audio(source=<span class="hljs-string">&quot;microphone&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;filepath&quot;</span>, optional=<span class="hljs-literal">True</span>),
        gr.inputs.Audio(source=<span class="hljs-string">&quot;upload&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;filepath&quot;</span>, optional=<span class="hljs-literal">True</span>),
    ],
    outputs=<span class="hljs-string">&quot;text&quot;</span>,
).launch()`}}),{c(){D=l("meta"),Jt=c(),P=l("h1"),M=l("a"),We=l("span"),F(ue.$$.fragment),ao=c(),Me=l("span"),oo=o("Understanding the Interface class"),Rt=c(),B=l("p"),so=o("In this section, we will take a closer look at the "),Be=l("code"),lo=o("Interface"),no=o(` class, and understand the
main parameters used to create one.`),Kt=c(),O=l("h2"),J=l("a"),Je=l("span"),F(ce.$$.fragment),ro=c(),Re=l("span"),io=o("How to create an Interface"),Qt=c(),R=l("p"),po=o("You\u2019ll notice that the "),Ke=l("code"),uo=o("Interface"),co=o(" class has 3 required parameters:"),Vt=c(),je=l("p"),Qe=l("code"),ho=o("Interface(fn, inputs, outputs, ...)"),Xt=c(),xe=l("p"),fo=o("These parameters are:"),Zt=c(),g=l("ul"),$e=l("li"),Ve=l("code"),mo=o("fn"),wo=o(": the prediction function that is wrapped by the Gradio interface. This function can take one or more parameters and return one or more values"),vo=c(),j=l("li"),Xe=l("code"),yo=o("inputs"),_o=o(": the input component type(s). Gradio provides many pre-built components such as"),Ze=l("code"),bo=o('"image"'),Eo=o(" or "),et=l("code"),ko=o('"mic"'),go=o("."),jo=c(),b=l("li"),tt=l("code"),xo=o("outputs"),$o=o(": the output component type(s). Again, "),at=l("code"),qo=o("gradio"),Ao=o(" provides many pre-built components e.g. "),ot=l("code"),Io=o('"image"'),Co=o(" or "),st=l("code"),Do=o('"label"'),Po=o("."),ea=c(),K=l("p"),Oo=o("For a complete list of components, "),he=l("a"),To=o("see the Gradio docs "),So=o(". Each pre-built component can be customized by instantiating the class corresponding to the component."),ta=c(),m=l("p"),No=o("For example, as we saw in the "),qe=l("a"),Lo=o("previous section"),Go=o(`,
instead of passing in `),lt=l("code"),Fo=o('"textbox"'),Ho=o(" to the "),nt=l("code"),Yo=o("inputs"),zo=o(" parameter, you can pass in a "),rt=l("code"),Uo=o('Textbox(lines=7, label="Prompt")'),Wo=o(" component to create a textbox with 7 lines and a label."),aa=c(),Q=l("p"),Mo=o("Let\u2019s take a look at another example, this time with an "),it=l("code"),Bo=o("Audio"),Jo=o(" component."),oa=c(),T=l("h2"),V=l("a"),pt=l("span"),F(de.$$.fragment),Ro=c(),ut=l("span"),Ko=o("A simple example with audio"),sa=c(),X=l("p"),Qo=o(`As mentioned earlier, Gradio provides many different inputs and outputs.
So let\u2019s build an `),ct=l("code"),Vo=o("Interface"),Xo=o(" that works with audio."),la=c(),Ae=l("p"),Zo=o(`In this example, we\u2019ll build an audio-to-audio function that takes an
audio file and simply reverses it.`),na=c(),d=l("p"),es=o("We will use for the input the "),ht=l("code"),ts=o("Audio"),as=o(" component. When using the "),dt=l("code"),os=o("Audio"),ss=o(` component,
you can specify whether you want the `),ft=l("code"),ls=o("source"),ns=o(` of the audio to be a file that the user
uploads or a microphone that the user records their voice with. In this case, let\u2019s
set it to a `),mt=l("code"),rs=o('"microphone"'),is=o(". Just for fun, we\u2019ll add a label to our "),wt=l("code"),ps=o("Audio"),us=o(` that says
\u201CSpeak here\u2026\u201C.`),ra=c(),w=l("p"),cs=o(`In addition, we\u2019d like to receive the audio as a numpy array so that we can easily
\u201Creverse\u201D it. So we\u2019ll set the `),vt=l("code"),hs=o('"type"'),ds=o(" to be "),yt=l("code"),fs=o('"numpy"'),ms=o(`, which passes the input
data as a tuple of (`),_t=l("code"),ws=o("sample_rate"),vs=o(", "),bt=l("code"),ys=o("data"),_s=o(") into our function."),ia=c(),x=l("p"),bs=o("We will also use the "),Et=l("code"),Es=o("Audio"),ks=o(` output component which can automatically
render a tuple with a sample rate and numpy array of data as a playable audio file.
In this case, we do not need to do any customization, so we will use the string
shortcut `),kt=l("code"),gs=o('"audio"'),js=o("."),pa=c(),F(fe.$$.fragment),ua=c(),Z=l("p"),xs=o(`The code above will produce an interface like the one below (if your browser doesn\u2019t
ask you for microphone permissions, `),me=l("a"),$s=o("open the demo in  a separate tab"),qs=o(".)"),ca=c(),v=l("iframe"),ha=c(),Ie=l("p"),As=o("You should now be able to record your voice and hear yourself speaking in reverse - spooky \u{1F47B}!"),da=c(),S=l("h2"),ee=l("a"),gt=l("span"),F(we.$$.fragment),Is=c(),jt=l("span"),Cs=o("Handling multiple inputs and outputs"),fa=c(),Ce=l("p"),Ds=o(`Let\u2019s say we had a more complicated function, with multiple inputs and outputs.
In the example below, we have a function that takes a dropdown index, a slider value, and number,
and returns an audio sample of a musical tone.`),ma=c(),De=l("p"),Ps=o(`Take a look how we pass a list of input and output components,
and see if you can follow along what\u2019s happening.`),wa=c(),Pe=l("p"),Os=o("The key here is that when you pass:"),va=c(),te=l("ul"),xt=l("li"),Ts=o("a list of input components, each component corresponds to a parameter in order."),Ss=c(),$t=l("li"),Ns=o("a list of output coponents, each component corresponds to a returned value."),ya=c(),ae=l("p"),Ls=o("The code snippet below shows how three input components line up with the three arguments of the "),qt=l("code"),Gs=o("generate_tone()"),Fs=o(" function:"),_a=c(),F(ve.$$.fragment),ba=c(),y=l("iframe"),Ea=c(),N=l("h3"),oe=l("a"),At=l("span"),F(ye.$$.fragment),Hs=c(),_e=l("span"),Ys=o("The "),It=l("code"),zs=o("launch()"),Us=o(" method"),ka=c(),se=l("p"),Ws=o("So far, we have used the "),Ct=l("code"),Ms=o("launch()"),Bs=o(` method to launch the interface, but we
haven\u2019t really discussed what it does.`),ga=c(),le=l("p"),Js=o("By default, the "),Dt=l("code"),Rs=o("launch()"),Ks=o(` method will launch the demo in a web server that
is running locally. If you are running your code in a Jupyter or Colab notebook, then
Gradio will embed the demo GUI in the notebook so you can easily use it.`),ja=c(),ne=l("p"),Qs=o("You can customize the behavior of "),Pt=l("code"),Vs=o("launch()"),Xs=o(" through different parameters:"),xa=c(),$=l("ul"),Oe=l("li"),Ot=l("code"),Zs=o("inline"),el=o(" - whether to display the interface inline on Python notebooks."),tl=c(),Te=l("li"),Tt=l("code"),al=o("inbrowser"),ol=o(" - whether to automatically launch the interface in a new tab on the default browser."),sl=c(),Se=l("li"),St=l("code"),ll=o("share"),nl=o(" - whether to create a publicly shareable link from your computer for the interface. Kind of like a Google Drive link!"),$a=c(),re=l("p"),rl=o("We\u2019ll cover the "),Nt=l("code"),il=o("share"),pl=o(" parameter in a lot more detail in the next section!"),qa=c(),L=l("h2"),ie=l("a"),Lt=l("span"),F(be.$$.fragment),ul=c(),Gt=l("span"),cl=o("\u270F\uFE0F Let's apply it!"),Aa=c(),q=l("p"),hl=o("Let\u2019s build an interface that allows you to demo a "),Ft=l("strong"),dl=o("speech-recognition"),fl=o(` model.
To make it interesting, we will accept `),Ht=l("em"),ml=o("either"),wl=o(" a mic input or an uploaded file."),Ia=c(),f=l("p"),vl=o("As usual, we\u2019ll load our speech recognition model using the the "),Yt=l("code"),yl=o("pipeline()"),_l=o(` function \u{1F917} Transformers.
If you need a quick refresher, you can go back to `),Ne=l("a"),bl=o("that section in Chapter 1"),El=o(".   Next, we\u2019ll implement a "),zt=l("code"),kl=o("transcribe_audio()"),gl=o(" function that processes the audio and returns the transcription. Finally, we\u2019ll wrap this function in an "),Ut=l("code"),jl=o("Interface"),xl=o(" with the "),Wt=l("code"),$l=o("Audio"),ql=o(" components for the inputs and just text for the output. Altogether, the code for this application is the following:"),Ca=c(),F(Ee.$$.fragment),Da=c(),pe=l("p"),Al=o("If your browser doesn\u2019t ask you for microphone permissions, "),ke=l("a"),Il=o("open the demo in a separate tab"),Cl=o("."),Pa=c(),_=l("iframe"),Oa=c(),A=l("p"),Dl=o(`That\u2019s it! You can now use this interface to transcribe audio. Notice here that
by passing in the `),Mt=l("code"),Pl=o("optional"),Ol=o(" parameter as "),Bt=l("code"),Tl=o("True"),Sl=o(`, we allow the user to either
provide a microphone or an audio file (or neither, but that will return an error message).`),Ta=c(),Le=l("p"),Nl=o("Keep going to see how to share your interface with others!"),this.h()},l(e){const i=_r('[data-svelte="svelte-1phssyn"]',document.head);D=n(i,"META",{name:!0,content:!0}),i.forEach(a),Jt=h(e),P=n(e,"H1",{class:!0});var Na=r(P);M=n(Na,"A",{id:!0,class:!0,href:!0});var Jl=r(M);We=n(Jl,"SPAN",{});var Rl=r(We);H(ue.$$.fragment,Rl),Rl.forEach(a),Jl.forEach(a),ao=h(Na),Me=n(Na,"SPAN",{});var Kl=r(Me);oo=s(Kl,"Understanding the Interface class"),Kl.forEach(a),Na.forEach(a),Rt=h(e),B=n(e,"P",{});var La=r(B);so=s(La,"In this section, we will take a closer look at the "),Be=n(La,"CODE",{});var Ql=r(Be);lo=s(Ql,"Interface"),Ql.forEach(a),no=s(La,` class, and understand the
main parameters used to create one.`),La.forEach(a),Kt=h(e),O=n(e,"H2",{class:!0});var Ga=r(O);J=n(Ga,"A",{id:!0,class:!0,href:!0});var Vl=r(J);Je=n(Vl,"SPAN",{});var Xl=r(Je);H(ce.$$.fragment,Xl),Xl.forEach(a),Vl.forEach(a),ro=h(Ga),Re=n(Ga,"SPAN",{});var Zl=r(Re);io=s(Zl,"How to create an Interface"),Zl.forEach(a),Ga.forEach(a),Qt=h(e),R=n(e,"P",{});var Fa=r(R);po=s(Fa,"You\u2019ll notice that the "),Ke=n(Fa,"CODE",{});var en=r(Ke);uo=s(en,"Interface"),en.forEach(a),co=s(Fa," class has 3 required parameters:"),Fa.forEach(a),Vt=h(e),je=n(e,"P",{});var tn=r(je);Qe=n(tn,"CODE",{});var an=r(Qe);ho=s(an,"Interface(fn, inputs, outputs, ...)"),an.forEach(a),tn.forEach(a),Xt=h(e),xe=n(e,"P",{});var on=r(xe);fo=s(on,"These parameters are:"),on.forEach(a),Zt=h(e),g=n(e,"UL",{});var Ge=r(g);$e=n(Ge,"LI",{});var Ll=r($e);Ve=n(Ll,"CODE",{});var sn=r(Ve);mo=s(sn,"fn"),sn.forEach(a),wo=s(Ll,": the prediction function that is wrapped by the Gradio interface. This function can take one or more parameters and return one or more values"),Ll.forEach(a),vo=h(Ge),j=n(Ge,"LI",{});var ge=r(j);Xe=n(ge,"CODE",{});var ln=r(Xe);yo=s(ln,"inputs"),ln.forEach(a),_o=s(ge,": the input component type(s). Gradio provides many pre-built components such as"),Ze=n(ge,"CODE",{});var nn=r(Ze);bo=s(nn,'"image"'),nn.forEach(a),Eo=s(ge," or "),et=n(ge,"CODE",{});var rn=r(et);ko=s(rn,'"mic"'),rn.forEach(a),go=s(ge,"."),ge.forEach(a),jo=h(Ge),b=n(Ge,"LI",{});var G=r(b);tt=n(G,"CODE",{});var pn=r(tt);xo=s(pn,"outputs"),pn.forEach(a),$o=s(G,": the output component type(s). Again, "),at=n(G,"CODE",{});var un=r(at);qo=s(un,"gradio"),un.forEach(a),Ao=s(G," provides many pre-built components e.g. "),ot=n(G,"CODE",{});var cn=r(ot);Io=s(cn,'"image"'),cn.forEach(a),Co=s(G," or "),st=n(G,"CODE",{});var hn=r(st);Do=s(hn,'"label"'),hn.forEach(a),Po=s(G,"."),G.forEach(a),Ge.forEach(a),ea=h(e),K=n(e,"P",{});var Ha=r(K);Oo=s(Ha,"For a complete list of components, "),he=n(Ha,"A",{href:!0,rel:!0});var dn=r(he);To=s(dn,"see the Gradio docs "),dn.forEach(a),So=s(Ha,". Each pre-built component can be customized by instantiating the class corresponding to the component."),Ha.forEach(a),ta=h(e),m=n(e,"P",{});var I=r(m);No=s(I,"For example, as we saw in the "),qe=n(I,"A",{href:!0});var fn=r(qe);Lo=s(fn,"previous section"),fn.forEach(a),Go=s(I,`,
instead of passing in `),lt=n(I,"CODE",{});var mn=r(lt);Fo=s(mn,'"textbox"'),mn.forEach(a),Ho=s(I," to the "),nt=n(I,"CODE",{});var wn=r(nt);Yo=s(wn,"inputs"),wn.forEach(a),zo=s(I," parameter, you can pass in a "),rt=n(I,"CODE",{});var vn=r(rt);Uo=s(vn,'Textbox(lines=7, label="Prompt")'),vn.forEach(a),Wo=s(I," component to create a textbox with 7 lines and a label."),I.forEach(a),aa=h(e),Q=n(e,"P",{});var Ya=r(Q);Mo=s(Ya,"Let\u2019s take a look at another example, this time with an "),it=n(Ya,"CODE",{});var yn=r(it);Bo=s(yn,"Audio"),yn.forEach(a),Jo=s(Ya," component."),Ya.forEach(a),oa=h(e),T=n(e,"H2",{class:!0});var za=r(T);V=n(za,"A",{id:!0,class:!0,href:!0});var _n=r(V);pt=n(_n,"SPAN",{});var bn=r(pt);H(de.$$.fragment,bn),bn.forEach(a),_n.forEach(a),Ro=h(za),ut=n(za,"SPAN",{});var En=r(ut);Ko=s(En,"A simple example with audio"),En.forEach(a),za.forEach(a),sa=h(e),X=n(e,"P",{});var Ua=r(X);Qo=s(Ua,`As mentioned earlier, Gradio provides many different inputs and outputs.
So let\u2019s build an `),ct=n(Ua,"CODE",{});var kn=r(ct);Vo=s(kn,"Interface"),kn.forEach(a),Xo=s(Ua," that works with audio."),Ua.forEach(a),la=h(e),Ae=n(e,"P",{});var gn=r(Ae);Zo=s(gn,`In this example, we\u2019ll build an audio-to-audio function that takes an
audio file and simply reverses it.`),gn.forEach(a),na=h(e),d=n(e,"P",{});var E=r(d);es=s(E,"We will use for the input the "),ht=n(E,"CODE",{});var jn=r(ht);ts=s(jn,"Audio"),jn.forEach(a),as=s(E," component. When using the "),dt=n(E,"CODE",{});var xn=r(dt);os=s(xn,"Audio"),xn.forEach(a),ss=s(E,` component,
you can specify whether you want the `),ft=n(E,"CODE",{});var $n=r(ft);ls=s($n,"source"),$n.forEach(a),ns=s(E,` of the audio to be a file that the user
uploads or a microphone that the user records their voice with. In this case, let\u2019s
set it to a `),mt=n(E,"CODE",{});var qn=r(mt);rs=s(qn,'"microphone"'),qn.forEach(a),is=s(E,". Just for fun, we\u2019ll add a label to our "),wt=n(E,"CODE",{});var An=r(wt);ps=s(An,"Audio"),An.forEach(a),us=s(E,` that says
\u201CSpeak here\u2026\u201C.`),E.forEach(a),ra=h(e),w=n(e,"P",{});var C=r(w);cs=s(C,`In addition, we\u2019d like to receive the audio as a numpy array so that we can easily
\u201Creverse\u201D it. So we\u2019ll set the `),vt=n(C,"CODE",{});var In=r(vt);hs=s(In,'"type"'),In.forEach(a),ds=s(C," to be "),yt=n(C,"CODE",{});var Cn=r(yt);fs=s(Cn,'"numpy"'),Cn.forEach(a),ms=s(C,`, which passes the input
data as a tuple of (`),_t=n(C,"CODE",{});var Dn=r(_t);ws=s(Dn,"sample_rate"),Dn.forEach(a),vs=s(C,", "),bt=n(C,"CODE",{});var Pn=r(bt);ys=s(Pn,"data"),Pn.forEach(a),_s=s(C,") into our function."),C.forEach(a),ia=h(e),x=n(e,"P",{});var Fe=r(x);bs=s(Fe,"We will also use the "),Et=n(Fe,"CODE",{});var On=r(Et);Es=s(On,"Audio"),On.forEach(a),ks=s(Fe,` output component which can automatically
render a tuple with a sample rate and numpy array of data as a playable audio file.
In this case, we do not need to do any customization, so we will use the string
shortcut `),kt=n(Fe,"CODE",{});var Tn=r(kt);gs=s(Tn,'"audio"'),Tn.forEach(a),js=s(Fe,"."),Fe.forEach(a),pa=h(e),H(fe.$$.fragment,e),ua=h(e),Z=n(e,"P",{});var Wa=r(Z);xs=s(Wa,`The code above will produce an interface like the one below (if your browser doesn\u2019t
ask you for microphone permissions, `),me=n(Wa,"A",{href:!0,target:!0});var Sn=r(me);$s=s(Sn,"open the demo in  a separate tab"),Sn.forEach(a),qs=s(Wa,".)"),Wa.forEach(a),ca=h(e),v=n(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),r(v).forEach(a),ha=h(e),Ie=n(e,"P",{});var Nn=r(Ie);As=s(Nn,"You should now be able to record your voice and hear yourself speaking in reverse - spooky \u{1F47B}!"),Nn.forEach(a),da=h(e),S=n(e,"H2",{class:!0});var Ma=r(S);ee=n(Ma,"A",{id:!0,class:!0,href:!0});var Ln=r(ee);gt=n(Ln,"SPAN",{});var Gn=r(gt);H(we.$$.fragment,Gn),Gn.forEach(a),Ln.forEach(a),Is=h(Ma),jt=n(Ma,"SPAN",{});var Fn=r(jt);Cs=s(Fn,"Handling multiple inputs and outputs"),Fn.forEach(a),Ma.forEach(a),fa=h(e),Ce=n(e,"P",{});var Hn=r(Ce);Ds=s(Hn,`Let\u2019s say we had a more complicated function, with multiple inputs and outputs.
In the example below, we have a function that takes a dropdown index, a slider value, and number,
and returns an audio sample of a musical tone.`),Hn.forEach(a),ma=h(e),De=n(e,"P",{});var Yn=r(De);Ps=s(Yn,`Take a look how we pass a list of input and output components,
and see if you can follow along what\u2019s happening.`),Yn.forEach(a),wa=h(e),Pe=n(e,"P",{});var zn=r(Pe);Os=s(zn,"The key here is that when you pass:"),zn.forEach(a),va=h(e),te=n(e,"UL",{});var Ba=r(te);xt=n(Ba,"LI",{});var Un=r(xt);Ts=s(Un,"a list of input components, each component corresponds to a parameter in order."),Un.forEach(a),Ss=h(Ba),$t=n(Ba,"LI",{});var Wn=r($t);Ns=s(Wn,"a list of output coponents, each component corresponds to a returned value."),Wn.forEach(a),Ba.forEach(a),ya=h(e),ae=n(e,"P",{});var Ja=r(ae);Ls=s(Ja,"The code snippet below shows how three input components line up with the three arguments of the "),qt=n(Ja,"CODE",{});var Mn=r(qt);Gs=s(Mn,"generate_tone()"),Mn.forEach(a),Fs=s(Ja," function:"),Ja.forEach(a),_a=h(e),H(ve.$$.fragment,e),ba=h(e),y=n(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),r(y).forEach(a),Ea=h(e),N=n(e,"H3",{class:!0});var Ra=r(N);oe=n(Ra,"A",{id:!0,class:!0,href:!0});var Bn=r(oe);At=n(Bn,"SPAN",{});var Jn=r(At);H(ye.$$.fragment,Jn),Jn.forEach(a),Bn.forEach(a),Hs=h(Ra),_e=n(Ra,"SPAN",{});var Ka=r(_e);Ys=s(Ka,"The "),It=n(Ka,"CODE",{});var Rn=r(It);zs=s(Rn,"launch()"),Rn.forEach(a),Us=s(Ka," method"),Ka.forEach(a),Ra.forEach(a),ka=h(e),se=n(e,"P",{});var Qa=r(se);Ws=s(Qa,"So far, we have used the "),Ct=n(Qa,"CODE",{});var Kn=r(Ct);Ms=s(Kn,"launch()"),Kn.forEach(a),Bs=s(Qa,` method to launch the interface, but we
haven\u2019t really discussed what it does.`),Qa.forEach(a),ga=h(e),le=n(e,"P",{});var Va=r(le);Js=s(Va,"By default, the "),Dt=n(Va,"CODE",{});var Qn=r(Dt);Rs=s(Qn,"launch()"),Qn.forEach(a),Ks=s(Va,` method will launch the demo in a web server that
is running locally. If you are running your code in a Jupyter or Colab notebook, then
Gradio will embed the demo GUI in the notebook so you can easily use it.`),Va.forEach(a),ja=h(e),ne=n(e,"P",{});var Xa=r(ne);Qs=s(Xa,"You can customize the behavior of "),Pt=n(Xa,"CODE",{});var Vn=r(Pt);Vs=s(Vn,"launch()"),Vn.forEach(a),Xs=s(Xa," through different parameters:"),Xa.forEach(a),xa=h(e),$=n(e,"UL",{});var He=r($);Oe=n(He,"LI",{});var Gl=r(Oe);Ot=n(Gl,"CODE",{});var Xn=r(Ot);Zs=s(Xn,"inline"),Xn.forEach(a),el=s(Gl," - whether to display the interface inline on Python notebooks."),Gl.forEach(a),tl=h(He),Te=n(He,"LI",{});var Fl=r(Te);Tt=n(Fl,"CODE",{});var Zn=r(Tt);al=s(Zn,"inbrowser"),Zn.forEach(a),ol=s(Fl," - whether to automatically launch the interface in a new tab on the default browser."),Fl.forEach(a),sl=h(He),Se=n(He,"LI",{});var Hl=r(Se);St=n(Hl,"CODE",{});var er=r(St);ll=s(er,"share"),er.forEach(a),nl=s(Hl," - whether to create a publicly shareable link from your computer for the interface. Kind of like a Google Drive link!"),Hl.forEach(a),He.forEach(a),$a=h(e),re=n(e,"P",{});var Za=r(re);rl=s(Za,"We\u2019ll cover the "),Nt=n(Za,"CODE",{});var tr=r(Nt);il=s(tr,"share"),tr.forEach(a),pl=s(Za," parameter in a lot more detail in the next section!"),Za.forEach(a),qa=h(e),L=n(e,"H2",{class:!0});var eo=r(L);ie=n(eo,"A",{id:!0,class:!0,href:!0});var ar=r(ie);Lt=n(ar,"SPAN",{});var or=r(Lt);H(be.$$.fragment,or),or.forEach(a),ar.forEach(a),ul=h(eo),Gt=n(eo,"SPAN",{});var sr=r(Gt);cl=s(sr,"\u270F\uFE0F Let's apply it!"),sr.forEach(a),eo.forEach(a),Aa=h(e),q=n(e,"P",{});var Ye=r(q);hl=s(Ye,"Let\u2019s build an interface that allows you to demo a "),Ft=n(Ye,"STRONG",{});var lr=r(Ft);dl=s(lr,"speech-recognition"),lr.forEach(a),fl=s(Ye,` model.
To make it interesting, we will accept `),Ht=n(Ye,"EM",{});var nr=r(Ht);ml=s(nr,"either"),nr.forEach(a),wl=s(Ye," a mic input or an uploaded file."),Ye.forEach(a),Ia=h(e),f=n(e,"P",{});var k=r(f);vl=s(k,"As usual, we\u2019ll load our speech recognition model using the the "),Yt=n(k,"CODE",{});var rr=r(Yt);yl=s(rr,"pipeline()"),rr.forEach(a),_l=s(k,` function \u{1F917} Transformers.
If you need a quick refresher, you can go back to `),Ne=n(k,"A",{href:!0});var ir=r(Ne);bl=s(ir,"that section in Chapter 1"),ir.forEach(a),El=s(k,".   Next, we\u2019ll implement a "),zt=n(k,"CODE",{});var pr=r(zt);kl=s(pr,"transcribe_audio()"),pr.forEach(a),gl=s(k," function that processes the audio and returns the transcription. Finally, we\u2019ll wrap this function in an "),Ut=n(k,"CODE",{});var ur=r(Ut);jl=s(ur,"Interface"),ur.forEach(a),xl=s(k," with the "),Wt=n(k,"CODE",{});var cr=r(Wt);$l=s(cr,"Audio"),cr.forEach(a),ql=s(k," components for the inputs and just text for the output. Altogether, the code for this application is the following:"),k.forEach(a),Ca=h(e),H(Ee.$$.fragment,e),Da=h(e),pe=n(e,"P",{});var to=r(pe);Al=s(to,"If your browser doesn\u2019t ask you for microphone permissions, "),ke=n(to,"A",{href:!0,target:!0});var hr=r(ke);Il=s(hr,"open the demo in a separate tab"),hr.forEach(a),Cl=s(to,"."),to.forEach(a),Pa=h(e),_=n(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),r(_).forEach(a),Oa=h(e),A=n(e,"P",{});var ze=r(A);Dl=s(ze,`That\u2019s it! You can now use this interface to transcribe audio. Notice here that
by passing in the `),Mt=n(ze,"CODE",{});var dr=r(Mt);Pl=s(dr,"optional"),dr.forEach(a),Ol=s(ze," parameter as "),Bt=n(ze,"CODE",{});var fr=r(Bt);Tl=s(fr,"True"),fr.forEach(a),Sl=s(ze,`, we allow the user to either
provide a microphone or an audio file (or neither, but that will return an error message).`),ze.forEach(a),Ta=h(e),Le=n(e,"P",{});var mr=r(Le);Nl=s(mr,"Keep going to see how to share your interface with others!"),mr.forEach(a),this.h()},h(){u(D,"name","hf:doc:metadata"),u(D,"content",JSON.stringify(gr)),u(M,"id","understanding-the-interface-class"),u(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(M,"href","#understanding-the-interface-class"),u(P,"class","relative group"),u(J,"id","how-to-create-an-interface"),u(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(J,"href","#how-to-create-an-interface"),u(O,"class","relative group"),u(he,"href","https://gradio.app/docs"),u(he,"rel","nofollow"),u(qe,"href","/course/chapter9/2"),u(V,"id","a-simple-example-with-audio"),u(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(V,"href","#a-simple-example-with-audio"),u(T,"class","relative group"),u(me,"href","https://huggingface.co/spaces/course-demos/audio-reverse"),u(me,"target","_blank"),Yl(v.src,Wl="https://hf.space/gradioiframe/course-demos/audio-reverse/+")||u(v,"src",Wl),u(v,"frameborder","0"),u(v,"height","250"),u(v,"title","Gradio app"),u(v,"class","container p-0 flex-grow space-iframe"),u(v,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),u(v,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),u(ee,"id","handling-multiple-inputs-and-outputs"),u(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ee,"href","#handling-multiple-inputs-and-outputs"),u(S,"class","relative group"),Yl(y.src,Ml="https://hf.space/gradioiframe/course-demos/generate-tone/+")||u(y,"src",Ml),u(y,"frameborder","0"),u(y,"height","450"),u(y,"title","Gradio app"),u(y,"class","container p-0 flex-grow space-iframe"),u(y,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),u(y,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),u(oe,"id","the-launch-method"),u(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(oe,"href","#the-launch-method"),u(N,"class","relative group"),u(ie,"id","lets-apply-it"),u(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ie,"href","#lets-apply-it"),u(L,"class","relative group"),u(Ne,"href","/course/chapter1/3"),u(ke,"href","https://huggingface.co/spaces/course-demos/audio-reverse"),u(ke,"target","_blank"),Yl(_.src,Bl="https://hf.space/gradioiframe/course-demos/asr/+")||u(_,"src",Bl),u(_,"frameborder","0"),u(_,"height","550"),u(_,"title","Gradio app"),u(_,"class","container p-0 flex-grow space-iframe"),u(_,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),u(_,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads")},m(e,i){t(document.head,D),p(e,Jt,i),p(e,P,i),t(P,M),t(M,We),Y(ue,We,null),t(P,ao),t(P,Me),t(Me,oo),p(e,Rt,i),p(e,B,i),t(B,so),t(B,Be),t(Be,lo),t(B,no),p(e,Kt,i),p(e,O,i),t(O,J),t(J,Je),Y(ce,Je,null),t(O,ro),t(O,Re),t(Re,io),p(e,Qt,i),p(e,R,i),t(R,po),t(R,Ke),t(Ke,uo),t(R,co),p(e,Vt,i),p(e,je,i),t(je,Qe),t(Qe,ho),p(e,Xt,i),p(e,xe,i),t(xe,fo),p(e,Zt,i),p(e,g,i),t(g,$e),t($e,Ve),t(Ve,mo),t($e,wo),t(g,vo),t(g,j),t(j,Xe),t(Xe,yo),t(j,_o),t(j,Ze),t(Ze,bo),t(j,Eo),t(j,et),t(et,ko),t(j,go),t(g,jo),t(g,b),t(b,tt),t(tt,xo),t(b,$o),t(b,at),t(at,qo),t(b,Ao),t(b,ot),t(ot,Io),t(b,Co),t(b,st),t(st,Do),t(b,Po),p(e,ea,i),p(e,K,i),t(K,Oo),t(K,he),t(he,To),t(K,So),p(e,ta,i),p(e,m,i),t(m,No),t(m,qe),t(qe,Lo),t(m,Go),t(m,lt),t(lt,Fo),t(m,Ho),t(m,nt),t(nt,Yo),t(m,zo),t(m,rt),t(rt,Uo),t(m,Wo),p(e,aa,i),p(e,Q,i),t(Q,Mo),t(Q,it),t(it,Bo),t(Q,Jo),p(e,oa,i),p(e,T,i),t(T,V),t(V,pt),Y(de,pt,null),t(T,Ro),t(T,ut),t(ut,Ko),p(e,sa,i),p(e,X,i),t(X,Qo),t(X,ct),t(ct,Vo),t(X,Xo),p(e,la,i),p(e,Ae,i),t(Ae,Zo),p(e,na,i),p(e,d,i),t(d,es),t(d,ht),t(ht,ts),t(d,as),t(d,dt),t(dt,os),t(d,ss),t(d,ft),t(ft,ls),t(d,ns),t(d,mt),t(mt,rs),t(d,is),t(d,wt),t(wt,ps),t(d,us),p(e,ra,i),p(e,w,i),t(w,cs),t(w,vt),t(vt,hs),t(w,ds),t(w,yt),t(yt,fs),t(w,ms),t(w,_t),t(_t,ws),t(w,vs),t(w,bt),t(bt,ys),t(w,_s),p(e,ia,i),p(e,x,i),t(x,bs),t(x,Et),t(Et,Es),t(x,ks),t(x,kt),t(kt,gs),t(x,js),p(e,pa,i),Y(fe,e,i),p(e,ua,i),p(e,Z,i),t(Z,xs),t(Z,me),t(me,$s),t(Z,qs),p(e,ca,i),p(e,v,i),p(e,ha,i),p(e,Ie,i),t(Ie,As),p(e,da,i),p(e,S,i),t(S,ee),t(ee,gt),Y(we,gt,null),t(S,Is),t(S,jt),t(jt,Cs),p(e,fa,i),p(e,Ce,i),t(Ce,Ds),p(e,ma,i),p(e,De,i),t(De,Ps),p(e,wa,i),p(e,Pe,i),t(Pe,Os),p(e,va,i),p(e,te,i),t(te,xt),t(xt,Ts),t(te,Ss),t(te,$t),t($t,Ns),p(e,ya,i),p(e,ae,i),t(ae,Ls),t(ae,qt),t(qt,Gs),t(ae,Fs),p(e,_a,i),Y(ve,e,i),p(e,ba,i),p(e,y,i),p(e,Ea,i),p(e,N,i),t(N,oe),t(oe,At),Y(ye,At,null),t(N,Hs),t(N,_e),t(_e,Ys),t(_e,It),t(It,zs),t(_e,Us),p(e,ka,i),p(e,se,i),t(se,Ws),t(se,Ct),t(Ct,Ms),t(se,Bs),p(e,ga,i),p(e,le,i),t(le,Js),t(le,Dt),t(Dt,Rs),t(le,Ks),p(e,ja,i),p(e,ne,i),t(ne,Qs),t(ne,Pt),t(Pt,Vs),t(ne,Xs),p(e,xa,i),p(e,$,i),t($,Oe),t(Oe,Ot),t(Ot,Zs),t(Oe,el),t($,tl),t($,Te),t(Te,Tt),t(Tt,al),t(Te,ol),t($,sl),t($,Se),t(Se,St),t(St,ll),t(Se,nl),p(e,$a,i),p(e,re,i),t(re,rl),t(re,Nt),t(Nt,il),t(re,pl),p(e,qa,i),p(e,L,i),t(L,ie),t(ie,Lt),Y(be,Lt,null),t(L,ul),t(L,Gt),t(Gt,cl),p(e,Aa,i),p(e,q,i),t(q,hl),t(q,Ft),t(Ft,dl),t(q,fl),t(q,Ht),t(Ht,ml),t(q,wl),p(e,Ia,i),p(e,f,i),t(f,vl),t(f,Yt),t(Yt,yl),t(f,_l),t(f,Ne),t(Ne,bl),t(f,El),t(f,zt),t(zt,kl),t(f,gl),t(f,Ut),t(Ut,jl),t(f,xl),t(f,Wt),t(Wt,$l),t(f,ql),p(e,Ca,i),Y(Ee,e,i),p(e,Da,i),p(e,pe,i),t(pe,Al),t(pe,ke),t(ke,Il),t(pe,Cl),p(e,Pa,i),p(e,_,i),p(e,Oa,i),p(e,A,i),t(A,Dl),t(A,Mt),t(Mt,Pl),t(A,Ol),t(A,Bt),t(Bt,Tl),t(A,Sl),p(e,Ta,i),p(e,Le,i),t(Le,Nl),Sa=!0},p:br,i(e){Sa||(z(ue.$$.fragment,e),z(ce.$$.fragment,e),z(de.$$.fragment,e),z(fe.$$.fragment,e),z(we.$$.fragment,e),z(ve.$$.fragment,e),z(ye.$$.fragment,e),z(be.$$.fragment,e),z(Ee.$$.fragment,e),Sa=!0)},o(e){U(ue.$$.fragment,e),U(ce.$$.fragment,e),U(de.$$.fragment,e),U(fe.$$.fragment,e),U(we.$$.fragment,e),U(ve.$$.fragment,e),U(ye.$$.fragment,e),U(be.$$.fragment,e),U(Ee.$$.fragment,e),Sa=!1},d(e){a(D),e&&a(Jt),e&&a(P),W(ue),e&&a(Rt),e&&a(B),e&&a(Kt),e&&a(O),W(ce),e&&a(Qt),e&&a(R),e&&a(Vt),e&&a(je),e&&a(Xt),e&&a(xe),e&&a(Zt),e&&a(g),e&&a(ea),e&&a(K),e&&a(ta),e&&a(m),e&&a(aa),e&&a(Q),e&&a(oa),e&&a(T),W(de),e&&a(sa),e&&a(X),e&&a(la),e&&a(Ae),e&&a(na),e&&a(d),e&&a(ra),e&&a(w),e&&a(ia),e&&a(x),e&&a(pa),W(fe,e),e&&a(ua),e&&a(Z),e&&a(ca),e&&a(v),e&&a(ha),e&&a(Ie),e&&a(da),e&&a(S),W(we),e&&a(fa),e&&a(Ce),e&&a(ma),e&&a(De),e&&a(wa),e&&a(Pe),e&&a(va),e&&a(te),e&&a(ya),e&&a(ae),e&&a(_a),W(ve,e),e&&a(ba),e&&a(y),e&&a(Ea),e&&a(N),W(ye),e&&a(ka),e&&a(se),e&&a(ga),e&&a(le),e&&a(ja),e&&a(ne),e&&a(xa),e&&a($),e&&a($a),e&&a(re),e&&a(qa),e&&a(L),W(be),e&&a(Aa),e&&a(q),e&&a(Ia),e&&a(f),e&&a(Ca),W(Ee,e),e&&a(Da),e&&a(pe),e&&a(Pa),e&&a(_),e&&a(Oa),e&&a(A),e&&a(Ta),e&&a(Le)}}}const gr={local:"understanding-the-interface-class",sections:[{local:"how-to-create-an-interface",title:"How to create an Interface"},{local:"a-simple-example-with-audio",title:"A simple example with audio"},{local:"handling-multiple-inputs-and-outputs",sections:[{local:"the-launch-method",title:"The `launch()` method"}],title:"Handling multiple inputs and outputs"},{local:"lets-apply-it",title:"\u270F\uFE0F Let's apply it!"}],title:"Understanding the Interface class"};function jr(Ul){return Er(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ar extends wr{constructor(D){super();vr(this,D,jr,kr,yr,{})}}export{Ar as default,gr as metadata};
