import{S as mn,i as wn,s as vn,e as r,k as u,w as z,t as o,M as yn,c as l,d as a,m as h,a as n,x as H,h as s,b as c,N as Wr,F as t,g as p,y as U,L as _n,q as Y,o as B,B as J,v as bn}from"../../chunks/vendor-1e8b365d.js";import{I as Ye}from"../../chunks/IconCopyLink-483c28ba.js";import{C as Mr}from"../../chunks/CodeBlock-e5764662.js";function En(zr){let P,Qt,S,R,Be,ce,Za,Je,eo,Vt,g,to,Re,ao,oo,Ke,so,ro,Xt,T,K,Qe,ue,lo,ge,no,Ve,io,Zt,Q,po,Xe,co,uo,ea,je,Ze,ho,ta,$e,fo,aa,j,qe,et,mo,wo,vo,_,tt,yo,_o,at,bo,Eo,ot,ko,go,st,jo,$o,qo,b,rt,xo,Io,lt,Co,Do,nt,Ao,Oo,it,Po,So,oa,V,To,he,No,Lo,sa,f,Fo,xe,Go,Wo,pt,Mo,zo,ct,Ho,Uo,ut,Yo,Bo,ra,X,Jo,ht,Ro,Ko,la,N,Z,dt,de,Qo,ft,Vo,na,$,Xo,mt,Zo,es,wt,ts,as,ia,Ie,os,pa,d,ss,vt,rs,ls,yt,ns,is,_t,ps,cs,bt,us,hs,Et,ds,fs,ca,m,ms,kt,ws,vs,gt,ys,_s,jt,bs,Es,$t,ks,gs,ua,q,js,qt,$s,qs,xt,xs,Is,ha,fe,da,ee,Cs,me,Ds,As,fa,w,Hr,ma,L,te,It,we,Os,Ct,Ps,wa,Ce,Ss,va,De,Ts,ya,Ae,Ns,_a,ae,Dt,Ls,Fs,At,Gs,ba,ve,Ea,v,Ur,ka,F,oe,Ot,ye,Ws,_e,Ms,Pt,zs,Hs,ga,se,Us,St,Ys,Bs,ja,x,Js,Tt,Rs,Ks,Nt,Qs,Vs,$a,re,Xs,Lt,Zs,er,qa,I,Oe,Ft,tr,ar,or,Pe,Gt,sr,rr,lr,Se,Wt,nr,ir,xa,le,pr,Mt,cr,ur,Ia,G,ne,zt,be,hr,Ht,dr,Ca,C,fr,Ut,mr,wr,Yt,vr,yr,Da,E,_r,Bt,br,Er,Jt,kr,gr,Te,jr,$r,Aa,Ee,Oa,ie,qr,ke,xr,Ir,Pa,y,Yr,Sa,D,Cr,Rt,Dr,Ar,Kt,Or,Pr,Ta,Ne,Sr,Na;return ce=new Ye({}),ue=new Ye({}),de=new Ye({}),fe=new Mr({props:{code:`import numpy as np
import gradio as gr


def reverse_audio(audio):
    sr, data = audio
    reversed_audio = (sr, np.flipud(data))
    return reversed_audio


mic = gr.inputs.Audio(source="microphone", type="numpy", label="Speak here...")
gr.Interface(reverse_audio, mic, "audio").launch()`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr


<span class="hljs-keyword">def</span> <span class="hljs-title function_">reverse_audio</span>(<span class="hljs-params">audio</span>):
    sr, data = audio
    reversed_audio = (sr, np.flipud(data))
    <span class="hljs-keyword">return</span> reversed_audio


mic = gr.inputs.Audio(source=<span class="hljs-string">&quot;microphone&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;numpy&quot;</span>, label=<span class="hljs-string">&quot;Speak here...&quot;</span>)
gr.Interface(reverse_audio, mic, <span class="hljs-string">&quot;audio&quot;</span>).launch()`}}),we=new Ye({}),ve=new Mr({props:{code:`import numpy as np
import gradio as gr

notes = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]


def generate_tone(note, octave, duration):
    sr = 48000
    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)
    frequency = a4_freq * 2 ** (tones_from_a4 / 12)
    duration = int(duration)
    audio = np.linspace(0, duration, duration * sr)
    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)
    return (sr, audio)


gr.Interface(
    generate_tone,
    [
        gr.inputs.Dropdown(notes, type="index"),
        gr.inputs.Slider(4, 6, step=1),
        gr.inputs.Textbox(type="number", default=1, label="Duration in seconds"),
    ],
    "audio",
).launch()`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr

notes = [<span class="hljs-string">&quot;C&quot;</span>, <span class="hljs-string">&quot;C#&quot;</span>, <span class="hljs-string">&quot;D&quot;</span>, <span class="hljs-string">&quot;D#&quot;</span>, <span class="hljs-string">&quot;E&quot;</span>, <span class="hljs-string">&quot;F&quot;</span>, <span class="hljs-string">&quot;F#&quot;</span>, <span class="hljs-string">&quot;G&quot;</span>, <span class="hljs-string">&quot;G#&quot;</span>, <span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-string">&quot;A#&quot;</span>, <span class="hljs-string">&quot;B&quot;</span>]


<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_tone</span>(<span class="hljs-params">note, octave, duration</span>):
    sr = <span class="hljs-number">48000</span>
    a4_freq, tones_from_a4 = <span class="hljs-number">440</span>, <span class="hljs-number">12</span> * (octave - <span class="hljs-number">4</span>) + (note - <span class="hljs-number">9</span>)
    frequency = a4_freq * <span class="hljs-number">2</span> ** (tones_from_a4 / <span class="hljs-number">12</span>)
    duration = <span class="hljs-built_in">int</span>(duration)
    audio = np.linspace(<span class="hljs-number">0</span>, duration, duration * sr)
    audio = (<span class="hljs-number">20000</span> * np.sin(audio * (<span class="hljs-number">2</span> * np.pi * frequency))).astype(np.int16)
    <span class="hljs-keyword">return</span> (sr, audio)


gr.Interface(
    generate_tone,
    [
        gr.inputs.Dropdown(notes, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;index&quot;</span>),
        gr.inputs.Slider(<span class="hljs-number">4</span>, <span class="hljs-number">6</span>, step=<span class="hljs-number">1</span>),
        gr.inputs.Textbox(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;number&quot;</span>, default=<span class="hljs-number">1</span>, label=<span class="hljs-string">&quot;Duration in seconds&quot;</span>),
    ],
    <span class="hljs-string">&quot;audio&quot;</span>,
).launch()`}}),ye=new Ye({}),be=new Ye({}),Ee=new Mr({props:{code:`from transformers import pipeline
import gradio as gr

model = pipeline("automatic-speech-recognition")


def transcribe_audio(mic=None, file=None):
    if mic is not None:
        audio = mic
    elif file is not None:
        audio = file
    else:
        return "You must either provide a mic recording or a file"
    transcription = model(audio)["text"]
    return transcription


gr.Interface(
    fn=transcribe_audio,
    inputs=[
        gr.inputs.Audio(source="microphone", type="filepath", optional=True),
        gr.inputs.Audio(source="upload", type="filepath", optional=True),
    ],
    outputs="text",
).launch()`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr

model = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">transcribe_audio</span>(<span class="hljs-params">mic=<span class="hljs-literal">None</span>, file=<span class="hljs-literal">None</span></span>):
    <span class="hljs-keyword">if</span> mic <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
        audio = mic
    <span class="hljs-keyword">elif</span> file <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
        audio = file
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;You must either provide a mic recording or a file&quot;</span>
    transcription = model(audio)[<span class="hljs-string">&quot;text&quot;</span>]
    <span class="hljs-keyword">return</span> transcription


gr.Interface(
    fn=transcribe_audio,
    inputs=[
        gr.inputs.Audio(source=<span class="hljs-string">&quot;microphone&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;filepath&quot;</span>, optional=<span class="hljs-literal">True</span>),
        gr.inputs.Audio(source=<span class="hljs-string">&quot;upload&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;filepath&quot;</span>, optional=<span class="hljs-literal">True</span>),
    ],
    outputs=<span class="hljs-string">&quot;text&quot;</span>,
).launch()`}}),{c(){P=r("meta"),Qt=u(),S=r("h1"),R=r("a"),Be=r("span"),z(ce.$$.fragment),Za=u(),Je=r("span"),eo=o("Understanding the Interface class"),Vt=u(),g=r("p"),to=o("In this section, we will take a closer look at the "),Re=r("code"),ao=o("gradio.Interface"),oo=o(` class, and understand the
main parameters used to create an `),Ke=r("code"),so=o("Interface"),ro=o("."),Xt=u(),T=r("h2"),K=r("a"),Qe=r("span"),z(ue.$$.fragment),lo=u(),ge=r("span"),no=o("How to create an "),Ve=r("code"),io=o("Interface"),Zt=u(),Q=r("p"),po=o("You\u2019ll notice that the "),Xe=r("code"),co=o("Interface"),uo=o(" class has 3 required parameters:"),ea=u(),je=r("p"),Ze=r("code"),ho=o("gradio.Interface(fn, inputs, outputs, ...)"),ta=u(),$e=r("p"),fo=o("These parameters are:"),aa=u(),j=r("ul"),qe=r("li"),et=r("code"),mo=o("fn"),wo=o(": the core prediction function that is wrapped by the gradio interface. This function can take one or more parameters and return one or more values"),vo=u(),_=r("li"),tt=r("code"),yo=o("inputs"),_o=o(": the input component type(s) ("),at=r("code"),bo=o("gradio"),Eo=o(" provides many pre-built components e.g. "),ot=r("code"),ko=o('"image"'),go=o(" or "),st=r("code"),jo=o('"mic"'),$o=o(")."),qo=u(),b=r("li"),rt=r("code"),xo=o("outputs"),Io=o(": the output component type(s)  (again, "),lt=r("code"),Co=o("gradio"),Do=o(" provides many pre-built components e.g. "),nt=r("code"),Ao=o('"image"'),Oo=o(" or "),it=r("code"),Po=o('"label"'),So=o(")."),oa=u(),V=r("p"),To=o("For a complete list of components, "),he=r("a"),No=o("see the docs "),Lo=o(`. Each pre-built
can be customized by instantiating the class corresponding to the component.`),sa=u(),f=r("p"),Fo=o("For example, as we saw in the "),xe=r("a"),Go=o("previous section"),Wo=o(`,
instead of passing in `),pt=r("code"),Mo=o('"textbox"'),zo=o(" to the "),ct=r("code"),Ho=o("inputs"),Uo=o(" parameter, you can pass in "),ut=r("code"),Yo=o('gradio.inputs.Textbox(lines=7, label="Prompt")'),Bo=o(" to create a textbox with 7 lines and a label."),ra=u(),X=r("p"),Jo=o("Let\u2019s take a look at another example, this time with an "),ht=r("code"),Ro=o("Audio"),Ko=o(" component."),la=u(),N=r("h2"),Z=r("a"),dt=r("span"),z(de.$$.fragment),Qo=u(),ft=r("span"),Vo=o("A simple example with audio"),na=u(),$=r("p"),Xo=o("As mentioned earlier, "),mt=r("code"),Zo=o("gradio"),es=o(` provides many different inputs and outputs.
So let\u2019s build an `),wt=r("code"),ts=o("Interface"),as=o(" that works with audio."),ia=u(),Ie=r("p"),os=o(`In this example, we\u2019re building an audio-to-audio function that takes an
audio file and simply reverses it.`),pa=u(),d=r("p"),ss=o("We will use for the input the "),vt=r("code"),rs=o("Audio"),ls=o(" component. When using the "),yt=r("code"),ns=o("Audio"),is=o(` component,
you can specify whether you want the `),_t=r("code"),ps=o("source"),cs=o(` of the audio to be a file that the user
uploads or a microphone that the user records their voice with. In this case, let\u2019s
set it to a `),bt=r("code"),us=o('"microphone"'),hs=o(". Just for fun, we\u2019ll add a label to our "),Et=r("code"),ds=o("Audio"),fs=o(` that says
\u201CSpeak here\u2026\u201C.`),ca=u(),m=r("p"),ms=o(`In addition, we\u2019d like to receive the audio as a numpy array so that we can easily
\u201Creverse\u201D it. So we\u2019ll set the `),kt=r("code"),ws=o('"type"'),vs=o(" to be "),gt=r("code"),ys=o('"numpy"'),_s=o(`, which passes the input
data as a tuple of (`),jt=r("code"),bs=o("sample_rate"),Es=o(", "),$t=r("code"),ks=o("data"),gs=o(") into our function."),ua=u(),q=r("p"),js=o("We will also use the "),qt=r("code"),$s=o("Audio"),qs=o(` output component which can automatically
render a tuple with a sample rate and numpy array of data as a playable audio file.
In this case, we do not need to do any customization, so we will use the string
shortcut `),xt=r("code"),xs=o('"audio"'),Is=o("."),ha=u(),z(fe.$$.fragment),da=u(),ee=r("p"),Cs=o(`The code above will produce an interface like the one below (if your browser doesn\u2019t
ask you for microphone permissions, `),me=r("a"),Ds=o("open the demo in  a separate tab"),As=o(".)"),fa=u(),w=r("iframe"),ma=u(),L=r("h2"),te=r("a"),It=r("span"),z(we.$$.fragment),Os=u(),Ct=r("span"),Ps=o("Multiple inputs and outputs:"),wa=u(),Ce=r("p"),Ss=o(`Let\u2019s say we had a more complicated function, with multiple inputs and outputs.
In the example below, we have a function that takes a dropdown index, a slider value, and number,
and returns an audio sample of a musical tone.`),va=u(),De=r("p"),Ts=o(`Take a look how we pass a list of input and output components,
and see if you can follow along what\u2019s happening.`),ya=u(),Ae=r("p"),Ns=o("The key here is that when:"),_a=u(),ae=r("ul"),Dt=r("li"),Ls=o("you pass in a list of input components, each component corresponds to a parameter in order."),Fs=u(),At=r("li"),Gs=o("you pass in a list of output coponents, each component corresponds to a returned value."),ba=u(),z(ve.$$.fragment),Ea=u(),v=r("iframe"),ka=u(),F=r("h3"),oe=r("a"),Ot=r("span"),z(ye.$$.fragment),Ws=u(),_e=r("span"),Ms=o("The "),Pt=r("code"),zs=o("launch()"),Hs=o(" method"),ga=u(),se=r("p"),Us=o("So far, we have used the "),St=r("code"),Ys=o("launch()"),Bs=o(` method to launch the interface, but we
haven\u2019t really discussed what it does.`),ja=u(),x=r("p"),Js=o("By default, the "),Tt=r("code"),Rs=o("launch()"),Ks=o(` method will launch the demo in a web server that
is running locally. If you are running your code in a Jupyter or colab notebook, then
`),Nt=r("code"),Qs=o("gradio"),Vs=o(" will embed the demo GUI in the notebook so you can easily use it."),$a=u(),re=r("p"),Xs=o("You can customize the behavior of "),Lt=r("code"),Zs=o("launch()"),er=o(" through different parameters"),qa=u(),I=r("ul"),Oe=r("li"),Ft=r("code"),tr=o("inline"),ar=o(" - whether to display in the interface inline on python notebooks."),or=u(),Pe=r("li"),Gt=r("code"),sr=o("inbrowser"),rr=o(" - whether to automatically launch the interface in a new tab on the default browser."),lr=u(),Se=r("li"),Wt=r("code"),nr=o("share"),ir=o(" - whether to create a publicly shareable link from your computer for the interface. Kind of like a Google Drive link!"),xa=u(),le=r("p"),pr=o("We\u2019ll cover the "),Mt=r("code"),cr=o("share"),ur=o(" parameter in a lot more detail in the next section!"),Ia=u(),G=r("h2"),ne=r("a"),zt=r("span"),z(be.$$.fragment),hr=u(),Ht=r("span"),dr=o("\u270F\uFE0F Let's apply it!"),Ca=u(),C=r("p"),fr=o("We\u2019ll build an interface that allows you to demo a "),Ut=r("strong"),mr=o("speech-recognition"),wr=o(` model.
To make it interesting, we will accept `),Yt=r("em"),vr=o("either"),yr=o(" a mic input or an uploaded file."),Da=u(),E=r("p"),_r=o("We\u2019ll load our speech recognition model using the the "),Bt=r("code"),br=o("pipeline"),Er=o(" abstraction from the "),Jt=r("code"),kr=o("transformers"),gr=o(` library.
If you need a quick refresher, you can go back to `),Te=r("a"),jr=o("that section in Chapter 1"),$r=o("."),Aa=u(),z(Ee.$$.fragment),Oa=u(),ie=r("p"),qr=o("If your browser doesn\u2019t ask you for microphone permissions, "),ke=r("a"),xr=o("open the demo in a separate tab"),Ir=o("."),Pa=u(),y=r("iframe"),Sa=u(),D=r("p"),Cr=o(`That\u2019s it! You can now use this interface to transcribe audio. Notice here that
by passing in the `),Rt=r("code"),Dr=o("optional"),Ar=o(" parameter as "),Kt=r("code"),Or=o("True"),Pr=o(`, we allow the user to either
provide a microphone or an audio file (or neither, but that will return an error message).`),Ta=u(),Ne=r("p"),Sr=o("Keep going to see how to share your interface with others!"),this.h()},l(e){const i=yn('[data-svelte="svelte-1phssyn"]',document.head);P=l(i,"META",{name:!0,content:!0}),i.forEach(a),Qt=h(e),S=l(e,"H1",{class:!0});var La=n(S);R=l(La,"A",{id:!0,class:!0,href:!0});var Br=n(R);Be=l(Br,"SPAN",{});var Jr=n(Be);H(ce.$$.fragment,Jr),Jr.forEach(a),Br.forEach(a),Za=h(La),Je=l(La,"SPAN",{});var Rr=n(Je);eo=s(Rr,"Understanding the Interface class"),Rr.forEach(a),La.forEach(a),Vt=h(e),g=l(e,"P",{});var Le=n(g);to=s(Le,"In this section, we will take a closer look at the "),Re=l(Le,"CODE",{});var Kr=n(Re);ao=s(Kr,"gradio.Interface"),Kr.forEach(a),oo=s(Le,` class, and understand the
main parameters used to create an `),Ke=l(Le,"CODE",{});var Qr=n(Ke);so=s(Qr,"Interface"),Qr.forEach(a),ro=s(Le,"."),Le.forEach(a),Xt=h(e),T=l(e,"H2",{class:!0});var Fa=n(T);K=l(Fa,"A",{id:!0,class:!0,href:!0});var Vr=n(K);Qe=l(Vr,"SPAN",{});var Xr=n(Qe);H(ue.$$.fragment,Xr),Xr.forEach(a),Vr.forEach(a),lo=h(Fa),ge=l(Fa,"SPAN",{});var Tr=n(ge);no=s(Tr,"How to create an "),Ve=l(Tr,"CODE",{});var Zr=n(Ve);io=s(Zr,"Interface"),Zr.forEach(a),Tr.forEach(a),Fa.forEach(a),Zt=h(e),Q=l(e,"P",{});var Ga=n(Q);po=s(Ga,"You\u2019ll notice that the "),Xe=l(Ga,"CODE",{});var el=n(Xe);co=s(el,"Interface"),el.forEach(a),uo=s(Ga," class has 3 required parameters:"),Ga.forEach(a),ea=h(e),je=l(e,"P",{});var tl=n(je);Ze=l(tl,"CODE",{});var al=n(Ze);ho=s(al,"gradio.Interface(fn, inputs, outputs, ...)"),al.forEach(a),tl.forEach(a),ta=h(e),$e=l(e,"P",{});var ol=n($e);fo=s(ol,"These parameters are:"),ol.forEach(a),aa=h(e),j=l(e,"UL",{});var Fe=n(j);qe=l(Fe,"LI",{});var Nr=n(qe);et=l(Nr,"CODE",{});var sl=n(et);mo=s(sl,"fn"),sl.forEach(a),wo=s(Nr,": the core prediction function that is wrapped by the gradio interface. This function can take one or more parameters and return one or more values"),Nr.forEach(a),vo=h(Fe),_=l(Fe,"LI",{});var W=n(_);tt=l(W,"CODE",{});var rl=n(tt);yo=s(rl,"inputs"),rl.forEach(a),_o=s(W,": the input component type(s) ("),at=l(W,"CODE",{});var ll=n(at);bo=s(ll,"gradio"),ll.forEach(a),Eo=s(W," provides many pre-built components e.g. "),ot=l(W,"CODE",{});var nl=n(ot);ko=s(nl,'"image"'),nl.forEach(a),go=s(W," or "),st=l(W,"CODE",{});var il=n(st);jo=s(il,'"mic"'),il.forEach(a),$o=s(W,")."),W.forEach(a),qo=h(Fe),b=l(Fe,"LI",{});var M=n(b);rt=l(M,"CODE",{});var pl=n(rt);xo=s(pl,"outputs"),pl.forEach(a),Io=s(M,": the output component type(s)  (again, "),lt=l(M,"CODE",{});var cl=n(lt);Co=s(cl,"gradio"),cl.forEach(a),Do=s(M," provides many pre-built components e.g. "),nt=l(M,"CODE",{});var ul=n(nt);Ao=s(ul,'"image"'),ul.forEach(a),Oo=s(M," or "),it=l(M,"CODE",{});var hl=n(it);Po=s(hl,'"label"'),hl.forEach(a),So=s(M,")."),M.forEach(a),Fe.forEach(a),oa=h(e),V=l(e,"P",{});var Wa=n(V);To=s(Wa,"For a complete list of components, "),he=l(Wa,"A",{href:!0,rel:!0});var dl=n(he);No=s(dl,"see the docs "),dl.forEach(a),Lo=s(Wa,`. Each pre-built
can be customized by instantiating the class corresponding to the component.`),Wa.forEach(a),sa=h(e),f=l(e,"P",{});var A=n(f);Fo=s(A,"For example, as we saw in the "),xe=l(A,"A",{href:!0});var fl=n(xe);Go=s(fl,"previous section"),fl.forEach(a),Wo=s(A,`,
instead of passing in `),pt=l(A,"CODE",{});var ml=n(pt);Mo=s(ml,'"textbox"'),ml.forEach(a),zo=s(A," to the "),ct=l(A,"CODE",{});var wl=n(ct);Ho=s(wl,"inputs"),wl.forEach(a),Uo=s(A," parameter, you can pass in "),ut=l(A,"CODE",{});var vl=n(ut);Yo=s(vl,'gradio.inputs.Textbox(lines=7, label="Prompt")'),vl.forEach(a),Bo=s(A," to create a textbox with 7 lines and a label."),A.forEach(a),ra=h(e),X=l(e,"P",{});var Ma=n(X);Jo=s(Ma,"Let\u2019s take a look at another example, this time with an "),ht=l(Ma,"CODE",{});var yl=n(ht);Ro=s(yl,"Audio"),yl.forEach(a),Ko=s(Ma," component."),Ma.forEach(a),la=h(e),N=l(e,"H2",{class:!0});var za=n(N);Z=l(za,"A",{id:!0,class:!0,href:!0});var _l=n(Z);dt=l(_l,"SPAN",{});var bl=n(dt);H(de.$$.fragment,bl),bl.forEach(a),_l.forEach(a),Qo=h(za),ft=l(za,"SPAN",{});var El=n(ft);Vo=s(El,"A simple example with audio"),El.forEach(a),za.forEach(a),na=h(e),$=l(e,"P",{});var Ge=n($);Xo=s(Ge,"As mentioned earlier, "),mt=l(Ge,"CODE",{});var kl=n(mt);Zo=s(kl,"gradio"),kl.forEach(a),es=s(Ge,` provides many different inputs and outputs.
So let\u2019s build an `),wt=l(Ge,"CODE",{});var gl=n(wt);ts=s(gl,"Interface"),gl.forEach(a),as=s(Ge," that works with audio."),Ge.forEach(a),ia=h(e),Ie=l(e,"P",{});var jl=n(Ie);os=s(jl,`In this example, we\u2019re building an audio-to-audio function that takes an
audio file and simply reverses it.`),jl.forEach(a),pa=h(e),d=l(e,"P",{});var k=n(d);ss=s(k,"We will use for the input the "),vt=l(k,"CODE",{});var $l=n(vt);rs=s($l,"Audio"),$l.forEach(a),ls=s(k," component. When using the "),yt=l(k,"CODE",{});var ql=n(yt);ns=s(ql,"Audio"),ql.forEach(a),is=s(k,` component,
you can specify whether you want the `),_t=l(k,"CODE",{});var xl=n(_t);ps=s(xl,"source"),xl.forEach(a),cs=s(k,` of the audio to be a file that the user
uploads or a microphone that the user records their voice with. In this case, let\u2019s
set it to a `),bt=l(k,"CODE",{});var Il=n(bt);us=s(Il,'"microphone"'),Il.forEach(a),hs=s(k,". Just for fun, we\u2019ll add a label to our "),Et=l(k,"CODE",{});var Cl=n(Et);ds=s(Cl,"Audio"),Cl.forEach(a),fs=s(k,` that says
\u201CSpeak here\u2026\u201C.`),k.forEach(a),ca=h(e),m=l(e,"P",{});var O=n(m);ms=s(O,`In addition, we\u2019d like to receive the audio as a numpy array so that we can easily
\u201Creverse\u201D it. So we\u2019ll set the `),kt=l(O,"CODE",{});var Dl=n(kt);ws=s(Dl,'"type"'),Dl.forEach(a),vs=s(O," to be "),gt=l(O,"CODE",{});var Al=n(gt);ys=s(Al,'"numpy"'),Al.forEach(a),_s=s(O,`, which passes the input
data as a tuple of (`),jt=l(O,"CODE",{});var Ol=n(jt);bs=s(Ol,"sample_rate"),Ol.forEach(a),Es=s(O,", "),$t=l(O,"CODE",{});var Pl=n($t);ks=s(Pl,"data"),Pl.forEach(a),gs=s(O,") into our function."),O.forEach(a),ua=h(e),q=l(e,"P",{});var We=n(q);js=s(We,"We will also use the "),qt=l(We,"CODE",{});var Sl=n(qt);$s=s(Sl,"Audio"),Sl.forEach(a),qs=s(We,` output component which can automatically
render a tuple with a sample rate and numpy array of data as a playable audio file.
In this case, we do not need to do any customization, so we will use the string
shortcut `),xt=l(We,"CODE",{});var Tl=n(xt);xs=s(Tl,'"audio"'),Tl.forEach(a),Is=s(We,"."),We.forEach(a),ha=h(e),H(fe.$$.fragment,e),da=h(e),ee=l(e,"P",{});var Ha=n(ee);Cs=s(Ha,`The code above will produce an interface like the one below (if your browser doesn\u2019t
ask you for microphone permissions, `),me=l(Ha,"A",{href:!0,target:!0});var Nl=n(me);Ds=s(Nl,"open the demo in  a separate tab"),Nl.forEach(a),As=s(Ha,".)"),Ha.forEach(a),fa=h(e),w=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),n(w).forEach(a),ma=h(e),L=l(e,"H2",{class:!0});var Ua=n(L);te=l(Ua,"A",{id:!0,class:!0,href:!0});var Ll=n(te);It=l(Ll,"SPAN",{});var Fl=n(It);H(we.$$.fragment,Fl),Fl.forEach(a),Ll.forEach(a),Os=h(Ua),Ct=l(Ua,"SPAN",{});var Gl=n(Ct);Ps=s(Gl,"Multiple inputs and outputs:"),Gl.forEach(a),Ua.forEach(a),wa=h(e),Ce=l(e,"P",{});var Wl=n(Ce);Ss=s(Wl,`Let\u2019s say we had a more complicated function, with multiple inputs and outputs.
In the example below, we have a function that takes a dropdown index, a slider value, and number,
and returns an audio sample of a musical tone.`),Wl.forEach(a),va=h(e),De=l(e,"P",{});var Ml=n(De);Ts=s(Ml,`Take a look how we pass a list of input and output components,
and see if you can follow along what\u2019s happening.`),Ml.forEach(a),ya=h(e),Ae=l(e,"P",{});var zl=n(Ae);Ns=s(zl,"The key here is that when:"),zl.forEach(a),_a=h(e),ae=l(e,"UL",{});var Ya=n(ae);Dt=l(Ya,"LI",{});var Hl=n(Dt);Ls=s(Hl,"you pass in a list of input components, each component corresponds to a parameter in order."),Hl.forEach(a),Fs=h(Ya),At=l(Ya,"LI",{});var Ul=n(At);Gs=s(Ul,"you pass in a list of output coponents, each component corresponds to a returned value."),Ul.forEach(a),Ya.forEach(a),ba=h(e),H(ve.$$.fragment,e),Ea=h(e),v=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),n(v).forEach(a),ka=h(e),F=l(e,"H3",{class:!0});var Ba=n(F);oe=l(Ba,"A",{id:!0,class:!0,href:!0});var Yl=n(oe);Ot=l(Yl,"SPAN",{});var Bl=n(Ot);H(ye.$$.fragment,Bl),Bl.forEach(a),Yl.forEach(a),Ws=h(Ba),_e=l(Ba,"SPAN",{});var Ja=n(_e);Ms=s(Ja,"The "),Pt=l(Ja,"CODE",{});var Jl=n(Pt);zs=s(Jl,"launch()"),Jl.forEach(a),Hs=s(Ja," method"),Ja.forEach(a),Ba.forEach(a),ga=h(e),se=l(e,"P",{});var Ra=n(se);Us=s(Ra,"So far, we have used the "),St=l(Ra,"CODE",{});var Rl=n(St);Ys=s(Rl,"launch()"),Rl.forEach(a),Bs=s(Ra,` method to launch the interface, but we
haven\u2019t really discussed what it does.`),Ra.forEach(a),ja=h(e),x=l(e,"P",{});var Me=n(x);Js=s(Me,"By default, the "),Tt=l(Me,"CODE",{});var Kl=n(Tt);Rs=s(Kl,"launch()"),Kl.forEach(a),Ks=s(Me,` method will launch the demo in a web server that
is running locally. If you are running your code in a Jupyter or colab notebook, then
`),Nt=l(Me,"CODE",{});var Ql=n(Nt);Qs=s(Ql,"gradio"),Ql.forEach(a),Vs=s(Me," will embed the demo GUI in the notebook so you can easily use it."),Me.forEach(a),$a=h(e),re=l(e,"P",{});var Ka=n(re);Xs=s(Ka,"You can customize the behavior of "),Lt=l(Ka,"CODE",{});var Vl=n(Lt);Zs=s(Vl,"launch()"),Vl.forEach(a),er=s(Ka," through different parameters"),Ka.forEach(a),qa=h(e),I=l(e,"UL",{});var ze=n(I);Oe=l(ze,"LI",{});var Lr=n(Oe);Ft=l(Lr,"CODE",{});var Xl=n(Ft);tr=s(Xl,"inline"),Xl.forEach(a),ar=s(Lr," - whether to display in the interface inline on python notebooks."),Lr.forEach(a),or=h(ze),Pe=l(ze,"LI",{});var Fr=n(Pe);Gt=l(Fr,"CODE",{});var Zl=n(Gt);sr=s(Zl,"inbrowser"),Zl.forEach(a),rr=s(Fr," - whether to automatically launch the interface in a new tab on the default browser."),Fr.forEach(a),lr=h(ze),Se=l(ze,"LI",{});var Gr=n(Se);Wt=l(Gr,"CODE",{});var en=n(Wt);nr=s(en,"share"),en.forEach(a),ir=s(Gr," - whether to create a publicly shareable link from your computer for the interface. Kind of like a Google Drive link!"),Gr.forEach(a),ze.forEach(a),xa=h(e),le=l(e,"P",{});var Qa=n(le);pr=s(Qa,"We\u2019ll cover the "),Mt=l(Qa,"CODE",{});var tn=n(Mt);cr=s(tn,"share"),tn.forEach(a),ur=s(Qa," parameter in a lot more detail in the next section!"),Qa.forEach(a),Ia=h(e),G=l(e,"H2",{class:!0});var Va=n(G);ne=l(Va,"A",{id:!0,class:!0,href:!0});var an=n(ne);zt=l(an,"SPAN",{});var on=n(zt);H(be.$$.fragment,on),on.forEach(a),an.forEach(a),hr=h(Va),Ht=l(Va,"SPAN",{});var sn=n(Ht);dr=s(sn,"\u270F\uFE0F Let's apply it!"),sn.forEach(a),Va.forEach(a),Ca=h(e),C=l(e,"P",{});var He=n(C);fr=s(He,"We\u2019ll build an interface that allows you to demo a "),Ut=l(He,"STRONG",{});var rn=n(Ut);mr=s(rn,"speech-recognition"),rn.forEach(a),wr=s(He,` model.
To make it interesting, we will accept `),Yt=l(He,"EM",{});var ln=n(Yt);vr=s(ln,"either"),ln.forEach(a),yr=s(He," a mic input or an uploaded file."),He.forEach(a),Da=h(e),E=l(e,"P",{});var pe=n(E);_r=s(pe,"We\u2019ll load our speech recognition model using the the "),Bt=l(pe,"CODE",{});var nn=n(Bt);br=s(nn,"pipeline"),nn.forEach(a),Er=s(pe," abstraction from the "),Jt=l(pe,"CODE",{});var pn=n(Jt);kr=s(pn,"transformers"),pn.forEach(a),gr=s(pe,` library.
If you need a quick refresher, you can go back to `),Te=l(pe,"A",{href:!0});var cn=n(Te);jr=s(cn,"that section in Chapter 1"),cn.forEach(a),$r=s(pe,"."),pe.forEach(a),Aa=h(e),H(Ee.$$.fragment,e),Oa=h(e),ie=l(e,"P",{});var Xa=n(ie);qr=s(Xa,"If your browser doesn\u2019t ask you for microphone permissions, "),ke=l(Xa,"A",{href:!0,target:!0});var un=n(ke);xr=s(un,"open the demo in a separate tab"),un.forEach(a),Ir=s(Xa,"."),Xa.forEach(a),Pa=h(e),y=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),n(y).forEach(a),Sa=h(e),D=l(e,"P",{});var Ue=n(D);Cr=s(Ue,`That\u2019s it! You can now use this interface to transcribe audio. Notice here that
by passing in the `),Rt=l(Ue,"CODE",{});var hn=n(Rt);Dr=s(hn,"optional"),hn.forEach(a),Ar=s(Ue," parameter as "),Kt=l(Ue,"CODE",{});var dn=n(Kt);Or=s(dn,"True"),dn.forEach(a),Pr=s(Ue,`, we allow the user to either
provide a microphone or an audio file (or neither, but that will return an error message).`),Ue.forEach(a),Ta=h(e),Ne=l(e,"P",{});var fn=n(Ne);Sr=s(fn,"Keep going to see how to share your interface with others!"),fn.forEach(a),this.h()},h(){c(P,"name","hf:doc:metadata"),c(P,"content",JSON.stringify(kn)),c(R,"id","understanding-the-interface-class"),c(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R,"href","#understanding-the-interface-class"),c(S,"class","relative group"),c(K,"id","how-to-create-an-interface"),c(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K,"href","#how-to-create-an-interface"),c(T,"class","relative group"),c(he,"href","https://gradio.app/docs"),c(he,"rel","nofollow"),c(xe,"href","/course/chapter9/2"),c(Z,"id","a-simple-example-with-audio"),c(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z,"href","#a-simple-example-with-audio"),c(N,"class","relative group"),c(me,"href","https://huggingface.co/spaces/course-demos/audio-reverse"),c(me,"target","_blank"),Wr(w.src,Hr="https://hf.space/gradioiframe/course-demos/audio-reverse/+")||c(w,"src",Hr),c(w,"frameborder","0"),c(w,"height","250"),c(w,"title","Gradio app"),c(w,"class","container p-0 flex-grow space-iframe"),c(w,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),c(w,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),c(te,"id","multiple-inputs-and-outputs"),c(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(te,"href","#multiple-inputs-and-outputs"),c(L,"class","relative group"),Wr(v.src,Ur="https://hf.space/gradioiframe/course-demos/generate-tone/+")||c(v,"src",Ur),c(v,"frameborder","0"),c(v,"height","450"),c(v,"title","Gradio app"),c(v,"class","container p-0 flex-grow space-iframe"),c(v,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),c(v,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),c(oe,"id","the-launch-method"),c(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oe,"href","#the-launch-method"),c(F,"class","relative group"),c(ne,"id","lets-apply-it"),c(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ne,"href","#lets-apply-it"),c(G,"class","relative group"),c(Te,"href","/course/chapter1/section3"),c(ke,"href","https://huggingface.co/spaces/course-demos/audio-reverse"),c(ke,"target","_blank"),Wr(y.src,Yr="https://hf.space/gradioiframe/course-demos/asr/+")||c(y,"src",Yr),c(y,"frameborder","0"),c(y,"height","550"),c(y,"title","Gradio app"),c(y,"class","container p-0 flex-grow space-iframe"),c(y,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),c(y,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads")},m(e,i){t(document.head,P),p(e,Qt,i),p(e,S,i),t(S,R),t(R,Be),U(ce,Be,null),t(S,Za),t(S,Je),t(Je,eo),p(e,Vt,i),p(e,g,i),t(g,to),t(g,Re),t(Re,ao),t(g,oo),t(g,Ke),t(Ke,so),t(g,ro),p(e,Xt,i),p(e,T,i),t(T,K),t(K,Qe),U(ue,Qe,null),t(T,lo),t(T,ge),t(ge,no),t(ge,Ve),t(Ve,io),p(e,Zt,i),p(e,Q,i),t(Q,po),t(Q,Xe),t(Xe,co),t(Q,uo),p(e,ea,i),p(e,je,i),t(je,Ze),t(Ze,ho),p(e,ta,i),p(e,$e,i),t($e,fo),p(e,aa,i),p(e,j,i),t(j,qe),t(qe,et),t(et,mo),t(qe,wo),t(j,vo),t(j,_),t(_,tt),t(tt,yo),t(_,_o),t(_,at),t(at,bo),t(_,Eo),t(_,ot),t(ot,ko),t(_,go),t(_,st),t(st,jo),t(_,$o),t(j,qo),t(j,b),t(b,rt),t(rt,xo),t(b,Io),t(b,lt),t(lt,Co),t(b,Do),t(b,nt),t(nt,Ao),t(b,Oo),t(b,it),t(it,Po),t(b,So),p(e,oa,i),p(e,V,i),t(V,To),t(V,he),t(he,No),t(V,Lo),p(e,sa,i),p(e,f,i),t(f,Fo),t(f,xe),t(xe,Go),t(f,Wo),t(f,pt),t(pt,Mo),t(f,zo),t(f,ct),t(ct,Ho),t(f,Uo),t(f,ut),t(ut,Yo),t(f,Bo),p(e,ra,i),p(e,X,i),t(X,Jo),t(X,ht),t(ht,Ro),t(X,Ko),p(e,la,i),p(e,N,i),t(N,Z),t(Z,dt),U(de,dt,null),t(N,Qo),t(N,ft),t(ft,Vo),p(e,na,i),p(e,$,i),t($,Xo),t($,mt),t(mt,Zo),t($,es),t($,wt),t(wt,ts),t($,as),p(e,ia,i),p(e,Ie,i),t(Ie,os),p(e,pa,i),p(e,d,i),t(d,ss),t(d,vt),t(vt,rs),t(d,ls),t(d,yt),t(yt,ns),t(d,is),t(d,_t),t(_t,ps),t(d,cs),t(d,bt),t(bt,us),t(d,hs),t(d,Et),t(Et,ds),t(d,fs),p(e,ca,i),p(e,m,i),t(m,ms),t(m,kt),t(kt,ws),t(m,vs),t(m,gt),t(gt,ys),t(m,_s),t(m,jt),t(jt,bs),t(m,Es),t(m,$t),t($t,ks),t(m,gs),p(e,ua,i),p(e,q,i),t(q,js),t(q,qt),t(qt,$s),t(q,qs),t(q,xt),t(xt,xs),t(q,Is),p(e,ha,i),U(fe,e,i),p(e,da,i),p(e,ee,i),t(ee,Cs),t(ee,me),t(me,Ds),t(ee,As),p(e,fa,i),p(e,w,i),p(e,ma,i),p(e,L,i),t(L,te),t(te,It),U(we,It,null),t(L,Os),t(L,Ct),t(Ct,Ps),p(e,wa,i),p(e,Ce,i),t(Ce,Ss),p(e,va,i),p(e,De,i),t(De,Ts),p(e,ya,i),p(e,Ae,i),t(Ae,Ns),p(e,_a,i),p(e,ae,i),t(ae,Dt),t(Dt,Ls),t(ae,Fs),t(ae,At),t(At,Gs),p(e,ba,i),U(ve,e,i),p(e,Ea,i),p(e,v,i),p(e,ka,i),p(e,F,i),t(F,oe),t(oe,Ot),U(ye,Ot,null),t(F,Ws),t(F,_e),t(_e,Ms),t(_e,Pt),t(Pt,zs),t(_e,Hs),p(e,ga,i),p(e,se,i),t(se,Us),t(se,St),t(St,Ys),t(se,Bs),p(e,ja,i),p(e,x,i),t(x,Js),t(x,Tt),t(Tt,Rs),t(x,Ks),t(x,Nt),t(Nt,Qs),t(x,Vs),p(e,$a,i),p(e,re,i),t(re,Xs),t(re,Lt),t(Lt,Zs),t(re,er),p(e,qa,i),p(e,I,i),t(I,Oe),t(Oe,Ft),t(Ft,tr),t(Oe,ar),t(I,or),t(I,Pe),t(Pe,Gt),t(Gt,sr),t(Pe,rr),t(I,lr),t(I,Se),t(Se,Wt),t(Wt,nr),t(Se,ir),p(e,xa,i),p(e,le,i),t(le,pr),t(le,Mt),t(Mt,cr),t(le,ur),p(e,Ia,i),p(e,G,i),t(G,ne),t(ne,zt),U(be,zt,null),t(G,hr),t(G,Ht),t(Ht,dr),p(e,Ca,i),p(e,C,i),t(C,fr),t(C,Ut),t(Ut,mr),t(C,wr),t(C,Yt),t(Yt,vr),t(C,yr),p(e,Da,i),p(e,E,i),t(E,_r),t(E,Bt),t(Bt,br),t(E,Er),t(E,Jt),t(Jt,kr),t(E,gr),t(E,Te),t(Te,jr),t(E,$r),p(e,Aa,i),U(Ee,e,i),p(e,Oa,i),p(e,ie,i),t(ie,qr),t(ie,ke),t(ke,xr),t(ie,Ir),p(e,Pa,i),p(e,y,i),p(e,Sa,i),p(e,D,i),t(D,Cr),t(D,Rt),t(Rt,Dr),t(D,Ar),t(D,Kt),t(Kt,Or),t(D,Pr),p(e,Ta,i),p(e,Ne,i),t(Ne,Sr),Na=!0},p:_n,i(e){Na||(Y(ce.$$.fragment,e),Y(ue.$$.fragment,e),Y(de.$$.fragment,e),Y(fe.$$.fragment,e),Y(we.$$.fragment,e),Y(ve.$$.fragment,e),Y(ye.$$.fragment,e),Y(be.$$.fragment,e),Y(Ee.$$.fragment,e),Na=!0)},o(e){B(ce.$$.fragment,e),B(ue.$$.fragment,e),B(de.$$.fragment,e),B(fe.$$.fragment,e),B(we.$$.fragment,e),B(ve.$$.fragment,e),B(ye.$$.fragment,e),B(be.$$.fragment,e),B(Ee.$$.fragment,e),Na=!1},d(e){a(P),e&&a(Qt),e&&a(S),J(ce),e&&a(Vt),e&&a(g),e&&a(Xt),e&&a(T),J(ue),e&&a(Zt),e&&a(Q),e&&a(ea),e&&a(je),e&&a(ta),e&&a($e),e&&a(aa),e&&a(j),e&&a(oa),e&&a(V),e&&a(sa),e&&a(f),e&&a(ra),e&&a(X),e&&a(la),e&&a(N),J(de),e&&a(na),e&&a($),e&&a(ia),e&&a(Ie),e&&a(pa),e&&a(d),e&&a(ca),e&&a(m),e&&a(ua),e&&a(q),e&&a(ha),J(fe,e),e&&a(da),e&&a(ee),e&&a(fa),e&&a(w),e&&a(ma),e&&a(L),J(we),e&&a(wa),e&&a(Ce),e&&a(va),e&&a(De),e&&a(ya),e&&a(Ae),e&&a(_a),e&&a(ae),e&&a(ba),J(ve,e),e&&a(Ea),e&&a(v),e&&a(ka),e&&a(F),J(ye),e&&a(ga),e&&a(se),e&&a(ja),e&&a(x),e&&a($a),e&&a(re),e&&a(qa),e&&a(I),e&&a(xa),e&&a(le),e&&a(Ia),e&&a(G),J(be),e&&a(Ca),e&&a(C),e&&a(Da),e&&a(E),e&&a(Aa),J(Ee,e),e&&a(Oa),e&&a(ie),e&&a(Pa),e&&a(y),e&&a(Sa),e&&a(D),e&&a(Ta),e&&a(Ne)}}}const kn={local:"understanding-the-interface-class",sections:[{local:"how-to-create-an-interface",title:"How to create an `Interface`"},{local:"a-simple-example-with-audio",title:"A simple example with audio"},{local:"multiple-inputs-and-outputs",sections:[{local:"the-launch-method",title:"The `launch()` method"}],title:"Multiple inputs and outputs:"},{local:"lets-apply-it",title:"\u270F\uFE0F Let's apply it!"}],title:"Understanding the Interface class"};function gn(zr){return bn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xn extends mn{constructor(P){super();wn(this,P,gn,En,vn,{})}}export{xn as default,kn as metadata};
