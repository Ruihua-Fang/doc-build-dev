import{S as Sx,i as Hx,s as Mx,e as o,k as d,w as f,t as n,M as Rx,c as r,d as s,m as p,a as l,x as v,h as a,b as m,f as Lx,F as t,g as u,y as h,q as _,o as g,B as $,v as Fx}from"../../chunks/vendor-e6c5d93e.js";import{D as Ux,Y as l1,T as is}from"../../chunks/DocNotebookDropdown-b3e38740.js";import{I as Mn}from"../../chunks/IconCopyLink-7b8d27fe.js";import{C as b}from"../../chunks/CodeBlock-37867453.js";function Vx(M){let c,D,E,j,w;return{c(){c=o("p"),D=n("\u270F\uFE0F "),E=o("strong"),j=n("Essayez-le\xA0!"),w=n(" Utilisez la fonction \u201CDataset.unique()\u201D pour trouver le nombre de m\xE9dicaments et de conditions uniques dans les ensembles d\u2019entra\xEEnement et de test.")},l(x){c=r(x,"P",{});var q=l(c);D=a(q,"\u270F\uFE0F "),E=r(q,"STRONG",{});var C=l(E);j=a(C,"Essayez-le\xA0!"),C.forEach(s),w=a(q," Utilisez la fonction \u201CDataset.unique()\u201D pour trouver le nombre de m\xE9dicaments et de conditions uniques dans les ensembles d\u2019entra\xEEnement et de test."),q.forEach(s)},m(x,q){u(x,c,q),t(c,D),t(c,E),t(E,j),t(c,w)},d(x){x&&s(c)}}}function Bx(M){let c,D,E,j,w,x,q,C;return{c(){c=o("p"),D=n("\u{1F64B} Une autre fa\xE7on d\u2019ajouter de nouvelles colonnes \xE0 un ensemble de donn\xE9es consiste \xE0 utiliser la fonction "),E=o("code"),j=n("Dataset.add_column()"),w=n(". Cela vous permet de fournir la colonne sous forme de liste Python ou de tableau NumPy et peut \xEAtre utile dans les situations o\xF9 "),x=o("code"),q=n("Dataset.map()"),C=n(" n\u2019est pas bien adapt\xE9 \xE0 votre analyse.")},l(y){c=r(y,"P",{});var P=l(c);D=a(P,"\u{1F64B} Une autre fa\xE7on d\u2019ajouter de nouvelles colonnes \xE0 un ensemble de donn\xE9es consiste \xE0 utiliser la fonction "),E=r(P,"CODE",{});var O=l(E);j=a(O,"Dataset.add_column()"),O.forEach(s),w=a(P,". Cela vous permet de fournir la colonne sous forme de liste Python ou de tableau NumPy et peut \xEAtre utile dans les situations o\xF9 "),x=r(P,"CODE",{});var T=l(x);q=a(T,"Dataset.map()"),T.forEach(s),C=a(P," n\u2019est pas bien adapt\xE9 \xE0 votre analyse."),P.forEach(s)},m(y,P){u(y,c,P),t(c,D),t(c,E),t(E,j),t(c,w),t(c,x),t(x,q),t(c,C)},d(y){y&&s(c)}}}function Gx(M){let c,D,E,j,w,x,q,C,y,P,O;return{c(){c=o("p"),D=n("\u270F\uFE0F "),E=o("strong"),j=n("Essayez-le !"),w=n(" Utilisez la fonction "),x=o("code"),q=n("Dataset.sort()"),C=n(" pour inspecter les avis avec le plus grand nombre de mots. Consultez la "),y=o("a"),P=n("documentation"),O=n(" pour voir quel argument vous devez utiliser pour trier les avis par longueur dans l\u2019ordre d\xE9croissant."),this.h()},l(T){c=r(T,"P",{});var k=l(c);D=a(k,"\u270F\uFE0F "),E=r(k,"STRONG",{});var J=l(E);j=a(J,"Essayez-le !"),J.forEach(s),w=a(k," Utilisez la fonction "),x=r(k,"CODE",{});var A=l(x);q=a(A,"Dataset.sort()"),A.forEach(s),C=a(k," pour inspecter les avis avec le plus grand nombre de mots. Consultez la "),y=r(k,"A",{href:!0,rel:!0});var z=l(y);P=a(z,"documentation"),z.forEach(s),O=a(k," pour voir quel argument vous devez utiliser pour trier les avis par longueur dans l\u2019ordre d\xE9croissant."),k.forEach(s),this.h()},h(){m(y,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.sort"),m(y,"rel","nofollow")},m(T,k){u(T,c,k),t(c,D),t(c,E),t(E,j),t(c,w),t(c,x),t(x,q),t(c,C),t(c,y),t(y,P),t(c,O)},d(T){T&&s(c)}}}function Jx(M){let c,D,E,j,w,x,q,C,y,P,O,T,k,J;return{c(){c=o("p"),D=n("\u270F\uFE0F "),E=o("strong"),j=n("Essayez-le\xA0!"),w=n(" Ex\xE9cutez la m\xEAme instruction avec et sans "),x=o("code"),q=n("batched=True"),C=n(", puis essayez-le avec un tokenizer lent (ajoutez "),y=o("code"),P=n("use_fast=False"),O=n(" dans la m\xE9thode "),T=o("code"),k=n("AutoTokenizer.from_pretrained()"),J=n(") afin que vous puissiez voir quels num\xE9ros vous obtenez sur votre mat\xE9riel.")},l(A){c=r(A,"P",{});var z=l(c);D=a(z,"\u270F\uFE0F "),E=r(z,"STRONG",{});var me=l(E);j=a(me,"Essayez-le\xA0!"),me.forEach(s),w=a(z," Ex\xE9cutez la m\xEAme instruction avec et sans "),x=r(z,"CODE",{});var R=l(x);q=a(R,"batched=True"),R.forEach(s),C=a(z,", puis essayez-le avec un tokenizer lent (ajoutez "),y=r(z,"CODE",{});var W=l(y);P=a(W,"use_fast=False"),W.forEach(s),O=a(z," dans la m\xE9thode "),T=r(z,"CODE",{});var se=l(T);k=a(se,"AutoTokenizer.from_pretrained()"),se.forEach(s),J=a(z,") afin que vous puissiez voir quels num\xE9ros vous obtenez sur votre mat\xE9riel."),z.forEach(s)},m(A,z){u(A,c,z),t(c,D),t(c,E),t(E,j),t(c,w),t(c,x),t(x,q),t(c,C),t(c,y),t(y,P),t(c,O),t(c,T),t(T,k),t(c,J)},d(A){A&&s(c)}}}function Yx(M){let c,D,E,j,w;return{c(){c=o("p"),D=n("Utiliser "),E=o("code"),j=n("num_proc"),w=n(" pour acc\xE9l\xE9rer votre traitement est g\xE9n\xE9ralement une bonne id\xE9e, tant que la fonction que vous utilisez n\u2019effectue pas d\xE9j\xE0 une sorte de multitraitement.")},l(x){c=r(x,"P",{});var q=l(c);D=a(q,"Utiliser "),E=r(q,"CODE",{});var C=l(E);j=a(C,"num_proc"),C.forEach(s),w=a(q," pour acc\xE9l\xE9rer votre traitement est g\xE9n\xE9ralement une bonne id\xE9e, tant que la fonction que vous utilisez n\u2019effectue pas d\xE9j\xE0 une sorte de multitraitement."),q.forEach(s)},m(x,q){u(x,c,q),t(c,D),t(c,E),t(E,j),t(c,w)},d(x){x&&s(c)}}}function Wx(M){let c,D,E,j,w,x,q,C,y,P,O;return{c(){c=o("p"),D=n("\u{1F4A1} En machine learning, un "),E=o("em"),j=n("example"),w=n(" est g\xE9n\xE9ralement d\xE9fini comme l\u2019ensemble de "),x=o("em"),q=n("features"),C=n(" que nous alimentons au mod\xE8le. Dans certains contextes, ces caract\xE9ristiques seront l\u2019ensemble des colonnes d\u2019un "),y=o("code"),P=n("Dataset"),O=n(", mais dans d\u2019autres (comme ici et pour la r\xE9ponse aux questions), plusieurs caract\xE9ristiques peuvent \xEAtre extraites d\u2019un seul exemple et appartenir \xE0 une seule colonne.")},l(T){c=r(T,"P",{});var k=l(c);D=a(k,"\u{1F4A1} En machine learning, un "),E=r(k,"EM",{});var J=l(E);j=a(J,"example"),J.forEach(s),w=a(k," est g\xE9n\xE9ralement d\xE9fini comme l\u2019ensemble de "),x=r(k,"EM",{});var A=l(x);q=a(A,"features"),A.forEach(s),C=a(k," que nous alimentons au mod\xE8le. Dans certains contextes, ces caract\xE9ristiques seront l\u2019ensemble des colonnes d\u2019un "),y=r(k,"CODE",{});var z=l(y);P=a(z,"Dataset"),z.forEach(s),O=a(k,", mais dans d\u2019autres (comme ici et pour la r\xE9ponse aux questions), plusieurs caract\xE9ristiques peuvent \xEAtre extraites d\u2019un seul exemple et appartenir \xE0 une seule colonne."),k.forEach(s)},m(T,k){u(T,c,k),t(c,D),t(c,E),t(E,j),t(c,w),t(c,x),t(x,q),t(c,C),t(c,y),t(y,P),t(c,O)},d(T){T&&s(c)}}}function Xx(M){let c,D,E,j,w,x,q,C,y,P,O,T,k,J,A,z,me,R,W,se,ee,us,Re,Fe,mt,F;return{c(){c=o("p"),D=n("\u{1F6A8} Sous le capot, "),E=o("code"),j=n("Dataset.set_format()"),w=n(" change le format de retour pour la m\xE9thode dunder "),x=o("code"),q=n("__getitem__()"),C=n(" de l\u2019ensemble de donn\xE9es. Cela signifie que lorsque nous voulons cr\xE9er un nouvel objet comme "),y=o("code"),P=n("train_df"),O=n(" \xE0 partir d\u2019un "),T=o("code"),k=n("Dataset"),J=n(" au format "),A=o("code"),z=n('"pandas"'),me=n(", nous devons d\xE9couper tout l\u2019ensemble de donn\xE9es pour obtenir un "),R=o("code"),W=n("pandas.DataFrame"),se=n(". Vous pouvez v\xE9rifier par vous-m\xEAme que le type de "),ee=o("code"),us=n('drug_dataset["train"]'),Re=n(" est "),Fe=o("code"),mt=n("Dataset"),F=n(", quel que soit le format de sortie.")},l(Ue){c=r(Ue,"P",{});var N=l(c);D=a(N,"\u{1F6A8} Sous le capot, "),E=r(N,"CODE",{});var Rn=l(E);j=a(Rn,"Dataset.set_format()"),Rn.forEach(s),w=a(N," change le format de retour pour la m\xE9thode dunder "),x=r(N,"CODE",{});var Fn=l(x);q=a(Fn,"__getitem__()"),Fn.forEach(s),C=a(N," de l\u2019ensemble de donn\xE9es. Cela signifie que lorsque nous voulons cr\xE9er un nouvel objet comme "),y=r(N,"CODE",{});var ft=l(y);P=a(ft,"train_df"),ft.forEach(s),O=a(N," \xE0 partir d\u2019un "),T=r(N,"CODE",{});var Un=l(T);k=a(Un,"Dataset"),Un.forEach(s),J=a(N," au format "),A=r(N,"CODE",{});var Vn=l(A);z=a(Vn,'"pandas"'),Vn.forEach(s),me=a(N,", nous devons d\xE9couper tout l\u2019ensemble de donn\xE9es pour obtenir un "),R=r(N,"CODE",{});var vt=l(R);W=a(vt,"pandas.DataFrame"),vt.forEach(s),se=a(N,". Vous pouvez v\xE9rifier par vous-m\xEAme que le type de "),ee=r(N,"CODE",{});var Bn=l(ee);us=a(Bn,'drug_dataset["train"]'),Bn.forEach(s),Re=a(N," est "),Fe=r(N,"CODE",{});var Gn=l(Fe);mt=a(Gn,"Dataset"),Gn.forEach(s),F=a(N,", quel que soit le format de sortie."),N.forEach(s)},m(Ue,N){u(Ue,c,N),t(c,D),t(c,E),t(E,j),t(c,w),t(c,x),t(x,q),t(c,C),t(c,y),t(y,P),t(c,O),t(c,T),t(T,k),t(c,J),t(c,A),t(A,z),t(c,me),t(c,R),t(R,W),t(c,se),t(c,ee),t(ee,us),t(c,Re),t(c,Fe),t(Fe,mt),t(c,F)},d(Ue){Ue&&s(c)}}}function Kx(M){let c,D,E,j,w;return{c(){c=o("p"),D=n("\u270F\uFE0F "),E=o("strong"),j=n("Essayez-le\xA0!"),w=n(" Calculez la note moyenne par m\xE9dicament et stockez le r\xE9sultat dans un nouvel ensemble de donn\xE9es.")},l(x){c=r(x,"P",{});var q=l(c);D=a(q,"\u270F\uFE0F "),E=r(q,"STRONG",{});var C=l(E);j=a(C,"Essayez-le\xA0!"),C.forEach(s),w=a(q," Calculez la note moyenne par m\xE9dicament et stockez le r\xE9sultat dans un nouvel ensemble de donn\xE9es."),q.forEach(s)},m(x,q){u(x,c,q),t(c,D),t(c,E),t(E,j),t(c,w)},d(x){x&&s(c)}}}function Qx(M){let c,D,E,j,w,x,q,C,y,P,O,T,k,J,A,z,me,R,W,se,ee,us,Re,Fe,mt,F,Ue,N,Rn,Fn,ft,Un,Vn,vt,Bn,Gn,Jn,jc,wc,Xi,he,Dc,ds,kc,yc,ps,Cc,Tc,Ki,_e,zc,Ao,Pc,Oc,Io,Nc,Ac,Qi,cs,Zi,ne,Ic,Lo,Lc,Sc,So,Hc,Mc,Ho,Rc,Fc,eu,ms,tu,ge,Uc,Mo,Vc,Bc,Ro,Gc,Jc,su,fs,nu,vs,au,ae,Yc,Fo,Wc,Xc,Uo,Kc,Qc,Vo,Zc,em,ou,$e,Bo,tm,sm,Go,nm,am,Ve,om,Jo,rm,lm,Yo,im,um,ru,be,dm,Wo,pm,cm,Xo,mm,fm,lu,hs,iu,Ee,vm,Ko,hm,_m,Qo,gm,$m,uu,_s,du,gs,pu,ht,cu,X,bm,Zo,Em,xm,er,qm,jm,Yn,wm,Dm,tr,km,ym,mu,$s,fu,bs,vu,xe,Cm,sr,Tm,zm,nr,Pm,Om,hu,Es,_u,qe,Nm,ar,Am,Im,or,Lm,Sm,gu,xs,$u,K,Hm,rr,Mm,Rm,qs,Fm,Um,lr,Vm,Bm,ir,Gm,Jm,bu,js,Eu,Wn,Ym,xu,ws,qu,Ds,ju,Xn,Wm,wu,ks,Du,ys,ku,_t,Xm,Cs,Km,Qm,yu,Ts,Cu,Kn,Zm,Tu,zs,zu,Ps,Pu,Qn,ef,Ou,Be,gt,ur,Os,tf,dr,sf,Nu,Zn,nf,Au,ea,af,Iu,Ns,Lu,Y,of,pr,rf,lf,cr,uf,df,mr,pf,cf,fr,mf,ff,vr,vf,hf,Su,As,Hu,Is,Mu,$t,_f,hr,gf,$f,Ru,Ls,Fu,Ss,Uu,ta,bf,Vu,bt,Bu,Et,Ef,_r,xf,qf,Gu,Hs,Ju,Ms,Yu,sa,jf,Wu,xt,Xu,qt,wf,gr,Df,kf,Ku,Rs,Qu,Fs,Zu,jt,yf,$r,Cf,Tf,ed,Us,td,wt,zf,br,Pf,Of,sd,Ge,Dt,Er,Vs,Nf,na,Af,xr,If,nd,oe,Lf,qr,Sf,Hf,jr,Mf,Rf,wr,Ff,Uf,ad,Q,Vf,Dr,Bf,Gf,kr,Jf,Yf,yr,Wf,Xf,Cr,Kf,Qf,od,Bs,rd,kt,Zf,Tr,ev,tv,ld,re,sv,zr,nv,av,Pr,ov,rv,aa,lv,iv,id,Gs,ud,le,uv,oa,dv,pv,Or,cv,mv,Nr,fv,vv,dd,Js,pd,yt,hv,Ar,_v,gv,cd,Ct,md,ra,$v,fd,Tt,Ir,Je,la,bv,Ev,ia,xv,qv,ua,jv,wv,Ys,Ye,da,Lr,Dv,kv,pa,yv,Cv,ca,Tv,zv,We,ma,Sr,Pv,Ov,fa,Nv,Av,va,Iv,vd,je,Lv,Hr,Sv,Hv,Mr,Mv,Rv,hd,ha,Fv,_d,fe,Rr,Uv,Vv,Fr,Bv,Gv,Ur,Jv,Yv,gd,Ws,$d,_a,Wv,bd,zt,Vr,Xe,ga,Xv,Kv,$a,Qv,Zv,ba,eh,th,ve,Ke,Ea,Br,sh,nh,xa,ah,oh,qa,rh,lh,Qe,ja,Gr,ih,uh,wa,dh,ph,Da,ch,mh,Ze,Pt,Jr,fh,vh,Yr,hh,_h,ka,gh,$h,ya,bh,Eh,et,Ot,Wr,xh,qh,Xr,jh,wh,Ca,Dh,kh,Ta,yh,Ed,ie,Ch,Kr,Th,zh,Qr,Ph,Oh,Zr,Nh,Ah,xd,Nt,qd,we,Ih,el,Lh,Sh,tl,Hh,Mh,jd,At,wd,De,Rh,sl,Fh,Uh,nl,Vh,Bh,Dd,Xs,kd,It,Gh,al,Jh,Yh,yd,Ks,Cd,Qs,Td,za,Wh,zd,Zs,Pd,en,Od,ke,Xh,ol,Kh,Qh,tn,Zh,e_,Nd,Z,t_,rl,s_,n_,ll,a_,o_,il,r_,l_,ul,i_,u_,Ad,sn,Id,Pa,d_,Ld,nn,Sd,an,Hd,ye,p_,dl,c_,m_,pl,f_,v_,Md,on,Rd,Lt,h_,cl,__,g_,Fd,rn,Ud,ln,Vd,Oa,$_,Bd,St,b_,ml,E_,x_,Gd,tt,Ht,fl,un,q_,st,j_,vl,w_,D_,hl,k_,y_,Jd,dn,Yd,ue,C_,_l,T_,z_,gl,P_,O_,$l,N_,A_,Wd,pn,Xd,Mt,I_,bl,L_,S_,Kd,cn,Qd,Ce,El,I,Zd,H_,xl,M_,R_,ql,F_,U_,jl,V_,B_,wl,G_,J_,Dl,Y_,W_,kl,X_,K_,yl,Q_,Z_,Cl,e2,t2,nt,L,Tl,s2,n2,zl,a2,o2,Pl,r2,l2,Ol,i2,u2,Nl,d2,p2,Al,c2,m2,Il,f2,v2,Ll,h2,_2,Sl,g2,$2,S,Hl,b2,E2,Ml,x2,q2,Rl,j2,w2,Fl,D2,k2,Ul,y2,C2,Vl,T2,z2,Bl,P2,O2,Gl,N2,A2,Jl,I2,L2,H,Yl,S2,H2,Wl,M2,R2,Xl,F2,U2,Kl,V2,B2,Ql,G2,J2,Zl,Y2,W2,ei,X2,K2,ti,Q2,Z2,si,eg,ep,Te,tg,ni,sg,ng,ai,ag,og,tp,mn,sp,Rt,np,Ft,rg,oi,lg,ig,ap,fn,op,ze,ri,Pe,rp,ug,li,dg,pg,ii,cg,mg,te,at,ui,fg,vg,di,hg,_g,pi,gg,$g,ot,ci,bg,Eg,mi,xg,qg,fi,jg,wg,rt,vi,Dg,kg,hi,yg,Cg,_i,Tg,zg,lt,gi,Pg,Og,$i,Ng,Ag,bi,Ig,Lg,it,Ei,Sg,Hg,xi,Mg,Rg,qi,Fg,lp,Oe,Ug,ji,Vg,Bg,wi,Gg,Jg,ip,vn,up,hn,dp,Ut,pp,de,Yg,Di,Wg,Xg,ki,Kg,Qg,yi,Zg,e$,cp,_n,mp,ut,Vt,Ci,gn,t$,Ti,s$,fp,Na,n$,vp,Ne,a$,zi,o$,r$,Pi,l$,i$,hp,$n,_p,bn,gp,Bt,u$,Aa,d$,p$,$p,dt,Gt,Oi,En,c$,Ni,m$,bp,xn,Ep,Ia,f$,xp,Jt,Ai,qn,La,v$,h$,Sa,_$,g$,pt,jn,Ha,$$,b$,Ma,Ii,E$,x$,wn,Ra,q$,j$,Fa,Li,w$,D$,Dn,Ua,k$,y$,Va,Si,C$,qp,Ba,T$,jp,kn,wp,Ga,z$,Dp,yn,kp,pe,P$,Hi,O$,N$,Mi,A$,I$,Ri,L$,S$,yp,Yt,H$,Fi,M$,R$,Cp,Cn,Tp,Tn,zp,Ja,F$,Pp,zn,Op,Wt,U$,Pn,V$,B$,Np,On,Ap,Nn,Ip,Xt,G$,Ya,J$,Y$,Lp,An,Sp,Wa,W$,Hp,Kt,In,X$,Xa,K$,Q$,Z$,ct,e1,Ui,t1,s1,Ka,n1,a1,Mp,Qa,o1,Rp;return x=new Mn({}),O=new Ux({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter5/section3.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter5/section3.ipynb"}]}}),z=new l1({props:{id:"tqfSFcPMgOI"}}),ee=new Mn({}),cs=new b({props:{code:`!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
!unzip drugsCom_raw.zip`,highlighted:`!wget <span class="hljs-string">&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip&quot;</span>
!unzip drugsCom_raw.<span class="hljs-built_in">zip</span>`}}),ms=new b({props:{code:`from datasets import load_dataset

data_files = {"train": "drugsComTrain_raw.tsv", "test": "drugsComTest_raw.tsv"}
# \\t is the tab character in Python
drug_dataset = load_dataset("csv", data_files=data_files, delimiter="\\t")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

data_files = {<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;drugsComTrain_raw.tsv&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;drugsComTest_raw.tsv&quot;</span>}
<span class="hljs-comment"># \\t is the tab character in Python</span>
drug_dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="hljs-string">&quot;\\t&quot;</span>)`}}),fs=new b({props:{code:`drug_sample = drug_dataset["train"].shuffle(seed=42).select(range(1000))
# Peek at the first few examples
drug_sample[:3]`,highlighted:`drug_sample = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-comment"># Peek at the first few examples</span>
drug_sample[:<span class="hljs-number">3</span>]`}}),vs=new b({props:{code:`{'Unnamed: 0': [87571, 178045, 80482],
 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],
 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],
 'review': ['"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"',
  '"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."',
  '"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."'],
 'rating': [9.0, 3.0, 10.0],
 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],
 'usefulCount': [36, 13, 128]}`,highlighted:`{<span class="hljs-string">&#x27;Unnamed: 0&#x27;</span>: [<span class="hljs-number">87571</span>, <span class="hljs-number">178045</span>, <span class="hljs-number">80482</span>],
 <span class="hljs-string">&#x27;drugName&#x27;</span>: [<span class="hljs-string">&#x27;Naproxen&#x27;</span>, <span class="hljs-string">&#x27;Duloxetine&#x27;</span>, <span class="hljs-string">&#x27;Mobic&#x27;</span>],
 <span class="hljs-string">&#x27;condition&#x27;</span>: [<span class="hljs-string">&#x27;Gout, Acute&#x27;</span>, <span class="hljs-string">&#x27;ibromyalgia&#x27;</span>, <span class="hljs-string">&#x27;Inflammatory Conditions&#x27;</span>],
 <span class="hljs-string">&#x27;review&#x27;</span>: [<span class="hljs-string">&#x27;&quot;like the previous person mention, I&amp;#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!&quot;&#x27;</span>,
  <span class="hljs-string">&#x27;&quot;I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.&quot;&#x27;</span>,
  <span class="hljs-string">&#x27;&quot;I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days.&quot;&#x27;</span>],
 <span class="hljs-string">&#x27;rating&#x27;</span>: [<span class="hljs-number">9.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">10.0</span>],
 <span class="hljs-string">&#x27;date&#x27;</span>: [<span class="hljs-string">&#x27;September 2, 2015&#x27;</span>, <span class="hljs-string">&#x27;November 7, 2011&#x27;</span>, <span class="hljs-string">&#x27;June 5, 2013&#x27;</span>],
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: [<span class="hljs-number">36</span>, <span class="hljs-number">13</span>, <span class="hljs-number">128</span>]}`}}),hs=new b({props:{code:`for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))`,highlighted:`<span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> drug_dataset.keys():
    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(drug_dataset[split]) == <span class="hljs-built_in">len</span>(drug_dataset[split].unique(<span class="hljs-string">&quot;Unnamed: 0&quot;</span>))`}}),_s=new b({props:{code:`drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
drug_dataset`,highlighted:`drug_dataset = drug_dataset.rename_column(
    original_column_name=<span class="hljs-string">&quot;Unnamed: 0&quot;</span>, new_column_name=<span class="hljs-string">&quot;patient_id&quot;</span>
)
drug_dataset`}}),gs=new b({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 161297
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 53766
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">161297</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">53766</span>
    })
})`}}),ht=new is({props:{$$slots:{default:[Vx]},$$scope:{ctx:M}}}),$s=new b({props:{code:`def lowercase_condition(example):
    return {"condition": example["condition"].lower()}


drug_dataset.map(lowercase_condition)`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">lowercase_condition</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;condition&quot;</span>: example[<span class="hljs-string">&quot;condition&quot;</span>].lower()}


drug_dataset.<span class="hljs-built_in">map</span>(lowercase_condition)`}}),bs=new b({props:{code:"AttributeError: 'NoneType' object has no attribute 'lower'",highlighted:'AttributeError: <span class="hljs-string">&#x27;NoneType&#x27;</span> <span class="hljs-built_in">object</span> has no attribute <span class="hljs-string">&#x27;lower&#x27;</span>'}}),Es=new b({props:{code:`def filter_nones(x):
    return x["condition"] is not None`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_nones</span>(<span class="hljs-params">x</span>):
    <span class="hljs-keyword">return</span> x[<span class="hljs-string">&quot;condition&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>`}}),xs=new b({props:{code:"lambda <arguments> : <expression>",highlighted:'lambda <span class="hljs-tag">&lt;<span class="hljs-name">arguments</span>&gt;</span> : <span class="hljs-tag">&lt;<span class="hljs-name">expression</span>&gt;</span>'}}),js=new b({props:{code:"lambda x : x * x",highlighted:'lambda <span class="hljs-keyword">x</span> : <span class="hljs-keyword">x</span> * <span class="hljs-keyword">x</span>'}}),ws=new b({props:{code:"(lambda x: x * x)(3)",highlighted:'(<span class="hljs-keyword">lambda</span> x: x * x)(<span class="hljs-number">3</span>)'}}),Ds=new b({props:{code:"9",highlighted:'<span class="hljs-number">9</span>'}}),ks=new b({props:{code:"(lambda base, height: 0.5 * base * height)(4, 8)",highlighted:'(<span class="hljs-keyword">lambda</span> base, height: <span class="hljs-number">0.5</span> * base * height)(<span class="hljs-number">4</span>, <span class="hljs-number">8</span>)'}}),ys=new b({props:{code:"16.0",highlighted:'<span class="hljs-number">16.0</span>'}}),Ts=new b({props:{code:'drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)',highlighted:'drug_dataset = drug_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;condition&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>)'}}),zs=new b({props:{code:`drug_dataset = drug_dataset.map(lowercase_condition)
# Check that lowercasing worked
drug_dataset["train"]["condition"][:3]`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(lowercase_condition)
<span class="hljs-comment"># Check that lowercasing worked</span>
drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;condition&quot;</span>][:<span class="hljs-number">3</span>]`}}),Ps=new b({props:{code:"['left ventricular dysfunction', 'adhd', 'birth control']",highlighted:'[<span class="hljs-string">&#x27;left ventricular dysfunction&#x27;</span>, <span class="hljs-string">&#x27;adhd&#x27;</span>, <span class="hljs-string">&#x27;birth control&#x27;</span>]'}}),Os=new Mn({}),Ns=new b({props:{code:`def compute_review_length(example):
    return {"review_length": len(example["review"].split())}`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_review_length</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;review_length&quot;</span>: <span class="hljs-built_in">len</span>(example[<span class="hljs-string">&quot;review&quot;</span>].split())}`}}),As=new b({props:{code:`drug_dataset = drug_dataset.map(compute_review_length)
# Inspect the first training example
drug_dataset["train"][0]`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(compute_review_length)
<span class="hljs-comment"># Inspect the first training example</span>
drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]`}}),Is=new b({props:{code:`{'patient_id': 206461,
 'drugName': 'Valsartan',
 'condition': 'left ventricular dysfunction',
 'review': '"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil"',
 'rating': 9.0,
 'date': 'May 20, 2012',
 'usefulCount': 27,
 'review_length': 17}`,highlighted:`{<span class="hljs-string">&#x27;patient_id&#x27;</span>: <span class="hljs-number">206461</span>,
 <span class="hljs-string">&#x27;drugName&#x27;</span>: <span class="hljs-string">&#x27;Valsartan&#x27;</span>,
 <span class="hljs-string">&#x27;condition&#x27;</span>: <span class="hljs-string">&#x27;left ventricular dysfunction&#x27;</span>,
 <span class="hljs-string">&#x27;review&#x27;</span>: <span class="hljs-string">&#x27;&quot;It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil&quot;&#x27;</span>,
 <span class="hljs-string">&#x27;rating&#x27;</span>: <span class="hljs-number">9.0</span>,
 <span class="hljs-string">&#x27;date&#x27;</span>: <span class="hljs-string">&#x27;May 20, 2012&#x27;</span>,
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: <span class="hljs-number">27</span>,
 <span class="hljs-string">&#x27;review_length&#x27;</span>: <span class="hljs-number">17</span>}`}}),Ls=new b({props:{code:'drug_dataset["train"].sort("review_length")[:3]',highlighted:'drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].sort(<span class="hljs-string">&quot;review_length&quot;</span>)[:<span class="hljs-number">3</span>]'}}),Ss=new b({props:{code:`{'patient_id': [103488, 23627, 20558],
 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],
 'condition': ['birth control', 'muscle spasm', 'pain'],
 'review': ['"Excellent."', '"useless"', '"ok"'],
 'rating': [10.0, 1.0, 6.0],
 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'],
 'usefulCount': [5, 2, 10],
 'review_length': [1, 1, 1]}`,highlighted:`{<span class="hljs-string">&#x27;patient_id&#x27;</span>: [<span class="hljs-number">103488</span>, <span class="hljs-number">23627</span>, <span class="hljs-number">20558</span>],
 <span class="hljs-string">&#x27;drugName&#x27;</span>: [<span class="hljs-string">&#x27;Loestrin 21 1 / 20&#x27;</span>, <span class="hljs-string">&#x27;Chlorzoxazone&#x27;</span>, <span class="hljs-string">&#x27;Nucynta&#x27;</span>],
 <span class="hljs-string">&#x27;condition&#x27;</span>: [<span class="hljs-string">&#x27;birth control&#x27;</span>, <span class="hljs-string">&#x27;muscle spasm&#x27;</span>, <span class="hljs-string">&#x27;pain&#x27;</span>],
 <span class="hljs-string">&#x27;review&#x27;</span>: [<span class="hljs-string">&#x27;&quot;Excellent.&quot;&#x27;</span>, <span class="hljs-string">&#x27;&quot;useless&quot;&#x27;</span>, <span class="hljs-string">&#x27;&quot;ok&quot;&#x27;</span>],
 <span class="hljs-string">&#x27;rating&#x27;</span>: [<span class="hljs-number">10.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">6.0</span>],
 <span class="hljs-string">&#x27;date&#x27;</span>: [<span class="hljs-string">&#x27;November 4, 2008&#x27;</span>, <span class="hljs-string">&#x27;March 24, 2017&#x27;</span>, <span class="hljs-string">&#x27;August 20, 2016&#x27;</span>],
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">10</span>],
 <span class="hljs-string">&#x27;review_length&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),bt=new is({props:{$$slots:{default:[Bx]},$$scope:{ctx:M}}}),Hs=new b({props:{code:`drug_dataset = drug_dataset.filter(lambda x: x["review_length"] > 30)
print(drug_dataset.num_rows)`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;review_length&quot;</span>] &gt; <span class="hljs-number">30</span>)
<span class="hljs-built_in">print</span>(drug_dataset.num_rows)`}}),Ms=new b({props:{code:"{'train': 138514, 'test': 46108}",highlighted:'{<span class="hljs-string">&#x27;train&#x27;</span>: <span class="hljs-number">138514</span>, <span class="hljs-string">&#x27;test&#x27;</span>: <span class="hljs-number">46108</span>}'}}),xt=new is({props:{$$slots:{default:[Gx]},$$scope:{ctx:M}}}),Rs=new b({props:{code:`import html

text = "I&#039;m a transformer called BERT"
html.unescape(text)`,highlighted:`<span class="hljs-keyword">import</span> html

text = <span class="hljs-string">&quot;I&amp;#039;m a transformer called BERT&quot;</span>
html.unescape(text)`}}),Fs=new b({props:{code:`"I'm a transformer called BERT"`,highlighted:'<span class="hljs-string">&quot;I&#x27;m a transformer called BERT&quot;</span>'}}),Us=new b({props:{code:'drug_dataset = drug_dataset.map(lambda x: {"review": html.unescape(x["review"])})',highlighted:'drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;review&quot;</span>: html.unescape(x[<span class="hljs-string">&quot;review&quot;</span>])})'}}),Vs=new Mn({}),Bs=new b({props:{code:`new_drug_dataset = drug_dataset.map(
    lambda x: {"review": [html.unescape(o) for o in x["review"]]}, batched=True
)`,highlighted:`new_drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(
    <span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;review&quot;</span>: [html.unescape(o) <span class="hljs-keyword">for</span> o <span class="hljs-keyword">in</span> x[<span class="hljs-string">&quot;review&quot;</span>]]}, batched=<span class="hljs-literal">True</span>
)`}}),Gs=new b({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["review"], truncation=True)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], truncation=<span class="hljs-literal">True</span>)`}}),Js=new b({props:{code:"%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)",highlighted:'%time tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)'}}),Ct=new is({props:{$$slots:{default:[Jx]},$$scope:{ctx:M}}}),Ws=new b({props:{code:`slow_tokenizer = AutoTokenizer.from_pretrained("bert-base-cased", use_fast=False)


def slow_tokenize_function(examples):
    return slow_tokenizer(examples["review"], truncation=True)


tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)`,highlighted:`slow_tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, use_fast=<span class="hljs-literal">False</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">slow_tokenize_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> slow_tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(slow_tokenize_function, batched=<span class="hljs-literal">True</span>, num_proc=<span class="hljs-number">8</span>)`}}),Nt=new is({props:{$$slots:{default:[Yx]},$$scope:{ctx:M}}}),At=new is({props:{$$slots:{default:[Wx]},$$scope:{ctx:M}}}),Xs=new b({props:{code:`def tokenize_and_split(examples):
    return tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_split</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(
        examples[<span class="hljs-string">&quot;review&quot;</span>],
        truncation=<span class="hljs-literal">True</span>,
        max_length=<span class="hljs-number">128</span>,
        return_overflowing_tokens=<span class="hljs-literal">True</span>,
    )`}}),Ks=new b({props:{code:`result = tokenize_and_split(drug_dataset["train"][0])
[len(inp) for inp in result["input_ids"]]`,highlighted:`result = tokenize_and_split(drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>])
[<span class="hljs-built_in">len</span>(inp) <span class="hljs-keyword">for</span> inp <span class="hljs-keyword">in</span> result[<span class="hljs-string">&quot;input_ids&quot;</span>]]`}}),Qs=new b({props:{code:"[128, 49]",highlighted:'[<span class="hljs-number">128</span>, <span class="hljs-number">49</span>]'}}),Zs=new b({props:{code:"tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)",highlighted:'tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_and_split, batched=<span class="hljs-literal">True</span>)'}}),en=new b({props:{code:"ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000",highlighted:'ArrowInvalid: Column <span class="hljs-number">1</span> named condition expected length <span class="hljs-number">1463</span> but got length <span class="hljs-number">1000</span>'}}),sn=new b({props:{code:`tokenized_dataset = drug_dataset.map(
    tokenize_and_split, batched=True, remove_columns=drug_dataset["train"].column_names
)`,highlighted:`tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(
    tokenize_and_split, batched=<span class="hljs-literal">True</span>, remove_columns=drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].column_names
)`}}),nn=new b({props:{code:'len(tokenized_dataset["train"]), len(drug_dataset["train"])',highlighted:'<span class="hljs-built_in">len</span>(tokenized_dataset[<span class="hljs-string">&quot;train&quot;</span>]), <span class="hljs-built_in">len</span>(drug_dataset[<span class="hljs-string">&quot;train&quot;</span>])'}}),an=new b({props:{code:"(206772, 138514)",highlighted:'(<span class="hljs-number">206772</span>, <span class="hljs-number">138514</span>)'}}),on=new b({props:{code:`def tokenize_and_split(examples):
    result = tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
    # Extract mapping between new and old indices
    sample_map = result.pop("overflow_to_sample_mapping")
    for key, values in examples.items():
        result[key] = [values[i] for i in sample_map]
    return result`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_split</span>(<span class="hljs-params">examples</span>):
    result = tokenizer(
        examples[<span class="hljs-string">&quot;review&quot;</span>],
        truncation=<span class="hljs-literal">True</span>,
        max_length=<span class="hljs-number">128</span>,
        return_overflowing_tokens=<span class="hljs-literal">True</span>,
    )
    <span class="hljs-comment"># Extract mapping between new and old indices</span>
    sample_map = result.pop(<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>)
    <span class="hljs-keyword">for</span> key, values <span class="hljs-keyword">in</span> examples.items():
        result[key] = [values[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sample_map]
    <span class="hljs-keyword">return</span> result`}}),rn=new b({props:{code:`tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
tokenized_dataset`,highlighted:`tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_and_split, batched=<span class="hljs-literal">True</span>)
tokenized_dataset`}}),ln=new b({props:{code:`DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 206772
    })
    test: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 68876
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">206772</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">68876</span>
    })
})`}}),un=new Mn({}),dn=new l1({props:{id:"tfcY1067A5Q"}}),pn=new b({props:{code:'drug_dataset.set_format("pandas")',highlighted:'drug_dataset.set_format(<span class="hljs-string">&quot;pandas&quot;</span>)'}}),cn=new b({props:{code:'drug_dataset["train"][:3]',highlighted:'drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][:<span class="hljs-number">3</span>]'}}),mn=new b({props:{code:'train_df = drug_dataset["train"][:]',highlighted:'train_df = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][:]'}}),Rt=new is({props:{$$slots:{default:[Xx]},$$scope:{ctx:M}}}),fn=new b({props:{code:`frequencies = (
    train_df["condition"]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={"index": "condition", "condition": "frequency"})
)
frequencies.head()`,highlighted:`frequencies = (
    train_df[<span class="hljs-string">&quot;condition&quot;</span>]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={<span class="hljs-string">&quot;index&quot;</span>: <span class="hljs-string">&quot;condition&quot;</span>, <span class="hljs-string">&quot;condition&quot;</span>: <span class="hljs-string">&quot;frequency&quot;</span>})
)
frequencies.head()`}}),vn=new b({props:{code:`from datasets import Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset`}}),hn=new b({props:{code:`Dataset({
    features: ['condition', 'frequency'],
    num_rows: 819
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;frequency&#x27;</span>],
    num_rows: <span class="hljs-number">819</span>
})`}}),Ut=new is({props:{$$slots:{default:[Kx]},$$scope:{ctx:M}}}),_n=new b({props:{code:"drug_dataset.reset_format()",highlighted:"drug_dataset.reset_format()"}}),gn=new Mn({}),$n=new b({props:{code:`drug_dataset_clean = drug_dataset["train"].train_test_split(train_size=0.8, seed=42)
# Rename the default "test" split to "validation"
drug_dataset_clean["validation"] = drug_dataset_clean.pop("test")
# Add the "test" set to our \`DatasetDict\`
drug_dataset_clean["test"] = drug_dataset["test"]
drug_dataset_clean`,highlighted:`drug_dataset_clean = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(train_size=<span class="hljs-number">0.8</span>, seed=<span class="hljs-number">42</span>)
<span class="hljs-comment"># Rename the default &quot;test&quot; split to &quot;validation&quot;</span>
drug_dataset_clean[<span class="hljs-string">&quot;validation&quot;</span>] = drug_dataset_clean.pop(<span class="hljs-string">&quot;test&quot;</span>)
<span class="hljs-comment"># Add the &quot;test&quot; set to our \`DatasetDict\`</span>
drug_dataset_clean[<span class="hljs-string">&quot;test&quot;</span>] = drug_dataset[<span class="hljs-string">&quot;test&quot;</span>]
drug_dataset_clean`}}),bn=new b({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 46108
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">110811</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">27703</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">46108</span>
    })
})`}}),En=new Mn({}),xn=new l1({props:{id:"blF9uxYcKHo"}}),kn=new b({props:{code:'drug_dataset_clean.save_to_disk("drug-reviews")',highlighted:'drug_dataset_clean.save_to_disk(<span class="hljs-string">&quot;drug-reviews&quot;</span>)'}}),yn=new b({props:{code:`drug-reviews/
\u251C\u2500\u2500 dataset_dict.json
\u251C\u2500\u2500 test
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u2514\u2500\u2500 state.json
\u251C\u2500\u2500 train
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u251C\u2500\u2500 indices.arrow
\u2502   \u2514\u2500\u2500 state.json
\u2514\u2500\u2500 validation
    \u251C\u2500\u2500 dataset.arrow
    \u251C\u2500\u2500 dataset_info.json
    \u251C\u2500\u2500 indices.arrow
    \u2514\u2500\u2500 state.json`,highlighted:`drug-reviews/
\u251C\u2500\u2500 dataset_dict.json
\u251C\u2500\u2500 test
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json
\u251C\u2500\u2500 train
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u251C\u2500\u2500 indices.arrow
\u2502   \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json
\u2514\u2500\u2500 validation
    \u251C\u2500\u2500 dataset.arrow
    \u251C\u2500\u2500 dataset_info.json
    \u251C\u2500\u2500 indices.arrow
    \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json`}}),Cn=new b({props:{code:`from datasets import load_from_disk

drug_dataset_reloaded = load_from_disk("drug-reviews")
drug_dataset_reloaded`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_from_disk

drug_dataset_reloaded = load_from_disk(<span class="hljs-string">&quot;drug-reviews&quot;</span>)
drug_dataset_reloaded`}}),Tn=new b({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 46108
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">110811</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">27703</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">46108</span>
    })
})`}}),zn=new b({props:{code:`for split, dataset in drug_dataset_clean.items():
    dataset.to_json(f"drug-reviews-{split}.jsonl")`,highlighted:`<span class="hljs-keyword">for</span> split, dataset <span class="hljs-keyword">in</span> drug_dataset_clean.items():
    dataset.to_json(<span class="hljs-string">f&quot;drug-reviews-<span class="hljs-subst">{split}</span>.jsonl&quot;</span>)`}}),On=new b({props:{code:"!head -n 1 drug-reviews-train.jsonl",highlighted:'!head -n <span class="hljs-number">1</span> drug-reviews-train.jsonl'}}),Nn=new b({props:{code:`{"patient_id":141780,"drugName":"Escitalopram","condition":"depression","review":"\\"I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven't worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\\"","rating":9.0,"date":"May 29, 2011","usefulCount":10,"review_length":125}`,highlighted:'{<span class="hljs-string">&quot;patient_id&quot;</span>:<span class="hljs-number">141780</span>,<span class="hljs-string">&quot;drugName&quot;</span>:<span class="hljs-string">&quot;Escitalopram&quot;</span>,<span class="hljs-string">&quot;condition&quot;</span>:<span class="hljs-string">&quot;depression&quot;</span>,<span class="hljs-string">&quot;review&quot;</span>:<span class="hljs-string">&quot;\\&quot;I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven&#x27;t worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\\&quot;&quot;</span>,<span class="hljs-string">&quot;rating&quot;</span>:<span class="hljs-number">9.0</span>,<span class="hljs-string">&quot;date&quot;</span>:<span class="hljs-string">&quot;May 29, 2011&quot;</span>,<span class="hljs-string">&quot;usefulCount&quot;</span>:<span class="hljs-number">10</span>,<span class="hljs-string">&quot;review_length&quot;</span>:<span class="hljs-number">125</span>}'}}),An=new b({props:{code:`data_files = {
    "train": "drug-reviews-train.jsonl",
    "validation": "drug-reviews-validation.jsonl",
    "test": "drug-reviews-test.jsonl",
}
drug_dataset_reloaded = load_dataset("json", data_files=data_files)`,highlighted:`data_files = {
    <span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;drug-reviews-train.jsonl&quot;</span>,
    <span class="hljs-string">&quot;validation&quot;</span>: <span class="hljs-string">&quot;drug-reviews-validation.jsonl&quot;</span>,
    <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;drug-reviews-test.jsonl&quot;</span>,
}
drug_dataset_reloaded = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files)`}}),{c(){c=o("meta"),D=d(),E=o("h1"),j=o("a"),w=o("span"),f(x.$$.fragment),q=d(),C=o("span"),y=n("Il est temps de trancher et de d\xE9couper"),P=d(),f(O.$$.fragment),T=d(),k=o("p"),J=n("La plupart du temps, les donn\xE9es avec lesquelles vous travaillez ne seront pas parfaitement pr\xE9par\xE9es pour les mod\xE8les de formation. Dans cette section, nous allons explorer les diff\xE9rentes fonctionnalit\xE9s fournies par \u{1F917} Datasets pour nettoyer vos ensembles de donn\xE9es."),A=d(),f(z.$$.fragment),me=d(),R=o("h2"),W=o("a"),se=o("span"),f(ee.$$.fragment),us=d(),Re=o("span"),Fe=n("Trancher et d\xE9couper nos donn\xE9es"),mt=d(),F=o("p"),Ue=n("Semblable \xE0 Pandas, \u{1F917} Datasets fournit plusieurs fonctions pour manipuler le contenu des objets "),N=o("code"),Rn=n("Dataset"),Fn=n(" et "),ft=o("code"),Un=n("DatasetDict"),Vn=n(". Nous avons d\xE9j\xE0 rencontr\xE9 la m\xE9thode "),vt=o("code"),Bn=n("Dataset.map()"),Gn=n(" dans le "),Jn=o("a"),jc=n("Chapitre 3"),wc=n(", et dans cette section nous allons explorer certaines des autres fonctions \xE0 notre disposition."),Xi=d(),he=o("p"),Dc=n("Pour cet exemple, nous utiliserons le "),ds=o("a"),kc=n("Drug Review Dataset"),yc=n(" qui est h\xE9berg\xE9 sur [UC Irvine Machine Learning Repository] ("),ps=o("a"),Cc=n("https://archive.ics.uci.edu/ml/index.php"),Tc=n("), qui contient des avis de patients sur divers m\xE9dicaments, ainsi que la condition trait\xE9e et une note de 10 \xE9toiles sur la satisfaction du patient."),Ki=d(),_e=o("p"),zc=n("Nous devons d\u2019abord t\xE9l\xE9charger et extraire les donn\xE9es, ce qui peut \xEAtre fait avec les commandes "),Ao=o("code"),Pc=n("wget"),Oc=n(" et "),Io=o("code"),Nc=n("unzip"),Ac=n("\xA0:"),Qi=d(),f(cs.$$.fragment),Zi=d(),ne=o("p"),Ic=n("\xC9tant donn\xE9 que TSV n\u2019est qu\u2019une variante de CSV qui utilise des tabulations au lieu de virgules comme s\xE9parateurs, nous pouvons charger ces fichiers en utilisant le script de chargement "),Lo=o("code"),Lc=n("csv"),Sc=n(" et en sp\xE9cifiant l\u2019argument "),So=o("code"),Hc=n("delimiter"),Mc=n(" dans la fonction "),Ho=o("code"),Rc=n("load_dataset()"),Fc=n(" comme suit\xA0:"),eu=d(),f(ms.$$.fragment),tu=d(),ge=o("p"),Uc=n("Une bonne pratique lors de toute sorte d\u2019analyse de donn\xE9es consiste \xE0 pr\xE9lever un petit \xE9chantillon al\xE9atoire pour avoir une id\xE9e rapide du type de donn\xE9es avec lesquelles vous travaillez. Dans \u{1F917} Datasets, nous pouvons cr\xE9er un \xE9chantillon al\xE9atoire en encha\xEEnant les fonctions "),Mo=o("code"),Vc=n("Dataset.shuffle()"),Bc=n(" et "),Ro=o("code"),Gc=n("Dataset.select()"),Jc=n("\xA0:"),su=d(),f(fs.$$.fragment),nu=d(),f(vs.$$.fragment),au=d(),ae=o("p"),Yc=n("Notez que nous avons corrig\xE9 la graine dans "),Fo=o("code"),Wc=n("Dataset.shuffle()"),Xc=n(" \xE0 des fins de reproductibilit\xE9. "),Uo=o("code"),Kc=n("Dataset.select()"),Qc=n(" attend un it\xE9rable d\u2019indices, nous avons donc pass\xE9 "),Vo=o("code"),Zc=n("range(1000)"),em=n(" pour r\xE9cup\xE9rer les 1 000 premiers exemples de l\u2019ensemble de donn\xE9es m\xE9lang\xE9. \xC0 partir de cet \xE9chantillon, nous pouvons d\xE9j\xE0 voir quelques bizarreries dans notre ensemble de donn\xE9es\xA0:"),ou=d(),$e=o("ul"),Bo=o("li"),tm=n("La colonne \u201CSans nom\xA0:\xA00\u201D ressemble \xE9trangement \xE0 un identifiant anonyme pour chaque patient."),sm=d(),Go=o("li"),nm=n("La colonne \u201Ccondition\u201D comprend un m\xE9lange d\u2019\xE9tiquettes en majuscules et en minuscules."),am=d(),Ve=o("li"),om=n("Les avis sont de longueur variable et contiennent un m\xE9lange de s\xE9parateurs de lignes Python ("),Jo=o("code"),rm=n("\\r\\n"),lm=n(") ainsi que des codes de caract\xE8res HTML comme "),Yo=o("code"),im=n("&\\#039;"),um=n("."),ru=d(),be=o("p"),dm=n("Voyons comment nous pouvons utiliser \u{1F917} Datasets pour traiter chacun de ces probl\xE8mes. Pour tester l\u2019hypoth\xE8se de l\u2019ID patient pour la colonne "),Wo=o("code"),pm=n("Unnamed : 0"),cm=n(", nous pouvons utiliser la fonction "),Xo=o("code"),mm=n("Dataset.unique()"),fm=n(" pour v\xE9rifier que le nombre d\u2019ID correspond au nombre de lignes dans chaque division\xA0:"),lu=d(),f(hs.$$.fragment),iu=d(),Ee=o("p"),vm=n("Cela semble confirmer notre hypoth\xE8se, alors nettoyons un peu l\u2019ensemble de donn\xE9es en renommant la colonne "),Ko=o("code"),hm=n("Unnamed: 0"),_m=n(" en quelque chose d\u2019un peu plus interpr\xE9table. Nous pouvons utiliser la fonction "),Qo=o("code"),gm=n("DatasetDict.rename_column()"),$m=n(" pour renommer la colonne sur les deux divisions en une seule fois\xA0:"),uu=d(),f(_s.$$.fragment),du=d(),f(gs.$$.fragment),pu=d(),f(ht.$$.fragment),cu=d(),X=o("p"),bm=n("Ensuite, normalisons toutes les \xE9tiquettes "),Zo=o("code"),Em=n("condition"),xm=n(" en utilisant "),er=o("code"),qm=n("Dataset.map()"),jm=n(". Comme nous l\u2019avons fait avec la tokenisation dans le "),Yn=o("a"),wm=n("chapitre 3"),Dm=n(", nous pouvons d\xE9finir une fonction simple qui peut \xEAtre appliqu\xE9e sur toutes les lignes de chaque division dans "),tr=o("code"),km=n("drug_dataset"),ym=n("\xA0:"),mu=d(),f($s.$$.fragment),fu=d(),f(bs.$$.fragment),vu=d(),xe=o("p"),Cm=n("Oh non, nous avons rencontr\xE9 un probl\xE8me avec notre fonction de carte\xA0! \xC0 partir de l\u2019erreur, nous pouvons d\xE9duire que certaines des entr\xE9es de la colonne \u201Ccondition\u201D sont \u201CAucune\u201D, qui ne peuvent pas \xEAtre mises en minuscules car ce ne sont pas des cha\xEEnes. Supprimons ces lignes en utilisant "),sr=o("code"),Tm=n("Dataset.filter()"),zm=n(", qui fonctionne de mani\xE8re similaire \xE0 "),nr=o("code"),Pm=n("Dataset.map()"),Om=n(" et attend une fonction qui re\xE7oit un seul exemple de l\u2019ensemble de donn\xE9es. Au lieu d\u2019\xE9crire une fonction explicite comme :"),hu=d(),f(Es.$$.fragment),_u=d(),qe=o("p"),Nm=n("puis en ex\xE9cutant "),ar=o("code"),Am=n("drug_dataset.filter(filter_nones)"),Im=n(", nous pouvons le faire en une seule ligne en utilisant une "),or=o("em"),Lm=n("lambda function"),Sm=n(". En Python, les fonctions lambda sont de petites fonctions que vous pouvez d\xE9finir sans les nommer explicitement. Ils prennent la forme g\xE9n\xE9rale :"),gu=d(),f(xs.$$.fragment),$u=d(),K=o("p"),Hm=n("o\xF9 "),rr=o("code"),Mm=n("lambda"),Rm=n(" est l\u2019un des [mots cl\xE9s] sp\xE9ciaux de Python ("),qs=o("a"),Fm=n("https://docs.python.org/3/reference/lexical_analysis.html#keywords"),Um=n("), "),lr=o("code"),Vm=n("<arguments>"),Bm=n(" est une liste/ensemble de valeurs s\xE9par\xE9es par des virgules qui d\xE9finissent les entr\xE9es de la fonction et "),ir=o("code"),Gm=n("<expression>"),Jm=n(" repr\xE9sente les op\xE9rations que vous souhaitez ex\xE9cuter. Par exemple, nous pouvons d\xE9finir une simple fonction lambda qui met au carr\xE9 un nombre comme suit\xA0:"),bu=d(),f(js.$$.fragment),Eu=d(),Wn=o("p"),Ym=n("Pour appliquer cette fonction \xE0 une entr\xE9e, nous devons l\u2019envelopper ainsi que l\u2019entr\xE9e entre parenth\xE8ses\xA0:"),xu=d(),f(ws.$$.fragment),qu=d(),f(Ds.$$.fragment),ju=d(),Xn=o("p"),Wm=n("De m\xEAme, nous pouvons d\xE9finir des fonctions lambda avec plusieurs arguments en les s\xE9parant par des virgules. Par exemple, nous pouvons calculer l\u2019aire d\u2019un triangle comme suit :"),wu=d(),f(ks.$$.fragment),Du=d(),f(ys.$$.fragment),ku=d(),_t=o("p"),Xm=n("Les fonctions Lambda sont pratiques lorsque vous souhaitez d\xE9finir de petites fonctions \xE0 usage unique (pour plus d\u2019informations \xE0 leur sujet, nous vous recommandons de lire l\u2019excellent "),Cs=o("a"),Km=n("tutoriel Real Python"),Qm=n(" d\u2019Andr\xE9 Burgaud) . Dans le contexte \u{1F917} Datasets, nous pouvons utiliser des fonctions lambda pour d\xE9finir des op\xE9rations simples de mappage et de filtrage, alors utilisons cette astuce pour \xE9liminer les entr\xE9es \u201CNone\u201D dans notre jeu de donn\xE9es\xA0:"),yu=d(),f(Ts.$$.fragment),Cu=d(),Kn=o("p"),Zm=n("Avec les entr\xE9es \u201CNone\u201D supprim\xE9es, nous pouvons normaliser notre colonne \u201Ccondition\u201D\xA0:"),Tu=d(),f(zs.$$.fragment),zu=d(),f(Ps.$$.fragment),Pu=d(),Qn=o("p"),ef=n("\xC7a marche ! Maintenant que nous avons nettoy\xE9 les \xE9tiquettes, examinons le nettoyage des avis eux-m\xEAmes."),Ou=d(),Be=o("h2"),gt=o("a"),ur=o("span"),f(Os.$$.fragment),tf=d(),dr=o("span"),sf=n("Cr\xE9ation de nouvelles colonnes"),Nu=d(),Zn=o("p"),nf=n("Chaque fois que vous avez affaire \xE0 des avis de clients, une bonne pratique consiste \xE0 v\xE9rifier le nombre de mots dans chaque avis. Une critique peut \xEAtre un simple mot comme \u201CG\xE9nial\xA0!\u201D ou un essai complet avec des milliers de mots, et selon le cas d\u2019utilisation, vous devrez g\xE9rer ces extr\xEAmes diff\xE9remment. Pour calculer le nombre de mots dans chaque r\xE9vision, nous utiliserons une heuristique approximative bas\xE9e sur la division de chaque texte par des espaces."),Au=d(),ea=o("p"),af=n("D\xE9finissons une fonction simple qui compte le nombre de mots dans chaque avis\xA0:"),Iu=d(),f(Ns.$$.fragment),Lu=d(),Y=o("p"),of=n("Contrairement \xE0 notre fonction "),pr=o("code"),rf=n("lowercase_condition()"),lf=n(", "),cr=o("code"),uf=n("compute_review_length()"),df=n(" renvoie un dictionnaire dont la cl\xE9 ne correspond pas \xE0 l\u2019un des noms de colonne de l\u2019ensemble de donn\xE9es. Dans ce cas, lorsque "),mr=o("code"),pf=n("compute_review_length()"),cf=n(" est pass\xE9 \xE0 "),fr=o("code"),mf=n("Dataset.map()"),ff=n(", il sera appliqu\xE9 \xE0 toutes les lignes du jeu de donn\xE9es pour cr\xE9er une nouvelle colonne "),vr=o("code"),vf=n("review_length"),hf=n("\xA0:"),Su=d(),f(As.$$.fragment),Hu=d(),f(Is.$$.fragment),Mu=d(),$t=o("p"),_f=n("Comme pr\xE9vu, nous pouvons voir qu\u2019une colonne \u201Creview_length\u201D a \xE9t\xE9 ajout\xE9e \xE0 notre ensemble d\u2019entra\xEEnement. Nous pouvons trier cette nouvelle colonne avec "),hr=o("code"),gf=n("Dataset.sort()"),$f=n(" pour voir \xE0 quoi ressemblent les valeurs extr\xEAmes\xA0:"),Ru=d(),f(Ls.$$.fragment),Fu=d(),f(Ss.$$.fragment),Uu=d(),ta=o("p"),bf=n("Comme nous le soup\xE7onnions, certaines critiques ne contiennent qu\u2019un seul mot, ce qui, bien que cela puisse convenir \xE0 l\u2019analyse des sentiments, ne serait pas informatif si nous voulons pr\xE9dire la condition."),Vu=d(),f(bt.$$.fragment),Bu=d(),Et=o("p"),Ef=n("Utilisons la fonction "),_r=o("code"),xf=n("Dataset.filter()"),qf=n(" pour supprimer les avis contenant moins de 30 mots. De la m\xEAme mani\xE8re que nous l\u2019avons fait avec la colonne \u201Ccondition\u201D, nous pouvons filtrer les avis tr\xE8s courts en exigeant que les avis aient une longueur sup\xE9rieure \xE0 ce seuil\xA0:"),Gu=d(),f(Hs.$$.fragment),Ju=d(),f(Ms.$$.fragment),Yu=d(),sa=o("p"),jf=n("Comme vous pouvez le constater, cela a supprim\xE9 environ 15\xA0% des avis de nos ensembles d\u2019entra\xEEnement et de test d\u2019origine."),Wu=d(),f(xt.$$.fragment),Xu=d(),qt=o("p"),wf=n("La derni\xE8re chose \xE0 laquelle nous devons faire face est la pr\xE9sence de codes de caract\xE8res HTML dans nos avis. Nous pouvons utiliser le module "),gr=o("code"),Df=n("html"),kf=n(" de Python pour supprimer ces caract\xE8res, comme ceci\xA0:"),Ku=d(),f(Rs.$$.fragment),Qu=d(),f(Fs.$$.fragment),Zu=d(),jt=o("p"),yf=n("Nous utiliserons "),$r=o("code"),Cf=n("Dataset.map()"),Tf=n(" pour d\xE9masquer tous les caract\xE8res HTML de notre corpus\xA0:"),ed=d(),f(Us.$$.fragment),td=d(),wt=o("p"),zf=n("Comme vous pouvez le voir, la m\xE9thode "),br=o("code"),Pf=n("Dataset.map()"),Of=n(" est tr\xE8s utile pour le traitement des donn\xE9es \u2014 et nous n\u2019avons m\xEAme pas effleur\xE9 la surface de tout ce qu\u2019elle peut faire\xA0!"),sd=d(),Ge=o("h2"),Dt=o("a"),Er=o("span"),f(Vs.$$.fragment),Nf=d(),na=o("span"),Af=n("Les superpouvoirs de la m\xE9thode "),xr=o("code"),If=n("map()"),nd=d(),oe=o("p"),Lf=n("La m\xE9thode "),qr=o("code"),Sf=n("Dataset.map()"),Hf=n(" prend un argument "),jr=o("code"),Mf=n("batched"),Rf=n(" qui, s\u2019il est d\xE9fini sur "),wr=o("code"),Ff=n("True"),Uf=n(", l\u2019am\xE8ne \xE0 envoyer un lot d\u2019exemples \xE0 la fonction map en une seule fois (la taille du lot est configurable mais par d\xE9faut \xE0 1 000). Par exemple, la fonction de carte pr\xE9c\xE9dente qui d\xE9gageait tout le code HTML prenait un peu de temps \xE0 s\u2019ex\xE9cuter (vous pouvez lire le temps pris dans les barres de progression). On peut acc\xE9l\xE9rer cela en traitant plusieurs \xE9l\xE9ments en m\xEAme temps \xE0 l\u2019aide d\u2019une liste en compr\xE9hension."),ad=d(),Q=o("p"),Vf=n("Lorsque vous sp\xE9cifiez "),Dr=o("code"),Bf=n("batched=True"),Gf=n(", la fonction re\xE7oit un dictionnaire avec les champs de l\u2019ensemble de donn\xE9es, mais chaque valeur est maintenant une "),kr=o("em"),Jf=n("liste de valeurs"),Yf=n(", et non plus une seule valeur. La valeur de retour de "),yr=o("code"),Wf=n("Dataset.map()"),Xf=n(" devrait \xEAtre la m\xEAme\xA0: un dictionnaire avec les champs que nous voulons mettre \xE0 jour ou ajouter \xE0 notre ensemble de donn\xE9es, et une liste de valeurs. Par exemple, voici une autre fa\xE7on de supprimer tous les caract\xE8res HTML, mais en utilisant "),Cr=o("code"),Kf=n("batched=True"),Qf=n("\xA0:"),od=d(),f(Bs.$$.fragment),rd=d(),kt=o("p"),Zf=n("Si vous ex\xE9cutez ce code dans un notebook, vous verrez que cette commande s\u2019ex\xE9cute beaucoup plus rapidement que la pr\xE9c\xE9dente. Et ce n\u2019est pas parce que nos critiques ont d\xE9j\xE0 \xE9t\xE9 sans \xE9chappement HTML \u2014 si vous r\xE9-ex\xE9cutez l\u2019instruction de la section pr\xE9c\xE9dente (sans "),Tr=o("code"),ev=n("batched=True"),tv=n("), cela prendra le m\xEAme temps qu\u2019avant. En effet, les compr\xE9hensions de liste sont g\xE9n\xE9ralement plus rapides que l\u2019ex\xE9cution du m\xEAme code dans une boucle \u201Cfor\u201D, et nous gagnons \xE9galement en performances en acc\xE9dant \xE0 de nombreux \xE9l\xE9ments en m\xEAme temps au lieu d\u2019un par un."),ld=d(),re=o("p"),sv=n("L\u2019utilisation de "),zr=o("code"),nv=n("Dataset.map()"),av=n(" avec "),Pr=o("code"),ov=n("batched=True"),rv=n(" sera essentielle pour d\xE9bloquer la vitesse des tokenizers \u201Crapides\u201D que nous rencontrerons dans "),aa=o("a"),lv=n("Chapitre 6"),iv=n(", qui peuvent rapidement tokeniser de grandes listes de textes. Par exemple, pour tokeniser toutes les revues de m\xE9dicaments avec un tokenizer rapide, nous pourrions utiliser une fonction comme celle-ci\xA0:"),id=d(),f(Gs.$$.fragment),ud=d(),le=o("p"),uv=n("Comme vous l\u2019avez vu dans le "),oa=o("a"),dv=n("Chapitre 3"),pv=n(", nous pouvons passer un ou plusieurs exemples au tokenizer, nous pouvons donc utiliser cette fonction avec ou sans "),Or=o("code"),cv=n("batched=True"),mv=n(". Profitons-en pour comparer les performances des diff\xE9rentes options. Dans un cahier, vous pouvez chronom\xE9trer une instruction d\u2019une ligne en ajoutant "),Nr=o("code"),fv=n("%time"),vv=n(" avant la ligne de code que vous souhaitez mesurer\xA0:"),dd=d(),f(Js.$$.fragment),pd=d(),yt=o("p"),hv=n("Vous pouvez \xE9galement chronom\xE9trer une cellule enti\xE8re en mettant "),Ar=o("code"),_v=n("%%time"),gv=n(" au d\xE9but de la cellule. Sur le mat\xE9riel sur lequel nous avons ex\xE9cut\xE9 cela, il affichait 10,8 s pour cette instruction (c\u2019est le nombre \xE9crit apr\xE8s \u201CWall time\u201D)."),cd=d(),f(Ct.$$.fragment),md=d(),ra=o("p"),$v=n("Voici les r\xE9sultats que nous avons obtenus avec et sans batching, avec un tokenizer rapide et un lent :"),fd=d(),Tt=o("table"),Ir=o("thead"),Je=o("tr"),la=o("th"),bv=n("Options"),Ev=d(),ia=o("th"),xv=n("Tokenizer rapide"),qv=d(),ua=o("th"),jv=n("Tokenizer lent"),wv=d(),Ys=o("tbody"),Ye=o("tr"),da=o("td"),Lr=o("code"),Dv=n("batched=True"),kv=d(),pa=o("td"),yv=n("10.8s"),Cv=d(),ca=o("td"),Tv=n("4min41s"),zv=d(),We=o("tr"),ma=o("td"),Sr=o("code"),Pv=n("batched=False"),Ov=d(),fa=o("td"),Nv=n("59.2s"),Av=d(),va=o("td"),Iv=n("5min3s"),vd=d(),je=o("p"),Lv=n("Cela signifie que l\u2019utilisation d\u2019un tokenizer rapide avec l\u2019option "),Hr=o("code"),Sv=n("batched=True"),Hv=n(" est 30 fois plus rapide que son homologue lent sans traitement par lot \u2014 c\u2019est vraiment incroyable\xA0! C\u2019est la raison principale pour laquelle les tokenizers rapides sont la valeur par d\xE9faut lors de l\u2019utilisation de "),Mr=o("code"),Mv=n("AutoTokenizer"),Rv=n(" (et pourquoi ils sont appel\xE9s \u201Crapides\u201D). Ils sont capables d\u2019atteindre une telle acc\xE9l\xE9ration car dans les coulisses, le code de tokenisation est ex\xE9cut\xE9 dans Rust, qui est un langage qui facilite la parall\xE9lisation de l\u2019ex\xE9cution du code."),hd=d(),ha=o("p"),Fv=n("La parall\xE9lisation est \xE9galement la raison de l\u2019acc\xE9l\xE9ration de pr\xE8s de 6 fois obtenue par le fast tokenizer avec le traitement par lots\xA0: vous ne pouvez pas parall\xE9liser une seule op\xE9ration de tokenisation, mais lorsque vous souhaitez tokeniser de nombreux textes en m\xEAme temps, vous pouvez simplement r\xE9partir l\u2019ex\xE9cution sur plusieurs processus. chacun responsable de ses propres textes."),_d=d(),fe=o("p"),Rr=o("code"),Uv=n("Dataset.map()"),Vv=n(" poss\xE8de \xE9galement ses propres capacit\xE9s de parall\xE9lisation. Comme ils ne sont pas soutenus par Rust, ils ne laisseront pas un tokenizer lent rattraper un rapide, mais ils peuvent toujours \xEAtre utiles (surtout si vous utilisez un tokenizer qui n\u2019a pas de version rapide). Pour activer le multitraitement, utilisez l\u2019argument "),Fr=o("code"),Bv=n("num_proc"),Gv=n(" et sp\xE9cifiez le nombre de processus \xE0 utiliser dans votre appel \xE0 "),Ur=o("code"),Jv=n("Dataset.map()"),Yv=n("\xA0:"),gd=d(),f(Ws.$$.fragment),$d=d(),_a=o("p"),Wv=n("Vous pouvez exp\xE9rimenter un peu le timing pour d\xE9terminer le nombre optimal de processus \xE0 utiliser ; dans notre cas 8 semblait produire le meilleur gain de vitesse. Voici les chiffres que nous avons obtenus avec et sans multitraitement\xA0:"),bd=d(),zt=o("table"),Vr=o("thead"),Xe=o("tr"),ga=o("th"),Xv=n("Options"),Kv=d(),$a=o("th"),Qv=n("Tokenizer rapide"),Zv=d(),ba=o("th"),eh=n("Tokenizer lent"),th=d(),ve=o("tbody"),Ke=o("tr"),Ea=o("td"),Br=o("code"),sh=n("batched=True"),nh=d(),xa=o("td"),ah=n("10.8s"),oh=d(),qa=o("td"),rh=n("4min41s"),lh=d(),Qe=o("tr"),ja=o("td"),Gr=o("code"),ih=n("batched=False"),uh=d(),wa=o("td"),dh=n("59.2s"),ph=d(),Da=o("td"),ch=n("5min3s"),mh=d(),Ze=o("tr"),Pt=o("td"),Jr=o("code"),fh=n("batched=True"),vh=n(", "),Yr=o("code"),hh=n("num_proc=8"),_h=d(),ka=o("td"),gh=n("6.52s"),$h=d(),ya=o("td"),bh=n("41.3s"),Eh=d(),et=o("tr"),Ot=o("td"),Wr=o("code"),xh=n("batched=False"),qh=n(", "),Xr=o("code"),jh=n("num_proc=8"),wh=d(),Ca=o("td"),Dh=n("9.49s"),kh=d(),Ta=o("td"),yh=n("45.2s"),Ed=d(),ie=o("p"),Ch=n("Ce sont des r\xE9sultats beaucoup plus raisonnables pour le tokenizer lent, mais les performances du tokenizer rapide ont \xE9galement \xE9t\xE9 consid\xE9rablement am\xE9lior\xE9es. Notez, cependant, que ce ne sera pas toujours le cas - pour les valeurs de "),Kr=o("code"),Th=n("num_proc"),zh=n(" autres que 8, nos tests ont montr\xE9 qu\u2019il \xE9tait plus rapide d\u2019utiliser "),Qr=o("code"),Ph=n("batched=True"),Oh=n(" sans cette option. En g\xE9n\xE9ral, nous ne recommandons pas d\u2019utiliser le multitraitement Python pour les tokenizers rapides avec "),Zr=o("code"),Nh=n("batched=True"),Ah=n("."),xd=d(),f(Nt.$$.fragment),qd=d(),we=o("p"),Ih=n("Toutes ces fonctionnalit\xE9s condens\xE9es en une seule m\xE9thode sont d\xE9j\xE0 assez \xE9tonnantes, mais il y a plus ! Avec "),el=o("code"),Lh=n("Dataset.map()"),Sh=n(" et "),tl=o("code"),Hh=n("batched=True"),Mh=n(" vous pouvez modifier le nombre d\u2019\xE9l\xE9ments dans votre jeu de donn\xE9es. Ceci est tr\xE8s utile dans de nombreuses situations o\xF9 vous souhaitez cr\xE9er plusieurs fonctionnalit\xE9s d\u2019entra\xEEnement \xE0 partir d\u2019un exemple, et nous devrons le faire dans le cadre du pr\xE9traitement de plusieurs des t\xE2ches NLP que nous entreprendrons dans [Chapitre 7](/course/ Chapitre 7)."),jd=d(),f(At.$$.fragment),wd=d(),De=o("p"),Rh=n("Voyons comment cela fonctionne\xA0! Ici, nous allons tokeniser nos exemples et les tronquer \xE0 une longueur maximale de 128, mais nous demanderons au tokenizer de renvoyer "),sl=o("em"),Fh=n("tous"),Uh=n(" les morceaux des textes au lieu du premier. Cela peut \xEAtre fait avec "),nl=o("code"),Vh=n("return_overflowing_tokens=True"),Bh=n("\xA0:"),Dd=d(),f(Xs.$$.fragment),kd=d(),It=o("p"),Gh=n("Testons cela sur un exemple avant d\u2019utiliser "),al=o("code"),Jh=n("Dataset.map()"),Yh=n(" sur l\u2019ensemble de donn\xE9es\xA0:"),yd=d(),f(Ks.$$.fragment),Cd=d(),f(Qs.$$.fragment),Td=d(),za=o("p"),Wh=n("Ainsi, notre premier exemple dans l\u2019ensemble de formation est devenu deux fonctionnalit\xE9s car il a \xE9t\xE9 segment\xE9 \xE0 plus que le nombre maximum de jetons que nous avons sp\xE9cifi\xE9\xA0: le premier de longueur 128 et le second de longueur 49. Faisons maintenant cela pour tous les \xE9l\xE9ments du base de donn\xE9es!"),zd=d(),f(Zs.$$.fragment),Pd=d(),f(en.$$.fragment),Od=d(),ke=o("p"),Xh=n("Oh non! Cela n\u2019a pas fonctionn\xE9 ! Pourquoi pas? L\u2019examen du message d\u2019erreur nous donnera un indice\xA0: il y a une incompatibilit\xE9 dans les longueurs de l\u2019une des colonnes, l\u2019une \xE9tant de longueur 1\xA0463 et l\u2019autre de longueur 1\xA0000. Si vous avez consult\xE9 la [documentation] "),ol=o("code"),Kh=n("Dataset.map()"),Qh=n("("),tn=o("a"),Zh=n("https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),e_=n("), vous vous souviendrez peut-\xEAtre qu\u2019il s\u2019agit du nombre d\u2019\xE9chantillons pass\xE9s \xE0 la fonction que nous mappons\xA0; ici, ces 1 000 exemples ont donn\xE9 1 463 nouvelles fonctionnalit\xE9s, entra\xEEnant une erreur de forme."),Nd=d(),Z=o("p"),t_=n("Le probl\xE8me est que nous essayons de m\xE9langer deux ensembles de donn\xE9es diff\xE9rents de tailles diff\xE9rentes\xA0: les colonnes "),rl=o("code"),s_=n("drug_dataset"),n_=n(" auront un certain nombre d\u2019exemples (les 1 000 dans notre erreur), mais le "),ll=o("code"),a_=n("tokenized_dataset"),o_=n(" que nous construisons en aura plus (le 1 463 dans le message d\u2019erreur). Cela ne fonctionne pas pour un "),il=o("code"),r_=n("Dataset"),l_=n(", nous devons donc soit supprimer les colonnes de l\u2019ancien jeu de donn\xE9es, soit leur donner la m\xEAme taille que dans le nouveau jeu de donn\xE9es. Nous pouvons faire le premier avec l\u2019argument "),ul=o("code"),i_=n("remove_columns"),u_=n("\xA0:"),Ad=d(),f(sn.$$.fragment),Id=d(),Pa=o("p"),d_=n("Maintenant, cela fonctionne sans erreur. Nous pouvons v\xE9rifier que notre nouveau jeu de donn\xE9es contient beaucoup plus d\u2019\xE9l\xE9ments que le jeu de donn\xE9es d\u2019origine en comparant les longueurs\xA0:"),Ld=d(),f(nn.$$.fragment),Sd=d(),f(an.$$.fragment),Hd=d(),ye=o("p"),p_=n("Nous avons mentionn\xE9 que nous pouvions \xE9galement r\xE9soudre le probl\xE8me de longueur non concordante en donnant aux anciennes colonnes la m\xEAme taille que les nouvelles. Pour ce faire, nous aurons besoin du champ "),dl=o("code"),c_=n("overflow_to_sample_mapping"),m_=n(" que le tokenizer renvoie lorsque nous d\xE9finissons "),pl=o("code"),f_=n("return_overflowing_tokens=True"),v_=n(". Il nous donne une correspondance entre un nouvel index de fonctionnalit\xE9 et l\u2019index de l\u2019\xE9chantillon dont il est issu. Gr\xE2ce \xE0 cela, nous pouvons associer chaque cl\xE9 pr\xE9sente dans notre jeu de donn\xE9es d\u2019origine \xE0 une liste de valeurs de la bonne taille en r\xE9p\xE9tant les valeurs de chaque exemple autant de fois qu\u2019il g\xE9n\xE8re de nouvelles fonctionnalit\xE9s\xA0:"),Md=d(),f(on.$$.fragment),Rd=d(),Lt=o("p"),h_=n("Nous pouvons voir que cela fonctionne avec "),cl=o("code"),__=n("Dataset.map()"),g_=n(" sans que nous ayons besoin de supprimer les anciennes colonnes\xA0:"),Fd=d(),f(rn.$$.fragment),Ud=d(),f(ln.$$.fragment),Vd=d(),Oa=o("p"),$_=n("Nous obtenons le m\xEAme nombre de fonctionnalit\xE9s d\u2019entra\xEEnement qu\u2019auparavant, mais ici nous avons conserv\xE9 tous les anciens champs. Si vous en avez besoin pour un post-traitement apr\xE8s l\u2019application de votre mod\xE8le, vous pouvez utiliser cette approche."),Bd=d(),St=o("p"),b_=n(`Vous avez maintenant vu comment \u{1F917} Datasets peut \xEAtre utilis\xE9 pour pr\xE9traiter un ensemble de donn\xE9es de diff\xE9rentes mani\xE8res. Bien que les fonctions de traitement de \u{1F917} Datasets couvrent la plupart de vos besoins de formation de mod\xE8les,
il peut arriver que vous deviez passer \xE0 Pandas pour acc\xE9der \xE0 des fonctionnalit\xE9s plus puissantes, telles que `),ml=o("code"),E_=n("DataFrame.groupby()"),x_=n(" ou des API de haut niveau pour la visualisation. Heureusement, \u{1F917} Datasets est con\xE7u pour \xEAtre interop\xE9rable avec des biblioth\xE8ques telles que Pandas, NumPy, PyTorch, TensorFlow et JAX. Voyons comment cela fonctionne."),Gd=d(),tt=o("h2"),Ht=o("a"),fl=o("span"),f(un.$$.fragment),q_=d(),st=o("span"),j_=n("De "),vl=o("code"),w_=n("Dataset"),D_=n("s \xE0 "),hl=o("code"),k_=n("DataFrame"),y_=n("s et vice versa"),Jd=d(),f(dn.$$.fragment),Yd=d(),ue=o("p"),C_=n("Pour permettre la conversion entre diverses biblioth\xE8ques tierces, \u{1F917} Datasets fournit une fonction "),_l=o("code"),T_=n("Dataset.set_format()"),z_=n(". Cette fonction ne modifie que le "),gl=o("em"),P_=n("format de sortie"),O_=n(" de l\u2019ensemble de donn\xE9es, vous pouvez donc facilement passer \xE0 un autre format sans affecter le "),$l=o("em"),N_=n("format de donn\xE9es"),A_=n(" sous-jacent, qui est Apache Arrow. Le formatage se fait sur place. Pour d\xE9montrer, convertissons notre jeu de donn\xE9es en Pandas\xA0:"),Wd=d(),f(pn.$$.fragment),Xd=d(),Mt=o("p"),I_=n("Maintenant, lorsque nous acc\xE9dons aux \xE9l\xE9ments du jeu de donn\xE9es, nous obtenons un "),bl=o("code"),L_=n("pandas.DataFrame"),S_=n(" au lieu d\u2019un dictionnaire\xA0:"),Kd=d(),f(cn.$$.fragment),Qd=d(),Ce=o("table"),El=o("thead"),I=o("tr"),Zd=o("th"),H_=d(),xl=o("th"),M_=n("patient_id"),R_=d(),ql=o("th"),F_=n("drugName"),U_=d(),jl=o("th"),V_=n("condition"),B_=d(),wl=o("th"),G_=n("review"),J_=d(),Dl=o("th"),Y_=n("rating"),W_=d(),kl=o("th"),X_=n("date"),K_=d(),yl=o("th"),Q_=n("usefulCount"),Z_=d(),Cl=o("th"),e2=n("review_length"),t2=d(),nt=o("tbody"),L=o("tr"),Tl=o("th"),s2=n("0"),n2=d(),zl=o("td"),a2=n("95260"),o2=d(),Pl=o("td"),r2=n("Guanfacine"),l2=d(),Ol=o("td"),i2=n("adhd"),u2=d(),Nl=o("td"),d2=n('"My son is halfway through his fourth week of Intuniv..."'),p2=d(),Al=o("td"),c2=n("8.0"),m2=d(),Il=o("td"),f2=n("April 27, 2010"),v2=d(),Ll=o("td"),h2=n("192"),_2=d(),Sl=o("td"),g2=n("141"),$2=d(),S=o("tr"),Hl=o("th"),b2=n("1"),E2=d(),Ml=o("td"),x2=n("92703"),q2=d(),Rl=o("td"),j2=n("Lybrel"),w2=d(),Fl=o("td"),D2=n("birth control"),k2=d(),Ul=o("td"),y2=n('"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."'),C2=d(),Vl=o("td"),T2=n("5.0"),z2=d(),Bl=o("td"),P2=n("December 14, 2009"),O2=d(),Gl=o("td"),N2=n("17"),A2=d(),Jl=o("td"),I2=n("134"),L2=d(),H=o("tr"),Yl=o("th"),S2=n("2"),H2=d(),Wl=o("td"),M2=n("138000"),R2=d(),Xl=o("td"),F2=n("Ortho Evra"),U2=d(),Kl=o("td"),V2=n("birth control"),B2=d(),Ql=o("td"),G2=n('"This is my first time using any form of birth control..."'),J2=d(),Zl=o("td"),Y2=n("8.0"),W2=d(),ei=o("td"),X2=n("November 3, 2015"),K2=d(),ti=o("td"),Q2=n("10"),Z2=d(),si=o("td"),eg=n("89"),ep=d(),Te=o("p"),tg=n("Cr\xE9ons un "),ni=o("code"),sg=n("pandas.DataFrame"),ng=n(" pour l\u2019ensemble d\u2019entra\xEEnement en s\xE9lectionnant tous les \xE9l\xE9ments de "),ai=o("code"),ag=n('drug_dataset["train"]'),og=n("\xA0:"),tp=d(),f(mn.$$.fragment),sp=d(),f(Rt.$$.fragment),np=d(),Ft=o("p"),rg=n("De l\xE0, nous pouvons utiliser toutes les fonctionnalit\xE9s Pandas que nous voulons. Par exemple, nous pouvons faire un cha\xEEnage sophistiqu\xE9 pour calculer la distribution de classe parmi les entr\xE9es "),oi=o("code"),lg=n("condition"),ig=n("\xA0:"),ap=d(),f(fn.$$.fragment),op=d(),ze=o("table"),ri=o("thead"),Pe=o("tr"),rp=o("th"),ug=d(),li=o("th"),dg=n("condition"),pg=d(),ii=o("th"),cg=n("frequency"),mg=d(),te=o("tbody"),at=o("tr"),ui=o("th"),fg=n("0"),vg=d(),di=o("td"),hg=n("birth control"),_g=d(),pi=o("td"),gg=n("27655"),$g=d(),ot=o("tr"),ci=o("th"),bg=n("1"),Eg=d(),mi=o("td"),xg=n("depression"),qg=d(),fi=o("td"),jg=n("8023"),wg=d(),rt=o("tr"),vi=o("th"),Dg=n("2"),kg=d(),hi=o("td"),yg=n("acne"),Cg=d(),_i=o("td"),Tg=n("5209"),zg=d(),lt=o("tr"),gi=o("th"),Pg=n("3"),Og=d(),$i=o("td"),Ng=n("anxiety"),Ag=d(),bi=o("td"),Ig=n("4991"),Lg=d(),it=o("tr"),Ei=o("th"),Sg=n("4"),Hg=d(),xi=o("td"),Mg=n("pain"),Rg=d(),qi=o("td"),Fg=n("4744"),lp=d(),Oe=o("p"),Ug=n("Et une fois que nous avons termin\xE9 notre analyse Pandas, nous pouvons toujours cr\xE9er un nouvel objet "),ji=o("code"),Vg=n("Dataset"),Bg=n(" en utilisant la fonction "),wi=o("code"),Gg=n("Dataset.from_pandas()"),Jg=n(" comme suit\xA0:"),ip=d(),f(vn.$$.fragment),up=d(),f(hn.$$.fragment),dp=d(),f(Ut.$$.fragment),pp=d(),de=o("p"),Yg=n("Ceci conclut notre visite des diff\xE9rentes techniques de pr\xE9traitement disponibles dans \u{1F917} Datasets. Pour compl\xE9ter la section, cr\xE9ons un ensemble de validation pour pr\xE9parer l\u2019ensemble de donn\xE9es pour la formation d\u2019un classificateur. Avant cela, nous allons r\xE9initialiser le format de sortie de "),Di=o("code"),Wg=n("drug_dataset"),Xg=n(" de "),ki=o("code"),Kg=n('"pandas"'),Qg=n(" \xE0 "),yi=o("code"),Zg=n('"arrow"'),e$=n("\xA0:"),cp=d(),f(_n.$$.fragment),mp=d(),ut=o("h2"),Vt=o("a"),Ci=o("span"),f(gn.$$.fragment),t$=d(),Ti=o("span"),s$=n("Cr\xE9ation d'un ensemble de validation"),fp=d(),Na=o("p"),n$=n("Bien que nous ayons un jeu de test que nous pourrions utiliser pour l\u2019\xE9valuation, il est recommand\xE9 de ne pas toucher au jeu de test et de cr\xE9er un jeu de validation s\xE9par\xE9 pendant le d\xE9veloppement. Une fois que vous \xEAtes satisfait des performances de vos mod\xE8les sur l\u2019ensemble de validation, vous pouvez effectuer une derni\xE8re v\xE9rification d\u2019int\xE9grit\xE9 sur l\u2019ensemble de test. Ce processus permet d\u2019att\xE9nuer le risque de d\xE9passement de l\u2019ensemble de test et de d\xE9ploiement d\u2019un mod\xE8le qui \xE9choue sur des donn\xE9es du monde r\xE9el."),vp=d(),Ne=o("p"),a$=n("\u{1F917} Datasets fournit une fonction "),zi=o("code"),o$=n("Dataset.train_test_split()"),r$=n(" bas\xE9e sur la c\xE9l\xE8bre fonctionnalit\xE9 de "),Pi=o("code"),l$=n("scikit-learn"),i$=n(". Utilisons-le pour diviser notre ensemble d\u2019entra\xEEnement en divisions \u201Ctrain\u201D et \u201Cvalidation\u201D (nous d\xE9finissons l\u2019argument \u201Cseed\u201D pour la reproductibilit\xE9)\xA0:"),hp=d(),f($n.$$.fragment),_p=d(),f(bn.$$.fragment),gp=d(),Bt=o("p"),u$=n("G\xE9nial, nous avons maintenant pr\xE9par\xE9 un jeu de donn\xE9es pr\xEAt pour l\u2019entra\xEEnement de certains mod\xE8les\xA0! Dans la "),Aa=o("a"),d$=n("section 5"),p$=n(", nous vous montrerons comment t\xE9l\xE9charger des ensembles de donn\xE9es sur le Hugging Face Hub, mais pour l\u2019instant, terminons notre analyse en examinant quelques fa\xE7ons d\u2019enregistrer des ensembles de donn\xE9es sur votre ordinateur local."),$p=d(),dt=o("h2"),Gt=o("a"),Oi=o("span"),f(En.$$.fragment),c$=d(),Ni=o("span"),m$=n("Enregistrer un jeu de donn\xE9es"),bp=d(),f(xn.$$.fragment),Ep=d(),Ia=o("p"),f$=n("Bien que \u{1F917} Datasets mette en cache chaque jeu de donn\xE9es t\xE9l\xE9charg\xE9 et les op\xE9rations qui y sont effectu\xE9es, il y a des moments o\xF9 vous voudrez enregistrer un jeu de donn\xE9es sur le disque (par exemple, au cas o\xF9 le cache serait supprim\xE9). Comme indiqu\xE9 dans le tableau ci-dessous, \u{1F917} Datasets fournit trois fonctions principales pour enregistrer votre jeu de donn\xE9es dans diff\xE9rents formats\xA0:"),xp=d(),Jt=o("table"),Ai=o("thead"),qn=o("tr"),La=o("th"),v$=n("Format de donn\xE9es"),h$=d(),Sa=o("th"),_$=n("Fonction"),g$=d(),pt=o("tbody"),jn=o("tr"),Ha=o("td"),$$=n("Fl\xE8che"),b$=d(),Ma=o("td"),Ii=o("code"),E$=n("Dataset.save_to_disk()"),x$=d(),wn=o("tr"),Ra=o("td"),q$=n("CSV"),j$=d(),Fa=o("td"),Li=o("code"),w$=n("Dataset.to_csv()"),D$=d(),Dn=o("tr"),Ua=o("td"),k$=n("JSON"),y$=d(),Va=o("td"),Si=o("code"),C$=n("Dataset.to_json()"),qp=d(),Ba=o("p"),T$=n("Par exemple, enregistrons notre jeu de donn\xE9es nettoy\xE9 au format Arrow\xA0:"),jp=d(),f(kn.$$.fragment),wp=d(),Ga=o("p"),z$=n("Cela cr\xE9era un r\xE9pertoire avec la structure suivante\xA0:"),Dp=d(),f(yn.$$.fragment),kp=d(),pe=o("p"),P$=n("o\xF9 nous pouvons voir que chaque division est associ\xE9e \xE0 sa propre table "),Hi=o("em"),O$=n("dataset.arrow"),N$=n(" et \xE0 certaines m\xE9tadonn\xE9es dans "),Mi=o("em"),A$=n("dataset_info.json"),I$=n(" et "),Ri=o("em"),L$=n("state.json "),S$=n(". Vous pouvez consid\xE9rer le format Arrow comme un tableau sophistiqu\xE9 de colonnes et de lignes optimis\xE9 pour la cr\xE9ation d\u2019applications hautes performances qui traitent et transportent de grands ensembles de donn\xE9es."),yp=d(),Yt=o("p"),H$=n("Une fois le jeu de donn\xE9es enregistr\xE9, nous pouvons le charger en utilisant la fonction "),Fi=o("code"),M$=n("load_from_disk()"),R$=n(" comme suit\xA0:"),Cp=d(),f(Cn.$$.fragment),Tp=d(),f(Tn.$$.fragment),zp=d(),Ja=o("p"),F$=n("Pour les formats CSV et JSON, nous devons stocker chaque fractionnement dans un fichier s\xE9par\xE9. Pour ce faire, vous pouvez parcourir les cl\xE9s et les valeurs de l\u2019objet \u201CDatasetDict\u201D\xA0:"),Pp=d(),f(zn.$$.fragment),Op=d(),Wt=o("p"),U$=n("Cela enregistre chaque fractionnement au [format de lignes JSON] ("),Pn=o("a"),V$=n("https://jsonlines.org"),B$=n("), o\xF9 chaque ligne de l\u2019ensemble de donn\xE9es est stock\xE9e sous la forme d\u2019une seule ligne de JSON. Voici \xE0 quoi ressemble le premier exemple\xA0:"),Np=d(),f(On.$$.fragment),Ap=d(),f(Nn.$$.fragment),Ip=d(),Xt=o("p"),G$=n("Nous pouvons ensuite utiliser les techniques de "),Ya=o("a"),J$=n("section 2"),Y$=n(" pour charger les fichiers JSON comme suit\xA0:"),Lp=d(),f(An.$$.fragment),Sp=d(),Wa=o("p"),W$=n("Et c\u2019est tout pour notre excursion dans le data wrangling avec \u{1F917} Datasets\xA0! Maintenant que nous disposons d\u2019un ensemble de donn\xE9es nettoy\xE9 pour entra\xEEner un mod\xE8le, voici quelques id\xE9es que vous pouvez essayer\xA0:"),Hp=d(),Kt=o("ol"),In=o("li"),X$=n("Utilisez les techniques du "),Xa=o("a"),K$=n("Chapitre 3"),Q$=n(" pour former un classificateur capable de pr\xE9dire l\u2019\xE9tat du patient en fonction de l\u2019examen du m\xE9dicament."),Z$=d(),ct=o("li"),e1=n("Utilisez le pipeline "),Ui=o("code"),t1=n("summarization"),s1=n(" du "),Ka=o("a"),n1=n("Chapitre 1"),a1=n(" pour g\xE9n\xE9rer des r\xE9sum\xE9s des r\xE9visions."),Mp=d(),Qa=o("p"),o1=n("Ensuite, nous verrons comment \u{1F917} Datasets peut vous permettre de travailler avec d\u2019\xE9normes ensembles de donn\xE9es sans faire exploser votre ordinateur portable\xA0!"),this.h()},l(e){const i=Rx('[data-svelte="svelte-1phssyn"]',document.head);c=r(i,"META",{name:!0,content:!0}),i.forEach(s),D=p(e),E=r(e,"H1",{class:!0});var Ln=l(E);j=r(Ln,"A",{id:!0,class:!0,href:!0});var Vi=l(j);w=r(Vi,"SPAN",{});var Bi=l(w);v(x.$$.fragment,Bi),Bi.forEach(s),Vi.forEach(s),q=p(Ln),C=r(Ln,"SPAN",{});var Gi=l(C);y=a(Gi,"Il est temps de trancher et de d\xE9couper"),Gi.forEach(s),Ln.forEach(s),P=p(e),v(O.$$.fragment,e),T=p(e),k=r(e,"P",{});var Ji=l(k);J=a(Ji,"La plupart du temps, les donn\xE9es avec lesquelles vous travaillez ne seront pas parfaitement pr\xE9par\xE9es pour les mod\xE8les de formation. Dans cette section, nous allons explorer les diff\xE9rentes fonctionnalit\xE9s fournies par \u{1F917} Datasets pour nettoyer vos ensembles de donn\xE9es."),Ji.forEach(s),A=p(e),v(z.$$.fragment,e),me=p(e),R=r(e,"H2",{class:!0});var Sn=l(R);W=r(Sn,"A",{id:!0,class:!0,href:!0});var Yi=l(W);se=r(Yi,"SPAN",{});var Wi=l(se);v(ee.$$.fragment,Wi),Wi.forEach(s),Yi.forEach(s),us=p(Sn),Re=r(Sn,"SPAN",{});var i1=l(Re);Fe=a(i1,"Trancher et d\xE9couper nos donn\xE9es"),i1.forEach(s),Sn.forEach(s),mt=p(e),F=r(e,"P",{});var Ae=l(F);Ue=a(Ae,"Semblable \xE0 Pandas, \u{1F917} Datasets fournit plusieurs fonctions pour manipuler le contenu des objets "),N=r(Ae,"CODE",{});var u1=l(N);Rn=a(u1,"Dataset"),u1.forEach(s),Fn=a(Ae," et "),ft=r(Ae,"CODE",{});var d1=l(ft);Un=a(d1,"DatasetDict"),d1.forEach(s),Vn=a(Ae,". Nous avons d\xE9j\xE0 rencontr\xE9 la m\xE9thode "),vt=r(Ae,"CODE",{});var p1=l(vt);Bn=a(p1,"Dataset.map()"),p1.forEach(s),Gn=a(Ae," dans le "),Jn=r(Ae,"A",{href:!0});var c1=l(Jn);jc=a(c1,"Chapitre 3"),c1.forEach(s),wc=a(Ae,", et dans cette section nous allons explorer certaines des autres fonctions \xE0 notre disposition."),Ae.forEach(s),Xi=p(e),he=r(e,"P",{});var Za=l(he);Dc=a(Za,"Pour cet exemple, nous utiliserons le "),ds=r(Za,"A",{href:!0,rel:!0});var m1=l(ds);kc=a(m1,"Drug Review Dataset"),m1.forEach(s),yc=a(Za," qui est h\xE9berg\xE9 sur [UC Irvine Machine Learning Repository] ("),ps=r(Za,"A",{href:!0,rel:!0});var f1=l(ps);Cc=a(f1,"https://archive.ics.uci.edu/ml/index.php"),f1.forEach(s),Tc=a(Za,"), qui contient des avis de patients sur divers m\xE9dicaments, ainsi que la condition trait\xE9e et une note de 10 \xE9toiles sur la satisfaction du patient."),Za.forEach(s),Ki=p(e),_e=r(e,"P",{});var eo=l(_e);zc=a(eo,"Nous devons d\u2019abord t\xE9l\xE9charger et extraire les donn\xE9es, ce qui peut \xEAtre fait avec les commandes "),Ao=r(eo,"CODE",{});var v1=l(Ao);Pc=a(v1,"wget"),v1.forEach(s),Oc=a(eo," et "),Io=r(eo,"CODE",{});var h1=l(Io);Nc=a(h1,"unzip"),h1.forEach(s),Ac=a(eo,"\xA0:"),eo.forEach(s),Qi=p(e),v(cs.$$.fragment,e),Zi=p(e),ne=r(e,"P",{});var Qt=l(ne);Ic=a(Qt,"\xC9tant donn\xE9 que TSV n\u2019est qu\u2019une variante de CSV qui utilise des tabulations au lieu de virgules comme s\xE9parateurs, nous pouvons charger ces fichiers en utilisant le script de chargement "),Lo=r(Qt,"CODE",{});var _1=l(Lo);Lc=a(_1,"csv"),_1.forEach(s),Sc=a(Qt," et en sp\xE9cifiant l\u2019argument "),So=r(Qt,"CODE",{});var g1=l(So);Hc=a(g1,"delimiter"),g1.forEach(s),Mc=a(Qt," dans la fonction "),Ho=r(Qt,"CODE",{});var $1=l(Ho);Rc=a($1,"load_dataset()"),$1.forEach(s),Fc=a(Qt," comme suit\xA0:"),Qt.forEach(s),eu=p(e),v(ms.$$.fragment,e),tu=p(e),ge=r(e,"P",{});var to=l(ge);Uc=a(to,"Une bonne pratique lors de toute sorte d\u2019analyse de donn\xE9es consiste \xE0 pr\xE9lever un petit \xE9chantillon al\xE9atoire pour avoir une id\xE9e rapide du type de donn\xE9es avec lesquelles vous travaillez. Dans \u{1F917} Datasets, nous pouvons cr\xE9er un \xE9chantillon al\xE9atoire en encha\xEEnant les fonctions "),Mo=r(to,"CODE",{});var b1=l(Mo);Vc=a(b1,"Dataset.shuffle()"),b1.forEach(s),Bc=a(to," et "),Ro=r(to,"CODE",{});var E1=l(Ro);Gc=a(E1,"Dataset.select()"),E1.forEach(s),Jc=a(to,"\xA0:"),to.forEach(s),su=p(e),v(fs.$$.fragment,e),nu=p(e),v(vs.$$.fragment,e),au=p(e),ae=r(e,"P",{});var Zt=l(ae);Yc=a(Zt,"Notez que nous avons corrig\xE9 la graine dans "),Fo=r(Zt,"CODE",{});var x1=l(Fo);Wc=a(x1,"Dataset.shuffle()"),x1.forEach(s),Xc=a(Zt," \xE0 des fins de reproductibilit\xE9. "),Uo=r(Zt,"CODE",{});var q1=l(Uo);Kc=a(q1,"Dataset.select()"),q1.forEach(s),Qc=a(Zt," attend un it\xE9rable d\u2019indices, nous avons donc pass\xE9 "),Vo=r(Zt,"CODE",{});var j1=l(Vo);Zc=a(j1,"range(1000)"),j1.forEach(s),em=a(Zt," pour r\xE9cup\xE9rer les 1 000 premiers exemples de l\u2019ensemble de donn\xE9es m\xE9lang\xE9. \xC0 partir de cet \xE9chantillon, nous pouvons d\xE9j\xE0 voir quelques bizarreries dans notre ensemble de donn\xE9es\xA0:"),Zt.forEach(s),ou=p(e),$e=r(e,"UL",{});var so=l($e);Bo=r(so,"LI",{});var w1=l(Bo);tm=a(w1,"La colonne \u201CSans nom\xA0:\xA00\u201D ressemble \xE9trangement \xE0 un identifiant anonyme pour chaque patient."),w1.forEach(s),sm=p(so),Go=r(so,"LI",{});var D1=l(Go);nm=a(D1,"La colonne \u201Ccondition\u201D comprend un m\xE9lange d\u2019\xE9tiquettes en majuscules et en minuscules."),D1.forEach(s),am=p(so),Ve=r(so,"LI",{});var no=l(Ve);om=a(no,"Les avis sont de longueur variable et contiennent un m\xE9lange de s\xE9parateurs de lignes Python ("),Jo=r(no,"CODE",{});var k1=l(Jo);rm=a(k1,"\\r\\n"),k1.forEach(s),lm=a(no,") ainsi que des codes de caract\xE8res HTML comme "),Yo=r(no,"CODE",{});var y1=l(Yo);im=a(y1,"&\\#039;"),y1.forEach(s),um=a(no,"."),no.forEach(s),so.forEach(s),ru=p(e),be=r(e,"P",{});var ao=l(be);dm=a(ao,"Voyons comment nous pouvons utiliser \u{1F917} Datasets pour traiter chacun de ces probl\xE8mes. Pour tester l\u2019hypoth\xE8se de l\u2019ID patient pour la colonne "),Wo=r(ao,"CODE",{});var C1=l(Wo);pm=a(C1,"Unnamed : 0"),C1.forEach(s),cm=a(ao,", nous pouvons utiliser la fonction "),Xo=r(ao,"CODE",{});var T1=l(Xo);mm=a(T1,"Dataset.unique()"),T1.forEach(s),fm=a(ao," pour v\xE9rifier que le nombre d\u2019ID correspond au nombre de lignes dans chaque division\xA0:"),ao.forEach(s),lu=p(e),v(hs.$$.fragment,e),iu=p(e),Ee=r(e,"P",{});var oo=l(Ee);vm=a(oo,"Cela semble confirmer notre hypoth\xE8se, alors nettoyons un peu l\u2019ensemble de donn\xE9es en renommant la colonne "),Ko=r(oo,"CODE",{});var z1=l(Ko);hm=a(z1,"Unnamed: 0"),z1.forEach(s),_m=a(oo," en quelque chose d\u2019un peu plus interpr\xE9table. Nous pouvons utiliser la fonction "),Qo=r(oo,"CODE",{});var P1=l(Qo);gm=a(P1,"DatasetDict.rename_column()"),P1.forEach(s),$m=a(oo," pour renommer la colonne sur les deux divisions en une seule fois\xA0:"),oo.forEach(s),uu=p(e),v(_s.$$.fragment,e),du=p(e),v(gs.$$.fragment,e),pu=p(e),v(ht.$$.fragment,e),cu=p(e),X=r(e,"P",{});var Ie=l(X);bm=a(Ie,"Ensuite, normalisons toutes les \xE9tiquettes "),Zo=r(Ie,"CODE",{});var O1=l(Zo);Em=a(O1,"condition"),O1.forEach(s),xm=a(Ie," en utilisant "),er=r(Ie,"CODE",{});var N1=l(er);qm=a(N1,"Dataset.map()"),N1.forEach(s),jm=a(Ie,". Comme nous l\u2019avons fait avec la tokenisation dans le "),Yn=r(Ie,"A",{href:!0});var A1=l(Yn);wm=a(A1,"chapitre 3"),A1.forEach(s),Dm=a(Ie,", nous pouvons d\xE9finir une fonction simple qui peut \xEAtre appliqu\xE9e sur toutes les lignes de chaque division dans "),tr=r(Ie,"CODE",{});var I1=l(tr);km=a(I1,"drug_dataset"),I1.forEach(s),ym=a(Ie,"\xA0:"),Ie.forEach(s),mu=p(e),v($s.$$.fragment,e),fu=p(e),v(bs.$$.fragment,e),vu=p(e),xe=r(e,"P",{});var ro=l(xe);Cm=a(ro,"Oh non, nous avons rencontr\xE9 un probl\xE8me avec notre fonction de carte\xA0! \xC0 partir de l\u2019erreur, nous pouvons d\xE9duire que certaines des entr\xE9es de la colonne \u201Ccondition\u201D sont \u201CAucune\u201D, qui ne peuvent pas \xEAtre mises en minuscules car ce ne sont pas des cha\xEEnes. Supprimons ces lignes en utilisant "),sr=r(ro,"CODE",{});var L1=l(sr);Tm=a(L1,"Dataset.filter()"),L1.forEach(s),zm=a(ro,", qui fonctionne de mani\xE8re similaire \xE0 "),nr=r(ro,"CODE",{});var S1=l(nr);Pm=a(S1,"Dataset.map()"),S1.forEach(s),Om=a(ro," et attend une fonction qui re\xE7oit un seul exemple de l\u2019ensemble de donn\xE9es. Au lieu d\u2019\xE9crire une fonction explicite comme :"),ro.forEach(s),hu=p(e),v(Es.$$.fragment,e),_u=p(e),qe=r(e,"P",{});var lo=l(qe);Nm=a(lo,"puis en ex\xE9cutant "),ar=r(lo,"CODE",{});var H1=l(ar);Am=a(H1,"drug_dataset.filter(filter_nones)"),H1.forEach(s),Im=a(lo,", nous pouvons le faire en une seule ligne en utilisant une "),or=r(lo,"EM",{});var M1=l(or);Lm=a(M1,"lambda function"),M1.forEach(s),Sm=a(lo,". En Python, les fonctions lambda sont de petites fonctions que vous pouvez d\xE9finir sans les nommer explicitement. Ils prennent la forme g\xE9n\xE9rale :"),lo.forEach(s),gu=p(e),v(xs.$$.fragment,e),$u=p(e),K=r(e,"P",{});var Le=l(K);Hm=a(Le,"o\xF9 "),rr=r(Le,"CODE",{});var R1=l(rr);Mm=a(R1,"lambda"),R1.forEach(s),Rm=a(Le," est l\u2019un des [mots cl\xE9s] sp\xE9ciaux de Python ("),qs=r(Le,"A",{href:!0,rel:!0});var F1=l(qs);Fm=a(F1,"https://docs.python.org/3/reference/lexical_analysis.html#keywords"),F1.forEach(s),Um=a(Le,"), "),lr=r(Le,"CODE",{});var U1=l(lr);Vm=a(U1,"<arguments>"),U1.forEach(s),Bm=a(Le," est une liste/ensemble de valeurs s\xE9par\xE9es par des virgules qui d\xE9finissent les entr\xE9es de la fonction et "),ir=r(Le,"CODE",{});var V1=l(ir);Gm=a(V1,"<expression>"),V1.forEach(s),Jm=a(Le," repr\xE9sente les op\xE9rations que vous souhaitez ex\xE9cuter. Par exemple, nous pouvons d\xE9finir une simple fonction lambda qui met au carr\xE9 un nombre comme suit\xA0:"),Le.forEach(s),bu=p(e),v(js.$$.fragment,e),Eu=p(e),Wn=r(e,"P",{});var B1=l(Wn);Ym=a(B1,"Pour appliquer cette fonction \xE0 une entr\xE9e, nous devons l\u2019envelopper ainsi que l\u2019entr\xE9e entre parenth\xE8ses\xA0:"),B1.forEach(s),xu=p(e),v(ws.$$.fragment,e),qu=p(e),v(Ds.$$.fragment,e),ju=p(e),Xn=r(e,"P",{});var G1=l(Xn);Wm=a(G1,"De m\xEAme, nous pouvons d\xE9finir des fonctions lambda avec plusieurs arguments en les s\xE9parant par des virgules. Par exemple, nous pouvons calculer l\u2019aire d\u2019un triangle comme suit :"),G1.forEach(s),wu=p(e),v(ks.$$.fragment,e),Du=p(e),v(ys.$$.fragment,e),ku=p(e),_t=r(e,"P",{});var Fp=l(_t);Xm=a(Fp,"Les fonctions Lambda sont pratiques lorsque vous souhaitez d\xE9finir de petites fonctions \xE0 usage unique (pour plus d\u2019informations \xE0 leur sujet, nous vous recommandons de lire l\u2019excellent "),Cs=r(Fp,"A",{href:!0,rel:!0});var J1=l(Cs);Km=a(J1,"tutoriel Real Python"),J1.forEach(s),Qm=a(Fp," d\u2019Andr\xE9 Burgaud) . Dans le contexte \u{1F917} Datasets, nous pouvons utiliser des fonctions lambda pour d\xE9finir des op\xE9rations simples de mappage et de filtrage, alors utilisons cette astuce pour \xE9liminer les entr\xE9es \u201CNone\u201D dans notre jeu de donn\xE9es\xA0:"),Fp.forEach(s),yu=p(e),v(Ts.$$.fragment,e),Cu=p(e),Kn=r(e,"P",{});var Y1=l(Kn);Zm=a(Y1,"Avec les entr\xE9es \u201CNone\u201D supprim\xE9es, nous pouvons normaliser notre colonne \u201Ccondition\u201D\xA0:"),Y1.forEach(s),Tu=p(e),v(zs.$$.fragment,e),zu=p(e),v(Ps.$$.fragment,e),Pu=p(e),Qn=r(e,"P",{});var W1=l(Qn);ef=a(W1,"\xC7a marche ! Maintenant que nous avons nettoy\xE9 les \xE9tiquettes, examinons le nettoyage des avis eux-m\xEAmes."),W1.forEach(s),Ou=p(e),Be=r(e,"H2",{class:!0});var Up=l(Be);gt=r(Up,"A",{id:!0,class:!0,href:!0});var X1=l(gt);ur=r(X1,"SPAN",{});var K1=l(ur);v(Os.$$.fragment,K1),K1.forEach(s),X1.forEach(s),tf=p(Up),dr=r(Up,"SPAN",{});var Q1=l(dr);sf=a(Q1,"Cr\xE9ation de nouvelles colonnes"),Q1.forEach(s),Up.forEach(s),Nu=p(e),Zn=r(e,"P",{});var Z1=l(Zn);nf=a(Z1,"Chaque fois que vous avez affaire \xE0 des avis de clients, une bonne pratique consiste \xE0 v\xE9rifier le nombre de mots dans chaque avis. Une critique peut \xEAtre un simple mot comme \u201CG\xE9nial\xA0!\u201D ou un essai complet avec des milliers de mots, et selon le cas d\u2019utilisation, vous devrez g\xE9rer ces extr\xEAmes diff\xE9remment. Pour calculer le nombre de mots dans chaque r\xE9vision, nous utiliserons une heuristique approximative bas\xE9e sur la division de chaque texte par des espaces."),Z1.forEach(s),Au=p(e),ea=r(e,"P",{});var eb=l(ea);af=a(eb,"D\xE9finissons une fonction simple qui compte le nombre de mots dans chaque avis\xA0:"),eb.forEach(s),Iu=p(e),v(Ns.$$.fragment,e),Lu=p(e),Y=r(e,"P",{});var ce=l(Y);of=a(ce,"Contrairement \xE0 notre fonction "),pr=r(ce,"CODE",{});var tb=l(pr);rf=a(tb,"lowercase_condition()"),tb.forEach(s),lf=a(ce,", "),cr=r(ce,"CODE",{});var sb=l(cr);uf=a(sb,"compute_review_length()"),sb.forEach(s),df=a(ce," renvoie un dictionnaire dont la cl\xE9 ne correspond pas \xE0 l\u2019un des noms de colonne de l\u2019ensemble de donn\xE9es. Dans ce cas, lorsque "),mr=r(ce,"CODE",{});var nb=l(mr);pf=a(nb,"compute_review_length()"),nb.forEach(s),cf=a(ce," est pass\xE9 \xE0 "),fr=r(ce,"CODE",{});var ab=l(fr);mf=a(ab,"Dataset.map()"),ab.forEach(s),ff=a(ce,", il sera appliqu\xE9 \xE0 toutes les lignes du jeu de donn\xE9es pour cr\xE9er une nouvelle colonne "),vr=r(ce,"CODE",{});var ob=l(vr);vf=a(ob,"review_length"),ob.forEach(s),hf=a(ce,"\xA0:"),ce.forEach(s),Su=p(e),v(As.$$.fragment,e),Hu=p(e),v(Is.$$.fragment,e),Mu=p(e),$t=r(e,"P",{});var Vp=l($t);_f=a(Vp,"Comme pr\xE9vu, nous pouvons voir qu\u2019une colonne \u201Creview_length\u201D a \xE9t\xE9 ajout\xE9e \xE0 notre ensemble d\u2019entra\xEEnement. Nous pouvons trier cette nouvelle colonne avec "),hr=r(Vp,"CODE",{});var rb=l(hr);gf=a(rb,"Dataset.sort()"),rb.forEach(s),$f=a(Vp," pour voir \xE0 quoi ressemblent les valeurs extr\xEAmes\xA0:"),Vp.forEach(s),Ru=p(e),v(Ls.$$.fragment,e),Fu=p(e),v(Ss.$$.fragment,e),Uu=p(e),ta=r(e,"P",{});var lb=l(ta);bf=a(lb,"Comme nous le soup\xE7onnions, certaines critiques ne contiennent qu\u2019un seul mot, ce qui, bien que cela puisse convenir \xE0 l\u2019analyse des sentiments, ne serait pas informatif si nous voulons pr\xE9dire la condition."),lb.forEach(s),Vu=p(e),v(bt.$$.fragment,e),Bu=p(e),Et=r(e,"P",{});var Bp=l(Et);Ef=a(Bp,"Utilisons la fonction "),_r=r(Bp,"CODE",{});var ib=l(_r);xf=a(ib,"Dataset.filter()"),ib.forEach(s),qf=a(Bp," pour supprimer les avis contenant moins de 30 mots. De la m\xEAme mani\xE8re que nous l\u2019avons fait avec la colonne \u201Ccondition\u201D, nous pouvons filtrer les avis tr\xE8s courts en exigeant que les avis aient une longueur sup\xE9rieure \xE0 ce seuil\xA0:"),Bp.forEach(s),Gu=p(e),v(Hs.$$.fragment,e),Ju=p(e),v(Ms.$$.fragment,e),Yu=p(e),sa=r(e,"P",{});var ub=l(sa);jf=a(ub,"Comme vous pouvez le constater, cela a supprim\xE9 environ 15\xA0% des avis de nos ensembles d\u2019entra\xEEnement et de test d\u2019origine."),ub.forEach(s),Wu=p(e),v(xt.$$.fragment,e),Xu=p(e),qt=r(e,"P",{});var Gp=l(qt);wf=a(Gp,"La derni\xE8re chose \xE0 laquelle nous devons faire face est la pr\xE9sence de codes de caract\xE8res HTML dans nos avis. Nous pouvons utiliser le module "),gr=r(Gp,"CODE",{});var db=l(gr);Df=a(db,"html"),db.forEach(s),kf=a(Gp," de Python pour supprimer ces caract\xE8res, comme ceci\xA0:"),Gp.forEach(s),Ku=p(e),v(Rs.$$.fragment,e),Qu=p(e),v(Fs.$$.fragment,e),Zu=p(e),jt=r(e,"P",{});var Jp=l(jt);yf=a(Jp,"Nous utiliserons "),$r=r(Jp,"CODE",{});var pb=l($r);Cf=a(pb,"Dataset.map()"),pb.forEach(s),Tf=a(Jp," pour d\xE9masquer tous les caract\xE8res HTML de notre corpus\xA0:"),Jp.forEach(s),ed=p(e),v(Us.$$.fragment,e),td=p(e),wt=r(e,"P",{});var Yp=l(wt);zf=a(Yp,"Comme vous pouvez le voir, la m\xE9thode "),br=r(Yp,"CODE",{});var cb=l(br);Pf=a(cb,"Dataset.map()"),cb.forEach(s),Of=a(Yp," est tr\xE8s utile pour le traitement des donn\xE9es \u2014 et nous n\u2019avons m\xEAme pas effleur\xE9 la surface de tout ce qu\u2019elle peut faire\xA0!"),Yp.forEach(s),sd=p(e),Ge=r(e,"H2",{class:!0});var Wp=l(Ge);Dt=r(Wp,"A",{id:!0,class:!0,href:!0});var mb=l(Dt);Er=r(mb,"SPAN",{});var fb=l(Er);v(Vs.$$.fragment,fb),fb.forEach(s),mb.forEach(s),Nf=p(Wp),na=r(Wp,"SPAN",{});var r1=l(na);Af=a(r1,"Les superpouvoirs de la m\xE9thode "),xr=r(r1,"CODE",{});var vb=l(xr);If=a(vb,"map()"),vb.forEach(s),r1.forEach(s),Wp.forEach(s),nd=p(e),oe=r(e,"P",{});var es=l(oe);Lf=a(es,"La m\xE9thode "),qr=r(es,"CODE",{});var hb=l(qr);Sf=a(hb,"Dataset.map()"),hb.forEach(s),Hf=a(es," prend un argument "),jr=r(es,"CODE",{});var _b=l(jr);Mf=a(_b,"batched"),_b.forEach(s),Rf=a(es," qui, s\u2019il est d\xE9fini sur "),wr=r(es,"CODE",{});var gb=l(wr);Ff=a(gb,"True"),gb.forEach(s),Uf=a(es,", l\u2019am\xE8ne \xE0 envoyer un lot d\u2019exemples \xE0 la fonction map en une seule fois (la taille du lot est configurable mais par d\xE9faut \xE0 1 000). Par exemple, la fonction de carte pr\xE9c\xE9dente qui d\xE9gageait tout le code HTML prenait un peu de temps \xE0 s\u2019ex\xE9cuter (vous pouvez lire le temps pris dans les barres de progression). On peut acc\xE9l\xE9rer cela en traitant plusieurs \xE9l\xE9ments en m\xEAme temps \xE0 l\u2019aide d\u2019une liste en compr\xE9hension."),es.forEach(s),ad=p(e),Q=r(e,"P",{});var Se=l(Q);Vf=a(Se,"Lorsque vous sp\xE9cifiez "),Dr=r(Se,"CODE",{});var $b=l(Dr);Bf=a($b,"batched=True"),$b.forEach(s),Gf=a(Se,", la fonction re\xE7oit un dictionnaire avec les champs de l\u2019ensemble de donn\xE9es, mais chaque valeur est maintenant une "),kr=r(Se,"EM",{});var bb=l(kr);Jf=a(bb,"liste de valeurs"),bb.forEach(s),Yf=a(Se,", et non plus une seule valeur. La valeur de retour de "),yr=r(Se,"CODE",{});var Eb=l(yr);Wf=a(Eb,"Dataset.map()"),Eb.forEach(s),Xf=a(Se," devrait \xEAtre la m\xEAme\xA0: un dictionnaire avec les champs que nous voulons mettre \xE0 jour ou ajouter \xE0 notre ensemble de donn\xE9es, et une liste de valeurs. Par exemple, voici une autre fa\xE7on de supprimer tous les caract\xE8res HTML, mais en utilisant "),Cr=r(Se,"CODE",{});var xb=l(Cr);Kf=a(xb,"batched=True"),xb.forEach(s),Qf=a(Se,"\xA0:"),Se.forEach(s),od=p(e),v(Bs.$$.fragment,e),rd=p(e),kt=r(e,"P",{});var Xp=l(kt);Zf=a(Xp,"Si vous ex\xE9cutez ce code dans un notebook, vous verrez que cette commande s\u2019ex\xE9cute beaucoup plus rapidement que la pr\xE9c\xE9dente. Et ce n\u2019est pas parce que nos critiques ont d\xE9j\xE0 \xE9t\xE9 sans \xE9chappement HTML \u2014 si vous r\xE9-ex\xE9cutez l\u2019instruction de la section pr\xE9c\xE9dente (sans "),Tr=r(Xp,"CODE",{});var qb=l(Tr);ev=a(qb,"batched=True"),qb.forEach(s),tv=a(Xp,"), cela prendra le m\xEAme temps qu\u2019avant. En effet, les compr\xE9hensions de liste sont g\xE9n\xE9ralement plus rapides que l\u2019ex\xE9cution du m\xEAme code dans une boucle \u201Cfor\u201D, et nous gagnons \xE9galement en performances en acc\xE9dant \xE0 de nombreux \xE9l\xE9ments en m\xEAme temps au lieu d\u2019un par un."),Xp.forEach(s),ld=p(e),re=r(e,"P",{});var ts=l(re);sv=a(ts,"L\u2019utilisation de "),zr=r(ts,"CODE",{});var jb=l(zr);nv=a(jb,"Dataset.map()"),jb.forEach(s),av=a(ts," avec "),Pr=r(ts,"CODE",{});var wb=l(Pr);ov=a(wb,"batched=True"),wb.forEach(s),rv=a(ts," sera essentielle pour d\xE9bloquer la vitesse des tokenizers \u201Crapides\u201D que nous rencontrerons dans "),aa=r(ts,"A",{href:!0});var Db=l(aa);lv=a(Db,"Chapitre 6"),Db.forEach(s),iv=a(ts,", qui peuvent rapidement tokeniser de grandes listes de textes. Par exemple, pour tokeniser toutes les revues de m\xE9dicaments avec un tokenizer rapide, nous pourrions utiliser une fonction comme celle-ci\xA0:"),ts.forEach(s),id=p(e),v(Gs.$$.fragment,e),ud=p(e),le=r(e,"P",{});var ss=l(le);uv=a(ss,"Comme vous l\u2019avez vu dans le "),oa=r(ss,"A",{href:!0});var kb=l(oa);dv=a(kb,"Chapitre 3"),kb.forEach(s),pv=a(ss,", nous pouvons passer un ou plusieurs exemples au tokenizer, nous pouvons donc utiliser cette fonction avec ou sans "),Or=r(ss,"CODE",{});var yb=l(Or);cv=a(yb,"batched=True"),yb.forEach(s),mv=a(ss,". Profitons-en pour comparer les performances des diff\xE9rentes options. Dans un cahier, vous pouvez chronom\xE9trer une instruction d\u2019une ligne en ajoutant "),Nr=r(ss,"CODE",{});var Cb=l(Nr);fv=a(Cb,"%time"),Cb.forEach(s),vv=a(ss," avant la ligne de code que vous souhaitez mesurer\xA0:"),ss.forEach(s),dd=p(e),v(Js.$$.fragment,e),pd=p(e),yt=r(e,"P",{});var Kp=l(yt);hv=a(Kp,"Vous pouvez \xE9galement chronom\xE9trer une cellule enti\xE8re en mettant "),Ar=r(Kp,"CODE",{});var Tb=l(Ar);_v=a(Tb,"%%time"),Tb.forEach(s),gv=a(Kp," au d\xE9but de la cellule. Sur le mat\xE9riel sur lequel nous avons ex\xE9cut\xE9 cela, il affichait 10,8 s pour cette instruction (c\u2019est le nombre \xE9crit apr\xE8s \u201CWall time\u201D)."),Kp.forEach(s),cd=p(e),v(Ct.$$.fragment,e),md=p(e),ra=r(e,"P",{});var zb=l(ra);$v=a(zb,"Voici les r\xE9sultats que nous avons obtenus avec et sans batching, avec un tokenizer rapide et un lent :"),zb.forEach(s),fd=p(e),Tt=r(e,"TABLE",{});var Qp=l(Tt);Ir=r(Qp,"THEAD",{});var Pb=l(Ir);Je=r(Pb,"TR",{});var io=l(Je);la=r(io,"TH",{align:!0});var Ob=l(la);bv=a(Ob,"Options"),Ob.forEach(s),Ev=p(io),ia=r(io,"TH",{align:!0});var Nb=l(ia);xv=a(Nb,"Tokenizer rapide"),Nb.forEach(s),qv=p(io),ua=r(io,"TH",{align:!0});var Ab=l(ua);jv=a(Ab,"Tokenizer lent"),Ab.forEach(s),io.forEach(s),Pb.forEach(s),wv=p(Qp),Ys=r(Qp,"TBODY",{});var Zp=l(Ys);Ye=r(Zp,"TR",{});var uo=l(Ye);da=r(uo,"TD",{align:!0});var Ib=l(da);Lr=r(Ib,"CODE",{});var Lb=l(Lr);Dv=a(Lb,"batched=True"),Lb.forEach(s),Ib.forEach(s),kv=p(uo),pa=r(uo,"TD",{align:!0});var Sb=l(pa);yv=a(Sb,"10.8s"),Sb.forEach(s),Cv=p(uo),ca=r(uo,"TD",{align:!0});var Hb=l(ca);Tv=a(Hb,"4min41s"),Hb.forEach(s),uo.forEach(s),zv=p(Zp),We=r(Zp,"TR",{});var po=l(We);ma=r(po,"TD",{align:!0});var Mb=l(ma);Sr=r(Mb,"CODE",{});var Rb=l(Sr);Pv=a(Rb,"batched=False"),Rb.forEach(s),Mb.forEach(s),Ov=p(po),fa=r(po,"TD",{align:!0});var Fb=l(fa);Nv=a(Fb,"59.2s"),Fb.forEach(s),Av=p(po),va=r(po,"TD",{align:!0});var Ub=l(va);Iv=a(Ub,"5min3s"),Ub.forEach(s),po.forEach(s),Zp.forEach(s),Qp.forEach(s),vd=p(e),je=r(e,"P",{});var co=l(je);Lv=a(co,"Cela signifie que l\u2019utilisation d\u2019un tokenizer rapide avec l\u2019option "),Hr=r(co,"CODE",{});var Vb=l(Hr);Sv=a(Vb,"batched=True"),Vb.forEach(s),Hv=a(co," est 30 fois plus rapide que son homologue lent sans traitement par lot \u2014 c\u2019est vraiment incroyable\xA0! C\u2019est la raison principale pour laquelle les tokenizers rapides sont la valeur par d\xE9faut lors de l\u2019utilisation de "),Mr=r(co,"CODE",{});var Bb=l(Mr);Mv=a(Bb,"AutoTokenizer"),Bb.forEach(s),Rv=a(co," (et pourquoi ils sont appel\xE9s \u201Crapides\u201D). Ils sont capables d\u2019atteindre une telle acc\xE9l\xE9ration car dans les coulisses, le code de tokenisation est ex\xE9cut\xE9 dans Rust, qui est un langage qui facilite la parall\xE9lisation de l\u2019ex\xE9cution du code."),co.forEach(s),hd=p(e),ha=r(e,"P",{});var Gb=l(ha);Fv=a(Gb,"La parall\xE9lisation est \xE9galement la raison de l\u2019acc\xE9l\xE9ration de pr\xE8s de 6 fois obtenue par le fast tokenizer avec le traitement par lots\xA0: vous ne pouvez pas parall\xE9liser une seule op\xE9ration de tokenisation, mais lorsque vous souhaitez tokeniser de nombreux textes en m\xEAme temps, vous pouvez simplement r\xE9partir l\u2019ex\xE9cution sur plusieurs processus. chacun responsable de ses propres textes."),Gb.forEach(s),_d=p(e),fe=r(e,"P",{});var Hn=l(fe);Rr=r(Hn,"CODE",{});var Jb=l(Rr);Uv=a(Jb,"Dataset.map()"),Jb.forEach(s),Vv=a(Hn," poss\xE8de \xE9galement ses propres capacit\xE9s de parall\xE9lisation. Comme ils ne sont pas soutenus par Rust, ils ne laisseront pas un tokenizer lent rattraper un rapide, mais ils peuvent toujours \xEAtre utiles (surtout si vous utilisez un tokenizer qui n\u2019a pas de version rapide). Pour activer le multitraitement, utilisez l\u2019argument "),Fr=r(Hn,"CODE",{});var Yb=l(Fr);Bv=a(Yb,"num_proc"),Yb.forEach(s),Gv=a(Hn," et sp\xE9cifiez le nombre de processus \xE0 utiliser dans votre appel \xE0 "),Ur=r(Hn,"CODE",{});var Wb=l(Ur);Jv=a(Wb,"Dataset.map()"),Wb.forEach(s),Yv=a(Hn,"\xA0:"),Hn.forEach(s),gd=p(e),v(Ws.$$.fragment,e),$d=p(e),_a=r(e,"P",{});var Xb=l(_a);Wv=a(Xb,"Vous pouvez exp\xE9rimenter un peu le timing pour d\xE9terminer le nombre optimal de processus \xE0 utiliser ; dans notre cas 8 semblait produire le meilleur gain de vitesse. Voici les chiffres que nous avons obtenus avec et sans multitraitement\xA0:"),Xb.forEach(s),bd=p(e),zt=r(e,"TABLE",{});var ec=l(zt);Vr=r(ec,"THEAD",{});var Kb=l(Vr);Xe=r(Kb,"TR",{});var mo=l(Xe);ga=r(mo,"TH",{align:!0});var Qb=l(ga);Xv=a(Qb,"Options"),Qb.forEach(s),Kv=p(mo),$a=r(mo,"TH",{align:!0});var Zb=l($a);Qv=a(Zb,"Tokenizer rapide"),Zb.forEach(s),Zv=p(mo),ba=r(mo,"TH",{align:!0});var e7=l(ba);eh=a(e7,"Tokenizer lent"),e7.forEach(s),mo.forEach(s),Kb.forEach(s),th=p(ec),ve=r(ec,"TBODY",{});var ns=l(ve);Ke=r(ns,"TR",{});var fo=l(Ke);Ea=r(fo,"TD",{align:!0});var t7=l(Ea);Br=r(t7,"CODE",{});var s7=l(Br);sh=a(s7,"batched=True"),s7.forEach(s),t7.forEach(s),nh=p(fo),xa=r(fo,"TD",{align:!0});var n7=l(xa);ah=a(n7,"10.8s"),n7.forEach(s),oh=p(fo),qa=r(fo,"TD",{align:!0});var a7=l(qa);rh=a(a7,"4min41s"),a7.forEach(s),fo.forEach(s),lh=p(ns),Qe=r(ns,"TR",{});var vo=l(Qe);ja=r(vo,"TD",{align:!0});var o7=l(ja);Gr=r(o7,"CODE",{});var r7=l(Gr);ih=a(r7,"batched=False"),r7.forEach(s),o7.forEach(s),uh=p(vo),wa=r(vo,"TD",{align:!0});var l7=l(wa);dh=a(l7,"59.2s"),l7.forEach(s),ph=p(vo),Da=r(vo,"TD",{align:!0});var i7=l(Da);ch=a(i7,"5min3s"),i7.forEach(s),vo.forEach(s),mh=p(ns),Ze=r(ns,"TR",{});var ho=l(Ze);Pt=r(ho,"TD",{align:!0});var tc=l(Pt);Jr=r(tc,"CODE",{});var u7=l(Jr);fh=a(u7,"batched=True"),u7.forEach(s),vh=a(tc,", "),Yr=r(tc,"CODE",{});var d7=l(Yr);hh=a(d7,"num_proc=8"),d7.forEach(s),tc.forEach(s),_h=p(ho),ka=r(ho,"TD",{align:!0});var p7=l(ka);gh=a(p7,"6.52s"),p7.forEach(s),$h=p(ho),ya=r(ho,"TD",{align:!0});var c7=l(ya);bh=a(c7,"41.3s"),c7.forEach(s),ho.forEach(s),Eh=p(ns),et=r(ns,"TR",{});var _o=l(et);Ot=r(_o,"TD",{align:!0});var sc=l(Ot);Wr=r(sc,"CODE",{});var m7=l(Wr);xh=a(m7,"batched=False"),m7.forEach(s),qh=a(sc,", "),Xr=r(sc,"CODE",{});var f7=l(Xr);jh=a(f7,"num_proc=8"),f7.forEach(s),sc.forEach(s),wh=p(_o),Ca=r(_o,"TD",{align:!0});var v7=l(Ca);Dh=a(v7,"9.49s"),v7.forEach(s),kh=p(_o),Ta=r(_o,"TD",{align:!0});var h7=l(Ta);yh=a(h7,"45.2s"),h7.forEach(s),_o.forEach(s),ns.forEach(s),ec.forEach(s),Ed=p(e),ie=r(e,"P",{});var as=l(ie);Ch=a(as,"Ce sont des r\xE9sultats beaucoup plus raisonnables pour le tokenizer lent, mais les performances du tokenizer rapide ont \xE9galement \xE9t\xE9 consid\xE9rablement am\xE9lior\xE9es. Notez, cependant, que ce ne sera pas toujours le cas - pour les valeurs de "),Kr=r(as,"CODE",{});var _7=l(Kr);Th=a(_7,"num_proc"),_7.forEach(s),zh=a(as," autres que 8, nos tests ont montr\xE9 qu\u2019il \xE9tait plus rapide d\u2019utiliser "),Qr=r(as,"CODE",{});var g7=l(Qr);Ph=a(g7,"batched=True"),g7.forEach(s),Oh=a(as," sans cette option. En g\xE9n\xE9ral, nous ne recommandons pas d\u2019utiliser le multitraitement Python pour les tokenizers rapides avec "),Zr=r(as,"CODE",{});var $7=l(Zr);Nh=a($7,"batched=True"),$7.forEach(s),Ah=a(as,"."),as.forEach(s),xd=p(e),v(Nt.$$.fragment,e),qd=p(e),we=r(e,"P",{});var go=l(we);Ih=a(go,"Toutes ces fonctionnalit\xE9s condens\xE9es en une seule m\xE9thode sont d\xE9j\xE0 assez \xE9tonnantes, mais il y a plus ! Avec "),el=r(go,"CODE",{});var b7=l(el);Lh=a(b7,"Dataset.map()"),b7.forEach(s),Sh=a(go," et "),tl=r(go,"CODE",{});var E7=l(tl);Hh=a(E7,"batched=True"),E7.forEach(s),Mh=a(go," vous pouvez modifier le nombre d\u2019\xE9l\xE9ments dans votre jeu de donn\xE9es. Ceci est tr\xE8s utile dans de nombreuses situations o\xF9 vous souhaitez cr\xE9er plusieurs fonctionnalit\xE9s d\u2019entra\xEEnement \xE0 partir d\u2019un exemple, et nous devrons le faire dans le cadre du pr\xE9traitement de plusieurs des t\xE2ches NLP que nous entreprendrons dans [Chapitre 7](/course/ Chapitre 7)."),go.forEach(s),jd=p(e),v(At.$$.fragment,e),wd=p(e),De=r(e,"P",{});var $o=l(De);Rh=a($o,"Voyons comment cela fonctionne\xA0! Ici, nous allons tokeniser nos exemples et les tronquer \xE0 une longueur maximale de 128, mais nous demanderons au tokenizer de renvoyer "),sl=r($o,"EM",{});var x7=l(sl);Fh=a(x7,"tous"),x7.forEach(s),Uh=a($o," les morceaux des textes au lieu du premier. Cela peut \xEAtre fait avec "),nl=r($o,"CODE",{});var q7=l(nl);Vh=a(q7,"return_overflowing_tokens=True"),q7.forEach(s),Bh=a($o,"\xA0:"),$o.forEach(s),Dd=p(e),v(Xs.$$.fragment,e),kd=p(e),It=r(e,"P",{});var nc=l(It);Gh=a(nc,"Testons cela sur un exemple avant d\u2019utiliser "),al=r(nc,"CODE",{});var j7=l(al);Jh=a(j7,"Dataset.map()"),j7.forEach(s),Yh=a(nc," sur l\u2019ensemble de donn\xE9es\xA0:"),nc.forEach(s),yd=p(e),v(Ks.$$.fragment,e),Cd=p(e),v(Qs.$$.fragment,e),Td=p(e),za=r(e,"P",{});var w7=l(za);Wh=a(w7,"Ainsi, notre premier exemple dans l\u2019ensemble de formation est devenu deux fonctionnalit\xE9s car il a \xE9t\xE9 segment\xE9 \xE0 plus que le nombre maximum de jetons que nous avons sp\xE9cifi\xE9\xA0: le premier de longueur 128 et le second de longueur 49. Faisons maintenant cela pour tous les \xE9l\xE9ments du base de donn\xE9es!"),w7.forEach(s),zd=p(e),v(Zs.$$.fragment,e),Pd=p(e),v(en.$$.fragment,e),Od=p(e),ke=r(e,"P",{});var bo=l(ke);Xh=a(bo,"Oh non! Cela n\u2019a pas fonctionn\xE9 ! Pourquoi pas? L\u2019examen du message d\u2019erreur nous donnera un indice\xA0: il y a une incompatibilit\xE9 dans les longueurs de l\u2019une des colonnes, l\u2019une \xE9tant de longueur 1\xA0463 et l\u2019autre de longueur 1\xA0000. Si vous avez consult\xE9 la [documentation] "),ol=r(bo,"CODE",{});var D7=l(ol);Kh=a(D7,"Dataset.map()"),D7.forEach(s),Qh=a(bo,"("),tn=r(bo,"A",{href:!0,rel:!0});var k7=l(tn);Zh=a(k7,"https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),k7.forEach(s),e_=a(bo,"), vous vous souviendrez peut-\xEAtre qu\u2019il s\u2019agit du nombre d\u2019\xE9chantillons pass\xE9s \xE0 la fonction que nous mappons\xA0; ici, ces 1 000 exemples ont donn\xE9 1 463 nouvelles fonctionnalit\xE9s, entra\xEEnant une erreur de forme."),bo.forEach(s),Nd=p(e),Z=r(e,"P",{});var He=l(Z);t_=a(He,"Le probl\xE8me est que nous essayons de m\xE9langer deux ensembles de donn\xE9es diff\xE9rents de tailles diff\xE9rentes\xA0: les colonnes "),rl=r(He,"CODE",{});var y7=l(rl);s_=a(y7,"drug_dataset"),y7.forEach(s),n_=a(He," auront un certain nombre d\u2019exemples (les 1 000 dans notre erreur), mais le "),ll=r(He,"CODE",{});var C7=l(ll);a_=a(C7,"tokenized_dataset"),C7.forEach(s),o_=a(He," que nous construisons en aura plus (le 1 463 dans le message d\u2019erreur). Cela ne fonctionne pas pour un "),il=r(He,"CODE",{});var T7=l(il);r_=a(T7,"Dataset"),T7.forEach(s),l_=a(He,", nous devons donc soit supprimer les colonnes de l\u2019ancien jeu de donn\xE9es, soit leur donner la m\xEAme taille que dans le nouveau jeu de donn\xE9es. Nous pouvons faire le premier avec l\u2019argument "),ul=r(He,"CODE",{});var z7=l(ul);i_=a(z7,"remove_columns"),z7.forEach(s),u_=a(He,"\xA0:"),He.forEach(s),Ad=p(e),v(sn.$$.fragment,e),Id=p(e),Pa=r(e,"P",{});var P7=l(Pa);d_=a(P7,"Maintenant, cela fonctionne sans erreur. Nous pouvons v\xE9rifier que notre nouveau jeu de donn\xE9es contient beaucoup plus d\u2019\xE9l\xE9ments que le jeu de donn\xE9es d\u2019origine en comparant les longueurs\xA0:"),P7.forEach(s),Ld=p(e),v(nn.$$.fragment,e),Sd=p(e),v(an.$$.fragment,e),Hd=p(e),ye=r(e,"P",{});var Eo=l(ye);p_=a(Eo,"Nous avons mentionn\xE9 que nous pouvions \xE9galement r\xE9soudre le probl\xE8me de longueur non concordante en donnant aux anciennes colonnes la m\xEAme taille que les nouvelles. Pour ce faire, nous aurons besoin du champ "),dl=r(Eo,"CODE",{});var O7=l(dl);c_=a(O7,"overflow_to_sample_mapping"),O7.forEach(s),m_=a(Eo," que le tokenizer renvoie lorsque nous d\xE9finissons "),pl=r(Eo,"CODE",{});var N7=l(pl);f_=a(N7,"return_overflowing_tokens=True"),N7.forEach(s),v_=a(Eo,". Il nous donne une correspondance entre un nouvel index de fonctionnalit\xE9 et l\u2019index de l\u2019\xE9chantillon dont il est issu. Gr\xE2ce \xE0 cela, nous pouvons associer chaque cl\xE9 pr\xE9sente dans notre jeu de donn\xE9es d\u2019origine \xE0 une liste de valeurs de la bonne taille en r\xE9p\xE9tant les valeurs de chaque exemple autant de fois qu\u2019il g\xE9n\xE8re de nouvelles fonctionnalit\xE9s\xA0:"),Eo.forEach(s),Md=p(e),v(on.$$.fragment,e),Rd=p(e),Lt=r(e,"P",{});var ac=l(Lt);h_=a(ac,"Nous pouvons voir que cela fonctionne avec "),cl=r(ac,"CODE",{});var A7=l(cl);__=a(A7,"Dataset.map()"),A7.forEach(s),g_=a(ac," sans que nous ayons besoin de supprimer les anciennes colonnes\xA0:"),ac.forEach(s),Fd=p(e),v(rn.$$.fragment,e),Ud=p(e),v(ln.$$.fragment,e),Vd=p(e),Oa=r(e,"P",{});var I7=l(Oa);$_=a(I7,"Nous obtenons le m\xEAme nombre de fonctionnalit\xE9s d\u2019entra\xEEnement qu\u2019auparavant, mais ici nous avons conserv\xE9 tous les anciens champs. Si vous en avez besoin pour un post-traitement apr\xE8s l\u2019application de votre mod\xE8le, vous pouvez utiliser cette approche."),I7.forEach(s),Bd=p(e),St=r(e,"P",{});var oc=l(St);b_=a(oc,`Vous avez maintenant vu comment \u{1F917} Datasets peut \xEAtre utilis\xE9 pour pr\xE9traiter un ensemble de donn\xE9es de diff\xE9rentes mani\xE8res. Bien que les fonctions de traitement de \u{1F917} Datasets couvrent la plupart de vos besoins de formation de mod\xE8les,
il peut arriver que vous deviez passer \xE0 Pandas pour acc\xE9der \xE0 des fonctionnalit\xE9s plus puissantes, telles que `),ml=r(oc,"CODE",{});var L7=l(ml);E_=a(L7,"DataFrame.groupby()"),L7.forEach(s),x_=a(oc," ou des API de haut niveau pour la visualisation. Heureusement, \u{1F917} Datasets est con\xE7u pour \xEAtre interop\xE9rable avec des biblioth\xE8ques telles que Pandas, NumPy, PyTorch, TensorFlow et JAX. Voyons comment cela fonctionne."),oc.forEach(s),Gd=p(e),tt=r(e,"H2",{class:!0});var rc=l(tt);Ht=r(rc,"A",{id:!0,class:!0,href:!0});var S7=l(Ht);fl=r(S7,"SPAN",{});var H7=l(fl);v(un.$$.fragment,H7),H7.forEach(s),S7.forEach(s),q_=p(rc),st=r(rc,"SPAN",{});var xo=l(st);j_=a(xo,"De "),vl=r(xo,"CODE",{});var M7=l(vl);w_=a(M7,"Dataset"),M7.forEach(s),D_=a(xo,"s \xE0 "),hl=r(xo,"CODE",{});var R7=l(hl);k_=a(R7,"DataFrame"),R7.forEach(s),y_=a(xo,"s et vice versa"),xo.forEach(s),rc.forEach(s),Jd=p(e),v(dn.$$.fragment,e),Yd=p(e),ue=r(e,"P",{});var os=l(ue);C_=a(os,"Pour permettre la conversion entre diverses biblioth\xE8ques tierces, \u{1F917} Datasets fournit une fonction "),_l=r(os,"CODE",{});var F7=l(_l);T_=a(F7,"Dataset.set_format()"),F7.forEach(s),z_=a(os,". Cette fonction ne modifie que le "),gl=r(os,"EM",{});var U7=l(gl);P_=a(U7,"format de sortie"),U7.forEach(s),O_=a(os," de l\u2019ensemble de donn\xE9es, vous pouvez donc facilement passer \xE0 un autre format sans affecter le "),$l=r(os,"EM",{});var V7=l($l);N_=a(V7,"format de donn\xE9es"),V7.forEach(s),A_=a(os," sous-jacent, qui est Apache Arrow. Le formatage se fait sur place. Pour d\xE9montrer, convertissons notre jeu de donn\xE9es en Pandas\xA0:"),os.forEach(s),Wd=p(e),v(pn.$$.fragment,e),Xd=p(e),Mt=r(e,"P",{});var lc=l(Mt);I_=a(lc,"Maintenant, lorsque nous acc\xE9dons aux \xE9l\xE9ments du jeu de donn\xE9es, nous obtenons un "),bl=r(lc,"CODE",{});var B7=l(bl);L_=a(B7,"pandas.DataFrame"),B7.forEach(s),S_=a(lc," au lieu d\u2019un dictionnaire\xA0:"),lc.forEach(s),Kd=p(e),v(cn.$$.fragment,e),Qd=p(e),Ce=r(e,"TABLE",{border:!0,class:!0});var ic=l(Ce);El=r(ic,"THEAD",{});var G7=l(El);I=r(G7,"TR",{style:!0});var U=l(I);Zd=r(U,"TH",{}),l(Zd).forEach(s),H_=p(U),xl=r(U,"TH",{});var J7=l(xl);M_=a(J7,"patient_id"),J7.forEach(s),R_=p(U),ql=r(U,"TH",{});var Y7=l(ql);F_=a(Y7,"drugName"),Y7.forEach(s),U_=p(U),jl=r(U,"TH",{});var W7=l(jl);V_=a(W7,"condition"),W7.forEach(s),B_=p(U),wl=r(U,"TH",{});var X7=l(wl);G_=a(X7,"review"),X7.forEach(s),J_=p(U),Dl=r(U,"TH",{});var K7=l(Dl);Y_=a(K7,"rating"),K7.forEach(s),W_=p(U),kl=r(U,"TH",{});var Q7=l(kl);X_=a(Q7,"date"),Q7.forEach(s),K_=p(U),yl=r(U,"TH",{});var Z7=l(yl);Q_=a(Z7,"usefulCount"),Z7.forEach(s),Z_=p(U),Cl=r(U,"TH",{});var eE=l(Cl);e2=a(eE,"review_length"),eE.forEach(s),U.forEach(s),G7.forEach(s),t2=p(ic),nt=r(ic,"TBODY",{});var qo=l(nt);L=r(qo,"TR",{});var V=l(L);Tl=r(V,"TH",{});var tE=l(Tl);s2=a(tE,"0"),tE.forEach(s),n2=p(V),zl=r(V,"TD",{});var sE=l(zl);a2=a(sE,"95260"),sE.forEach(s),o2=p(V),Pl=r(V,"TD",{});var nE=l(Pl);r2=a(nE,"Guanfacine"),nE.forEach(s),l2=p(V),Ol=r(V,"TD",{});var aE=l(Ol);i2=a(aE,"adhd"),aE.forEach(s),u2=p(V),Nl=r(V,"TD",{});var oE=l(Nl);d2=a(oE,'"My son is halfway through his fourth week of Intuniv..."'),oE.forEach(s),p2=p(V),Al=r(V,"TD",{});var rE=l(Al);c2=a(rE,"8.0"),rE.forEach(s),m2=p(V),Il=r(V,"TD",{});var lE=l(Il);f2=a(lE,"April 27, 2010"),lE.forEach(s),v2=p(V),Ll=r(V,"TD",{});var iE=l(Ll);h2=a(iE,"192"),iE.forEach(s),_2=p(V),Sl=r(V,"TD",{});var uE=l(Sl);g2=a(uE,"141"),uE.forEach(s),V.forEach(s),$2=p(qo),S=r(qo,"TR",{});var B=l(S);Hl=r(B,"TH",{});var dE=l(Hl);b2=a(dE,"1"),dE.forEach(s),E2=p(B),Ml=r(B,"TD",{});var pE=l(Ml);x2=a(pE,"92703"),pE.forEach(s),q2=p(B),Rl=r(B,"TD",{});var cE=l(Rl);j2=a(cE,"Lybrel"),cE.forEach(s),w2=p(B),Fl=r(B,"TD",{});var mE=l(Fl);D2=a(mE,"birth control"),mE.forEach(s),k2=p(B),Ul=r(B,"TD",{});var fE=l(Ul);y2=a(fE,'"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."'),fE.forEach(s),C2=p(B),Vl=r(B,"TD",{});var vE=l(Vl);T2=a(vE,"5.0"),vE.forEach(s),z2=p(B),Bl=r(B,"TD",{});var hE=l(Bl);P2=a(hE,"December 14, 2009"),hE.forEach(s),O2=p(B),Gl=r(B,"TD",{});var _E=l(Gl);N2=a(_E,"17"),_E.forEach(s),A2=p(B),Jl=r(B,"TD",{});var gE=l(Jl);I2=a(gE,"134"),gE.forEach(s),B.forEach(s),L2=p(qo),H=r(qo,"TR",{});var G=l(H);Yl=r(G,"TH",{});var $E=l(Yl);S2=a($E,"2"),$E.forEach(s),H2=p(G),Wl=r(G,"TD",{});var bE=l(Wl);M2=a(bE,"138000"),bE.forEach(s),R2=p(G),Xl=r(G,"TD",{});var EE=l(Xl);F2=a(EE,"Ortho Evra"),EE.forEach(s),U2=p(G),Kl=r(G,"TD",{});var xE=l(Kl);V2=a(xE,"birth control"),xE.forEach(s),B2=p(G),Ql=r(G,"TD",{});var qE=l(Ql);G2=a(qE,'"This is my first time using any form of birth control..."'),qE.forEach(s),J2=p(G),Zl=r(G,"TD",{});var jE=l(Zl);Y2=a(jE,"8.0"),jE.forEach(s),W2=p(G),ei=r(G,"TD",{});var wE=l(ei);X2=a(wE,"November 3, 2015"),wE.forEach(s),K2=p(G),ti=r(G,"TD",{});var DE=l(ti);Q2=a(DE,"10"),DE.forEach(s),Z2=p(G),si=r(G,"TD",{});var kE=l(si);eg=a(kE,"89"),kE.forEach(s),G.forEach(s),qo.forEach(s),ic.forEach(s),ep=p(e),Te=r(e,"P",{});var jo=l(Te);tg=a(jo,"Cr\xE9ons un "),ni=r(jo,"CODE",{});var yE=l(ni);sg=a(yE,"pandas.DataFrame"),yE.forEach(s),ng=a(jo," pour l\u2019ensemble d\u2019entra\xEEnement en s\xE9lectionnant tous les \xE9l\xE9ments de "),ai=r(jo,"CODE",{});var CE=l(ai);ag=a(CE,'drug_dataset["train"]'),CE.forEach(s),og=a(jo,"\xA0:"),jo.forEach(s),tp=p(e),v(mn.$$.fragment,e),sp=p(e),v(Rt.$$.fragment,e),np=p(e),Ft=r(e,"P",{});var uc=l(Ft);rg=a(uc,"De l\xE0, nous pouvons utiliser toutes les fonctionnalit\xE9s Pandas que nous voulons. Par exemple, nous pouvons faire un cha\xEEnage sophistiqu\xE9 pour calculer la distribution de classe parmi les entr\xE9es "),oi=r(uc,"CODE",{});var TE=l(oi);lg=a(TE,"condition"),TE.forEach(s),ig=a(uc,"\xA0:"),uc.forEach(s),ap=p(e),v(fn.$$.fragment,e),op=p(e),ze=r(e,"TABLE",{border:!0,class:!0});var dc=l(ze);ri=r(dc,"THEAD",{});var zE=l(ri);Pe=r(zE,"TR",{style:!0});var wo=l(Pe);rp=r(wo,"TH",{}),l(rp).forEach(s),ug=p(wo),li=r(wo,"TH",{});var PE=l(li);dg=a(PE,"condition"),PE.forEach(s),pg=p(wo),ii=r(wo,"TH",{});var OE=l(ii);cg=a(OE,"frequency"),OE.forEach(s),wo.forEach(s),zE.forEach(s),mg=p(dc),te=r(dc,"TBODY",{});var Me=l(te);at=r(Me,"TR",{});var Do=l(at);ui=r(Do,"TH",{});var NE=l(ui);fg=a(NE,"0"),NE.forEach(s),vg=p(Do),di=r(Do,"TD",{});var AE=l(di);hg=a(AE,"birth control"),AE.forEach(s),_g=p(Do),pi=r(Do,"TD",{});var IE=l(pi);gg=a(IE,"27655"),IE.forEach(s),Do.forEach(s),$g=p(Me),ot=r(Me,"TR",{});var ko=l(ot);ci=r(ko,"TH",{});var LE=l(ci);bg=a(LE,"1"),LE.forEach(s),Eg=p(ko),mi=r(ko,"TD",{});var SE=l(mi);xg=a(SE,"depression"),SE.forEach(s),qg=p(ko),fi=r(ko,"TD",{});var HE=l(fi);jg=a(HE,"8023"),HE.forEach(s),ko.forEach(s),wg=p(Me),rt=r(Me,"TR",{});var yo=l(rt);vi=r(yo,"TH",{});var ME=l(vi);Dg=a(ME,"2"),ME.forEach(s),kg=p(yo),hi=r(yo,"TD",{});var RE=l(hi);yg=a(RE,"acne"),RE.forEach(s),Cg=p(yo),_i=r(yo,"TD",{});var FE=l(_i);Tg=a(FE,"5209"),FE.forEach(s),yo.forEach(s),zg=p(Me),lt=r(Me,"TR",{});var Co=l(lt);gi=r(Co,"TH",{});var UE=l(gi);Pg=a(UE,"3"),UE.forEach(s),Og=p(Co),$i=r(Co,"TD",{});var VE=l($i);Ng=a(VE,"anxiety"),VE.forEach(s),Ag=p(Co),bi=r(Co,"TD",{});var BE=l(bi);Ig=a(BE,"4991"),BE.forEach(s),Co.forEach(s),Lg=p(Me),it=r(Me,"TR",{});var To=l(it);Ei=r(To,"TH",{});var GE=l(Ei);Sg=a(GE,"4"),GE.forEach(s),Hg=p(To),xi=r(To,"TD",{});var JE=l(xi);Mg=a(JE,"pain"),JE.forEach(s),Rg=p(To),qi=r(To,"TD",{});var YE=l(qi);Fg=a(YE,"4744"),YE.forEach(s),To.forEach(s),Me.forEach(s),dc.forEach(s),lp=p(e),Oe=r(e,"P",{});var zo=l(Oe);Ug=a(zo,"Et une fois que nous avons termin\xE9 notre analyse Pandas, nous pouvons toujours cr\xE9er un nouvel objet "),ji=r(zo,"CODE",{});var WE=l(ji);Vg=a(WE,"Dataset"),WE.forEach(s),Bg=a(zo," en utilisant la fonction "),wi=r(zo,"CODE",{});var XE=l(wi);Gg=a(XE,"Dataset.from_pandas()"),XE.forEach(s),Jg=a(zo," comme suit\xA0:"),zo.forEach(s),ip=p(e),v(vn.$$.fragment,e),up=p(e),v(hn.$$.fragment,e),dp=p(e),v(Ut.$$.fragment,e),pp=p(e),de=r(e,"P",{});var rs=l(de);Yg=a(rs,"Ceci conclut notre visite des diff\xE9rentes techniques de pr\xE9traitement disponibles dans \u{1F917} Datasets. Pour compl\xE9ter la section, cr\xE9ons un ensemble de validation pour pr\xE9parer l\u2019ensemble de donn\xE9es pour la formation d\u2019un classificateur. Avant cela, nous allons r\xE9initialiser le format de sortie de "),Di=r(rs,"CODE",{});var KE=l(Di);Wg=a(KE,"drug_dataset"),KE.forEach(s),Xg=a(rs," de "),ki=r(rs,"CODE",{});var QE=l(ki);Kg=a(QE,'"pandas"'),QE.forEach(s),Qg=a(rs," \xE0 "),yi=r(rs,"CODE",{});var ZE=l(yi);Zg=a(ZE,'"arrow"'),ZE.forEach(s),e$=a(rs,"\xA0:"),rs.forEach(s),cp=p(e),v(_n.$$.fragment,e),mp=p(e),ut=r(e,"H2",{class:!0});var pc=l(ut);Vt=r(pc,"A",{id:!0,class:!0,href:!0});var ex=l(Vt);Ci=r(ex,"SPAN",{});var tx=l(Ci);v(gn.$$.fragment,tx),tx.forEach(s),ex.forEach(s),t$=p(pc),Ti=r(pc,"SPAN",{});var sx=l(Ti);s$=a(sx,"Cr\xE9ation d'un ensemble de validation"),sx.forEach(s),pc.forEach(s),fp=p(e),Na=r(e,"P",{});var nx=l(Na);n$=a(nx,"Bien que nous ayons un jeu de test que nous pourrions utiliser pour l\u2019\xE9valuation, il est recommand\xE9 de ne pas toucher au jeu de test et de cr\xE9er un jeu de validation s\xE9par\xE9 pendant le d\xE9veloppement. Une fois que vous \xEAtes satisfait des performances de vos mod\xE8les sur l\u2019ensemble de validation, vous pouvez effectuer une derni\xE8re v\xE9rification d\u2019int\xE9grit\xE9 sur l\u2019ensemble de test. Ce processus permet d\u2019att\xE9nuer le risque de d\xE9passement de l\u2019ensemble de test et de d\xE9ploiement d\u2019un mod\xE8le qui \xE9choue sur des donn\xE9es du monde r\xE9el."),nx.forEach(s),vp=p(e),Ne=r(e,"P",{});var Po=l(Ne);a$=a(Po,"\u{1F917} Datasets fournit une fonction "),zi=r(Po,"CODE",{});var ax=l(zi);o$=a(ax,"Dataset.train_test_split()"),ax.forEach(s),r$=a(Po," bas\xE9e sur la c\xE9l\xE8bre fonctionnalit\xE9 de "),Pi=r(Po,"CODE",{});var ox=l(Pi);l$=a(ox,"scikit-learn"),ox.forEach(s),i$=a(Po,". Utilisons-le pour diviser notre ensemble d\u2019entra\xEEnement en divisions \u201Ctrain\u201D et \u201Cvalidation\u201D (nous d\xE9finissons l\u2019argument \u201Cseed\u201D pour la reproductibilit\xE9)\xA0:"),Po.forEach(s),hp=p(e),v($n.$$.fragment,e),_p=p(e),v(bn.$$.fragment,e),gp=p(e),Bt=r(e,"P",{});var cc=l(Bt);u$=a(cc,"G\xE9nial, nous avons maintenant pr\xE9par\xE9 un jeu de donn\xE9es pr\xEAt pour l\u2019entra\xEEnement de certains mod\xE8les\xA0! Dans la "),Aa=r(cc,"A",{href:!0});var rx=l(Aa);d$=a(rx,"section 5"),rx.forEach(s),p$=a(cc,", nous vous montrerons comment t\xE9l\xE9charger des ensembles de donn\xE9es sur le Hugging Face Hub, mais pour l\u2019instant, terminons notre analyse en examinant quelques fa\xE7ons d\u2019enregistrer des ensembles de donn\xE9es sur votre ordinateur local."),cc.forEach(s),$p=p(e),dt=r(e,"H2",{class:!0});var mc=l(dt);Gt=r(mc,"A",{id:!0,class:!0,href:!0});var lx=l(Gt);Oi=r(lx,"SPAN",{});var ix=l(Oi);v(En.$$.fragment,ix),ix.forEach(s),lx.forEach(s),c$=p(mc),Ni=r(mc,"SPAN",{});var ux=l(Ni);m$=a(ux,"Enregistrer un jeu de donn\xE9es"),ux.forEach(s),mc.forEach(s),bp=p(e),v(xn.$$.fragment,e),Ep=p(e),Ia=r(e,"P",{});var dx=l(Ia);f$=a(dx,"Bien que \u{1F917} Datasets mette en cache chaque jeu de donn\xE9es t\xE9l\xE9charg\xE9 et les op\xE9rations qui y sont effectu\xE9es, il y a des moments o\xF9 vous voudrez enregistrer un jeu de donn\xE9es sur le disque (par exemple, au cas o\xF9 le cache serait supprim\xE9). Comme indiqu\xE9 dans le tableau ci-dessous, \u{1F917} Datasets fournit trois fonctions principales pour enregistrer votre jeu de donn\xE9es dans diff\xE9rents formats\xA0:"),dx.forEach(s),xp=p(e),Jt=r(e,"TABLE",{});var fc=l(Jt);Ai=r(fc,"THEAD",{});var px=l(Ai);qn=r(px,"TR",{});var vc=l(qn);La=r(vc,"TH",{align:!0});var cx=l(La);v$=a(cx,"Format de donn\xE9es"),cx.forEach(s),h$=p(vc),Sa=r(vc,"TH",{align:!0});var mx=l(Sa);_$=a(mx,"Fonction"),mx.forEach(s),vc.forEach(s),px.forEach(s),g$=p(fc),pt=r(fc,"TBODY",{});var Oo=l(pt);jn=r(Oo,"TR",{});var hc=l(jn);Ha=r(hc,"TD",{align:!0});var fx=l(Ha);$$=a(fx,"Fl\xE8che"),fx.forEach(s),b$=p(hc),Ma=r(hc,"TD",{align:!0});var vx=l(Ma);Ii=r(vx,"CODE",{});var hx=l(Ii);E$=a(hx,"Dataset.save_to_disk()"),hx.forEach(s),vx.forEach(s),hc.forEach(s),x$=p(Oo),wn=r(Oo,"TR",{});var _c=l(wn);Ra=r(_c,"TD",{align:!0});var _x=l(Ra);q$=a(_x,"CSV"),_x.forEach(s),j$=p(_c),Fa=r(_c,"TD",{align:!0});var gx=l(Fa);Li=r(gx,"CODE",{});var $x=l(Li);w$=a($x,"Dataset.to_csv()"),$x.forEach(s),gx.forEach(s),_c.forEach(s),D$=p(Oo),Dn=r(Oo,"TR",{});var gc=l(Dn);Ua=r(gc,"TD",{align:!0});var bx=l(Ua);k$=a(bx,"JSON"),bx.forEach(s),y$=p(gc),Va=r(gc,"TD",{align:!0});var Ex=l(Va);Si=r(Ex,"CODE",{});var xx=l(Si);C$=a(xx,"Dataset.to_json()"),xx.forEach(s),Ex.forEach(s),gc.forEach(s),Oo.forEach(s),fc.forEach(s),qp=p(e),Ba=r(e,"P",{});var qx=l(Ba);T$=a(qx,"Par exemple, enregistrons notre jeu de donn\xE9es nettoy\xE9 au format Arrow\xA0:"),qx.forEach(s),jp=p(e),v(kn.$$.fragment,e),wp=p(e),Ga=r(e,"P",{});var jx=l(Ga);z$=a(jx,"Cela cr\xE9era un r\xE9pertoire avec la structure suivante\xA0:"),jx.forEach(s),Dp=p(e),v(yn.$$.fragment,e),kp=p(e),pe=r(e,"P",{});var ls=l(pe);P$=a(ls,"o\xF9 nous pouvons voir que chaque division est associ\xE9e \xE0 sa propre table "),Hi=r(ls,"EM",{});var wx=l(Hi);O$=a(wx,"dataset.arrow"),wx.forEach(s),N$=a(ls," et \xE0 certaines m\xE9tadonn\xE9es dans "),Mi=r(ls,"EM",{});var Dx=l(Mi);A$=a(Dx,"dataset_info.json"),Dx.forEach(s),I$=a(ls," et "),Ri=r(ls,"EM",{});var kx=l(Ri);L$=a(kx,"state.json "),kx.forEach(s),S$=a(ls,". Vous pouvez consid\xE9rer le format Arrow comme un tableau sophistiqu\xE9 de colonnes et de lignes optimis\xE9 pour la cr\xE9ation d\u2019applications hautes performances qui traitent et transportent de grands ensembles de donn\xE9es."),ls.forEach(s),yp=p(e),Yt=r(e,"P",{});var $c=l(Yt);H$=a($c,"Une fois le jeu de donn\xE9es enregistr\xE9, nous pouvons le charger en utilisant la fonction "),Fi=r($c,"CODE",{});var yx=l(Fi);M$=a(yx,"load_from_disk()"),yx.forEach(s),R$=a($c," comme suit\xA0:"),$c.forEach(s),Cp=p(e),v(Cn.$$.fragment,e),Tp=p(e),v(Tn.$$.fragment,e),zp=p(e),Ja=r(e,"P",{});var Cx=l(Ja);F$=a(Cx,"Pour les formats CSV et JSON, nous devons stocker chaque fractionnement dans un fichier s\xE9par\xE9. Pour ce faire, vous pouvez parcourir les cl\xE9s et les valeurs de l\u2019objet \u201CDatasetDict\u201D\xA0:"),Cx.forEach(s),Pp=p(e),v(zn.$$.fragment,e),Op=p(e),Wt=r(e,"P",{});var bc=l(Wt);U$=a(bc,"Cela enregistre chaque fractionnement au [format de lignes JSON] ("),Pn=r(bc,"A",{href:!0,rel:!0});var Tx=l(Pn);V$=a(Tx,"https://jsonlines.org"),Tx.forEach(s),B$=a(bc,"), o\xF9 chaque ligne de l\u2019ensemble de donn\xE9es est stock\xE9e sous la forme d\u2019une seule ligne de JSON. Voici \xE0 quoi ressemble le premier exemple\xA0:"),bc.forEach(s),Np=p(e),v(On.$$.fragment,e),Ap=p(e),v(Nn.$$.fragment,e),Ip=p(e),Xt=r(e,"P",{});var Ec=l(Xt);G$=a(Ec,"Nous pouvons ensuite utiliser les techniques de "),Ya=r(Ec,"A",{href:!0});var zx=l(Ya);J$=a(zx,"section 2"),zx.forEach(s),Y$=a(Ec," pour charger les fichiers JSON comme suit\xA0:"),Ec.forEach(s),Lp=p(e),v(An.$$.fragment,e),Sp=p(e),Wa=r(e,"P",{});var Px=l(Wa);W$=a(Px,"Et c\u2019est tout pour notre excursion dans le data wrangling avec \u{1F917} Datasets\xA0! Maintenant que nous disposons d\u2019un ensemble de donn\xE9es nettoy\xE9 pour entra\xEEner un mod\xE8le, voici quelques id\xE9es que vous pouvez essayer\xA0:"),Px.forEach(s),Hp=p(e),Kt=r(e,"OL",{});var xc=l(Kt);In=r(xc,"LI",{});var qc=l(In);X$=a(qc,"Utilisez les techniques du "),Xa=r(qc,"A",{href:!0});var Ox=l(Xa);K$=a(Ox,"Chapitre 3"),Ox.forEach(s),Q$=a(qc," pour former un classificateur capable de pr\xE9dire l\u2019\xE9tat du patient en fonction de l\u2019examen du m\xE9dicament."),qc.forEach(s),Z$=p(xc),ct=r(xc,"LI",{});var No=l(ct);e1=a(No,"Utilisez le pipeline "),Ui=r(No,"CODE",{});var Nx=l(Ui);t1=a(Nx,"summarization"),Nx.forEach(s),s1=a(No," du "),Ka=r(No,"A",{href:!0});var Ax=l(Ka);n1=a(Ax,"Chapitre 1"),Ax.forEach(s),a1=a(No," pour g\xE9n\xE9rer des r\xE9sum\xE9s des r\xE9visions."),No.forEach(s),xc.forEach(s),Mp=p(e),Qa=r(e,"P",{});var Ix=l(Qa);o1=a(Ix,"Ensuite, nous verrons comment \u{1F917} Datasets peut vous permettre de travailler avec d\u2019\xE9normes ensembles de donn\xE9es sans faire exploser votre ordinateur portable\xA0!"),Ix.forEach(s),this.h()},h(){m(c,"name","hf:doc:metadata"),m(c,"content",JSON.stringify(Zx)),m(j,"id","il-est-temps-de-trancher-et-de-dcouper"),m(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(j,"href","#il-est-temps-de-trancher-et-de-dcouper"),m(E,"class","relative group"),m(W,"id","trancher-et-dcouper-nos-donnes"),m(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(W,"href","#trancher-et-dcouper-nos-donnes"),m(R,"class","relative group"),m(Jn,"href","/course/chapter3"),m(ds,"href","https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29"),m(ds,"rel","nofollow"),m(ps,"href","https://archive.ics.uci.edu/ml/index.php"),m(ps,"rel","nofollow"),m(Yn,"href","/course/chapter3"),m(qs,"href","https://docs.python.org/3/reference/lexical_analysis.html#keywords"),m(qs,"rel","nofollow"),m(Cs,"href","https://realpython.com/python-lambda/"),m(Cs,"rel","nofollow"),m(gt,"id","cration-de-nouvelles-colonnes"),m(gt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(gt,"href","#cration-de-nouvelles-colonnes"),m(Be,"class","relative group"),m(Dt,"id","les-superpouvoirs-de-la-mthode-map"),m(Dt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Dt,"href","#les-superpouvoirs-de-la-mthode-map"),m(Ge,"class","relative group"),m(aa,"href","/course/chapter6"),m(oa,"href","/course/chapter3"),m(la,"align","center"),m(ia,"align","center"),m(ua,"align","center"),m(da,"align","center"),m(pa,"align","center"),m(ca,"align","center"),m(ma,"align","center"),m(fa,"align","center"),m(va,"align","center"),m(ga,"align","center"),m($a,"align","center"),m(ba,"align","center"),m(Ea,"align","center"),m(xa,"align","center"),m(qa,"align","center"),m(ja,"align","center"),m(wa,"align","center"),m(Da,"align","center"),m(Pt,"align","center"),m(ka,"align","center"),m(ya,"align","center"),m(Ot,"align","center"),m(Ca,"align","center"),m(Ta,"align","center"),m(tn,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),m(tn,"rel","nofollow"),m(Ht,"id","de-datasets-dataframes-et-vice-versa"),m(Ht,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ht,"href","#de-datasets-dataframes-et-vice-versa"),m(tt,"class","relative group"),Lx(I,"text-align","right"),m(Ce,"border","1"),m(Ce,"class","dataframe"),Lx(Pe,"text-align","right"),m(ze,"border","1"),m(ze,"class","dataframe"),m(Vt,"id","cration-dun-ensemble-de-validation"),m(Vt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Vt,"href","#cration-dun-ensemble-de-validation"),m(ut,"class","relative group"),m(Aa,"href","/course/chapter5/5"),m(Gt,"id","enregistrer-un-jeu-de-donnes"),m(Gt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Gt,"href","#enregistrer-un-jeu-de-donnes"),m(dt,"class","relative group"),m(La,"align","center"),m(Sa,"align","center"),m(Ha,"align","center"),m(Ma,"align","center"),m(Ra,"align","center"),m(Fa,"align","center"),m(Ua,"align","center"),m(Va,"align","center"),m(Pn,"href","https://jsonlines.org"),m(Pn,"rel","nofollow"),m(Ya,"href","/course/chapter5/2"),m(Xa,"href","/course/chapter3"),m(Ka,"href","/course/chapter1")},m(e,i){t(document.head,c),u(e,D,i),u(e,E,i),t(E,j),t(j,w),h(x,w,null),t(E,q),t(E,C),t(C,y),u(e,P,i),h(O,e,i),u(e,T,i),u(e,k,i),t(k,J),u(e,A,i),h(z,e,i),u(e,me,i),u(e,R,i),t(R,W),t(W,se),h(ee,se,null),t(R,us),t(R,Re),t(Re,Fe),u(e,mt,i),u(e,F,i),t(F,Ue),t(F,N),t(N,Rn),t(F,Fn),t(F,ft),t(ft,Un),t(F,Vn),t(F,vt),t(vt,Bn),t(F,Gn),t(F,Jn),t(Jn,jc),t(F,wc),u(e,Xi,i),u(e,he,i),t(he,Dc),t(he,ds),t(ds,kc),t(he,yc),t(he,ps),t(ps,Cc),t(he,Tc),u(e,Ki,i),u(e,_e,i),t(_e,zc),t(_e,Ao),t(Ao,Pc),t(_e,Oc),t(_e,Io),t(Io,Nc),t(_e,Ac),u(e,Qi,i),h(cs,e,i),u(e,Zi,i),u(e,ne,i),t(ne,Ic),t(ne,Lo),t(Lo,Lc),t(ne,Sc),t(ne,So),t(So,Hc),t(ne,Mc),t(ne,Ho),t(Ho,Rc),t(ne,Fc),u(e,eu,i),h(ms,e,i),u(e,tu,i),u(e,ge,i),t(ge,Uc),t(ge,Mo),t(Mo,Vc),t(ge,Bc),t(ge,Ro),t(Ro,Gc),t(ge,Jc),u(e,su,i),h(fs,e,i),u(e,nu,i),h(vs,e,i),u(e,au,i),u(e,ae,i),t(ae,Yc),t(ae,Fo),t(Fo,Wc),t(ae,Xc),t(ae,Uo),t(Uo,Kc),t(ae,Qc),t(ae,Vo),t(Vo,Zc),t(ae,em),u(e,ou,i),u(e,$e,i),t($e,Bo),t(Bo,tm),t($e,sm),t($e,Go),t(Go,nm),t($e,am),t($e,Ve),t(Ve,om),t(Ve,Jo),t(Jo,rm),t(Ve,lm),t(Ve,Yo),t(Yo,im),t(Ve,um),u(e,ru,i),u(e,be,i),t(be,dm),t(be,Wo),t(Wo,pm),t(be,cm),t(be,Xo),t(Xo,mm),t(be,fm),u(e,lu,i),h(hs,e,i),u(e,iu,i),u(e,Ee,i),t(Ee,vm),t(Ee,Ko),t(Ko,hm),t(Ee,_m),t(Ee,Qo),t(Qo,gm),t(Ee,$m),u(e,uu,i),h(_s,e,i),u(e,du,i),h(gs,e,i),u(e,pu,i),h(ht,e,i),u(e,cu,i),u(e,X,i),t(X,bm),t(X,Zo),t(Zo,Em),t(X,xm),t(X,er),t(er,qm),t(X,jm),t(X,Yn),t(Yn,wm),t(X,Dm),t(X,tr),t(tr,km),t(X,ym),u(e,mu,i),h($s,e,i),u(e,fu,i),h(bs,e,i),u(e,vu,i),u(e,xe,i),t(xe,Cm),t(xe,sr),t(sr,Tm),t(xe,zm),t(xe,nr),t(nr,Pm),t(xe,Om),u(e,hu,i),h(Es,e,i),u(e,_u,i),u(e,qe,i),t(qe,Nm),t(qe,ar),t(ar,Am),t(qe,Im),t(qe,or),t(or,Lm),t(qe,Sm),u(e,gu,i),h(xs,e,i),u(e,$u,i),u(e,K,i),t(K,Hm),t(K,rr),t(rr,Mm),t(K,Rm),t(K,qs),t(qs,Fm),t(K,Um),t(K,lr),t(lr,Vm),t(K,Bm),t(K,ir),t(ir,Gm),t(K,Jm),u(e,bu,i),h(js,e,i),u(e,Eu,i),u(e,Wn,i),t(Wn,Ym),u(e,xu,i),h(ws,e,i),u(e,qu,i),h(Ds,e,i),u(e,ju,i),u(e,Xn,i),t(Xn,Wm),u(e,wu,i),h(ks,e,i),u(e,Du,i),h(ys,e,i),u(e,ku,i),u(e,_t,i),t(_t,Xm),t(_t,Cs),t(Cs,Km),t(_t,Qm),u(e,yu,i),h(Ts,e,i),u(e,Cu,i),u(e,Kn,i),t(Kn,Zm),u(e,Tu,i),h(zs,e,i),u(e,zu,i),h(Ps,e,i),u(e,Pu,i),u(e,Qn,i),t(Qn,ef),u(e,Ou,i),u(e,Be,i),t(Be,gt),t(gt,ur),h(Os,ur,null),t(Be,tf),t(Be,dr),t(dr,sf),u(e,Nu,i),u(e,Zn,i),t(Zn,nf),u(e,Au,i),u(e,ea,i),t(ea,af),u(e,Iu,i),h(Ns,e,i),u(e,Lu,i),u(e,Y,i),t(Y,of),t(Y,pr),t(pr,rf),t(Y,lf),t(Y,cr),t(cr,uf),t(Y,df),t(Y,mr),t(mr,pf),t(Y,cf),t(Y,fr),t(fr,mf),t(Y,ff),t(Y,vr),t(vr,vf),t(Y,hf),u(e,Su,i),h(As,e,i),u(e,Hu,i),h(Is,e,i),u(e,Mu,i),u(e,$t,i),t($t,_f),t($t,hr),t(hr,gf),t($t,$f),u(e,Ru,i),h(Ls,e,i),u(e,Fu,i),h(Ss,e,i),u(e,Uu,i),u(e,ta,i),t(ta,bf),u(e,Vu,i),h(bt,e,i),u(e,Bu,i),u(e,Et,i),t(Et,Ef),t(Et,_r),t(_r,xf),t(Et,qf),u(e,Gu,i),h(Hs,e,i),u(e,Ju,i),h(Ms,e,i),u(e,Yu,i),u(e,sa,i),t(sa,jf),u(e,Wu,i),h(xt,e,i),u(e,Xu,i),u(e,qt,i),t(qt,wf),t(qt,gr),t(gr,Df),t(qt,kf),u(e,Ku,i),h(Rs,e,i),u(e,Qu,i),h(Fs,e,i),u(e,Zu,i),u(e,jt,i),t(jt,yf),t(jt,$r),t($r,Cf),t(jt,Tf),u(e,ed,i),h(Us,e,i),u(e,td,i),u(e,wt,i),t(wt,zf),t(wt,br),t(br,Pf),t(wt,Of),u(e,sd,i),u(e,Ge,i),t(Ge,Dt),t(Dt,Er),h(Vs,Er,null),t(Ge,Nf),t(Ge,na),t(na,Af),t(na,xr),t(xr,If),u(e,nd,i),u(e,oe,i),t(oe,Lf),t(oe,qr),t(qr,Sf),t(oe,Hf),t(oe,jr),t(jr,Mf),t(oe,Rf),t(oe,wr),t(wr,Ff),t(oe,Uf),u(e,ad,i),u(e,Q,i),t(Q,Vf),t(Q,Dr),t(Dr,Bf),t(Q,Gf),t(Q,kr),t(kr,Jf),t(Q,Yf),t(Q,yr),t(yr,Wf),t(Q,Xf),t(Q,Cr),t(Cr,Kf),t(Q,Qf),u(e,od,i),h(Bs,e,i),u(e,rd,i),u(e,kt,i),t(kt,Zf),t(kt,Tr),t(Tr,ev),t(kt,tv),u(e,ld,i),u(e,re,i),t(re,sv),t(re,zr),t(zr,nv),t(re,av),t(re,Pr),t(Pr,ov),t(re,rv),t(re,aa),t(aa,lv),t(re,iv),u(e,id,i),h(Gs,e,i),u(e,ud,i),u(e,le,i),t(le,uv),t(le,oa),t(oa,dv),t(le,pv),t(le,Or),t(Or,cv),t(le,mv),t(le,Nr),t(Nr,fv),t(le,vv),u(e,dd,i),h(Js,e,i),u(e,pd,i),u(e,yt,i),t(yt,hv),t(yt,Ar),t(Ar,_v),t(yt,gv),u(e,cd,i),h(Ct,e,i),u(e,md,i),u(e,ra,i),t(ra,$v),u(e,fd,i),u(e,Tt,i),t(Tt,Ir),t(Ir,Je),t(Je,la),t(la,bv),t(Je,Ev),t(Je,ia),t(ia,xv),t(Je,qv),t(Je,ua),t(ua,jv),t(Tt,wv),t(Tt,Ys),t(Ys,Ye),t(Ye,da),t(da,Lr),t(Lr,Dv),t(Ye,kv),t(Ye,pa),t(pa,yv),t(Ye,Cv),t(Ye,ca),t(ca,Tv),t(Ys,zv),t(Ys,We),t(We,ma),t(ma,Sr),t(Sr,Pv),t(We,Ov),t(We,fa),t(fa,Nv),t(We,Av),t(We,va),t(va,Iv),u(e,vd,i),u(e,je,i),t(je,Lv),t(je,Hr),t(Hr,Sv),t(je,Hv),t(je,Mr),t(Mr,Mv),t(je,Rv),u(e,hd,i),u(e,ha,i),t(ha,Fv),u(e,_d,i),u(e,fe,i),t(fe,Rr),t(Rr,Uv),t(fe,Vv),t(fe,Fr),t(Fr,Bv),t(fe,Gv),t(fe,Ur),t(Ur,Jv),t(fe,Yv),u(e,gd,i),h(Ws,e,i),u(e,$d,i),u(e,_a,i),t(_a,Wv),u(e,bd,i),u(e,zt,i),t(zt,Vr),t(Vr,Xe),t(Xe,ga),t(ga,Xv),t(Xe,Kv),t(Xe,$a),t($a,Qv),t(Xe,Zv),t(Xe,ba),t(ba,eh),t(zt,th),t(zt,ve),t(ve,Ke),t(Ke,Ea),t(Ea,Br),t(Br,sh),t(Ke,nh),t(Ke,xa),t(xa,ah),t(Ke,oh),t(Ke,qa),t(qa,rh),t(ve,lh),t(ve,Qe),t(Qe,ja),t(ja,Gr),t(Gr,ih),t(Qe,uh),t(Qe,wa),t(wa,dh),t(Qe,ph),t(Qe,Da),t(Da,ch),t(ve,mh),t(ve,Ze),t(Ze,Pt),t(Pt,Jr),t(Jr,fh),t(Pt,vh),t(Pt,Yr),t(Yr,hh),t(Ze,_h),t(Ze,ka),t(ka,gh),t(Ze,$h),t(Ze,ya),t(ya,bh),t(ve,Eh),t(ve,et),t(et,Ot),t(Ot,Wr),t(Wr,xh),t(Ot,qh),t(Ot,Xr),t(Xr,jh),t(et,wh),t(et,Ca),t(Ca,Dh),t(et,kh),t(et,Ta),t(Ta,yh),u(e,Ed,i),u(e,ie,i),t(ie,Ch),t(ie,Kr),t(Kr,Th),t(ie,zh),t(ie,Qr),t(Qr,Ph),t(ie,Oh),t(ie,Zr),t(Zr,Nh),t(ie,Ah),u(e,xd,i),h(Nt,e,i),u(e,qd,i),u(e,we,i),t(we,Ih),t(we,el),t(el,Lh),t(we,Sh),t(we,tl),t(tl,Hh),t(we,Mh),u(e,jd,i),h(At,e,i),u(e,wd,i),u(e,De,i),t(De,Rh),t(De,sl),t(sl,Fh),t(De,Uh),t(De,nl),t(nl,Vh),t(De,Bh),u(e,Dd,i),h(Xs,e,i),u(e,kd,i),u(e,It,i),t(It,Gh),t(It,al),t(al,Jh),t(It,Yh),u(e,yd,i),h(Ks,e,i),u(e,Cd,i),h(Qs,e,i),u(e,Td,i),u(e,za,i),t(za,Wh),u(e,zd,i),h(Zs,e,i),u(e,Pd,i),h(en,e,i),u(e,Od,i),u(e,ke,i),t(ke,Xh),t(ke,ol),t(ol,Kh),t(ke,Qh),t(ke,tn),t(tn,Zh),t(ke,e_),u(e,Nd,i),u(e,Z,i),t(Z,t_),t(Z,rl),t(rl,s_),t(Z,n_),t(Z,ll),t(ll,a_),t(Z,o_),t(Z,il),t(il,r_),t(Z,l_),t(Z,ul),t(ul,i_),t(Z,u_),u(e,Ad,i),h(sn,e,i),u(e,Id,i),u(e,Pa,i),t(Pa,d_),u(e,Ld,i),h(nn,e,i),u(e,Sd,i),h(an,e,i),u(e,Hd,i),u(e,ye,i),t(ye,p_),t(ye,dl),t(dl,c_),t(ye,m_),t(ye,pl),t(pl,f_),t(ye,v_),u(e,Md,i),h(on,e,i),u(e,Rd,i),u(e,Lt,i),t(Lt,h_),t(Lt,cl),t(cl,__),t(Lt,g_),u(e,Fd,i),h(rn,e,i),u(e,Ud,i),h(ln,e,i),u(e,Vd,i),u(e,Oa,i),t(Oa,$_),u(e,Bd,i),u(e,St,i),t(St,b_),t(St,ml),t(ml,E_),t(St,x_),u(e,Gd,i),u(e,tt,i),t(tt,Ht),t(Ht,fl),h(un,fl,null),t(tt,q_),t(tt,st),t(st,j_),t(st,vl),t(vl,w_),t(st,D_),t(st,hl),t(hl,k_),t(st,y_),u(e,Jd,i),h(dn,e,i),u(e,Yd,i),u(e,ue,i),t(ue,C_),t(ue,_l),t(_l,T_),t(ue,z_),t(ue,gl),t(gl,P_),t(ue,O_),t(ue,$l),t($l,N_),t(ue,A_),u(e,Wd,i),h(pn,e,i),u(e,Xd,i),u(e,Mt,i),t(Mt,I_),t(Mt,bl),t(bl,L_),t(Mt,S_),u(e,Kd,i),h(cn,e,i),u(e,Qd,i),u(e,Ce,i),t(Ce,El),t(El,I),t(I,Zd),t(I,H_),t(I,xl),t(xl,M_),t(I,R_),t(I,ql),t(ql,F_),t(I,U_),t(I,jl),t(jl,V_),t(I,B_),t(I,wl),t(wl,G_),t(I,J_),t(I,Dl),t(Dl,Y_),t(I,W_),t(I,kl),t(kl,X_),t(I,K_),t(I,yl),t(yl,Q_),t(I,Z_),t(I,Cl),t(Cl,e2),t(Ce,t2),t(Ce,nt),t(nt,L),t(L,Tl),t(Tl,s2),t(L,n2),t(L,zl),t(zl,a2),t(L,o2),t(L,Pl),t(Pl,r2),t(L,l2),t(L,Ol),t(Ol,i2),t(L,u2),t(L,Nl),t(Nl,d2),t(L,p2),t(L,Al),t(Al,c2),t(L,m2),t(L,Il),t(Il,f2),t(L,v2),t(L,Ll),t(Ll,h2),t(L,_2),t(L,Sl),t(Sl,g2),t(nt,$2),t(nt,S),t(S,Hl),t(Hl,b2),t(S,E2),t(S,Ml),t(Ml,x2),t(S,q2),t(S,Rl),t(Rl,j2),t(S,w2),t(S,Fl),t(Fl,D2),t(S,k2),t(S,Ul),t(Ul,y2),t(S,C2),t(S,Vl),t(Vl,T2),t(S,z2),t(S,Bl),t(Bl,P2),t(S,O2),t(S,Gl),t(Gl,N2),t(S,A2),t(S,Jl),t(Jl,I2),t(nt,L2),t(nt,H),t(H,Yl),t(Yl,S2),t(H,H2),t(H,Wl),t(Wl,M2),t(H,R2),t(H,Xl),t(Xl,F2),t(H,U2),t(H,Kl),t(Kl,V2),t(H,B2),t(H,Ql),t(Ql,G2),t(H,J2),t(H,Zl),t(Zl,Y2),t(H,W2),t(H,ei),t(ei,X2),t(H,K2),t(H,ti),t(ti,Q2),t(H,Z2),t(H,si),t(si,eg),u(e,ep,i),u(e,Te,i),t(Te,tg),t(Te,ni),t(ni,sg),t(Te,ng),t(Te,ai),t(ai,ag),t(Te,og),u(e,tp,i),h(mn,e,i),u(e,sp,i),h(Rt,e,i),u(e,np,i),u(e,Ft,i),t(Ft,rg),t(Ft,oi),t(oi,lg),t(Ft,ig),u(e,ap,i),h(fn,e,i),u(e,op,i),u(e,ze,i),t(ze,ri),t(ri,Pe),t(Pe,rp),t(Pe,ug),t(Pe,li),t(li,dg),t(Pe,pg),t(Pe,ii),t(ii,cg),t(ze,mg),t(ze,te),t(te,at),t(at,ui),t(ui,fg),t(at,vg),t(at,di),t(di,hg),t(at,_g),t(at,pi),t(pi,gg),t(te,$g),t(te,ot),t(ot,ci),t(ci,bg),t(ot,Eg),t(ot,mi),t(mi,xg),t(ot,qg),t(ot,fi),t(fi,jg),t(te,wg),t(te,rt),t(rt,vi),t(vi,Dg),t(rt,kg),t(rt,hi),t(hi,yg),t(rt,Cg),t(rt,_i),t(_i,Tg),t(te,zg),t(te,lt),t(lt,gi),t(gi,Pg),t(lt,Og),t(lt,$i),t($i,Ng),t(lt,Ag),t(lt,bi),t(bi,Ig),t(te,Lg),t(te,it),t(it,Ei),t(Ei,Sg),t(it,Hg),t(it,xi),t(xi,Mg),t(it,Rg),t(it,qi),t(qi,Fg),u(e,lp,i),u(e,Oe,i),t(Oe,Ug),t(Oe,ji),t(ji,Vg),t(Oe,Bg),t(Oe,wi),t(wi,Gg),t(Oe,Jg),u(e,ip,i),h(vn,e,i),u(e,up,i),h(hn,e,i),u(e,dp,i),h(Ut,e,i),u(e,pp,i),u(e,de,i),t(de,Yg),t(de,Di),t(Di,Wg),t(de,Xg),t(de,ki),t(ki,Kg),t(de,Qg),t(de,yi),t(yi,Zg),t(de,e$),u(e,cp,i),h(_n,e,i),u(e,mp,i),u(e,ut,i),t(ut,Vt),t(Vt,Ci),h(gn,Ci,null),t(ut,t$),t(ut,Ti),t(Ti,s$),u(e,fp,i),u(e,Na,i),t(Na,n$),u(e,vp,i),u(e,Ne,i),t(Ne,a$),t(Ne,zi),t(zi,o$),t(Ne,r$),t(Ne,Pi),t(Pi,l$),t(Ne,i$),u(e,hp,i),h($n,e,i),u(e,_p,i),h(bn,e,i),u(e,gp,i),u(e,Bt,i),t(Bt,u$),t(Bt,Aa),t(Aa,d$),t(Bt,p$),u(e,$p,i),u(e,dt,i),t(dt,Gt),t(Gt,Oi),h(En,Oi,null),t(dt,c$),t(dt,Ni),t(Ni,m$),u(e,bp,i),h(xn,e,i),u(e,Ep,i),u(e,Ia,i),t(Ia,f$),u(e,xp,i),u(e,Jt,i),t(Jt,Ai),t(Ai,qn),t(qn,La),t(La,v$),t(qn,h$),t(qn,Sa),t(Sa,_$),t(Jt,g$),t(Jt,pt),t(pt,jn),t(jn,Ha),t(Ha,$$),t(jn,b$),t(jn,Ma),t(Ma,Ii),t(Ii,E$),t(pt,x$),t(pt,wn),t(wn,Ra),t(Ra,q$),t(wn,j$),t(wn,Fa),t(Fa,Li),t(Li,w$),t(pt,D$),t(pt,Dn),t(Dn,Ua),t(Ua,k$),t(Dn,y$),t(Dn,Va),t(Va,Si),t(Si,C$),u(e,qp,i),u(e,Ba,i),t(Ba,T$),u(e,jp,i),h(kn,e,i),u(e,wp,i),u(e,Ga,i),t(Ga,z$),u(e,Dp,i),h(yn,e,i),u(e,kp,i),u(e,pe,i),t(pe,P$),t(pe,Hi),t(Hi,O$),t(pe,N$),t(pe,Mi),t(Mi,A$),t(pe,I$),t(pe,Ri),t(Ri,L$),t(pe,S$),u(e,yp,i),u(e,Yt,i),t(Yt,H$),t(Yt,Fi),t(Fi,M$),t(Yt,R$),u(e,Cp,i),h(Cn,e,i),u(e,Tp,i),h(Tn,e,i),u(e,zp,i),u(e,Ja,i),t(Ja,F$),u(e,Pp,i),h(zn,e,i),u(e,Op,i),u(e,Wt,i),t(Wt,U$),t(Wt,Pn),t(Pn,V$),t(Wt,B$),u(e,Np,i),h(On,e,i),u(e,Ap,i),h(Nn,e,i),u(e,Ip,i),u(e,Xt,i),t(Xt,G$),t(Xt,Ya),t(Ya,J$),t(Xt,Y$),u(e,Lp,i),h(An,e,i),u(e,Sp,i),u(e,Wa,i),t(Wa,W$),u(e,Hp,i),u(e,Kt,i),t(Kt,In),t(In,X$),t(In,Xa),t(Xa,K$),t(In,Q$),t(Kt,Z$),t(Kt,ct),t(ct,e1),t(ct,Ui),t(Ui,t1),t(ct,s1),t(ct,Ka),t(Ka,n1),t(ct,a1),u(e,Mp,i),u(e,Qa,i),t(Qa,o1),Rp=!0},p(e,[i]){const Ln={};i&2&&(Ln.$$scope={dirty:i,ctx:e}),ht.$set(Ln);const Vi={};i&2&&(Vi.$$scope={dirty:i,ctx:e}),bt.$set(Vi);const Bi={};i&2&&(Bi.$$scope={dirty:i,ctx:e}),xt.$set(Bi);const Gi={};i&2&&(Gi.$$scope={dirty:i,ctx:e}),Ct.$set(Gi);const Ji={};i&2&&(Ji.$$scope={dirty:i,ctx:e}),Nt.$set(Ji);const Sn={};i&2&&(Sn.$$scope={dirty:i,ctx:e}),At.$set(Sn);const Yi={};i&2&&(Yi.$$scope={dirty:i,ctx:e}),Rt.$set(Yi);const Wi={};i&2&&(Wi.$$scope={dirty:i,ctx:e}),Ut.$set(Wi)},i(e){Rp||(_(x.$$.fragment,e),_(O.$$.fragment,e),_(z.$$.fragment,e),_(ee.$$.fragment,e),_(cs.$$.fragment,e),_(ms.$$.fragment,e),_(fs.$$.fragment,e),_(vs.$$.fragment,e),_(hs.$$.fragment,e),_(_s.$$.fragment,e),_(gs.$$.fragment,e),_(ht.$$.fragment,e),_($s.$$.fragment,e),_(bs.$$.fragment,e),_(Es.$$.fragment,e),_(xs.$$.fragment,e),_(js.$$.fragment,e),_(ws.$$.fragment,e),_(Ds.$$.fragment,e),_(ks.$$.fragment,e),_(ys.$$.fragment,e),_(Ts.$$.fragment,e),_(zs.$$.fragment,e),_(Ps.$$.fragment,e),_(Os.$$.fragment,e),_(Ns.$$.fragment,e),_(As.$$.fragment,e),_(Is.$$.fragment,e),_(Ls.$$.fragment,e),_(Ss.$$.fragment,e),_(bt.$$.fragment,e),_(Hs.$$.fragment,e),_(Ms.$$.fragment,e),_(xt.$$.fragment,e),_(Rs.$$.fragment,e),_(Fs.$$.fragment,e),_(Us.$$.fragment,e),_(Vs.$$.fragment,e),_(Bs.$$.fragment,e),_(Gs.$$.fragment,e),_(Js.$$.fragment,e),_(Ct.$$.fragment,e),_(Ws.$$.fragment,e),_(Nt.$$.fragment,e),_(At.$$.fragment,e),_(Xs.$$.fragment,e),_(Ks.$$.fragment,e),_(Qs.$$.fragment,e),_(Zs.$$.fragment,e),_(en.$$.fragment,e),_(sn.$$.fragment,e),_(nn.$$.fragment,e),_(an.$$.fragment,e),_(on.$$.fragment,e),_(rn.$$.fragment,e),_(ln.$$.fragment,e),_(un.$$.fragment,e),_(dn.$$.fragment,e),_(pn.$$.fragment,e),_(cn.$$.fragment,e),_(mn.$$.fragment,e),_(Rt.$$.fragment,e),_(fn.$$.fragment,e),_(vn.$$.fragment,e),_(hn.$$.fragment,e),_(Ut.$$.fragment,e),_(_n.$$.fragment,e),_(gn.$$.fragment,e),_($n.$$.fragment,e),_(bn.$$.fragment,e),_(En.$$.fragment,e),_(xn.$$.fragment,e),_(kn.$$.fragment,e),_(yn.$$.fragment,e),_(Cn.$$.fragment,e),_(Tn.$$.fragment,e),_(zn.$$.fragment,e),_(On.$$.fragment,e),_(Nn.$$.fragment,e),_(An.$$.fragment,e),Rp=!0)},o(e){g(x.$$.fragment,e),g(O.$$.fragment,e),g(z.$$.fragment,e),g(ee.$$.fragment,e),g(cs.$$.fragment,e),g(ms.$$.fragment,e),g(fs.$$.fragment,e),g(vs.$$.fragment,e),g(hs.$$.fragment,e),g(_s.$$.fragment,e),g(gs.$$.fragment,e),g(ht.$$.fragment,e),g($s.$$.fragment,e),g(bs.$$.fragment,e),g(Es.$$.fragment,e),g(xs.$$.fragment,e),g(js.$$.fragment,e),g(ws.$$.fragment,e),g(Ds.$$.fragment,e),g(ks.$$.fragment,e),g(ys.$$.fragment,e),g(Ts.$$.fragment,e),g(zs.$$.fragment,e),g(Ps.$$.fragment,e),g(Os.$$.fragment,e),g(Ns.$$.fragment,e),g(As.$$.fragment,e),g(Is.$$.fragment,e),g(Ls.$$.fragment,e),g(Ss.$$.fragment,e),g(bt.$$.fragment,e),g(Hs.$$.fragment,e),g(Ms.$$.fragment,e),g(xt.$$.fragment,e),g(Rs.$$.fragment,e),g(Fs.$$.fragment,e),g(Us.$$.fragment,e),g(Vs.$$.fragment,e),g(Bs.$$.fragment,e),g(Gs.$$.fragment,e),g(Js.$$.fragment,e),g(Ct.$$.fragment,e),g(Ws.$$.fragment,e),g(Nt.$$.fragment,e),g(At.$$.fragment,e),g(Xs.$$.fragment,e),g(Ks.$$.fragment,e),g(Qs.$$.fragment,e),g(Zs.$$.fragment,e),g(en.$$.fragment,e),g(sn.$$.fragment,e),g(nn.$$.fragment,e),g(an.$$.fragment,e),g(on.$$.fragment,e),g(rn.$$.fragment,e),g(ln.$$.fragment,e),g(un.$$.fragment,e),g(dn.$$.fragment,e),g(pn.$$.fragment,e),g(cn.$$.fragment,e),g(mn.$$.fragment,e),g(Rt.$$.fragment,e),g(fn.$$.fragment,e),g(vn.$$.fragment,e),g(hn.$$.fragment,e),g(Ut.$$.fragment,e),g(_n.$$.fragment,e),g(gn.$$.fragment,e),g($n.$$.fragment,e),g(bn.$$.fragment,e),g(En.$$.fragment,e),g(xn.$$.fragment,e),g(kn.$$.fragment,e),g(yn.$$.fragment,e),g(Cn.$$.fragment,e),g(Tn.$$.fragment,e),g(zn.$$.fragment,e),g(On.$$.fragment,e),g(Nn.$$.fragment,e),g(An.$$.fragment,e),Rp=!1},d(e){s(c),e&&s(D),e&&s(E),$(x),e&&s(P),$(O,e),e&&s(T),e&&s(k),e&&s(A),$(z,e),e&&s(me),e&&s(R),$(ee),e&&s(mt),e&&s(F),e&&s(Xi),e&&s(he),e&&s(Ki),e&&s(_e),e&&s(Qi),$(cs,e),e&&s(Zi),e&&s(ne),e&&s(eu),$(ms,e),e&&s(tu),e&&s(ge),e&&s(su),$(fs,e),e&&s(nu),$(vs,e),e&&s(au),e&&s(ae),e&&s(ou),e&&s($e),e&&s(ru),e&&s(be),e&&s(lu),$(hs,e),e&&s(iu),e&&s(Ee),e&&s(uu),$(_s,e),e&&s(du),$(gs,e),e&&s(pu),$(ht,e),e&&s(cu),e&&s(X),e&&s(mu),$($s,e),e&&s(fu),$(bs,e),e&&s(vu),e&&s(xe),e&&s(hu),$(Es,e),e&&s(_u),e&&s(qe),e&&s(gu),$(xs,e),e&&s($u),e&&s(K),e&&s(bu),$(js,e),e&&s(Eu),e&&s(Wn),e&&s(xu),$(ws,e),e&&s(qu),$(Ds,e),e&&s(ju),e&&s(Xn),e&&s(wu),$(ks,e),e&&s(Du),$(ys,e),e&&s(ku),e&&s(_t),e&&s(yu),$(Ts,e),e&&s(Cu),e&&s(Kn),e&&s(Tu),$(zs,e),e&&s(zu),$(Ps,e),e&&s(Pu),e&&s(Qn),e&&s(Ou),e&&s(Be),$(Os),e&&s(Nu),e&&s(Zn),e&&s(Au),e&&s(ea),e&&s(Iu),$(Ns,e),e&&s(Lu),e&&s(Y),e&&s(Su),$(As,e),e&&s(Hu),$(Is,e),e&&s(Mu),e&&s($t),e&&s(Ru),$(Ls,e),e&&s(Fu),$(Ss,e),e&&s(Uu),e&&s(ta),e&&s(Vu),$(bt,e),e&&s(Bu),e&&s(Et),e&&s(Gu),$(Hs,e),e&&s(Ju),$(Ms,e),e&&s(Yu),e&&s(sa),e&&s(Wu),$(xt,e),e&&s(Xu),e&&s(qt),e&&s(Ku),$(Rs,e),e&&s(Qu),$(Fs,e),e&&s(Zu),e&&s(jt),e&&s(ed),$(Us,e),e&&s(td),e&&s(wt),e&&s(sd),e&&s(Ge),$(Vs),e&&s(nd),e&&s(oe),e&&s(ad),e&&s(Q),e&&s(od),$(Bs,e),e&&s(rd),e&&s(kt),e&&s(ld),e&&s(re),e&&s(id),$(Gs,e),e&&s(ud),e&&s(le),e&&s(dd),$(Js,e),e&&s(pd),e&&s(yt),e&&s(cd),$(Ct,e),e&&s(md),e&&s(ra),e&&s(fd),e&&s(Tt),e&&s(vd),e&&s(je),e&&s(hd),e&&s(ha),e&&s(_d),e&&s(fe),e&&s(gd),$(Ws,e),e&&s($d),e&&s(_a),e&&s(bd),e&&s(zt),e&&s(Ed),e&&s(ie),e&&s(xd),$(Nt,e),e&&s(qd),e&&s(we),e&&s(jd),$(At,e),e&&s(wd),e&&s(De),e&&s(Dd),$(Xs,e),e&&s(kd),e&&s(It),e&&s(yd),$(Ks,e),e&&s(Cd),$(Qs,e),e&&s(Td),e&&s(za),e&&s(zd),$(Zs,e),e&&s(Pd),$(en,e),e&&s(Od),e&&s(ke),e&&s(Nd),e&&s(Z),e&&s(Ad),$(sn,e),e&&s(Id),e&&s(Pa),e&&s(Ld),$(nn,e),e&&s(Sd),$(an,e),e&&s(Hd),e&&s(ye),e&&s(Md),$(on,e),e&&s(Rd),e&&s(Lt),e&&s(Fd),$(rn,e),e&&s(Ud),$(ln,e),e&&s(Vd),e&&s(Oa),e&&s(Bd),e&&s(St),e&&s(Gd),e&&s(tt),$(un),e&&s(Jd),$(dn,e),e&&s(Yd),e&&s(ue),e&&s(Wd),$(pn,e),e&&s(Xd),e&&s(Mt),e&&s(Kd),$(cn,e),e&&s(Qd),e&&s(Ce),e&&s(ep),e&&s(Te),e&&s(tp),$(mn,e),e&&s(sp),$(Rt,e),e&&s(np),e&&s(Ft),e&&s(ap),$(fn,e),e&&s(op),e&&s(ze),e&&s(lp),e&&s(Oe),e&&s(ip),$(vn,e),e&&s(up),$(hn,e),e&&s(dp),$(Ut,e),e&&s(pp),e&&s(de),e&&s(cp),$(_n,e),e&&s(mp),e&&s(ut),$(gn),e&&s(fp),e&&s(Na),e&&s(vp),e&&s(Ne),e&&s(hp),$($n,e),e&&s(_p),$(bn,e),e&&s(gp),e&&s(Bt),e&&s($p),e&&s(dt),$(En),e&&s(bp),$(xn,e),e&&s(Ep),e&&s(Ia),e&&s(xp),e&&s(Jt),e&&s(qp),e&&s(Ba),e&&s(jp),$(kn,e),e&&s(wp),e&&s(Ga),e&&s(Dp),$(yn,e),e&&s(kp),e&&s(pe),e&&s(yp),e&&s(Yt),e&&s(Cp),$(Cn,e),e&&s(Tp),$(Tn,e),e&&s(zp),e&&s(Ja),e&&s(Pp),$(zn,e),e&&s(Op),e&&s(Wt),e&&s(Np),$(On,e),e&&s(Ap),$(Nn,e),e&&s(Ip),e&&s(Xt),e&&s(Lp),$(An,e),e&&s(Sp),e&&s(Wa),e&&s(Hp),e&&s(Kt),e&&s(Mp),e&&s(Qa)}}}const Zx={local:"il-est-temps-de-trancher-et-de-dcouper",sections:[{local:"trancher-et-dcouper-nos-donnes",title:"Trancher et d\xE9couper nos donn\xE9es"},{local:"cration-de-nouvelles-colonnes",title:"Cr\xE9ation de nouvelles colonnes"},{local:"les-superpouvoirs-de-la-mthode-map",title:"Les superpouvoirs de la m\xE9thode `map()`"},{local:"de-datasets-dataframes-et-vice-versa",title:"De `Dataset`s \xE0 `DataFrame`s et vice versa"},{local:"cration-dun-ensemble-de-validation",title:"Cr\xE9ation d'un ensemble de validation"},{local:"enregistrer-un-jeu-de-donnes",title:"Enregistrer un jeu de donn\xE9es"}],title:"Il est temps de trancher et de d\xE9couper"};function eq(M){return Fx(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class oq extends Sx{constructor(c){super();Hx(this,c,eq,Qx,Mx,{})}}export{oq as default,Zx as metadata};
