import{S as St,i as Nt,s as Ot,e as o,k as x,w as wt,t as r,M as Dt,c as l,d as s,m as $,a,x as yt,h as n,b as w,F as e,g as c,y as Tt,q as It,o as Ct,B as zt,v as Rt}from"../../chunks/vendor-1e8b365d.js";import{T as jt}from"../../chunks/Tip-62b14c6e.js";import{I as Ft}from"../../chunks/IconCopyLink-483c28ba.js";function Gt(oe){let d,_,f,h,v,q,y;return{c(){d=r("\u26A0\uFE0F Afin de b\xE9n\xE9ficier de toutes les fonctionnalit\xE9s disponibles avec le Model Hub et le \u{1F917} "),_=o("i"),f=r("Transformers"),h=r(", nous vous recommandons "),v=o("a"),q=r("de cr\xE9er un compte"),y=r("."),this.h()},l(i){d=n(i,"\u26A0\uFE0F Afin de b\xE9n\xE9ficier de toutes les fonctionnalit\xE9s disponibles avec le Model Hub et le \u{1F917} "),_=l(i,"I",{});var E=a(_);f=n(E,"Transformers"),E.forEach(s),h=n(i,", nous vous recommandons "),v=l(i,"A",{href:!0});var C=a(v);q=n(C,"de cr\xE9er un compte"),C.forEach(s),y=n(i,"."),this.h()},h(){w(v,"href","https://huggingface.co/join")},m(i,E){c(i,d,E),c(i,_,E),e(_,f),c(i,h,E),c(i,v,E),e(v,q),c(i,y,E)},d(i){i&&s(d),i&&s(_),i&&s(h),i&&s(v),i&&s(y)}}}function Ht(oe){let d,_,f,h,v,q,y,i,E,C,L,fe,S,he,ve,G,Ee,be,le,P,_e,H,qe,xe,U,$e,Le,ae,g,N,B,Pe,ge,Ae,b,J,Me,ke,K,we,ye,Q,Te,Ie,V,Ce,ze,Se,O,W,Ne,Oe,ie,T,De,X,Re,je,ue,m,Fe,Y,Ge,He,Z,Ue,Be,D,Je,Ke,ee,Qe,Ve,ce,p,We,te,Xe,Ye,se,Ze,et,re,tt,st,ne,rt,nt,de,I,me;return q=new Ft({}),I=new jt({props:{$$slots:{default:[Gt]},$$scope:{ctx:oe}}}),{c(){d=o("meta"),_=x(),f=o("h1"),h=o("a"),v=o("span"),wt(q.$$.fragment),y=x(),i=o("span"),E=r("Introduction"),C=x(),L=o("p"),fe=r("Comme vous l\u2019avez vu dans le "),S=o("a"),he=r("chapitre 1"),ve=r(", les "),G=o("em"),Ee=r("transformers"),be=r(" sont g\xE9n\xE9ralement tr\xE8s grands. Pouvant aller de plusieurs millions \xE0 des dizaines de milliards de param\xE8tres, l\u2019entra\xEEnement et le d\xE9ploiement de ces mod\xE8les est une entreprise compliqu\xE9e. De plus, avec de nouveaux mod\xE8les publi\xE9s presque quotidiennement et ayant chacun sa propre impl\xE9mentation, les essayer tous n\u2019est pas une t\xE2che facile."),le=x(),P=o("p"),_e=r("La biblioth\xE8que \u{1F917} "),H=o("em"),qe=r("Transformers"),xe=r(" a \xE9t\xE9 cr\xE9\xE9e pour r\xE9soudre ce probl\xE8me. Son objectif est de fournir une API unique \xE0 travers laquelle tout mod\xE8le de "),U=o("em"),$e=r("transformers"),Le=r(" peut \xEAtre charg\xE9, entra\xEEn\xE9 et sauvegard\xE9. Les principales caract\xE9ristiques de la biblioth\xE8que sont :"),ae=x(),g=o("ul"),N=o("li"),B=o("strong"),Pe=r("La facilit\xE9 d\u2019utilisation"),ge=r(" : en seulement deux lignes de code il est possible de t\xE9l\xE9charger, charger et utiliser un mod\xE8le de NLP \xE0 l\u2019\xE9tat de l\u2019art pour faire de l\u2019inf\xE9rence,"),Ae=x(),b=o("li"),J=o("strong"),Me=r("La flexibilit\xE9"),ke=r(" : au fond, tous les mod\xE8les sont de simples classes PyTorch "),K=o("code"),we=r("nn.Module"),ye=r(" ou TensorFlow "),Q=o("code"),Te=r("tf.keras.Model"),Ie=r(" et peuvent \xEAtre manipul\xE9s comme n\u2019importe quel autre mod\xE8le dans leurs "),V=o("em"),Ce=r("frameworks"),ze=r(" d\u2019apprentissage automatique respectifs,"),Se=x(),O=o("li"),W=o("strong"),Ne=r("La simplicit\xE9"),Oe=r(" : pratiquement aucune abstraction n\u2019est faite dans la biblioth\xE8que. Avoir tout dans un fichier est un concept central : la passe avant d\u2019un mod\xE8le est enti\xE8rement d\xE9finie dans un seul fichier afin que le code lui-m\xEAme soit compr\xE9hensible et piratable."),ie=x(),T=o("p"),De=r("Cette derni\xE8re caract\xE9ristique rend \u{1F917} "),X=o("em"),Re=r("Transformers"),je=r(` tr\xE8s diff\xE9rent des autres biblioth\xE8ques d\u2019apprentissage automatique.
Les mod\xE8les ne sont pas construits sur des modules partag\xE9s entre plusieurs fichiers. Au lieu de cela, chaque mod\xE8le poss\xE8de ses propres couches.
En plus de rendre les mod\xE8les plus accessibles et compr\xE9hensibles, cela vous permet d\u2019exp\xE9rimenter des choses facilement sur un mod\xE8le sans affecter les autres.`),ue=x(),m=o("p"),Fe=r("Ce chapitre commence par un exemple de bout en bout o\xF9 nous utilisons un mod\xE8le et un "),Y=o("em"),Ge=r("tokenizer"),He=r(" ensemble pour reproduire la fonction "),Z=o("code"),Ue=r("pipeline()"),Be=r(" introduite dans le "),D=o("a"),Je=r("chapitre 1"),Ke=r(`.
Ensuite, nous aborderons l\u2019API `),ee=o("em"),Qe=r("model"),Ve=r(" : nous nous plongerons dans les classes de mod\xE8le et de configuration, nous verrons comment charger un mod\xE8le et enfin comment il traite les entr\xE9es num\xE9riques pour produire des pr\xE9dictions."),ce=x(),p=o("p"),We=r("Nous examinerons ensuite l\u2019API "),te=o("em"),Xe=r("tokenizer"),Ye=r(" qui est l\u2019autre composant principal de la fonction "),se=o("code"),Ze=r("pipeline()"),et=r(`.
Les `),re=o("em"),tt=r("tokenizers"),st=r(` s\u2019occupent de la premi\xE8re et de la derni\xE8re \xE9tape du traitement en g\xE9rant la conversion du texte en entr\xE9es num\xE9riques pour le r\xE9seau neuronal et la reconversion en texte lorsqu\u2019elle est n\xE9cessaire.
Enfin, nous montrerons comment g\xE9rer l\u2019envoi de plusieurs phrases \xE0 travers un mod\xE8le dans un batch pr\xE9par\xE9 et nous conclurons le tout en examinant de plus pr\xE8s la fonction `),ne=o("code"),rt=r("tokenizer()"),nt=r("."),de=x(),wt(I.$$.fragment),this.h()},l(t){const u=Dt('[data-svelte="svelte-1phssyn"]',document.head);d=l(u,"META",{name:!0,content:!0}),u.forEach(s),_=$(t),f=l(t,"H1",{class:!0});var z=a(f);h=l(z,"A",{id:!0,class:!0,href:!0});var at=a(h);v=l(at,"SPAN",{});var it=a(v);yt(q.$$.fragment,it),it.forEach(s),at.forEach(s),y=$(z),i=l(z,"SPAN",{});var ut=a(i);E=n(ut,"Introduction"),ut.forEach(s),z.forEach(s),C=$(t),L=l(t,"P",{});var R=a(L);fe=n(R,"Comme vous l\u2019avez vu dans le "),S=l(R,"A",{href:!0});var ct=a(S);he=n(ct,"chapitre 1"),ct.forEach(s),ve=n(R,", les "),G=l(R,"EM",{});var dt=a(G);Ee=n(dt,"transformers"),dt.forEach(s),be=n(R," sont g\xE9n\xE9ralement tr\xE8s grands. Pouvant aller de plusieurs millions \xE0 des dizaines de milliards de param\xE8tres, l\u2019entra\xEEnement et le d\xE9ploiement de ces mod\xE8les est une entreprise compliqu\xE9e. De plus, avec de nouveaux mod\xE8les publi\xE9s presque quotidiennement et ayant chacun sa propre impl\xE9mentation, les essayer tous n\u2019est pas une t\xE2che facile."),R.forEach(s),le=$(t),P=l(t,"P",{});var j=a(P);_e=n(j,"La biblioth\xE8que \u{1F917} "),H=l(j,"EM",{});var mt=a(H);qe=n(mt,"Transformers"),mt.forEach(s),xe=n(j," a \xE9t\xE9 cr\xE9\xE9e pour r\xE9soudre ce probl\xE8me. Son objectif est de fournir une API unique \xE0 travers laquelle tout mod\xE8le de "),U=l(j,"EM",{});var pt=a(U);$e=n(pt,"transformers"),pt.forEach(s),Le=n(j," peut \xEAtre charg\xE9, entra\xEEn\xE9 et sauvegard\xE9. Les principales caract\xE9ristiques de la biblioth\xE8que sont :"),j.forEach(s),ae=$(t),g=l(t,"UL",{});var F=a(g);N=l(F,"LI",{});var ot=a(N);B=l(ot,"STRONG",{});var ft=a(B);Pe=n(ft,"La facilit\xE9 d\u2019utilisation"),ft.forEach(s),ge=n(ot," : en seulement deux lignes de code il est possible de t\xE9l\xE9charger, charger et utiliser un mod\xE8le de NLP \xE0 l\u2019\xE9tat de l\u2019art pour faire de l\u2019inf\xE9rence,"),ot.forEach(s),Ae=$(F),b=l(F,"LI",{});var k=a(b);J=l(k,"STRONG",{});var ht=a(J);Me=n(ht,"La flexibilit\xE9"),ht.forEach(s),ke=n(k," : au fond, tous les mod\xE8les sont de simples classes PyTorch "),K=l(k,"CODE",{});var vt=a(K);we=n(vt,"nn.Module"),vt.forEach(s),ye=n(k," ou TensorFlow "),Q=l(k,"CODE",{});var Et=a(Q);Te=n(Et,"tf.keras.Model"),Et.forEach(s),Ie=n(k," et peuvent \xEAtre manipul\xE9s comme n\u2019importe quel autre mod\xE8le dans leurs "),V=l(k,"EM",{});var bt=a(V);Ce=n(bt,"frameworks"),bt.forEach(s),ze=n(k," d\u2019apprentissage automatique respectifs,"),k.forEach(s),Se=$(F),O=l(F,"LI",{});var lt=a(O);W=l(lt,"STRONG",{});var _t=a(W);Ne=n(_t,"La simplicit\xE9"),_t.forEach(s),Oe=n(lt," : pratiquement aucune abstraction n\u2019est faite dans la biblioth\xE8que. Avoir tout dans un fichier est un concept central : la passe avant d\u2019un mod\xE8le est enti\xE8rement d\xE9finie dans un seul fichier afin que le code lui-m\xEAme soit compr\xE9hensible et piratable."),lt.forEach(s),F.forEach(s),ie=$(t),T=l(t,"P",{});var pe=a(T);De=n(pe,"Cette derni\xE8re caract\xE9ristique rend \u{1F917} "),X=l(pe,"EM",{});var qt=a(X);Re=n(qt,"Transformers"),qt.forEach(s),je=n(pe,` tr\xE8s diff\xE9rent des autres biblioth\xE8ques d\u2019apprentissage automatique.
Les mod\xE8les ne sont pas construits sur des modules partag\xE9s entre plusieurs fichiers. Au lieu de cela, chaque mod\xE8le poss\xE8de ses propres couches.
En plus de rendre les mod\xE8les plus accessibles et compr\xE9hensibles, cela vous permet d\u2019exp\xE9rimenter des choses facilement sur un mod\xE8le sans affecter les autres.`),pe.forEach(s),ue=$(t),m=l(t,"P",{});var A=a(m);Fe=n(A,"Ce chapitre commence par un exemple de bout en bout o\xF9 nous utilisons un mod\xE8le et un "),Y=l(A,"EM",{});var xt=a(Y);Ge=n(xt,"tokenizer"),xt.forEach(s),He=n(A," ensemble pour reproduire la fonction "),Z=l(A,"CODE",{});var $t=a(Z);Ue=n($t,"pipeline()"),$t.forEach(s),Be=n(A," introduite dans le "),D=l(A,"A",{href:!0});var Lt=a(D);Je=n(Lt,"chapitre 1"),Lt.forEach(s),Ke=n(A,`.
Ensuite, nous aborderons l\u2019API `),ee=l(A,"EM",{});var Pt=a(ee);Qe=n(Pt,"model"),Pt.forEach(s),Ve=n(A," : nous nous plongerons dans les classes de mod\xE8le et de configuration, nous verrons comment charger un mod\xE8le et enfin comment il traite les entr\xE9es num\xE9riques pour produire des pr\xE9dictions."),A.forEach(s),ce=$(t),p=l(t,"P",{});var M=a(p);We=n(M,"Nous examinerons ensuite l\u2019API "),te=l(M,"EM",{});var gt=a(te);Xe=n(gt,"tokenizer"),gt.forEach(s),Ye=n(M," qui est l\u2019autre composant principal de la fonction "),se=l(M,"CODE",{});var At=a(se);Ze=n(At,"pipeline()"),At.forEach(s),et=n(M,`.
Les `),re=l(M,"EM",{});var Mt=a(re);tt=n(Mt,"tokenizers"),Mt.forEach(s),st=n(M,` s\u2019occupent de la premi\xE8re et de la derni\xE8re \xE9tape du traitement en g\xE9rant la conversion du texte en entr\xE9es num\xE9riques pour le r\xE9seau neuronal et la reconversion en texte lorsqu\u2019elle est n\xE9cessaire.
Enfin, nous montrerons comment g\xE9rer l\u2019envoi de plusieurs phrases \xE0 travers un mod\xE8le dans un batch pr\xE9par\xE9 et nous conclurons le tout en examinant de plus pr\xE8s la fonction `),ne=l(M,"CODE",{});var kt=a(ne);rt=n(kt,"tokenizer()"),kt.forEach(s),nt=n(M,"."),M.forEach(s),de=$(t),yt(I.$$.fragment,t),this.h()},h(){w(d,"name","hf:doc:metadata"),w(d,"content",JSON.stringify(Ut)),w(h,"id","introduction"),w(h,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(h,"href","#introduction"),w(f,"class","relative group"),w(S,"href","/course/fr/chapter1"),w(D,"href","/course/fr/chapter1")},m(t,u){e(document.head,d),c(t,_,u),c(t,f,u),e(f,h),e(h,v),Tt(q,v,null),e(f,y),e(f,i),e(i,E),c(t,C,u),c(t,L,u),e(L,fe),e(L,S),e(S,he),e(L,ve),e(L,G),e(G,Ee),e(L,be),c(t,le,u),c(t,P,u),e(P,_e),e(P,H),e(H,qe),e(P,xe),e(P,U),e(U,$e),e(P,Le),c(t,ae,u),c(t,g,u),e(g,N),e(N,B),e(B,Pe),e(N,ge),e(g,Ae),e(g,b),e(b,J),e(J,Me),e(b,ke),e(b,K),e(K,we),e(b,ye),e(b,Q),e(Q,Te),e(b,Ie),e(b,V),e(V,Ce),e(b,ze),e(g,Se),e(g,O),e(O,W),e(W,Ne),e(O,Oe),c(t,ie,u),c(t,T,u),e(T,De),e(T,X),e(X,Re),e(T,je),c(t,ue,u),c(t,m,u),e(m,Fe),e(m,Y),e(Y,Ge),e(m,He),e(m,Z),e(Z,Ue),e(m,Be),e(m,D),e(D,Je),e(m,Ke),e(m,ee),e(ee,Qe),e(m,Ve),c(t,ce,u),c(t,p,u),e(p,We),e(p,te),e(te,Xe),e(p,Ye),e(p,se),e(se,Ze),e(p,et),e(p,re),e(re,tt),e(p,st),e(p,ne),e(ne,rt),e(p,nt),c(t,de,u),Tt(I,t,u),me=!0},p(t,[u]){const z={};u&2&&(z.$$scope={dirty:u,ctx:t}),I.$set(z)},i(t){me||(It(q.$$.fragment,t),It(I.$$.fragment,t),me=!0)},o(t){Ct(q.$$.fragment,t),Ct(I.$$.fragment,t),me=!1},d(t){s(d),t&&s(_),t&&s(f),zt(q),t&&s(C),t&&s(L),t&&s(le),t&&s(P),t&&s(ae),t&&s(g),t&&s(ie),t&&s(T),t&&s(ue),t&&s(m),t&&s(ce),t&&s(p),t&&s(de),zt(I,t)}}}const Ut={local:"introduction",title:"Introduction"};function Bt(oe){return Rt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Vt extends St{constructor(d){super();Nt(this,d,Bt,Ht,Ot,{})}}export{Vt as default,Ut as metadata};
