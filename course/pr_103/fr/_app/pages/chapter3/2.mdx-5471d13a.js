import{S as Uu,i as Gu,s as Qu,e as i,t as n,k as m,w as k,c as u,a as p,h as a,d as t,m as f,x as $,g as c,F as s,y as x,q as b,o as g,B as E,l as Wu,M as Ju,b as w,p as Ps,v as Ku,n as Ds}from"../../chunks/vendor-1e8b365d.js";import{T as si}from"../../chunks/Tip-62b14c6e.js";import{Y as $n}from"../../chunks/Youtube-c2a8cc39.js";import{I as Fa}from"../../chunks/IconCopyLink-483c28ba.js";import{C as T}from"../../chunks/CodeBlock-e5764662.js";import{D as Vu}from"../../chunks/DocNotebookDropdown-37d928d3.js";import{F as Yu}from"../../chunks/FrameworkSwitchCourse-7f8f0f31.js";function Zu(z){let r,d;return r=new Vu({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section2_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section2_tf.ipynb"}]}}),{c(){k(r.$$.fragment)},l(l){$(r.$$.fragment,l)},m(l,v){x(r,l,v),d=!0},i(l){d||(b(r.$$.fragment,l),d=!0)},o(l){g(r.$$.fragment,l),d=!1},d(l){E(r,l)}}}function Xu(z){let r,d;return r=new Vu({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section2_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section2_pt.ipynb"}]}}),{c(){k(r.$$.fragment)},l(l){$(r.$$.fragment,l)},m(l,v){x(r,l,v),d=!0},i(l){d||(b(r.$$.fragment,l),d=!0)},o(l){g(r.$$.fragment,l),d=!1},d(l){E(r,l)}}}function ep(z){let r,d,l,v,j,h,_,y;return _=new T({props:{code:`import tensorflow as tf
import numpy as np
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

# Same as before
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [
    "I've been waiting for a HuggingFace course my whole life.",
    "This course is amazing!",
]
batch = dict(tokenizer(sequences, padding=True, truncation=True, return_tensors="tf"))

# This is new
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy")
labels = tf.convert_to_tensor([1, 1])
model.train_on_batch(batch, labels)`,highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-comment"># Same as before</span>
checkpoint = <span class="hljs-string">&quot;bert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [
    <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>,
    <span class="hljs-string">&quot;This course is amazing!&quot;</span>,
]
batch = <span class="hljs-built_in">dict</span>(tokenizer(sequences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>))

<span class="hljs-comment"># This is new</span>
model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&quot;adam&quot;</span>, loss=<span class="hljs-string">&quot;sparse_categorical_crossentropy&quot;</span>)
labels = tf.convert_to_tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])
model.train_on_batch(batch, labels)`}}),{c(){r=i("p"),d=n("Continuons avec "),l=i("a"),v=n("l\u2019exemple pr\xE9c\xE9dent"),j=n(", voil\xE0 comment on entra\xEEne un classifieur de s\xE9quences sur un batch avec TensorFlow :"),h=m(),k(_.$$.fragment),this.h()},l(q){r=u(q,"P",{});var P=p(r);d=a(P,"Continuons avec "),l=u(P,"A",{href:!0});var L=p(l);v=a(L,"l\u2019exemple pr\xE9c\xE9dent"),L.forEach(t),j=a(P,", voil\xE0 comment on entra\xEEne un classifieur de s\xE9quences sur un batch avec TensorFlow :"),P.forEach(t),h=f(q),$(_.$$.fragment,q),this.h()},h(){w(l,"href","/course/chapter2")},m(q,P){c(q,r,P),s(r,d),s(r,l),s(l,v),s(r,j),c(q,h,P),x(_,q,P),y=!0},i(q){y||(b(_.$$.fragment,q),y=!0)},o(q){g(_.$$.fragment,q),y=!1},d(q){q&&t(r),q&&t(h),E(_,q)}}}function sp(z){let r,d,l,v,j,h,_,y;return _=new T({props:{code:`import torch
from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification

# Same as before
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [
    "I've been waiting for a HuggingFace course my whole life.",
    "This course is amazing!",
]
batch = tokenizer(sequences, padding=True, truncation=True, return_tensors="pt")

# This is new
batch["labels"] = torch.tensor([1, 1])

optimizer = AdamW(model.parameters())
loss = model(**batch).loss
loss.backward()
optimizer.step()`,highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW, AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-comment"># Same as before</span>
checkpoint = <span class="hljs-string">&quot;bert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [
    <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>,
    <span class="hljs-string">&quot;This course is amazing!&quot;</span>,
]
batch = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

<span class="hljs-comment"># This is new</span>
batch[<span class="hljs-string">&quot;labels&quot;</span>] = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])

optimizer = AdamW(model.parameters())
loss = model(**batch).loss
loss.backward()
optimizer.step()`}}),{c(){r=i("p"),d=n("Continuons avec "),l=i("a"),v=n("l\u2019exemple pr\xE9c\xE9dent"),j=n(`, voil\xE0 comment on entra\xEEne un classifieur de s\xE9quences sur un batch avec PyTorch :
s`),h=m(),k(_.$$.fragment),this.h()},l(q){r=u(q,"P",{});var P=p(r);d=a(P,"Continuons avec "),l=u(P,"A",{href:!0});var L=p(l);v=a(L,"l\u2019exemple pr\xE9c\xE9dent"),L.forEach(t),j=a(P,`, voil\xE0 comment on entra\xEEne un classifieur de s\xE9quences sur un batch avec PyTorch :
s`),P.forEach(t),h=f(q),$(_.$$.fragment,q),this.h()},h(){w(l,"href","/course/chapter2")},m(q,P){c(q,r,P),s(r,d),s(r,l),s(l,v),s(r,j),c(q,h,P),x(_,q,P),y=!0},i(q){y||(b(_.$$.fragment,q),y=!0)},o(q){g(_.$$.fragment,q),y=!1},d(q){q&&t(r),q&&t(h),E(_,q)}}}function tp(z){let r,d;return r=new $n({props:{id:"W_gMJF0xomE"}}),{c(){k(r.$$.fragment)},l(l){$(r.$$.fragment,l)},m(l,v){x(r,l,v),d=!0},i(l){d||(b(r.$$.fragment,l),d=!0)},o(l){g(r.$$.fragment,l),d=!1},d(l){E(r,l)}}}function np(z){let r,d;return r=new $n({props:{id:"_BZearw7f0w"}}),{c(){k(r.$$.fragment)},l(l){$(r.$$.fragment,l)},m(l,v){x(r,l,v),d=!0},i(l){d||(b(r.$$.fragment,l),d=!0)},o(l){g(r.$$.fragment,l),d=!1},d(l){E(r,l)}}}function ap(z){let r,d,l,v,j;return{c(){r=i("p"),d=n("\u270F\uFE0F "),l=i("strong"),v=n("Essayez ceci!"),j=n(" Regardez l\u2019\xE9l\xE9ment 15 du jeu d\u2019entra\xEEnement et l\u2019\xE9l\xE9ment 87 du jeu de validation. Quels sont leurs labels?")},l(h){r=u(h,"P",{});var _=p(r);d=a(_,"\u270F\uFE0F "),l=u(_,"STRONG",{});var y=p(l);v=a(y,"Essayez ceci!"),y.forEach(t),j=a(_," Regardez l\u2019\xE9l\xE9ment 15 du jeu d\u2019entra\xEEnement et l\u2019\xE9l\xE9ment 87 du jeu de validation. Quels sont leurs labels?"),_.forEach(t)},m(h,_){c(h,r,_),s(r,d),s(r,l),s(l,v),s(r,j)},d(h){h&&t(r)}}}function rp(z){let r,d;return r=new $n({props:{id:"P-rZWqcB6CE"}}),{c(){k(r.$$.fragment)},l(l){$(r.$$.fragment,l)},m(l,v){x(r,l,v),d=!0},i(l){d||(b(r.$$.fragment,l),d=!0)},o(l){g(r.$$.fragment,l),d=!1},d(l){E(r,l)}}}function lp(z){let r,d;return r=new $n({props:{id:"0u3ioSwev3s"}}),{c(){k(r.$$.fragment)},l(l){$(r.$$.fragment,l)},m(l,v){x(r,l,v),d=!0},i(l){d||(b(r.$$.fragment,l),d=!0)},o(l){g(r.$$.fragment,l),d=!1},d(l){E(r,l)}}}function op(z){let r,d,l,v,j;return{c(){r=i("p"),d=n("\u270F\uFE0F "),l=i("strong"),v=n("Essayez ceci!"),j=n(" Prenez l\u2019\xE9l\xE9ment 15 de l\u2019ensemble d\u2019entra\xEEnement et tokenisez les deux phrases s\xE9par\xE9ment et comme une paire. Quelle est la diff\xE9rence entre les deux r\xE9sultats\xA0?")},l(h){r=u(h,"P",{});var _=p(r);d=a(_,"\u270F\uFE0F "),l=u(_,"STRONG",{});var y=p(l);v=a(y,"Essayez ceci!"),y.forEach(t),j=a(_," Prenez l\u2019\xE9l\xE9ment 15 de l\u2019ensemble d\u2019entra\xEEnement et tokenisez les deux phrases s\xE9par\xE9ment et comme une paire. Quelle est la diff\xE9rence entre les deux r\xE9sultats\xA0?"),_.forEach(t)},m(h,_){c(h,r,_),s(r,d),s(r,l),s(l,v),s(r,j)},d(h){h&&t(r)}}}function ip(z){let r,d,l,v,j,h,_,y,q,P,L;return{c(){r=i("p"),d=n("La fonction responsable de mettre en ensemble les \xE9l\xE9ments pour en faire un batch est appel\xE9e "),l=i("em"),v=n("fonction d\u2019assemblage"),j=n(" -"),h=i("em"),_=n("collate function"),y=n("-. C\u2019est un argument que vous pouvez fournir lorsque vous construisez un "),q=i("code"),P=n("DataLoader"),L=n(", par d\xE9faut il s\u2019agit d\u2019une fonction qui va juste convertir les \xE9l\xE9ments en type tf.Tensor et les concat\xE9ner (r\xE9cursivement si les \xE9l\xE9ments sont des listes, des tuples ou des dictionnaires). Cela -la concat\xE9nation- ne sera pas possible dans notre cas puisque toutes les entr\xE9es n\u2019auront pas la m\xEAme taille. Nous avons volontairement reporter \xE0 plus tard le padding, pour n\u2019appliquer que le padding n\xE9cessaire pour chaque batch et \xE9viter d\u2019avoir des entr\xE9es excessivement longues avec beaucoup de padding. Cela va beaucoup acc\xE9l\xE9rer l\u2019entra\xEEnement, notez cependant que si vous faites l\u2019entra\xEEnement sur TPU cela peut poser des probl\xE8mes \u2014 Les TPUs pr\xE9f\xE8rent une taille fixe m\xEAme si cela requiert beaucoup de padding.")},l(O){r=u(O,"P",{});var C=p(r);d=a(C,"La fonction responsable de mettre en ensemble les \xE9l\xE9ments pour en faire un batch est appel\xE9e "),l=u(C,"EM",{});var M=p(l);v=a(M,"fonction d\u2019assemblage"),M.forEach(t),j=a(C," -"),h=u(C,"EM",{});var H=p(h);_=a(H,"collate function"),H.forEach(t),y=a(C,"-. C\u2019est un argument que vous pouvez fournir lorsque vous construisez un "),q=u(C,"CODE",{});var S=p(q);P=a(S,"DataLoader"),S.forEach(t),L=a(C,", par d\xE9faut il s\u2019agit d\u2019une fonction qui va juste convertir les \xE9l\xE9ments en type tf.Tensor et les concat\xE9ner (r\xE9cursivement si les \xE9l\xE9ments sont des listes, des tuples ou des dictionnaires). Cela -la concat\xE9nation- ne sera pas possible dans notre cas puisque toutes les entr\xE9es n\u2019auront pas la m\xEAme taille. Nous avons volontairement reporter \xE0 plus tard le padding, pour n\u2019appliquer que le padding n\xE9cessaire pour chaque batch et \xE9viter d\u2019avoir des entr\xE9es excessivement longues avec beaucoup de padding. Cela va beaucoup acc\xE9l\xE9rer l\u2019entra\xEEnement, notez cependant que si vous faites l\u2019entra\xEEnement sur TPU cela peut poser des probl\xE8mes \u2014 Les TPUs pr\xE9f\xE8rent une taille fixe m\xEAme si cela requiert beaucoup de padding."),C.forEach(t)},m(O,C){c(O,r,C),s(r,d),s(r,l),s(l,v),s(r,j),s(r,h),s(h,_),s(r,y),s(r,q),s(q,P),s(r,L)},d(O){O&&t(r)}}}function up(z){let r,d,l,v,j,h,_,y,q,P,L;return{c(){r=i("p"),d=n("La fonction responsable de mettre en ensemble les \xE9l\xE9ments pour en faire un batch est appel\xE9e "),l=i("em"),v=n("fonction d\u2019assemblage"),j=n(" -"),h=i("em"),_=n("collate function"),y=n("-. C\u2019est un argument que vous pouvez fournir lorsque vous construisez un "),q=i("code"),P=n("DataLoader"),L=n(", par d\xE9faut il s\u2019agit d\u2019une fonction qui va juste convertir les \xE9l\xE9ments en type tensor de Pytorch et les concat\xE9ner (r\xE9cursivement si les \xE9l\xE9ments sont des listes, des tuples ou des dictionnaires). Cela -la concat\xE9nation- ne sera pas possible dans notre cas puisque toutes les entr\xE9es n\u2019auront pas la m\xEAme taille. Nous avons volontairement reporter \xE0 plus tard le padding, pour n\u2019appliquer que le padding n\xE9cessaire pour chaque batch et \xE9viter d\u2019avoir des entr\xE9es excessivement longues avec beaucoup de padding. Cela va beaucoup acc\xE9l\xE9rer l\u2019entra\xEEnement, notez cependant que si vous faites l\u2019entra\xEEnement sur TPU cela peut poser des probl\xE8mes \u2014 Les TPUs pr\xE9f\xE8rent une taille fixe m\xEAme si cela requiert beaucoup de padding.")},l(O){r=u(O,"P",{});var C=p(r);d=a(C,"La fonction responsable de mettre en ensemble les \xE9l\xE9ments pour en faire un batch est appel\xE9e "),l=u(C,"EM",{});var M=p(l);v=a(M,"fonction d\u2019assemblage"),M.forEach(t),j=a(C," -"),h=u(C,"EM",{});var H=p(h);_=a(H,"collate function"),H.forEach(t),y=a(C,"-. C\u2019est un argument que vous pouvez fournir lorsque vous construisez un "),q=u(C,"CODE",{});var S=p(q);P=a(S,"DataLoader"),S.forEach(t),L=a(C,", par d\xE9faut il s\u2019agit d\u2019une fonction qui va juste convertir les \xE9l\xE9ments en type tensor de Pytorch et les concat\xE9ner (r\xE9cursivement si les \xE9l\xE9ments sont des listes, des tuples ou des dictionnaires). Cela -la concat\xE9nation- ne sera pas possible dans notre cas puisque toutes les entr\xE9es n\u2019auront pas la m\xEAme taille. Nous avons volontairement reporter \xE0 plus tard le padding, pour n\u2019appliquer que le padding n\xE9cessaire pour chaque batch et \xE9viter d\u2019avoir des entr\xE9es excessivement longues avec beaucoup de padding. Cela va beaucoup acc\xE9l\xE9rer l\u2019entra\xEEnement, notez cependant que si vous faites l\u2019entra\xEEnement sur TPU cela peut poser des probl\xE8mes \u2014 Les TPUs pr\xE9f\xE8rent une taille fixe m\xEAme si cela requiert beaucoup de padding."),C.forEach(t)},m(O,C){c(O,r,C),s(r,d),s(r,l),s(l,v),s(r,j),s(r,h),s(h,_),s(r,y),s(r,q),s(q,P),s(r,L)},d(O){O&&t(r)}}}function pp(z){let r,d;return r=new T({props:{code:`from transformers import DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors="tf")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),{c(){k(r.$$.fragment)},l(l){$(r.$$.fragment,l)},m(l,v){x(r,l,v),d=!0},i(l){d||(b(r.$$.fragment,l),d=!0)},o(l){g(r.$$.fragment,l),d=!1},d(l){E(r,l)}}}function cp(z){let r,d;return r=new T({props:{code:`from transformers import DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`}}),{c(){k(r.$$.fragment)},l(l){$(r.$$.fragment,l)},m(l,v){x(r,l,v),d=!0},i(l){d||(b(r.$$.fragment,l),d=!0)},o(l){g(r.$$.fragment,l),d=!1},d(l){E(r,l)}}}function dp(z){let r,d,l,v,j;return r=new T({props:{code:`{'attention_mask': torch.Size([8, 67]),
 'input_ids': torch.Size([8, 67]),
 'token_type_ids': torch.Size([8, 67]),
 'labels': torch.Size([8])}`,highlighted:`{<span class="hljs-string">&#x27;attention_mask&#x27;</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;input_ids&#x27;</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;labels&#x27;</span>: torch.Size([<span class="hljs-number">8</span>])}`}}),{c(){k(r.$$.fragment),d=m(),l=i("p"),v=n("Bien! Maintenant que nous sommes pass\xE9s du texte brut aux batchs que notre mod\xE8le peut exploiter, nous sommes pr\xEAt \xE0 proc\xE9der au fine-tuning!")},l(h){$(r.$$.fragment,h),d=f(h),l=u(h,"P",{});var _=p(l);v=a(_,"Bien! Maintenant que nous sommes pass\xE9s du texte brut aux batchs que notre mod\xE8le peut exploiter, nous sommes pr\xEAt \xE0 proc\xE9der au fine-tuning!"),_.forEach(t)},m(h,_){x(r,h,_),c(h,d,_),c(h,l,_),s(l,v),j=!0},i(h){j||(b(r.$$.fragment,h),j=!0)},o(h){g(r.$$.fragment,h),j=!1},d(h){E(r,h),h&&t(d),h&&t(l)}}}function mp(z){let r,d;return r=new T({props:{code:`{'attention_mask': TensorShape([8, 67]),
 'input_ids': TensorShape([8, 67]),
 'token_type_ids': TensorShape([8, 67]),
 'labels': TensorShape([8])}`,highlighted:`{<span class="hljs-string">&#x27;attention_mask&#x27;</span>: TensorShape([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;input_ids&#x27;</span>: TensorShape([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: TensorShape([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;labels&#x27;</span>: TensorShape([<span class="hljs-number">8</span>])}`}}),{c(){k(r.$$.fragment)},l(l){$(r.$$.fragment,l)},m(l,v){x(r,l,v),d=!0},i(l){d||(b(r.$$.fragment,l),d=!0)},o(l){g(r.$$.fragment,l),d=!1},d(l){E(r,l)}}}function fp(z){let r,d,l,v,j;return{c(){r=i("p"),d=n("\u270F\uFE0F "),l=i("strong"),v=n("Essayez ceci!"),j=n(" Reproduisez le preprocessing  sur le dataset GLUE SST-2. Il est un peu diff\xE9rent puisqu\u2019il est compos\xE9 d\u2019uniques phrases et non de paires de phrases, mais le reste de ce que nous avons fait devrait \xEAtre similaire. Pour un d\xE9fi plus cors\xE9, essayez d\u2019\xE9crire une fonction de pr\xE9processing qui marche pour toutes les t\xE2ches de GLUE.")},l(h){r=u(h,"P",{});var _=p(r);d=a(_,"\u270F\uFE0F "),l=u(_,"STRONG",{});var y=p(l);v=a(y,"Essayez ceci!"),y.forEach(t),j=a(_," Reproduisez le preprocessing  sur le dataset GLUE SST-2. Il est un peu diff\xE9rent puisqu\u2019il est compos\xE9 d\u2019uniques phrases et non de paires de phrases, mais le reste de ce que nous avons fait devrait \xEAtre similaire. Pour un d\xE9fi plus cors\xE9, essayez d\u2019\xE9crire une fonction de pr\xE9processing qui marche pour toutes les t\xE2ches de GLUE."),_.forEach(t)},m(h,_){c(h,r,_),s(r,d),s(r,l),s(l,v),s(r,j)},d(h){h&&t(r)}}}function Bu(z){let r,d,l,v,j,h,_,y,q,P,L,O,C,M,H,S,W,K,pe,ze;return S=new T({props:{code:`tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)`,highlighted:`tf_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
    shuffle=<span class="hljs-literal">True</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)

tf_validation_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
    shuffle=<span class="hljs-literal">False</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)`}}),{c(){r=i("p"),d=n("Maintenant que nous avons notre dataset et notre assembleur de donn\xE9es, nous devons les mettre ensemble. On pourrait charger manuellement les batchs et les assembler, mais cela repr\xE9sente beaucoup de travail, et ce n\u2019est pas tr\xE8s performant non plus. Au lieu de faire cela, il y a une simple m\xE9thode qui offre une solution performante \xE0 ce probl\xE8me : "),l=i("code"),v=n("to_tf_dataset()"),j=n(".  Cette m\xE9thode va passer "),h=i("code"),_=n("tf.data.Dataset"),y=n(" sur votre dataset, avec une fonction d\u2019assemblage optionnelle. "),q=i("code"),P=n("tf.data.Dataset"),L=n(" est un format natif de Tensorflow que Keras peut utiliser avec "),O=i("code"),C=n("model.fit()"),M=n(", donc cette m\xE9thode \xE0 elle seule convertit un dataset de \u{1F917} \xE0 un format pr\xEAt pour l\u2019entra\xEEnement. Voyons la \xE0 l\u2019\u0153uvre avec notre dataset!"),H=m(),k(S.$$.fragment),W=m(),K=i("p"),pe=n("Et c\u2019est tout! Nous pouvons utiliser ces datasets dans le prochain cours, o\xF9 l\u2019entra\xEEnement va \xEAtre agr\xE9ablement facile apr\xE8s tout le difficile travail de pr\xE9processing.")},l(D){r=u(D,"P",{});var N=p(r);d=a(N,"Maintenant que nous avons notre dataset et notre assembleur de donn\xE9es, nous devons les mettre ensemble. On pourrait charger manuellement les batchs et les assembler, mais cela repr\xE9sente beaucoup de travail, et ce n\u2019est pas tr\xE8s performant non plus. Au lieu de faire cela, il y a une simple m\xE9thode qui offre une solution performante \xE0 ce probl\xE8me : "),l=u(N,"CODE",{});var Ts=p(l);v=a(Ts,"to_tf_dataset()"),Ts.forEach(t),j=a(N,".  Cette m\xE9thode va passer "),h=u(N,"CODE",{});var ce=p(h);_=a(ce,"tf.data.Dataset"),ce.forEach(t),y=a(N," sur votre dataset, avec une fonction d\u2019assemblage optionnelle. "),q=u(N,"CODE",{});var Ss=p(q);P=a(Ss,"tf.data.Dataset"),Ss.forEach(t),L=a(N," est un format natif de Tensorflow que Keras peut utiliser avec "),O=u(N,"CODE",{});var Ns=p(O);C=a(Ns,"model.fit()"),Ns.forEach(t),M=a(N,", donc cette m\xE9thode \xE0 elle seule convertit un dataset de \u{1F917} \xE0 un format pr\xEAt pour l\u2019entra\xEEnement. Voyons la \xE0 l\u2019\u0153uvre avec notre dataset!"),N.forEach(t),H=f(D),$(S.$$.fragment,D),W=f(D),K=u(D,"P",{});var Ge=p(K);pe=a(Ge,"Et c\u2019est tout! Nous pouvons utiliser ces datasets dans le prochain cours, o\xF9 l\u2019entra\xEEnement va \xEAtre agr\xE9ablement facile apr\xE8s tout le difficile travail de pr\xE9processing."),Ge.forEach(t)},m(D,N){c(D,r,N),s(r,d),s(r,l),s(l,v),s(r,j),s(r,h),s(h,_),s(r,y),s(r,q),s(q,P),s(r,L),s(r,O),s(O,C),s(r,M),c(D,H,N),x(S,D,N),c(D,W,N),c(D,K,N),s(K,pe),ze=!0},i(D){ze||(b(S.$$.fragment,D),ze=!0)},o(D){g(S.$$.fragment,D),ze=!1},d(D){D&&t(r),D&&t(H),E(S,D),D&&t(W),D&&t(K)}}}function hp(z){let r,d,l,v,j,h,_,y,q,P,L,O,C,M,H,S,W,K,pe,ze,D,N,Ts,ce,Ss,Ns,Ge,ke,we,it,Qe,Ia,ut,Ha,xn,te,ne,Os,Y,Wa,Je,Ba,Va,Ke,Ua,Ga,Ye,Qa,Ja,En,As,Ka,zn,Ze,wn,Xe,yn,B,Ya,pt,Za,Xa,ct,er,sr,dt,tr,nr,mt,ar,rr,ft,lr,or,Cn,de,ir,ht,ur,pr,_t,cr,dr,Pn,ye,mr,vt,fr,hr,Dn,es,Tn,ss,Sn,me,_r,bt,vr,br,gt,gr,qr,Nn,ts,On,ns,An,R,jr,qt,kr,$r,jt,xr,Er,kt,zr,wr,$t,yr,Cr,xt,Pr,Dr,Et,Tr,Sr,zt,Nr,Or,Ln,Ce,Mn,$e,Pe,wt,as,Ar,yt,Lr,Rn,ae,re,Ls,De,Mr,Ms,Rr,Fr,Fn,rs,In,Rs,Ir,Hn,ls,Wn,os,Bn,G,Hr,Ct,Wr,Br,Pt,Vr,Ur,Fs,Gr,Qr,Dt,Jr,Kr,Vn,Te,Un,Se,Yr,Tt,Zr,Xr,Gn,is,Qn,Is,el,Jn,us,Kn,fe,sl,St,tl,nl,Nt,al,rl,Yn,ps,Zn,Q,ll,Ot,ol,il,At,ul,pl,Lt,cl,dl,Mt,ml,fl,Xn,Ne,hl,Rt,_l,vl,ea,Z,bl,Hs,gl,ql,Ft,jl,kl,It,$l,xl,sa,Ws,El,ta,Oe,zl,Ht,wl,yl,na,he,Cl,Bs,Pl,Dl,Vs,Tl,Sl,aa,cs,ra,J,Nl,Wt,Ol,Al,Bt,Ll,Ml,Vt,Rl,Fl,ds,Il,Hl,la,_e,Wl,ms,Ut,Bl,Vl,Gt,Ul,Gl,oa,fs,ia,A,Ql,Qt,Jl,Kl,Jt,Yl,Zl,Kt,Xl,eo,Yt,so,to,Zt,no,ao,Xt,ro,lo,en,oo,io,hs,uo,po,ua,Ae,co,sn,mo,fo,pa,ve,ho,tn,_o,vo,nn,bo,go,ca,_s,da,Us,qo,ma,vs,fa,be,jo,an,ko,$o,rn,xo,Eo,ha,V,zo,ln,wo,yo,on,Co,Po,un,Do,To,pn,So,No,cn,Oo,Ao,_a,Le,Lo,dn,Mo,Ro,va,xe,Me,mn,bs,Fo,fn,Io,ba,gs,ga,Gs,Re,Ho,hn,Wo,Bo,qa,le,oe,Qs,X,Vo,_n,Uo,Go,vn,Qo,Jo,bn,Ko,Yo,ja,qs,ka,js,$a,Fe,Zo,gn,Xo,ei,xa,ks,Ea,ie,ue,Js,Ie,za,Ks,wa;l=new Yu({props:{fw:z[0]}}),y=new Fa({});const ti=[Xu,Zu],$s=[];function ni(e,o){return e[0]==="pt"?0:1}C=ni(z),M=$s[C]=ti[C](z);const ai=[sp,ep],xs=[];function ri(e,o){return e[0]==="pt"?0:1}S=ri(z),W=xs[S]=ai[S](z),Qe=new Fa({});const li=[np,tp],Es=[];function oi(e,o){return e[0]==="pt"?0:1}te=oi(z),ne=Es[te]=li[te](z),Ze=new T({props:{code:`from datasets import load_dataset

raw_datasets = load_dataset("glue", "mrpc")
raw_datasets`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
raw_datasets`}}),Xe=new T({props:{code:`DatasetDict({
    train: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx'],
        num_rows: 3668
    })
    validation: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx'],
        num_rows: 408
    })
    test: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx'],
        num_rows: 1725
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>],
        num_rows: <span class="hljs-number">3668</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>],
        num_rows: <span class="hljs-number">408</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>],
        num_rows: <span class="hljs-number">1725</span>
    })
})`}}),es=new T({props:{code:`raw_train_dataset = raw_datasets["train"]
raw_train_dataset[0]`,highlighted:`raw_train_dataset = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>]
raw_train_dataset[<span class="hljs-number">0</span>]`}}),ss=new T({props:{code:`{'idx': 0,
 'label': 1,
 'sentence1': 'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .',
 'sentence2': 'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .'}`,highlighted:`{<span class="hljs-string">&#x27;idx&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">1</span>,
 <span class="hljs-string">&#x27;sentence1&#x27;</span>: <span class="hljs-string">&#x27;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .&#x27;</span>,
 <span class="hljs-string">&#x27;sentence2&#x27;</span>: <span class="hljs-string">&#x27;Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#x27;</span>}`}}),ts=new T({props:{code:"raw_train_dataset.features",highlighted:"raw_train_dataset.features"}}),ns=new T({props:{code:`{'sentence1': Value(dtype='string', id=None),
 'sentence2': Value(dtype='string', id=None),
 'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], names_file=None, id=None),
 'idx': Value(dtype='int32', id=None)}`,highlighted:`{<span class="hljs-string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
 <span class="hljs-string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
 <span class="hljs-string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="hljs-number">2</span>, names=[<span class="hljs-string">&#x27;not_equivalent&#x27;</span>, <span class="hljs-string">&#x27;equivalent&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
 <span class="hljs-string">&#x27;idx&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int32&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}`}}),Ce=new si({props:{$$slots:{default:[ap]},$$scope:{ctx:z}}}),as=new Fa({});const ii=[lp,rp],zs=[];function ui(e,o){return e[0]==="pt"?0:1}ae=ui(z),re=zs[ae]=ii[ae](z),rs=new T({props:{code:`from transformers import AutoTokenizer

checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
tokenized_sentences_1 = tokenizer(raw_datasets["train"]["sentence1"])
tokenized_sentences_2 = tokenizer(raw_datasets["train"]["sentence2"])`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

checkpoint = <span class="hljs-string">&quot;bert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
tokenized_sentences_1 = tokenizer(raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;sentence1&quot;</span>])
tokenized_sentences_2 = tokenizer(raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;sentence2&quot;</span>])`}}),ls=new T({props:{code:`inputs = tokenizer("This is the first sentence.", "This is the second one.")
inputs`,highlighted:`inputs = tokenizer(<span class="hljs-string">&quot;This is the first sentence.&quot;</span>, <span class="hljs-string">&quot;This is the second one.&quot;</span>)
inputs`}}),os=new T({props:{code:`{ 
  'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102],
  'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],
  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
}`,highlighted:`{ 
  <span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">2023</span>, <span class="hljs-number">2003</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2034</span>, <span class="hljs-number">6251</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>, <span class="hljs-number">2023</span>, <span class="hljs-number">2003</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2117</span>, <span class="hljs-number">2028</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>],
  <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
  <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
}`}}),Te=new si({props:{$$slots:{default:[op]},$$scope:{ctx:z}}}),is=new T({props:{code:'tokenizer.convert_ids_to_tokens(inputs["input_ids"])',highlighted:'tokenizer.convert_ids_to_tokens(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])'}}),us=new T({props:{code:"['[CLS]', 'this', 'is', 'the', 'first', 'sentence', '.', '[SEP]', 'this', 'is', 'the', 'second', 'one', '.', '[SEP]']",highlighted:'[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;first&#x27;</span>, <span class="hljs-string">&#x27;sentence&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;second&#x27;</span>, <span class="hljs-string">&#x27;one&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]'}}),ps=new T({props:{code:`['[CLS]', 'this', 'is', 'the', 'first', 'sentence', '.', '[SEP]', 'this', 'is', 'the', 'second', 'one', '.', '[SEP]']
[      0,      0,    0,     0,       0,          0,   0,       0,      1,    1,     1,        1,     1,   1,       1]`,highlighted:`[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;first&#x27;</span>, <span class="hljs-string">&#x27;sentence&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;second&#x27;</span>, <span class="hljs-string">&#x27;one&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]
[      <span class="hljs-number">0</span>,      <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,       <span class="hljs-number">0</span>,          <span class="hljs-number">0</span>,   <span class="hljs-number">0</span>,       <span class="hljs-number">0</span>,      <span class="hljs-number">1</span>,    <span class="hljs-number">1</span>,     <span class="hljs-number">1</span>,        <span class="hljs-number">1</span>,     <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,       <span class="hljs-number">1</span>]`}}),cs=new T({props:{code:`tokenized_dataset = tokenizer(
    raw_datasets["train"]["sentence1"],
    raw_datasets["train"]["sentence2"],
    padding=True,
    truncation=True,
)`,highlighted:`tokenized_dataset = tokenizer(
    raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;sentence1&quot;</span>],
    raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;sentence2&quot;</span>],
    padding=<span class="hljs-literal">True</span>,
    truncation=<span class="hljs-literal">True</span>,
)`}}),fs=new T({props:{code:`def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> tokenizer(example[<span class="hljs-string">&quot;sentence1&quot;</span>], example[<span class="hljs-string">&quot;sentence2&quot;</span>], truncation=<span class="hljs-literal">True</span>)`}}),_s=new T({props:{code:`tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
tokenized_datasets`,highlighted:`tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)
tokenized_datasets`}}),vs=new T({props:{code:`DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],
        num_rows: 3668
    })
    validation: Dataset({
        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],
        num_rows: 408
    })
    test: Dataset({
        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],
        num_rows: 1725
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>],
        num_rows: <span class="hljs-number">3668</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>],
        num_rows: <span class="hljs-number">408</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>],
        num_rows: <span class="hljs-number">1725</span>
    })
})`}}),bs=new Fa({}),gs=new $n({props:{id:"7q5NyFT8REg"}});function pi(e,o){return e[0]==="pt"?up:ip}let ya=pi(z),Ee=ya(z);const ci=[cp,pp],ws=[];function di(e,o){return e[0]==="pt"?0:1}le=di(z),oe=ws[le]=ci[le](z),qs=new T({props:{code:`samples = tokenized_datasets["train"][:8]
samples = {k: v for k, v in samples.items() if k not in ["idx", "sentence1", "sentence2"]}
[len(x) for x in samples["input_ids"]]`,highlighted:`samples = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][:<span class="hljs-number">8</span>]
samples = {k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> samples.items() <span class="hljs-keyword">if</span> k <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;idx&quot;</span>, <span class="hljs-string">&quot;sentence1&quot;</span>, <span class="hljs-string">&quot;sentence2&quot;</span>]}
[<span class="hljs-built_in">len</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> samples[<span class="hljs-string">&quot;input_ids&quot;</span>]]`}}),js=new T({props:{code:"[50, 59, 47, 67, 59, 50, 62, 32]",highlighted:'[<span class="hljs-number">50</span>, <span class="hljs-number">59</span>, <span class="hljs-number">47</span>, <span class="hljs-number">67</span>, <span class="hljs-number">59</span>, <span class="hljs-number">50</span>, <span class="hljs-number">62</span>, <span class="hljs-number">32</span>]'}}),ks=new T({props:{code:`batch = data_collator(samples)
{k: v.shape for k, v in batch.items()}`,highlighted:`batch = data_collator(samples)
{k: v.shape <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}`}});const mi=[mp,dp],ys=[];function fi(e,o){return e[0]==="tf"?0:1}ie=fi(z),ue=ys[ie]=mi[ie](z),Ie=new si({props:{$$slots:{default:[fp]},$$scope:{ctx:z}}});let F=z[0]==="tf"&&Bu();return{c(){r=i("meta"),d=m(),k(l.$$.fragment),v=m(),j=i("h1"),h=i("a"),_=i("span"),k(y.$$.fragment),q=m(),P=i("span"),L=n("Pr\xE9parer les donn\xE9es"),O=m(),M.c(),H=m(),W.c(),K=m(),pe=i("p"),ze=n("Evidemment, entra\xEEner un mod\xE8le avec seulement deux phrases ne va pas donner de bons r\xE9sultats. Pour obtenir de meilleurs r\xE9sultats, vous allez avoir \xE0 pr\xE9parer un plus grand jeu de donn\xE9es."),D=m(),N=i("p"),Ts=n("Dans cette section, nous allons utiliser comme exemple le jeu de donn\xE9es (dataset) MRPC (Microsoft Research Paraphrase Corpus) pr\xE9sent\xE9 dans un "),ce=i("a"),Ss=n("papier"),Ns=n(" de William B. Dolan et Chris Brockett. Ce jeu de donn\xE9es contient 5801 paires de phrases avec un label indiquant si ces paires sont des paraphrases ou non (i.e. si elles ont la m\xEAme signification). Nous l\u2019avons choisi pour ce chapitre parce que c\u2019est un petit jeu de donn\xE9es, et cela rend donc facile les exp\xE9riences d\u2019entra\xEEnement sur ce dataset."),Ge=m(),ke=i("h3"),we=i("a"),it=i("span"),k(Qe.$$.fragment),Ia=m(),ut=i("span"),Ha=n("Charger un jeu de donn\xE9es depuis le Hub"),xn=m(),ne.c(),Os=m(),Y=i("p"),Wa=n("Le hub ne contient pas juste des mod\xE8les; il contient aussi plusieurs jeux de donn\xE9es dans un tas de langages diff\xE9rents. Vous pouvez explorer les jeux de donn\xE9es "),Je=i("a"),Ba=n("ici"),Va=n(", et nous vous conseillons d\u2019essayer de charger un nouveau jeu de donn\xE9es une fois que vous avez \xE9tudi\xE9 cette section (voir la documentation g\xE9n\xE9rale "),Ke=i("a"),Ua=n("ici"),Ga=n("). Mais pour l\u2019instant, concentrons nous sur le jeu de donn\xE9es MRPC! Il s\u2019agit de l\u2019un des 10 jeux de donn\xE9es qui constituent le "),Ye=i("a"),Qa=n("benchmark GLUE"),Ja=n(" qui est un benchmark acad\xE9mique utilis\xE9 pour mesurer les performances des mod\xE8les de Machine Learning sur 10 t\xE2ches de classification de textes."),En=m(),As=i("p"),Ka=n("La librairie de datasets de \u{1F917} propose une commande tr\xE8s simple pour t\xE9l\xE9charger et mettre en cache un jeu de donn\xE9es \xE0 partir du Hub. On peut t\xE9l\xE9charger le jeu de donn\xE9es MRPC comme ceci :"),zn=m(),k(Ze.$$.fragment),wn=m(),k(Xe.$$.fragment),yn=m(),B=i("p"),Ya=n("Comme vous le voyez, on obtient un objet de type "),pt=i("code"),Za=n("DatasetDict"),Xa=n(" qui contient le jeu de donn\xE9es d\u2019entra\xEEnement, celui de validation et celui de test. Chacun d\u2019eux contient plusieurs colonnes ("),ct=i("code"),er=n("sentence1"),sr=n(", "),dt=i("code"),tr=n("sentence2"),nr=n(", "),mt=i("code"),ar=n("label"),rr=n(" et "),ft=i("code"),lr=n("idx"),or=n(") et une variable nombre de lignes qui contient le nombre d\u2019\xE9l\xE9ments dans chaque jeu de donn\xE9es (il y a donc 3.668 paires de phrases dans le jeu d\u2019entra\xEEnement, 408 dans celui de validation et 1.725 dans celui de test)."),Cn=m(),de=i("p"),ir=n("Cette commande t\xE9l\xE9charge et met en cache le jeu de donn\xE9es dans "),ht=i("em"),ur=n("~/.cache/huggingface/dataset"),pr=n(". Rappelez-vous que comme vu au chapitre 2, vous pouvez personnaliser votre dossier cache en modifiant la variable d\u2019environnement "),_t=i("code"),cr=n("HF_HOME"),dr=n("."),Pn=m(),ye=i("p"),mr=n("Nous pouvons acc\xE9der \xE0 chaque paire de phrase de notre objet "),vt=i("code"),fr=n("raw_datasets"),hr=n(" par les indices, comme avec un dictionnaire :"),Dn=m(),k(es.$$.fragment),Tn=m(),k(ss.$$.fragment),Sn=m(),me=i("p"),_r=n("Nous pouvons voir que les labels sont d\xE9j\xE0 des entiers, nous n\u2019avons donc aucun preprocessing \xE0 faire sur les labels. Pour savoir quel entier correspond \xE0 quel label, on peut inspecter les "),bt=i("code"),vr=n("features"),br=n(" de notre "),gt=i("code"),gr=n("raw_train_dataset"),qr=n(". Cela nous dira le type de chaque colonne :"),Nn=m(),k(ts.$$.fragment),On=m(),k(ns.$$.fragment),An=m(),R=i("p"),jr=n("En r\xE9alit\xE9, "),qt=i("code"),kr=n("label"),$r=n(" est de type "),jt=i("code"),xr=n("ClassLabel"),Er=n(", et la correspondance des entiers aux noms des labels est enregistr\xE9e le dossier "),kt=i("em"),zr=n("names"),wr=n(". "),$t=i("code"),yr=n("0"),Cr=n(" correspond \xE0  "),xt=i("code"),Pr=n("not_equivalent"),Dr=n(" (pas \xE9quivalent), et "),Et=i("code"),Tr=n("1"),Sr=n(" correspond \xE0 "),zt=i("code"),Nr=n("equivalent"),Or=n("."),Ln=m(),k(Ce.$$.fragment),Mn=m(),$e=i("h3"),Pe=i("a"),wt=i("span"),k(as.$$.fragment),Ar=m(),yt=i("span"),Lr=n("Preprocessing d'un jeu de donn\xE9e"),Rn=m(),re.c(),Ls=m(),De=i("p"),Mr=n("Pour pr\xE9traiter l\u2019ensemble de donn\xE9es, nous devons convertir le texte en nombres que le mod\xE8le peut comprendre. Comme vous l\u2019avez vu dans le "),Ms=i("a"),Rr=n("chapitre pr\xE9c\xE9dent"),Fr=n(", cela se fait avec un tokenizer. Nous pouvons passer au tokenizer une phrase ou une liste de phrases, ainsi nous pouvons directement tokeniser toutes les premi\xE8res phrases et toutes les deuxi\xE8mes phrases de chaque paire comme ceci :"),Fn=m(),k(rs.$$.fragment),In=m(),Rs=i("p"),Ir=n("N\xE9anmoins, nous ne pouvons pas simplement transmettre deux s\xE9quences au mod\xE8le et obtenir une pr\xE9diction indiquant si les deux phrases sont des paraphrases ou non. Nous devons g\xE9rer les deux s\xE9quences comme une paire et appliquer le pr\xE9traitement appropri\xE9. Heureusement, le tokenizer peut \xE9galement prendre une paire de s\xE9quences et la mettre dans le format attendu par notre mod\xE8le BERT\xA0:"),Hn=m(),k(ls.$$.fragment),Wn=m(),k(os.$$.fragment),Bn=m(),G=i("p"),Hr=n("Nous avons vu les cl\xE9s "),Ct=i("code"),Wr=n("input_ids"),Br=n(" et "),Pt=i("code"),Vr=n("attention_mask"),Ur=n(" au "),Fs=i("a"),Gr=n("chapitre 2"),Qr=n(", mais nous avons omis de parler des "),Dt=i("code"),Jr=n("token_type_ids"),Kr=n(". Dans cet exemple, c\u2019est ce qui indique au mod\xE8le quelle partie de l\u2019entr\xE9e repr\xE9sente la premi\xE8re phrase et quelle partie repr\xE9sente la deuxi\xE8me phrase."),Vn=m(),k(Te.$$.fragment),Un=m(),Se=i("p"),Yr=n("Si nous d\xE9codons les IDs contenus dans "),Tt=i("code"),Zr=n("input_ids"),Xr=n(" pour r\xE9obtenir des mots :"),Gn=m(),k(is.$$.fragment),Qn=m(),Is=i("p"),el=n("Nous obtiendrons :"),Jn=m(),k(us.$$.fragment),Kn=m(),fe=i("p"),sl=n("Nous pouvons donc voir que le mod\xE8le attend une entr\xE9e de la forme  "),St=i("code"),tl=n("[CLS] sentence1 [SEP] sentence2 [SEP]"),nl=n(" lorsqu\u2019il y a deux phrases. Aligner cette repr\xE9sentation avec "),Nt=i("code"),al=n("token_type_ids"),rl=n(" nous donne :"),Yn=m(),k(ps.$$.fragment),Zn=m(),Q=i("p"),ll=n("Comme vous pouvez le voir, les parties correspondant \xE0 "),Ot=i("code"),ol=n("[CLS] sentence1 [SEP]"),il=n(" ont toutes "),At=i("code"),ul=n("0"),pl=n(" comme ID de type de token, alors que les autres parties qui correspondent \xE0 "),Lt=i("code"),cl=n("sentence2 [SEP]"),dl=n(", ont toute "),Mt=i("code"),ml=n("1"),fl=n(" comme ID de type de token."),Xn=m(),Ne=i("p"),hl=n("Notez que si vous s\xE9lectionnez un checkpoint diff\xE9rent, vous n\u2019aurez pas n\xE9cessairement les "),Rt=i("code"),_l=n("token_type_ids"),vl=n(" dans vos entr\xE9es tokenis\xE9es (par exemple, ils ne sont pas retourn\xE9s lorsque vous utilisez le mod\xE8le DistilBERT). Ils ne sont renvoy\xE9s que lorsque le mod\xE8le sait les utiliser, pour les avoir vu pendant le pr\xE9-entra\xEEnement."),ea=m(),Z=i("p"),bl=n("Ici, BERT est pr\xE9-entra\xEEn\xE9 avec des IDs de type de token, et en plus de la fonction de co\xFBt MLM (Masked Language Modelling) dont nous avons parl\xE9 au "),Hs=i("a"),gl=n("chapitre 1"),ql=n(", il a un co\xFBt suppl\xE9mentaire appel\xE9 "),Ft=i("em"),jl=n("pr\xE9diction de la phrase suivante"),kl=n("("),It=i("em"),$l=n("next sentence prediction"),xl=n("). Le but de cette t\xE2che est de mod\xE9liser la relation entre des paires de phrases."),sa=m(),Ws=i("p"),El=n("Pour la pr\xE9diction de la phrase suivante, le mod\xE8le re\xE7oit des paires de phrases (avec des tokens masqu\xE9s de mani\xE8re al\xE9atoire) et on lui demande de pr\xE9dire si la deuxi\xE8me phrase suit la premi\xE8re. Pour rendre la t\xE2che non triviale, la moiti\xE9 du temps les phrases se suivent dans le document original dont elles sont extraites, et l\u2019autre moiti\xE9 du temps les deux phrases proviennent de deux documents diff\xE9rents."),ta=m(),Oe=i("p"),zl=n("En g\xE9n\xE9ral, vous n\u2019avez pas \xE0 vous soucier de savoir s\u2019il y a ou non des "),Ht=i("code"),wl=n("token_type_ids"),yl=n(" dans vos entr\xE9es tokenis\xE9es\xA0: tant que vous utilisez le m\xEAme checkpoint pour le tokenizer et le mod\xE8le, tout ira bien car le tokenizer sait quoi fournir \xE0 son mod\xE8le."),na=m(),he=i("p"),Cl=n("Maintenant que nous avons vu comment notre tokenizer peut traiter une paire de phrases, nous pouvons l\u2019utiliser pour tokeniser l\u2019ensemble de nos donn\xE9es\xA0: comme dans le "),Bs=i("a"),Pl=n("chapitre pr\xE9c\xE9dent"),Dl=n(", nous pouvons fournir au tokenizer une liste de paires de phrases en lui donnant la liste des premi\xE8res phrases, puis la liste des secondes phrases. Ceci est \xE9galement compatible avec les options de padding et de troncature que nous avons vues au "),Vs=i("a"),Tl=n("chapitre 2"),Sl=n(". Ainsi, une fa\xE7on de pr\xE9traiter l\u2019ensemble de donn\xE9es d\u2019entra\xEEnement est\xA0:"),aa=m(),k(cs.$$.fragment),ra=m(),J=i("p"),Nl=n("Cela marche bien, mais a le d\xE9savantage de retourner un dictionnaire (avec nos cl\xE9s, "),Wt=i("code"),Ol=n("input_ids"),Al=n(", "),Bt=i("code"),Ll=n("attention_mask"),Ml=n(" et "),Vt=i("code"),Rl=n("token_type_ids"),Fl=n(", et des valeurs qui sont des listes de listes). Cela ne marchera que si vous avez assez de RAM pour contenir tout le jeu de donn\xE9es pendant la tokenisation (tandis que les jeux de donn\xE9es de la librairie de \u{1F917} sont des fichiers "),ds=i("a"),Il=n("Apache Arrow"),Hl=n(" charg\xE9es sur le disque, de sorte que vous ne gardez que les exemples dont vous avez besoin en m\xE9moire )"),la=m(),_e=i("p"),Wl=n("Pour garder les donn\xE9es sous forme de dataset (jeu de donn\xE9es), nous allons utiliser la m\xE9thode "),ms=i("a"),Ut=i("code"),Bl=n("Dataset.map()"),Vl=n(". Cela nous permet d\u2019avoir plus de flexibilit\xE9 si nous avons besoin de faire plus que juste tokeniser pendant la phase de pr\xE9-tra\xEEtement. La m\xE9thode "),Gt=i("code"),Ul=n("map()"),Gl=n(" fonctionne en applicant une fonction \xE0 chaque \xE9l\xE9ment du dataset, d\xE9finissons alors une fonction qui tokenise nos entr\xE9es :"),oa=m(),k(fs.$$.fragment),ia=m(),A=i("p"),Ql=n("Cette prend en entr\xE9e un dictionnaire (comme les items de notre dataset) and renvioe un nouveau dictionnaire avec les cl\xE9s "),Qt=i("code"),Jl=n("input_ids"),Kl=n(", "),Jt=i("code"),Yl=n("attention_mask"),Zl=n(" et "),Kt=i("code"),Xl=n("token_type_ids"),eo=n(". Notez que cela marche aussi si le dictionnaire "),Yt=i("code"),so=n("example"),to=n(" contient plusieurs exemples puisque le tokenizer fonctionne aussi sur des listes de paires de phrases, comme nous l\u2019avons vu pr\xE9c\xE9demment. Cela permettra d\u2019utiliser l\u2019option "),Zt=i("code"),no=n("batched=True"),ao=n(" dans notre appel de la m\xE9thode "),Xt=i("code"),ro=n("map()"),lo=n(", ce qui permettra d\u2019acc\xE9l\xE9rer la tokenisation.  Le "),en=i("code"),oo=n("tokenizer"),io=n(" est aid\xE9 par  un tokenizer \xE9crit en Rust  provenant de la librairie "),hs=i("a"),uo=n("Tokenizers"),po=n(" de \u{1F917}. Ce tokenizer peut \xEAtre tr\xE8s rapide, mais seulement si on lui donne beaucoup d\u2019entr\xE9es en m\xEAme temps."),ua=m(),Ae=i("p"),co=n("Notez que nous avons ignorer l\u2019argument "),sn=i("code"),mo=n("padding"),fo=n(" dans notre fonction de tokenisation pour l\u2019instant. Ceci parce que faire le padding de tous les exemples \xE0 la longueur maximale n\u2019est pas efficace : il vaut mieux faire le padding lorsque nous construisons un batch, puisque dans ce cas nous allons seulement faire le padding pour la longueur maximale dans ce batch, et non pour la longueur maximale de tout le dataset. Cela permet d\u2019\xE9conomiser beaucoup de temps et de puissance de calcul lorsqu\u2019on traite des entr\xE9es avec des longueurs tr\xE9s vari\xE9es!"),pa=m(),ve=i("p"),ho=n("Voil\xE0 comment on applique la fonction de tokenisation \xE0 tous nos datasets en m\xEAme temps. Nous utilisons "),tn=i("code"),_o=n("batched=True"),vo=n(" dans notre appel de "),nn=i("code"),bo=n("map"),go=n(" pour que la fonction soit appliqu\xE9e \xE0 plusieurs \xE9l\xE9ments de notre dataset en m\xEAme temps, et non sur chaque \xE9l\xE9ment s\xE9par\xE9ment. Cela permet d\u2019avoir un pr\xE9-tra\xEEtement plus rapide."),ca=m(),k(_s.$$.fragment),da=m(),Us=i("p"),qo=n("La librairie Datasets de \u{1F917} applique le processing en ajoutant de nouveaux champs aux datasets, un nouveau pour chaque cl\xE9 retourn\xE9e par la fonction de preprocessing :"),ma=m(),k(vs.$$.fragment),fa=m(),be=i("p"),jo=n("Vous pouvez m\xEAme utiliser le multiprocessing en appliquant votre pr\xE9-tra\xEEtement avec "),an=i("code"),ko=n("map()"),$o=n(" en lui passant l\u2019argument "),rn=i("code"),xo=n("num_proc"),Eo=n(". Nous ne l\u2019avons pas utilis\xE9 ici parce que la librairie Tokenizers de \u{1F917} utilise plusieurs threads pour tokeniser nos exemples plus rapidement, mais si vous n\u2019utilisez pas de tokenizer rapide qui s\u2019aide de cette librairie, cela pourrait acc\xE9l\xE9rer votre pr\xE9-tra\xEEtement."),ha=m(),V=i("p"),zo=n("Notre "),ln=i("code"),wo=n("tokenize_function"),yo=n(" retourne un dictionnaire avec les cl\xE9s "),on=i("code"),Co=n("input_ids"),Po=n(", "),un=i("code"),Do=n("attention_mask"),To=n(" et "),pn=i("code"),So=n("token_type_ids"),No=n(", donc ces trois champs sont ajout\xE9s \xE0 toutes les parties (entra\xEEnement, validation et test) de notre dataset. Notez que nous aurions aussi pu changer des champs existants si notre pr\xE9-tra\xEEtement retournait une nouvelle valeur pour une cl\xE9 qui existait d\xE9j\xE0 dans le dataset sur lequel nous avons appel\xE9 "),cn=i("code"),Oo=n("map()"),Ao=n("."),_a=m(),Le=i("p"),Lo=n("La derni\xE8re chose que nous aurons besoin de faire est le padding de tous les \xE9l\xE9ments pour que leur longueur atteigne la longueur de la plus longue s\xE9quence du batch lorsque nous construisons les batchs \u2014 une technique que nous appelons "),dn=i("em"),Mo=n("padding dynamique"),Ro=n("."),va=m(),xe=i("h3"),Me=i("a"),mn=i("span"),k(bs.$$.fragment),Fo=m(),fn=i("span"),Io=n("Padding dynamique"),ba=m(),k(gs.$$.fragment),ga=m(),Ee.c(),Gs=m(),Re=i("p"),Ho=n("En pratique, pour faire cela, on utilise une fonction d\u2019assemblage qui va mettre la bonne quantit\xE9 de padding aux \xE9l\xE9ments du dataset que nous mettre ensemble pour former un batch.  Heureusement,  la librairie Transformers de \u{1F917} fournit une telle fonction via  "),hn=i("code"),Wo=n("DataCollatorWithPadding"),Bo=n(". Elle prend un tokenizer lorsqu\u2019on l\u2019instancie (pour savoir quel token utiliser pour le padding, et aussi s\u2019il faut faire le padding \xE0 gauche ou \xE0 droite en fonction des attentes du  mod\xE8le) et va faire le n\xE9cessaire:"),qa=m(),oe.c(),Qs=m(),X=i("p"),Vo=n("Pour tester notre nouveau jouet, prenons quelques \xE9l\xE9ments de notre jeu d\u2019entra\xEEnement avec lesquels nous allons former un batch. Ici, on supprime les colonnes "),_n=i("code"),Uo=n("idx"),Go=n(", "),vn=i("code"),Qo=n("sentence1"),Jo=n(" et "),bn=i("code"),Ko=n("sentence2"),Yo=n(" puisque nous n\u2019en aurons pas besoin et qu\u2019elles contiennent des strings ( et nous ne pouvons pas cr\xE9er des tensors avec des strings) et on regarde la longueur de chaque entr\xE9e du batch :"),ja=m(),k(qs.$$.fragment),ka=m(),k(js.$$.fragment),$a=m(),Fe=i("p"),Zo=n("Sans surprise, nous obtenons des \xE9l\xE9ments de longueurs diff\xE9rentes, allant de 32 \xE0 67. Le padding dynamique signifie que nous allons utiliser le padding sur tous les \xE9l\xE9ments du batch pour obtenir une longueur de 67, la longueur maximale pour ce batch. Sans le padding dynamique, on appliquerait un padding \xE0 tous les \xE9l\xE9ments pour atteindre la longueur maximale de tout le dataset, ou la longueur maximale que le mod\xE8le peut accepter. V\xE9rifions que notre "),gn=i("code"),Xo=n("data_collator"),ei=n(" effectue correctement le padding dynamique :"),xa=m(),k(ks.$$.fragment),Ea=m(),ue.c(),Js=m(),k(Ie.$$.fragment),za=m(),F&&F.c(),Ks=Wu(),this.h()},l(e){const o=Ju('[data-svelte="svelte-1phssyn"]',document.head);r=u(o,"META",{name:!0,content:!0}),o.forEach(t),d=f(e),$(l.$$.fragment,e),v=f(e),j=u(e,"H1",{class:!0});var Cs=p(j);h=u(Cs,"A",{id:!0,class:!0,href:!0});var Ys=p(h);_=u(Ys,"SPAN",{});var Zs=p(_);$(y.$$.fragment,Zs),Zs.forEach(t),Ys.forEach(t),q=f(Cs),P=u(Cs,"SPAN",{});var Xs=p(P);L=a(Xs,"Pr\xE9parer les donn\xE9es"),Xs.forEach(t),Cs.forEach(t),O=f(e),M.l(e),H=f(e),W.l(e),K=f(e),pe=u(e,"P",{});var qn=p(pe);ze=a(qn,"Evidemment, entra\xEEner un mod\xE8le avec seulement deux phrases ne va pas donner de bons r\xE9sultats. Pour obtenir de meilleurs r\xE9sultats, vous allez avoir \xE0 pr\xE9parer un plus grand jeu de donn\xE9es."),qn.forEach(t),D=f(e),N=u(e,"P",{});var He=p(N);Ts=a(He,"Dans cette section, nous allons utiliser comme exemple le jeu de donn\xE9es (dataset) MRPC (Microsoft Research Paraphrase Corpus) pr\xE9sent\xE9 dans un "),ce=u(He,"A",{href:!0,rel:!0});var jn=p(ce);Ss=a(jn,"papier"),jn.forEach(t),Ns=a(He," de William B. Dolan et Chris Brockett. Ce jeu de donn\xE9es contient 5801 paires de phrases avec un label indiquant si ces paires sont des paraphrases ou non (i.e. si elles ont la m\xEAme signification). Nous l\u2019avons choisi pour ce chapitre parce que c\u2019est un petit jeu de donn\xE9es, et cela rend donc facile les exp\xE9riences d\u2019entra\xEEnement sur ce dataset."),He.forEach(t),Ge=f(e),ke=u(e,"H3",{class:!0});var We=p(ke);we=u(We,"A",{id:!0,class:!0,href:!0});var et=p(we);it=u(et,"SPAN",{});var kn=p(it);$(Qe.$$.fragment,kn),kn.forEach(t),et.forEach(t),Ia=f(We),ut=u(We,"SPAN",{});var hi=p(ut);Ha=a(hi,"Charger un jeu de donn\xE9es depuis le Hub"),hi.forEach(t),We.forEach(t),xn=f(e),ne.l(e),Os=f(e),Y=u(e,"P",{});var Be=p(Y);Wa=a(Be,"Le hub ne contient pas juste des mod\xE8les; il contient aussi plusieurs jeux de donn\xE9es dans un tas de langages diff\xE9rents. Vous pouvez explorer les jeux de donn\xE9es "),Je=u(Be,"A",{href:!0,rel:!0});var _i=p(Je);Ba=a(_i,"ici"),_i.forEach(t),Va=a(Be,", et nous vous conseillons d\u2019essayer de charger un nouveau jeu de donn\xE9es une fois que vous avez \xE9tudi\xE9 cette section (voir la documentation g\xE9n\xE9rale "),Ke=u(Be,"A",{href:!0,rel:!0});var vi=p(Ke);Ua=a(vi,"ici"),vi.forEach(t),Ga=a(Be,"). Mais pour l\u2019instant, concentrons nous sur le jeu de donn\xE9es MRPC! Il s\u2019agit de l\u2019un des 10 jeux de donn\xE9es qui constituent le "),Ye=u(Be,"A",{href:!0,rel:!0});var bi=p(Ye);Qa=a(bi,"benchmark GLUE"),bi.forEach(t),Ja=a(Be," qui est un benchmark acad\xE9mique utilis\xE9 pour mesurer les performances des mod\xE8les de Machine Learning sur 10 t\xE2ches de classification de textes."),Be.forEach(t),En=f(e),As=u(e,"P",{});var gi=p(As);Ka=a(gi,"La librairie de datasets de \u{1F917} propose une commande tr\xE8s simple pour t\xE9l\xE9charger et mettre en cache un jeu de donn\xE9es \xE0 partir du Hub. On peut t\xE9l\xE9charger le jeu de donn\xE9es MRPC comme ceci :"),gi.forEach(t),zn=f(e),$(Ze.$$.fragment,e),wn=f(e),$(Xe.$$.fragment,e),yn=f(e),B=u(e,"P",{});var ee=p(B);Ya=a(ee,"Comme vous le voyez, on obtient un objet de type "),pt=u(ee,"CODE",{});var qi=p(pt);Za=a(qi,"DatasetDict"),qi.forEach(t),Xa=a(ee," qui contient le jeu de donn\xE9es d\u2019entra\xEEnement, celui de validation et celui de test. Chacun d\u2019eux contient plusieurs colonnes ("),ct=u(ee,"CODE",{});var ji=p(ct);er=a(ji,"sentence1"),ji.forEach(t),sr=a(ee,", "),dt=u(ee,"CODE",{});var ki=p(dt);tr=a(ki,"sentence2"),ki.forEach(t),nr=a(ee,", "),mt=u(ee,"CODE",{});var $i=p(mt);ar=a($i,"label"),$i.forEach(t),rr=a(ee," et "),ft=u(ee,"CODE",{});var xi=p(ft);lr=a(xi,"idx"),xi.forEach(t),or=a(ee,") et une variable nombre de lignes qui contient le nombre d\u2019\xE9l\xE9ments dans chaque jeu de donn\xE9es (il y a donc 3.668 paires de phrases dans le jeu d\u2019entra\xEEnement, 408 dans celui de validation et 1.725 dans celui de test)."),ee.forEach(t),Cn=f(e),de=u(e,"P",{});var st=p(de);ir=a(st,"Cette commande t\xE9l\xE9charge et met en cache le jeu de donn\xE9es dans "),ht=u(st,"EM",{});var Ei=p(ht);ur=a(Ei,"~/.cache/huggingface/dataset"),Ei.forEach(t),pr=a(st,". Rappelez-vous que comme vu au chapitre 2, vous pouvez personnaliser votre dossier cache en modifiant la variable d\u2019environnement "),_t=u(st,"CODE",{});var zi=p(_t);cr=a(zi,"HF_HOME"),zi.forEach(t),dr=a(st,"."),st.forEach(t),Pn=f(e),ye=u(e,"P",{});var Ca=p(ye);mr=a(Ca,"Nous pouvons acc\xE9der \xE0 chaque paire de phrase de notre objet "),vt=u(Ca,"CODE",{});var wi=p(vt);fr=a(wi,"raw_datasets"),wi.forEach(t),hr=a(Ca," par les indices, comme avec un dictionnaire :"),Ca.forEach(t),Dn=f(e),$(es.$$.fragment,e),Tn=f(e),$(ss.$$.fragment,e),Sn=f(e),me=u(e,"P",{});var tt=p(me);_r=a(tt,"Nous pouvons voir que les labels sont d\xE9j\xE0 des entiers, nous n\u2019avons donc aucun preprocessing \xE0 faire sur les labels. Pour savoir quel entier correspond \xE0 quel label, on peut inspecter les "),bt=u(tt,"CODE",{});var yi=p(bt);vr=a(yi,"features"),yi.forEach(t),br=a(tt," de notre "),gt=u(tt,"CODE",{});var Ci=p(gt);gr=a(Ci,"raw_train_dataset"),Ci.forEach(t),qr=a(tt,". Cela nous dira le type de chaque colonne :"),tt.forEach(t),Nn=f(e),$(ts.$$.fragment,e),On=f(e),$(ns.$$.fragment,e),An=f(e),R=u(e,"P",{});var U=p(R);jr=a(U,"En r\xE9alit\xE9, "),qt=u(U,"CODE",{});var Pi=p(qt);kr=a(Pi,"label"),Pi.forEach(t),$r=a(U," est de type "),jt=u(U,"CODE",{});var Di=p(jt);xr=a(Di,"ClassLabel"),Di.forEach(t),Er=a(U,", et la correspondance des entiers aux noms des labels est enregistr\xE9e le dossier "),kt=u(U,"EM",{});var Ti=p(kt);zr=a(Ti,"names"),Ti.forEach(t),wr=a(U,". "),$t=u(U,"CODE",{});var Si=p($t);yr=a(Si,"0"),Si.forEach(t),Cr=a(U," correspond \xE0  "),xt=u(U,"CODE",{});var Ni=p(xt);Pr=a(Ni,"not_equivalent"),Ni.forEach(t),Dr=a(U," (pas \xE9quivalent), et "),Et=u(U,"CODE",{});var Oi=p(Et);Tr=a(Oi,"1"),Oi.forEach(t),Sr=a(U," correspond \xE0 "),zt=u(U,"CODE",{});var Ai=p(zt);Nr=a(Ai,"equivalent"),Ai.forEach(t),Or=a(U,"."),U.forEach(t),Ln=f(e),$(Ce.$$.fragment,e),Mn=f(e),$e=u(e,"H3",{class:!0});var Pa=p($e);Pe=u(Pa,"A",{id:!0,class:!0,href:!0});var Li=p(Pe);wt=u(Li,"SPAN",{});var Mi=p(wt);$(as.$$.fragment,Mi),Mi.forEach(t),Li.forEach(t),Ar=f(Pa),yt=u(Pa,"SPAN",{});var Ri=p(yt);Lr=a(Ri,"Preprocessing d'un jeu de donn\xE9e"),Ri.forEach(t),Pa.forEach(t),Rn=f(e),re.l(e),Ls=f(e),De=u(e,"P",{});var Da=p(De);Mr=a(Da,"Pour pr\xE9traiter l\u2019ensemble de donn\xE9es, nous devons convertir le texte en nombres que le mod\xE8le peut comprendre. Comme vous l\u2019avez vu dans le "),Ms=u(Da,"A",{href:!0});var Fi=p(Ms);Rr=a(Fi,"chapitre pr\xE9c\xE9dent"),Fi.forEach(t),Fr=a(Da,", cela se fait avec un tokenizer. Nous pouvons passer au tokenizer une phrase ou une liste de phrases, ainsi nous pouvons directement tokeniser toutes les premi\xE8res phrases et toutes les deuxi\xE8mes phrases de chaque paire comme ceci :"),Da.forEach(t),Fn=f(e),$(rs.$$.fragment,e),In=f(e),Rs=u(e,"P",{});var Ii=p(Rs);Ir=a(Ii,"N\xE9anmoins, nous ne pouvons pas simplement transmettre deux s\xE9quences au mod\xE8le et obtenir une pr\xE9diction indiquant si les deux phrases sont des paraphrases ou non. Nous devons g\xE9rer les deux s\xE9quences comme une paire et appliquer le pr\xE9traitement appropri\xE9. Heureusement, le tokenizer peut \xE9galement prendre une paire de s\xE9quences et la mettre dans le format attendu par notre mod\xE8le BERT\xA0:"),Ii.forEach(t),Hn=f(e),$(ls.$$.fragment,e),Wn=f(e),$(os.$$.fragment,e),Bn=f(e),G=u(e,"P",{});var ge=p(G);Hr=a(ge,"Nous avons vu les cl\xE9s "),Ct=u(ge,"CODE",{});var Hi=p(Ct);Wr=a(Hi,"input_ids"),Hi.forEach(t),Br=a(ge," et "),Pt=u(ge,"CODE",{});var Wi=p(Pt);Vr=a(Wi,"attention_mask"),Wi.forEach(t),Ur=a(ge," au "),Fs=u(ge,"A",{href:!0});var Bi=p(Fs);Gr=a(Bi,"chapitre 2"),Bi.forEach(t),Qr=a(ge,", mais nous avons omis de parler des "),Dt=u(ge,"CODE",{});var Vi=p(Dt);Jr=a(Vi,"token_type_ids"),Vi.forEach(t),Kr=a(ge,". Dans cet exemple, c\u2019est ce qui indique au mod\xE8le quelle partie de l\u2019entr\xE9e repr\xE9sente la premi\xE8re phrase et quelle partie repr\xE9sente la deuxi\xE8me phrase."),ge.forEach(t),Vn=f(e),$(Te.$$.fragment,e),Un=f(e),Se=u(e,"P",{});var Ta=p(Se);Yr=a(Ta,"Si nous d\xE9codons les IDs contenus dans "),Tt=u(Ta,"CODE",{});var Ui=p(Tt);Zr=a(Ui,"input_ids"),Ui.forEach(t),Xr=a(Ta," pour r\xE9obtenir des mots :"),Ta.forEach(t),Gn=f(e),$(is.$$.fragment,e),Qn=f(e),Is=u(e,"P",{});var Gi=p(Is);el=a(Gi,"Nous obtiendrons :"),Gi.forEach(t),Jn=f(e),$(us.$$.fragment,e),Kn=f(e),fe=u(e,"P",{});var nt=p(fe);sl=a(nt,"Nous pouvons donc voir que le mod\xE8le attend une entr\xE9e de la forme  "),St=u(nt,"CODE",{});var Qi=p(St);tl=a(Qi,"[CLS] sentence1 [SEP] sentence2 [SEP]"),Qi.forEach(t),nl=a(nt," lorsqu\u2019il y a deux phrases. Aligner cette repr\xE9sentation avec "),Nt=u(nt,"CODE",{});var Ji=p(Nt);al=a(Ji,"token_type_ids"),Ji.forEach(t),rl=a(nt," nous donne :"),nt.forEach(t),Yn=f(e),$(ps.$$.fragment,e),Zn=f(e),Q=u(e,"P",{});var qe=p(Q);ll=a(qe,"Comme vous pouvez le voir, les parties correspondant \xE0 "),Ot=u(qe,"CODE",{});var Ki=p(Ot);ol=a(Ki,"[CLS] sentence1 [SEP]"),Ki.forEach(t),il=a(qe," ont toutes "),At=u(qe,"CODE",{});var Yi=p(At);ul=a(Yi,"0"),Yi.forEach(t),pl=a(qe," comme ID de type de token, alors que les autres parties qui correspondent \xE0 "),Lt=u(qe,"CODE",{});var Zi=p(Lt);cl=a(Zi,"sentence2 [SEP]"),Zi.forEach(t),dl=a(qe,", ont toute "),Mt=u(qe,"CODE",{});var Xi=p(Mt);ml=a(Xi,"1"),Xi.forEach(t),fl=a(qe," comme ID de type de token."),qe.forEach(t),Xn=f(e),Ne=u(e,"P",{});var Sa=p(Ne);hl=a(Sa,"Notez que si vous s\xE9lectionnez un checkpoint diff\xE9rent, vous n\u2019aurez pas n\xE9cessairement les "),Rt=u(Sa,"CODE",{});var eu=p(Rt);_l=a(eu,"token_type_ids"),eu.forEach(t),vl=a(Sa," dans vos entr\xE9es tokenis\xE9es (par exemple, ils ne sont pas retourn\xE9s lorsque vous utilisez le mod\xE8le DistilBERT). Ils ne sont renvoy\xE9s que lorsque le mod\xE8le sait les utiliser, pour les avoir vu pendant le pr\xE9-entra\xEEnement."),Sa.forEach(t),ea=f(e),Z=u(e,"P",{});var Ve=p(Z);bl=a(Ve,"Ici, BERT est pr\xE9-entra\xEEn\xE9 avec des IDs de type de token, et en plus de la fonction de co\xFBt MLM (Masked Language Modelling) dont nous avons parl\xE9 au "),Hs=u(Ve,"A",{href:!0});var su=p(Hs);gl=a(su,"chapitre 1"),su.forEach(t),ql=a(Ve,", il a un co\xFBt suppl\xE9mentaire appel\xE9 "),Ft=u(Ve,"EM",{});var tu=p(Ft);jl=a(tu,"pr\xE9diction de la phrase suivante"),tu.forEach(t),kl=a(Ve,"("),It=u(Ve,"EM",{});var nu=p(It);$l=a(nu,"next sentence prediction"),nu.forEach(t),xl=a(Ve,"). Le but de cette t\xE2che est de mod\xE9liser la relation entre des paires de phrases."),Ve.forEach(t),sa=f(e),Ws=u(e,"P",{});var au=p(Ws);El=a(au,"Pour la pr\xE9diction de la phrase suivante, le mod\xE8le re\xE7oit des paires de phrases (avec des tokens masqu\xE9s de mani\xE8re al\xE9atoire) et on lui demande de pr\xE9dire si la deuxi\xE8me phrase suit la premi\xE8re. Pour rendre la t\xE2che non triviale, la moiti\xE9 du temps les phrases se suivent dans le document original dont elles sont extraites, et l\u2019autre moiti\xE9 du temps les deux phrases proviennent de deux documents diff\xE9rents."),au.forEach(t),ta=f(e),Oe=u(e,"P",{});var Na=p(Oe);zl=a(Na,"En g\xE9n\xE9ral, vous n\u2019avez pas \xE0 vous soucier de savoir s\u2019il y a ou non des "),Ht=u(Na,"CODE",{});var ru=p(Ht);wl=a(ru,"token_type_ids"),ru.forEach(t),yl=a(Na," dans vos entr\xE9es tokenis\xE9es\xA0: tant que vous utilisez le m\xEAme checkpoint pour le tokenizer et le mod\xE8le, tout ira bien car le tokenizer sait quoi fournir \xE0 son mod\xE8le."),Na.forEach(t),na=f(e),he=u(e,"P",{});var at=p(he);Cl=a(at,"Maintenant que nous avons vu comment notre tokenizer peut traiter une paire de phrases, nous pouvons l\u2019utiliser pour tokeniser l\u2019ensemble de nos donn\xE9es\xA0: comme dans le "),Bs=u(at,"A",{href:!0});var lu=p(Bs);Pl=a(lu,"chapitre pr\xE9c\xE9dent"),lu.forEach(t),Dl=a(at,", nous pouvons fournir au tokenizer une liste de paires de phrases en lui donnant la liste des premi\xE8res phrases, puis la liste des secondes phrases. Ceci est \xE9galement compatible avec les options de padding et de troncature que nous avons vues au "),Vs=u(at,"A",{href:!0});var ou=p(Vs);Tl=a(ou,"chapitre 2"),ou.forEach(t),Sl=a(at,". Ainsi, une fa\xE7on de pr\xE9traiter l\u2019ensemble de donn\xE9es d\u2019entra\xEEnement est\xA0:"),at.forEach(t),aa=f(e),$(cs.$$.fragment,e),ra=f(e),J=u(e,"P",{});var je=p(J);Nl=a(je,"Cela marche bien, mais a le d\xE9savantage de retourner un dictionnaire (avec nos cl\xE9s, "),Wt=u(je,"CODE",{});var iu=p(Wt);Ol=a(iu,"input_ids"),iu.forEach(t),Al=a(je,", "),Bt=u(je,"CODE",{});var uu=p(Bt);Ll=a(uu,"attention_mask"),uu.forEach(t),Ml=a(je," et "),Vt=u(je,"CODE",{});var pu=p(Vt);Rl=a(pu,"token_type_ids"),pu.forEach(t),Fl=a(je,", et des valeurs qui sont des listes de listes). Cela ne marchera que si vous avez assez de RAM pour contenir tout le jeu de donn\xE9es pendant la tokenisation (tandis que les jeux de donn\xE9es de la librairie de \u{1F917} sont des fichiers "),ds=u(je,"A",{href:!0,rel:!0});var cu=p(ds);Il=a(cu,"Apache Arrow"),cu.forEach(t),Hl=a(je," charg\xE9es sur le disque, de sorte que vous ne gardez que les exemples dont vous avez besoin en m\xE9moire )"),je.forEach(t),la=f(e),_e=u(e,"P",{});var rt=p(_e);Wl=a(rt,"Pour garder les donn\xE9es sous forme de dataset (jeu de donn\xE9es), nous allons utiliser la m\xE9thode "),ms=u(rt,"A",{href:!0,rel:!0});var du=p(ms);Ut=u(du,"CODE",{});var mu=p(Ut);Bl=a(mu,"Dataset.map()"),mu.forEach(t),du.forEach(t),Vl=a(rt,". Cela nous permet d\u2019avoir plus de flexibilit\xE9 si nous avons besoin de faire plus que juste tokeniser pendant la phase de pr\xE9-tra\xEEtement. La m\xE9thode "),Gt=u(rt,"CODE",{});var fu=p(Gt);Ul=a(fu,"map()"),fu.forEach(t),Gl=a(rt," fonctionne en applicant une fonction \xE0 chaque \xE9l\xE9ment du dataset, d\xE9finissons alors une fonction qui tokenise nos entr\xE9es :"),rt.forEach(t),oa=f(e),$(fs.$$.fragment,e),ia=f(e),A=u(e,"P",{});var I=p(A);Ql=a(I,"Cette prend en entr\xE9e un dictionnaire (comme les items de notre dataset) and renvioe un nouveau dictionnaire avec les cl\xE9s "),Qt=u(I,"CODE",{});var hu=p(Qt);Jl=a(hu,"input_ids"),hu.forEach(t),Kl=a(I,", "),Jt=u(I,"CODE",{});var _u=p(Jt);Yl=a(_u,"attention_mask"),_u.forEach(t),Zl=a(I," et "),Kt=u(I,"CODE",{});var vu=p(Kt);Xl=a(vu,"token_type_ids"),vu.forEach(t),eo=a(I,". Notez que cela marche aussi si le dictionnaire "),Yt=u(I,"CODE",{});var bu=p(Yt);so=a(bu,"example"),bu.forEach(t),to=a(I," contient plusieurs exemples puisque le tokenizer fonctionne aussi sur des listes de paires de phrases, comme nous l\u2019avons vu pr\xE9c\xE9demment. Cela permettra d\u2019utiliser l\u2019option "),Zt=u(I,"CODE",{});var gu=p(Zt);no=a(gu,"batched=True"),gu.forEach(t),ao=a(I," dans notre appel de la m\xE9thode "),Xt=u(I,"CODE",{});var qu=p(Xt);ro=a(qu,"map()"),qu.forEach(t),lo=a(I,", ce qui permettra d\u2019acc\xE9l\xE9rer la tokenisation.  Le "),en=u(I,"CODE",{});var ju=p(en);oo=a(ju,"tokenizer"),ju.forEach(t),io=a(I," est aid\xE9 par  un tokenizer \xE9crit en Rust  provenant de la librairie "),hs=u(I,"A",{href:!0,rel:!0});var ku=p(hs);uo=a(ku,"Tokenizers"),ku.forEach(t),po=a(I," de \u{1F917}. Ce tokenizer peut \xEAtre tr\xE8s rapide, mais seulement si on lui donne beaucoup d\u2019entr\xE9es en m\xEAme temps."),I.forEach(t),ua=f(e),Ae=u(e,"P",{});var Oa=p(Ae);co=a(Oa,"Notez que nous avons ignorer l\u2019argument "),sn=u(Oa,"CODE",{});var $u=p(sn);mo=a($u,"padding"),$u.forEach(t),fo=a(Oa," dans notre fonction de tokenisation pour l\u2019instant. Ceci parce que faire le padding de tous les exemples \xE0 la longueur maximale n\u2019est pas efficace : il vaut mieux faire le padding lorsque nous construisons un batch, puisque dans ce cas nous allons seulement faire le padding pour la longueur maximale dans ce batch, et non pour la longueur maximale de tout le dataset. Cela permet d\u2019\xE9conomiser beaucoup de temps et de puissance de calcul lorsqu\u2019on traite des entr\xE9es avec des longueurs tr\xE9s vari\xE9es!"),Oa.forEach(t),pa=f(e),ve=u(e,"P",{});var lt=p(ve);ho=a(lt,"Voil\xE0 comment on applique la fonction de tokenisation \xE0 tous nos datasets en m\xEAme temps. Nous utilisons "),tn=u(lt,"CODE",{});var xu=p(tn);_o=a(xu,"batched=True"),xu.forEach(t),vo=a(lt," dans notre appel de "),nn=u(lt,"CODE",{});var Eu=p(nn);bo=a(Eu,"map"),Eu.forEach(t),go=a(lt," pour que la fonction soit appliqu\xE9e \xE0 plusieurs \xE9l\xE9ments de notre dataset en m\xEAme temps, et non sur chaque \xE9l\xE9ment s\xE9par\xE9ment. Cela permet d\u2019avoir un pr\xE9-tra\xEEtement plus rapide."),lt.forEach(t),ca=f(e),$(_s.$$.fragment,e),da=f(e),Us=u(e,"P",{});var zu=p(Us);qo=a(zu,"La librairie Datasets de \u{1F917} applique le processing en ajoutant de nouveaux champs aux datasets, un nouveau pour chaque cl\xE9 retourn\xE9e par la fonction de preprocessing :"),zu.forEach(t),ma=f(e),$(vs.$$.fragment,e),fa=f(e),be=u(e,"P",{});var ot=p(be);jo=a(ot,"Vous pouvez m\xEAme utiliser le multiprocessing en appliquant votre pr\xE9-tra\xEEtement avec "),an=u(ot,"CODE",{});var wu=p(an);ko=a(wu,"map()"),wu.forEach(t),$o=a(ot," en lui passant l\u2019argument "),rn=u(ot,"CODE",{});var yu=p(rn);xo=a(yu,"num_proc"),yu.forEach(t),Eo=a(ot,". Nous ne l\u2019avons pas utilis\xE9 ici parce que la librairie Tokenizers de \u{1F917} utilise plusieurs threads pour tokeniser nos exemples plus rapidement, mais si vous n\u2019utilisez pas de tokenizer rapide qui s\u2019aide de cette librairie, cela pourrait acc\xE9l\xE9rer votre pr\xE9-tra\xEEtement."),ot.forEach(t),ha=f(e),V=u(e,"P",{});var se=p(V);zo=a(se,"Notre "),ln=u(se,"CODE",{});var Cu=p(ln);wo=a(Cu,"tokenize_function"),Cu.forEach(t),yo=a(se," retourne un dictionnaire avec les cl\xE9s "),on=u(se,"CODE",{});var Pu=p(on);Co=a(Pu,"input_ids"),Pu.forEach(t),Po=a(se,", "),un=u(se,"CODE",{});var Du=p(un);Do=a(Du,"attention_mask"),Du.forEach(t),To=a(se," et "),pn=u(se,"CODE",{});var Tu=p(pn);So=a(Tu,"token_type_ids"),Tu.forEach(t),No=a(se,", donc ces trois champs sont ajout\xE9s \xE0 toutes les parties (entra\xEEnement, validation et test) de notre dataset. Notez que nous aurions aussi pu changer des champs existants si notre pr\xE9-tra\xEEtement retournait une nouvelle valeur pour une cl\xE9 qui existait d\xE9j\xE0 dans le dataset sur lequel nous avons appel\xE9 "),cn=u(se,"CODE",{});var Su=p(cn);Oo=a(Su,"map()"),Su.forEach(t),Ao=a(se,"."),se.forEach(t),_a=f(e),Le=u(e,"P",{});var Aa=p(Le);Lo=a(Aa,"La derni\xE8re chose que nous aurons besoin de faire est le padding de tous les \xE9l\xE9ments pour que leur longueur atteigne la longueur de la plus longue s\xE9quence du batch lorsque nous construisons les batchs \u2014 une technique que nous appelons "),dn=u(Aa,"EM",{});var Nu=p(dn);Mo=a(Nu,"padding dynamique"),Nu.forEach(t),Ro=a(Aa,"."),Aa.forEach(t),va=f(e),xe=u(e,"H3",{class:!0});var La=p(xe);Me=u(La,"A",{id:!0,class:!0,href:!0});var Ou=p(Me);mn=u(Ou,"SPAN",{});var Au=p(mn);$(bs.$$.fragment,Au),Au.forEach(t),Ou.forEach(t),Fo=f(La),fn=u(La,"SPAN",{});var Lu=p(fn);Io=a(Lu,"Padding dynamique"),Lu.forEach(t),La.forEach(t),ba=f(e),$(gs.$$.fragment,e),ga=f(e),Ee.l(e),Gs=f(e),Re=u(e,"P",{});var Ma=p(Re);Ho=a(Ma,"En pratique, pour faire cela, on utilise une fonction d\u2019assemblage qui va mettre la bonne quantit\xE9 de padding aux \xE9l\xE9ments du dataset que nous mettre ensemble pour former un batch.  Heureusement,  la librairie Transformers de \u{1F917} fournit une telle fonction via  "),hn=u(Ma,"CODE",{});var Mu=p(hn);Wo=a(Mu,"DataCollatorWithPadding"),Mu.forEach(t),Bo=a(Ma,". Elle prend un tokenizer lorsqu\u2019on l\u2019instancie (pour savoir quel token utiliser pour le padding, et aussi s\u2019il faut faire le padding \xE0 gauche ou \xE0 droite en fonction des attentes du  mod\xE8le) et va faire le n\xE9cessaire:"),Ma.forEach(t),qa=f(e),oe.l(e),Qs=f(e),X=u(e,"P",{});var Ue=p(X);Vo=a(Ue,"Pour tester notre nouveau jouet, prenons quelques \xE9l\xE9ments de notre jeu d\u2019entra\xEEnement avec lesquels nous allons former un batch. Ici, on supprime les colonnes "),_n=u(Ue,"CODE",{});var Ru=p(_n);Uo=a(Ru,"idx"),Ru.forEach(t),Go=a(Ue,", "),vn=u(Ue,"CODE",{});var Fu=p(vn);Qo=a(Fu,"sentence1"),Fu.forEach(t),Jo=a(Ue," et "),bn=u(Ue,"CODE",{});var Iu=p(bn);Ko=a(Iu,"sentence2"),Iu.forEach(t),Yo=a(Ue," puisque nous n\u2019en aurons pas besoin et qu\u2019elles contiennent des strings ( et nous ne pouvons pas cr\xE9er des tensors avec des strings) et on regarde la longueur de chaque entr\xE9e du batch :"),Ue.forEach(t),ja=f(e),$(qs.$$.fragment,e),ka=f(e),$(js.$$.fragment,e),$a=f(e),Fe=u(e,"P",{});var Ra=p(Fe);Zo=a(Ra,"Sans surprise, nous obtenons des \xE9l\xE9ments de longueurs diff\xE9rentes, allant de 32 \xE0 67. Le padding dynamique signifie que nous allons utiliser le padding sur tous les \xE9l\xE9ments du batch pour obtenir une longueur de 67, la longueur maximale pour ce batch. Sans le padding dynamique, on appliquerait un padding \xE0 tous les \xE9l\xE9ments pour atteindre la longueur maximale de tout le dataset, ou la longueur maximale que le mod\xE8le peut accepter. V\xE9rifions que notre "),gn=u(Ra,"CODE",{});var Hu=p(gn);Xo=a(Hu,"data_collator"),Hu.forEach(t),ei=a(Ra," effectue correctement le padding dynamique :"),Ra.forEach(t),xa=f(e),$(ks.$$.fragment,e),Ea=f(e),ue.l(e),Js=f(e),$(Ie.$$.fragment,e),za=f(e),F&&F.l(e),Ks=Wu(),this.h()},h(){w(r,"name","hf:doc:metadata"),w(r,"content",JSON.stringify(_p)),w(h,"id","prparer-les-donnes"),w(h,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(h,"href","#prparer-les-donnes"),w(j,"class","relative group"),w(ce,"href","https://www.aclweb.org/anthology/I05-5002.pdf"),w(ce,"rel","nofollow"),w(we,"id","charger-un-jeu-de-donnes-depuis-le-hub"),w(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(we,"href","#charger-un-jeu-de-donnes-depuis-le-hub"),w(ke,"class","relative group"),w(Je,"href","https://huggingface.co/datasets"),w(Je,"rel","nofollow"),w(Ke,"href","https://huggingface.co/docs/datasets/loading_datasets.html#from-the-huggingface-hub"),w(Ke,"rel","nofollow"),w(Ye,"href","https://gluebenchmark.com/"),w(Ye,"rel","nofollow"),w(Pe,"id","preprocessing-dun-jeu-de-donne"),w(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(Pe,"href","#preprocessing-dun-jeu-de-donne"),w($e,"class","relative group"),w(Ms,"href","/course/chapter2"),w(Fs,"href","/course/chapter2"),w(Hs,"href","/course/chapter1"),w(Bs,"href","/course/chapter2"),w(Vs,"href","/course/chapter2"),w(ds,"href","https://arrow.apache.org/"),w(ds,"rel","nofollow"),w(ms,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),w(ms,"rel","nofollow"),w(hs,"href","https://github.com/huggingface/tokenizers"),w(hs,"rel","nofollow"),w(Me,"id","padding-dynamique"),w(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),w(Me,"href","#padding-dynamique"),w(xe,"class","relative group")},m(e,o){s(document.head,r),c(e,d,o),x(l,e,o),c(e,v,o),c(e,j,o),s(j,h),s(h,_),x(y,_,null),s(j,q),s(j,P),s(P,L),c(e,O,o),$s[C].m(e,o),c(e,H,o),xs[S].m(e,o),c(e,K,o),c(e,pe,o),s(pe,ze),c(e,D,o),c(e,N,o),s(N,Ts),s(N,ce),s(ce,Ss),s(N,Ns),c(e,Ge,o),c(e,ke,o),s(ke,we),s(we,it),x(Qe,it,null),s(ke,Ia),s(ke,ut),s(ut,Ha),c(e,xn,o),Es[te].m(e,o),c(e,Os,o),c(e,Y,o),s(Y,Wa),s(Y,Je),s(Je,Ba),s(Y,Va),s(Y,Ke),s(Ke,Ua),s(Y,Ga),s(Y,Ye),s(Ye,Qa),s(Y,Ja),c(e,En,o),c(e,As,o),s(As,Ka),c(e,zn,o),x(Ze,e,o),c(e,wn,o),x(Xe,e,o),c(e,yn,o),c(e,B,o),s(B,Ya),s(B,pt),s(pt,Za),s(B,Xa),s(B,ct),s(ct,er),s(B,sr),s(B,dt),s(dt,tr),s(B,nr),s(B,mt),s(mt,ar),s(B,rr),s(B,ft),s(ft,lr),s(B,or),c(e,Cn,o),c(e,de,o),s(de,ir),s(de,ht),s(ht,ur),s(de,pr),s(de,_t),s(_t,cr),s(de,dr),c(e,Pn,o),c(e,ye,o),s(ye,mr),s(ye,vt),s(vt,fr),s(ye,hr),c(e,Dn,o),x(es,e,o),c(e,Tn,o),x(ss,e,o),c(e,Sn,o),c(e,me,o),s(me,_r),s(me,bt),s(bt,vr),s(me,br),s(me,gt),s(gt,gr),s(me,qr),c(e,Nn,o),x(ts,e,o),c(e,On,o),x(ns,e,o),c(e,An,o),c(e,R,o),s(R,jr),s(R,qt),s(qt,kr),s(R,$r),s(R,jt),s(jt,xr),s(R,Er),s(R,kt),s(kt,zr),s(R,wr),s(R,$t),s($t,yr),s(R,Cr),s(R,xt),s(xt,Pr),s(R,Dr),s(R,Et),s(Et,Tr),s(R,Sr),s(R,zt),s(zt,Nr),s(R,Or),c(e,Ln,o),x(Ce,e,o),c(e,Mn,o),c(e,$e,o),s($e,Pe),s(Pe,wt),x(as,wt,null),s($e,Ar),s($e,yt),s(yt,Lr),c(e,Rn,o),zs[ae].m(e,o),c(e,Ls,o),c(e,De,o),s(De,Mr),s(De,Ms),s(Ms,Rr),s(De,Fr),c(e,Fn,o),x(rs,e,o),c(e,In,o),c(e,Rs,o),s(Rs,Ir),c(e,Hn,o),x(ls,e,o),c(e,Wn,o),x(os,e,o),c(e,Bn,o),c(e,G,o),s(G,Hr),s(G,Ct),s(Ct,Wr),s(G,Br),s(G,Pt),s(Pt,Vr),s(G,Ur),s(G,Fs),s(Fs,Gr),s(G,Qr),s(G,Dt),s(Dt,Jr),s(G,Kr),c(e,Vn,o),x(Te,e,o),c(e,Un,o),c(e,Se,o),s(Se,Yr),s(Se,Tt),s(Tt,Zr),s(Se,Xr),c(e,Gn,o),x(is,e,o),c(e,Qn,o),c(e,Is,o),s(Is,el),c(e,Jn,o),x(us,e,o),c(e,Kn,o),c(e,fe,o),s(fe,sl),s(fe,St),s(St,tl),s(fe,nl),s(fe,Nt),s(Nt,al),s(fe,rl),c(e,Yn,o),x(ps,e,o),c(e,Zn,o),c(e,Q,o),s(Q,ll),s(Q,Ot),s(Ot,ol),s(Q,il),s(Q,At),s(At,ul),s(Q,pl),s(Q,Lt),s(Lt,cl),s(Q,dl),s(Q,Mt),s(Mt,ml),s(Q,fl),c(e,Xn,o),c(e,Ne,o),s(Ne,hl),s(Ne,Rt),s(Rt,_l),s(Ne,vl),c(e,ea,o),c(e,Z,o),s(Z,bl),s(Z,Hs),s(Hs,gl),s(Z,ql),s(Z,Ft),s(Ft,jl),s(Z,kl),s(Z,It),s(It,$l),s(Z,xl),c(e,sa,o),c(e,Ws,o),s(Ws,El),c(e,ta,o),c(e,Oe,o),s(Oe,zl),s(Oe,Ht),s(Ht,wl),s(Oe,yl),c(e,na,o),c(e,he,o),s(he,Cl),s(he,Bs),s(Bs,Pl),s(he,Dl),s(he,Vs),s(Vs,Tl),s(he,Sl),c(e,aa,o),x(cs,e,o),c(e,ra,o),c(e,J,o),s(J,Nl),s(J,Wt),s(Wt,Ol),s(J,Al),s(J,Bt),s(Bt,Ll),s(J,Ml),s(J,Vt),s(Vt,Rl),s(J,Fl),s(J,ds),s(ds,Il),s(J,Hl),c(e,la,o),c(e,_e,o),s(_e,Wl),s(_e,ms),s(ms,Ut),s(Ut,Bl),s(_e,Vl),s(_e,Gt),s(Gt,Ul),s(_e,Gl),c(e,oa,o),x(fs,e,o),c(e,ia,o),c(e,A,o),s(A,Ql),s(A,Qt),s(Qt,Jl),s(A,Kl),s(A,Jt),s(Jt,Yl),s(A,Zl),s(A,Kt),s(Kt,Xl),s(A,eo),s(A,Yt),s(Yt,so),s(A,to),s(A,Zt),s(Zt,no),s(A,ao),s(A,Xt),s(Xt,ro),s(A,lo),s(A,en),s(en,oo),s(A,io),s(A,hs),s(hs,uo),s(A,po),c(e,ua,o),c(e,Ae,o),s(Ae,co),s(Ae,sn),s(sn,mo),s(Ae,fo),c(e,pa,o),c(e,ve,o),s(ve,ho),s(ve,tn),s(tn,_o),s(ve,vo),s(ve,nn),s(nn,bo),s(ve,go),c(e,ca,o),x(_s,e,o),c(e,da,o),c(e,Us,o),s(Us,qo),c(e,ma,o),x(vs,e,o),c(e,fa,o),c(e,be,o),s(be,jo),s(be,an),s(an,ko),s(be,$o),s(be,rn),s(rn,xo),s(be,Eo),c(e,ha,o),c(e,V,o),s(V,zo),s(V,ln),s(ln,wo),s(V,yo),s(V,on),s(on,Co),s(V,Po),s(V,un),s(un,Do),s(V,To),s(V,pn),s(pn,So),s(V,No),s(V,cn),s(cn,Oo),s(V,Ao),c(e,_a,o),c(e,Le,o),s(Le,Lo),s(Le,dn),s(dn,Mo),s(Le,Ro),c(e,va,o),c(e,xe,o),s(xe,Me),s(Me,mn),x(bs,mn,null),s(xe,Fo),s(xe,fn),s(fn,Io),c(e,ba,o),x(gs,e,o),c(e,ga,o),Ee.m(e,o),c(e,Gs,o),c(e,Re,o),s(Re,Ho),s(Re,hn),s(hn,Wo),s(Re,Bo),c(e,qa,o),ws[le].m(e,o),c(e,Qs,o),c(e,X,o),s(X,Vo),s(X,_n),s(_n,Uo),s(X,Go),s(X,vn),s(vn,Qo),s(X,Jo),s(X,bn),s(bn,Ko),s(X,Yo),c(e,ja,o),x(qs,e,o),c(e,ka,o),x(js,e,o),c(e,$a,o),c(e,Fe,o),s(Fe,Zo),s(Fe,gn),s(gn,Xo),s(Fe,ei),c(e,xa,o),x(ks,e,o),c(e,Ea,o),ys[ie].m(e,o),c(e,Js,o),x(Ie,e,o),c(e,za,o),F&&F.m(e,o),c(e,Ks,o),wa=!0},p(e,[o]){const Cs={};o&1&&(Cs.fw=e[0]),l.$set(Cs);let Ys=C;C=ni(e),C!==Ys&&(Ds(),g($s[Ys],1,1,()=>{$s[Ys]=null}),Ps(),M=$s[C],M||(M=$s[C]=ti[C](e),M.c()),b(M,1),M.m(H.parentNode,H));let Zs=S;S=ri(e),S!==Zs&&(Ds(),g(xs[Zs],1,1,()=>{xs[Zs]=null}),Ps(),W=xs[S],W||(W=xs[S]=ai[S](e),W.c()),b(W,1),W.m(K.parentNode,K));let Xs=te;te=oi(e),te!==Xs&&(Ds(),g(Es[Xs],1,1,()=>{Es[Xs]=null}),Ps(),ne=Es[te],ne||(ne=Es[te]=li[te](e),ne.c()),b(ne,1),ne.m(Os.parentNode,Os));const qn={};o&2&&(qn.$$scope={dirty:o,ctx:e}),Ce.$set(qn);let He=ae;ae=ui(e),ae!==He&&(Ds(),g(zs[He],1,1,()=>{zs[He]=null}),Ps(),re=zs[ae],re||(re=zs[ae]=ii[ae](e),re.c()),b(re,1),re.m(Ls.parentNode,Ls));const jn={};o&2&&(jn.$$scope={dirty:o,ctx:e}),Te.$set(jn),ya!==(ya=pi(e))&&(Ee.d(1),Ee=ya(e),Ee&&(Ee.c(),Ee.m(Gs.parentNode,Gs)));let We=le;le=di(e),le!==We&&(Ds(),g(ws[We],1,1,()=>{ws[We]=null}),Ps(),oe=ws[le],oe||(oe=ws[le]=ci[le](e),oe.c()),b(oe,1),oe.m(Qs.parentNode,Qs));let et=ie;ie=fi(e),ie!==et&&(Ds(),g(ys[et],1,1,()=>{ys[et]=null}),Ps(),ue=ys[ie],ue||(ue=ys[ie]=mi[ie](e),ue.c()),b(ue,1),ue.m(Js.parentNode,Js));const kn={};o&2&&(kn.$$scope={dirty:o,ctx:e}),Ie.$set(kn),e[0]==="tf"?F?o&1&&b(F,1):(F=Bu(),F.c(),b(F,1),F.m(Ks.parentNode,Ks)):F&&(Ds(),g(F,1,1,()=>{F=null}),Ps())},i(e){wa||(b(l.$$.fragment,e),b(y.$$.fragment,e),b(M),b(W),b(Qe.$$.fragment,e),b(ne),b(Ze.$$.fragment,e),b(Xe.$$.fragment,e),b(es.$$.fragment,e),b(ss.$$.fragment,e),b(ts.$$.fragment,e),b(ns.$$.fragment,e),b(Ce.$$.fragment,e),b(as.$$.fragment,e),b(re),b(rs.$$.fragment,e),b(ls.$$.fragment,e),b(os.$$.fragment,e),b(Te.$$.fragment,e),b(is.$$.fragment,e),b(us.$$.fragment,e),b(ps.$$.fragment,e),b(cs.$$.fragment,e),b(fs.$$.fragment,e),b(_s.$$.fragment,e),b(vs.$$.fragment,e),b(bs.$$.fragment,e),b(gs.$$.fragment,e),b(oe),b(qs.$$.fragment,e),b(js.$$.fragment,e),b(ks.$$.fragment,e),b(ue),b(Ie.$$.fragment,e),b(F),wa=!0)},o(e){g(l.$$.fragment,e),g(y.$$.fragment,e),g(M),g(W),g(Qe.$$.fragment,e),g(ne),g(Ze.$$.fragment,e),g(Xe.$$.fragment,e),g(es.$$.fragment,e),g(ss.$$.fragment,e),g(ts.$$.fragment,e),g(ns.$$.fragment,e),g(Ce.$$.fragment,e),g(as.$$.fragment,e),g(re),g(rs.$$.fragment,e),g(ls.$$.fragment,e),g(os.$$.fragment,e),g(Te.$$.fragment,e),g(is.$$.fragment,e),g(us.$$.fragment,e),g(ps.$$.fragment,e),g(cs.$$.fragment,e),g(fs.$$.fragment,e),g(_s.$$.fragment,e),g(vs.$$.fragment,e),g(bs.$$.fragment,e),g(gs.$$.fragment,e),g(oe),g(qs.$$.fragment,e),g(js.$$.fragment,e),g(ks.$$.fragment,e),g(ue),g(Ie.$$.fragment,e),g(F),wa=!1},d(e){t(r),e&&t(d),E(l,e),e&&t(v),e&&t(j),E(y),e&&t(O),$s[C].d(e),e&&t(H),xs[S].d(e),e&&t(K),e&&t(pe),e&&t(D),e&&t(N),e&&t(Ge),e&&t(ke),E(Qe),e&&t(xn),Es[te].d(e),e&&t(Os),e&&t(Y),e&&t(En),e&&t(As),e&&t(zn),E(Ze,e),e&&t(wn),E(Xe,e),e&&t(yn),e&&t(B),e&&t(Cn),e&&t(de),e&&t(Pn),e&&t(ye),e&&t(Dn),E(es,e),e&&t(Tn),E(ss,e),e&&t(Sn),e&&t(me),e&&t(Nn),E(ts,e),e&&t(On),E(ns,e),e&&t(An),e&&t(R),e&&t(Ln),E(Ce,e),e&&t(Mn),e&&t($e),E(as),e&&t(Rn),zs[ae].d(e),e&&t(Ls),e&&t(De),e&&t(Fn),E(rs,e),e&&t(In),e&&t(Rs),e&&t(Hn),E(ls,e),e&&t(Wn),E(os,e),e&&t(Bn),e&&t(G),e&&t(Vn),E(Te,e),e&&t(Un),e&&t(Se),e&&t(Gn),E(is,e),e&&t(Qn),e&&t(Is),e&&t(Jn),E(us,e),e&&t(Kn),e&&t(fe),e&&t(Yn),E(ps,e),e&&t(Zn),e&&t(Q),e&&t(Xn),e&&t(Ne),e&&t(ea),e&&t(Z),e&&t(sa),e&&t(Ws),e&&t(ta),e&&t(Oe),e&&t(na),e&&t(he),e&&t(aa),E(cs,e),e&&t(ra),e&&t(J),e&&t(la),e&&t(_e),e&&t(oa),E(fs,e),e&&t(ia),e&&t(A),e&&t(ua),e&&t(Ae),e&&t(pa),e&&t(ve),e&&t(ca),E(_s,e),e&&t(da),e&&t(Us),e&&t(ma),E(vs,e),e&&t(fa),e&&t(be),e&&t(ha),e&&t(V),e&&t(_a),e&&t(Le),e&&t(va),e&&t(xe),E(bs),e&&t(ba),E(gs,e),e&&t(ga),Ee.d(e),e&&t(Gs),e&&t(Re),e&&t(qa),ws[le].d(e),e&&t(Qs),e&&t(X),e&&t(ja),E(qs,e),e&&t(ka),E(js,e),e&&t($a),e&&t(Fe),e&&t(xa),E(ks,e),e&&t(Ea),ys[ie].d(e),e&&t(Js),E(Ie,e),e&&t(za),F&&F.d(e),e&&t(Ks)}}}const _p={local:"prparer-les-donnes",sections:[{local:"charger-un-jeu-de-donnes-depuis-le-hub",title:"Charger un jeu de donn\xE9es depuis le Hub"},{local:"preprocessing-dun-jeu-de-donne",title:"Preprocessing d'un jeu de donn\xE9e"},{local:"padding-dynamique",title:"Padding dynamique"}],title:"Pr\xE9parer les donn\xE9es"};function vp(z,r,d){let l="pt";return Ku(()=>{const v=new URLSearchParams(window.location.search);d(0,l=v.get("fw")||"pt")}),[l]}class Ep extends Uu{constructor(r){super();Gu(this,r,vp,hp,Qu,{})}}export{Ep as default,_p as metadata};
