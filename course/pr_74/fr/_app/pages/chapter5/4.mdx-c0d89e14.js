import{S as to,i as ao,s as no,e as r,k as d,w as b,t as a,M as lo,c as o,d as t,m,a as i,x as g,h as n,b as c,F as s,g as u,y as v,q as _,o as x,B as $,v as ro}from"../../chunks/vendor-e6c5d93e.js";import{D as oo,Y as io,T as vt}from"../../chunks/DocNotebookDropdown-b3e38740.js";import{I as Oa}from"../../chunks/IconCopyLink-7b8d27fe.js";import{C as A}from"../../chunks/CodeBlock-37867453.js";function uo(L){let p,C,f,y,P,h,D,q,E,w,I,z,j,N;return{c(){p=r("p"),C=a("\u270E Par d\xE9faut, \u{1F917} Datasets d\xE9compressera les fichiers n\xE9cessaires pour charger un jeu de donn\xE9es. Si vous souhaitez conserver de l\u2019espace sur le disque dur, vous pouvez passer "),f=r("code"),y=a("DownloadConfig(delete_extracted=True)"),P=a(" \xE0 l\u2019argument "),h=r("code"),D=a("download_config"),q=a(" de "),E=r("code"),w=a("load_dataset()"),I=a(". Voir la "),z=r("a"),j=a("documentation"),N=a(" pour plus de d\xE9tails."),this.h()},l(O){p=o(O,"P",{});var k=i(p);C=n(k,"\u270E Par d\xE9faut, \u{1F917} Datasets d\xE9compressera les fichiers n\xE9cessaires pour charger un jeu de donn\xE9es. Si vous souhaitez conserver de l\u2019espace sur le disque dur, vous pouvez passer "),f=o(k,"CODE",{});var T=i(f);y=n(T,"DownloadConfig(delete_extracted=True)"),T.forEach(t),P=n(k," \xE0 l\u2019argument "),h=o(k,"CODE",{});var J=i(h);D=n(J,"download_config"),J.forEach(t),q=n(k," de "),E=o(k,"CODE",{});var R=i(E);w=n(R,"load_dataset()"),R.forEach(t),I=n(k,". Voir la "),z=o(k,"A",{href:!0,rel:!0});var te=i(z);j=n(te,"documentation"),te.forEach(t),N=n(k," pour plus de d\xE9tails."),k.forEach(t),this.h()},h(){c(z,"href","https://huggingface.co/docs/datasets/package_reference/builder_classes.html?#datasets.utils.DownloadConfig"),c(z,"rel","nofollow")},m(O,k){u(O,p,k),s(p,C),s(p,f),s(f,y),s(p,P),s(p,h),s(h,D),s(p,q),s(p,E),s(E,w),s(p,I),s(p,z),s(z,j),s(p,N)},d(O){O&&t(p)}}}function po(L){let p,C,f,y,P,h,D,q,E,w,I;return{c(){p=r("p"),C=a("\u270F\uFE0F "),f=r("strong"),y=a("Essayez-le\xA0!"),P=a(" Choisissez l\u2019un des "),h=r("a"),D=a("sous-ensembles"),q=a(" de la Pile qui est plus grand que la RAM de votre ordinateur portable ou de bureau, chargez avec \u{1F917} Datasets, et mesurez la quantit\xE9 de RAM utilis\xE9e. Notez que pour obtenir une mesure pr\xE9cise, vous devrez le faire dans un nouveau processus. Vous pouvez trouver les tailles d\xE9compress\xE9es de chaque sous-ensemble dans le tableau 1 de "),E=r("a"),w=a("the Pile paper"),I=a("."),this.h()},l(z){p=o(z,"P",{});var j=i(p);C=n(j,"\u270F\uFE0F "),f=o(j,"STRONG",{});var N=i(f);y=n(N,"Essayez-le\xA0!"),N.forEach(t),P=n(j," Choisissez l\u2019un des "),h=o(j,"A",{href:!0,rel:!0});var O=i(h);D=n(O,"sous-ensembles"),O.forEach(t),q=n(j," de la Pile qui est plus grand que la RAM de votre ordinateur portable ou de bureau, chargez avec \u{1F917} Datasets, et mesurez la quantit\xE9 de RAM utilis\xE9e. Notez que pour obtenir une mesure pr\xE9cise, vous devrez le faire dans un nouveau processus. Vous pouvez trouver les tailles d\xE9compress\xE9es de chaque sous-ensemble dans le tableau 1 de "),E=o(j,"A",{href:!0,rel:!0});var k=i(E);w=n(k,"the Pile paper"),k.forEach(t),I=n(j,"."),j.forEach(t),this.h()},h(){c(h,"href","https://mystic.the-eye.eu/public/AI/pile_preliminary_components/"),c(h,"rel","nofollow"),c(E,"href","https://arxiv.org/abs/2101.00027"),c(E,"rel","nofollow")},m(z,j){u(z,p,j),s(p,C),s(p,f),s(f,y),s(p,P),s(p,h),s(h,D),s(p,q),s(p,E),s(E,w),s(p,I)},d(z){z&&t(p)}}}function mo(L){let p,C,f,y,P,h;return{c(){p=r("p"),C=a("\u{1F4A1} Dans les notebooks Jupyter, vous pouvez \xE9galement chronom\xE9trer les cellules \xE0 l\u2019aide de la fonction magique "),f=r("a"),y=r("code"),P=a("%%timeit"),h=a("."),this.h()},l(D){p=o(D,"P",{});var q=i(p);C=n(q,"\u{1F4A1} Dans les notebooks Jupyter, vous pouvez \xE9galement chronom\xE9trer les cellules \xE0 l\u2019aide de la fonction magique "),f=o(q,"A",{href:!0,rel:!0});var E=i(f);y=o(E,"CODE",{});var w=i(y);P=n(w,"%%timeit"),w.forEach(t),E.forEach(t),h=n(q,"."),q.forEach(t),this.h()},h(){c(f,"href","https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit"),c(f,"rel","nofollow")},m(D,q){u(D,p,q),s(p,C),s(p,f),s(f,y),s(y,P),s(p,h)},d(D){D&&t(p)}}}function co(L){let p,C,f,y,P,h,D,q;return{c(){p=r("p"),C=a("\u{1F4A1} Pour acc\xE9l\xE9rer la tokenisation avec le streaming, vous pouvez passer "),f=r("code"),y=a("batched=True"),P=a(", comme nous l\u2019avons vu dans la derni\xE8re section. Il traitera les exemples lot par lot ; la taille de lot par d\xE9faut est de 1 000 et peut \xEAtre sp\xE9cifi\xE9e avec l\u2019argument "),h=r("code"),D=a("batch_size"),q=a(".")},l(E){p=o(E,"P",{});var w=i(p);C=n(w,"\u{1F4A1} Pour acc\xE9l\xE9rer la tokenisation avec le streaming, vous pouvez passer "),f=o(w,"CODE",{});var I=i(f);y=n(I,"batched=True"),I.forEach(t),P=n(w,", comme nous l\u2019avons vu dans la derni\xE8re section. Il traitera les exemples lot par lot ; la taille de lot par d\xE9faut est de 1 000 et peut \xEAtre sp\xE9cifi\xE9e avec l\u2019argument "),h=o(w,"CODE",{});var z=i(h);D=n(z,"batch_size"),z.forEach(t),q=n(w,"."),w.forEach(t)},m(E,w){u(E,p,w),s(p,C),s(p,f),s(f,y),s(p,P),s(p,h),s(h,D),s(p,q)},d(E){E&&t(p)}}}function fo(L){let p,C,f,y,P,h,D,q,E,w,I,z,j,N,O;return{c(){p=r("p"),C=a("\u270F\uFE0F "),f=r("strong"),y=a("Essayez-le\xA0!"),P=a(" Utilisez l\u2019un des grands corpus Common Crawl comme "),h=r("a"),D=r("code"),q=a("mc4"),E=a(" ou ["),w=r("code"),I=a("oscar"),z=a("]("),j=r("a"),N=a("https://huggingface.co"),O=a(" /datasets/oscar) pour cr\xE9er un jeu de donn\xE9es multilingue en continu qui repr\xE9sente les proportions de langues parl\xE9es dans un pays de votre choix. Par exemple, les quatre langues nationales en Suisse sont l\u2019allemand, le fran\xE7ais, l\u2019italien et le romanche, vous pouvez donc essayer de cr\xE9er un corpus suisse en \xE9chantillonnant les sous-ensembles Oscar en fonction de leur proportion parl\xE9e."),this.h()},l(k){p=o(k,"P",{});var T=i(p);C=n(T,"\u270F\uFE0F "),f=o(T,"STRONG",{});var J=i(f);y=n(J,"Essayez-le\xA0!"),J.forEach(t),P=n(T," Utilisez l\u2019un des grands corpus Common Crawl comme "),h=o(T,"A",{href:!0,rel:!0});var R=i(h);D=o(R,"CODE",{});var te=i(D);q=n(te,"mc4"),te.forEach(t),R.forEach(t),E=n(T," ou ["),w=o(T,"CODE",{});var re=i(w);I=n(re,"oscar"),re.forEach(t),z=n(T,"]("),j=o(T,"A",{href:!0,rel:!0});var hs=i(j);N=n(hs,"https://huggingface.co"),hs.forEach(t),O=n(T," /datasets/oscar) pour cr\xE9er un jeu de donn\xE9es multilingue en continu qui repr\xE9sente les proportions de langues parl\xE9es dans un pays de votre choix. Par exemple, les quatre langues nationales en Suisse sont l\u2019allemand, le fran\xE7ais, l\u2019italien et le romanche, vous pouvez donc essayer de cr\xE9er un corpus suisse en \xE9chantillonnant les sous-ensembles Oscar en fonction de leur proportion parl\xE9e."),T.forEach(t),this.h()},h(){c(h,"href","https://huggingface.co/datasets/mc4"),c(h,"rel","nofollow"),c(j,"href","https://huggingface.co"),c(j,"rel","nofollow")},m(k,T){u(k,p,T),s(p,C),s(p,f),s(f,y),s(p,P),s(p,h),s(h,D),s(D,q),s(p,E),s(p,w),s(w,I),s(p,z),s(p,j),s(j,N),s(p,O)},d(k){k&&t(p)}}}function ho(L){let p,C,f,y,P,h,D,q,E,w,I,z,j,N,O,k,T,J,R,te,re,hs,Ra,ks,Ma,Sa,_t,Ee,xt,oe,Na,we,Ga,La,$t,ae,ie,Cs,qe,Ha,Is,Ua,jt,M,Ba,Ae,Fa,Va,De,Wa,Ja,Pe,Ka,Ya,ze,Za,Qa,Ts,Xa,en,yt,ke,Et,ue,sn,bs,tn,an,wt,Ce,qt,Ie,At,gs,nn,Dt,pe,Pt,vs,ln,zt,Te,kt,Oe,Ct,_s,rn,It,ne,de,Os,Re,on,Rs,un,Tt,K,pn,Me,Ms,dn,mn,Ss,cn,fn,Ot,Se,Rt,me,hn,Ns,bn,gn,Mt,Ne,St,Ge,Nt,H,vn,Gs,_n,xn,Ls,$n,jn,Hs,yn,En,Gt,Le,Lt,He,Ht,xs,wn,Ut,ce,Bt,Y,qn,Ue,An,Dn,Be,Pn,zn,Ft,S,kn,Us,Cn,In,Fe,Tn,On,Bs,Rn,Mn,Ve,Sn,Nn,We,Gn,Ln,Vt,Je,Wt,Ke,Jt,Z,Hn,Fs,Un,Bn,Vs,Fn,Vn,Kt,fe,Yt,le,he,Ws,Ye,Wn,Js,Jn,Zt,Q,Kn,Ks,Yn,Zn,Ys,Qn,Xn,Qt,Ze,Xt,G,el,Zs,sl,tl,Qs,al,nl,Xs,ll,rl,et,ol,il,ea,Qe,sa,Xe,ta,X,ul,st,pl,dl,$s,ml,cl,aa,es,na,ss,la,be,ra,U,fl,tt,hl,bl,at,gl,vl,nt,_l,xl,oa,ts,ia,as,ua,B,$l,lt,jl,yl,rt,El,wl,ot,ql,Al,pa,ns,da,ls,ma,ge,Dl,it,Pl,zl,ca,rs,fa,F,kl,ut,Cl,Il,pt,Tl,Ol,dt,Rl,Ml,ha,os,ba,is,ga,ve,Sl,mt,Nl,Gl,va,us,_a,ps,xa,ee,Ll,ct,Hl,Ul,ft,Bl,Fl,$a,js,Vl,ja,ds,ya,ms,Ea,_e,wa,ys,Wl,qa;return h=new Oa({}),I=new oo({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter5/section4.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter5/section4.ipynb"}]}}),Ee=new io({props:{id:"JwISwTCPPWo"}}),qe=new Oa({}),ke=new A({props:{code:"!pip install zstandard",highlighted:"!pip install zstandard"}}),Ce=new A({props:{code:`from datasets import load_dataset

# Cela prend quelques minutes \xE0 ex\xE9cuter, alors allez prendre un th\xE9 ou un caf\xE9 en attendant :)
data_files = "https://mystic.the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst"
pubmed_dataset = load_dataset("json", data_files=data_files, split="train")
pubmed_dataset`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-comment"># Cela prend quelques minutes \xE0 ex\xE9cuter, alors allez prendre un th\xE9 ou un caf\xE9 en attendant :)</span>
data_files = <span class="hljs-string">&quot;https://mystic.the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst&quot;</span>
pubmed_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, split=<span class="hljs-string">&quot;train&quot;</span>)
pubmed_dataset`}}),Ie=new A({props:{code:`Dataset({
    features: ['meta', 'text'],
    num_rows: 15518009
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;meta&#x27;</span>, <span class="hljs-string">&#x27;text&#x27;</span>],
    num_rows: <span class="hljs-number">15518009</span>
})`}}),pe=new vt({props:{$$slots:{default:[uo]},$$scope:{ctx:L}}}),Te=new A({props:{code:"pubmed_dataset[0]",highlighted:'pubmed_dataset[<span class="hljs-number">0</span>]'}}),Oe=new A({props:{code:`{'meta': {'pmid': 11409574, 'language': 'eng'},
 'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection.\\nTo determine the prevalence of hypoxaemia in children aged under 5 years suffering acute lower respiratory infections (ALRI), the risk factors for hypoxaemia in children under 5 years of age with ALRI, and the association of hypoxaemia with an increased risk of dying in children of the same age ...'}`,highlighted:`{<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;pmid&#x27;</span>: <span class="hljs-number">11409574</span>, <span class="hljs-string">&#x27;language&#x27;</span>: <span class="hljs-string">&#x27;eng&#x27;</span>},
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Epidemiology of hypoxaemia in children with acute lower respiratory infection.\\nTo determine the prevalence of hypoxaemia in children aged under 5 years suffering acute lower respiratory infections (ALRI), the risk factors for hypoxaemia in children under 5 years of age with ALRI, and the association of hypoxaemia with an increased risk of dying in children of the same age ...&#x27;</span>}`}}),Re=new Oa({}),Se=new A({props:{code:"!pip install psutil",highlighted:"!pip install psutil"}}),Ne=new A({props:{code:`import psutil

# Process.memory_info is expressed in bytes, so convert to megabytes
print(f"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB")`,highlighted:`<span class="hljs-keyword">import</span> psutil

<span class="hljs-comment"># Process.memory_info is expressed in bytes, so convert to megabytes</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;RAM used: <span class="hljs-subst">{psutil.Process().memory_info().rss / (<span class="hljs-number">1024</span> * <span class="hljs-number">1024</span>):<span class="hljs-number">.2</span>f}</span> MB&quot;</span>)`}}),Ge=new A({props:{code:"RAM used: 5678.33 MB",highlighted:'RAM used: <span class="hljs-number">5678.33</span> MB'}}),Le=new A({props:{code:`print(f"Number of files in dataset : {pubmed_dataset.dataset_size}")
size_gb = pubmed_dataset.dataset_size / (1024**3)
print(f"Dataset size (cache file) : {size_gb:.2f} GB")`,highlighted:`<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Number of files in dataset : <span class="hljs-subst">{pubmed_dataset.dataset_size}</span>&quot;</span>)
size_gb = pubmed_dataset.dataset_size / (<span class="hljs-number">1024</span>**<span class="hljs-number">3</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Dataset size (cache file) : <span class="hljs-subst">{size_gb:<span class="hljs-number">.2</span>f}</span> GB&quot;</span>)`}}),He=new A({props:{code:`Number of files in dataset : 20979437051
Dataset size (cache file) : 19.54 GB`,highlighted:`Number of files <span class="hljs-keyword">in</span> dataset : <span class="hljs-number">20979437051</span>
Dataset size (cache file) : <span class="hljs-number">19.54</span> GB`}}),ce=new vt({props:{$$slots:{default:[po]},$$scope:{ctx:L}}}),Je=new A({props:{code:`import timeit

code_snippet = """batch_size = 1000

for idx in range(0, len(pubmed_dataset), batch_size):
    _ = pubmed_dataset[idx:idx + batch_size]
"""

time = timeit.timeit(stmt=code_snippet, number=1, globals=globals())
print(
    f"Iterated over {len(pubmed_dataset)} examples (about {size_gb:.1f} GB) in "
    f"{time:.1f}s, i.e. {size_gb/time:.3f} GB/s"
)`,highlighted:`<span class="hljs-keyword">import</span> timeit

code_snippet = <span class="hljs-string">&quot;&quot;&quot;batch_size = 1000

for idx in range(0, len(pubmed_dataset), batch_size):
    _ = pubmed_dataset[idx:idx + batch_size]
&quot;&quot;&quot;</span>

time = timeit.timeit(stmt=code_snippet, number=<span class="hljs-number">1</span>, <span class="hljs-built_in">globals</span>=<span class="hljs-built_in">globals</span>())
<span class="hljs-built_in">print</span>(
    <span class="hljs-string">f&quot;Iterated over <span class="hljs-subst">{<span class="hljs-built_in">len</span>(pubmed_dataset)}</span> examples (about <span class="hljs-subst">{size_gb:<span class="hljs-number">.1</span>f}</span> GB) in &quot;</span>
    <span class="hljs-string">f&quot;<span class="hljs-subst">{time:<span class="hljs-number">.1</span>f}</span>s, i.e. <span class="hljs-subst">{size_gb/time:<span class="hljs-number">.3</span>f}</span> GB/s&quot;</span>
)`}}),Ke=new A({props:{code:"'Iterated over 15518009 examples (about 19.5 GB) in 64.2s, i.e. 0.304 GB/s'",highlighted:'<span class="hljs-string">&#x27;Iterated over 15518009 examples (about 19.5 GB) in 64.2s, i.e. 0.304 GB/s&#x27;</span>'}}),fe=new vt({props:{$$slots:{default:[mo]},$$scope:{ctx:L}}}),Ye=new Oa({}),Ze=new A({props:{code:`pubmed_dataset_streamed = load_dataset(
    "json", data_files=data_files, split="train", streaming=True
)`,highlighted:`pubmed_dataset_streamed = load_dataset(
    <span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, split=<span class="hljs-string">&quot;train&quot;</span>, streaming=<span class="hljs-literal">True</span>
)`}}),Qe=new A({props:{code:"next(iter(pubmed_dataset_streamed))",highlighted:'<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(pubmed_dataset_streamed))'}}),Xe=new A({props:{code:`{'meta': {'pmid': 11409574, 'language': 'eng'},
 'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection.\\nTo determine the prevalence of hypoxaemia in children aged under 5 years suffering acute lower respiratory infections (ALRI), the risk factors for hypoxaemia in children under 5 years of age with ALRI, and the association of hypoxaemia with an increased risk of dying in children of the same age ...'}`,highlighted:`{<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;pmid&#x27;</span>: <span class="hljs-number">11409574</span>, <span class="hljs-string">&#x27;language&#x27;</span>: <span class="hljs-string">&#x27;eng&#x27;</span>},
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Epidemiology of hypoxaemia in children with acute lower respiratory infection.\\nTo determine the prevalence of hypoxaemia in children aged under 5 years suffering acute lower respiratory infections (ALRI), the risk factors for hypoxaemia in children under 5 years of age with ALRI, and the association of hypoxaemia with an increased risk of dying in children of the same age ...&#x27;</span>}`}}),es=new A({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
tokenized_dataset = pubmed_dataset_streamed.map(lambda x: tokenizer(x["text"]))
next(iter(tokenized_dataset))`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
tokenized_dataset = pubmed_dataset_streamed.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: tokenizer(x[<span class="hljs-string">&quot;text&quot;</span>]))
<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(tokenized_dataset))`}}),ss=new A({props:{code:"{'input_ids': [101, 4958, 5178, 4328, 6779, ...], 'attention_mask': [1, 1, 1, 1, 1, ...]}",highlighted:'{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">4958</span>, <span class="hljs-number">5178</span>, <span class="hljs-number">4328</span>, <span class="hljs-number">6779</span>, ...], <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, ...]}'}}),be=new vt({props:{$$slots:{default:[co]},$$scope:{ctx:L}}}),ts=new A({props:{code:`shuffled_dataset = pubmed_dataset_streamed.shuffle(buffer_size=10_000, seed=42)
next(iter(shuffled_dataset))`,highlighted:`shuffled_dataset = pubmed_dataset_streamed.shuffle(buffer_size=<span class="hljs-number">10_000</span>, seed=<span class="hljs-number">42</span>)
<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(shuffled_dataset))`}}),as=new A({props:{code:`{'meta': {'pmid': 11410799, 'language': 'eng'},
 'text': 'Randomized study of dose or schedule modification of granulocyte colony-stimulating factor in platinum-based chemotherapy for elderly patients with lung cancer ...'}`,highlighted:`{<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;pmid&#x27;</span>: <span class="hljs-number">11410799</span>, <span class="hljs-string">&#x27;language&#x27;</span>: <span class="hljs-string">&#x27;eng&#x27;</span>},
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Randomized study of dose or schedule modification of granulocyte colony-stimulating factor in platinum-based chemotherapy for elderly patients with lung cancer ...&#x27;</span>}`}}),ns=new A({props:{code:`dataset_head = pubmed_dataset_streamed.take(5)
list(dataset_head)`,highlighted:`dataset_head = pubmed_dataset_streamed.take(<span class="hljs-number">5</span>)
<span class="hljs-built_in">list</span>(dataset_head)`}}),ls=new A({props:{code:`[{'meta': {'pmid': 11409574, 'language': 'eng'},
  'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection ...'},
 {'meta': {'pmid': 11409575, 'language': 'eng'},
  'text': 'Clinical signs of hypoxaemia in children with acute lower respiratory infection: indicators of oxygen therapy ...'},
 {'meta': {'pmid': 11409576, 'language': 'eng'},
  'text': "Hypoxaemia in children with severe pneumonia in Papua New Guinea ..."},
 {'meta': {'pmid': 11409577, 'language': 'eng'},
  'text': 'Oxygen concentrators and cylinders ...'},
 {'meta': {'pmid': 11409578, 'language': 'eng'},
  'text': 'Oxygen supply in rural africa: a personal experience ...'}]`,highlighted:`[{<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;pmid&#x27;</span>: <span class="hljs-number">11409574</span>, <span class="hljs-string">&#x27;language&#x27;</span>: <span class="hljs-string">&#x27;eng&#x27;</span>},
  <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Epidemiology of hypoxaemia in children with acute lower respiratory infection ...&#x27;</span>},
 {<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;pmid&#x27;</span>: <span class="hljs-number">11409575</span>, <span class="hljs-string">&#x27;language&#x27;</span>: <span class="hljs-string">&#x27;eng&#x27;</span>},
  <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Clinical signs of hypoxaemia in children with acute lower respiratory infection: indicators of oxygen therapy ...&#x27;</span>},
 {<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;pmid&#x27;</span>: <span class="hljs-number">11409576</span>, <span class="hljs-string">&#x27;language&#x27;</span>: <span class="hljs-string">&#x27;eng&#x27;</span>},
  <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&quot;Hypoxaemia in children with severe pneumonia in Papua New Guinea ...&quot;</span>},
 {<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;pmid&#x27;</span>: <span class="hljs-number">11409577</span>, <span class="hljs-string">&#x27;language&#x27;</span>: <span class="hljs-string">&#x27;eng&#x27;</span>},
  <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Oxygen concentrators and cylinders ...&#x27;</span>},
 {<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;pmid&#x27;</span>: <span class="hljs-number">11409578</span>, <span class="hljs-string">&#x27;language&#x27;</span>: <span class="hljs-string">&#x27;eng&#x27;</span>},
  <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Oxygen supply in rural africa: a personal experience ...&#x27;</span>}]`}}),rs=new A({props:{code:`# Skip the first 1,000 examples and include the rest in the training set
train_dataset = shuffled_dataset.skip(1000)
# Take the first 1,000 examples for the validation set
validation_dataset = shuffled_dataset.take(1000)`,highlighted:`<span class="hljs-comment"># Skip the first 1,000 examples and include the rest in the training set</span>
train_dataset = shuffled_dataset.skip(<span class="hljs-number">1000</span>)
<span class="hljs-comment"># Take the first 1,000 examples for the validation set</span>
validation_dataset = shuffled_dataset.take(<span class="hljs-number">1000</span>)`}}),os=new A({props:{code:`law_dataset_streamed = load_dataset(
    "json",
    data_files="https://mystic.the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst",
    split="train",
    streaming=True,
)
next(iter(law_dataset_streamed))`,highlighted:`law_dataset_streamed = load_dataset(
    <span class="hljs-string">&quot;json&quot;</span>,
    data_files=<span class="hljs-string">&quot;https://mystic.the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst&quot;</span>,
    split=<span class="hljs-string">&quot;train&quot;</span>,
    streaming=<span class="hljs-literal">True</span>,
)
<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(law_dataset_streamed))`}}),is=new A({props:{code:`{'meta': {'case_ID': '110921.json',
  'case_jurisdiction': 'scotus.tar.gz',
  'date_created': '2010-04-28T17:12:49Z'},
 'text': '\\n461 U.S. 238 (1983)\\nOLIM ET AL.\\nv.\\nWAKINEKONA\\nNo. 81-1581.\\nSupreme Court of United States.\\nArgued January 19, 1983.\\nDecided April 26, 1983.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General...'}`,highlighted:`{<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;case_ID&#x27;</span>: <span class="hljs-string">&#x27;110921.json&#x27;</span>,
  <span class="hljs-string">&#x27;case_jurisdiction&#x27;</span>: <span class="hljs-string">&#x27;scotus.tar.gz&#x27;</span>,
  <span class="hljs-string">&#x27;date_created&#x27;</span>: <span class="hljs-string">&#x27;2010-04-28T17:12:49Z&#x27;</span>},
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;\\n461 U.S. 238 (1983)\\nOLIM ET AL.\\nv.\\nWAKINEKONA\\nNo. 81-1581.\\nSupreme Court of United States.\\nArgued January 19, 1983.\\nDecided April 26, 1983.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General...&#x27;</span>}`}}),us=new A({props:{code:`from itertools import islice
from datasets import interleave_datasets

combined_dataset = interleave_datasets([pubmed_dataset_streamed, law_dataset_streamed])
list(islice(combined_dataset, 2))`,highlighted:`<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> islice
<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> interleave_datasets

combined_dataset = interleave_datasets([pubmed_dataset_streamed, law_dataset_streamed])
<span class="hljs-built_in">list</span>(islice(combined_dataset, <span class="hljs-number">2</span>))`}}),ps=new A({props:{code:`[{'meta': {'pmid': 11409574, 'language': 'eng'},
  'text': 'Epidemiology of hypoxaemia in children with acute lower respiratory infection ...'},
 {'meta': {'case_ID': '110921.json',
   'case_jurisdiction': 'scotus.tar.gz',
   'date_created': '2010-04-28T17:12:49Z'},
  'text': '\\n461 U.S. 238 (1983)\\nOLIM ET AL.\\nv.\\nWAKINEKONA\\nNo. 81-1581.\\nSupreme Court of United States.\\nArgued January 19, 1983.\\nDecided April 26, 1983.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General...'}]`,highlighted:`[{<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;pmid&#x27;</span>: <span class="hljs-number">11409574</span>, <span class="hljs-string">&#x27;language&#x27;</span>: <span class="hljs-string">&#x27;eng&#x27;</span>},
  <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;Epidemiology of hypoxaemia in children with acute lower respiratory infection ...&#x27;</span>},
 {<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;case_ID&#x27;</span>: <span class="hljs-string">&#x27;110921.json&#x27;</span>,
   <span class="hljs-string">&#x27;case_jurisdiction&#x27;</span>: <span class="hljs-string">&#x27;scotus.tar.gz&#x27;</span>,
   <span class="hljs-string">&#x27;date_created&#x27;</span>: <span class="hljs-string">&#x27;2010-04-28T17:12:49Z&#x27;</span>},
  <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;\\n461 U.S. 238 (1983)\\nOLIM ET AL.\\nv.\\nWAKINEKONA\\nNo. 81-1581.\\nSupreme Court of United States.\\nArgued January 19, 1983.\\nDecided April 26, 1983.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*239 Michael A. Lilly, First Deputy Attorney General of Hawaii, argued the cause for petitioners. With him on the brief was James H. Dannenberg, Deputy Attorney General...&#x27;</span>}]`}}),ds=new A({props:{code:`base_url = "https://mystic.the-eye.eu/public/AI/pile/"
data_files = {
    "train": [base_url + "train/" + f"{idx:02d}.jsonl.zst" for idx in range(30)],
    "validation": base_url + "val.jsonl.zst",
    "test": base_url + "test.jsonl.zst",
}
pile_dataset = load_dataset("json", data_files=data_files, streaming=True)
next(iter(pile_dataset["train"]))`,highlighted:`base_url = <span class="hljs-string">&quot;https://mystic.the-eye.eu/public/AI/pile/&quot;</span>
data_files = {
    <span class="hljs-string">&quot;train&quot;</span>: [base_url + <span class="hljs-string">&quot;train/&quot;</span> + <span class="hljs-string">f&quot;<span class="hljs-subst">{idx:02d}</span>.jsonl.zst&quot;</span> <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">30</span>)],
    <span class="hljs-string">&quot;validation&quot;</span>: base_url + <span class="hljs-string">&quot;val.jsonl.zst&quot;</span>,
    <span class="hljs-string">&quot;test&quot;</span>: base_url + <span class="hljs-string">&quot;test.jsonl.zst&quot;</span>,
}
pile_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, streaming=<span class="hljs-literal">True</span>)
<span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(pile_dataset[<span class="hljs-string">&quot;train&quot;</span>]))`}}),ms=new A({props:{code:`{'meta': {'pile_set_name': 'Pile-CC'},
 'text': 'It is done, and submitted. You can play \u201CSurvival of the Tastiest\u201D on Android, and on the web...'}`,highlighted:`{<span class="hljs-string">&#x27;meta&#x27;</span>: {<span class="hljs-string">&#x27;pile_set_name&#x27;</span>: <span class="hljs-string">&#x27;Pile-CC&#x27;</span>},
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;It is done, and submitted. You can play \u201CSurvival of the Tastiest\u201D on Android, and on the web...&#x27;</span>}`}}),_e=new vt({props:{$$slots:{default:[fo]},$$scope:{ctx:L}}}),{c(){p=r("meta"),C=d(),f=r("h1"),y=r("a"),P=r("span"),b(h.$$.fragment),D=d(),q=r("span"),E=a("Big Data? \u{1F917} Datasets \xE0 la rescousse\xA0!"),w=d(),b(I.$$.fragment),z=d(),j=r("p"),N=a("De nos jours, il n\u2019est pas rare de travailler avec des ensembles de donn\xE9es de plusieurs gigaoctets, surtout si vous envisagez de pr\xE9-entra\xEEner un transformateur comme BERT ou GPT-2 \xE0 partir de z\xE9ro. Dans ces cas, m\xEAme "),O=r("em"),k=a("charger"),T=a(" les donn\xE9es peut \xEAtre un d\xE9fi. Par exemple, le corpus WebText utilis\xE9 pour pr\xE9-entra\xEEner GPT-2 se compose de plus de 8 millions de documents et de 40 Go de texte - le charger dans la RAM de votre ordinateur portable est susceptible de lui donner une crise cardiaque !"),J=d(),R=r("p"),te=a("Heureusement, \u{1F917} Datasets a \xE9t\xE9 con\xE7u pour surmonter ces limitations. Il vous lib\xE8re des probl\xE8mes de gestion de la m\xE9moire en traitant les ensembles de donn\xE9es comme des fichiers "),re=r("em"),hs=a("mapp\xE9s en m\xE9moire"),Ra=a(", et des limites du disque dur en "),ks=r("em"),Ma=a("streaming"),Sa=a(" les entr\xE9es dans un corpus."),_t=d(),b(Ee.$$.fragment),xt=d(),oe=r("p"),Na=a("Dans cette section, nous allons explorer ces fonctionnalit\xE9s de \u{1F917} Datasets avec un \xE9norme corpus de 825 Go connu sous le nom de "),we=r("a"),Ga=a("the Pile"),La=a(". Commen\xE7ons!"),$t=d(),ae=r("h2"),ie=r("a"),Cs=r("span"),b(qe.$$.fragment),Ha=d(),Is=r("span"),Ua=a("Qu'est-ce que The Pile ?"),jt=d(),M=r("p"),Ba=a("The Pile est un corpus de texte en anglais cr\xE9\xE9 par "),Ae=r("a"),Fa=a("EleutherAI"),Va=a(" pour entra\xEEner des mod\xE8les de langage \xE0 grande \xE9chelle. Il comprend une gamme vari\xE9e d\u2019ensembles de donn\xE9es, couvrant des articles scientifiques, des r\xE9f\xE9rentiels de code GitHub et du texte Web filtr\xE9. Le corpus de formation est disponible en "),De=r("a"),Wa=a("morceaux de 14 Go"),Ja=a(", et vous pouvez \xE9galement t\xE9l\xE9charger plusieurs des [composants individuels](https://mystic .the-eye.eu/public/AI/pile_preliminary_components/). Commen\xE7ons par jeter un coup d\u2019\u0153il \xE0 l\u2019ensemble de donn\xE9es PubMed Abstracts, qui est un corpus de r\xE9sum\xE9s de 15 millions de publications biom\xE9dicales sur "),Pe=r("a"),Ka=a("PubMed"),Ya=a(". L\u2019ensemble de donn\xE9es est au "),ze=r("a"),Za=a("format JSON Lines"),Qa=a(" et est compress\xE9 \xE0 l\u2019aide de la biblioth\xE8que "),Ts=r("code"),Xa=a("zstandard"),en=a(", nous devons donc d\u2019abord l\u2019installer\xA0:"),yt=d(),b(ke.$$.fragment),Et=d(),ue=r("p"),sn=a("Ensuite, nous pouvons charger le jeu de donn\xE9es en utilisant la m\xE9thode pour les fichiers distants que nous avons apprise dans "),bs=r("a"),tn=a("section\xA02"),an=a("\xA0:"),wt=d(),b(Ce.$$.fragment),qt=d(),b(Ie.$$.fragment),At=d(),gs=r("p"),nn=a("Nous pouvons voir qu\u2019il y a 15 518 009 lignes et 2 colonnes dans notre ensemble de donn\xE9es \u2014 c\u2019est beaucoup\xA0!"),Dt=d(),b(pe.$$.fragment),Pt=d(),vs=r("p"),ln=a("Inspectons le contenu du premier exemple\xA0:"),zt=d(),b(Te.$$.fragment),kt=d(),b(Oe.$$.fragment),Ct=d(),_s=r("p"),rn=a("OK, \xE7a ressemble au r\xE9sum\xE9 d\u2019un article m\xE9dical. Voyons maintenant combien de RAM nous avons utilis\xE9 pour charger le jeu de donn\xE9es\xA0!"),It=d(),ne=r("h2"),de=r("a"),Os=r("span"),b(Re.$$.fragment),on=d(),Rs=r("span"),un=a("La magie de la cartographie m\xE9moire"),Tt=d(),K=r("p"),pn=a("Un moyen simple de mesurer l\u2019utilisation de la m\xE9moire dans Python consiste \xE0 utiliser la biblioth\xE8que "),Me=r("a"),Ms=r("code"),dn=a("psutil"),mn=a(", qui peut \xEAtre install\xE9e avec "),Ss=r("code"),cn=a("pip"),fn=a(" comme suit\xA0:"),Ot=d(),b(Se.$$.fragment),Rt=d(),me=r("p"),hn=a("Il fournit une classe "),Ns=r("code"),bn=a("Process"),gn=a(" qui nous permet de v\xE9rifier l\u2019utilisation de la m\xE9moire du processus en cours comme suit\xA0:"),Mt=d(),b(Ne.$$.fragment),St=d(),b(Ge.$$.fragment),Nt=d(),H=r("p"),vn=a("Ici, l\u2019attribut "),Gs=r("code"),_n=a("rss"),xn=a(" fait r\xE9f\xE9rence \xE0 la "),Ls=r("em"),$n=a("taille de l\u2019ensemble r\xE9sident"),jn=a(", qui est la fraction de m\xE9moire qu\u2019un processus occupe dans la RAM. Cette mesure inclut \xE9galement la m\xE9moire utilis\xE9e par l\u2019interpr\xE9teur Python et les biblioth\xE8ques que nous avons charg\xE9es, de sorte que la quantit\xE9 r\xE9elle de m\xE9moire utilis\xE9e pour charger l\u2019ensemble de donn\xE9es est un peu plus petite. \xC0 titre de comparaison, voyons la taille de l\u2019ensemble de donn\xE9es sur le disque, en utilisant l\u2019attribut "),Hs=r("code"),yn=a("dataset_size"),En=a(". Comme le r\xE9sultat est exprim\xE9 en octets comme pr\xE9c\xE9demment, nous devons le convertir manuellement en gigaoctets\xA0:"),Gt=d(),b(Le.$$.fragment),Lt=d(),b(He.$$.fragment),Ht=d(),xs=r("p"),wn=a("Bien - malgr\xE9 sa taille de pr\xE8s de 20 Go, nous pouvons charger et acc\xE9der \xE0 l\u2019ensemble de donn\xE9es avec beaucoup moins de RAM\xA0!"),Ut=d(),b(ce.$$.fragment),Bt=d(),Y=r("p"),qn=a("Si vous \xEAtes familier avec les pandas, ce r\xE9sultat pourrait surprendre en raison de la c\xE9l\xE8bre "),Ue=r("a"),An=a("r\xE8gle d\u2019or"),Dn=a(" de Wes Kinney selon laquelle vous avez g\xE9n\xE9ralement besoin de 5 \xE0 10 fois plus de RAM que la taille de votre jeu de donn\xE9es. Alors, comment \u{1F917} Datasets r\xE9sout-il ce probl\xE8me de gestion de la m\xE9moire\xA0? \u{1F917} Datasets traite chaque ensemble de donn\xE9es comme un [fichier mapp\xE9 en m\xE9moire] ("),Be=r("a"),Pn=a("https://en.wikipedia.org/wiki/Memory-mapped_file"),zn=a("), qui fournit un mappage entre la RAM et le stockage du syst\xE8me de fichiers qui permet \xE0 la biblioth\xE8que d\u2019acc\xE9der et d\u2019op\xE9rer sur des \xE9l\xE9ments du jeu de donn\xE9es sans avoir besoin de le charger enti\xE8rement en m\xE9moire."),Ft=d(),S=r("p"),kn=a("Les fichiers mapp\xE9s en m\xE9moire peuvent \xE9galement \xEAtre partag\xE9s entre plusieurs processus, ce qui permet de parall\xE9liser des m\xE9thodes telles que "),Us=r("code"),Cn=a("Dataset.map()"),In=a(" sans avoir \xE0 d\xE9placer ou copier l\u2019ensemble de donn\xE9es. Sous le capot, ces capacit\xE9s sont toutes r\xE9alis\xE9es par le format de m\xE9moire "),Fe=r("a"),Tn=a("Apache Arrow"),On=a(" et ["),Bs=r("code"),Rn=a("pyarrow"),Mn=a("]("),Ve=r("a"),Sn=a("https://arrow.apache.org/docs/python/index"),Nn=a(" .html), qui acc\xE9l\xE8rent le chargement et le traitement des donn\xE9es. (Pour plus de d\xE9tails sur Apache Arrow et les comparaisons avec Pandas, consultez "),We=r("a"),Gn=a("l\u2019article de blog de Dejan Simic"),Ln=a(".) Pour voir ceci en action, effectuons un petit test de vitesse en it\xE9rant sur tous les \xE9l\xE9ments du jeu de donn\xE9es PubMed Abstracts\xA0:"),Vt=d(),b(Je.$$.fragment),Wt=d(),b(Ke.$$.fragment),Jt=d(),Z=r("p"),Hn=a("Ici, nous avons utilis\xE9 le module "),Fs=r("code"),Un=a("timeit"),Bn=a(" de Python pour mesurer le temps d\u2019ex\xE9cution pris par "),Vs=r("code"),Fn=a("code_snippet"),Vn=a(". Vous pourrez g\xE9n\xE9ralement it\xE9rer sur un ensemble de donn\xE9es \xE0 une vitesse de quelques dixi\xE8mes de Go/s \xE0 plusieurs Go/s. Cela fonctionne tr\xE8s bien pour la grande majorit\xE9 des applications, mais vous devrez parfois travailler avec un ensemble de donn\xE9es trop volumineux pour \xEAtre m\xEAme stock\xE9 sur le disque dur de votre ordinateur portable. Par exemple, si nous essayions de t\xE9l\xE9charger la Pile dans son int\xE9gralit\xE9, nous aurions besoin de 825 Go d\u2019espace disque libre ! Pour g\xE9rer ces cas, \u{1F917} Datasets fournit une fonctionnalit\xE9 de streaming qui nous permet de t\xE9l\xE9charger et d\u2019acc\xE9der aux \xE9l\xE9ments \xE0 la vol\xE9e, sans avoir besoin de t\xE9l\xE9charger l\u2019int\xE9gralit\xE9 du jeu de donn\xE9es. Voyons comment cela fonctionne."),Kt=d(),b(fe.$$.fragment),Yt=d(),le=r("h2"),he=r("a"),Ws=r("span"),b(Ye.$$.fragment),Wn=d(),Js=r("span"),Jn=a("Ensembles de donn\xE9es en continu"),Zt=d(),Q=r("p"),Kn=a("Pour activer le streaming de l\u2019ensemble de donn\xE9es, il vous suffit de passer l\u2019argument "),Ks=r("code"),Yn=a("streaming=True"),Zn=a(" \xE0 la fonction "),Ys=r("code"),Qn=a("load_dataset()"),Xn=a(". Par exemple, chargeons \xE0 nouveau le jeu de donn\xE9es PubMed Abstracts, mais en mode streaming\xA0:"),Qt=d(),b(Ze.$$.fragment),Xt=d(),G=r("p"),el=a("Au lieu du familier "),Zs=r("code"),sl=a("Dataset"),tl=a(" que nous avons rencontr\xE9 ailleurs dans ce chapitre, l\u2019objet retourn\xE9 avec "),Qs=r("code"),al=a("streaming=True"),nl=a(" est un "),Xs=r("code"),ll=a("IterableDataset"),rl=a(". Comme son nom l\u2019indique, pour acc\xE9der aux \xE9l\xE9ments d\u2019un "),et=r("code"),ol=a("IterableDataset"),il=a(", nous devons parcourir celui-ci. Nous pouvons acc\xE9der au premier \xE9l\xE9ment de notre jeu de donn\xE9es diffus\xE9 comme suit\xA0:"),ea=d(),b(Qe.$$.fragment),sa=d(),b(Xe.$$.fragment),ta=d(),X=r("p"),ul=a("Les \xE9l\xE9ments d\u2019un ensemble de donn\xE9es diffus\xE9 en continu peuvent \xEAtre trait\xE9s \xE0 la vol\xE9e \xE0 l\u2019aide de "),st=r("code"),pl=a("IterableDataset.map()"),dl=a(", ce qui est utile pendant la formation si vous avez besoin de tokeniser les entr\xE9es. Le processus est exactement le m\xEAme que celui que nous avons utilis\xE9 pour tokeniser notre jeu de donn\xE9es dans "),$s=r("a"),ml=a("Chapitre 3"),cl=a(", \xE0 la seule diff\xE9rence que les sorties sont renvoy\xE9es une par une\xA0:"),aa=d(),b(es.$$.fragment),na=d(),b(ss.$$.fragment),la=d(),b(be.$$.fragment),ra=d(),U=r("p"),fl=a("Vous pouvez \xE9galement m\xE9langer un ensemble de donn\xE9es diffus\xE9 en continu \xE0 l\u2019aide de "),tt=r("code"),hl=a("IterableDataset.shuffle()"),bl=a(", mais contrairement \xE0 "),at=r("code"),gl=a("Dataset.shuffle()"),vl=a(", cela ne m\xE9lange que les \xE9l\xE9ments dans un "),nt=r("code"),_l=a("buffer_size"),xl=a(" pr\xE9d\xE9fini\xA0:"),oa=d(),b(ts.$$.fragment),ia=d(),b(as.$$.fragment),ua=d(),B=r("p"),$l=a("Dans cet exemple, nous avons s\xE9lectionn\xE9 un exemple al\xE9atoire parmi les 10 000 premiers exemples du tampon. Une fois qu\u2019un exemple est acc\xE9d\xE9, sa place dans le tampon est remplie avec l\u2019exemple suivant dans le corpus (c\u2019est-\xE0-dire le 10 001e exemple dans le cas ci-dessus). Vous pouvez \xE9galement s\xE9lectionner des \xE9l\xE9ments d\u2019un ensemble de donn\xE9es diffus\xE9 en continu \xE0 l\u2019aide des fonctions "),lt=r("code"),jl=a("IterableDataset.take()"),yl=a(" et "),rt=r("code"),El=a("IterableDataset.skip()"),wl=a(", qui agissent de la m\xEAme mani\xE8re que "),ot=r("code"),ql=a("Dataset.select()"),Al=a(". Par exemple, pour s\xE9lectionner les 5 premiers exemples dans l\u2019ensemble de donn\xE9es PubMed Abstracts, nous pouvons proc\xE9der comme suit\xA0:"),pa=d(),b(ns.$$.fragment),da=d(),b(ls.$$.fragment),ma=d(),ge=r("p"),Dl=a("De m\xEAme, vous pouvez utiliser la fonction "),it=r("code"),Pl=a("IterableDataset.skip()"),zl=a(" pour cr\xE9er des fractionnements d\u2019entra\xEEnement et de validation \xE0 partir d\u2019un ensemble de donn\xE9es m\xE9lang\xE9 comme suit\xA0:"),ca=d(),b(rs.$$.fragment),fa=d(),F=r("p"),kl=a("Terminons notre exploration du streaming d\u2019ensembles de donn\xE9es avec une application commune\xA0: combiner plusieurs ensembles de donn\xE9es pour cr\xE9er un seul corpus. \u{1F917} Datasets fournit une fonction "),ut=r("code"),Cl=a("interleave_datasets()"),Il=a(" qui convertit une liste d\u2019objets "),pt=r("code"),Tl=a("IterableDataset"),Ol=a(" en un seul "),dt=r("code"),Rl=a("IterableDataset"),Ml=a(", o\xF9 les \xE9l\xE9ments du nouveau jeu de donn\xE9es sont obtenus en alternant entre les exemples source. Cette fonction est particuli\xE8rement utile lorsque vous essayez de combiner de grands ensembles de donn\xE9es. Par exemple, diffusons le sous-ensemble FreeLaw de la pile, qui est un ensemble de donn\xE9es de 51\xA0Go d\u2019avis juridiques de tribunaux am\xE9ricains\xA0:"),ha=d(),b(os.$$.fragment),ba=d(),b(is.$$.fragment),ga=d(),ve=r("p"),Sl=a("Cet ensemble de donn\xE9es est suffisamment volumineux pour solliciter la RAM de la plupart des ordinateurs portables, mais nous avons pu le charger et y acc\xE9der sans transpirer\xA0! Combinons maintenant les exemples des jeux de donn\xE9es FreeLaw et PubMed Abstracts avec la fonction "),mt=r("code"),Nl=a("interleave_datasets()"),Gl=a("\xA0:"),va=d(),b(us.$$.fragment),_a=d(),b(ps.$$.fragment),xa=d(),ee=r("p"),Ll=a("Ici, nous avons utilis\xE9 la fonction "),ct=r("code"),Hl=a("islice()"),Ul=a(" du module "),ft=r("code"),Bl=a("itertools"),Fl=a(" de Python pour s\xE9lectionner les deux premiers exemples de l\u2019ensemble de donn\xE9es combin\xE9, et nous pouvons voir qu\u2019ils correspondent aux premiers exemples de chacun des deux ensembles de donn\xE9es source."),$a=d(),js=r("p"),Vl=a("Enfin, si vous souhaitez diffuser le Pile dans son int\xE9gralit\xE9 de 825 Go, vous pouvez r\xE9cup\xE9rer tous les fichiers pr\xE9par\xE9s comme suit :"),ja=d(),b(ds.$$.fragment),ya=d(),b(ms.$$.fragment),Ea=d(),b(_e.$$.fragment),wa=d(),ys=r("p"),Wl=a("Vous disposez maintenant de tous les outils dont vous avez besoin pour charger et traiter des ensembles de donn\xE9es de toutes formes et tailles - mais \xE0 moins que vous ne soyez exceptionnellement chanceux, il arrivera un moment dans votre parcours PNL o\xF9 vous devrez r\xE9ellement cr\xE9er un ensemble de donn\xE9es pour r\xE9soudre le probl\xE8me \xE0 port\xE9e de main. C\u2019est le sujet de la section suivante !"),this.h()},l(e){const l=lo('[data-svelte="svelte-1phssyn"]',document.head);p=o(l,"META",{name:!0,content:!0}),l.forEach(t),C=m(e),f=o(e,"H1",{class:!0});var cs=i(f);y=o(cs,"A",{id:!0,class:!0,href:!0});var ht=i(y);P=o(ht,"SPAN",{});var bt=i(P);g(h.$$.fragment,bt),bt.forEach(t),ht.forEach(t),D=m(cs),q=o(cs,"SPAN",{});var gt=i(q);E=n(gt,"Big Data? \u{1F917} Datasets \xE0 la rescousse\xA0!"),gt.forEach(t),cs.forEach(t),w=m(e),g(I.$$.fragment,e),z=m(e),j=o(e,"P",{});var fs=i(j);N=n(fs,"De nos jours, il n\u2019est pas rare de travailler avec des ensembles de donn\xE9es de plusieurs gigaoctets, surtout si vous envisagez de pr\xE9-entra\xEEner un transformateur comme BERT ou GPT-2 \xE0 partir de z\xE9ro. Dans ces cas, m\xEAme "),O=o(fs,"EM",{});var Jl=i(O);k=n(Jl,"charger"),Jl.forEach(t),T=n(fs," les donn\xE9es peut \xEAtre un d\xE9fi. Par exemple, le corpus WebText utilis\xE9 pour pr\xE9-entra\xEEner GPT-2 se compose de plus de 8 millions de documents et de 40 Go de texte - le charger dans la RAM de votre ordinateur portable est susceptible de lui donner une crise cardiaque !"),fs.forEach(t),J=m(e),R=o(e,"P",{});var Es=i(R);te=n(Es,"Heureusement, \u{1F917} Datasets a \xE9t\xE9 con\xE7u pour surmonter ces limitations. Il vous lib\xE8re des probl\xE8mes de gestion de la m\xE9moire en traitant les ensembles de donn\xE9es comme des fichiers "),re=o(Es,"EM",{});var Kl=i(re);hs=n(Kl,"mapp\xE9s en m\xE9moire"),Kl.forEach(t),Ra=n(Es,", et des limites du disque dur en "),ks=o(Es,"EM",{});var Yl=i(ks);Ma=n(Yl,"streaming"),Yl.forEach(t),Sa=n(Es," les entr\xE9es dans un corpus."),Es.forEach(t),_t=m(e),g(Ee.$$.fragment,e),xt=m(e),oe=o(e,"P",{});var Aa=i(oe);Na=n(Aa,"Dans cette section, nous allons explorer ces fonctionnalit\xE9s de \u{1F917} Datasets avec un \xE9norme corpus de 825 Go connu sous le nom de "),we=o(Aa,"A",{href:!0,rel:!0});var Zl=i(we);Ga=n(Zl,"the Pile"),Zl.forEach(t),La=n(Aa,". Commen\xE7ons!"),Aa.forEach(t),$t=m(e),ae=o(e,"H2",{class:!0});var Da=i(ae);ie=o(Da,"A",{id:!0,class:!0,href:!0});var Ql=i(ie);Cs=o(Ql,"SPAN",{});var Xl=i(Cs);g(qe.$$.fragment,Xl),Xl.forEach(t),Ql.forEach(t),Ha=m(Da),Is=o(Da,"SPAN",{});var er=i(Is);Ua=n(er,"Qu'est-ce que The Pile ?"),er.forEach(t),Da.forEach(t),jt=m(e),M=o(e,"P",{});var V=i(M);Ba=n(V,"The Pile est un corpus de texte en anglais cr\xE9\xE9 par "),Ae=o(V,"A",{href:!0,rel:!0});var sr=i(Ae);Fa=n(sr,"EleutherAI"),sr.forEach(t),Va=n(V," pour entra\xEEner des mod\xE8les de langage \xE0 grande \xE9chelle. Il comprend une gamme vari\xE9e d\u2019ensembles de donn\xE9es, couvrant des articles scientifiques, des r\xE9f\xE9rentiels de code GitHub et du texte Web filtr\xE9. Le corpus de formation est disponible en "),De=o(V,"A",{href:!0,rel:!0});var tr=i(De);Wa=n(tr,"morceaux de 14 Go"),tr.forEach(t),Ja=n(V,", et vous pouvez \xE9galement t\xE9l\xE9charger plusieurs des [composants individuels](https://mystic .the-eye.eu/public/AI/pile_preliminary_components/). Commen\xE7ons par jeter un coup d\u2019\u0153il \xE0 l\u2019ensemble de donn\xE9es PubMed Abstracts, qui est un corpus de r\xE9sum\xE9s de 15 millions de publications biom\xE9dicales sur "),Pe=o(V,"A",{href:!0,rel:!0});var ar=i(Pe);Ka=n(ar,"PubMed"),ar.forEach(t),Ya=n(V,". L\u2019ensemble de donn\xE9es est au "),ze=o(V,"A",{href:!0,rel:!0});var nr=i(ze);Za=n(nr,"format JSON Lines"),nr.forEach(t),Qa=n(V," et est compress\xE9 \xE0 l\u2019aide de la biblioth\xE8que "),Ts=o(V,"CODE",{});var lr=i(Ts);Xa=n(lr,"zstandard"),lr.forEach(t),en=n(V,", nous devons donc d\u2019abord l\u2019installer\xA0:"),V.forEach(t),yt=m(e),g(ke.$$.fragment,e),Et=m(e),ue=o(e,"P",{});var Pa=i(ue);sn=n(Pa,"Ensuite, nous pouvons charger le jeu de donn\xE9es en utilisant la m\xE9thode pour les fichiers distants que nous avons apprise dans "),bs=o(Pa,"A",{href:!0});var rr=i(bs);tn=n(rr,"section\xA02"),rr.forEach(t),an=n(Pa,"\xA0:"),Pa.forEach(t),wt=m(e),g(Ce.$$.fragment,e),qt=m(e),g(Ie.$$.fragment,e),At=m(e),gs=o(e,"P",{});var or=i(gs);nn=n(or,"Nous pouvons voir qu\u2019il y a 15 518 009 lignes et 2 colonnes dans notre ensemble de donn\xE9es \u2014 c\u2019est beaucoup\xA0!"),or.forEach(t),Dt=m(e),g(pe.$$.fragment,e),Pt=m(e),vs=o(e,"P",{});var ir=i(vs);ln=n(ir,"Inspectons le contenu du premier exemple\xA0:"),ir.forEach(t),zt=m(e),g(Te.$$.fragment,e),kt=m(e),g(Oe.$$.fragment,e),Ct=m(e),_s=o(e,"P",{});var ur=i(_s);rn=n(ur,"OK, \xE7a ressemble au r\xE9sum\xE9 d\u2019un article m\xE9dical. Voyons maintenant combien de RAM nous avons utilis\xE9 pour charger le jeu de donn\xE9es\xA0!"),ur.forEach(t),It=m(e),ne=o(e,"H2",{class:!0});var za=i(ne);de=o(za,"A",{id:!0,class:!0,href:!0});var pr=i(de);Os=o(pr,"SPAN",{});var dr=i(Os);g(Re.$$.fragment,dr),dr.forEach(t),pr.forEach(t),on=m(za),Rs=o(za,"SPAN",{});var mr=i(Rs);un=n(mr,"La magie de la cartographie m\xE9moire"),mr.forEach(t),za.forEach(t),Tt=m(e),K=o(e,"P",{});var ws=i(K);pn=n(ws,"Un moyen simple de mesurer l\u2019utilisation de la m\xE9moire dans Python consiste \xE0 utiliser la biblioth\xE8que "),Me=o(ws,"A",{href:!0,rel:!0});var cr=i(Me);Ms=o(cr,"CODE",{});var fr=i(Ms);dn=n(fr,"psutil"),fr.forEach(t),cr.forEach(t),mn=n(ws,", qui peut \xEAtre install\xE9e avec "),Ss=o(ws,"CODE",{});var hr=i(Ss);cn=n(hr,"pip"),hr.forEach(t),fn=n(ws," comme suit\xA0:"),ws.forEach(t),Ot=m(e),g(Se.$$.fragment,e),Rt=m(e),me=o(e,"P",{});var ka=i(me);hn=n(ka,"Il fournit une classe "),Ns=o(ka,"CODE",{});var br=i(Ns);bn=n(br,"Process"),br.forEach(t),gn=n(ka," qui nous permet de v\xE9rifier l\u2019utilisation de la m\xE9moire du processus en cours comme suit\xA0:"),ka.forEach(t),Mt=m(e),g(Ne.$$.fragment,e),St=m(e),g(Ge.$$.fragment,e),Nt=m(e),H=o(e,"P",{});var xe=i(H);vn=n(xe,"Ici, l\u2019attribut "),Gs=o(xe,"CODE",{});var gr=i(Gs);_n=n(gr,"rss"),gr.forEach(t),xn=n(xe," fait r\xE9f\xE9rence \xE0 la "),Ls=o(xe,"EM",{});var vr=i(Ls);$n=n(vr,"taille de l\u2019ensemble r\xE9sident"),vr.forEach(t),jn=n(xe,", qui est la fraction de m\xE9moire qu\u2019un processus occupe dans la RAM. Cette mesure inclut \xE9galement la m\xE9moire utilis\xE9e par l\u2019interpr\xE9teur Python et les biblioth\xE8ques que nous avons charg\xE9es, de sorte que la quantit\xE9 r\xE9elle de m\xE9moire utilis\xE9e pour charger l\u2019ensemble de donn\xE9es est un peu plus petite. \xC0 titre de comparaison, voyons la taille de l\u2019ensemble de donn\xE9es sur le disque, en utilisant l\u2019attribut "),Hs=o(xe,"CODE",{});var _r=i(Hs);yn=n(_r,"dataset_size"),_r.forEach(t),En=n(xe,". Comme le r\xE9sultat est exprim\xE9 en octets comme pr\xE9c\xE9demment, nous devons le convertir manuellement en gigaoctets\xA0:"),xe.forEach(t),Gt=m(e),g(Le.$$.fragment,e),Lt=m(e),g(He.$$.fragment,e),Ht=m(e),xs=o(e,"P",{});var xr=i(xs);wn=n(xr,"Bien - malgr\xE9 sa taille de pr\xE8s de 20 Go, nous pouvons charger et acc\xE9der \xE0 l\u2019ensemble de donn\xE9es avec beaucoup moins de RAM\xA0!"),xr.forEach(t),Ut=m(e),g(ce.$$.fragment,e),Bt=m(e),Y=o(e,"P",{});var qs=i(Y);qn=n(qs,"Si vous \xEAtes familier avec les pandas, ce r\xE9sultat pourrait surprendre en raison de la c\xE9l\xE8bre "),Ue=o(qs,"A",{href:!0,rel:!0});var $r=i(Ue);An=n($r,"r\xE8gle d\u2019or"),$r.forEach(t),Dn=n(qs," de Wes Kinney selon laquelle vous avez g\xE9n\xE9ralement besoin de 5 \xE0 10 fois plus de RAM que la taille de votre jeu de donn\xE9es. Alors, comment \u{1F917} Datasets r\xE9sout-il ce probl\xE8me de gestion de la m\xE9moire\xA0? \u{1F917} Datasets traite chaque ensemble de donn\xE9es comme un [fichier mapp\xE9 en m\xE9moire] ("),Be=o(qs,"A",{href:!0,rel:!0});var jr=i(Be);Pn=n(jr,"https://en.wikipedia.org/wiki/Memory-mapped_file"),jr.forEach(t),zn=n(qs,"), qui fournit un mappage entre la RAM et le stockage du syst\xE8me de fichiers qui permet \xE0 la biblioth\xE8que d\u2019acc\xE9der et d\u2019op\xE9rer sur des \xE9l\xE9ments du jeu de donn\xE9es sans avoir besoin de le charger enti\xE8rement en m\xE9moire."),qs.forEach(t),Ft=m(e),S=o(e,"P",{});var W=i(S);kn=n(W,"Les fichiers mapp\xE9s en m\xE9moire peuvent \xE9galement \xEAtre partag\xE9s entre plusieurs processus, ce qui permet de parall\xE9liser des m\xE9thodes telles que "),Us=o(W,"CODE",{});var yr=i(Us);Cn=n(yr,"Dataset.map()"),yr.forEach(t),In=n(W," sans avoir \xE0 d\xE9placer ou copier l\u2019ensemble de donn\xE9es. Sous le capot, ces capacit\xE9s sont toutes r\xE9alis\xE9es par le format de m\xE9moire "),Fe=o(W,"A",{href:!0,rel:!0});var Er=i(Fe);Tn=n(Er,"Apache Arrow"),Er.forEach(t),On=n(W," et ["),Bs=o(W,"CODE",{});var wr=i(Bs);Rn=n(wr,"pyarrow"),wr.forEach(t),Mn=n(W,"]("),Ve=o(W,"A",{href:!0,rel:!0});var qr=i(Ve);Sn=n(qr,"https://arrow.apache.org/docs/python/index"),qr.forEach(t),Nn=n(W," .html), qui acc\xE9l\xE8rent le chargement et le traitement des donn\xE9es. (Pour plus de d\xE9tails sur Apache Arrow et les comparaisons avec Pandas, consultez "),We=o(W,"A",{href:!0,rel:!0});var Ar=i(We);Gn=n(Ar,"l\u2019article de blog de Dejan Simic"),Ar.forEach(t),Ln=n(W,".) Pour voir ceci en action, effectuons un petit test de vitesse en it\xE9rant sur tous les \xE9l\xE9ments du jeu de donn\xE9es PubMed Abstracts\xA0:"),W.forEach(t),Vt=m(e),g(Je.$$.fragment,e),Wt=m(e),g(Ke.$$.fragment,e),Jt=m(e),Z=o(e,"P",{});var As=i(Z);Hn=n(As,"Ici, nous avons utilis\xE9 le module "),Fs=o(As,"CODE",{});var Dr=i(Fs);Un=n(Dr,"timeit"),Dr.forEach(t),Bn=n(As," de Python pour mesurer le temps d\u2019ex\xE9cution pris par "),Vs=o(As,"CODE",{});var Pr=i(Vs);Fn=n(Pr,"code_snippet"),Pr.forEach(t),Vn=n(As,". Vous pourrez g\xE9n\xE9ralement it\xE9rer sur un ensemble de donn\xE9es \xE0 une vitesse de quelques dixi\xE8mes de Go/s \xE0 plusieurs Go/s. Cela fonctionne tr\xE8s bien pour la grande majorit\xE9 des applications, mais vous devrez parfois travailler avec un ensemble de donn\xE9es trop volumineux pour \xEAtre m\xEAme stock\xE9 sur le disque dur de votre ordinateur portable. Par exemple, si nous essayions de t\xE9l\xE9charger la Pile dans son int\xE9gralit\xE9, nous aurions besoin de 825 Go d\u2019espace disque libre ! Pour g\xE9rer ces cas, \u{1F917} Datasets fournit une fonctionnalit\xE9 de streaming qui nous permet de t\xE9l\xE9charger et d\u2019acc\xE9der aux \xE9l\xE9ments \xE0 la vol\xE9e, sans avoir besoin de t\xE9l\xE9charger l\u2019int\xE9gralit\xE9 du jeu de donn\xE9es. Voyons comment cela fonctionne."),As.forEach(t),Kt=m(e),g(fe.$$.fragment,e),Yt=m(e),le=o(e,"H2",{class:!0});var Ca=i(le);he=o(Ca,"A",{id:!0,class:!0,href:!0});var zr=i(he);Ws=o(zr,"SPAN",{});var kr=i(Ws);g(Ye.$$.fragment,kr),kr.forEach(t),zr.forEach(t),Wn=m(Ca),Js=o(Ca,"SPAN",{});var Cr=i(Js);Jn=n(Cr,"Ensembles de donn\xE9es en continu"),Cr.forEach(t),Ca.forEach(t),Zt=m(e),Q=o(e,"P",{});var Ds=i(Q);Kn=n(Ds,"Pour activer le streaming de l\u2019ensemble de donn\xE9es, il vous suffit de passer l\u2019argument "),Ks=o(Ds,"CODE",{});var Ir=i(Ks);Yn=n(Ir,"streaming=True"),Ir.forEach(t),Zn=n(Ds," \xE0 la fonction "),Ys=o(Ds,"CODE",{});var Tr=i(Ys);Qn=n(Tr,"load_dataset()"),Tr.forEach(t),Xn=n(Ds,". Par exemple, chargeons \xE0 nouveau le jeu de donn\xE9es PubMed Abstracts, mais en mode streaming\xA0:"),Ds.forEach(t),Qt=m(e),g(Ze.$$.fragment,e),Xt=m(e),G=o(e,"P",{});var se=i(G);el=n(se,"Au lieu du familier "),Zs=o(se,"CODE",{});var Or=i(Zs);sl=n(Or,"Dataset"),Or.forEach(t),tl=n(se," que nous avons rencontr\xE9 ailleurs dans ce chapitre, l\u2019objet retourn\xE9 avec "),Qs=o(se,"CODE",{});var Rr=i(Qs);al=n(Rr,"streaming=True"),Rr.forEach(t),nl=n(se," est un "),Xs=o(se,"CODE",{});var Mr=i(Xs);ll=n(Mr,"IterableDataset"),Mr.forEach(t),rl=n(se,". Comme son nom l\u2019indique, pour acc\xE9der aux \xE9l\xE9ments d\u2019un "),et=o(se,"CODE",{});var Sr=i(et);ol=n(Sr,"IterableDataset"),Sr.forEach(t),il=n(se,", nous devons parcourir celui-ci. Nous pouvons acc\xE9der au premier \xE9l\xE9ment de notre jeu de donn\xE9es diffus\xE9 comme suit\xA0:"),se.forEach(t),ea=m(e),g(Qe.$$.fragment,e),sa=m(e),g(Xe.$$.fragment,e),ta=m(e),X=o(e,"P",{});var Ps=i(X);ul=n(Ps,"Les \xE9l\xE9ments d\u2019un ensemble de donn\xE9es diffus\xE9 en continu peuvent \xEAtre trait\xE9s \xE0 la vol\xE9e \xE0 l\u2019aide de "),st=o(Ps,"CODE",{});var Nr=i(st);pl=n(Nr,"IterableDataset.map()"),Nr.forEach(t),dl=n(Ps,", ce qui est utile pendant la formation si vous avez besoin de tokeniser les entr\xE9es. Le processus est exactement le m\xEAme que celui que nous avons utilis\xE9 pour tokeniser notre jeu de donn\xE9es dans "),$s=o(Ps,"A",{href:!0});var Gr=i($s);ml=n(Gr,"Chapitre 3"),Gr.forEach(t),cl=n(Ps,", \xE0 la seule diff\xE9rence que les sorties sont renvoy\xE9es une par une\xA0:"),Ps.forEach(t),aa=m(e),g(es.$$.fragment,e),na=m(e),g(ss.$$.fragment,e),la=m(e),g(be.$$.fragment,e),ra=m(e),U=o(e,"P",{});var $e=i(U);fl=n($e,"Vous pouvez \xE9galement m\xE9langer un ensemble de donn\xE9es diffus\xE9 en continu \xE0 l\u2019aide de "),tt=o($e,"CODE",{});var Lr=i(tt);hl=n(Lr,"IterableDataset.shuffle()"),Lr.forEach(t),bl=n($e,", mais contrairement \xE0 "),at=o($e,"CODE",{});var Hr=i(at);gl=n(Hr,"Dataset.shuffle()"),Hr.forEach(t),vl=n($e,", cela ne m\xE9lange que les \xE9l\xE9ments dans un "),nt=o($e,"CODE",{});var Ur=i(nt);_l=n(Ur,"buffer_size"),Ur.forEach(t),xl=n($e," pr\xE9d\xE9fini\xA0:"),$e.forEach(t),oa=m(e),g(ts.$$.fragment,e),ia=m(e),g(as.$$.fragment,e),ua=m(e),B=o(e,"P",{});var je=i(B);$l=n(je,"Dans cet exemple, nous avons s\xE9lectionn\xE9 un exemple al\xE9atoire parmi les 10 000 premiers exemples du tampon. Une fois qu\u2019un exemple est acc\xE9d\xE9, sa place dans le tampon est remplie avec l\u2019exemple suivant dans le corpus (c\u2019est-\xE0-dire le 10 001e exemple dans le cas ci-dessus). Vous pouvez \xE9galement s\xE9lectionner des \xE9l\xE9ments d\u2019un ensemble de donn\xE9es diffus\xE9 en continu \xE0 l\u2019aide des fonctions "),lt=o(je,"CODE",{});var Br=i(lt);jl=n(Br,"IterableDataset.take()"),Br.forEach(t),yl=n(je," et "),rt=o(je,"CODE",{});var Fr=i(rt);El=n(Fr,"IterableDataset.skip()"),Fr.forEach(t),wl=n(je,", qui agissent de la m\xEAme mani\xE8re que "),ot=o(je,"CODE",{});var Vr=i(ot);ql=n(Vr,"Dataset.select()"),Vr.forEach(t),Al=n(je,". Par exemple, pour s\xE9lectionner les 5 premiers exemples dans l\u2019ensemble de donn\xE9es PubMed Abstracts, nous pouvons proc\xE9der comme suit\xA0:"),je.forEach(t),pa=m(e),g(ns.$$.fragment,e),da=m(e),g(ls.$$.fragment,e),ma=m(e),ge=o(e,"P",{});var Ia=i(ge);Dl=n(Ia,"De m\xEAme, vous pouvez utiliser la fonction "),it=o(Ia,"CODE",{});var Wr=i(it);Pl=n(Wr,"IterableDataset.skip()"),Wr.forEach(t),zl=n(Ia," pour cr\xE9er des fractionnements d\u2019entra\xEEnement et de validation \xE0 partir d\u2019un ensemble de donn\xE9es m\xE9lang\xE9 comme suit\xA0:"),Ia.forEach(t),ca=m(e),g(rs.$$.fragment,e),fa=m(e),F=o(e,"P",{});var ye=i(F);kl=n(ye,"Terminons notre exploration du streaming d\u2019ensembles de donn\xE9es avec une application commune\xA0: combiner plusieurs ensembles de donn\xE9es pour cr\xE9er un seul corpus. \u{1F917} Datasets fournit une fonction "),ut=o(ye,"CODE",{});var Jr=i(ut);Cl=n(Jr,"interleave_datasets()"),Jr.forEach(t),Il=n(ye," qui convertit une liste d\u2019objets "),pt=o(ye,"CODE",{});var Kr=i(pt);Tl=n(Kr,"IterableDataset"),Kr.forEach(t),Ol=n(ye," en un seul "),dt=o(ye,"CODE",{});var Yr=i(dt);Rl=n(Yr,"IterableDataset"),Yr.forEach(t),Ml=n(ye,", o\xF9 les \xE9l\xE9ments du nouveau jeu de donn\xE9es sont obtenus en alternant entre les exemples source. Cette fonction est particuli\xE8rement utile lorsque vous essayez de combiner de grands ensembles de donn\xE9es. Par exemple, diffusons le sous-ensemble FreeLaw de la pile, qui est un ensemble de donn\xE9es de 51\xA0Go d\u2019avis juridiques de tribunaux am\xE9ricains\xA0:"),ye.forEach(t),ha=m(e),g(os.$$.fragment,e),ba=m(e),g(is.$$.fragment,e),ga=m(e),ve=o(e,"P",{});var Ta=i(ve);Sl=n(Ta,"Cet ensemble de donn\xE9es est suffisamment volumineux pour solliciter la RAM de la plupart des ordinateurs portables, mais nous avons pu le charger et y acc\xE9der sans transpirer\xA0! Combinons maintenant les exemples des jeux de donn\xE9es FreeLaw et PubMed Abstracts avec la fonction "),mt=o(Ta,"CODE",{});var Zr=i(mt);Nl=n(Zr,"interleave_datasets()"),Zr.forEach(t),Gl=n(Ta,"\xA0:"),Ta.forEach(t),va=m(e),g(us.$$.fragment,e),_a=m(e),g(ps.$$.fragment,e),xa=m(e),ee=o(e,"P",{});var zs=i(ee);Ll=n(zs,"Ici, nous avons utilis\xE9 la fonction "),ct=o(zs,"CODE",{});var Qr=i(ct);Hl=n(Qr,"islice()"),Qr.forEach(t),Ul=n(zs," du module "),ft=o(zs,"CODE",{});var Xr=i(ft);Bl=n(Xr,"itertools"),Xr.forEach(t),Fl=n(zs," de Python pour s\xE9lectionner les deux premiers exemples de l\u2019ensemble de donn\xE9es combin\xE9, et nous pouvons voir qu\u2019ils correspondent aux premiers exemples de chacun des deux ensembles de donn\xE9es source."),zs.forEach(t),$a=m(e),js=o(e,"P",{});var eo=i(js);Vl=n(eo,"Enfin, si vous souhaitez diffuser le Pile dans son int\xE9gralit\xE9 de 825 Go, vous pouvez r\xE9cup\xE9rer tous les fichiers pr\xE9par\xE9s comme suit :"),eo.forEach(t),ja=m(e),g(ds.$$.fragment,e),ya=m(e),g(ms.$$.fragment,e),Ea=m(e),g(_e.$$.fragment,e),wa=m(e),ys=o(e,"P",{});var so=i(ys);Wl=n(so,"Vous disposez maintenant de tous les outils dont vous avez besoin pour charger et traiter des ensembles de donn\xE9es de toutes formes et tailles - mais \xE0 moins que vous ne soyez exceptionnellement chanceux, il arrivera un moment dans votre parcours PNL o\xF9 vous devrez r\xE9ellement cr\xE9er un ensemble de donn\xE9es pour r\xE9soudre le probl\xE8me \xE0 port\xE9e de main. C\u2019est le sujet de la section suivante !"),so.forEach(t),this.h()},h(){c(p,"name","hf:doc:metadata"),c(p,"content",JSON.stringify(bo)),c(y,"id","big-data-datasets-la-rescousse"),c(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y,"href","#big-data-datasets-la-rescousse"),c(f,"class","relative group"),c(we,"href","https://pile.eleuther.ai"),c(we,"rel","nofollow"),c(ie,"id","questce-que-the-pile"),c(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ie,"href","#questce-que-the-pile"),c(ae,"class","relative group"),c(Ae,"href","https://www.eleuther.ai"),c(Ae,"rel","nofollow"),c(De,"href","https://mystic.the-eye.eu/public/AI/pile/"),c(De,"rel","nofollow"),c(Pe,"href","https://pubmed.ncbi.nlm.nih.gov/"),c(Pe,"rel","nofollow"),c(ze,"href","https://jsonlines.org"),c(ze,"rel","nofollow"),c(bs,"href","/course/chapter5/2"),c(de,"id","la-magie-de-la-cartographie-mmoire"),c(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(de,"href","#la-magie-de-la-cartographie-mmoire"),c(ne,"class","relative group"),c(Me,"href","https://psutil.readthedocs.io/en/latest/"),c(Me,"rel","nofollow"),c(Ue,"href","https://wesmckinney.com/blog/apache-arrow-pandas-internals/"),c(Ue,"rel","nofollow"),c(Be,"href","https://en.wikipedia.org/wiki/Memory-mapped_file"),c(Be,"rel","nofollow"),c(Fe,"href","https://arrow.apache.org"),c(Fe,"rel","nofollow"),c(Ve,"href","https://arrow.apache.org/docs/python/index"),c(Ve,"rel","nofollow"),c(We,"href","https://towardsdatascience.com/apache-arrow-read-dataframe-with-zero-memory-69634092b1a"),c(We,"rel","nofollow"),c(he,"id","ensembles-de-donnes-en-continu"),c(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(he,"href","#ensembles-de-donnes-en-continu"),c(le,"class","relative group"),c($s,"href","/course/chapter3")},m(e,l){s(document.head,p),u(e,C,l),u(e,f,l),s(f,y),s(y,P),v(h,P,null),s(f,D),s(f,q),s(q,E),u(e,w,l),v(I,e,l),u(e,z,l),u(e,j,l),s(j,N),s(j,O),s(O,k),s(j,T),u(e,J,l),u(e,R,l),s(R,te),s(R,re),s(re,hs),s(R,Ra),s(R,ks),s(ks,Ma),s(R,Sa),u(e,_t,l),v(Ee,e,l),u(e,xt,l),u(e,oe,l),s(oe,Na),s(oe,we),s(we,Ga),s(oe,La),u(e,$t,l),u(e,ae,l),s(ae,ie),s(ie,Cs),v(qe,Cs,null),s(ae,Ha),s(ae,Is),s(Is,Ua),u(e,jt,l),u(e,M,l),s(M,Ba),s(M,Ae),s(Ae,Fa),s(M,Va),s(M,De),s(De,Wa),s(M,Ja),s(M,Pe),s(Pe,Ka),s(M,Ya),s(M,ze),s(ze,Za),s(M,Qa),s(M,Ts),s(Ts,Xa),s(M,en),u(e,yt,l),v(ke,e,l),u(e,Et,l),u(e,ue,l),s(ue,sn),s(ue,bs),s(bs,tn),s(ue,an),u(e,wt,l),v(Ce,e,l),u(e,qt,l),v(Ie,e,l),u(e,At,l),u(e,gs,l),s(gs,nn),u(e,Dt,l),v(pe,e,l),u(e,Pt,l),u(e,vs,l),s(vs,ln),u(e,zt,l),v(Te,e,l),u(e,kt,l),v(Oe,e,l),u(e,Ct,l),u(e,_s,l),s(_s,rn),u(e,It,l),u(e,ne,l),s(ne,de),s(de,Os),v(Re,Os,null),s(ne,on),s(ne,Rs),s(Rs,un),u(e,Tt,l),u(e,K,l),s(K,pn),s(K,Me),s(Me,Ms),s(Ms,dn),s(K,mn),s(K,Ss),s(Ss,cn),s(K,fn),u(e,Ot,l),v(Se,e,l),u(e,Rt,l),u(e,me,l),s(me,hn),s(me,Ns),s(Ns,bn),s(me,gn),u(e,Mt,l),v(Ne,e,l),u(e,St,l),v(Ge,e,l),u(e,Nt,l),u(e,H,l),s(H,vn),s(H,Gs),s(Gs,_n),s(H,xn),s(H,Ls),s(Ls,$n),s(H,jn),s(H,Hs),s(Hs,yn),s(H,En),u(e,Gt,l),v(Le,e,l),u(e,Lt,l),v(He,e,l),u(e,Ht,l),u(e,xs,l),s(xs,wn),u(e,Ut,l),v(ce,e,l),u(e,Bt,l),u(e,Y,l),s(Y,qn),s(Y,Ue),s(Ue,An),s(Y,Dn),s(Y,Be),s(Be,Pn),s(Y,zn),u(e,Ft,l),u(e,S,l),s(S,kn),s(S,Us),s(Us,Cn),s(S,In),s(S,Fe),s(Fe,Tn),s(S,On),s(S,Bs),s(Bs,Rn),s(S,Mn),s(S,Ve),s(Ve,Sn),s(S,Nn),s(S,We),s(We,Gn),s(S,Ln),u(e,Vt,l),v(Je,e,l),u(e,Wt,l),v(Ke,e,l),u(e,Jt,l),u(e,Z,l),s(Z,Hn),s(Z,Fs),s(Fs,Un),s(Z,Bn),s(Z,Vs),s(Vs,Fn),s(Z,Vn),u(e,Kt,l),v(fe,e,l),u(e,Yt,l),u(e,le,l),s(le,he),s(he,Ws),v(Ye,Ws,null),s(le,Wn),s(le,Js),s(Js,Jn),u(e,Zt,l),u(e,Q,l),s(Q,Kn),s(Q,Ks),s(Ks,Yn),s(Q,Zn),s(Q,Ys),s(Ys,Qn),s(Q,Xn),u(e,Qt,l),v(Ze,e,l),u(e,Xt,l),u(e,G,l),s(G,el),s(G,Zs),s(Zs,sl),s(G,tl),s(G,Qs),s(Qs,al),s(G,nl),s(G,Xs),s(Xs,ll),s(G,rl),s(G,et),s(et,ol),s(G,il),u(e,ea,l),v(Qe,e,l),u(e,sa,l),v(Xe,e,l),u(e,ta,l),u(e,X,l),s(X,ul),s(X,st),s(st,pl),s(X,dl),s(X,$s),s($s,ml),s(X,cl),u(e,aa,l),v(es,e,l),u(e,na,l),v(ss,e,l),u(e,la,l),v(be,e,l),u(e,ra,l),u(e,U,l),s(U,fl),s(U,tt),s(tt,hl),s(U,bl),s(U,at),s(at,gl),s(U,vl),s(U,nt),s(nt,_l),s(U,xl),u(e,oa,l),v(ts,e,l),u(e,ia,l),v(as,e,l),u(e,ua,l),u(e,B,l),s(B,$l),s(B,lt),s(lt,jl),s(B,yl),s(B,rt),s(rt,El),s(B,wl),s(B,ot),s(ot,ql),s(B,Al),u(e,pa,l),v(ns,e,l),u(e,da,l),v(ls,e,l),u(e,ma,l),u(e,ge,l),s(ge,Dl),s(ge,it),s(it,Pl),s(ge,zl),u(e,ca,l),v(rs,e,l),u(e,fa,l),u(e,F,l),s(F,kl),s(F,ut),s(ut,Cl),s(F,Il),s(F,pt),s(pt,Tl),s(F,Ol),s(F,dt),s(dt,Rl),s(F,Ml),u(e,ha,l),v(os,e,l),u(e,ba,l),v(is,e,l),u(e,ga,l),u(e,ve,l),s(ve,Sl),s(ve,mt),s(mt,Nl),s(ve,Gl),u(e,va,l),v(us,e,l),u(e,_a,l),v(ps,e,l),u(e,xa,l),u(e,ee,l),s(ee,Ll),s(ee,ct),s(ct,Hl),s(ee,Ul),s(ee,ft),s(ft,Bl),s(ee,Fl),u(e,$a,l),u(e,js,l),s(js,Vl),u(e,ja,l),v(ds,e,l),u(e,ya,l),v(ms,e,l),u(e,Ea,l),v(_e,e,l),u(e,wa,l),u(e,ys,l),s(ys,Wl),qa=!0},p(e,[l]){const cs={};l&2&&(cs.$$scope={dirty:l,ctx:e}),pe.$set(cs);const ht={};l&2&&(ht.$$scope={dirty:l,ctx:e}),ce.$set(ht);const bt={};l&2&&(bt.$$scope={dirty:l,ctx:e}),fe.$set(bt);const gt={};l&2&&(gt.$$scope={dirty:l,ctx:e}),be.$set(gt);const fs={};l&2&&(fs.$$scope={dirty:l,ctx:e}),_e.$set(fs)},i(e){qa||(_(h.$$.fragment,e),_(I.$$.fragment,e),_(Ee.$$.fragment,e),_(qe.$$.fragment,e),_(ke.$$.fragment,e),_(Ce.$$.fragment,e),_(Ie.$$.fragment,e),_(pe.$$.fragment,e),_(Te.$$.fragment,e),_(Oe.$$.fragment,e),_(Re.$$.fragment,e),_(Se.$$.fragment,e),_(Ne.$$.fragment,e),_(Ge.$$.fragment,e),_(Le.$$.fragment,e),_(He.$$.fragment,e),_(ce.$$.fragment,e),_(Je.$$.fragment,e),_(Ke.$$.fragment,e),_(fe.$$.fragment,e),_(Ye.$$.fragment,e),_(Ze.$$.fragment,e),_(Qe.$$.fragment,e),_(Xe.$$.fragment,e),_(es.$$.fragment,e),_(ss.$$.fragment,e),_(be.$$.fragment,e),_(ts.$$.fragment,e),_(as.$$.fragment,e),_(ns.$$.fragment,e),_(ls.$$.fragment,e),_(rs.$$.fragment,e),_(os.$$.fragment,e),_(is.$$.fragment,e),_(us.$$.fragment,e),_(ps.$$.fragment,e),_(ds.$$.fragment,e),_(ms.$$.fragment,e),_(_e.$$.fragment,e),qa=!0)},o(e){x(h.$$.fragment,e),x(I.$$.fragment,e),x(Ee.$$.fragment,e),x(qe.$$.fragment,e),x(ke.$$.fragment,e),x(Ce.$$.fragment,e),x(Ie.$$.fragment,e),x(pe.$$.fragment,e),x(Te.$$.fragment,e),x(Oe.$$.fragment,e),x(Re.$$.fragment,e),x(Se.$$.fragment,e),x(Ne.$$.fragment,e),x(Ge.$$.fragment,e),x(Le.$$.fragment,e),x(He.$$.fragment,e),x(ce.$$.fragment,e),x(Je.$$.fragment,e),x(Ke.$$.fragment,e),x(fe.$$.fragment,e),x(Ye.$$.fragment,e),x(Ze.$$.fragment,e),x(Qe.$$.fragment,e),x(Xe.$$.fragment,e),x(es.$$.fragment,e),x(ss.$$.fragment,e),x(be.$$.fragment,e),x(ts.$$.fragment,e),x(as.$$.fragment,e),x(ns.$$.fragment,e),x(ls.$$.fragment,e),x(rs.$$.fragment,e),x(os.$$.fragment,e),x(is.$$.fragment,e),x(us.$$.fragment,e),x(ps.$$.fragment,e),x(ds.$$.fragment,e),x(ms.$$.fragment,e),x(_e.$$.fragment,e),qa=!1},d(e){t(p),e&&t(C),e&&t(f),$(h),e&&t(w),$(I,e),e&&t(z),e&&t(j),e&&t(J),e&&t(R),e&&t(_t),$(Ee,e),e&&t(xt),e&&t(oe),e&&t($t),e&&t(ae),$(qe),e&&t(jt),e&&t(M),e&&t(yt),$(ke,e),e&&t(Et),e&&t(ue),e&&t(wt),$(Ce,e),e&&t(qt),$(Ie,e),e&&t(At),e&&t(gs),e&&t(Dt),$(pe,e),e&&t(Pt),e&&t(vs),e&&t(zt),$(Te,e),e&&t(kt),$(Oe,e),e&&t(Ct),e&&t(_s),e&&t(It),e&&t(ne),$(Re),e&&t(Tt),e&&t(K),e&&t(Ot),$(Se,e),e&&t(Rt),e&&t(me),e&&t(Mt),$(Ne,e),e&&t(St),$(Ge,e),e&&t(Nt),e&&t(H),e&&t(Gt),$(Le,e),e&&t(Lt),$(He,e),e&&t(Ht),e&&t(xs),e&&t(Ut),$(ce,e),e&&t(Bt),e&&t(Y),e&&t(Ft),e&&t(S),e&&t(Vt),$(Je,e),e&&t(Wt),$(Ke,e),e&&t(Jt),e&&t(Z),e&&t(Kt),$(fe,e),e&&t(Yt),e&&t(le),$(Ye),e&&t(Zt),e&&t(Q),e&&t(Qt),$(Ze,e),e&&t(Xt),e&&t(G),e&&t(ea),$(Qe,e),e&&t(sa),$(Xe,e),e&&t(ta),e&&t(X),e&&t(aa),$(es,e),e&&t(na),$(ss,e),e&&t(la),$(be,e),e&&t(ra),e&&t(U),e&&t(oa),$(ts,e),e&&t(ia),$(as,e),e&&t(ua),e&&t(B),e&&t(pa),$(ns,e),e&&t(da),$(ls,e),e&&t(ma),e&&t(ge),e&&t(ca),$(rs,e),e&&t(fa),e&&t(F),e&&t(ha),$(os,e),e&&t(ba),$(is,e),e&&t(ga),e&&t(ve),e&&t(va),$(us,e),e&&t(_a),$(ps,e),e&&t(xa),e&&t(ee),e&&t($a),e&&t(js),e&&t(ja),$(ds,e),e&&t(ya),$(ms,e),e&&t(Ea),$(_e,e),e&&t(wa),e&&t(ys)}}}const bo={local:"big-data-datasets-la-rescousse",sections:[{local:"questce-que-the-pile",title:"Qu'est-ce que The Pile ?"},{local:"la-magie-de-la-cartographie-mmoire",title:"La magie de la cartographie m\xE9moire"},{local:"ensembles-de-donnes-en-continu",title:"Ensembles de donn\xE9es en continu"}],title:"Big Data? \u{1F917} Datasets \xE0 la rescousse\xA0!"};function go(L){return ro(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class jo extends to{constructor(p){super();ao(this,p,go,ho,no,{})}}export{jo as default,bo as metadata};
