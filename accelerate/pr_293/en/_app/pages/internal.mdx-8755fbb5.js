import{S as $n,i as yn,s as wn,e as r,k as d,w as m,t as n,M as En,c as o,d as a,m as h,a as s,x as u,h as l,b as i,F as t,g as p,y as g,q as v,o as _,B as b,v as Dn}from"../chunks/vendor-19e06bd2.js";import{T as cs}from"../chunks/Tip-f0fa2d82.js";import{D as T}from"../chunks/Docstring-395e5a9c.js";import{I as U}from"../chunks/IconCopyLink-3c713d38.js";function Sn(ne){let f,D,$,y,x;return{c(){f=r("p"),D=n("This does not support "),$=r("code"),y=n("BatchSampler"),x=n(" with varying batch size yet.")},l(w){f=o(w,"P",{});var E=s(f);D=l(E,"This does not support "),$=o(E,"CODE",{});var I=s($);y=l(I,"BatchSampler"),I.forEach(a),x=l(E," with varying batch size yet."),E.forEach(a)},m(w,E){p(w,f,E),t(f,D),t(f,$),t($,y),t(f,x)},d(w){w&&a(f)}}}function Tn(ne){let f,D,$,y,x;return{c(){f=r("p"),D=n("This does not support "),$=r("code"),y=n("BatchSampler"),x=n(" with varying batch size yet.")},l(w){f=o(w,"P",{});var E=s(f);D=l(E,"This does not support "),$=o(E,"CODE",{});var I=s($);y=l(I,"BatchSampler"),I.forEach(a),x=l(E," with varying batch size yet."),E.forEach(a)},m(w,E){p(w,f,E),t(f,D),t(f,$),t($,y),t(f,x)},d(w){w&&a(f)}}}function xn(ne){let f,D;return{c(){f=r("p"),D=n("Make sure all processes will reach this instruction otherwise one of your processes will hang forever.")},l($){f=o($,"P",{});var y=s(f);D=l(y,"Make sure all processes will reach this instruction otherwise one of your processes will hang forever."),y.forEach(a)},m($,y){p($,f,y),t(f,D)},d($){$&&a(f)}}}function Pn(ne){let f,D,$,y,x,w,E,I,or,ia,B,le,ht,Se,sr,pt,nr,da,q,Te,lr,ft,cr,ha,F,ce,mt,xe,ir,ut,dr,pa,ie,hr,gt,pr,fr,fa,P,Pe,mr,Ae,ur,vt,gr,vr,_r,R,br,_t,$r,yr,bt,wr,Er,Dr,de,ma,V,he,$t,ke,Sr,yt,Tr,ua,W,ze,xr,Ie,Pr,wt,Ar,kr,ga,H,pe,Et,Le,zr,Dt,Ir,va,L,Ne,Lr,N,Nr,St,Or,Cr,Tt,Ur,Gr,xt,Br,qr,Fr,fe,_a,M,me,Pt,Oe,Rr,At,Vr,ba,j,Ce,Wr,S,Hr,kt,Mr,jr,zt,Xr,Jr,It,Kr,Qr,Lt,Yr,Zr,Nt,eo,to,$a,X,ue,Ot,Ue,ao,Ct,ro,ya,J,ge,Ut,Ge,oo,Gt,so,wa,K,Be,no,Q,lo,qe,co,io,Bt,ho,po,Ea,Y,ve,qt,Fe,fo,Ft,mo,Da,A,Re,uo,Rt,go,vo,Vt,_o,bo,k,at,Wt,$o,yo,wo,rt,Ht,Eo,Do,So,ot,Mt,To,xo,Po,st,jt,Ao,ko,zo,nt,Xt,Io,Lo,Sa,Z,_e,Jt,Ve,No,Kt,Oo,Ta,ee,We,Co,Qt,Uo,xa,te,be,Yt,He,Go,Zt,Bo,Pa,ae,Me,qo,ea,Fo,Aa,re,je,Ro,ta,Vo,ka,oe,Xe,Wo,aa,Ho,za,se,Je,Mo,O,jo,ra,Xo,Jo,oa,Ko,Qo,sa,Yo,Zo,Ia,Ke,Qe,La,Ye,Ze,Na,C,et,es,na,ts,as,$e,Oa;return w=new U({}),Se=new U({}),Te=new T({props:{name:"class accelerate.optimizer.AcceleratedOptimizer",anchor:"accelerate.optimizer.AcceleratedOptimizer",parameters:[{name:"optimizer",val:""},{name:"device_placement",val:" = True"},{name:"scaler",val:" = None"}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/optimizer.py#L39",parametersDescription:[{anchor:"accelerate.optimizer.AcceleratedOptimizer.optimizer",description:`<strong>optimizer</strong> (<code>torch.optim.optimizer.Optimizer</code>) &#x2014;
The optimizer to wrap.`,name:"optimizer"},{anchor:"accelerate.optimizer.AcceleratedOptimizer.device_placement",description:`<strong>device_placement</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not the optimizer should handle device placement. If so, it will place the state dictionary of
<code>optimizer</code> on the right device.`,name:"device_placement"},{anchor:"accelerate.optimizer.AcceleratedOptimizer.scaler",description:`<strong>scaler</strong> (<code>torch.cuda.amp.grad_scaler.GradScaler</code>, <em>optional</em>) &#x2014;
The scaler to use in the step function if training with mixed precision.`,name:"scaler"}]}}),xe=new U({}),Pe=new T({props:{name:"accelerate.data_loader.prepare_data_loader",anchor:"accelerate.data_loader.prepare_data_loader",parameters:[{name:"dataloader",val:": DataLoader"},{name:"device",val:": typing.Optional[torch.device] = None"},{name:"num_processes",val:": typing.Optional[int] = None"},{name:"process_index",val:": typing.Optional[int] = None"},{name:"split_batches",val:": bool = False"},{name:"put_on_device",val:": bool = False"},{name:"rng_types",val:": typing.Union[typing.List[typing.Union[str, accelerate.utils.RNGType]], NoneType] = None"},{name:"dispatch_batches",val:": typing.Optional[bool] = None"}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/data_loader.py#L417",parametersDescription:[{anchor:"accelerate.data_loader.prepare_data_loader.dataloader",description:`<strong>dataloader</strong> (<code>torch.utils.data.dataloader.DataLoader</code>) &#x2014;
The data loader to split across several devices.`,name:"dataloader"},{anchor:"accelerate.data_loader.prepare_data_loader.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The target device for the returned <code>DataLoader</code>.`,name:"device"},{anchor:"accelerate.data_loader.prepare_data_loader.num_processes",description:`<strong>num_processes</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The number of processes running concurrently. Will default to the value given by
<a href="/docs/accelerate/pr_293/en/internal#accelerate.state.AcceleratorState">AcceleratorState</a>.`,name:"num_processes"},{anchor:"accelerate.data_loader.prepare_data_loader.process_index",description:`<strong>process_index</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The index of the current process. Will default to the value given by <a href="/docs/accelerate/pr_293/en/internal#accelerate.state.AcceleratorState">AcceleratorState</a>.`,name:"process_index"},{anchor:"accelerate.data_loader.prepare_data_loader.split_batches",description:`<strong>split_batches</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the resulting <code>DataLoader</code> should split the batches of the original data loader across devices or
yield full batches (in which case it will yield batches starting at the <code>process_index</code>-th and advancing of
<code>num_processes</code> batches at each iteration).</p>
<p>Another way to see this is that the observed batch size will be the same as the initial <code>dataloader</code> if
this option is set to <code>True</code>, the batch size of the initial <code>dataloader</code> multiplied by <code>num_processes</code>
otherwise.</p>
<p>Setting this option to <code>True</code> requires that the batch size of the <code>dataloader</code> is a round multiple of
<code>batch_size</code>.`,name:"split_batches"},{anchor:"accelerate.data_loader.prepare_data_loader.put_on_device",description:`<strong>put_on_device</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to put the batches on <code>device</code> (only works if the batches are nested list, tuples or
dictionaries of tensors).`,name:"put_on_device"},{anchor:"accelerate.data_loader.prepare_data_loader.rng_types",description:`<strong>rng_types</strong> (list of <code>str</code> or <code>RNGType</code> &#x2014;
The list of random number generators to synchronize at the beginning of each iteration. Should be one or
several of:</p>
<ul>
<li><code>&quot;torch&quot;</code>: the base torch random number generator</li>
<li><code>&quot;cuda&quot;</code>: the CUDA random number generator (GPU only)</li>
<li><code>&quot;xla&quot;</code>: the XLA random number generator (TPU only)</li>
<li><code>&quot;generator&quot;</code>: the <code>torch.Generator</code> of the sampler (or batch sampler if there is no sampler in your
dataloader) or of the iterable dataset (if it exists) if the underlying dataset is of that type.</li>
</ul>`,name:"rng_types"},{anchor:"accelerate.data_loader.prepare_data_loader.dispatch_batches",description:`<strong>dispatch_batches</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
If set to <code>True</code>, the datalaoder prepared is only iterated through on the main process and then the batches
are split and broadcast to each process. Will default to <code>True</code> when the underlying dataset is an
<code>IterableDataset</code>, <code>False</code> otherwise.`,name:"dispatch_batches"}],returnDescription:`
<p>A new data loader that will yield the portion of the batches</p>
`,returnType:`
<p><code>torch.utils.data.dataloader.DataLoader</code></p>
`}}),de=new cs({props:{warning:!0,$$slots:{default:[Sn]},$$scope:{ctx:ne}}}),ke=new U({}),ze=new T({props:{name:"class accelerate.data_loader.DataLoaderShard",anchor:"accelerate.data_loader.DataLoaderShard",parameters:[{name:"*args",val:""},{name:"**kwds",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/data_loader.py#L270",parametersDescription:[{anchor:"accelerate.data_loader.DataLoaderShard.dataset",description:`<strong>dataset</strong> (<code>torch.utils.data.dataset.Dataset</code>) &#x2014;
The dataset to use to build this datalaoder.`,name:"dataset"},{anchor:"accelerate.data_loader.DataLoaderShard.device",description:`<strong>device</strong> (<code>torch.device</code>, <em>optional</em>) &#x2014;
If passed, the device to put all batches on.`,name:"device"},{anchor:"accelerate.data_loader.DataLoaderShard.rng_types",description:`<strong>rng_types</strong> (list of <code>str</code> or <code>RNGType</code> &#x2014;
The list of random number generators to synchronize at the beginning of each iteration. Should be one or
several of:</p>
<ul>
<li><code>&quot;torch&quot;</code>: the base torch random number generator</li>
<li><code>&quot;cuda&quot;</code>: the CUDA random number generator (GPU only)</li>
<li><code>&quot;xla&quot;</code>: the XLA random number generator (TPU only)</li>
<li><code>&quot;generator&quot;</code>: an optional <code>torch.Generator</code></li>
</ul>`,name:"rng_types"},{anchor:"accelerate.data_loader.DataLoaderShard.generator",description:`<strong>generator</strong> (<code>torch.Generator</code>, <em>optional</em>) &#x2014;
A random number generator to keep synchronized across processes.
kwargs &#x2014;
All other keyword arguments to pass to the regular <code>DataLoader</code> initialization.`,name:"generator"}]}}),Le=new U({}),Ne=new T({props:{name:"class accelerate.data_loader.BatchSamplerShard",anchor:"accelerate.data_loader.BatchSamplerShard",parameters:[{name:"*args",val:""},{name:"**kwds",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/data_loader.py#L68",parametersDescription:[{anchor:"accelerate.data_loader.BatchSamplerShard.batch_sampler",description:`<strong>batch_sampler</strong> (<code>torch.utils.data.sampler.BatchSampler</code>) &#x2014;
The batch sampler to split in several shards.`,name:"batch_sampler"},{anchor:"accelerate.data_loader.BatchSamplerShard.num_processes",description:`<strong>num_processes</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The number of processes running concurrently.`,name:"num_processes"},{anchor:"accelerate.data_loader.BatchSamplerShard.process_index",description:`<strong>process_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The index of the current process.`,name:"process_index"},{anchor:"accelerate.data_loader.BatchSamplerShard.split_batches",description:`<strong>split_batches</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the shards should be created by splitting a batch to give a piece of it on each process, or by
yielding different full batches on each process.</p>
<p>On two processes with a sampler of <code>[[0, 1, 2, 3], [4, 5, 6, 7]]</code>, this will result in:</p>
<ul>
<li>the sampler on process 0 to yield <code>[0, 1, 2, 3]</code> and the sampler on process 1 to yield <code>[4, 5, 6, 7]</code> if
this argument is set to <code>False</code>.</li>
<li>the sampler on process 0 to yield <code>[0, 1]</code> then <code>[4, 5]</code> and the sampler on process 1 to yield <code>[2, 3]</code>
then <code>[6, 7]</code> if this argument is set to <code>True</code>.</li>
</ul>`,name:"split_batches"}]}}),fe=new cs({props:{warning:!0,$$slots:{default:[Tn]},$$scope:{ctx:ne}}}),Oe=new U({}),Ce=new T({props:{name:"class accelerate.data_loader.IterableDatasetShard",anchor:"accelerate.data_loader.IterableDatasetShard",parameters:[{name:"*args",val:""},{name:"**kwds",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/data_loader.py#L189",parametersDescription:[{anchor:"accelerate.data_loader.IterableDatasetShard.dataset",description:`<strong>dataset</strong> (<code>torch.utils.data.dataset.IterableDataset</code>) &#x2014;
The batch sampler to split in several shards.`,name:"dataset"},{anchor:"accelerate.data_loader.IterableDatasetShard.batch_size",description:`<strong>batch_size</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The size of the batches per shard (if <code>split_batches=False</code>) or the size of the batches (if
<code>split_batches=True</code>).`,name:"batch_size"},{anchor:"accelerate.data_loader.IterableDatasetShard.drop_last",description:`<strong>drop_last</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to drop the last incomplete batch or complete the last batches by using the samples from the
beginning.`,name:"drop_last"},{anchor:"accelerate.data_loader.IterableDatasetShard.num_processes",description:`<strong>num_processes</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The number of processes running concurrently.`,name:"num_processes"},{anchor:"accelerate.data_loader.IterableDatasetShard.process_index",description:`<strong>process_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The index of the current process.`,name:"process_index"},{anchor:"accelerate.data_loader.IterableDatasetShard.split_batches",description:`<strong>split_batches</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the shards should be created by splitting a batch to give a piece of it on each process, or by
yielding different full batches on each process.</p>
<p>On two processes with an iterable dataset yielding of <code>[0, 1, 2, 3, 4, 5, 6, 7]</code>, this will result in:</p>
<ul>
<li>the shard on process 0 to yield <code>[0, 1, 2, 3]</code> and the shard on process 1 to yield <code>[4, 5, 6, 7]</code> if this
argument is set to <code>False</code>.</li>
<li>the shard on process 0 to yield <code>[0, 1, 4, 5]</code> and the sampler on process 1 to yield <code>[2, 3, 6, 7]</code> if
this argument is set to <code>True</code>.</li>
</ul>`,name:"split_batches"}]}}),Ue=new U({}),Ge=new U({}),Be=new T({props:{name:"class accelerate.state.AcceleratorState",anchor:"accelerate.state.AcceleratorState",parameters:[{name:"mixed_precision",val:": str = None"},{name:"cpu",val:": bool = False"},{name:"deepspeed_plugin",val:" = None"},{name:"_from_accelerator",val:": bool = False"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/state.py#L128",parametersDescription:[{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>device</strong> (<code>torch.device</code>) &#x2014; The device to use. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:`<strong>-</strong> <strong>distributed_type</strong> (<code>~accelerate.state.DistributedType</code>) &#x2014; The type of distributed environment currently &#x2014;
in use.`,name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>num_processes</strong> (<code>int</code>) &#x2014; The number of processes currently launched in parallel. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>process_index</strong> (<code>int</code>) &#x2014; The index of the current process. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>local_process_index</strong> (<code>int</code>) &#x2014; The index of the current process on the current server. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:`<strong>-</strong> <strong>mixed_precision</strong> (<code>str</code>) &#x2014; Whether or not the current script will use mixed precision. If you are using &#x2014;
mixed precision, define if you want to use FP16 or BF16 (bfloat16) as the floating point.`,name:"-"}]}}),Fe=new U({}),Re=new T({props:{name:"class accelerate.DistributedType",anchor:"accelerate.DistributedType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/state.py#L74"}}),Ve=new U({}),We=new T({props:{name:"class accelerate.tracking.GeneralTracker",anchor:"accelerate.tracking.GeneralTracker",parameters:[],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/tracking.py#L52"}}),He=new U({}),Me=new T({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/utils.py#L350",parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),je=new T({props:{name:"accelerate.utils.gather",anchor:"accelerate.utils.gather",parameters:[{name:"tensor",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/utils.py#L395",parametersDescription:[{anchor:"accelerate.utils.gather.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"}],returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Xe=new T({props:{name:"accelerate.utils.send_to_device",anchor:"accelerate.utils.send_to_device",parameters:[{name:"tensor",val:""},{name:"device",val:""}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/utils.py#L245",parametersDescription:[{anchor:"accelerate.utils.send_to_device.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to send to a given device.`,name:"tensor"},{anchor:"accelerate.utils.send_to_device.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The device to send the data to.`,name:"device"}],returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Je=new T({props:{name:"accelerate.utils.set_seed",anchor:"accelerate.utils.set_seed",parameters:[{name:"seed",val:": int"},{name:"device_specific",val:": bool = False"}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/utils.py#L115",parametersDescription:[{anchor:"accelerate.utils.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"},{anchor:"accelerate.utils.set_seed.device_specific",description:`<strong>device_specific</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to differ the seed on each device slightly with <code>self.process_index</code>.`,name:"device_specific"}]}}),Qe=new T({props:{name:"accelerate.utils.synchronize_rng_state",anchor:"accelerate.utils.synchronize_rng_state",parameters:[{name:"rng_type",val:": typing.Optional[accelerate.utils.RNGType] = None"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/utils.py#L135"}}),Ze=new T({props:{name:"accelerate.synchronize_rng_states",anchor:"accelerate.synchronize_rng_states",parameters:[{name:"rng_types",val:": typing.List[typing.Union[str, accelerate.utils.RNGType]]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/utils.py#L170"}}),et=new T({props:{name:"accelerate.utils.wait_for_everyone",anchor:"accelerate.utils.wait_for_everyone",parameters:[],source:"https://github.com/huggingface/accelerate/blob/pr_293/src/accelerate/utils.py#L619"}}),$e=new cs({props:{warning:!0,$$slots:{default:[xn]},$$scope:{ctx:ne}}}),{c(){f=r("meta"),D=d(),$=r("h1"),y=r("a"),x=r("span"),m(w.$$.fragment),E=d(),I=r("span"),or=n("Internals"),ia=d(),B=r("h2"),le=r("a"),ht=r("span"),m(Se.$$.fragment),sr=d(),pt=r("span"),nr=n("Optimizer"),da=d(),q=r("div"),m(Te.$$.fragment),lr=d(),ft=r("p"),cr=n("Internal wrapper around a torch optimizer."),ha=d(),F=r("h2"),ce=r("a"),mt=r("span"),m(xe.$$.fragment),ir=d(),ut=r("span"),dr=n("DataLoader"),pa=d(),ie=r("p"),hr=n("The main work on your PyTorch "),gt=r("code"),pr=n("DataLoader"),fr=n(" is done by the following function:"),fa=d(),P=r("div"),m(Pe.$$.fragment),mr=d(),Ae=r("p"),ur=n("Wraps a PyTorch "),vt=r("code"),gr=n("DataLoader"),vr=n(" to generate batches for one of the processes only."),_r=d(),R=r("p"),br=n("Depending on the value of the "),_t=r("code"),$r=n("drop_last"),yr=n(" attribute of the "),bt=r("code"),wr=n("dataloader"),Er=n(` passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),Dr=d(),m(de.$$.fragment),ma=d(),V=r("h3"),he=r("a"),$t=r("span"),m(ke.$$.fragment),Sr=d(),yt=r("span"),Tr=n("BatchSamplerShard"),ua=d(),W=r("div"),m(ze.$$.fragment),xr=d(),Ie=r("p"),Pr=n("Subclass of a PyTorch "),wt=r("code"),Ar=n("DataLoader"),kr=n(" that will deal with device placement and current distributed setup."),ga=d(),H=r("h3"),pe=r("a"),Et=r("span"),m(Le.$$.fragment),zr=d(),Dt=r("span"),Ir=n("BatchSamplerShard"),va=d(),L=r("div"),m(Ne.$$.fragment),Lr=d(),N=r("p"),Nr=n("Wraps a PyTorch "),St=r("code"),Or=n("BatchSampler"),Cr=n(` to generate batches for one of the processes only. Instances of this class will
always yield a number of batches that is a round multiple of `),Tt=r("code"),Ur=n("num_processes"),Gr=n(` and that all have the same size.
Depending on the value of the `),xt=r("code"),Br=n("drop_last"),qr=n(` attribute of the batch sampler passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),Fr=d(),m(fe.$$.fragment),_a=d(),M=r("h3"),me=r("a"),Pt=r("span"),m(Oe.$$.fragment),Rr=d(),At=r("span"),Vr=n("IterableDatasetShard"),ba=d(),j=r("div"),m(Ce.$$.fragment),Wr=d(),S=r("p"),Hr=n("Wraps a PyTorch "),kt=r("code"),Mr=n("IterableDataset"),jr=n(` to generate samples for one of the processes only. Instances of this class will
always yield a number of samples that is a round multiple of the actual batch size (depending of the value of
`),zt=r("code"),Xr=n("split_batches"),Jr=n(", this is either "),It=r("code"),Kr=n("batch_size"),Qr=n(" or "),Lt=r("code"),Yr=n("batch_size x num_processes"),Zr=n(`). Depending on the value of the
`),Nt=r("code"),eo=n("drop_last"),to=n(` attribute of the batch sampler passed, it will either stop the iteration at the first batch that would
be too small or loop with indices from the beginning.`),$a=d(),X=r("h2"),ue=r("a"),Ot=r("span"),m(Ue.$$.fragment),ao=d(),Ct=r("span"),ro=n("Distributed Config"),ya=d(),J=r("h3"),ge=r("a"),Ut=r("span"),m(Ge.$$.fragment),oo=d(),Gt=r("span"),so=n("AcceleratorState"),wa=d(),K=r("div"),m(Be.$$.fragment),no=d(),Q=r("p"),lo=n("This is a variation of a "),qe=r("a"),co=n("singleton class"),io=n(` in the sense that all
instance of `),Bt=r("code"),ho=n("AcceleratorState"),po=n(" share the same state, which is initialized on the first instantiation."),Ea=d(),Y=r("h3"),ve=r("a"),qt=r("span"),m(Fe.$$.fragment),fo=d(),Ft=r("span"),mo=n("DistributedType"),Da=d(),A=r("div"),m(Re.$$.fragment),uo=d(),Rt=r("p"),go=n("Represents a type of distributed environment."),vo=d(),Vt=r("p"),_o=n("Values:"),bo=d(),k=r("ul"),at=r("li"),Wt=r("strong"),$o=n("NO"),yo=n(" \u2014 Not a distributed environment, just a single process."),wo=d(),rt=r("li"),Ht=r("strong"),Eo=n("MULTI_CPU"),Do=n(" \u2014 Distributed on multiple CPU nodes."),So=d(),ot=r("li"),Mt=r("strong"),To=n("MULTI_GPU"),xo=n(" \u2014 Distributed on multiple GPUs."),Po=d(),st=r("li"),jt=r("strong"),Ao=n("DEEPSPEED"),ko=n(" \u2014 Using DeepSpeed."),zo=d(),nt=r("li"),Xt=r("strong"),Io=n("TPU"),Lo=n(" \u2014 Distributed on TPUs."),Sa=d(),Z=r("h2"),_e=r("a"),Jt=r("span"),m(Ve.$$.fragment),No=d(),Kt=r("span"),Oo=n("Tracking"),Ta=d(),ee=r("div"),m(We.$$.fragment),Co=d(),Qt=r("p"),Uo=n("A base Tracker class to be used for all logging integration implementations."),xa=d(),te=r("h2"),be=r("a"),Yt=r("span"),m(He.$$.fragment),Go=d(),Zt=r("span"),Bo=n("Utilities"),Pa=d(),ae=r("div"),m(Me.$$.fragment),qo=d(),ea=r("p"),Fo=n("Extract a model from its distributed containers."),Aa=d(),re=r("div"),m(je.$$.fragment),Ro=d(),ta=r("p"),Vo=n("Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),ka=d(),oe=r("div"),m(Xe.$$.fragment),Wo=d(),aa=r("p"),Ho=n("Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),za=d(),se=r("div"),m(Je.$$.fragment),Mo=d(),O=r("p"),jo=n("Helper function for reproducible behavior to set the seed in "),ra=r("code"),Xo=n("random"),Jo=n(", "),oa=r("code"),Ko=n("numpy"),Qo=n(", "),sa=r("code"),Yo=n("torch"),Zo=n("."),Ia=d(),Ke=r("div"),m(Qe.$$.fragment),La=d(),Ye=r("div"),m(Ze.$$.fragment),Na=d(),C=r("div"),m(et.$$.fragment),es=d(),na=r("p"),ts=n("Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),as=d(),m($e.$$.fragment),this.h()},l(e){const c=En('[data-svelte="svelte-1phssyn"]',document.head);f=o(c,"META",{name:!0,content:!0}),c.forEach(a),D=h(e),$=o(e,"H1",{class:!0});var tt=s($);y=o(tt,"A",{id:!0,class:!0,href:!0});var la=s(y);x=o(la,"SPAN",{});var ca=s(x);u(w.$$.fragment,ca),ca.forEach(a),la.forEach(a),E=h(tt),I=o(tt,"SPAN",{});var is=s(I);or=l(is,"Internals"),is.forEach(a),tt.forEach(a),ia=h(e),B=o(e,"H2",{class:!0});var Ca=s(B);le=o(Ca,"A",{id:!0,class:!0,href:!0});var ds=s(le);ht=o(ds,"SPAN",{});var hs=s(ht);u(Se.$$.fragment,hs),hs.forEach(a),ds.forEach(a),sr=h(Ca),pt=o(Ca,"SPAN",{});var ps=s(pt);nr=l(ps,"Optimizer"),ps.forEach(a),Ca.forEach(a),da=h(e),q=o(e,"DIV",{class:!0});var Ua=s(q);u(Te.$$.fragment,Ua),lr=h(Ua),ft=o(Ua,"P",{});var fs=s(ft);cr=l(fs,"Internal wrapper around a torch optimizer."),fs.forEach(a),Ua.forEach(a),ha=h(e),F=o(e,"H2",{class:!0});var Ga=s(F);ce=o(Ga,"A",{id:!0,class:!0,href:!0});var ms=s(ce);mt=o(ms,"SPAN",{});var us=s(mt);u(xe.$$.fragment,us),us.forEach(a),ms.forEach(a),ir=h(Ga),ut=o(Ga,"SPAN",{});var gs=s(ut);dr=l(gs,"DataLoader"),gs.forEach(a),Ga.forEach(a),pa=h(e),ie=o(e,"P",{});var Ba=s(ie);hr=l(Ba,"The main work on your PyTorch "),gt=o(Ba,"CODE",{});var vs=s(gt);pr=l(vs,"DataLoader"),vs.forEach(a),fr=l(Ba," is done by the following function:"),Ba.forEach(a),fa=h(e),P=o(e,"DIV",{class:!0});var ye=s(P);u(Pe.$$.fragment,ye),mr=h(ye),Ae=o(ye,"P",{});var qa=s(Ae);ur=l(qa,"Wraps a PyTorch "),vt=o(qa,"CODE",{});var _s=s(vt);gr=l(_s,"DataLoader"),_s.forEach(a),vr=l(qa," to generate batches for one of the processes only."),qa.forEach(a),_r=h(ye),R=o(ye,"P",{});var lt=s(R);br=l(lt,"Depending on the value of the "),_t=o(lt,"CODE",{});var bs=s(_t);$r=l(bs,"drop_last"),bs.forEach(a),yr=l(lt," attribute of the "),bt=o(lt,"CODE",{});var $s=s(bt);wr=l($s,"dataloader"),$s.forEach(a),Er=l(lt,` passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),lt.forEach(a),Dr=h(ye),u(de.$$.fragment,ye),ye.forEach(a),ma=h(e),V=o(e,"H3",{class:!0});var Fa=s(V);he=o(Fa,"A",{id:!0,class:!0,href:!0});var ys=s(he);$t=o(ys,"SPAN",{});var ws=s($t);u(ke.$$.fragment,ws),ws.forEach(a),ys.forEach(a),Sr=h(Fa),yt=o(Fa,"SPAN",{});var Es=s(yt);Tr=l(Es,"BatchSamplerShard"),Es.forEach(a),Fa.forEach(a),ua=h(e),W=o(e,"DIV",{class:!0});var Ra=s(W);u(ze.$$.fragment,Ra),xr=h(Ra),Ie=o(Ra,"P",{});var Va=s(Ie);Pr=l(Va,"Subclass of a PyTorch "),wt=o(Va,"CODE",{});var Ds=s(wt);Ar=l(Ds,"DataLoader"),Ds.forEach(a),kr=l(Va," that will deal with device placement and current distributed setup."),Va.forEach(a),Ra.forEach(a),ga=h(e),H=o(e,"H3",{class:!0});var Wa=s(H);pe=o(Wa,"A",{id:!0,class:!0,href:!0});var Ss=s(pe);Et=o(Ss,"SPAN",{});var Ts=s(Et);u(Le.$$.fragment,Ts),Ts.forEach(a),Ss.forEach(a),zr=h(Wa),Dt=o(Wa,"SPAN",{});var xs=s(Dt);Ir=l(xs,"BatchSamplerShard"),xs.forEach(a),Wa.forEach(a),va=h(e),L=o(e,"DIV",{class:!0});var ct=s(L);u(Ne.$$.fragment,ct),Lr=h(ct),N=o(ct,"P",{});var we=s(N);Nr=l(we,"Wraps a PyTorch "),St=o(we,"CODE",{});var Ps=s(St);Or=l(Ps,"BatchSampler"),Ps.forEach(a),Cr=l(we,` to generate batches for one of the processes only. Instances of this class will
always yield a number of batches that is a round multiple of `),Tt=o(we,"CODE",{});var As=s(Tt);Ur=l(As,"num_processes"),As.forEach(a),Gr=l(we,` and that all have the same size.
Depending on the value of the `),xt=o(we,"CODE",{});var ks=s(xt);Br=l(ks,"drop_last"),ks.forEach(a),qr=l(we,` attribute of the batch sampler passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),we.forEach(a),Fr=h(ct),u(fe.$$.fragment,ct),ct.forEach(a),_a=h(e),M=o(e,"H3",{class:!0});var Ha=s(M);me=o(Ha,"A",{id:!0,class:!0,href:!0});var zs=s(me);Pt=o(zs,"SPAN",{});var Is=s(Pt);u(Oe.$$.fragment,Is),Is.forEach(a),zs.forEach(a),Rr=h(Ha),At=o(Ha,"SPAN",{});var Ls=s(At);Vr=l(Ls,"IterableDatasetShard"),Ls.forEach(a),Ha.forEach(a),ba=h(e),j=o(e,"DIV",{class:!0});var Ma=s(j);u(Ce.$$.fragment,Ma),Wr=h(Ma),S=o(Ma,"P",{});var z=s(S);Hr=l(z,"Wraps a PyTorch "),kt=o(z,"CODE",{});var Ns=s(kt);Mr=l(Ns,"IterableDataset"),Ns.forEach(a),jr=l(z,` to generate samples for one of the processes only. Instances of this class will
always yield a number of samples that is a round multiple of the actual batch size (depending of the value of
`),zt=o(z,"CODE",{});var Os=s(zt);Xr=l(Os,"split_batches"),Os.forEach(a),Jr=l(z,", this is either "),It=o(z,"CODE",{});var Cs=s(It);Kr=l(Cs,"batch_size"),Cs.forEach(a),Qr=l(z," or "),Lt=o(z,"CODE",{});var Us=s(Lt);Yr=l(Us,"batch_size x num_processes"),Us.forEach(a),Zr=l(z,`). Depending on the value of the
`),Nt=o(z,"CODE",{});var Gs=s(Nt);eo=l(Gs,"drop_last"),Gs.forEach(a),to=l(z,` attribute of the batch sampler passed, it will either stop the iteration at the first batch that would
be too small or loop with indices from the beginning.`),z.forEach(a),Ma.forEach(a),$a=h(e),X=o(e,"H2",{class:!0});var ja=s(X);ue=o(ja,"A",{id:!0,class:!0,href:!0});var Bs=s(ue);Ot=o(Bs,"SPAN",{});var qs=s(Ot);u(Ue.$$.fragment,qs),qs.forEach(a),Bs.forEach(a),ao=h(ja),Ct=o(ja,"SPAN",{});var Fs=s(Ct);ro=l(Fs,"Distributed Config"),Fs.forEach(a),ja.forEach(a),ya=h(e),J=o(e,"H3",{class:!0});var Xa=s(J);ge=o(Xa,"A",{id:!0,class:!0,href:!0});var Rs=s(ge);Ut=o(Rs,"SPAN",{});var Vs=s(Ut);u(Ge.$$.fragment,Vs),Vs.forEach(a),Rs.forEach(a),oo=h(Xa),Gt=o(Xa,"SPAN",{});var Ws=s(Gt);so=l(Ws,"AcceleratorState"),Ws.forEach(a),Xa.forEach(a),wa=h(e),K=o(e,"DIV",{class:!0});var Ja=s(K);u(Be.$$.fragment,Ja),no=h(Ja),Q=o(Ja,"P",{});var it=s(Q);lo=l(it,"This is a variation of a "),qe=o(it,"A",{href:!0,rel:!0});var Hs=s(qe);co=l(Hs,"singleton class"),Hs.forEach(a),io=l(it,` in the sense that all
instance of `),Bt=o(it,"CODE",{});var Ms=s(Bt);ho=l(Ms,"AcceleratorState"),Ms.forEach(a),po=l(it," share the same state, which is initialized on the first instantiation."),it.forEach(a),Ja.forEach(a),Ea=h(e),Y=o(e,"H3",{class:!0});var Ka=s(Y);ve=o(Ka,"A",{id:!0,class:!0,href:!0});var js=s(ve);qt=o(js,"SPAN",{});var Xs=s(qt);u(Fe.$$.fragment,Xs),Xs.forEach(a),js.forEach(a),fo=h(Ka),Ft=o(Ka,"SPAN",{});var Js=s(Ft);mo=l(Js,"DistributedType"),Js.forEach(a),Ka.forEach(a),Da=h(e),A=o(e,"DIV",{class:!0});var Ee=s(A);u(Re.$$.fragment,Ee),uo=h(Ee),Rt=o(Ee,"P",{});var Ks=s(Rt);go=l(Ks,"Represents a type of distributed environment."),Ks.forEach(a),vo=h(Ee),Vt=o(Ee,"P",{});var Qs=s(Vt);_o=l(Qs,"Values:"),Qs.forEach(a),bo=h(Ee),k=o(Ee,"UL",{});var G=s(k);at=o(G,"LI",{});var rs=s(at);Wt=o(rs,"STRONG",{});var Ys=s(Wt);$o=l(Ys,"NO"),Ys.forEach(a),yo=l(rs," \u2014 Not a distributed environment, just a single process."),rs.forEach(a),wo=h(G),rt=o(G,"LI",{});var os=s(rt);Ht=o(os,"STRONG",{});var Zs=s(Ht);Eo=l(Zs,"MULTI_CPU"),Zs.forEach(a),Do=l(os," \u2014 Distributed on multiple CPU nodes."),os.forEach(a),So=h(G),ot=o(G,"LI",{});var ss=s(ot);Mt=o(ss,"STRONG",{});var en=s(Mt);To=l(en,"MULTI_GPU"),en.forEach(a),xo=l(ss," \u2014 Distributed on multiple GPUs."),ss.forEach(a),Po=h(G),st=o(G,"LI",{});var ns=s(st);jt=o(ns,"STRONG",{});var tn=s(jt);Ao=l(tn,"DEEPSPEED"),tn.forEach(a),ko=l(ns," \u2014 Using DeepSpeed."),ns.forEach(a),zo=h(G),nt=o(G,"LI",{});var ls=s(nt);Xt=o(ls,"STRONG",{});var an=s(Xt);Io=l(an,"TPU"),an.forEach(a),Lo=l(ls," \u2014 Distributed on TPUs."),ls.forEach(a),G.forEach(a),Ee.forEach(a),Sa=h(e),Z=o(e,"H2",{class:!0});var Qa=s(Z);_e=o(Qa,"A",{id:!0,class:!0,href:!0});var rn=s(_e);Jt=o(rn,"SPAN",{});var on=s(Jt);u(Ve.$$.fragment,on),on.forEach(a),rn.forEach(a),No=h(Qa),Kt=o(Qa,"SPAN",{});var sn=s(Kt);Oo=l(sn,"Tracking"),sn.forEach(a),Qa.forEach(a),Ta=h(e),ee=o(e,"DIV",{class:!0});var Ya=s(ee);u(We.$$.fragment,Ya),Co=h(Ya),Qt=o(Ya,"P",{});var nn=s(Qt);Uo=l(nn,"A base Tracker class to be used for all logging integration implementations."),nn.forEach(a),Ya.forEach(a),xa=h(e),te=o(e,"H2",{class:!0});var Za=s(te);be=o(Za,"A",{id:!0,class:!0,href:!0});var ln=s(be);Yt=o(ln,"SPAN",{});var cn=s(Yt);u(He.$$.fragment,cn),cn.forEach(a),ln.forEach(a),Go=h(Za),Zt=o(Za,"SPAN",{});var dn=s(Zt);Bo=l(dn,"Utilities"),dn.forEach(a),Za.forEach(a),Pa=h(e),ae=o(e,"DIV",{class:!0});var er=s(ae);u(Me.$$.fragment,er),qo=h(er),ea=o(er,"P",{});var hn=s(ea);Fo=l(hn,"Extract a model from its distributed containers."),hn.forEach(a),er.forEach(a),Aa=h(e),re=o(e,"DIV",{class:!0});var tr=s(re);u(je.$$.fragment,tr),Ro=h(tr),ta=o(tr,"P",{});var pn=s(ta);Vo=l(pn,"Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),pn.forEach(a),tr.forEach(a),ka=h(e),oe=o(e,"DIV",{class:!0});var ar=s(oe);u(Xe.$$.fragment,ar),Wo=h(ar),aa=o(ar,"P",{});var fn=s(aa);Ho=l(fn,"Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),fn.forEach(a),ar.forEach(a),za=h(e),se=o(e,"DIV",{class:!0});var rr=s(se);u(Je.$$.fragment,rr),Mo=h(rr),O=o(rr,"P",{});var De=s(O);jo=l(De,"Helper function for reproducible behavior to set the seed in "),ra=o(De,"CODE",{});var mn=s(ra);Xo=l(mn,"random"),mn.forEach(a),Jo=l(De,", "),oa=o(De,"CODE",{});var un=s(oa);Ko=l(un,"numpy"),un.forEach(a),Qo=l(De,", "),sa=o(De,"CODE",{});var gn=s(sa);Yo=l(gn,"torch"),gn.forEach(a),Zo=l(De,"."),De.forEach(a),rr.forEach(a),Ia=h(e),Ke=o(e,"DIV",{class:!0});var vn=s(Ke);u(Qe.$$.fragment,vn),vn.forEach(a),La=h(e),Ye=o(e,"DIV",{class:!0});var _n=s(Ye);u(Ze.$$.fragment,_n),_n.forEach(a),Na=h(e),C=o(e,"DIV",{class:!0});var dt=s(C);u(et.$$.fragment,dt),es=h(dt),na=o(dt,"P",{});var bn=s(na);ts=l(bn,"Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),bn.forEach(a),as=h(dt),u($e.$$.fragment,dt),dt.forEach(a),this.h()},h(){i(f,"name","hf:doc:metadata"),i(f,"content",JSON.stringify(An)),i(y,"id","internals"),i(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(y,"href","#internals"),i($,"class","relative group"),i(le,"id","accelerate.optimizer.AcceleratedOptimizer"),i(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(le,"href","#accelerate.optimizer.AcceleratedOptimizer"),i(B,"class","relative group"),i(q,"class","docstring"),i(ce,"id","accelerate.data_loader.prepare_data_loader"),i(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(ce,"href","#accelerate.data_loader.prepare_data_loader"),i(F,"class","relative group"),i(P,"class","docstring"),i(he,"id","accelerate.data_loader.DataLoaderShard"),i(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(he,"href","#accelerate.data_loader.DataLoaderShard"),i(V,"class","relative group"),i(W,"class","docstring"),i(pe,"id","accelerate.data_loader.BatchSamplerShard"),i(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(pe,"href","#accelerate.data_loader.BatchSamplerShard"),i(H,"class","relative group"),i(L,"class","docstring"),i(me,"id","accelerate.data_loader.IterableDatasetShard"),i(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(me,"href","#accelerate.data_loader.IterableDatasetShard"),i(M,"class","relative group"),i(j,"class","docstring"),i(ue,"id","distributed-config"),i(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(ue,"href","#distributed-config"),i(X,"class","relative group"),i(ge,"id","accelerate.state.AcceleratorState"),i(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(ge,"href","#accelerate.state.AcceleratorState"),i(J,"class","relative group"),i(qe,"href","https://en.wikipedia.org/wiki/Singleton_pattern"),i(qe,"rel","nofollow"),i(K,"class","docstring"),i(ve,"id","accelerate.DistributedType"),i(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(ve,"href","#accelerate.DistributedType"),i(Y,"class","relative group"),i(A,"class","docstring"),i(_e,"id","accelerate.tracking.GeneralTracker"),i(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(_e,"href","#accelerate.tracking.GeneralTracker"),i(Z,"class","relative group"),i(ee,"class","docstring"),i(be,"id","accelerate.utils.extract_model_from_parallel"),i(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(be,"href","#accelerate.utils.extract_model_from_parallel"),i(te,"class","relative group"),i(ae,"class","docstring"),i(re,"class","docstring"),i(oe,"class","docstring"),i(se,"class","docstring"),i(Ke,"class","docstring"),i(Ye,"class","docstring"),i(C,"class","docstring")},m(e,c){t(document.head,f),p(e,D,c),p(e,$,c),t($,y),t(y,x),g(w,x,null),t($,E),t($,I),t(I,or),p(e,ia,c),p(e,B,c),t(B,le),t(le,ht),g(Se,ht,null),t(B,sr),t(B,pt),t(pt,nr),p(e,da,c),p(e,q,c),g(Te,q,null),t(q,lr),t(q,ft),t(ft,cr),p(e,ha,c),p(e,F,c),t(F,ce),t(ce,mt),g(xe,mt,null),t(F,ir),t(F,ut),t(ut,dr),p(e,pa,c),p(e,ie,c),t(ie,hr),t(ie,gt),t(gt,pr),t(ie,fr),p(e,fa,c),p(e,P,c),g(Pe,P,null),t(P,mr),t(P,Ae),t(Ae,ur),t(Ae,vt),t(vt,gr),t(Ae,vr),t(P,_r),t(P,R),t(R,br),t(R,_t),t(_t,$r),t(R,yr),t(R,bt),t(bt,wr),t(R,Er),t(P,Dr),g(de,P,null),p(e,ma,c),p(e,V,c),t(V,he),t(he,$t),g(ke,$t,null),t(V,Sr),t(V,yt),t(yt,Tr),p(e,ua,c),p(e,W,c),g(ze,W,null),t(W,xr),t(W,Ie),t(Ie,Pr),t(Ie,wt),t(wt,Ar),t(Ie,kr),p(e,ga,c),p(e,H,c),t(H,pe),t(pe,Et),g(Le,Et,null),t(H,zr),t(H,Dt),t(Dt,Ir),p(e,va,c),p(e,L,c),g(Ne,L,null),t(L,Lr),t(L,N),t(N,Nr),t(N,St),t(St,Or),t(N,Cr),t(N,Tt),t(Tt,Ur),t(N,Gr),t(N,xt),t(xt,Br),t(N,qr),t(L,Fr),g(fe,L,null),p(e,_a,c),p(e,M,c),t(M,me),t(me,Pt),g(Oe,Pt,null),t(M,Rr),t(M,At),t(At,Vr),p(e,ba,c),p(e,j,c),g(Ce,j,null),t(j,Wr),t(j,S),t(S,Hr),t(S,kt),t(kt,Mr),t(S,jr),t(S,zt),t(zt,Xr),t(S,Jr),t(S,It),t(It,Kr),t(S,Qr),t(S,Lt),t(Lt,Yr),t(S,Zr),t(S,Nt),t(Nt,eo),t(S,to),p(e,$a,c),p(e,X,c),t(X,ue),t(ue,Ot),g(Ue,Ot,null),t(X,ao),t(X,Ct),t(Ct,ro),p(e,ya,c),p(e,J,c),t(J,ge),t(ge,Ut),g(Ge,Ut,null),t(J,oo),t(J,Gt),t(Gt,so),p(e,wa,c),p(e,K,c),g(Be,K,null),t(K,no),t(K,Q),t(Q,lo),t(Q,qe),t(qe,co),t(Q,io),t(Q,Bt),t(Bt,ho),t(Q,po),p(e,Ea,c),p(e,Y,c),t(Y,ve),t(ve,qt),g(Fe,qt,null),t(Y,fo),t(Y,Ft),t(Ft,mo),p(e,Da,c),p(e,A,c),g(Re,A,null),t(A,uo),t(A,Rt),t(Rt,go),t(A,vo),t(A,Vt),t(Vt,_o),t(A,bo),t(A,k),t(k,at),t(at,Wt),t(Wt,$o),t(at,yo),t(k,wo),t(k,rt),t(rt,Ht),t(Ht,Eo),t(rt,Do),t(k,So),t(k,ot),t(ot,Mt),t(Mt,To),t(ot,xo),t(k,Po),t(k,st),t(st,jt),t(jt,Ao),t(st,ko),t(k,zo),t(k,nt),t(nt,Xt),t(Xt,Io),t(nt,Lo),p(e,Sa,c),p(e,Z,c),t(Z,_e),t(_e,Jt),g(Ve,Jt,null),t(Z,No),t(Z,Kt),t(Kt,Oo),p(e,Ta,c),p(e,ee,c),g(We,ee,null),t(ee,Co),t(ee,Qt),t(Qt,Uo),p(e,xa,c),p(e,te,c),t(te,be),t(be,Yt),g(He,Yt,null),t(te,Go),t(te,Zt),t(Zt,Bo),p(e,Pa,c),p(e,ae,c),g(Me,ae,null),t(ae,qo),t(ae,ea),t(ea,Fo),p(e,Aa,c),p(e,re,c),g(je,re,null),t(re,Ro),t(re,ta),t(ta,Vo),p(e,ka,c),p(e,oe,c),g(Xe,oe,null),t(oe,Wo),t(oe,aa),t(aa,Ho),p(e,za,c),p(e,se,c),g(Je,se,null),t(se,Mo),t(se,O),t(O,jo),t(O,ra),t(ra,Xo),t(O,Jo),t(O,oa),t(oa,Ko),t(O,Qo),t(O,sa),t(sa,Yo),t(O,Zo),p(e,Ia,c),p(e,Ke,c),g(Qe,Ke,null),p(e,La,c),p(e,Ye,c),g(Ze,Ye,null),p(e,Na,c),p(e,C,c),g(et,C,null),t(C,es),t(C,na),t(na,ts),t(C,as),g($e,C,null),Oa=!0},p(e,[c]){const tt={};c&2&&(tt.$$scope={dirty:c,ctx:e}),de.$set(tt);const la={};c&2&&(la.$$scope={dirty:c,ctx:e}),fe.$set(la);const ca={};c&2&&(ca.$$scope={dirty:c,ctx:e}),$e.$set(ca)},i(e){Oa||(v(w.$$.fragment,e),v(Se.$$.fragment,e),v(Te.$$.fragment,e),v(xe.$$.fragment,e),v(Pe.$$.fragment,e),v(de.$$.fragment,e),v(ke.$$.fragment,e),v(ze.$$.fragment,e),v(Le.$$.fragment,e),v(Ne.$$.fragment,e),v(fe.$$.fragment,e),v(Oe.$$.fragment,e),v(Ce.$$.fragment,e),v(Ue.$$.fragment,e),v(Ge.$$.fragment,e),v(Be.$$.fragment,e),v(Fe.$$.fragment,e),v(Re.$$.fragment,e),v(Ve.$$.fragment,e),v(We.$$.fragment,e),v(He.$$.fragment,e),v(Me.$$.fragment,e),v(je.$$.fragment,e),v(Xe.$$.fragment,e),v(Je.$$.fragment,e),v(Qe.$$.fragment,e),v(Ze.$$.fragment,e),v(et.$$.fragment,e),v($e.$$.fragment,e),Oa=!0)},o(e){_(w.$$.fragment,e),_(Se.$$.fragment,e),_(Te.$$.fragment,e),_(xe.$$.fragment,e),_(Pe.$$.fragment,e),_(de.$$.fragment,e),_(ke.$$.fragment,e),_(ze.$$.fragment,e),_(Le.$$.fragment,e),_(Ne.$$.fragment,e),_(fe.$$.fragment,e),_(Oe.$$.fragment,e),_(Ce.$$.fragment,e),_(Ue.$$.fragment,e),_(Ge.$$.fragment,e),_(Be.$$.fragment,e),_(Fe.$$.fragment,e),_(Re.$$.fragment,e),_(Ve.$$.fragment,e),_(We.$$.fragment,e),_(He.$$.fragment,e),_(Me.$$.fragment,e),_(je.$$.fragment,e),_(Xe.$$.fragment,e),_(Je.$$.fragment,e),_(Qe.$$.fragment,e),_(Ze.$$.fragment,e),_(et.$$.fragment,e),_($e.$$.fragment,e),Oa=!1},d(e){a(f),e&&a(D),e&&a($),b(w),e&&a(ia),e&&a(B),b(Se),e&&a(da),e&&a(q),b(Te),e&&a(ha),e&&a(F),b(xe),e&&a(pa),e&&a(ie),e&&a(fa),e&&a(P),b(Pe),b(de),e&&a(ma),e&&a(V),b(ke),e&&a(ua),e&&a(W),b(ze),e&&a(ga),e&&a(H),b(Le),e&&a(va),e&&a(L),b(Ne),b(fe),e&&a(_a),e&&a(M),b(Oe),e&&a(ba),e&&a(j),b(Ce),e&&a($a),e&&a(X),b(Ue),e&&a(ya),e&&a(J),b(Ge),e&&a(wa),e&&a(K),b(Be),e&&a(Ea),e&&a(Y),b(Fe),e&&a(Da),e&&a(A),b(Re),e&&a(Sa),e&&a(Z),b(Ve),e&&a(Ta),e&&a(ee),b(We),e&&a(xa),e&&a(te),b(He),e&&a(Pa),e&&a(ae),b(Me),e&&a(Aa),e&&a(re),b(je),e&&a(ka),e&&a(oe),b(Xe),e&&a(za),e&&a(se),b(Je),e&&a(Ia),e&&a(Ke),b(Qe),e&&a(La),e&&a(Ye),b(Ze),e&&a(Na),e&&a(C),b(et),b($e)}}}const An={local:"internals",sections:[{local:"accelerate.optimizer.AcceleratedOptimizer",title:"Optimizer"},{local:"accelerate.data_loader.prepare_data_loader",sections:[{local:"accelerate.data_loader.DataLoaderShard",title:"BatchSamplerShard"},{local:"accelerate.data_loader.BatchSamplerShard",title:"BatchSamplerShard"},{local:"accelerate.data_loader.IterableDatasetShard",title:"IterableDatasetShard"}],title:"DataLoader"},{local:"distributed-config",sections:[{local:"accelerate.state.AcceleratorState",title:"AcceleratorState"},{local:"accelerate.DistributedType",title:"DistributedType"}],title:"Distributed Config"},{local:"accelerate.tracking.GeneralTracker",title:"Tracking"},{local:"accelerate.utils.extract_model_from_parallel",title:"Utilities"}],title:"Internals"};function kn(ne){return Dn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class On extends $n{constructor(f){super();yn(this,f,kn,Pn,wn,{})}}export{On as default,An as metadata};
